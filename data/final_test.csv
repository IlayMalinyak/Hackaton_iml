sample,label
"    axis = Vector((1, 0, 0)) if verts[0].co.y == verts[1].co.y else Vector((0, 1, 0))
",0
"    O_verts = {v for e in original_edges for v in e.verts}
    skeleton_verts = [v for v in skeleton_verts if v in S_verts and v not in O_verts]
",0
"            ):
                y = v
                x = y.next

",0
"    """""" Link object to active scene
    """"""
",0
"    add_faces_to_map(bm, slabs, FaceMap.SLABS)
    add_faces_to_map(bm, walls, FaceMap.WALLS)
    add_faces_to_map(bm, roof, FaceMap.ROOF)


",0
"        arch_face, arch_frame_faces = create_arch(bm, top_edges, frame_faces, prop.arch, prop.frame_thickness, local_xyz(face))
        frame_faces += arch_frame_faces

    bmesh.ops.recalc_face_normals(bm, faces=list(bm.faces))

",0
"        see map_new_faces for the option *skip*
",0
"    """"""
    random.seed(prop.seed)
",0
"
def add_facemap_for_groups(groups):
    """""" Creates a face_map called group.name.lower if none exists
",0
"    def add_stairs_facemaps(cls):
        add_facemap_for_groups(FaceMap.STAIRS)
",0
"        while True:
            print(cur.__repr__())
",0
"    faces = bmesh.ops.dissolve_faces(bm, faces=faces)[""region""]

    # extrude vertically
    if prop.add_slab:
        offsets = [prop.slab_thickness, prop.floor_height] * prop.floor_count
",0
"            col = box.column(align=True)
",0
"    except IndexError:
        # -- face is too small / has no width or height after sizeoffset prop adjusted
        return
    face_center = face.calc_center_median()

",0
"
def create_multigroup(bm, faces, prop):
    """""" Create multigroup from face selection
",0
"        """"""Return the angle to the vector other""""""
",0
"        min=0.0,
        max=100.0,
",0
"            if v in e.verts:
                continue

            v1, v2 = e.verts
",0
"        description=""Depth offset of stairs"",
    )
",0
"                fill_arch(bm, arch, prop)
",0
"    linked_edges = [e for v in verts for e in v.link_edges]
    return list(filter(lambda e: e in filter_edges, linked_edges))


",0
"
    def __truediv__(self, other):
        assert type(other) in (int, float)
        return Vector2(operator.truediv(self.x, other), operator.truediv(self.y, other))
",0
"

def unregister():
    unregister_core()
",0
"def extrude_slabs_and_floors(bm, faces, prop):
    """"""extrude edges alternating between slab and floor heights
",0
"from mathutils import Vector


def create_floors(bm, faces, prop):
    """"""Create extrusions of floor geometry from a floorplan
",0
"    clubbed_faces = subdivide_face_horizontally(bm, face, clubbed_widths)

    doors = []
    windows = []
",0
"

def map_balcony_faces(bm, face):
    """""" Add balcony faces to their facemap """"""
",0
"    def __lt__(self, other):
        if isinstance(other, LAVertex):
            return self.point.x < other.point.x

    def __repr__(self):
",0
"
    def D(direction):
",0
"        max=100.0,
        default=0.05,
        step=1,
",0
"    door_face, new_frame_faces = add_door_depth(bm, door_face, prop.door_depth, normal)
",0
"        cap_tris=True,
        segments=segs,
",0
"import bmesh

from mathutils import Vector, Quaternion
from bmesh.types import BMFace, BMEdge
",0
"class EdgeEvent(
",0
"def cycle_edges_form_polygon(bm, verts, skeleton_edges, linked_edges):
    """""" Move in opposite directions along edges linked to verts until
    you form a polygon
",0
"class SLAV:
",0
"            row.prop(self, ""width"")
            row.prop(self, ""length"")
",0
"
def create_hshaped_floorplan(bm, prop):
    """"""Create H_shaped geometry from a rectangle

    .___.      .___.
",0
"        box = layout.box()
        if self.type == ""RECTANGULAR"":
            col = box.column(align=True)
",0
"                        continue
",0
"
    min_z = min([v.co.z for e in edges for v in e.verts])
",0
"        return ev

    def invalidate(self):
        if self.lav is not None:
",0
"    verts = sort_verts(
        list({v for e in filter_geom(ret[""geom_split""], bmesh.types.BMEdge) for v in e.verts}),
        xyz[0]
    )
    theta = math.pi / (len(verts) - 1)
",0
"        add_facemap_for_groups(FaceMap.DOOR_LOUVERS)
        fill_louver(bm, face, prop.louver_fill, user=FillUser.DOOR)


",0
"        col.prop_menu_enum(self, ""fill_type"", text=prop_name)

",0
"    FaceMap,
    validate,
",0
"            source_height = [arc.height for arc in skeleton if arc.source == source]
            ht = source_height.pop() * height_scale
            vsource = make_vert(bm, Vector((source.x, source.y, median.z + ht)))
            skeleton_verts.append(vsource)
",0
"    )

    tl1: FloatProperty(
        name=""Tail Length 1"",
        min=0.0,
",0
"
def register_floorplan():
    for cls in classes:
        bpy.utils.register_class(cls)
",0
"            )
            vertex.lav = lav
            if lav.head is None:
",0
"        prop_name = ""Fill Type"" if self.fill_type == ""NONE"" else self.fill_type.title().replace('_', ' ')
",0
"def create_bar_from_face(bm, face, median, position, scale, depth, vertical=False):
    """"""Create bar geometry from a face
    """"""
    dup = duplicate_face_translate_scale(bm, face, position, scale, median).get(""geom"")
",0
"
    def __iter__(self):
        for lav in self._lavs:
            yield lav

",0
"from collections import namedtuple

",0
"from .multigroup_props import MultigroupProperty

classes = (MultigroupProperty, BTOOLS_OT_add_multigroup)

",0
"    )


def cone(bm, r1=0.5, r2=0.01, height=2, segs=32):
",0
"        edges.extend(filter_geom(res[""geom_inner""], BMEdge))
    bmesh.ops.remove_doubles(bm, verts=bm.verts, dist=0.01)
",0
"    WallFillProperty,
    RailProperty,
)

",0
"                break


class EventQueue:
    def __init__(self):
",0
"    frame_faces += new_frame_faces

    # add face maps
    add_faces_to_map(bm, [door_face], FaceMap.DOOR)
    add_faces_to_map(bm, frame_faces, FaceMap.FRAME)
",0
"        min=0.01,
        max=1.0,
        default=0.1,
",0
"
class BTOOLS_OT_add_stairs(bpy.types.Operator):
    """"""Create stairs from selected faces""""""

    bl_idname = ""btools.add_stairs""
",0
"    slab_outset: FloatProperty(
",0
"    """"""Create glass panes on face
    """"""
    if prop.pane_count_x + prop.pane_count_y == 0:
",0
"    _connect_line2 = _connect_unimplemented

",0
"        ev = min(
            events, key=lambda event: self.point.distance(event.intersection_point)
        )

",0
"
",0
"        for item in self.__data:
            print(item)


def skeletonize(polygon, holes=None):
",0
"    bl_options = {""DEFAULT_CLOSED""}

    @classmethod
    def poll(cls, context):
        obj = context.object
",0
"        for l in new_lavs:
",0
"    import os
    os.system(""clear"")

    # -- custom unregister for script watcher
    for tp in dir(bpy.types):
",0
"
    dw_depth: FloatProperty(
",0
"        min=0.0,
        max=100.0,
        description=""Width of floorplan segment"",
        get=lambda self : self.get_segment_width(""tw1""),
        set=lambda self, value : self.set_segment_width(value, ""tw1""),
",0
"    circle(bm, prop.radius, prop.segments, prop.cap_tris)
",0
"            return not all([f in roof_faces for f in e.link_faces])

",0
"        min=0,
        max=100,
        default=1,
",0
"        col.prop(self, ""count"")

        col = box.column(align=True)
        col.prop(self, ""double_door"")

",0
"
",0
"    elif prop.fill == ""WALL"":
        add_facemap_for_groups(FaceMap.RAILING_WALLS)
        create_fill_walls(bm, dup_face, prop)
",0
"
",0
"        Clamp the segment width to less than default_width + base width
",0
"    def __repr__(self):
        return ""{} = {}"".format(str(self), [vertex for vertex in self])

    def __len__(self):
",0
"from .balcony_ops import BTOOLS_OT_add_balcony
from .balcony_props import BalconyProperty

",0
"

def add_railing_to_stairs(bm, top_faces, normal, prop):
    steps = sort_faces(top_faces, normal)
",0
"        min=0.0,
        max=1.0,
        default=0.05,
        description=""Depth of door"",
",0
"    bmesh.ops.delete(bm, geom=ret[""faces""], context=""FACES"")

",0
"            layout.alignment = ""CENTER""
            layout.label(text="""", icon_value=icon)

",0
"    namedtuple(""EdgeEvent"", ""distance intersection_point etype vertex_a vertex_b"")
):
",0
"

class LAV:
",0
"        return {""CANCELLED""}
",0
"        bm = bmesh.from_edit_mesh(me)
        faces = [face for face in bm.faces if face.select]
",0
"    """"""
    ret = bmesh.ops.duplicate(bm, geom=[face])
    verts = filter_geom(ret[""geom""], BMVert)

",0
"    equal,
    FaceMap,
    filter_geom,
",0
"
def local_xyz(face):
    """""" Get local xyz directions
    """"""
",0
"            return self.get(""size"", restricted_size(
                self['parent_dimensions'], self.offset, (0.1, 0.1), self['default_size']
            ))
        else:
",0
"        default=""FILLED"",
        description=""Bottom type of stairs"",
    )
",0
"
    for e in edges:
        if rnd(normal.x):
            s = set([rnd(v.co.y) for v in e.verts])
        else:
",0
"    for cls in classes:
        bpy.utils.register_class(cls)


def unregister_roof():
",0
"    bmesh.ops.translate(
        bm,
",0
"
        box = layout.box()
",0
"
",0
"                fill_window_face(bm, window, prop)
            if prop.add_arch:
                fill_arch(bm, arch, prop)
    return True
",0
"    """"""
",0
"                    xedge = (
                        cross(edge.edge.v.normalized(), (b - edge.edge.p).normalized())
                        < 0
",0
"    wall_w, wall_h = calc_face_dimensions(face)
    # horizontal split
    h_widths = [wall_w/2 + offset.x - size.x/2, size.x, wall_w/2 - offset.x - size.x/2]
    h_faces = subdivide_face_horizontally(bm, face, h_widths)
",0
"    """""" Create a cone in the bmesh
",0
"
",0
"            s = set([rnd(v.co.x) for v in e.verts])

        if len(s) == 1:
            res.append(e)
    return res
",0
"    subdivide_edges,
    calc_edge_median,
    filter_vertical_edges,
    add_facemap_for_groups,
)
",0
"import heapq
import operator
import itertools as it
",0
"    """"""
    cy = cylinder(bm, radius, height, segs)
    bmesh.ops.translate(bm, verts=cy[""verts""], vec=position)
    return cy
",0
"    verts = sorted(verts, key=lambda v: (v.co.x, v.co.y))
    _min_x, _max_x = verts[0], verts[-1]

    verts = sorted(verts, key=lambda v: (v.co.y, v.co.x))
",0
"        elif self.type == ""H-SHAPED"":
            row = box.row(align=True)
",0
"            bmesh.update_edit_mesh(me, True)
            return {""FINISHED""}
        return {""CANCELLED""}

    @classmethod
",0
"        inset(bm, faces=[face], thickness=prop.louver_margin)

    segments = double_and_make_even(prop.louver_count)
    faces = subdivide_face_into_vertical_segments(bm, face, segments)
    faces.sort(key=lambda f: f.calc_center_median().z)
",0
"

def unregister_floorplan():
",0
"
    @classmethod
    def validate(cls, faces):
        if faces:
",0
"    elif prop.fill_type == ""LOUVER"":
        add_facemap_for_groups(FaceMap.WINDOW_LOUVERS)
        fill_louver(bm, face, prop.louver_fill, user=FillUser.WINDOW)
import bpy

",0
"        return self.__class__(self.x, self.y)

    copy = __copy__

    def __repr__(self):
",0
"
",1
"                )


",1
"        dist_backend=""nccl"",
        dist_init_method=dist_init_method,
        dist_master_addr=None,
        dist_master_port=None,
",1
"                Input variable from encoder.

        Returns:
            chainer.Variable: A n-dimension float array.
",1
"    ""normalize"",
    classes=dict(global_mvn=GlobalMVN, utterance_mvn=UtteranceMVN,),
    type_check=AbsNormalize,
    default=""utterance_mvn"",
    optional=True,
",1
"        else:
            self.writer_scp = None
        if write_num_frames is not None:
            self.writer_nframe = get_num_frames_writer(write_num_frames)
",1
"        if batch_size > 1:
            indices = sorted(range(len(dataset)), key=lambda i: -len(dataset[i]))
            bs = 0
            while bs < length:
",1
"        for train_subset in train_subsets:
            if maxlen != len(train_subset):
                for i in six.moves.xrange(maxlen - len(train_subset)):
",1
"        model.translate(in_data, args, args.char_list)  # decodable
        if ""pytorch"" in module:
            batch_in_data = np.random.randint(0, 5, (2, 10))
            model.translate_batch(
                batch_in_data, args, args.char_list
",1
"        ""--epochs"", ""-e"", default=30, type=int, help=""Maximum number of epochs""
    )
    parser.add_argument(
",1
"        report_wer (boolean): compute WER option
",1
"@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
",1
"        pos_enc_class=PositionalEncoding,
        normalize_before=True,
        concat_after=False,
        positionwise_layer_type=""linear"",
",1
"        return h, ilen
#!/usr/bin/env python3

""""""Define e2e module for multi-encoder network. https://arxiv.org/pdf/1811.04903.pdf.""""""
# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
"    dst = f""{gendir}/{fname}""
    modules_rst += f""   ./_gen/{fname}\n""
",1
"    type_check=AbsNormalize,
    default=""global_mvn"",
    optional=True,
)
tts_choices = ClassChoices(
",1
"            ""--log_level"",
            type=lambda x: x.upper(),
            default=""INFO"",
",1
"
        # Compute the loss at this time step and accumulate it
        if self.ngpu == 0:
",1
"    )
    trainer.extend(
        extensions.PrintReport(
",1
"        logging.info(""ctc loss:"" + str(self.loss.data))

        return self.loss

",1
"    else:
        rnnlm = None

    # gpu
",1
"    _, data = dataset[""a""]
    assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))

    _, data = dataset[""b""]
",1
"        type=str,
",1
"        :param Namespace recog_args: argument Namespace containing options
        :param list char_list: list of characters
        :param torch.nn.Module rnnlm: language model module
        :return: N-best decoding results
        :rtype: list
",1
"        ""oov rate in the training data = %.2f %%""
        % (n_train_oovs / n_train_tokens * 100)
    )
    logging.info(""#sentences in the validation data = "" + str(len(val)))
    logging.info(""#tokens in the validation data = "" + str(n_val_tokens))
",1
"        # pys: utt x olen
        ys_in_pad = pad_list(ys_in, self.eos)
",1
"        in_dic[""name""] = ""input1""
        in_dic[""feat""] = dic[""feat""]

        out_list = []
",1
"    parser = argparse.ArgumentParser(description=""evaluate permutation-free error"")
    parser.add_argument(
        ""--num-spkrs"", type=int, default=2, help=""number of mixed speakers.""
    )
    parser.add_argument(
",1
"    write_num_frames: str = None,
    compress: bool = False,
",1
"        :return: attention weighted encoder state (B, D_enc)
        :rtype: torch.Tensor
        :return: previous attention weights
        :rtype: torch.Tensor
        """"""
",1
"        group.add_argument(
            ""--dunits"", default=1536, type=int, help=""Number of decoder hidden units""
        )
        group.add_argument(
",1
"        output_sigmoid = dil_sigmoid(x)
        output_tanh = dil_tanh(x)
        aux_output_sigmoid = aux_1x1_sigmoid(h)
        aux_output_tanh = aux_1x1_tanh(h)
",1
"
        if beamformer_type != ""mvdr"":
",1
"    @staticmethod
    def add_arguments(parser):
        """"""Add arguments.""""""
        E2E.encoder_add_arguments(parser)
        E2E.attention_add_arguments(parser)
",1
"def get_args():
    parser = argparse.ArgumentParser(description=""my script"")
    parser.add_argument(""--path"", ""-p"", required=True, help=""path to decode dir"")
    args = parser.parse_args()
    return args
",1
"import six

# chainer related
import chainer

",1
"
    # load trained model parameters
    logging.info(""reading model parameters from "" + args.model)
",1
"        help=""Analisys window length in point"",
    )
    parser.add_argument(
        ""--window"",
        type=str,
",1
"
        # get positional encoding class
        pos_enc_class = (
",1
"    minlenratio: float = 0.0,
    pre_beam_ratio: float = 1.5,
",1
"                )
",1
"        elif isinstance(args.token_list, (tuple, list)):
            token_list = list(args.token_list)
",1
"    """"""Initialize encoder parameters.""""""
    if isinstance(m, torch.nn.Conv1d):
        torch.nn.init.xavier_uniform_(m.weight, torch.nn.init.calculate_gain(""relu""))
",1
"        ""-O"",
        tmpzip,
    ]
    subprocess.run(cmd, check=True)

",1
"        group.add_argument(
            # Not starting with ""dist_"" for compatibility to launch.py
            ""--local_rank"",
",1
"            rs = [re.compile(re.escape(x)) for x in nls]

    if args.text:
",1
"    if compute_permutation:
",1
"            return zip_longest(*kargs, fillvalue=fillvalue)

",1
"    ) as transcript_f, open(os.path.join(""data"", x, ""text""), ""w"") as text_f, open(
",1
"            (
",1
"
        # SD and Rec encoder
        xs_pad_sd = [xs_pad for i in range(self.num_spkrs)]
        ilens_sd = [ilens for i in range(self.num_spkrs)]
        for ns in range(self.num_spkrs):
",1
"        )
        group.add_argument(
",1
"    def log_attentions(self, logger, step):
        """"""Add image files of att_ws matrix to the tensorboard.""""""

        def log_fig(plot, filename):
",1
"                olens_in = olens.new([olen // self.reduction_factor for olen in olens])
            else:
                olens_in = olens
            attn_loss = self.attn_loss(att_ws, ilens, olens_in)
",1
"
        """"""
",1
"        type=int,
        default=2,
",1
"            For chainer, list of source sequences chainer.Variable
        :param ilens: batch of lengths of source sequences (B)
",1
"                        ""score"": new_hyp[""score""] + float(ytu[k]),
                        ""yseq"": new_hyp[""yseq""][:],
                        ""z_prev"": new_hyp[""z_prev""],
                        ""c_prev"": new_hyp[""c_prev""],
",1
"    # set torch device
",1
"    logging.info(""set random seed = %d"" % args.seed)

    # trans
",1
"
        if norm_vars:
            var = x.pow(2).sum(dim=1, keepdim=True) / ilens_
",1
"                            text = text.replace(model.blank, """")
                            logging.info(text)
                            for n in range(args.nbest):
",1
"    parser.add_argument(
        ""--compress"", type=strtobool, default=False, help=""Save in compressed format""
    )
    parser.add_argument(
",1
"    num_optimizers: int = 1

    # Add variable objects configurations
    class_choices_list = [
        # --frontend and --frontend_conf
",1
"            {""report_cer"": True, ""report_wer"": True, ""mtlalpha"": 0.0},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"            if isinstance(conffile, dict):
                self.conf = copy.deepcopy(conffile)
            else:
                with io.open(conffile, encoding=""utf-8"") as f:
",1
"                {
",1
"
        if utt2ratio is not None:
            self.utt2ratio = {}
            # Use the scheduled ratio for each utterances
",1
"        drop_last:
        min_batch_size:  Used for ""numel"" or ""folded"" mode
        fold_lengths: Used for ""folded"" mode
        padding: Whether sequences are input as a padded tensor or not.
            used for ""numel"" mode
",1
"
def make_dummy_json(
    n_utts=10,
    ilen_range=(100, 300),
    olen_range=(10, 300),
",1
"    def _get_last_yseq(exp_yseq):
        last = []
        for y_seq in exp_yseq:
            last.append(y_seq[-1])
        return last
",1
"
        if self.epoch - 1 not in self.stats or key not in self.stats[self.epoch - 1]:
            # If the previous epoch doesn't exist for some reason,
            # maybe due to bug, this case also indicates 0-count.
            if self.epoch - 1 != 0:
",1
"def test_(float_pad_value, int_pad_value, not_sequence):
    _common_collate_fn = CommonCollateFn(
        float_pad_value=float_pad_value,
        int_pad_value=int_pad_value,
        not_sequence=not_sequence,
",1
"
import configargparse
import logging
import os
import platform
",1
"    :param bool han_mode:
        flag to swith on mode of hierarchical attention and not store pre_compute_enc_h
    """"""

    def __init__(
",1
"            help=""Number of encoder layers (for shared recognition part ""
            ""in multi-speaker asr mode)"",
        )
        group.add_argument(
            ""--eunits"",
",1
"    maxout_len,
    spk_embed_dim=None,
    spc_dim=None,
",1
"        logging.info(
            self.__class__.__name__
",1
"
",1
"    ctc_type=""warpctc"",
    report_cer=False,
    report_wer=False,
",1
"@pytest.mark.parametrize(
",1
"                # w: previous concate attentions
                # w: (B, nprev, Tin)
                att_w = w[:, -1].detach().cpu()
                outputs.setdefault(name, []).append(att_w)
",1
"            pre, mid, last = source.split(""-"")
            utt_id = ""-"".join([mid, pre, last])

",1
"# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #
",1
"                    'embed_id_bwd_ignore_label')(
                        gy, xp.expand_dims(x, -1), gW.shape[1],
                        self.ignore_label, gW)
            """"""
            # EmbedID gradient alternative without atomicAdd, which simply
",1
"                att_list.append(att)
",1
"    parser.add_argument(
",1
"            cell (torch.nn.Module): Pytorch recurrent cell module
",1
"        plot_keys = [""loss"", ""l1_loss"", ""mse_loss"", ""bce_loss""]
        if self.use_guided_attn_loss:
            plot_keys += [""attn_loss""]
        if self.use_cbhg:
",1
"    ys = [np.random.randn(lg, odim) for lg in olens]
    ilens = torch.LongTensor(ilens).to(device)
    olens = torch.LongTensor(olens).to(device)
",1
"        logging.warning(""%s"", mods_model)

",1
"                torch.cat((self.dropout_dec[-1](z_list[-1]), att_c), dim=-1)
            )
",1
"            ilens (LongTensor): Batch of lengths of each input batch (B,).
",1
"        if len(keys) == 0:
            raise RuntimeError(f""0 lines found: {shape_files[0]}"")

        if padding:
            for d, s in zip(utt2shapes, shape_files):
",1
"        )
        return tscore, (presub_score, new_st)
""""""Length bonus module.""""""
from typing import Any
",1
"                The schedulers of `optimizer`
            device (int): The device id
            gradclip (float): The gradient clipping value to use
            use_apex (bool): The flag to use Apex in backprop.
",1
"        d = OrderedDict()
        with open(enh, ""r"") as f:
            for line in f:
                key, path = line.split(None, 1)
                d[key] = path.rstrip()
",1
"                    local_scores = (
",1
"
if __name__ == ""__main__"":
",1
"    text = uppercase(text)
    text = collapse_whitespace(text)
    return text


",1
"
    @classmethod
    @abstractmethod
    def build_preprocess_fn(
        cls, args: argparse.Namespace, train: bool
",1
"            ""normalized log probability: ""
            + str(nbest_hyps[0][""score""] / len(nbest_hyps[0][""yseq""]))
        )
        return nbest_hyps

",1
"        :return: N-best decoding results
        :rtype: list
        """"""
        raise NotImplementedError(""Batch decoding is not supported yet."")
",1
"    """"""

    def __init__(self, module: torch.nn.Module, name: str):
        assert check_argument_types()
        super().__init__()
",1
"        reporter.report({""loss"": sum_loss}, optimizer.target)
        reporter.report({""count"": count}, optimizer.target)
",1
"    assert torch.equal(enhanced2.real, enhanced[1].real)
",1
"    for some use-case. e.g. Concatenation, Splitting.

    """"""
    if filetype == ""mat"":
        return KaldiWriter(
",1
"
",1
"            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
",1
"    def __len__(self):
        return len(self.batch_list)
",1
"import yaml

",1
"    if uid in unnorm_utt:
        continue  # avoid double reporting the same problem
",1
"            {""atype"": [""multi_head_dot"", ""multi_head_dot"", ""multi_head_dot""]},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"    with pytest.raises(SystemExit):
        LMTask.main(cmd=[""--print_config""])


def test_main_with_no_args():
",1
"    else:
        use_apex = False

    # FIXME: TOO DIRTY HACK
    setattr(optimizer, ""target"", reporter)
",1
"        y_src = (torch.randn(batchsize, 10) * n_token % n_token).long() + 1
        y_tgt = (torch.randn(batchsize, 11) * n_token % n_token).long() + 1
        # NOTE: + 1 to avoid to assign idx:0
    else:
",1
"        also `loss.png` will be created as a figure visulizing `main/loss`
        and `validation/main/loss` values.

",1
"
",1
"    for i in range(bs):
        true_perm_2.append(perm_choices_2[i % 4])
    true_perm_2 = torch.tensor(true_perm_2).long()

",1
"#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
",1
"                hyps_same_length, key=lambda x: x[""score""], reverse=True
            )[0]
            if best_hyp_same_length[""score""] - best_hyp[""score""] < D_end:
                count += 1

",1
"
    retval = unpack(str(tmp_path / ""out.tgz""), str(tmp_path))
    assert retval == {
        ""abc"": str(tmp_path / ""packed"" / ""abc.pth""),
        ""def"": str(tmp_path / ""packed"" / ""def.yaml""),
",1
"        ),
        (""transformer"", {""encoder_concat_after"": True}),
        (""transformer"", {""decoder_concat_after"": True}),
        (""transformer"", {""encoder_concat_after"": True, ""decoder_concat_after"": True}),
        (""transformer"", {""transfer_encoder_from_teacher"": True}),
",1
"                bpemodel=bpemodel,
                delimiter=delimiter,
                space_symbol=space_symbol,
",1
"        ""xs"": xs,
        ""ilens"": ilens,
        ""ys"": ys,
        ""labels"": labels,
",1
"            help=""Whether to use masking in calculation of loss"",
        )
        group.add_argument(
            ""--use-weighted-masking"",
            default=False,
",1
"            # check gradient value
            grad_norm = np.sqrt(
                sum_sqnorm([p.grad for p in optimizer.target.params(False)])
            )
",1
"
        Returns:
",1
"def file_reader_helper(
",1
"            reporter.report({""cer"": cer}, self)
            reporter.report({""wer"": wer}, self)
",1
"        help=""language tag (can be used for multi lingual case)"",
    )
    parser.add_argument(""--spk_tag"", type=str, help=""speaker tag"")
    parser.add_argument(""jsons"", nargs=""+"", type=str, help=""*_mls.json filenames"")
    parser.add_argument(""out"", type=str, help=""output filename"")
",1
"    )
    # training configuration
",1
"    )
",1
"    """"""

    def __init__(
        self,
",1
"
        Args:
            hs (list of chainer.Variable | N-dimension array):
",1
"        assert olen < batch_elems

    model = m.E2E([20 for _ in range(num_encs)], 5, args)
    for batch in batchset:
",1
"        # weighted sum over flames
",1
"            help=""Number of layers to be applied guided attention loss""
",1
"        self.rnn_type = rnn_type
",1
"
""""""LM training in pytorch.""""""

",1
"            if ctc_scorer[0]:
",1
"from espnet.nets.pytorch_backend.ctc import CTC
",1
"from espnet.nets.chainer_backend.rnn.decoders import decoder_for
from espnet.nets.chainer_backend.rnn.encoders import encoder_for
",1
"
",1
"                # https://discuss.pytorch.org/t/why-torch-nn-parallel-distributeddataparallel-runs-faster-than-torch-nn-dataparallel-on-single-machine-with-multi-gpu/32977/2
                logging.info(f""single-node with {args.ngpu}gpu using DataParallel"")

        # Using cmd as it is simply
",1
"    scores, new_results = main()
    score_sum = np.sum(scores, axis=0, dtype=int)

    # Print results
    print(sys.argv)
",1
"def test_SortedBatchSampler(shape_files, sort_in_batch, sort_batch, drop_last):
    sampler = SortedBatchSampler(
        2,
        shape_file=shape_files[0],
        sort_in_batch=sort_in_batch,
",1
"    ""float_pad_value, int_pad_value, not_sequence"",
    [(0.0, -1, ()), (3.0, 2, (""a"",)), (np.inf, 100, (""a"", ""b""))],
)
def test_CommonCollateFn_repr(float_pad_value, int_pad_value, not_sequence):
",1
"                weight.new_zeros(self.nlayers, bsz, self.nhid),
            )
        else:
            return weight.new_zeros(self.nlayers, bsz, self.nhid)
",1
"    """"""Send tensor into the device of the module.

    Args:
        m (torch.nn.Module): Torch module.
",1
"from espnet.asr.asr_utils import torch_load
from espnet.asr.asr_utils import torch_resume
from espnet.asr.asr_utils import torch_snapshot
",1
"
    def __init__(self, idims, odim, args):
",1
"        return 0.5 * torch.square(r) * torch.log(torch.max(r, EPSILON))
    elif order % 2 == 0:
        r = torch.max(r, EPSILON)
        return 0.5 * torch.pow(r, 0.5 * order) * torch.log(r)
    else:
",1
"    report_keys = [
        ""epoch"",
        ""iteration"",
        ""main/loss"",
",1
"
import numpy
import pytest
",1
"    ""sphinx_markdown_tables"",
]

",1
"    )
",1
"                self.input_layer = LinearSampling(
                    idim, attention_dim, initialW=initialW, initial_bias=initial_bias
                )
",1
"                    z_list[0],
",1
"

def create_dense_flows(flattened_flows, batch_size, image_height, image_width):
",1
"        self.labeldist = labeldist
",1
"        att_conv = self.loc_conv(att_prev.view(batch, 1, 1, self.h_length))
        # att_conv: utt x att_conv_chans x 1 x frame -> utt x frame x att_conv_chans
        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"    parser.add_argument(""--fbank-fmin"", type=float, default=0.0, help="""")
    parser.add_argument(""--fbank-fmax"", type=float, default=None, help="""")
",1
"    except ImportError:
        logging.warning(""--> it seems that nccl is not installed. multi-gpu is not enabled."")
        logging.warning(""--> if you want to use multi-gpu, please install it and then re-setup."")
    try:
        assert torch.cuda.device_count() > 1
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"       Sentence batches are made in order of longer sentences, and then
       randomly shuffled.
",1
"import numpy as np
import torch
from typing import Tuple
",1
"    # define model
    model = Transformer(idim, odim, Namespace(**model_args))

    # test encoder self-attention
",1
"import torch
from torch import nn

from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm
",1
"        ch_model.ctc.ctc_lo.b.grad,
        th_model.ctc.ctc_lo.bias.grad.data.numpy(),
        1e-5,
        1e-6,
    )
",1
"        best_epoch = self.get_best_epoch(key1, key2, mode)
        if epoch - best_epoch > patience:
            logger.info(
                f""[Early stopping] {key1}.{key2} has not been ""
",1
"        value = (value[1], value[0])
",1
"        comm = MPI.COMM_WORLD
        # Assume ntasks_per_node == 1 (We can't check whether it is or not)
        return comm.Get_size()
    elif launcher is not None:
",1
"        # Note(kamo): Changed from the original: isalpha() -> isalnum()
        # not trans.strip().replace(' ', '').replace(""'"", """").isalpha():
        err(
            ""The transcript for '%s'(user '%s') is not properly normalized - skipped!""
            % (u, id_prefix)
",1
"        if model_args[""spk_embed_dim""] is None:
            spemb = None
        else:
            spemb = batch[""spembs""][0]
",1
"    args = get_parser().parse_args(args)
    convert(args.json, args.refs, args.hyps, args.num_spkrs)

",1
"            type=float,
            help=""Positive sample weight in BCE calculation ""
            ""(only for use-masking=True)"",
",1
"    """"""Apply utterance mean and variance normalization

    Args:
        x: (B, T, D), assumed zero padded
        ilens: (B,)
",1
"        xs = xs[:, : max(ilens)]
        ys = ys[:, : max(olens)]
        if extras is not None:
            extras = extras[:, : max(ilens)].squeeze(-1)
",1
"    """"""Parse wspecifier to dict

    Examples:
        >>> parse_wspecifier('ark,scp:out.ark,out.scp')
",1
"    key_file: Optional[str],
    asr_train_config: str,
    asr_model_file: str,
",1
"
        # get ctc loss
        self.loss = F.connectionist_temporal_classification(
",1
"        tgt_lang=False,
        asr_weight=0.0,
        mt_weight=0.0,
    )
    defaults.update(kwargs)
",1
"        melmat = librosa.filters.mel(**_mel_options)
        # melmat: (D2, D1) -> (D1, D2)
        self.register_buffer(""melmat"", torch.from_numpy(melmat.T).float())
",1
"    except AssertionError:
        logging.warning(""--> it seems that cudnn is not available in torch."")
",1
"    extras_require=extras_require,
    python_requires="">=3.6.0"",
    classifiers=[
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 3"",
",1
"        self.dropout_rate = dropout_rate
        self.loss = None
",1
"        if shared:
            # NOTE(kamo): Don't set manager as a field because Manager, which includes
            # weakref object, causes following error with method=""spawn"",
",1
"            lambda: EncoderLayer(
",1
"            "" ("" + j[""utts""][x][""utt2spk""].replace(""-"", ""_"") + ""-"" + x + "")\n""
",1
"        self.masks = None
",1
"            sys.stderr.write(
",1
"            hyp_words = seq_hat_text.split()
",1
"        )

    def __call__(self, x):
        return add_deltas(x, window=self.window, order=self.order)
",1
"        raise ValueError(""Only pytorch are supported."")

",1
"
",1
"        >>> make_non_pad_mask(lengths)
        masks = [[0, 0, 0, 0 ,0],
",1
"
        :param int d_model: embedding dim
        :param float dropout_rate: dropout rate
        :param int max_len: maximum input length
",1
"    parser.add_argument(
        ""--enc-init-mods"",
",1
"        ""main"": ChainerDataLoader(
            dataset=TransformDataset(valid, lambda data: converter([load_cv(data)])),
",1
"    DurationCalculator,  # noqa: H301
)
",1
"                for hyp in hyps:
                    logging.debug(
",1
"# If you need to define custom scheduler, please inherit these classes
class AbsBatchStepScheduler(AbsScheduler):
",1
"                ""multi_head_multi_res_loc"",
            ],
            help=""Type of attention architecture (multi-encoder asr mode only)"",
",1
"        use_projection: Use projection layer or not
        num_layers: Number of recurrent layers
",1
"    else:
        rnnlm = None

    if args.word_rnnlm:
",1
"
    If kwargs are invalid, raise TypeError as same as python default
    :param function func: function to be validated
    :param dict kwargs: keyword arguments for func
",1
"@pytest.mark.parametrize(""requires_grad"", [False, True])
@pytest.mark.parametrize(""replace_with_zero"", [False, True])
@pytest.mark.parametrize(""dim"", [""freq"", ""time""])
def test_MaskAlongAxis(dim, replace_with_zero, requires_grad):
",1
"
    def recognize(self, x, recog_args, char_list=None, rnnlm=None, use_jit=False):
        """"""Recognize input speech.
",1
"        help=""Apply Weighted Prediction Error"",
    )
    parser.add_argument(
        ""--wtype"",
",1
"            ""espnet.nets.pytorch_backend.e2e_st"",
",1
"        optim = torch.optim.Adam(model.parameters(), 0.01)
        loss = model(x, ilens, y_tgt, y_src)
        optim.zero_grad()
        loss.backward()
        optim.step()
",1
"            hs = self._integrate_with_spk_embed(hs, spembs)

        # forward duration predictor and length regulator
        d_masks = make_pad_mask(ilens).to(xs.device)
",1
"    try:
        assert torch.backends.cudnn.is_available()
        logging.info(""--> cudnn is available in torch."")
",1
"
        """"""
",1
"        """"""
        prev = self.training
        self.eval()
        ilens = [x.shape[0]]
",1
"        blayers=args.blayers,
        bunits=args.bunits,
        bprojs=args.bprojs,
        bnmask=args.bnmask,
        badim=args.badim,
",1
"            i.e. actual batchsize will be doubled.

    """"""

    def __init__(self, train_iter, optimizer, converter, device, accum_grad=1):
",1
"@pytest.mark.parametrize(""sort_in_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""drop_last"", [True, False])
",1
"        )
    else:
        trainer.extend(torch_snapshot(), trigger=(1, ""epoch""))

",1
"        )
        return parser

",1
"    Returns:
        type: Scheduler class

    """"""
",1
"                        # {""input"":
                        #  [{""feat"": ""some/path.h5:F01_050C0101_PED_REAL"",
                        #    ""filetype"": ""hdf5"",
                        #    ""name"": ""target1"", ...}], ...}
",1
"        trainer.extend(
",1
"        lpz = None

        # 2. Decoder
        hlens = torch.tensor(list(map(int, hlens)))  # make sure hlens is tensor
        y = self.dec.recognize_beam_batch(
",1
"        else:
            raise RuntimeError(f""Not supported: loader_type={loader_type}"")

    def has_name(self, name) -> bool:
        return name in self.loader_dict
",1
"        """"""

        batch = enc_hs_pad.size(0)
",1
"                MultiHeadedAttention(
                    attention_heads, output_size, attention_dropout_rate
",1
"
import torch


",1
"    """"""Load torch model states.

",1
"
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask


",1
"        return (
",1
"        t_zero = random.randrange(0, len_spectro - t)
",1
"        ""--trg"",
        ""-t"",
",1
"            # sort and get nbest
            hyps = hyps_best_kept
            logging.debug(""number of pruned hypothes: "" + str(len(hyps)))
",1
"    if backend == ""pytorch"":
        xs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0)
        ys_pad = pad_list([torch.from_numpy(y).long() for y in ys], -1)
        ilens = torch.from_numpy(ilens).long()
",1
"
        Returns:
",1
"        # make a utt list (1) to use the same interface for encoder
        if self.multilingual:
            ilen = [len(x[0][1:])]
            h = to_device(
",1
"""""""Initialize sub package.""""""
",1
"in the Software without restriction, including without limitation the rights
",1
"

def test_main():
    with pytest.raises(SystemExit):
        main()
",1
"        # att_conv: utt x att_conv_chans x 1 x frame -> utt x frame x att_conv_chans
        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"    # test runnable with tensorboard logger
    for log_interval in [1, 3]:
",1
"    parser.add_argument(""--verbose"", ""-V"", default=0, type=int, help=""Verbose option"")
    parser.add_argument(
",1
"
        for class_choices in cls.class_choices_list:
            if getattr(args, class_choices.name) is not None:
",1
"            2,
",1
"from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import (
    Tacotron2Loss as TransformerLoss,  # noqa: H301
)
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask
",1
"            hyps = kept_hyps
",1
"        # check ilens type (should be list of int)
        if isinstance(ilens, torch.Tensor) or isinstance(ilens, np.ndarray):
            ilens = list(map(int, ilens))

        self.eval()
",1
"                non_linguistic_symbols=args.non_linguistic_symbols,
            )
        else:
            retval = None
",1
"    [
        (""a,b, c"", (""a"", ""b"", ""c"")),
",1
"            reporter.load_state_dict(states[""reporter""])
",1
"    """"""Plot an attention reporter.

    Args:
",1
"                        ""a_prev"": new_hyp[""a_prev""],
                    }
                    if rnnlm:
",1
"
",1
"    shape_files, sort_in_batch, sort_batch, drop_last, padding
",1
"        if not write_vocabulary:
            fout.write("" "".join(tokens) + ""\n"")
        else:
",1
"from espnet.utils.training.train_utils import set_early_stop

from espnet.asr.pytorch_backend.asr import CustomEvaluator
from espnet.asr.pytorch_backend.asr import CustomUpdater
from espnet.asr.pytorch_backend.asr import load_trained_model
",1
"        self.y = None
",1
"            lm_pytorch.RNNLM(
                len(train_args.char_list), rnnlm_args.layer, rnnlm_args.unit
            )
        )
        torch_load(args.rnnlm, rnnlm)
",1
"        ({""spk_embed_dim"": 16, ""spk_embed_integration_type"": ""concat""}),
",1
"        f.write(""b 150,80\n"")
    return str(p)


",1
"                )
            key, wav = sps
            keys.append(key)
            wavs.append(wav.strip())

",1
"            cers = []

            y_hats = self.ctc.argmax(hs_pad).data
            for i, y in enumerate(y_hats):
                y_hat = [x[0] for x in groupby(y)]
",1
"        # report validation loss
        observation = {}
        with reporter.report_scope(observation):
",1
"
        # update transition agent prob
        self.trans_agent_prob = torch.sigmoid(
",1
"        hosts = []
        ids_list = []
",1
"    for key_p, value_p in partial_state_dict.items():
        if any(key_p.startswith(m) for m in modules):
",1
"    tmpFile = open(tmpFileLocation)
except IOError:
    print(""The file spk2gendertmp does not exist. Run fsp_make_trans.pl first?"")
",1
"from espnet.asr.asr_utils import restore_snapshot
",1
"            args.valid_batch_type = args.batch_type
        if args.valid_batch_size is None:
            args.valid_batch_size = args.batch_size
        if args.valid_batch_bins is None:
",1
"
    def forward(self, enc_hs_pad, enc_hs_len, dec_z, att_prev_states, scaling=2.0):
        """"""AttLocRec forward

        :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
",1
"        (for ASR, TTS iaxis=0, for MT iaxis=""1"".)
    :param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0,
        reserved for future research, -1 means all axis.)
",1
"        assert name.startswith(""--"")
        self.parser.add_argument(self.prefix + name[2:], **kwargs)


class SchedulerInterface:
",1
"                           (negative value indicates no location-aware attention)"",
        )
        group.add_argument(
            ""--dropout-rate"",
            default=0.0,
",1
"        else:
            # The ratio is given on runtime randomly
",1
"
    space = ""<space>""
    blank = ""<blank>""
",1
"            choices=[
                ""lstm"",
                ""blstm"",
                ""lstmp"",
",1
"        if len(batch_sizes) > 1 and batch_sizes[-1] < min_batch_size:
            for i in range(batch_sizes.pop(-1)):
                batch_sizes[-(i % len(batch_sizes)) - 2] += 1

",1
"            dec_z (chainer.Variable | N-dimensional array): Input variable of decoder.
            scaling (float): Scaling weight to make attention sharp.

        Returns:
            chainer.Variable: Weighted sum over flames.
",1
"        ...     subwriter[""uttidA""] = ""some/where/a.wav""
        ...     subwriter[""uttidB""] = ""some/where/b.wav""

    """"""
",1
"    try:
        params = inspect.signature(func).parameters
    except ValueError:
        return
    if name is None:
",1
"    parser.add_argument(
        ""--src-vocab"",
",1
"            extensions.observe_value(
                ""lr"",
                lambda trainer: trainer.updater.get_optimizer(""main"").param_groups[0][
                    ""lr""
                ],
",1
"    def __iter__(self) -> Iterator[Tuple[str, ...]]:
        return iter(self.batch_list)
",1
"        )

        for class_choices in cls.class_choices_list:
            # Append --<name> and --<name>_conf.
            # e.g. --encoder and --encoder_conf
",1
"        self,
        feats_extract: Optional[AbsFeatsExtract],
        normalize: Optional[AbsNormalize and InversibleInterface],
        tts: AbsTTS,
    ):
",1
"    )
    parser.add_argument(""--nbest"", type=int, default=1, help=""Output N-best hypotheses"")
    parser.add_argument(""--beam-size"", type=int, default=4, help=""Beam size"")
",1
"
",1
"            # Bug check
",1
"            )
        use_apex = True

        from espnet.nets.pytorch_backend.ctc import CTC
",1
"        >>> assert array.shape == (123, 83)
        >>> array = dataset[""uttB""]
        >>> assert array.shape == (34, 83)

    """"""
",1
"                for hyp in hyps:
                    hyp[""yseq""].append(self.eos)

            # add ended hypothes to a final list, and removed them from current hypothes
            # (this will be a probmlem, number of hyps < beam)
",1
"        else:
            # Output to stdout/stderr
            f = None

        rank = 0
",1
"
import chainer
",1
"                ),
            )
        ]

        in_data = data[0][1][""feat""]
",1
"            # TODO(karita): get help and choices from docstring?
            attr = k.replace(""_"", ""-"")
            group.add_argument(f""--{fname}-{attr}"", default=v, type=type(v))
",1
"            outyaml = p.parent / (p.stem + "".2"" + p.suffix)

        outyaml = Path(outyaml)
    else:
        outyaml = Path(args.outyaml)
",1
"
    yi, yo = add_sos_eos(y_tgt, model.sos, model.eos, model.ignore_id)
",1
"                    % (
                        i + 1,
                        n_samples,
                        (n_samples - i - 1) * elapsed_time_per_sample,
",1
"                        )

                lis.append((key, scp, type_func, key_scp, type_func_str))
",1
"        if self.use_scaled_pos_enc:
",1
"
    :param int idim: dimension of inputs
    :param int odim: dimension of outputs
    :param Namespace args: argument Namespace containing options

",1
"
class DefaultFrontend(AbsFrontend):
    """"""Conventional frontend structure for ASR

",1
"
    @classmethod
    @torch.no_grad()
",1
"        """"""
",1
"        if self.spk_embed_dim is not None:
",1
"
        Returns:
            list: List of strings which are base keys to plot during training.

        """"""
",1
"import numpy as np
import pytest
import torch

from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"            help=""Ratio of predicted labels fed back to decoder"",
        )
        group.add_argument(
            ""--lsm-type"",
            const="""",
",1
"                        )
                        se2e.accept_input(feat[i : i + args.streaming_window])
",1
"        main()
",1
"                    line = ""%s <%s> %s\n"" % (uid, args.lang_tag, text)
                out.write(line)

",1
"                output_device=(
                    torch.cuda.current_device()
                    if distributed_option.ngpu == 1
                    else None
                ),
",1
"                    ""validation/main/loss"",
                    lambda best_value, current_value: best_value < current_value,
                ),
",1
"        logging.info(""max output length: "" + str(maxlen))
        logging.info(""min output length: "" + str(minlen))

        # main loop of prefix search
        running_hyps = self.init_hyp(x)
",1
"            # Give features from data-loader
            args.feats_extract = None
            args.feats_extract_conf = None
",1
"    parser.add_argument(
        ""--normalize"",
",1
"        :param torch.Tensor ys_pad:
            batch of padded character id sequence tensor (B, Lmax)
        :return: loss value
        :rtype: torch.Tensor
        """"""
",1
"        unpack(str(tmp_path / ""a.tgz""), ""out"")
import argparse
from argparse import Namespace

",1
"            if self.load_input:
                # Note(kamo): This for-loop is for multiple inputs
                for idx, inp in enumerate(info[""input""]):
                    # {""input"":
                    #  [{""feat"": ""some/path.h5:F01_050C0101_PED_REAL"",
",1
"            ""--dropout-rate"", type=float, default=0.5, help=""dropout probability""
        )
        parser.add_argument(
",1
"
@pytest.mark.parametrize(
    ""norm_vars, norm_means"",
",1
"                        cers.append(
                            editdistance.eval(hyp_chars, ref_chars) / len(ref_chars)
                        )

                cer_ctc = sum(cers) / len(cers) if cers else None
",1
"        self.eos = subword_dict[""<eos>""]
        self.lexroot = make_lexical_tree(word_dict, subword_dict, self.word_unk)
        self.log_oov_penalty = math.log(oov_penalty)
        self.open_vocab = open_vocab
",1
"            logging.info(""Use label smoothing with "" + args.lsm_type)
            labeldist = label_smoothing_dist(
",1
"    subsets[dataset] = {""all"": subsets[""test""][dataset][:]}

for subset in subsets.keys():
    if ""all"" not in subsets[subset]:
",1
"            end_time = x[""end_time""][mictype]

",1
"            hyp[""ctc_score_prev""] = 0.0
            if ctc_weight != 1.0:
",1
"

class AbsFrontend(torch.nn.Module, ABC):
",1
"    trans = trans.strip().replace(""-"", "" "").upper()
",1
"                    np.random.RandomState(real_epoch - 1 + self.seed).shuffle(
                        prev_batches
                    )
                    np.random.RandomState(real_epoch + self.seed).shuffle(
                        current_batches
",1
"
",1
"                and next state for ys

        """"""
        y, new_state = self._before_loss(y[-1].view(1, 1), state)
        logp = y.log_softmax(dim=-1).view(-1)
",1
"    for f, mask_end in fs:
        f_zero = random.randrange(0, num_mel_channels - f)
        mask_end += f_zero
",1
"from typing import Optional
from typing import Tuple
from typing import Union

import torch
",1
"        lm_weight=0,
",1
"    :param int att_dim_k: dimension k in multi head attention
    :param int att_dim_v: dimension v in multi head attention
    :param int aconv_chans: # channels of attention convolution
",1
"    args = parser.parse_args()

    # set logger
    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
    if args.verbose > 0:
",1
"        args.spk_embed_dim = None
",1
"                            concat = sum(input_infos + output_infos + infos, [])
                            raise RuntimeError(
",1
"    )
    assert parser.parse_args(
        [""--conf"", '{""d"": 5, ""e"": 9}', ""--conf"", ""d.e=3""]
",1
"        if self.normalize_before:
",1
"    model = module.E2E(idim, odim, train_args)
    model.cuda()

    batch = prepare_inputs(backend, idim, odim, ilens, olens, is_cuda=True)
",1
"    set_early_stop(trainer, args)

    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
        trainer.extend(
",1
"        pass

",1
"                else chainer.ChainList(
                    *[L.StatelessGRU(n_units, n_units) for _ in range(n_layers)]
",1
"    parser = get_parser()
    args, _ = parser.parse_known_args(cmd_args)

",1
"        :return: argmax applied 2d tensor (B, Tmax)
",1
"        group.add_argument(
",1
"        out_size (int): Output dimension.
        initialW (Initializer): Initializer to initialize the weight.
",1
"                - spk_embed_dim (int): Number of speaker embedding dimensions.
                - spk_embed_integration_type: How to integrate speaker embedding.
                - teacher_model (str): Teacher auto-regressive transformer model path.
                - reduction_factor (int): Reduction factor.
                - transformer_init (float): How to initialize transformer parameters.
",1
"            ),
            trigger=(args.report_interval_iters, ""iteration""),
        )
        report_keys.append(""eps"")
    if args.report_cer:
",1
"                    elif isinstance(v, numbers.Number):
",1
"        ), ""SegmentStreamingE2E works only with uni-directional encoders""
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

from __future__ import print_function
",1
"from chainer import training
",1
"            type=int,
            help=""Number of heads for multi head attention"",
        )
",1
"    parser.add_argument(""dict"", type=str, help=""dict"")
",1
"
import math

import torch
",1
"                ""xavier_uniform"",
",1
"        if self.nmask == 2:  # (mask_speech, mask_noise)
            mask_speech, mask_noise = masks

            psd_speech = get_power_spectral_density_matrix(data, mask_speech)
",1
"from espnet2.samplers.num_elements_batch_sampler import NumElementsBatchSampler


@pytest.fixture()
def shape_files(tmp_path):
",1
"            odim=odim,
            att=att,
            dlayers=args.dlayers,
",1
"
import torch

",1
"
        # new CTC forward probs are prepared as a (T x 2 x BW x S) tensor
        # that corresponds to r_t^n(h) and r_t^b(h) in a batch.
",1
"                ""main/loss"",
",1
"                        output_dir / f""{e}epoch.pth"", map_location=""cpu"",
",1
"                wv = str(os.path.join(d, ""ref.{}.{}.wav"".format(isrc, imic)))
                soundfile.write(wv, ref[isrc, :, imic].astype(np.int16), fs)
                refs.append(wv)

",1
"        print(nbest[0][""yseq""][1:-1])


def test_sa_transducer_parallel():
",1
"        dropout_rate (float): Dropout rate.

    """"""

",1
"
",1
"    else:
        # This pattern can also works with Slurm.

        logging.info(f""{args.num_nodes}nodes and {args.ngpu}gpu-per-node using mpirun"")
        cmd = (
",1
"    """"""Feed Forward Transformer for TTS a.k.a. FastSpeech.

    This is a module of FastSpeech,
    feed-forward Transformer with duration predictor described in
",1
"            xp = importlib.import_module(""cupy"")
            xs = [chainer.Variable(xp.array(x)) for x in xs]
            ys = [chainer.Variable(xp.array(y)) for y in ys]
",1
"    plt.legend()
    plt.savefig(f""benchmark_{model}.png"")
# coding: utf-8
",1
"        description=""convert ASR recognized json to text"",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
",1
"
    else:
",1
"        ""--segments"",
",1
"            if avg[k] is not None:
                avg[k] /= args.num

        torch.save(avg, args.out)

",1
"        Args:
            in_chans (int): Number of input channels.
",1
"        # incremented if every word is visited at least once after the last
        # increment.
        self.epoch = 0
        # True if the epoch is incremented at the last iteration.
        self.is_new_epoch = False
",1
"                - postnet_dropout_rate (float): Dropout rate in postnet.
                - use_masking (bool):
                    Whether to apply masking for padded part in loss calculation.
",1
"        bidirectional=bidirectional,
        use_projection=use_projection,
        subsample=subsample,
",1
"from typing import Dict
from typing import Iterable
from typing import List
from typing import Optional
",1
"            n_mels=self.n_mels,
",1
"            logging.info(""grad norm={}"".format(grad_norm))

",1
"        reporter.report({""loss_att"": loss_att}, self)
        reporter.report({""acc"": acc}, self)
        reporter.report({""cer_ctc"": cer_ctc}, self)
        reporter.report({""cer"": cer}, self)
",1
"if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--skip-ncols"", ""-s"", default=0, type=int, help=""skip first n columns""
",1
"from test.test_beam_search import prepare
from test.test_beam_search import transformer_args


",1
"    ""adam"": AdamFactory,
    ""sgd"": SGDFactory,
",1
"import codecs
",1
"        durations = [
",1
"    # If the list values are given from yaml file,
    # the value givent to type() is shaped as python-list,
    # e.g. ['a', 'b', 'c'],
    # so we need to remove double quotes from it.
",1
"        """"""
        super(E2E, self).__init__()
        torch.nn.Module.__init__(self)
",1
"import logging


def check_early_stop(trainer, epochs):
",1
"                    # Accumulated
                    for k in avg:
",1
"    lsm_weight=0.001,
",1
"            + [
",1
"    """"""

    def __init__(
        self,
        input_size: int,
",1
"        super(MultiLevelLM, self).__init__()
",1
"    model = Model()
    with pytest.raises(ValueError):
        ForwardAdaptor(model, ""aa"")
from espnet2.torch_utils.pytorch_version import pytorch_cudnn_version

",1
"                clean_content = g2p(text)

            if args.lowercase:
",1
"        pass

    @abstractmethod
    def load_state_dict(self, state):
",1
"                subsample[idx],
                args.dropout_rate[idx],
            )
",1
"):
    idim, odim, ilens, olens = get_default_scope_inputs()
    args = make_arg()

    module = importlib.import_module(""espnet.nets.pytorch_backend.e2e_asr"")
",1
"            spc = logmelspc_to_linearspc(
",1
"    states: Dict[str, Dict] = dict()

",1
"            loss = self._master(*x) / self.accum_grad
            loss.backward()
",1
"def g2p(text):
    """"""Convert grapheme to phoneme.""""""
    tokens = filter(lambda s: s != "" "", f_g2p(text))
",1
"                            typ=typ,
                        ),
                    )
",1
"                [torch.from_numpy(x.real).float() for x in xs], 0
",1
"        normalize_before: whether to use layer_norm before the first block
        concat_after: whether to concat attention layer's input and output
",1
"# -*- coding: utf-8 -*-

""""""Network related utility tools.""""""
",1
"from espnet.nets.pytorch_backend.rnn.attentions import initial_att
from espnet2.asr.decoder.abs_decoder import AbsDecoder
from espnet2.utils.get_default_kwargs import get_default_kwargs

",1
"        )
",1
"@pytest.mark.parametrize(
",1
"                                hyp[""rnnlm_prev""]
                            )
                        ended_hyps.append(hyp)
                else:
                    remained_hyps.append(hyp)
",1
"
def func5(b={3: 5}):
",1
"        self.mtlalpha = args.mtlalpha
        if args.mtlalpha > 0.0:
            self.ctc = CTC(
",1
"        scale=1.0,
    ):
        """"""Initialize Vaswani rule extension.""""""
",1
"        nn.Module.__init__(self)
        # NOTE: for a compatibility with less than 0.5.0 version models
        dropout_rate = getattr(args, ""dropout_rate"", 0.0)
        # NOTE: for a compatibility with less than 0.6.1 version models
        embed_unit = getattr(args, ""embed_unit"", None)
",1
"
",1
"            ""--awin"", default=5, type=int, help=""Window size for location2d attention""
        )
        group.add_argument(
",1
"    def __init__(self, n_vocab, args):
        """"""Initialize class.

",1
"                    Whether to apply weighted masking in loss calculation.
                - bce_pos_weight (float): Positive sample weight in bce calculation
",1
"        model.cuda()
        loss = 1.0 / ngpu * model(*batch)
        loss.backward(loss.new_ones(ngpu))  # trainable
    else:
",1
"        return y

    def enhance(self, xs):
        """"""Forward only the frontend stage.
",1
"
        loss_data = float(self.loss)
        if not math.isnan(loss_data):
            self.reporter.report(loss_data, acc, ppl, bleu)
        else:
",1
"
Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
"
",1
"
",1
"            )
        ]
",1
"        else:
",1
"        TransformerEncoder(20, input_layer=""fff"")
",1
"
def build_batch_sampler(
    type: str,
    batch_size: int,
    batch_bins: int,
",1
"
    Args:
        args (namespace): The program arguments.
",1
"            ]

        # 5. compute cer/wer
        if self.training or not (self.report_cer or self.report_wer):
            cer, wer = 0.0, 0.0
",1
"                Input variable from encoders.
            dec_z (chainer.Variable | N-dimensional array): Input variable of decoder.
            att_prev (chainer.Variable | None): Attention weight.
",1
"
    """"""

    def __init__(
",1
"                    plt.subplot(shape[0], shape[1], idx1 * shape[1] + idx2)
                    plt.imshow(x, aspect=""auto"")
                    plt.xlabel(""Input"")
                    plt.ylabel(""Output"")
",1
"    AbsTask.get_parser()


def test_add_arguments_help():
    parser = AbsTask.get_parser()
",1
"        dist_world_size=2,
        dist_rank=None,
        ngpu=0,
        local_rank=None,
",1
"        # Skip epoch=2
",1
"        grad_norm = np.sqrt(
            sum_sqnorm([p.grad for p in optimizer.target.params(False)])
        )
        logging.info(""grad norm={}"".format(grad_norm))
        if math.isnan(grad_norm):
",1
"import io
import logging
",1
"    model = Tacotron2(idim, odim, Namespace(**model_args))
    optimizer = torch.optim.Adam(model.parameters())
    model.to(device)

",1
"
",1
"        assert model.encoder.embed[1].alpha.grad is not None
        assert model.decoder.embed[1].alpha.grad is not None
",1
"

def test_ESPnetDataset_h5file_1(h5file_1):
    dataset = ESPnetDataset(
",1
"            it = iterator
        else:
            it = copy.copy(iterator)
",1
"            data,
",1
"        pad_outputs (Tensor): Prediction tensors (B * Lmax, D).
",1
"            help=""Number of encoder layers ""
            ""(for shared recognition part in multi-speaker asr mode)"",
        )
        group.add_argument(
            ""--eunits"",
",1
"    model_class, args, ctc_weight, lm_weight, bonus, device, dtype
",1
"                ""coverage"",
                ""coverage_location"",
                ""location2d"",
",1
"        logging.info(
            self.__class__.__name__
            + "" output lengths: ""
",1
"
import numpy as np
",1
"            batch = to_device(batch, ""cuda"" if ngpu > 0 else ""cpu"")
            if no_forward_run:
                continue

            # 1. Forwarding model and gathering all attentions
",1
"        else:
            r[output_length - 1] = self.logzero

",1
"    losses_2 = torch.ones([bs, 4], dtype=torch.float32)
    for i in range(bs):
        losses_2[i][i % 4] = 0
    true_losses_2 = torch.ones(bs, dtype=torch.float32) / 2
    perm_choices_2 = [[0, 1], [1, 0], [1, 0], [0, 1]]
",1
"                ""main/loss_att"",
                ""validation/main/loss_att"",
",1
"import yaml

from espnet2.utils.yaml_no_alias_safe_dump import yaml_no_alias_safe_dump

d = {""a"": (1, 2, 3)}
",1
"
        for hi in h:
            ytu = F.log_softmax(self.joint(hi, y[0]), dim=0)
            logp, pred = torch.max(ytu, dim=0)

",1
"        """"""reset states""""""
        self.h_length = None
        self.enc_h = None
",1
"        is_config_file=True,
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"    with open(args.trans_json, ""rb"") as f:
        js = json.load(f)[""utts""]
    new_js = {}

",1
"from typing import Tuple

import torch
",1
"            )
            outs += [self.feat_out(zcs).view(1, self.odim, -1)]  # [(1, odim, r), ...]
            probs += [torch.sigmoid(self.prob_out(zcs))[0]]  # [(r), ...]
            if self.output_activation_fn is not None:
",1
"    model = model_class(idim, odim, train_args)
    assert isinstance(model, ASRInterface)
    torch_load(args.model, model)
",1
"            logging.warning(""loss (=%f) is not correct"", loss_data)
",1
"
",1
"    # test beam search
    trans_args = argparse.Namespace(
",1
"
def test_print_config_and_load_it(tmp_path):
    config_file = tmp_path / ""config.yaml""
    with config_file.open(""w"") as f:
",1
"            self.loss = loss_att
        elif alpha == 1:
",1
"
",1
"    parser.add_argument(""--verbose"", default=1, type=int, help=""verbose option"")
    args = parser.parse_args()

",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
            {""han_type"": ""coverage_location""},
        ),
",1
"        (""transformer"", {""reduction_factor"": 3}),
        (""transformer"", {""reduction_factor"": 4}),
        (""transformer"", {""reduction_factor"": 5}),
        (""tacotron2"", {}),
        (""tacotron2"", {""spk_embed_dim"": 16}),
",1
"                            _message += f""{key2}={v:.3f}""
",1
"    def extra_repr(self):
        return f""window={self.window}, mode={self.mode}""

    def forward(self, x: torch.Tensor, x_lengths: torch.Tensor = None):
        """"""Forward function.
",1
"if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(""in_text"", type=str, help=""text to be cleaned"")
",1
"from espnet2.main_funcs.calculate_all_attentions import calculate_all_attentions
from espnet2.train.abs_espnet_model import AbsESPnetModel

",1
"    """"""LM training.

    Example:

",1
"                subsets[subset][dataset].append([uttid, words, wav])

for dataset in subsets[""test""].keys():
",1
"    """"""
",1
"
        alpha = torch.tensor((queries - floor), dtype=grid_type, device=grid_device)
",1
"        group.add_argument(
            ""--duration-predictor-chans"",
            default=384,
            type=int,
            help=""Number of channels in duration predictor"",
",1
"        help=""List of modules to freeze (not to train), separated by a comma."",
    )

    return parser
",1
"    processed_xs = preprocessing(xs)
",1
"        self.h_length = None
",1
"            wer = (
",1
")
def test_fastspeech_gpu_trainable_and_decodable(teacher_type, model_dict):
    # make args
    idim, odim = 10, 25
    model_args = make_feedforward_transformer_args(**model_dict)
",1
"    state = decoder.init_state(x)
    t = torch.randint(0, 10, [4], dtype=torch.long)
    decoder.score(t, state, x)

",1
"        mode (str): db or linear.
        fs (int): Sample frequency. To convert y-axis to kHz unit.
        frame_shift (int): The frame shift of stft. To convert x-axis to second unit.
        bottom (bool):Whether to draw the respective ticks.
        left (bool):
",1
"    )

    # Note(kamo): Use '_' instead of '-' as separator.
    # '-' is confusing if written in yaml.
",1
"                ctc_beam = min(lpz.shape[-1], int(beam * CTC_SCORING_RATIO))
            else:
",1
"                    ax.set_xlabel(""frames"")
                    ax.set_ylabel(""fbank coeff"")
                    fig.tight_layout()
                else:
                    fig = _plot_and_save_attention(att_w, filename)
",1
"        else:
",1
"        model: torch.nn.Module,
        iterator: Iterable[Dict[str, torch.Tensor]],
        reporter: SubReporter,
        options: TrainerOptions,
    ) -> None:
",1
"        lm=args.lm_weight,
",1
"    writers = {k: open(os.path.join(args.outdir, k), ""w"") for k in evaltypes}

    for key in keylist:
",1
"                     [1, 1, 1, 0, 0],
                     [1, 1, 1, 0, 0]]], dtype=torch.uint8)

        """"""
",1
"                    backward_window=backward_window,
                    forward_window=forward_window,
                )

",1
"            weights_ctc_dec = recog_args.weights_ctc_dec / np.sum(
                recog_args.weights_ctc_dec
            )  # normalize
            logging.info(
                ""ctc weights (decoding): "" + "" "".join([str(x) for x in weights_ctc_dec])
",1
"        reporter: SubReporter,
        options: TrainerOptions,
    ) -> None:
",1
"        ""   ..."",
    ),
",1
"            olens (LongTensor): Batch of output lenghts (B,).

        Returns:
",1
"import logging
",1
"            self.batch_list = [
                tuple(keys[i * batch_size : (i + 1) * batch_size]) for i in range(N)
            ]
",1
"                    enh_writer[name] = (args.fs, enh)
                else:
                    # Hint: To dump stft_signal, mask or etc,
                    # enh_filetype='hdf5' might be convenient.
                    enh_writer[name] = enh
",1
"    :param torch.Tensor spec: input tensor with the shape (T, dim)
    :param int W: time warp parameter
    :param int F: maximum width of each freq mask
",1
"from espnet.nets.asr_interface import ASRInterface
from espnet.nets.pytorch_backend.nets_utils import get_subsample
",1
"    # setup data
    data_size = 6
",1
"            if self.norm_vars:
                x = np.divide(x, self.scale[spk])
",1
"                if rnnlm:
                    rnnlm_state, local_lm_scores = rnnlm.predict(hyp[""rnnlm_prev""], vy)
                    local_scores = (
                        local_att_scores + recog_args.lm_weight * local_lm_scores
                    )
",1
"            ""--valid_batch_type"",
            type=str_or_none,
",1
"def test_backward_not_leaf_in(stats_file, norm_vars, norm_means):
",1
"
        self.return_shape = return_shape
",1
"        for line in lines:
            line = line.strip()
            if not line:
",1
"            x = batch
            for key in x.keys():
                x[key] = x[key].to(self.device)

",1
"        replace_sos: bool = False,
        num_encs: int = 1,
        att_conf: dict = get_default_kwargs(build_attention_list),
    ):
",1
"                bleus.append(bleu)

            bleu = 0.0 if not self.report_bleu else sum(bleus) / len(bleus)
",1
"                ctc_idx = 0 if self.share_ctc else idx
                loss_ctc = self.ctc[ctc_idx](hs_pad, hlens, ys_pad)
                self.loss_ctc_list.append(loss_ctc)
",1
"from espnet.utils.cli_writers import file_writer_helper
from espnet.utils.dataset import ChainerDataLoader
from espnet.utils.dataset import TransformDataset
from espnet.utils.deterministic_utils import set_deterministic_pytorch
",1
"from espnet.utils.check_kwargs import check_kwargs
",1
"        stats1 = {""aa"": 0.6}
",1
"        token_list=train_args.char_list,
        pre_beam_score_key=None if args.ctc_weight == 1.0 else ""decoder"",
    )
    # TODO(karita): make all scorers batchfied
    if args.batchsize == 1:
",1
"            hs, _, _ = self.enc[idx](xs_list[idx], ilens_list[idx])
            hs_list.append(hs[0])
        return hs_list
",1
"            ""--adim"",
",1
"    if args.backend == ""pytorch"":
        from espnet.tts.pytorch_backend.tts import train

        train(args)
    else:
",1
"    )
    parser.add_argument(
        ""--patience"",
        default=3,
        type=int,
",1
"            x (Tensor): Batch of input tensors (B, ..., in_chans).

        Returns:
            Tensor: Batch of output tensors (B, ..., hidden_chans).

",1
"            return state, F.log_softmax(z).data

    def final(self, state):
        """"""Predict final log probabilities for given state using the predictor
",1
"            See the example.

    Returns:
        ByteTensor: mask tensor containing indices of padded part.
                    dtype=torch.uint8 in PyTorch 1.2-
",1
"            )
            args.batch_size *= args.ngpu

    # set torch device
    device = torch.device(""cuda"" if args.ngpu > 0 else ""cpu"")
",1
"    # hack to make batchsize argument as 1
    # actual bathsize is included in a list
",1
"import soundfile as sf

from nara_wpe.utils import istft
from nara_wpe.utils import stft
from nara_wpe.wpe import wpe
",1
"        """"""Compute AttLoc forward layer.
",1
"    # unfortunately, torch cross_entropy does not accept out-of-bound ids
    th_ignore = 0
    th_pred = torch.from_numpy(y_all.data)
    th_ys = [torch.from_numpy(numpy.append(t, eos)).long() for t in np_target]
    th_target = pad_list(th_ys, th_ignore)
",1
"        Returns: initial state

        """"""
        return None

",1
"                    f""Illegal name {etype}""
                )
",1
"        return ret

    def __iter__(self):
        """"""Implement iter function.""""""
",1
"def test_repr():
    print(Stft())
",1
"        ...     subwriter = writer[""sub.txt""]
        ...     # Write ""uttidA some/where/a.wav""
",1
"        value = value[1:-1]
    elif value.startswith(""'"") and value.endswith(""'""):
        value = value[1:-1]
    return value

",1
"        """"""Calculate forward propagation.

        Args:
            xs (Tensor): Batch of input sequences (B, Tmax, idim).
",1
"            self.initialW = chainer.initializers.GlorotNormal
",1
"            cer_ctc=cer_ctc,
        )

        # force_gatherable: to-device and to-tensor if scalar for DataParallel
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)
",1
"                            dropout,
                            typ=typ,
                        )
                    ]
",1
"    else:
        from torch.distributed import reduce_op as ReduceOp
else:
    ReduceOp = None
",1
"    reporter = Reporter()
    reporter.set_epoch(1)
    key1 = uuid.uuid4().hex
    with reporter.observe(key1) as sub:
",1
"            z_prev, c_prev = dstate

",1
"                amp.load_state_dict(states[""amp""])
",1
"                        n_chans,
                        kernel_size,
",1
"        if self.mt_weight == 0:
",1
"
from __future__ import division

import argparse
import copy
",1
"            r_prev, s_prev, f_min_prev, f_max_prev = state

        # select input dimensions for scoring
",1
"
class Postnet(torch.nn.Module):
",1
"                if len(sps) == 2:
",1
"        ""--use_att_constraint"",
        type=str2bool,
",1
"        else:
            scoring_ids = None
            scoring_idmap = None
            snum = self.odim
            x_ = self.x
",1
"    model_conf = args.outdir + ""/model.json""
    with open(model_conf, ""wb"") as f:
        logging.info(""writing a model config file to "" + model_conf)
",1
"            hs, hlens, mask = self.frontend(hs, ilens)
            hlens_n = [None] * self.num_spkrs
            for i in range(self.num_spkrs):
                hs[i], hlens_n[i] = self.feature_transform(hs[i], hlens)
            hlens = hlens_n
",1
"        y[i, olens[i] :] = model.ignore_id

",1
"
",1
"                ""location2d"",
                ""location_recurrent"",
                ""multi_head_dot"",
                ""multi_head_add"",
                ""multi_head_loc"",
",1
"            SequenceIterFactory(
                dataset=dataset,
                batches=batches,
                seed=seed,
",1
"    seed: int,
    num_workers: int,
    log_level: Union[int, str],
",1
"
        """"""
        with torch.no_grad():
            # forward encoder
            x_masks = self._source_mask(ilens)
",1
"from espnet2.torch_utils.device_funcs import force_gatherable
from espnet2.torch_utils.device_funcs import to_device

",1
"        type=int,
        help=""Maximum output frames in a minibatch (0 to disable)"",
    )
",1
"
",1
"        trigger=(args.report_interval_iters, ""iteration""),
",1
"            y_name = list(y_feats_dict.keys())[0]

",1
"    def calculate_attentions(self, xs, x_mask, ys_pad):
",1
"    ilens = np.array([x.shape[0] for x in xs], dtype=np.int32)

",1
"                - aheads (int): Number of heads for multi head attention.
                - dlayers (int): Number of decoder layers.
                - dunits (int): Number of decoder hidden units.
                - postnet_layers (int): Number of postnet layers.
                - postnet_chans (int): Number of postnet channels.
",1
"
def interpolate_bilinear(
",1
"        verbose=2,
        char_list=[u"""", u"""", u"""", u"""", u""""],
        outdir=None,
        report_bleu=False,
",1
"    def snapshot_object(trainer):
        torch_save(os.path.join(trainer.out, filename.format(trainer)), target)

    return snapshot_object
",1
"import tempfile

import chainer
",1
"    logging.basicConfig(
        level=log_level,
        format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
    )
",1
"                    elayers=2,
                    dlayers=2,
                    mtlalpha=0.5,
",1
"        help=""Specify the file format for the rspecifier. ""
        '""mat"" is the matrix format in kaldi',
",1
"                # To avoid disk access, create loader only for the first time
                loader = kaldiio.load_scp(filepath)
                self._loaders[filepath] = loader
            return loader[key]
",1
"        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vggbgrup""}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vgglstm""}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vgglstmp""}),
",1
"                    )
",1
"from typing import List
",1
"        return (
            logp,
",1
"    ):
        assert check_argument_types()
        assert all(len(x) == 1 for x in batches), ""batch-size must be 1""
",1
"    return spc


def logmelspectrogram(
    x,
",1
"        Reporter(-1)

",1
"            # ys_zero_pad_src, ys_pad = self.target_forcing(ys_zero_pad_src, ys_pad)
            hs_pad_mt, hs_mask_mt = self.encoder_mt(ys_zero_pad_src, src_mask_mt)
            # forward MT decoder
            pred_pad_mt, _ = self.decoder(ys_in_pad, ys_mask, hs_pad_mt, hs_mask_mt)
",1
"
def str2bool(value: str) -> bool:
    return bool(strtobool(value))

",1
"                )
            )
            init_torch_weight_random(model, rand_range)
            init_torch_weight_random(rnnlm, rand_range)
            model.eval()
",1
"            self.pre_compute_k = [
                self.mlp_k[h](self.enc_h) for h in six.moves.range(self.aheads)
",1
"
    if mode == ""chainer"":
        raise NotImplementedError

",1
"import codecs
import nltk

from tacotron_cleaner.cleaners import collapse_whitespace
from tacotron_cleaner.cleaners import custom_english_cleaners
",1
"    if args.opt == ""noam"":
        from espnet.nets.chainer_backend.transformer.training import VaswaniRule

",1
"    except ValueError:
",1
"        min_batch_size=args.ngpu if args.ngpu > 1 else 1,
",1
"class NumElementsBatchSampler(AbsSampler):
    def __init__(
        self,
",1
"        ""--normalize"",
        choices=[1, 16, 24, 32],
        type=int,
",1
"    if args.train_dtype in (""float16"", ""float32"", ""float64""):
",1
"        self.aconv_chans = aconv_chans

    def reset(self):
",1
"                    local_att_scores = traced_decoder(ys, ys_mask, enc_output)[0]
",1
"        )
        group.add_argument(
            ""--dropout-rate-decoder"",
            default=0.0,
",1
"                            [-1.2181, -0.5918],
",1
"
        # 2. Build ESPnetModel
        # Assume the last-id is sos_and_eos
        model = ESPnetLanguageModel(lm=lm, vocab_size=vocab_size, **args.model_conf)

",1
"

class Decoder(torch.nn.Module):
",1
"        Args:
            x (LongTensor): Initial waveform tensor with the shape  (T,).
            h (Tensor): Auxiliary feature tensor with the shape  (n_samples + T, n_aux).
",1
"        okey = ""input""
        if batch_sort_key == ""input"":
            batch_sort_key = ""output""
        elif batch_sort_key == ""output"":
            batch_sort_key = ""input""
",1
"

class TokenIDConverter:
    def __init__(
        self, token_list: Union[Path, str, Iterable[str]], unk_symbol: str = ""<unk>"",
",1
"    # logging info
",1
"        for uttid, info in batch:
",1
"from espnet.nets.scorers.ctc import CTCPrefixScorer
from espnet.nets.scorers.length_bonus import LengthBonus
from espnet.utils.cli_utils import get_commandline_args
from espnet2.tasks.asr import ASRTask
",1
"def test_calculate_all_attentions_MultiHeadedAttention():
    model = Dummy()
",1
"        default=None,
",1
"            )
            if args.mtlalpha > 0.0:
                if args.ctc_type == ""builtin"":
                    logging.info(""Using chainer CTC implementation"")
                    self.ctc = ctc.CTC(odim, args.adim, args.dropout_rate)
",1
"        preprocess=preprocess,
    )

    _, data = dataset[""a""]
    assert data[""data6""].shape == (100, 80,)
",1
"    Forward attention in sequence-to-sequence acoustic modeling for speech synthesis
        (https://arxiv.org/pdf/1807.06736.pdf)

    :param int eprojs: # projection-units of encoder
",1
"        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgggrup""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgglstm""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgglstmp""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vggbgru""}),
",1
"    def extra_repr(self):
",1
"

def test_main_print_config():
",1
"            seed=seed,
            allow_variable_data_keys=allow_variable_data_keys,
            ngpu=ngpu,
        )
",1
"        return float(sum(char_eds)) / sum(char_ref_lens)

    def calculate_wer(self, seqs_hat, seqs_true):
        """"""Calculate sentence-level WER score for transducer model.

",1
"
",1
"        dictionary = f.readlines()
    char_list = [entry.split("" "")[0] for entry in dictionary]
    char_list.insert(0, ""<blank>"")
",1
"                    y_true = ys_pad[i]

                    seq_hat = [
                        self.char_list[int(idx)] for idx in y_hat if int(idx) != -1
",1
"        dummy_hyps = [
",1
"    resolve_distributed_mode(args)


def test_resolve_distributed_mode4(dist_init_method):
",1
"        if args.report_bleu:
            trans_args = {
                ""beam_size"": args.beam_size,
",1
"        )

    def zero_grad(self):
        """"""Reset gradient.""""""
        self.optimizer.zero_grad()
",1
"import random
import six

import chainer
",1
"        ngpu = args.ngpu
    logging.info(f""ngpu: {ngpu}"")
",1
"from espnet.scheduler import scheduler
",1
"    def required_data_names(cls, inference: bool = False) -> Tuple[str, ...]:
        if not inference:
            retval = (""text"", ""speech"")
",1
"                )
                writers[""ISR""].write(
",1
"    # test loss with constant weights (1.0) and bias (0.0) except for foget-bias (1.0)
    np.testing.assert_allclose(ch_ctc.data, th_ctc.detach().numpy())
    np.testing.assert_allclose(ch_att.data, th_att.detach().numpy())

    # test grads in mtl mode
",1
"import numpy as np
from typeguard import check_argument_types

from espnet2.utils.fileio import load_num_sequence_text

",1
"            spcs: Batch of ground-truth spectrogram (B, Lmax, spc_dim).
            spcs_lengths:
        """"""
        text = text[:, : text_lengths.max()]  # for data-parallel
",1
"            TensorboardLogger(SummaryWriter(args.tensorboard_dir), att_reporter),
            trigger=(args.report_interval_iters, ""iteration""),
        )
    # Run the training
",1
"                            :, : self.num_heads_applied_guided_attn
",1
"from scipy.io.wavfile import write
from sklearn.preprocessing import StandardScaler

from espnet.nets.pytorch_backend.wavenet import decode_mu_law
",1
"        z = self.lin_out(z)

        return z

    def forward(self, hs_pad, ys_in_pad, hlens=None):
",1
"        onesided: bool = True,
    ):
",1
"            if len(hyps) > 0:
                logging.debug(""remaining hypotheses: "" + str(len(hyps)))
            else:
",1
"fin_lex = open(args.input, ""r"")
fin_Letter = open(args.Letter, ""r"")
fout_lex = open(args.output1, ""w"")
fout_lex_ori = open(args.output2, ""w"")
fout_map = open(args.Map, ""w"")
",1
"                    with decoder lstm outputs.
                - dropout_rate (float): Dropout rate.
                - zoneout_rate (float): Zoneout rate.
",1
"

if __name__ == ""__main__"":
    main(sys.argv[1:])
#!/usr/bin/env python3
",1
"                ""modules_applied_guided_attn"": [""encoder-decoder""],
            }
        ),
",1
"    obj2 = to_device(obj, ""cuda"")
    assert obj2[""a""][0].device == torch.device(""cuda:0"")


@pytest.mark.parametrize(
",1
"            # if no bias, 0 0-pad goes 0
",1
"
        in_data = data[0][1][""feat""]
        nbest_hyps = model.recognize(in_data, args, args.char_list)
        y_hat = nbest_hyps[0][""yseq""][1:]
        seq_hat = [args.char_list[int(idx)] for idx in y_hat]
",1
"
class DecoderLayer(nn.Module):
    """"""Single decoder layer module for transformer-transducer models.

    Args:
",1
"                logging.info(""groundtruth: %s"" % out_dic[""text""])
                logging.info(""prediction : %s"" % out_dic[""rec_text""])

        new_js[""output""].append(tmp_js)
    return new_js
",1
"import argparse
import importlib
",1
"        for idx in range(self.num_encs):
            logging.info(
",1
"        :param int eos:
        :return: batch, uttid_list
        :rtype: Tuple[OrderedDict, List[str]]
        """"""
",1
"# encoding: utf-8

",1
"            default=None,
            help=""Show the logs every the number iterations in each epochs at the ""
            ""training phase. If None is given, it is decided according the number ""
            ""of training samples automatically ."",
",1
"    ""The batch_size is decided by\n""
    ""    batch_size = base_batch_size // (L // fold_length)\n""
    ""L is referred to the largest length of samples in the mini-batch. ""
",1
"                - use_masking (bool):
                    Whether to apply masking for padded part in loss calculation.
",1
"
# err(str(sys.argv))
id_prefix = sys.argv[2]
utt_ids = sys.argv[3:]
utt2trans = dict()
",1
"                0.0
                if not self.report_wer
",1
"        """"""
        uniform_init_parameters(self)
        # exceptions
        # embed weight ~ Normal(-0.1, 0.1)
",1
"master_doc = 'index'

# General information about the project.
project = u'ESPnet'
copyright = u'2017, Shinji Watanabe'
",1
"    """"""Loss function module for feed-forward Transformer.""""""

    def __init__(self, use_masking=True, use_weighted_masking=False):
",1
"                    logging.info(
                        typ.upper() + "" with every-layer projection for encoder""
",1
"        )
",1
"    parser.add_argument(""--config"", is_config_file=True, help=""config file path"")

    parser.add_argument(
        ""--log_level"",
        type=lambda x: x.upper(),
",1
"
            # add to list of N-best result dicts
            tmp_js.append(out_dic)

            # show 1-best result
",1
"    utt_array = []  # uttrance array w/o '#'

    # get voice_part & utt_array
    with open(in_lab_file, ""r"") as f:
",1
"
    with file_writer_helper(
        args.wspecifier,
        filetype=args.out_filetype,
",1
"                x = x.ravel()
",1
"                            ys_pad[i % self.num_spkrs],
                        )
",1
"            k, v = sps
            if k in data:
                raise RuntimeError(f""{k} is duplicated ({path}:{linenum})"")
",1
"
    def score(self, yseq, state, x):
        # to support mutiple encoder asr mode, in single encoder mode,
        # convert torch.Tensor to List of torch.Tensor
",1
"                    add_gradient_noise(
                        model,
                        reporter.get_total_count(),
",1
"from typing import Tuple
from typing import Union
",1
"    f_g2p("""")
except ImportError:
",1
"    if mode == ""PIL"":
        t = x.shape[0]
",1
"        load_output=True,
        preprocess_conf=args.preprocess_conf,
        preprocess_args={""train"": True},  # Switch the mode of preprocessing
    )
    load_cv = LoadInputsAndTargets(
",1
"
class RNNDecoder(AbsDecoder):
    def __init__(
",1
"            if idim != odim:
                raise ValueError(
                    ""When using tie_src_tgt_embedding, idim and odim must be equal.""
                )
",1
"        group.add_argument(
            ""--eunits"",
            ""-u"",
",1
"            value = arg.translate(table)
            eles.append(""del-"" + value)
        for arg in args.arg:
            if ""="" not in arg:
                raise RuntimeError(f'""{arg}"" does\'t include ""=""')
",1
"        )
",1
"    args = make_arg(atype=atype)
    if ""pytorch"" in module:
",1
"        maxlen = ys_in.shape[1]
",1
"    group.add_argument(
        ""--cutoff"",
",1
"
    # Note(kamo): Use ""_"" instead of ""-"" as separator.
    # ""-"" is confusing if written in yaml.
    parser.add_argument(""--config"", is_config_file=True, help=""config file path"")

",1
"            else:
                t = line[0]
                if t == "" "":
",1
"        for j in seg_txt(blks[i]):
            out_line += "" "" + j
    print(out_line)
#!/usr/bin/env python3
",1
"                        (item * self.weights_ctc_train[i]).unsqueeze(0)
",1
"                out_add_dic[""shape""] = [int(adddic[""olen""]), int(adddic[""odim""])]
            elif ""odim"" in adddic:
                out_add_dic[""shape""] = [int(adddic[""odim""])]
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr"",
            {""etype"": ""vggblstmp"", ""atype"": ""coverage""},
        ),
",1
"        for d in dicts:
            chainer.reporter.report(d, self)
",1
"            if args.normalize is not None and args.normalize != 1:
                array = array / (1 << (args.normalize - 1))
            spc = spectrogram(
                x=array,
",1
"    with p1.open(""w"") as f:
        f.write(""a 1000,80\n"")
        f.write(""b 400,80\n"")
",1
"        train_json,
",1
"except LookupError:
    # NOTE: we need to download dict in initial running
    import ssl

",1
"        normalize: Optional[AbsNormalize],
        encoder: AbsEncoder,
        decoder: AbsDecoder,
        ctc: CTC,
        rnnt_decoder: None,
",1
"                odim,
                args.adim,
",1
"    # The final goal is creating a JSON file such as.
    # {
    #     ""utts"": {
    #         ""sample_id1"": {(omitted)},
    #         ""sample_id2"": {(omitted)},
",1
"        if torch.is_tensor(ilens):
            ilens = ilens.cpu().numpy()
",1
"from espnet2.layers.abs_normalize import AbsNormalize
from espnet2.layers.global_mvn import GlobalMVN
",1
"        :return: N-best decoding results
        :rtype: list
",1
"                    ),
                ]
            )

    def output_size(self) -> int:
",1
"                self.trans_args,
                self.char_list,
                self.rnnlm,
",1
"    print(msg, file=sys.stderr)

",1
"        :param torch.Tensor att_prev: attention weights of previous step
        :param torch.Tensor out_prev: decoder outputs of previous step (B, odim)
        :param float scaling: scaling parameter before applying softmax
",1
"                z_out = self.output(z_all[-1])
                z_out = F.argmax(F.log_softmax(z_out), axis=1)
",1
"        transform = None

",1
"def rand_int_loader(filepath, loader_type):
    # e.g. rand_int_3_10
    try:
        low, high = map(int, loader_type[len(""rand_int_"") :].split(""_""))
    except ValueError:
",1
"            },
            {},
        ),
    ],
",1
"            if i > 0 and random.random() < self.sampling_probability:
                logging.info("" scheduled sampling "")
                z_out = self.output(z_all[-1])
",1
"
    # in_lab_file open & get voice_part_old from lab_file
    voice_part_old, utt_array = get_vp(in_lab_file)

",1
"    set_deterministic_pytorch(args)
    model, train_args = load_trained_model(args.model)
",1
"from distutils.version import LooseVersion
",1
"        (""espnet.nets.pytorch_backend.e2e_mt"", ""dot""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""add""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""coverage""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""multi_head_dot""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""multi_head_add""),
",1
"    so.step(0)
    for g in o.param_groups:
        assert g[""lr""] == s.scale(0)
",1
"                        ax.yaxis.set_major_locator(MaxNLocator(integer=True))

                    if output_dir is not None:
",1
"

def dynamic_import(import_path, alias=dict()):
    """"""dynamic import module and class

",1
"        if not os.path.exists(self.outdir):
",1
"
                # get nbest local scores and their ids
",1
"
",1
"                        ):
                            print_new_keys(partial_state_dict, modules, model_path)
                            main_state_dict.update(partial_state_dict)
",1
"    ):
",1
"
# Copyright 2019 Tomoki Hayashi
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"
from espnet2.torch_utils.initialize import initialize

",1
"        for y in ys.transpose(0, 1):
",1
"            class_choices.add_arguments(group)
",1
"            type=float,
            help=""Dropout rate for the decoder"",
        )
        group.add_argument(
            ""--sampling-probability"",
",1
"        return logp, state_list
",1
"
from espnet.utils.cli_utils import get_commandline_args
from espnet2.utils.types import str2bool
",1
"        help=""Batch size for beam search (0: means no batch processing)"",
",1
"
",1
"            session, ids = line.strip().split()
            if len(ids.split(""_"")) == 1:
                line_new = texts[(session, int(ids))]
",1
"
def g2p(text):
    """"""Convert grapheme to phoneme.""""""
    tokens = filter(lambda s: s != "" "", f_g2p(text))
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Encoder self-attention layer definition.""""""

",1
"        xs = torch.as_tensor(xs).unsqueeze(0)
",1
"        if hasattr(iterator, ""reset""):
            iterator.reset()
",1
"            hs_pad, hlens, mask = self.frontend(to_torch_tensor(xs_pad), ilens)
            hs_pad, hlens = self.feature_transform(hs_pad, hlens)
        else:
            hs_pad, hlens = xs_pad, ilens

",1
"        ""trans_type"", type=str, default=""char"", help=""transcription type (char or phn)""
    )
",1
"

def plot_multi_head_attention(
    data,
    attn_dict,
",1
"            try:
                from apex import amp
            except ImportError:
                logging.error(
                    ""You need to install apex. ""
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_st"",
",1
"
""""""pytorch dataset and dataloader implementation for chainer training.""""""

import torch
",1
"if __name__ == ""__main__"":
    description = """"""
""""""
",1
"        1e-5,
        1e-6,
    )
",1
"        pytest.skip(""no cuda device is available"")
    if device == ""cpu"" and dtype == ""float16"":
        pytest.skip(""cpu float16 implementation is not available in pytorch yet"")

",1
"from espnet.nets.lm_interface import dynamic_import_lm
",1
"        if not self.set:
            for iterator in self.iterators:
                iterator.start_shuffle()
",1
"
def test__plot_stats_input_str():
    reporter = Reporter()
",1
"from nara_wpe.wpe import wpe
import numpy as np

parser = argparse.ArgumentParser()
",1
"        model_class = dynamic_import(args.model_module)
        model = model_class(idim, odim, args)
        torch_load(model_path, model)
",1
"        extensions.PlotReport(
",1
"        retval = tuple(self.classes)
        if self.optional:
            return retval + (None,)
        else:
",1
"        self.loc_conv = torch.nn.Conv2d(
            1,
",1
"dict_acronym_noi = {}  # Mapping of acronyms without I, i
for pair in fin_map:
    items = pair.split(""\t"")
",1
"                ""best hypo: ""
",1
"        ""--ngpu"", type=int, default=0, help=""The number of gpus. 0 indicates CPU mode"",
    )
",1
"    # do filtering
    drop_count = 0
    for utt_id in fr_reader.keys():
        focus_rate = fr_reader[utt_id]
        if focus_rate >= args.threshold:
",1
"                for n in range(self.n_layers)
            ]
            state = {""h"": h}
",1
"
    def index_select_state(self, state, best_ids):
        """"""Select CTC states according to best ids

",1
"                for hyp in hyps:
                    logging.debug(
",1
"    parser.add_argument(""text"", type=str, help=""text"")
",1
"    list(sampler)
",1
"                ),
                trigger=CompareValueTrigger(
                    ""validation/main/loss"",
                    lambda best_value, current_value: best_value < current_value,
",1
"        ""validation/main/loss"",
        ""validation/main/loss_ctc"",
        ""validation/main/loss_att"",
        ""main/acc"",
",1
"        Return:
            chainer.Variable: Output variable.

        """"""
        e = F.dropout(self.act(self.w_1(e)), self.dropout)
",1
"if __name__ == ""__main__"":
",1
"        ended_hyps = []

        for i in six.moves.range(maxlen):
            logging.debug(""position "" + str(i))

",1
"        reporter.report({""loss"": mtl_loss}, self)

",1
"        .. _`Deep Voice 3`: https://arxiv.org/abs/1710.07654

        """"""
        # setup
        assert len(h.size()) == 2
",1
"    :param int aconv_filts: filter size of attention convolution
",1
"        ""aconv_filts"": 100,
    }
    for k in default_dict.keys():
",1
"            x (Tensor): Input sequence of characters (T,).
            inference_args (Namespace):
                - threshold (float): Threshold in inference.
                - minlenratio (float): Minimum length ratio in inference.
",1
"            ]
        else:
            train_iters = [
                ToggleableShufflingSerialIterator(
",1
"    def backward(self, indexes, grads):
        xp = cuda.get_array_module(*grads)
",1
"
        Args:
            target: for pytorch `model.parameters()`,
                for chainer `model`
            args (argparse.Namespace): parsed command-line args
",1
"    bpemodel = ""test_spm""

    # test train
    spm.SentencePieceTrainer.Train(
        f""--input={testfile} --vocab_size={nbpe} --model_type={bpemode} \
",1
"
    # test encoder-decoder attention
",1
"
",1
"    odim = 5
    dummy_json = make_dummy_json(
        4, [10, 20], [10, 20], idim=idim, odim=odim, num_inputs=num_encs
    )
    import espnet.nets.pytorch_backend.e2e_asr_mulenc as m
",1
"
    for k in desired:
        rate1, t = target[k]
        rate2, d = desired[k]
        assert rate1 == rate2
",1
"            cls.trainer.run(
                model=model,
                optimizers=optimizers,
",1
"    if is_wspecifier:
        with file_writer_helper(
            args.wspecifier_or_wxfilename, filetype=args.out_filetype
",1
"    parser.add_argument(
        ""--enh"",
        dest=""enhfiles"",
",1
"    )
    parser.add_argument(
        ""--lowercase"", type=bool, default=False, help=""Lower case the result or not""
",1
"        hyp_file = codecs.open(hyps[ns], ""w"", encoding=""utf-8"")
        ref_file = codecs.open(refs[ns], ""w"", encoding=""utf-8"")
",1
"            std = torch.clamp(var.sqrt(), min=eps)
            x = x / std.sqrt()
        return x, ilens
    else:
",1
"        retval = WeightedAverage(v, weight)
",1
"                c, w = output
",1
"                    (only for use_masking=true).
                - loss_type (str): How to calculate loss.
                - use_guided_attn_loss (bool): Whether to use guided attention loss.
                - num_heads_applied_guided_attn (int):
",1
"from espnet.nets.scorer_interface import BatchScorerInterface
from espnet.nets.scorers.length_bonus import LengthBonus
from espnet.utils.deterministic_utils import set_deterministic_pytorch
",1
"        help=""Type of window"",
",1
"        intersec_add_dic[k] = v

",1
"        lang_ids=None,
    ):
",1
"        logging.basicConfig(level=logging.INFO, format=logfmt)
",1
"            chainer.Variable: Attention weight.
",1
"class RNNLM(nn.Module):
",1
"    else:
        device = ""cpu""
",1
"                f""sort_in_batch must be ascending or descending: {sort_in_batch}""
            )

        self.batch_size = batch_size
",1
"        np.testing.assert_array_equal(value, valid[key].shape)
# coding: utf-8

# Copyright 2019 Hirofumi Inaguma
",1
"                'attribute ""%s"" does not exist. use default %s.' % (key, str(value))
            )
            args[key] = value
",1
"        Args:
            train_iter (chainer.dataset.Iterator): The train iterator
            model (LMInterface) : The model to update
            optimizer (torch.optim.Optimizer): The optimizer for training
            schedulers (espnet.scheduler.scheduler.SchedulerInterface):
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
",1
"
        Args:
            idim (int): Input dimension.
            n_layers (int, optional): Number of convolutional layers.
            n_chans (int, optional): Number of channels of convolutional layers.
",1
"        if self.replace_sos:
            ys_in_pad = torch.cat([tgt_lang_ids, ys_in_pad[:, 1:]], dim=1)
        ys_mask = target_mask(ys_in_pad, self.ignore_id)
        pred_pad, pred_mask = self.decoder(ys_in_pad, ys_mask, hs_pad, hs_mask)
        self.pred_pad = pred_pad
",1
"
",1
"    assert window > 0
    delta_feat = np.zeros_like(feat)
",1
"
    # If {'real': ..., 'imag': ...}, convert to ComplexTensor
    elif isinstance(x, dict):
        # Dynamically importing because torch_complex requires python3
        from torch_complex.tensor import ComplexTensor
",1
"                ngpu = len(p.stderr.decode().split(""\n"")) - 1
        args.ngpu = ngpu
",1
"random.seed(1)
random.shuffle(subsets[""train""][""all""])

dev_size = min(int(len(subsets[""train""][""all""]) * 0.1), len(subsets[""test""][""all""]))
subsets[""dev""][""all""] = subsets[""train""][""all""][:dev_size]
",1
"        ""--compression-method"",
        type=int,
        default=2,
        help=""Specify the method(if mat) or "" ""gzip-level(if hdf5)"",
",1
"        end = min(len(sorted_data), start + bs)
",1
")
def test_backward_leaf_in(stats_file, norm_vars, norm_means):
    layer = GlobalMVN(stats_file, norm_means=norm_means, norm_vars=norm_vars)
    x = torch.randn(1, 2, 80, requires_grad=True)
    y, _ = layer(x)
",1
"            self.decoder.embed[-1].alpha.data = torch.tensor(init_dec_alpha)

    def _transfer_from_teacher(self, transferred_encoder_module):
",1
"    ""buriy_audiobooks_2_val"",
    ""public_youtube700_val"",
    # next the training datasets
    # (it needs all validation transcripts)
",1
"        z_all = []
        if self.num_encs == 1:
",1
"                    lines = list(f)
                raise RuntimeError(
                    f""\n################### The last 1000 lines of {args.log} ""
                    f""###################\n"" + """".join(lines[-1000:])
                )
",1
"        retval = defaultdict(list)
        for tarinfo in tar:
            outname = outpath / tarinfo.name
            outname.parent.mkdir(parents=True, exist_ok=True)
",1
"        Args:
            hs (Tensor): Batch of hidden state sequences (B, Tmax, adim).
            spembs (Tensor): Batch of speaker embeddings (B, spk_embed_dim).

        Returns:
",1
"        else:
            return False

    def has(self, key: str, key2: str, epoch: int = None) -> bool:
",1
"    )
",1
"
from espnet.utils.io_utils import SoundHDF5File
",1
"        numpy.random.randint(1, n_out - 1, size=ol, dtype=numpy.int32)
        for ol in label_length
    ]
",1
"        n_mels: int = 80,
        fmin: float = 0.0,
        fmax: float = None,
        # Normalization
        stats_file: str = None,
",1
"        sort_in_input_length=False,
        preprocess_conf=train_args.preprocess_conf
        if args.preprocess_conf is None
",1
"from pathlib import Path
import sys
from typing import List
from typing import Optional

",1
"        self.loss *= np.mean([len(x) for x in ys_in]) - 1
        acc = F.accuracy(y_all, F.flatten(pad_ys_out), ignore_label=-1)
        logging.info(""att loss:"" + str(self.loss.data))
",1
"            self.act = F.relu
        self.dropout = dropout
",1
"
    # check gradient of ScaledPositionalEncoding
",1
"        f.write(""f 999,80\n"")

",1
"            args.dropout_rate_embed_decoder,
        )
",1
"        psd_feat = (psd.real ** 2 + psd.imag ** 2) ** 0.5

        # (B, C, F) -> (B, C, F2)
",1
"
class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()
",1
"        model = cls.build_model(args=args)
        if not isinstance(model, AbsESPnetModel):
",1
"
        # initialization
        c_list = [None]  # list of cell state of each layer
        z_list = [None]  # list of hidden state of each layer
",1
"@pytest.mark.parametrize(
    ""in_length,out_length"", [([11, 17, 15], [4, 2, 3]), ([4], [1])]
)
def test_ctc_loss(in_length, out_length, use_warpctc):
    pytest.importorskip(""torch"")
",1
"                line_new = "" "".join(
                    [
",1
"        as input in `data` dict
    :param bool mt: if True, use 0-axis of ""output"" as output and 1-axis of ""output""
        as input in `data` dict
    :param int iaxis: dimension to access input
",1
"
",1
"        n_fft: int = 512,
        n_mels: int = 80,
        fmin: float = None,
",1
"                c_list[i], z_list[i] = self[""rnn%d"" % i](
                    c_prev[i], z_prev[i], z_list[i - 1]
                )
        else:
            if z_prev[0] is None:
",1
"    )
    parser.add_argument(""rspecifier"", type=str, help=""WAV scp file"")
    parser.add_argument(
",1
"def test_ForwardAdaptor_no_func():
",1
"            cer, wer = 0.0, 0.0
            # oracle_cer, oracle_wer = 0.0, 0.0
        else:
            if self.recog_args.ctc_weight > 0.0:
",1
"import chainer
import chainer.functions as F
from espnet.lm.lm_utils import make_lexical_tree

",1
"
if LooseVersion(torch.__version__) >= LooseVersion(""1.1.0""):
    from torch.utils.tensorboard import SummaryWriter
else:
    from tensorboardX import SummaryWriter
",1
"        next_size = 0
        max_olen = 0
",1
"    def __init__(
        self, norm_means: bool = True, norm_vars: bool = False, eps: float = 1.0e-20
    ):
        super().__init__()
        self.norm_means = norm_means
",1
"# Copyright 2019 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Neural machine translation model decoding script.""""""

",1
"            enh_files.append(enhs)

        if compute_permutation:
            index_list = list(itertools.permutations(range(n_src)))
",1
"        if not isinstance(model, AbsESPnetModel):
            raise RuntimeError(
                f""model must inherit {AbsESPnetModel.__name__}, but got {type(model)}""
            )
",1
"        assert grad[0] != grad_org[0]

",1
"        return x
""""""Initialize main package.""""""
import librosa
import numpy
",1
"
",1
"

@pytest.fixture
def char_converter():
    return CharTokenizer([""[foo]""])
",1
"
        Returns:
            Tensor: Batch of output tensors (B, ..., hidden_chans).
",1
"            max_out = max(olens)
            ys = ys[:, :max_out]
            labels = labels[:, :max_out]
            labels[:, -1] = 1.0  # make sure at least one frame has 1

",1
"        )
        return parser

    @property
    def attention_plot_class(self):
",1
"        >>> _ = parser.add_argument('--conf', action=NestedDictAction,
        ...                         default={'a': 4})
        >>> parser.parse_args(['--conf', 'a=3', '--conf', 'c=4'])
        Namespace(conf={'a': 3, 'c': 4})
",1
"        self.mtlalpha = args.mtlalpha
        assert 0.0 <= self.mtlalpha <= 1.0, ""mtlalpha should be [0.0, 1.0]""
        self.verbose = args.verbose
",1
"    :param int size: size of mask
    :param str device: ""cpu"" or ""cuda"" or torch.Tensor.device
    :param torch.dtype dtype: result dtype
    :rtype: torch.Tensor
",1
"except Exception:
    __version__ = ""(Not installed from setup.py)""
del pkg_resources
import io
",1
"                 [0, 0, 1, 1, 1, 1],
",1
"                f""there is no such an activation function. "" f""({output_activation})""
",1
"                ""lstmp"",
",1
"
    """"""
",1
"            zoneout_rate=zoneout_rate,
",1
"            trainer.extend(
",1
"        states = dict()
        for k, d in self.part_scorers.items():
            scores[k], states[k] = d.score_partial(hyp.yseq, ids, hyp.states[k], x)
",1
"                        if not args.allow_one_column:
",1
"            f""batch_size={self.batch_size}, ""
            f""key_file={self.key_file}, ""
        )

    def __len__(self):
",1
"        if param.grad is not None:
            _shape = param.grad.size()
",1
"        ) as writer:
",1
"        default=None,
        help=""The configuration file for the pre-processing"",
    )
    parser.add_argument(
",1
"
        # dot with gvec
        # utt x frame x att_dim -> utt x frame
        e = self.gvec(
            torch.tanh(att_conv + self.pre_compute_enc_h + dec_z_tiled)
",1
"        import matplotlib.pyplot as plt
        import matplotlib.ticker as ticker

",1
"                    ""c_prev"": c_list,
                    ""lm_state"": None,
                }
            ]
        else:
",1
"
",1
"        pin_memory: bool = False,
        preprocess_fn=None,
        collate_fn=None,
",1
"        writer = SummaryWriter(args.tensorboard_dir)
        trainer.extend(
            TensorboardLogger(writer), trigger=(args.report_interval_iters, ""iteration"")
",1
"            'Give a pair referring the phase, ""train"" or ""valid"",'
            'the criterion name, and the mode, ""min"" or ""max"", e.g. ""acc,max"".',
        )
        group.add_argument(
",1
"                )
            )
        # add eos in the final loop to avoid that there are no ended hyps
",1
"        aheads=2,
",1
"    def __init__(self, att_vis_fn, data, outdir, converter, device, reverse=False):
        """"""Initialize PlotAttentionReport.""""""
",1
"
class IStft(object):
    def __init__(self, n_shift, win_length=None, window=""hann"", center=True):
",1
"    def batch_score(
",1
"
    def score(self, y, state, x):
",1
"    start, end = n // 4, n // 2
    bias.data[start:end].fill_(1.0)
# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"        metavar=""ML"",
        help=""When --batch-count=seq, ""
        ""batch size is reduced if the output sequence length > ML"",
    )
",1
"parser = argparse.ArgumentParser(description=""format acronyms to a._b._c."")
parser.add_argument(""-i"", ""--input"", help=""Input lexicon"", required=True)
",1
"        type=float,
        help=""Multitask learning coefficient for ASR task, weight: ""
",1
"        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 2, {""etype"": [""bgru"", ""bgru""]}),
        (
",1
"    logging.info(""new json has "" + str(num_keys) + "" utterances"")

    # ensure ""ensure_ascii=False"", which is a bug
    jsonstring = json.dumps(
",1
"import logging
import six
",1
"    use_frontend=False,
    replace_sos=False,
",1
"from typeguard import check_argument_types
",1
"        ngpu=2,
        local_rank=None,
        dist_launcher=None,
        dist_backend=""nccl"",
",1
"    """"""
    if pretrain_key is None:
        obj = model
",1
"            mean = sum_v / count
            var = sum_square_v / count - mean * mean
",1
"        formatter_class=configargparse.ArgumentDefaultsHelpFormatter,
    )

    # Note(kamo): Use '_' instead of '-' as separator.
",1
"    def __call__(
        self, uid: str, data: Dict[str, Union[str, np.ndarray]]
    ) -> Dict[str, np.ndarray]:
        assert check_argument_types()

",1
"
",1
"    if not os.path.exists(args.outdir):
        os.makedirs(args.outdir)
",1
"    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
",1
"        x = text
        spemb = spembs
",1
"    def __init__(self, schedulers: List[SchedulerInterface], optimizer: Optimizer):
        """"""Initialize class.""""""
        self.schedulers = schedulers
        self.optimizer = optimizer
",1
"
def test_DatadirWriter(tmp_path: Path):
",1
"            return True
",1
"    Args:
",1
"        (for ASR, TTS, MT oaxis=0, reserved for future research, -1 means all axis.)
    :return: List[List[Tuple[str, dict]]] list of batches
    """"""
",1
"                ""blstmp"",
                ""vgglstmp"",
                ""vggblstmp"",
",1
"            w = DatadirWriter((self.path / key))
            self.chilidren[key] = w
            self.has_children = True

        retval = self.chilidren[key]
",1
"        group.add_argument(
",1
"import math
import random
import six

",1
"            spembs = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)
            hs = self.projection(torch.cat([hs, spembs], dim=-1))
        else:
",1
"
",1
"    Returns:
        tuple(str, str, str, float)

    """"""
    # remove sos and get results
",1
"@pytest.mark.parametrize(""sort_in_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""drop_last"", [True, False])
",1
"        text = "" "".join(x.rstrip().split()[1:])
        if text in fil:
            print(x.split()[0], text)
#!/usr/bin/env python3
",1
"        return observation


def train(args):
",1
"    idim = 5
    odim = 5
    T = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_mt_transformer"".format(backend)
    )
",1
"from espnet.utils.training.batchfy import make_batchset
from espnet.utils.training.iterators import ShufflingEnabler
from espnet.utils.training.tensorboard_logger import TensorboardLogger
from espnet.utils.training.train_utils import check_early_stop
from espnet.utils.training.train_utils import set_early_stop
",1
"        for h in six.moves.range(self.aheads):
            e = torch.sum(
                self.pre_compute_k[h]
                * torch.tanh(self.mlp_q[h](dec_z)).view(batch, 1, self.att_dim_k),
",1
"            self.ctc_lo = L.Linear(eprojs, odim)

    def __call__(self, hs, ys):
        """"""CTC forward.

",1
"        dist_master_addr=None,
        dist_master_port=None,
    )
",1
"    flattened_grid_locations = get_flat_grid_locations(
        image_height, image_width, device
    )

",1
"            split[0] = split[0].replace(""(("", ""("")
",1
"
    # setup batch
    idim = 5
    odim = 10
",1
"        )
        group.add_argument(
            ""--dist_launcher"",
            default=None,
            type=str_or_none,
",1
"        float_dtype: str = ""float32"",
        int_dtype: str = ""long"",
        max_cache_size: Union[float, int, str] = 0.0,
    ):
        assert check_argument_types()
",1
"        :return: attention weighted encoder state (B x D_enc)
        :rtype: torch.Tensor
        :return: list of previous attention weight (B x T_max) * aheads
",1
"                        local_att_scores + recog_args.lm_weight * local_lm_scores
                    )
",1
"    if lm_train_config is not None:
",1
"from espnet.utils.dataset import ChainerDataLoader
from espnet.utils.dataset import TransformDataset
from espnet.utils.deterministic_utils import set_deterministic_pytorch
from espnet.utils.dynamic_import import dynamic_import
from espnet.utils.io_utils import LoadInputsAndTargets
",1
"        args.out_text, ""w"", ""utf-8""
    ) as f_out:
        for line in f_in.readlines():
            id = line.split("" "")[0]
",1
"        # 5. compute cer/wer
",1
"        self.model.train()

        return summary.compute_mean()


",1
"            # Don't give args to run() directly!!!
",1
"# Create alias type to check the type
# Note(kamo): Currently PyTorch doesn't provide the base class
# to judge these classes.
AbsValEpochStepScheduler.register(L.ReduceLROnPlateau)
",1
"    utils.torch_load(tmppath, model)
    for p1, p2 in zip(p_saved, model.parameters()):
        np.testing.assert_array_equal(p1, p2.data.numpy())
    if os.path.exists(tmppath):
        os.remove(tmppath)
",1
"            self.guided_attn_masks = (
                self._make_guided_attention_masks(ilens, olens)
                .to(att_ws.device)
",1
"    parser.add_argument(
        ""--batch-frames-out"",
        default=0,
        type=int,
        help=""Maximum output frames in a minibatch (0 to disable)"",
",1
"        type=int,
",1
"                    ]
",1
"from espnet.bin.asr_train import get_parser
from espnet.utils.fill_missing_args import fill_missing_args


",1
"        self.att2 = AttAdd(10, 20, 15)
        self.desired = defaultdict(list)

",1
"            raise ValueError(
                f""sort_batch must be ascending or descending: {sort_batch}""
            )

    def __repr__(self):
",1
"        next_hidden = self._zoneout(hidden, next_hidden, self.zoneout_rate)
        return next_hidden

    def _zoneout(self, h, next_h, prob):
        # apply recursively
",1
"from espnet2.asr.decoder.abs_decoder import AbsDecoder


",1
"            )
",1
"
        Args:
            hs (list of chainer.Variable | N-dimension array):
                Input variable from encoder.
",1
"    """"""

",1
"                    lambda best_value, current_value: best_value > current_value,
                ),
",1
"    if args.ngpu == 1:
        gpu_id = list(range(args.ngpu))
        logging.info(""gpu id: "" + str(gpu_id))
",1
"        dunits=16,
        atype=""location"",
",1
"
        Args:
            enc_hs (chainer.Variable | N-dimensional array):
                Input variable from encoders.
            dec_z: Dummy.
",1
"        args.accum_grad,
        use_apex=use_apex,
",1
"        if lpz is not None:
            ctc_prefix_score = CTCPrefixScore(lpz.detach().numpy(), 0, self.eos, numpy)
            hyp[""ctc_state_prev""] = ctc_prefix_score.initial_state()
            hyp[""ctc_score_prev""] = 0.0
            if ctc_weight != 1.0:
",1
"    )

    return model.state_dict(), False


",1
"        ngpu=2,
",1
"            specaug = SpecAug(
                apply_time_warp=apply_time_warp,
                apply_freq_mask=apply_freq_mask,
                apply_time_mask=apply_time_mask,
            )
",1
"    parser.add_argument(
        ""--replace-sos"",
        default=False,
        type=strtobool,
        help=""Replace <sos> in the decoder with a target language ID ""
",1
"class AttLocRec(torch.nn.Module):
",1
"
# Copyright 2019 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"        padding_idx,
        smoothing,
",1
"        dur_old = voice_part_old[i][1] - voice_part_old[i][0]
        dur_new = voice_part_new[i][1] - voice_part_new[i][0]
        diff_dur = dur_old - dur_new

        if 1.0 < diff_st:
",1
"            positional_dropout_rate=args.dropout_rate,
            self_attention_dropout_rate=args.transformer_attn_dropout_rate,
            src_attention_dropout_rate=args.transformer_attn_dropout_rate,
",1
"            default=1.0,
            help=""Initial alpha value in decoder's ScaledPositionalEncoding"",
",1
"                        # Load all files in memory
                        self.utt2noise[utt] = (signal, rate)
",1
"        sub_reporter = self.start_epoch(key, epoch)
        yield sub_reporter
        # Receive the stats from sub_reporter
        self.finish_epoch(sub_reporter)
",1
"    y.sum().backward()

",1
"            args.dec_embed_dim,
            args.joint_dim,
            args.dropout_rate_decoder,
",1
"        ).to(device)

        return xs_list_pad, ilens_list, ys_pad
",1
"        ""--ngpu"",
",1
"        logging.info(xs.shape)
        xs = self.linear(xs, n_batch_axes=2)
        logging.info(xs.shape)
        xs = self.pe(xs)
        return xs, ilens
",1
"        # set scorers
",1
"                x = np.subtract(x, self.bias[spk])
",1
"            # http://docs.h5py.org/en/stable/special.html#arbitrary-vlen-data
            data = f.create_dataset(
",1
"        )
    elif filetype == ""sound.hdf5"":
        return SoundHDF5Writer(
            wspecifier, write_num_frames=write_num_frames, pcm_format=pcm_format
        )
",1
"            ""--cbhg-conv-bank-layers"",
            default=8,
            type=int,
",1
"            ],
            help=""Type of encoder network architecture"",
        )
        group.add_argument(
            ""--elayers"",
",1
"        """"""
        z = torch.tanh(self.lin_enc(h_enc) + self.lin_dec(h_dec))
        z = self.lin_out(z)

",1
"    return ys_in_pad, target, pred_len, target_len
",1
"                        # Truncate the frames added by stft padding
                        enh = enh[: len(org_feats[idx])]
                    elif len(org_feats) > len(enh):
                        padwidth = [(0, (len(org_feats[idx]) - len(enh)))] + [
",1
"    teacher_model = Transformer(idim, odim, Namespace(**teacher_model_args))
    tmpdir = tempfile.mkdtemp(prefix=""tmp_"", dir=""/tmp"")
    torch.save(teacher_model.state_dict(), tmpdir + ""/model.dummy.best"")
    with open(tmpdir + ""/model.json"", ""wb"") as f:
        f.write(
",1
"            for line in f.read().splitlines():
                path, _, content, _ = line.split(""|"")
                uid = args.spk_tag + ""_"" + os.path.basename(path).replace("".wav"", """")
                text = custom_finnish_cleaners(content.rstrip())
                if args.lang_tag is None:
",1
"    dec_model_path = args.dec_init
    enc_modules = args.enc_init_mods
    dec_modules = args.dec_init_mods

",1
"    parser.add_argument(
        ""--model"", type=str, required=True, help=""Model file parameters to read""
    )
",1
"

def str2pair_str(value: str) -> Tuple[str, str]:
    """"""str2pair_str.

",1
"    def encoder_add_arguments(parser):
        """"""Add arguments for the encoder.""""""
        group = parser.add_argument_group(""E2E encoder setting"")
",1
"
",1
"        minibatches.append(batch)
        # Check for min_batch_size and fixes the batches if needed
        i = -1
",1
"                    word_rnnlm.predictor, rnnlm.predictor, word_dict, char_dict
",1
"from typing import Any

import pytest

from espnet2.utils.get_default_kwargs import get_default_kwargs
",1
"def _restore_snapshot(model, snapshot, load_fn=chainer.serializers.load_npz):
    load_fn(snapshot, model)
    logging.info(""restored from "" + str(snapshot))
",1
"        res_1x1,
    ):
        output_sigmoid = dil_sigmoid(x)[:, :, -1:]
",1
"    args = get_parser().parse_args(args)
    filter_file(args.infile, args.filt, args.exclude)


",1
"    parser = get_parser()
",1
"
",1
"install_requires = requirements[""install""]
",1
"        preprocess_args={""train"": True},  # Switch the mode of preprocessing
    )
    load_cv = LoadInputsAndTargets(
        mode=""asr"",
",1
"    ys = model.decoder.embed(batch[""ys""])
    ys[1, olens[1] :] = float(""nan"")
",1
"            lm_pytorch.RNNLM(
                len(train_args.char_list),
                rnnlm_args.layer,
",1
"            reduction_str = ""mean""
        self.loss = F.cross_entropy(
            y_all,
",1
"#!/usr/bin/env python3
# encoding: utf-8

# Copyright 2018 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"    else:
",1
"import pytest
",1
"import nltk

from tacotron_cleaner.cleaners import custom_english_cleaners
",1
"
",1
"    model = m.E2E(6, 5, args)
    if ""pytorch"" in module:
        model = torch.nn.DataParallel(model, device_ids)
",1
"        enhanced, hlensm, mask = self.frontend(xs_pad, ilens)
        if prev:
            self.train()
        return enhanced.cpu().numpy(), mask.cpu().numpy(), ilens

",1
"                self.conv_proj_chans,
",1
"    )
    parser.add_argument(
        ""--report-interval-iters"",
        default=100,
        type=int,
",1
"

class BatchScorerInterface(ScorerInterface):
    """"""Batch scorer interface.""""""
",1
"            stride=1,
            padding=(kernel_size - 1) // 2,
        )
        self.w_2 = torch.nn.Conv1d(
            hidden_chans,
",1
"
        # 2b. CTC branch
",1
"    Args:
        n_vocab (int): The size of the vocabulary
",1
"
    @staticmethod
    def add_arguments(parser):
",1
"        self.eos = odim - 1
        self.odim = odim
",1
"unnorm_utt = set()
for line in open(sys.argv[1], encoding=""utf-8""):
",1
"            tarinfo = default_tarinfo(dst)
            tarinfo.size = fileobj.getbuffer().nbytes
            tar.addfile(tarinfo, fileobj=fileobj)
        for dst, src in files_map.items():
            # Resolve to avoid symbolic link
",1
"            cbhg_outs = self.cbhg.inference(outs)
            return cbhg_outs, probs, att_ws
        else:
            return outs, probs, att_ws
from abc import ABC
",1
"        padding=padding,
    )
",1
"        else:
            xs_pad = self.embed(xs_pad)
",1
"        not k.endswith(""_lengths"") for k in data[0]
    ), f""*_lengths is reserved: {list(data[0])}""

    output = {}
    for key in data[0]:
",1
"    pass

scheduler_classes = dict(
    ReduceLROnPlateau=torch.optim.lr_scheduler.ReduceLROnPlateau,
",1
"                            (0, 0)
                        ] * (enh.ndim - 1)
                        enh = np.pad(enh, padwidth, mode=""constant"")

                if args.enh_filetype in (""sound"", ""sound.hdf5""):
",1
"        # prior is None -> NUM_NODES = 1
        return int(os.environ.get(""WORLD_SIZE"", 1))
from typing import Collection
from typing import Dict
",1
"# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"        parser.add_argument(
            ""--total"",
            type=int,
            default=100000,
",1
"    device=torch.device(""cpu""),
):
    ilens = np.sort(np.random.randint(1, maxin_len, bs))[::-1].tolist()
    olens = np.sort(np.random.randint(3, maxout_len, bs))[::-1].tolist()
    xs = [np.random.randint(0, idim, lg) for lg in ilens]
",1
"                {
                    ""input"": [{""shape"": [ilens[i], idim]}],
                    ""output"": [{""shape"": [olens[i]]}],
                },
            )
",1
"        self.dtype = dtype
        self.always_2d = always_2d
        self.normalize = normalize
        self.data = read_2column_text(fname)
",1
"        ""main/loss_ctc"",
        ""main/loss_att"",
        ""validation/main/loss"",
        ""validation/main/loss_ctc"",
",1
"        feed_forward,
",1
"        help=""A text file in which is written a sequence of float numbers ""
        ""separated by comma.""
",1
"                logging.warning(
",1
"        """"""Subsample x.

",1
"        cls,
        config_file: Union[Path, str],
        model_file: Union[Path, str] = None,
",1
"@pytest.mark.parametrize(
    ""value, desired"", [(""3k"", 3000), (""2m "", 2000000), (""none"", None)],
",1
"        tarinfo.uid = os.getuid()
    tarinfo.mtime = datetime.now().timestamp()
",1
"
                    if "":"" not in value:
                        raise RuntimeError(
",1
"    idim = 11
    odim = idim
",1
"from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"        else:
",1
"        sort_batch=sort_batch,
",1
"            )
        else:
            self.error_calculator = None
        self.rnnlm = None

",1
"            if self.cumulate_att_w:
",1
"
    @abstractmethod
    def forward(
",1
"
if len(sys.argv) < 3:
    err(""Usage: %s <prompts-file> <id-prefix> <utt-id1> <utt-id2> ... "" % sys.argv[0])
    sys.exit(1)
",1
"from espnet2.text.build_tokenizer import build_tokenizer
",1
"

",1
"        )
        group.add_argument(
",1
"        # change batchsize depending on the input and output length
        # if ilen = 1000 and max_length_in = 800
        # then b = batchsize / 2
        # and max(min_batches, .) avoids batchsize = 0
",1
"            e = self[""encoders."" + str(i)](e, xx_mask, batch)
        return self.norm(e).reshape(batch, length, -1), x_mask, ilens
# encoding: utf-8
""""""Class Declaration of Transformer's Decoder.""""""

",1
"            device=device,
        )
        trainer.extend(att_reporter, trigger=(1, ""epoch""))
",1
"try:
    tmpFile = open(tmpFileLocation)
",1
"    args = parser.parse_args()
    with codecs.open(args.text, ""r"", ""utf-8"") as fid:
",1
"

def test_ESPnetDataset_h5file_2(h5file_2):
    dataset = ESPnetDataset(
",1
"    ngpu: Optional[int],
    log_interval: Optional[int],
    write_collected_feats: bool,
) -> None:
    """"""Perform on collect_stats mode.
",1
"
    @staticmethod
",1
"    labelright=True,
    labeltop=False,
    cmap=""inferno"",
):
    """"""Plot spectrogram using matplotlib.
",1
"@pytest.mark.parametrize(
    ""norm_vars, norm_means"",
    [(True, True), (False, False), (True, False), (False, True)],
)
def test_inverse_backwar_not_leaf_in(stats_file, norm_vars, norm_means):
",1
"                    econv_layers=args.eprenet_conv_layers,
                    econv_chans=args.eprenet_conv_chans,
                    econv_filts=args.eprenet_conv_filts,
                    use_batch_norm=args.use_batch_norm,
",1
"from espnet2.layers.utterance_mvn import UtteranceMVN

",1
"        :param list enc_hs_len: padded encoder hidden state length (B)
        :param torch.Tensor dec_z: decoder hidden state (B x D_dec)
        :param tuple att_prev_states: previous attention weight and lstm states
                                      ((B, T_max), ((B, att_dim), (B, att_dim)))
",1
"    :param int dunits: # units of decoder
    :param int att_dim: attention dimension
    :param int aconv_chans: # channels of attention convolution
",1
"        if type[-1] == ""p"":
            self.brnn = RNNP(idim, layers, units, projs, subsample, dropout, typ=typ)
        else:
",1
"    Ref:
        ""Attention Is All You Need"", https://arxiv.org/pdf/1706.03762.pdf
",1
"
def test_build_batch_sampler_invalid_fold_lengths(shape_files):
    with pytest.raises(ValueError):
",1
"    def forward(
        self, x: torch.Tensor, t: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """"""Compute LM loss value from buffer sequences.
",1
"        >>> load_pretrained_model(""somewhere/model.pth"", model)
        >>> load_pretrained_model(""somewhere/encoder.pth"", model, ""encoder"")
",1
"        scorers=scorers,
        token_list=train_args.char_list,
",1
"
",1
"        )
",1
"        return hs

    def _source_mask(self, ilens):
",1
"    else:
        retval = Average(v)
    assert check_return_type(retval)
    return retval
",1
"                f""args doesn't have {field.name}. You need to set it to ArgumentsParser""
            )
",1
"            text_f.write(utt_id + "" "" + words + ""\n"")
            wav_scp_f.write(
                utt_id
",1
"            f""N-batch={len(self)}, ""
            f""batch_bins={self.batch_bins}, ""
            f""sort_in_batch={self.sort_in_batch}, ""
",1
"    L.LambdaLR,
    L.StepLR,
    L.MultiStepLR,
",1
"
tmpFileLocation = ""data/local/tmp/spk2gendertmp""

tmpFile = None
",1
"    with pytest_raise_or_nothing(desired):
        assert float_or_none(value) == desired


",1
"                thr = accum_best_scores[:, -1]
                for samp_i in six.moves.range(batch):
",1
"    def attention_add_arguments(parser):
        """"""Add arguments for the attention.""""""
        group = parser.add_argument_group(""E2E attention setting"")
",1
"        ({""etype"": ""blstm"", ""eprojs"": 16}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""etype"": ""blstm"", ""eprojs"": 16}, {}),
",1
"    :param int eprojs: number of projection units of encoder network
",1
"def test_resolve_distributed_mode5(dist_init_method):
    args = argparse.Namespace(
        multiprocessing_distributed=False,
        dist_world_size=2,
",1
"    parser.add_argument(
        ""--patience"",
        default=3,
        type=int,
        nargs=""?"",
",1
"                :nbest
            ]
",1
"        #    uttB 201,...
        utt2shapes = [
",1
"            os.makedirs(self.outdir)

",1
"    x = torch.randn(2, 1000, requires_grad=True)
",1
"            dataset=TransformDataset(train, lambda data: converter([load_tr(data)])),
            batch_size=1,
            num_workers=args.n_iter_processes,
",1
"                        ""input"": [
                            {
                                ""feat"": str(p) + "":"" + uttid,
                                ""filetype"": ""hdf5"",
",1
"                dim=0,
            )

        for si in range(self.n_bb):
            log_psi[si, self.eos] = r_sum[self.end_frames[si], si]
",1
"    )
    parser.add_argument(
        ""--lr"", default=1e-3, type=float, help=""Learning rate for optimizer""
",1
"

",1
"        if self._init is None:
            self._init = self._d_inv05 * (1.0 * self._warmup_steps_inv15)
",1
"            cached output list of (batch, max_time_out-1, size)
",1
"class BaseEvaluator(Evaluator):
    """"""Base Evaluator in ESPnet""""""

    def __call__(self, trainer=None):
        ret = super().__call__(trainer)
",1
")
def test_asr_build(name, backend):
    model = dynamic_import_asr(name, backend).build(
        10, 10, mtlalpha=0.123, adim=4, eunits=3, dunits=3, elayers=2, dlayers=2
    )
",1
"
    model = m.E2E(40, 5, args)
",1
"        z_list = [self.zero_state(x[0].unsqueeze(0))]
        for _ in range(1, self.dlayers):
            c_list.append(self.zero_state(x[0].unsqueeze(0)))
",1
"            mod = min_batch_size - len(minibatch) % min_batch_size
",1
"                    self.dropout_dec[i - 1](z_list[i - 1]), (z_prev[i], c_prev[i])
                )
        else:
            z_list[0] = self.decoder[0](ey, z_prev[0])
",1
"        ),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""mtlalpha"": 0.0}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""mtlalpha"": 1.0}),
",1
"        self.enc_h = None
        self.pre_compute_k = None
        self.pre_compute_v = None
        self.mask = None
",1
"import torch
",1
"    random.seed(nseed)
    numpy.random.seed(nseed)
    os.environ[""CHAINER_SEED""] = str(nseed)
    import espnet.nets.chainer_backend.e2e_asr as m
",1
"@pytest.mark.parametrize(""module"", [""pytorch""])
",1
"            u (torch.Tensor): (B, C)
            ilens (torch.Tensor): (B,)
        """"""
        B, _, C = psd_in.size()[:3]
        assert psd_in.size(2) == psd_in.size(3), psd_in.size()
",1
"        eos=eos,
        token_list=token_list,
",1
"        LegacyPositionalEncoding(4, 0.0), torch.nn.Linear(4, 2)
",1
"        assert len(x) == len(ilens), (len(x), len(ilens))
        # (B, T, F) or (B, T, C, F)
        if x.dim() not in (3, 4):
            raise ValueError(f""Input dim must be 3 or 4: {x.dim()}"")
",1
"            [""main/acc"", ""validation/main/acc""], ""epoch"", file_name=""acc.png""
        )
    )
    trainer.extend(
",1
"        :param List xs_pad_list: list of batch (torch.Tensor) of padded input sequences
                                [(B, Tmax_1, idim), (B, Tmax_2, idim),..]
        :param List ilens_list:
",1
"
",1
"            elif input_layer == ""embed"":
                self.input_layer = chainer.Sequential(
",1
"
",1
"    parser.add_argument(""json"", type=str, help=""json files"")
    parser.add_argument(""dict"", type=str, help=""dict"")
    parser.add_argument(""ref"", type=str, help=""ref"")
    parser.add_argument(""hyp"", type=str, help=""hyp"")
",1
"        word_rnnlm.eval()

        if rnnlm is not None:
            rnnlm = lm_pytorch.ClassifierWithState(
                extlm_pytorch.MultiLevelLM(
",1
"                        dtype=np.int64,
                    )
                    for name in names
                ]
                nbest_hyps = model.translate_batch(
",1
"
",1
"    #   |- butterfly/
    #       |- 2857.png
",1
"        for i in six.moves.range(maxlen):
",1
"        # - ""CUDA_VISIBLE_DEVICES"" is set to an id. e.g. ""1""
        #   => This could be used for LOCAL_RANK
        cvd = os.environ[""CUDA_VISIBLE_DEVICES""].split("","")
        if len(cvd) == 1 and ""LOCAL_RANK"" not in os.environ:
            # If CUDA_VISIBLE_DEVICES is set and LOCAL_RANK is not set,
",1
"                help=""The optimizer type"",
            )
            group.add_argument(
                f""--optim{suf}_conf"",
",1
"    else:
        use_apex = False
",1
"        )
",1
"        self, hyp: Hypothesis, x: torch.Tensor
",1
"        return optimizers

    @classmethod
    def exclude_opts(cls) -> Tuple[str, ...]:
        """"""The options not to be shown by --print_config""""""
",1
"
        amp.register_float_function(CTC, ""loss_fn"")
        amp.init()
        logging.warning(""register ctc as float function"")
",1
"                    raise argparse.ArgumentError(self, mes)
",1
"from espnet.nets.pytorch_backend.rnn.encoders import encoder_for
from espnet.nets.scorers.ctc import CTCPrefixScorer

",1
"            self.mlp_k += [torch.nn.Linear(eprojs, att_dim_k, bias=False)]
            self.mlp_v += [torch.nn.Linear(eprojs, att_dim_v, bias=False)]
            self.gvec += [torch.nn.Linear(att_dim_k, 1)]
            self.loc_conv += [
                torch.nn.Conv2d(
",1
"
",1
"
",1
"            default=""pytorch"",
            choices=[
                ""pytorch"",
                ""xavier_uniform"",
                ""xavier_normal"",
",1
"        ""--ctc-weight"", type=float, default=0.0, help=""CTC weight in joint decoding""
    )
",1
"

# https://github.com/espnet/espnet/issues/1750
def test_v0_3_transformer_input_compatibility():
    args = make_arg()
",1
"        xs = F.relu(self.conv1(xs))
        xs = F.relu(self.conv2(xs))
        batch, _, length, _ = xs.shape
",1
"            # show progress
            if interval is not None and (i + 1) % interval == 0:
                elapsed_time_per_sample = (time.time() - start_time) / interval
                logging.info(
",1
"            In the case of multi-gpu, `device={""main"":0, ""sub_1"": 1, ...}`.
        accum_grad (int):The number of gradient accumulation. if set to 2, the network
            parameters will be updated once in twice,
            i.e. actual batchsize will be doubled.

",1
"        return h[0]

    def recognize(self, x, recog_args, char_list=None, rnnlm=None):
        """"""Recognize input features.

",1
"            type=float,
            help=""Initial value of learning rate"",
        )
        group.add_argument(
",1
"
",1
"
        # define duration calculator
        if self.teacher is not None:
            self.duration_calculator = DurationCalculator(self.teacher)
        else:
",1
"            trigger=training.triggers.MaxValueTrigger(""validation/main/acc""),
        )
",1
"            reduction_factor = model.module.reduction_factor
        else:
            att_vis_fn = model.calculate_all_attentions
            plot_class = model.attention_plot_class
            reduction_factor = model.reduction_factor
",1
"
""""""Mask module.""""""

from distutils.version import LooseVersion
",1
"        streaming_offset_margin=2,
        verbose=2,
        char_list=[u"""", u"""", u"""", u"""", u""""],
        outdir=None,
",1
"        "")"",
        ""|"",
        ""^"",
",1
"        ),
        ({""transfer_encoder_from_teacher"": True, ""encoder_concat_after"": True}),
        ({""transfer_encoder_from_teacher"": True, ""decoder_concat_after"": True}),
        (
",1
"            encoder_out.size(),
            speech.size(0),
        )
        assert encoder_out.size(1) <= encoder_out_lens.max(), (
            encoder_out.size(),
",1
"        yaml_files={""def.yaml"": str(tmp_path / ""bar.yaml"")},
        option=[tmp_path / ""a"", tmp_path / ""b"" / ""a""],
        outpath=str(tmp_path / ""out.tgz""),
",1
"        delimiter = "" ""
        dtype = np.long
",1
"    [(True, True), (False, False), (True, False), (False, True)],
)
def test_inverse_identity(stats_file, norm_vars, norm_means):
    layer = GlobalMVN(stats_file, norm_means=norm_means, norm_vars=norm_vars)
",1
"                ),
            )
        elif args.criterion == ""loss"":
",1
"from espnet.asr.asr_utils import torch_snapshot
from espnet.asr.pytorch_backend.asr_init import load_trained_modules
from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"    )
",1
"                loss_data,
            )
        else:
            logging.warning(""loss (=%f) is not correct"", loss_data)
",1
"                get_power_spectral_density_matrix(data, mask) for mask in mask_speech
            ]
",1
"from espnet.nets.pytorch_backend.e2e_asr import CTC_LOSS_THRESHOLD
from espnet.nets.pytorch_backend.e2e_asr import Reporter
from espnet.nets.pytorch_backend.nets_utils import get_subsample
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask
from espnet.nets.pytorch_backend.nets_utils import th_accuracy
",1
"        attention_heads: the number of heads of multi head attention
        linear_units: the number of units of position-wise feed forward
        num_blocks: the number of decoder blocks
",1
"                                stride=1,
                                padding=(econv_filts - 1) // 2,
                                bias=False,
",1
"        default=0.0,
        help=""""""Input length ratio to obtain max output length.
                        If maxlenratio=0.0 (default), it uses a end-detect function
",1
"        Returns:
",1
"    new_js = {}
    with chainer.no_backprop_mode():
        for idx, name in enumerate(js.keys(), 1):
",1
"                h._replace(yseq=self.append_token(h.yseq, self.eos))
                for h in running_hyps
            ]
",1
"            if is_scipy_wav_style(mat):
                # If data is sound file, then got as Tuple[int, ndarray]
",1
"                                {""yseq"": yk, ""vscore"": _vscore, ""score"": _score}
                            )
                        k = k + 1
",1
"        return None
    else:
        raise ValueError(type(obj))

",1
"            statistics_mode=self.statistics_mode,
        )
",1
"    args = parser.parse_args()

    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
    if args.verbose > 0:
",1
"                            [
                                ""-"".join(segment.split(""-"")[:3])
                                + ""-""
",1
"    sorted_data = random.sample(data.items(), len(data.items()))
    logging.info(""# utts: "" + str(len(sorted_data)))
",1
"
    """"""
    if isinstance(m, nn.Conv1d):
",1
"        else args.preprocess_conf,
        preprocess_args={""train"": False},
",1
"

@pytest.mark.skipif(torch.cuda.device_count() < 2, reason=""multi gpu required"")
",1
"    )
",1
"    # e.g. imagefolder_256x256
    # /
    #   |- horse/
    #       |- 8537.png
    #       |- ...
",1
"        return wav.split(""/"")[-4] + ""_"" + wav[-21:-4].replace(""/"", """")

",1
"

if __name__ == ""__main__"":
    main(sys.argv[1:])
",1
"
                for k in six.moves.range(self.odim):
                    beam_hyp = {
                        ""score"": new_hyp[""score""] + float(ytu[k]),
",1
"
        # Assume ntasks_per_node == 1
",1
"    return att


def att_to_numpy(att_ws, att):
",1
"                    for n in range(self.n_layers)
",1
"                (cumsum_probs[:, wids[1]] - cumsum_probs[:, wids[0]])
                if wids is not None
                else 1.0
",1
"        trainer.extend(
            ShufflingEnabler([train_iter]),
            trigger=(args.sortagrad if args.sortagrad != -1 else args.epochs, ""epoch""),
",1
"        att_idx = min(strm_idx, len(self.att) - 1)
        for idx in range(self.num_encs):
",1
"import sys


",1
"
def savefig(plot, filename):
    plot.savefig(filename)
    plt.clf()
",1
"            )
            if self.cumulate_att_w:
                logging.warning(
                    ""cumulation of attention weights is disabled in forward attention.""
                )
",1
"        ""--preprocess-conf"",
        type=str,
        default=None,
        help=""The configuration file for the pre-processing"",
    )
",1
"    )
    parser.add_argument(""utt2spk"", type=str, help=""utt2spk file for the speaker"")
",1
"
",1
"import yaml


",1
"        ({""beam_size"": 1, ""report_cer"": False, ""report_wer"": True}, {}),
        (
            {
                ""rnnt_mode"": ""rnnt-att"",
                ""beam_size"": 1,
",1
"        raise NotImplementedError
",1
"        shape_file=shape_files[0],
        sort_in_batch=sort_in_batch,
",1
"    module = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_asr_transducer"".format(backend)
    )
",1
"    @abstractmethod
    def step(self, epoch: int = None):
        pass

    @abstractmethod
",1
"                                wave.astype(np.float64), rate, args.fs, axis=0
",1
"    _, data = dataset[""a""]
    assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))

    _, data = dataset[""b""]
    assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))
",1
"
",1
"    else:
        device = ""cpu""

    # 1. Set random-seed
    set_all_random_seed(seed)
",1
"                    self.pre_compute_v[h] * w[h].view(batch, self.h_length, 1), dim=1
                )
",1
"        logging.info(""max output length: "" + str(maxlen))
        logging.info(""min output length: "" + str(minlen))

        # initialize hypothesis
",1
"    )
    parser.add_argument(
        ""rspecifier"", type=str, help=""Read specifier id. e.g. ark:some.ark""
    )
",1
"import torch

from test.test_e2e_asr_transformer import run_transformer_copy
from test.test_e2e_asr_transformer import subsequent_mask
",1
"    y, _ = layer(x)
",1
"
import argparse
import codecs
",1
"
    optim = torch.optim.Adam(model.parameters(), 0.02)

    for i in range(10):
",1
"        partial_modules, key=lambda x: (x[0], x[1])
",1
"            ""fastest way to use PyTorch for either single node or ""
            ""multi node data parallel training"",
        )
",1
"                return []
            else:
",1
"            batch.append(
                (
                    uttid,
                    {
                        ""input"": [{""feat"": path, ""name"": ""input1""}],
",1
"        ),  # MTL w/ CTC ASR + MT
        (
            ""pytorch"",
            {""asr_weight"": 0.1, ""mtlalpha"": 0.5, ""mt_weight"": 0.0},
        ),  # MTL w/ attention ASR + CTC ASR
",1
"    sp.load(model)
",1
"
import kaldiio
import numpy

from espnet.transform.spectrogram import spectrogram
",1
"            # forward decoder
",1
"
    :param link.Chain predictor : The RNNLM
    :param function lossfun: The loss function to use
",1
"        """"""
        x = self.conv(x)
        if self.padding != 0:
            x = x[:, :, : -self.padding]
",1
"            hop_length=self.hop_length,
",1
"    stats_list = [{""aa"": 0.3}, {""aa"": 0.5}, {""aa"": 0.2}]
    for e in range(len(stats_list)):
",1
"        # gradient accumulation is turned off in order to evaluate the model
",1
"    # optimization related
",1
"class ASRTask(AbsTask):
    # If you need more than one optimizers, change this value
",1
"            diagonal_scores = att_ws.max(dim=-1)[0].mean(dim=-1)  # (#heads * #layers,)
            diagonal_head_idx = diagonal_scores.argmax()
            att_ws = att_ws[diagonal_head_idx]  # (L, T)
        else:
",1
"
",1
"
    else:
",1
"
    # read json data
    with open(args.train_json, ""rb"") as f:
        train_json = json.load(f)[""utts""]
    with open(args.valid_json, ""rb"") as f:
",1
"        )
        if len(word_split) > 0:
            step_int = int(math.floor(float(diff_int) / len(word_split)))
",1
"            batch_frames_inout=args.batch_frames_inout,
            iaxis=0,
            oaxis=0,
        )
",1
"                    pass

",1
"
        """"""
        # local import to avoid cyclic import in lm_train
",1
"
""""""End-to-end speech translation model decoding script.""""""
",1
"        raise ValueError(
            ""Number of encoders needs to be more than one. {}"".format(num_encs)
        )
""""""Attention modules for RNN.""""""

",1
"        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""json"", type=str, help=""json file"")
    parser.add_argument(
        ""--parts"", ""-p"", type=int, help=""Number of subparts to be prepared"", default=0
",1
"            nargs=""+"",
            default=[
",1
"class Dummy2(AbsESPnetModel):
    def __init__(self, atype):
        super().__init__()
",1
"    """"""
    # check argument type
    assert isinstance(args, argparse.Namespace) or args is None
    assert callable(add_arguments)
",1
"    def forward(
        self, input: torch.Tensor, input_lengths: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        raise NotImplementedError
",1
"            ),
        )
        if self.normalize_before:
            self.after_norm = LayerNorm(output_size)

",1
"            normalized=normalized,
            onesided=onesided,
",1
"            f.write(f""{_log_base}\n"")
        logging.info(f""PPL={ppl}"")

",1
"        type=int,
        help=""Number of processes of iterator"",
    )
",1
"    )
    legacy_beam.to(device, dtype=dtype)
    legacy_beam.eval()
",1
"                for k in six.moves.range(self.odim):
                    beam_hyp = {
                        ""score"": new_hyp[""score""] + float(ytu[k]),
                        ""yseq"": new_hyp[""yseq""][:],
",1
"
    def tokens2ids(self, tokens: Iterable[str]) -> List[int]:
        return [self.token2id.get(i, self.unk_id) for i in tokens]
from pathlib import Path
from typing import Iterable
",1
"        args.lsm_weight,
        args.sampling_probability,
    )
",1
"            mask = None if mask is None else mask[:, -1:, :]

        if self.concat_after:
",1
"            )
            sys.exit(2)

",1
"
""""""Transformer text translation model (pytorch).""""""

from argparse import Namespace
from distutils.util import strtobool
",1
"def main(args):
    args = get_parser().parse_args(args)
    convert(args.json, args.dict, args.refs, args.hyps, args.num_spkrs)

",1
"            idim=idim,
",1
"    ):
",1
"        dtype = torch.float32
    model = model.to(device=device, dtype=dtype)

    # Setup an optimizer
    if args.opt == ""adadelta"":
",1
"        """"""Score new token.

        Args:
",1
"        return xs, ilens, ys
",1
"        if shuffle:
            indices = np.arange(0, len(id_list))
            state.shuffle(indices)
",1
"        if self.training or self.error_calculator is None:
            bleu = 0.0
        else:
",1
"

class BeamSearch(torch.nn.Module):
",1
"
        :param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out)
        :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                                      dtype=torch.uint8 in PyTorch 1.2-
                                      dtype=torch.bool in PyTorch 1.2+ (include 1.2)
",1
"                - elayers (int): The number of encoder blstm layers.
                - eunits (int): The number of encoder blstm units.
                - econv_layers (int): The number of encoder conv layers.
                - econv_filts (int): The number of encoder conv filter size.
",1
"# Copyright 2018 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"            self.fd = self.path.open(""w"", encoding=""utf-8"")

        self.keys.add(key)
        self.fd.write(f""{key} {value}\n"")

",1
"        Float: Sum of the norm calculated from the given array.

",1
"        raise ValueError(f""Not supported loader_type={loader_type}"")

",1
"        logging.info(""#sentences in the test data = "" + str(len(test)))
        logging.info(""#tokens in the test data = "" + str(n_test_tokens))
        logging.info(
            ""oov rate in the test data = %.2f %%"" % (n_test_oovs / n_test_tokens * 100)
",1
"

class AttLoc2D(torch.nn.Module):
    """"""2D location-aware attention

",1
"        lm=args.lm_weight,
",1
"                    model, args.outdir + ""/model.loss.best"", load_fn=torch_load
",1
"0: empty token for CTC algorithm
1: special UNK token
",1
"        (""transformer"", {""decoder_normalize_before"": False}),
",1
"            batch_in_data = [np.random.randn(10, 40), np.random.randn(5, 40)]
",1
"        retval = {k: v[0] if len(v) == 1 else v for k, v in retval.items()}
",1
"
        if self.report_wer:
            wer = self.calculate_wer(seqs_hat, seqs_true)

",1
"import logging
import os
",1
"                _model = copy.deepcopy(
                    model
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Tacotron2 decoder related modules.""""""
",1
"    Example:
",1
"import nltk
",1
"    :param int min_batch_size: minimum batch size (for multi-gpu)
    :param bool shortest_first: Sort from batch with shortest samples
",1
"        self.register_buffer(""inv_melmat"", torch.from_numpy(inv_mel.T).float())

    def extra_repr(self):
        return "", "".join(f""{k}={v}"" for k, v in self.mel_options.items())

",1
"                for idx in range(self.num_encs)
",1
"        logging.info(
            ""generation speed = %s (sec / sample)""
            % ((time.time() - start_time) / (len(y) - 1))
",1
"        self.eval()

        # 1. Encoder
",1
"        :return: batch, uttid_list
",1
"        y = decode_mu_law(y, mu=train_args.n_quantize)

        # apply mlsa filter for noise shaping
        y = mlsa_filter(y)

",1
"            trigger=(args.report_interval_iters, ""iteration""),
        )

",1
"        logging.basicConfig(
            level=logging.WARN,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"        ),
        ({""report_cer"": True, ""beam_size"": 1}, {}),
        ({""report_wer"": True, ""beam_size"": 1}, {}),
        ({""report_cer"": True, ""beam_size"": 2}, {}),
",1
"            compress=compress,
            compression_method=compression_method,
",1
"            For chainer, list of source sequences chainer.Variable
        :param ilens: batch of lengths of source sequences (B)
",1
"            or blks[i] == ""[LAUGHTER]""
        ):
            out_line += "" "" + blks[i]
            continue
",1
"        else:
            # Inference mode
",1
"from espnet2.layers.log_mel import LogMel
",1
"        fmax: float >= 0 [scalar] highest frequency (in Hz).
            If `None`, use `fmax = fs / 2.0`
        htk: use HTK formula instead of Slaney
        norm: {None, 1, np.inf} [scalar]
",1
"        feat_lens = [js[key][""output""][1][""shape""][0] for key in keys]
        sorted_index = sorted(range(len(feat_lens)), key=lambda i: -feat_lens[i])
        keys = [keys[i] for i in sorted_index]

",1
"    if norm_means:
        x -= mean
",1
"import pytest

",1
"        rnn_type = (""b"" if bidirectional else """") + rnn_type
        if use_projection:
            self.enc = torch.nn.ModuleList(
                [
",1
"
",1
"            time_warp(spec, W=W),
",1
"
",1
"
    # Save attention figure for each epoch
    if args.num_save_attention > 0:
",1
"    :param bool han_mode:
        flag to swith on mode of hierarchical attention and not store pre_compute_enc_h
    """"""
",1
"                start_t = None
                end_t = None
                utt_id += 1

",1
"
from espnet.nets.chainer_backend.nets_utils import _subsamplex
from espnet.nets.e2e_asr_common import get_vgg2l_odim
",1
"                stats, weight = recursive_average(stats, weight, distributed)

                # Now weight is summation over all workers
",1
"                        i += 1
                a = chars

            a = [a[j : j + n] for j in range(0, len(a), n)]

",1
"
        Args:
            h (torch.Tensor): encoder hidden state sequences (Tmax, Henc)
            recog_args (Namespace): argument Namespace containing options
            rnnlm (torch.nn.Module): language module
",1
"        [""o"", ""iuiuiuiuiuiuiuo"", ""ieieieieieieieieo""],
        [""o"", ""iuiuiuiuiuiuiuiuo"", ""iuiuiuiuiuiuiuiuo""],
",1
"
from typeguard import check_type


def build_dataclass(dataclass, args: argparse.Namespace):
",1
"    """"""Positional encoding module.

    :param int n_units: embedding dim
",1
"            shape_str = "","".join(map(str, mat.shape))
        else:
            if len(mat) == 2 and isinstance(mat[1], tuple):
",1
"            type=int,
            help=""Number of attention transformation dimensions"",
",1
"            postprocess=compute_perplexity,
            trigger=(args.report_interval_iters, ""iteration""),
        )
",1
"            init_torch_weight_const(model, const)
",1
"    aconv_filts = getattr(args, ""aconv_filts"", None)
",1
"
    def __setitem__(self, key, value):
",1
"        logging.info(""writing a model config file to "" + model_conf)
        f.write(
            json.dumps(
                (idim, odim, vars(args)), indent=4, ensure_ascii=False, sort_keys=True
",1
"# -*- coding: utf-8 -*-
",1
"        self.reporter.report(report_keys)

",1
"    The Postnet predicts refines the predicted
    Mel-filterbank of the decoder,
    which helps to compensate the detail sturcture of spectrogram.

",1
"            before_outs, ys
        )
        bce_loss = self.bce_criterion(logits, labels)
",1
"    """"""Decoder layer.

    Args:
        odim (int): The output dimension.
        n_layers (int): Number of ecoder layers.
",1
"

@pytest.mark.parametrize(
",1
"    )
    parser.add_argument(""text"", type=str, help=""input text"")
",1
"        sos=model.sos,
        eos=model.eos,
        pre_beam_score_key=None if ctc_weight == 1.0 else ""decoder"",
",1
"        :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                                      dtype=torch.uint8 in PyTorch 1.2-
                                      dtype=torch.bool in PyTorch 1.2+ (include 1.2)
        :param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)
",1
"
            if self.dtype == ""transformer"":
",1
"    Examples:
        >>> import argparse
        >>> str2pair_str('abc,def ')
        ('abc', 'def')
",1
"            if dim == ""time"":
                dim = 1
            elif dim == ""freq"":
                dim = 2
",1
"    return parser


if __name__ == ""__main__"":
    parser = get_parser()
",1
"            ey (torch.Tensor): batch of input features (B, Emb_dim)
            dstate (list): list of L input hidden and cell state (B, Hdec)

        Returns:
",1
"
    batch = {
",1
"        scorers=scorers,
",1
"            ""--postnet-chans"", default=256, type=int, help=""Number of postnet channels""
        )
",1
"            center=center,
            pad_mode=pad_mode,
            normalized=normalized,
",1
"            raise ValueError('""none"", ""nil"", and ""null"" are reserved.')
        if type_check is not None:
",1
"        # subsample frame
",1
"    parser.add_argument(
        ""--num-encs"", default=1, type=int, help=""Number of encoders in the model.""
    )
    # search related
",1
"    @classmethod
    def check_required_command_args(cls, args: argparse.Namespace):
        assert check_argument_types()
        for k in vars(args):
            if ""-"" in k:
",1
"
    # convert to string
    tokenid = "" "".join([str(idx) for idx in tokenid_as_list])
    token = "" "".join(token_as_list)
    text = """".join(token_as_list).replace(""<space>"", "" "")
",1
"                if m:
",1
"
",1
"        return c, w


class AttAdd(torch.nn.Module):
",1
"        logging.info(""total log probability: "" + str(nbest_hyps[0][""score""]))
        logging.info(
",1
"            choices=[""forward_ta"", ""forward"", ""location""],
            help=""Type of attention mechanism"",
        )
        group.add_argument(
            ""--adim"",
",1
"        path (str): Model path or snapshot file path to be loaded.
        model (chainer.Chain): Chainer model.
",1
"
        # apply word-level probabilies for <space> and <eos> labels
",1
"from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import GuidedAttentionLoss
from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import Tacotron2Loss
from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
from espnet.nets.pytorch_backend.rnn.attentions import AttForward
from espnet.nets.pytorch_backend.rnn.attentions import AttForwardTA
",1
"        else:
            self.global_mvn = None
",1
"        )
        fl = ""{}/{}.{}.json"".format(dirname, filename, i + 1)
",1
"from espnet.nets.batch_beam_search import BeamSearch
",1
"    sys.stdout = codecs.getwriter(""utf-8"")(
        sys.stdout if is_python2 else sys.stdout.buffer
    )
    line = f.readline()
",1
"        logging.warning(""Skip DEBUG/INFO messages"")

    # check CUDA_VISIBLE_DEVICES
    if args.ngpu > 0:
        cvd = os.environ.get(""CUDA_VISIBLE_DEVICES"")
",1
"            # Batch-size average
            loss = loss / th_pred.size(1)
            return loss

    n_out = 7
",1
"            logging.error(""#gpus is not matched with CUDA_VISIBLE_DEVICES."")
            sys.exit(1)
",1
"    result = {""cached"": [], ""baseline"": []}
",1
"                            yk = yseq[k][:]
                            _vscore = vscores[samp_i][beam_j] + penalty_i
                        if _vscore:
",1
"            iterator (chainer.dataset.Iterator): Iterator for training.
            optimizer (torch.optim.Optimizer) : Pytorch optimizer instance.
",1
"        :return: attention weighted encoder state (B, D_enc)
        :rtype: torch.Tensor
        :return: previous attention weights (B x att_win x T_max)
",1
"            )
            # should copy becasuse Namespace will be overwritten globally
            recog_args = Namespace(**vars(recog_args))
",1
"            if attr.isdigit():
                attr = int(attr)
            indict = indict[attr]
        print(indict)
",1
"    :param int att_dim_k: dimension k in multi head attention
    :param int att_dim_v: dimension v in multi head attention
    :param bool han_mode: flag to swith on mode of hierarchical attention
        and not store pre_compute_k and pre_compute_v
",1
"        concat_after (bool): whether to concat attention layer's input and output

    """"""
",1
"                mask = 1.0 - make_pad_mask(enc_hs_len).float()
                att_prev += [to_device(self, mask / mask.new(enc_hs_len).unsqueeze(-1))]
",1
"        >>> reporter = Reporter()
        >>> with reporter.observe('train') as sub_reporter:
        ...     for batch in iterator:
        ...         stats = dict(loss=0.2)
",1
"
import numpy as np
import torch

",1
"
    # Create subparser for ASR
    for name, contents in [(""asr"", ASRPackedContents), (""tts"", TTSPackedContents)]:
        parser_asr = subparsers.add_parser(
            name, formatter_class=argparse.ArgumentDefaultsHelpFormatter,
",1
"
",1
"    """"""Train with the given args.

    Args:
        args (namespace): The program arguments.

",1
"
    # convert to dict
",1
"

# TODO(watanabe) explanation of BLSTMP
",1
"import torch.nn as nn
",1
"    x = x + 2
",1
"            att_ws += [att_w]
            prev_out = y  # teacher forcing
",1
"

if __name__ == ""__main__"":
",1
"        type=float,
",1
"    dummy_json = make_dummy_json(
        num_encs, [10, 20], [10, 20], idim=20, odim=5, num_inputs=num_encs
",1
")
def test_transformer_trainable_and_decodable(module, model_dict):
    args = make_arg(**model_dict)
    model, x, ilens, y_tgt, y_src, data = prepare(module, args)

",1
"        help=""Token type"",
",1
"    main()
#!/usr/bin/env python3
import argparse
import logging

",1
"        # initialize CTC states
        output_length = len(y) - 1  # ignore sos
        # new CTC states are prepared as a frame x (n or b) x n_labels tensor
",1
"        subsample: Optional[Sequence[int]] = (2, 2, 1, 1),
    ):
        assert check_argument_types()
        super().__init__()
",1
"        tgt_lang_ids = None
        if self.multilingual:
",1
"            key (str): key of hyper parameter

        Returns:
            LMinterface: A new instance of LMInterface.

",1
"@pytest.mark.parametrize(
    ""loader_type"", [""text_int"", ""text_float"", ""csv_int"", ""csv_float"", ""dummy""]
)
",1
"        input_size: int,
        rnn_type: str = ""lstm"",
",1
"import kaldiio
import numpy

from espnet.transform.spectrogram import logmelspectrogram
from espnet.utils.cli_utils import get_commandline_args
",1
"    def calculate_all_attentions(self, xs_pad, ilens, ys_pad, ys_pad_src):
        """"""E2E attention calculation.

",1
"        )
        group.add_argument(
            ""--transformer-enc-positional-dropout-rate"",
",1
"
            for key in sequence_keys:
                if len(batch[key]) != len(batch[sequence_keys[0]]):
                    raise RuntimeError(
",1
"            key, value = arg.split(""="")
            key = key.translate(table)
            value = value.translate(table)
            eles.append(key + value)

",1
"            if args.eunits != args.dunits:
                raise ValueError(
                    ""When using tie_src_tgt_embedding, eunits and dunits must be equal.""
                )
            self.embed.weight = self.dec.embed.weight
",1
"    sampler = LengthBatchSampler(
",1
"    """"""Returns an attention layer given the program arguments.

    Args:
",1
"
def stft2logmelspectrogram(x_stft, fs, n_mels, n_fft, fmin=None, fmax=None, eps=1e-10):
",1
"            print(ref)
#!/usr/bin/env python3
# encoding: utf-8

",1
"        else:
            if not isinstance(hs_pad, list):  # single-speaker input xs_pad
                loss_att, acc, _ = self.dec(hs_pad, hlens, ys_pad)
",1
"            num_workers=args.num_workers,
            seed=args.seed,
            allow_variable_data_keys=args.allow_variable_data_keys,
            ngpu=args.ngpu,
",1
"                                * torch.from_numpy(
",1
"        group.add_argument(
            ""--sort_in_batch"",
            type=str,
            default=""descending"",
            choices=[""descending"", ""ascending""],
",1
"

def encoder_for(args, idim, subsample):
    """"""Return the Encoder module.

",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
",1
"        if report_cer or report_wer:
            self.error_calculator = ErrorCalculator(
                token_list, sym_space, sym_blank, report_cer, report_wer
            )
",1
"
    Returns:
        Tensor: Batch of masked input tensor (B, `*`).

",1
"    Args:
        x (chainer.Variable | np.ndarray): Batch vectors of IDs. Each
            element must be signed integer.
        W (chainer.Variable | np.ndarray): Distributed representation
            of each ID (a.k.a. word embeddings).
",1
"                words = words[:-5]
            source = re.search(r""\((.*)\)"", line).group(1)
            pre, mid, last = source.split(""-"")
            utt_id = ""-"".join([mid, pre, last])

",1
"
    def score_full(
        self, hyp: BatchHypothesis, x: torch.Tensor
    ) -> Tuple[Dict[str, torch.Tensor], Dict[str, Any]]:
        """"""Score new hypothesis by `self.full_scorers`.
",1
"        raise RuntimeError(""run.pl doesn't support submitting to the other nodes."")

    elif Path(args.cmd[0]).name == ""ssh.pl"":
        raise RuntimeError(""Use --host option instead of ssh.pl"")

",1
"
",1
"def frontend_for(args, idim):
    return Frontend(
        idim=idim,
",1
"    return int(x)
",1
"        elayers_sd,
",1
"    xs_1, xs_2, ys = load_inputs_and_targets(batch)
    for x, xd in zip(xs_1, desire_xs_1):
",1
"    from matplotlib.ticker import MaxNLocator
    import os

",1
"            default=False,
            help=""Apply preprocessing to data or not"",
        )
        group.add_argument(
            ""--token_type"",
",1
"    _, data = dataset[""a""]
    assert data[""data1""].shape == (160000,)

",1
"        use_apex = False

    # FIXME: TOO DIRTY HACK
    reporter = Reporter()
    setattr(model, ""reporter"", reporter)
",1
"        """"""Scale of lr.""""""
        import math
",1
"        - LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)
        """"""
        lecun_normal_init_parameters(self)
        # exceptions
",1
"import torch

from espnet.asr.asr_utils import chainer_load
from espnet.asr.asr_utils import get_model_conf
from espnet.asr.asr_utils import torch_load
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""FastSpeech related modules.""""""

import logging
",1
"    ilens = [10, 5]
    olens = [20, 15]
    device = torch.device(""cuda"")
    batch = prepare_inputs(
        idim, odim, ilens, olens, model_args[""spk_embed_dim""], device=device
",1
"        f_max (int, optional): Maximum frequency to analyze.
",1
"
    Returns:
        Tensor or ComplexTensor: Type converted inputs.

",1
"    for i in range(batchsize):
        data.append(
            (
                ""utt%d"" % i,
                {
",1
"
def test_pytorch_scheduler():
    warmup = 30000
",1
"    a(y_tgt, y_tgt, y_tgt, y_mask)
    assert not numpy.isnan(a.attn[0, :, :3, :3].detach().numpy()).any()
",1
"                x = np.add(x, self.bias[spk])
            if self.norm_vars:
                x = np.multiply(x, self.scale[spk])

        else:
",1
"            optimizer.update()
        optimizer.target.cleargrads()  # Clear the parameter gradients

    def update(self):
        self.update_core()
",1
"
subsets = {""train"": {}, ""dev"": {}, ""test"": {}}

",1
"        Returns:
",1
"
class NpyScpReader(collections.abc.Mapping):
    """"""Reader class for a scp file of numpy file.
",1
"

def test_lm():
    n_vocab = 3
    n_layers = 2
",1
"    batch_frames_out = 50
",1
"        trainer.extend(
",1
"            ""n_shift={n_shift}, win_length={win_length}, window={window}, ""
            ""fmin={fmin}, fmax={fmax}, eps={eps}))"".format(
                name=self.__class__.__name__,
                fs=self.fs,
                n_mels=self.n_mels,
",1
"        x: [batch_size, n, d] float `Tensor`
        y: [batch_size, m, d] float `Tensor`
        Returns:
        squared_dists: [batch_size, n, m] float `Tensor`, where
        squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2
",1
"    ),
    ""text_float"": dict(
        func=functools.partial(load_num_sequence_text, loader_type=""text_float""),
        kwargs=[],
        help=""A text file in which is written a sequence of float numbers ""
",1
"        group.add_argument(
            ""--elayers"", default=6, type=int, help=""Number of encoder layers""
        )
        group.add_argument(
",1
"        seed=None,
",1
"        else:
            loss.backward()  # trainable
",1
"
",1
"            self.output_layer = torch.nn.Linear(attention_dim, vocab_size)
        else:
            self.output_layer = None

    def forward(
",1
"
@pytest.mark.skipif(not torch.cuda.is_available(), reason=""gpu required"")
@pytest.mark.parametrize(
",1
"
    const = 1e-4
    init_torch_weight_const(th_model, const)

    th_batch = prepare_inputs(""pytorch"")
",1
"                    schedulers=schedulers,
                    iterator=train_iter_factory.build_iter(iepoch),
                    reporter=sub_reporter,
",1
"
",1
"        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"        args.maxlen_out,
",1
"        # Unsupported dimension
        with pytest.raises(RuntimeError):
            y = np.random.randint(-100, 100, [16, 1, 1], dtype=np.int16)
            writer[""ghi""] = 16, y
    target = SoundScpReader(tmp_path / ""wav.scp"", normalize=False, dtype=np.int16)
",1
"    print(""Usage: python data_prep.py [an4_root] [sph2pipe]"")
    sys.exit(1)
an4_root = sys.argv[1]
",1
"            if args.context_residual:
",1
"        if isinstance(loss, tuple):
            # chainer return several values as tuple
            loss[0].backward()  # trainable
",1
"            bias=False,
        )
        self.gvec = torch.nn.Linear(att_dim, 1)
        self.dunits = dunits
        self.eunits = eunits
",1
"                self.enc = torch.nn.ModuleList(
                    [
                        VGG2L(in_channel),
                        RNNP(
                            get_vgg2l_odim(idim, in_channel=in_channel),
",1
"            # The ratio is given on runtime randomly
            self.utt2ratio = None

    def __repr__(self):
        if self.utt2ratio is None:
",1
"        type=int,
        metavar=""ML"",
        help=""When --batch-count=seq, batch size is reduced ""
        ""if the input sequence length > ML."",
    )
",1
"        >>> x = torch.randn(2, 10)
        >>> model(x)
",1
"                num_cache_chunks=num_cache_chunks,
            )
        elif iterator_type == ""none"":
            # This branch is used for --dry_run mode
",1
"def test_Encoder_forward_backward(input_layer, positionwise_layer_type):
    encoder = TransformerEncoder(
",1
"                )[:beam]

",1
"                ]
",1
"                 [0, 0, 0, 0]],
                [[0, 0, 0, 1],
                 [0, 0, 0, 1]],
                [[0, 0, 1, 1],
                 [0, 0, 1, 1]]], dtype=torch.uint8)
",1
"        with torch.no_grad():
            for batch in it:
                if isinstance(batch, tuple):
",1
"            batches = {k: v[bs:] for k, v in batches.items()}
        return id_list, batches
from abc import ABC
from abc import abstractmethod

",1
"            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"        """"""Compute encoded features.
",1
"#!/usr/bin/env python

# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
# Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"        )
",1
"        )
        group.add_argument(
            ""--adim"",
            default=320,
",1
"        # test decodable
        with chainer.no_backprop_mode():
",1
"        model = load_trained_modules(idim_list[0], odim, args)
    else:
        model_class = dynamic_import(args.model_module)
",1
"    for x in sys.stdin:
        # extract text parts
",1
"                        RNN(
                            get_vgg2l_odim(idim, in_channel=in_channel),
                            elayers,
                            eunits,
                            eprojs,
",1
"            {},
        ),
        ({""dec-embed-dim"": 16}, {}),
        ({""dec-embed-dim"": 16, ""dropout-rate-embed-decoder"": 0.1}, {}),
        ({""dunits"": 16}, {""beam_size"": 1}),
",1
"
",1
"                # update wordlm state and log-prob vector
                wlm_state, z_wlm = self.wordlm(wlm_state, w)
                wlm_logprobs = F.log_softmax(z_wlm).data
                new_node = self.lexroot  # move to the tree root
                clm_logprob = 0.0
",1
"            idim=odim,
            attention_dim=adim,
            linear_units=3,
",1
"        # NOTE consider zero padding when compute w.
        if self.mask is None:
            self.mask = to_device(self, make_pad_mask(enc_hs_len))
",1
"        )
        self.n_fft = n_fft

    def output_size(self) -> int:
",1
"            r[t, 0] = self.xp.logaddexp(r[t - 1, 0], log_phi[t - 1]) + xs[t]
",1
"            id = segments[0]  # ex. E10001
",1
"        help=""Number of epochs to wait ""
",1
"        ""elapsed_time"",
    ]
    if args.opt == ""adadelta"":
        trainer.extend(
",1
"
            clean_content = vietnamese_cleaner(content)
            lines[id] = clean_content

        for id in sorted(lines.keys()):
",1
"            data,
",1
"                self._loaders[filepath] = loader
",1
"                    ctc_type=args.ctc_type,
                    reduce=reduce,
                )
                ctcs_list.append(ctc)
",1
"        n_e = self.self_attn(n_e, mask=yy_mask, batch=batch)
        e = e + F.dropout(n_e, self.dropout)

",1
"                 [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)
        >>> make_pad_mask(lengths, xs, 2)
        tensor([[[0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1],
",1
"    ) -> Tuple[torch.Tensor, torch.Tensor]:
",1
"        :return: N-best decoding results
        :rtype: list
        """"""
        prev = self.training
        self.eval()
",1
"        [""o"", ""iuiuiuiuiuiuiuiuo"", ""iuiuiuiuiuiuiuiuo""],
        [""o"", ""o"", ""ieieieieieieieieo""],
    ]

    # ctc_weight: 0.0 (attention), 0.5 (hybrid CTC/attention), 1.0 (CTC)
",1
"        # This format affects only saving
        self.format = format

    def __repr__(self):
        return '<SoundHDF5 file ""{}"" (mode {}, format {}, type {})>'.format(
",1
"
# NOTE: you need this func to generate our sphinx doc
",1
"        # below means the last number becomes eos/sos ID
        # note that sos/eos IDs are identical
        self.sos = odim - 1
        self.eos = odim - 1
        self.pad = 0
",1
"from tacotron_cleaner.cleaners import uppercase

E_lang_tag = ""en_US""
",1
"  } else {
    throw std::logic_error(""Communicator type "" + std::to_string(communicator_type_) +
",2
"            all_col_types, col_shapes, col_max_sizes = util._get_col_info(df)
",2
"    def wrapped_func():
        return func(*args, **kwargs)

",2
"
    if (response_cache_.capacity() > 0) {
      stall_inspector_.InvalidateStalledCachedTensors(cache_coordinator);
    }
",2
"#include ""tensor_util.h""

",2
"            for i in range(10):
                hvd.allgather_async(tensor, name='duplicate_name')
",2
"        class Net(torch.nn.Module):
",2
"
        # apply element-wise normalization
        return torch.batch_norm_elemt(input, weight, bias, mean, invstd, eps)

    @staticmethod
",2
"
import numbers
",2
"            self.assertTrue(shape_tests_passed,
                            ""hvd.allgather produces incorrect gathered tensor"")

",2
"        assert np.array_equal(col1_prepared, np.array([[1., 2., 3.]]))

        col3 = [np.array([3., 0., 2., 5., 0., 0.2, 0.5, 0, 0]),
                np.array([4., 0., 2., 5., 6., 0.2, 0.5, 0.6, 0])]
",2
"        for dtype in valid_dtypes:
",2
"        util._training_cache.get_dataset = mock.Mock(side_effect=util._training_cache.get_dataset)

",2
"  rank_strings_ = std::vector<std::string>(horovod_size);
  for (unsigned int i = 0; i < horovod_size; i++) {
    rank_strings_[i] = std::to_string(i);
  }
",2
"        self._wire = Wire(key)
",2
"    Tests for .buildkite directory
    """"""

    def __init__(self, *args, **kwargs):
",2
"            // Skip response and look ahead for more to fuse.
            skipped_responses.push_back(std::move(new_response));
            responses.pop_front();
",2
"            super(KerasModel, self)._set(_keras_pkg_type=pkg_type)

",2
"AdasumGpuAllreduceOp::AdasumGpuAllreduceOp(MPIContext* mpi_context,
                                           NCCLContext* nccl_context,
                                           GPUContext* gpu_context,
",2
"        if EstimatorParams.loss.name in kwargs and TorchEstimator.loss_constructors.name in kwargs:
            raise ValueError(""only one of loss_constructors and loss parameters can be specified."")

        self.setParams(**kwargs)
",2
"        raise ValueError('Gloo support is required to use elastic training, but has not been built.  Ensure CMake is '
                         'installed and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.')

",2
"        if 'CUDA_VISIBLE_DEVICES' in full_env:
            # In TensorFlow 2.0, we set this before calling `run` in order to prevent TensorFlow
            # from allocating memory on the GPU outside the training process.  Once we submit the
            # function for execution, we want to ensure that TensorFLow has visibility into GPUs on
            # the device so we can use them for training, which is why we need to unset this.
",2
"                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"
  void Finalize();

  std::shared_ptr<gloo::Context> GetGlooContext(Communicator communicator);
",2
"bool horovod_mpi_enabled();

// C interface to return flag indicating whether Horovod was compiled with MPI support.
bool horovod_mpi_built();

",2
"    input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])

",2
"        .join(elapsed, ['Date', 'Store']) \
        .select(test_df['*'], *[prefix + col for prefix in ['Before', 'After'] for col in elapsed_cols])

",2
"        for intf, intf_addresses in addresses.items():
            for ip, port in intf_addresses:
                if ip == target_ip:
",2
"def set_env_from_args(env, args):
    def identity(value):
        return 1 if value else 0

",2
"  auto obj = flatbuffers::GetRoot<wire::Request>(input);
  Request_ParseFromWire(request, obj);
}

",2
"    timeline.ActivityEndAll(entries);
  } else {
    buffer_data = (void*)first_entry.output->data();
    std::memcpy(buffer_data, first_entry.tensor->data(),
                (size_t)first_entry.tensor->size());
",2
"    throw std::logic_error(""No operation found for response type provided"");
  }
}

",2
"                                                     int divisor, char* name,
                                                     int reduce_op);

int horovod_torch_allgather_async_torch_ByteTensor(THByteTensor* tensor,
",2
"              (size_t)e.tensor->size());
}
",2
"        'epoch': state.epoch,
        'batch': state.batch,
        'commits': state.commits,
        'hostname': hostname,
        'start_rank': start_rank,
",2
"      LOG(DEBUG) << ""Exception: "" << e.what();
    }

    // sleep for 500ms before another try.
",2
"

# Spark will fail to initialize correctly locally on Mac OS without this
",2
"import os
import unittest
import warnings

from elastic_common import BaseElasticTests
",2
"  void Initialize(const std::string& gloo_iface);
",2
"                'Your TensorFlow version %s is outdated.  '
                'Horovod requires tensorflow>=1.1.0' % tf.__version__)
",2
"Status EnqueueJoin(std::shared_ptr<OpContext> context,
",2
"# limitations under the License.
# ==============================================================================

import os
import threading
",2
"
        tf.train.LoggingTensorHook(tensors={'step': global_step, 'loss': loss},
                                   every_n_iter=10),
    ]

",2
"            tf.keras.layers.Dense(2, activation='softmax')
        ])
        model2.build((2, 2))
",2
"            if _fp16_supported:
                dtypes += [torch.cuda.HalfTensor]
        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
            # Support tests up to MPI Size of 35
",2
"                            # Save model after every epoch
",2
"# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
",2
"                 shuffle_buffer_size=None,
                 partitions_per_process=None,
",2
"
        # This test does not apply if there is only one worker.
        if size == 1:
",2
"  std::vector<std::pair<double, double>> bounds_;
  double xi_;

",2
"        mean, invstd = torch.batch_norm_stats(input, eps)
",2
"      offset += global_state_->controller->GetLocalSizeAtCrossRank(i);
",2
"# ==============================================================================

",2
"    :param env: Environment dictionary to use for running MPI.  Can be None.
    :param stdout: Stdout of the mpi process.
                   Only used when settings.run_func_mode is True.
",2
"
if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
",2
"                with util.prepare_data(backend.num_processes(),
                                       store,
",2
"    return ::torch::kChar;
  case common::HOROVOD_INT16:
    return ::torch::kShort;
  case common::HOROVOD_INT32:
    return ::torch::kInt;
",2
"                           '--no-stall-check'):
            args = parse_args()
",2
"            stdout = MultiFile([sys.stdout, stdout_file])
            stderr = MultiFile([sys.stderr, stderr_file])

        try:
",2
"
from horovod.torch.compression import Compression

# import basic methods
",2
"            if MPI._sizeof(MPI.Comm) == ctypes.sizeof(ctypes.c_int):
                MPI_Comm = ctypes.c_int
            else:
                MPI_Comm = ctypes.c_void_p
",2
"        for option_key, option_value in group.items():
            if option_key == 'params':
                continue

            # Options like the learning rate are scalar, and need to be wrapped in tensors
",2
"        loss.backward()
        opt.step()

    def test_duplicate_names(self):
        """"""Test that passing duplicate names to optimizer will fail.""""""
",2
"
",2
"  void record_hit(uint32_t bit);
",2
"
",2
"        name: A name of the allgather operation.

",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")

",2
"  // Do allreduce.
  auto nccl_result = ncclAllReduce(fused_input_data, buffer_data,
                                   (size_t) num_elements,
",2
"                                          compression, sparse_as_dense)
    else:
        raise ValueError('Provided optimizer doesn\'t inherit from either legacy '
                         'TensorFlow or Keras optimizer: %s' % optimizer)

",2
"                    .coalesce(val_partitions) \
                    .write \
                    .mode('overwrite') \
                    .parquet(val_data_path)

",2
"    # Horovod: print output only on first rank.
    if hvd.rank() == 0:
",2
"    def _on_workers_recorded(self):
        logging.info('all {} workers recorded'.format(self.size()))

        # Check for success state, if any process succeeded, shutdown all other processes
        if self.count(SUCCESS) > 0:
",2
"  if (horovod_rank() == root_rank) {
    if (tensor.data_ptr() != output.data_ptr()) {
",2
"
void AllreduceOp::MemcpyEntryInFusionBuffer(
    const std::vector<TensorTableEntry>& entries, const TensorTableEntry& e,
",2
"            tensor = torch.FloatTensor(*dims)

        try:
            hvd.allreduce(tensor)
            assert False, 'hvd.allreduce did not throw error'
",2
"    x_test = np.reshape(x_test, (-1, 784)) / 255.0

    # Build model...
    with tf.name_scope('input'):
",2
"        padding=""same"",
",2
"                tmp.write('rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\n'.format(
",2
"  template <DataType DT, DeviceType Dev, class T>
  static const TensorShape GetShape(T* tensor);
  template <DataType DT, DeviceType Dev, class T>
",2
"  assert(synced_);
  return should_shut_down_;
}

bool CacheCoordinator::uncached_in_queue() const {
",2
"                    loss=self.getLoss(),
                    loss_constructors=self.getLossConstructors())


class TorchModel(HorovodModel, TorchEstimatorParamsWritable, TorchEstimatorParamsReadable):
",2
"import time

from horovod.run.common.util import safe_shell_exec

",2
"  return handle;
}
",2
"            # learning rate graphs look better.
",2
"def clear_training_cache():
    _training_cache.clear()

",2
"        """"""
        if comm is None:
            comm = []

        atexit.register(self.shutdown)
",2
"    import horovod.tensorflow.keras as hvd

",2
"    def test_horovod_broadcast_error(self):
        """"""Test that the broadcast returns an error if any dimension besides
        the first is different among the tensors being broadcasted.""""""
",2
"
",2
"}

void ParameterManager::SetParams(const Params& newParams) {
  hierarchical_allreduce_.SetValue(newParams.hierarchical_allreduce, true);
",2
"    if ""dev"" in version_str:
",2
"// CategoricalParameter
template <class T>
ParameterManager::CategoricalParameter<T>::CategoricalParameter(std::vector<T> values) :
    TunableParameter<T>(values[0]),
",2
"}

",2
"#endif
}

",2
"from distutils.version import LooseVersion

import tensorflow as tf

",2
"    int size = GetSizeWithComm(communicator);

    std::vector<std::vector<int>> nghrCountVec;
",2
"    return -1;
",2
"loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()
metric = mx.metric.Accuracy()

",2
"                opt_base64_encoded = codec.loads_base64(param_val)
                return keras_utils.deserialize_optimizer(opt_base64_encoded)
            else:
",2
"
",2
"        # Cache that provides the store
",2
"    """"""
    def __init__(self, *args, **kwargs):
        super(MPITests, self).__init__(*args, **kwargs)
",2
"                                                                tensor) {      \
    THTensor##_free(tensor);                                                   \
",2
"  int64_t shared_buffer_size = 0;

",2
"            exit_code = safe_shell_exec.execute(""{cmd} -n {node}"".format(
                cmd=LSFUtils._CSM_NODE_QUERY,
                node=LSFUtils._csm_allocation_info[""compute_nodes""][0]),
                stdout=output, stderr=output)
            if exit_code != 0:
",2
"            else:
                bcast_op = hvd.broadcast_global_variables(self.root_rank)
                self.backend.get_session().run(bcast_op)
",2
"private:
  ResponseType response_type_ = ResponseType::ALLREDUCE;
  std::vector<std::string> tensor_names_;
",2
"import horovod.tensorflow as hvd
from tensorflow.keras import applications

# Benchmark settings
",2
"
        if named_parameters is not None:
            named_parameters = list(named_parameters)
        else:
            named_parameters = [('allreduce.noname.%s' % i, v)
",2
"    server_ip = driver.addresses()[iface][0][0]
    command = (sys.executable,
               '-m', 'horovod.spark.task.gloo_exec_fn',
               codec.dumps_base64(driver.addresses()),
               codec.dumps_base64(settings))
",2
"
class WaitForCommandExitCodeResponse(object):
    def __init__(self, exit_code):
",2
"
    _validate_arg_nonnegative(args, 'stall_check_warning_time_seconds')
    _validate_arg_nonnegative(args, 'stall_check_shutdown_time_seconds')
    _validate_arg_nonnegative(args, 'num_nccl_streams')
",2
"inline const char * const *EnumNamesDataType() {
  static const char * const names[] = {
    ""HOROVOD_UINT8"",
    ""HOROVOD_INT8"",
    ""HOROVOD_UINT16"",
",2
"// This implementation is based on the blog by Martin Krasser on Gaussian Processes, along with
// scikit-learn, and is an adaptation of the Python + NumPy code to C++.
//
// See: http://krasserm.github.io/2018/03/19/gaussian-processes
",2
"#define _LOG(severity) _HVD_LOG_##severity

",2
"    # parse version
    version = parse_version(torch.__version__)
    if version is None:
",2
"
        return local_run_path
",2
"  case HOROVOD_UINT8:
    return new GlooAlgorithms<u_int8_t>(gloo_context);
  case HOROVOD_INT8:
    return new GlooAlgorithms<int8_t>(gloo_context);
  case HOROVOD_UINT16:
",2
"        super(ElasticSettings, self).__init__(elastic=True, **kwargs)
        self.discovery = discovery
        self.min_np = min_np
",2
"
  CategoricalParameter<bool> hierarchical_allreduce_;
  CategoricalParameter<bool> hierarchical_allgather_;
",2
"    Patches the _get_mpi_implementation_flags method used by horovod.run.mpi_run to retrieve
",2
"        different ranks.
    """"""
    if isinstance(optimizer, _LegacyOptimizer):
",2
"  return reason_;
}

",2
"
    # Split into training & validation.
",2
"            if cnt >= 10:
                for key, param in params.items():
                    hvd.allreduce_(param.list_data()[0])
",2
"    host_list = (x.split(':') for x in settings.hosts.split(','))
",2
"    :type remote_host_names: set
    :param _run_command: command to execute
    :type _run_command: string
    :return:
",2
"        sz = to_numpy(broadcast(sz, root_rank, name + '.sz'))
",2
"  if (gpu_op_context_.host_buffer != nullptr) {
    free(gpu_op_context_.host_buffer);
",2
"    def deserialize_optimizer(*args, **kwargs):
        return optimizer.deserialize_bare_keras_optimizer(*args, **kwargs)
",2
"# https://mxnet.incubator.apache.org/tutorials/basic/data.html?highlight=imagerecorditer
def get_data_rec(rec_train, rec_train_idx, rec_val, rec_val_idx, batch_size,
                 data_nthreads):
    rec_train = os.path.expanduser(rec_train)
    rec_train_idx = os.path.expanduser(rec_train_idx)
",2
"        rank = hvd.rank()
        size = hvd.size()

        # This test does not apply if there is only one worker.
        if size == 1:
",2
"parser.add_argument('--data-nthreads', type=int, default=2,
                    help='number of threads for data decoding (default: 2)')
parser.add_argument('--rec-train', type=str, default='',
                    help='the training data')
",2
"# limitations under the License.
# ==============================================================================

",2
"  DataType_HOROVOD_FLOAT64 = 8,
  DataType_HOROVOD_BOOL = 9,
",2
"                   std::shared_ptr<JoinOp> join_op,
                   std::vector<std::shared_ptr<AllreduceOp>> adasum_ops,
                   std::shared_ptr<ErrorOp> error_op);

  virtual ~OperationManager() = default;
",2
"      hvd_context, hvd_cpu_tensor, ready_event,
",2
"    That threat can be stopped by setting the optional stop event.
",2
"    data_iter.reset()
    metric = mx.metric.Accuracy()
    for _, batch in enumerate(data_iter):
",2
"        net.add(gluon.nn.Dense(10))
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
# Modifications copyright Microsoft
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"# Horovod: initialize Horovod.
hvd.init()

# Horovod: pin GPU to be used to process local rank (one GPU per process)
",2
"            # No-op for LocalStore since the `local_run_path` will be the same as the run path
            assert run_path == local_run_path
        return fn

",2
"        K.set_value(model.optimizer.lr, scaled_lr)

        # Horovod: print summary logs on the first worker.
        verbose = 2 if hvd.rank() == 0 else 0
",2
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
# Modifications copyright (C) 2017 Uber Technologies, Inc.
#
",2
"            state.epoch = 11
",2
"

# Step 1: Download the data.
",2
"from horovod.tensorflow.elastic import TensorFlowKerasState

",2
"Status Status::UnknownError(std::string message) {
  return Status(StatusType::UNKNOWN_ERROR, message);
}
",2
"int64_t TensorUtil::GetSize(NDArray* tensor) {
  int64_t element_size = 0;
",2
"    for (size_t ec = 0; ec < entries.size(); ++ec) {
      delete[] entry_component_sizes[ec];
",2
"            tensor_size + new_tensor_size <= TensorFusionThresholdBytes()) {
          // These tensors will fuse together well.
          tensor_size += new_tensor_size;
",2
"
void TimelineWriter::Initialize(std::string file_name) {
",2
"                threshold = 1e-4
            elif size < 15:
                threshold = 5e-4
            else:
",2
"#ifndef HOROVOD_OPERATION_MANAGER_H
#define HOROVOD_OPERATION_MANAGER_H

#include ""collective_operations.h""
#include ""../parameter_manager.h""
",2
"                             env={})
        return self._create_model(handle, run_id, metadata)

    def _load_checkpoint(self, run_id):
        store = self.getStore()
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"    std::this_thread::sleep_for(std::chrono::milliseconds(1));
  }
  auto status = handle_manager.ReleaseHandle(handle);
  ThrowIfError(*status);
}
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"#include <iostream>
",2
"        # Make sure it's an asynchronous operation.
        assert is_hvd_poll_false_once, 'hvd.poll() always returns True, not an async op?'

        for dtype, multiplied, handle in tests:
            summed = hvd.synchronize(handle)
",2
"  // Update a vector to a linear combination of itself and another vector.
  template <typename T>
  void ScaledAdd(int n, double acoeff, T* __restrict__ a, double bcoeff,
",2
"        q = np.dot(a,r.T)
",2
"        ckpt_file = io.BytesIO(store.read(last_ckpt_path))
        return torch.load(ckpt_file)

    def _create_model(self, run_results, run_id, metadata):
",2
"  if (horovod_global.shut_down) {
    return SHUT_DOWN_ERROR;
  }
",2
"        bio = io.BytesIO(model_bytes)
        with h5py.File(bio) as f:
",2
"    response.set_response_type(Response::ADASUM);
    for (auto dim : tensor_sizes) {
",2
"        self._args = args
        self._kwargs = kwargs
        self._ranks_to_indices = None
",2
"
// Return size of tensor in bytes
",2
"            with tf.device(""/cpu:0""):
                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"                torch.tensor([
                    [r, r + 1],
                    [r * 2, r * 2 + 1],
                    [r * 3, r * 3 + 1],
",2
"    np.random.seed(1 + hvd.rank())
    torch.manual_seed(1234)

    prev_zero = False

",2
"    """"""Wait for func to return True until timeout.""""""
",2
"// Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
// Modifications copyright Microsoft
//
",2
"                os._exit(1)
",2
"        average: A flag indicating whether to compute average or summation,
",2
"      if (state.joined_size > 0) {
        for (auto& table_iter : message_table_) {
          int count = (int)table_iter.second.size();
",2
"
# adjust learning rate on reset
def on_state_reset():
    for param_group in optimizer.param_groups:
",2
"    if len(sys.argv) != 5:
        print('Usage: {} <index> <num_hosts> <driver_addresses> <settings>'.format(sys.argv[0]))
        sys.exit(1)

",2
"inline const char *EnumNameRequestType(RequestType e) {
  if (e < RequestType_ALLREDUCE || e > RequestType_JOIN) return """";
  const size_t index = static_cast<size_t>(e);
",2
"    """"""
    rank = 0
    alloc_list = []

    # key: local_rank; value: cross_size for this local_rank
",2
"import argparse
",2
"#
",2
"    case HOROVOD_FLOAT64:
      return ncclFloat64;
    default:
",2
"  if (!invalid_in_queue_) {
    bitvector_[0] |= (1ull << StatusBit::INVALID_IN_QUEUE);
  }

  // Before communication, remove any invalid bits from cache hit set.
",2
"        shuffle_buffer_size = 10
        rows_in_row_group = 100
",2
"  std::unordered_map<std::string, std::vector<char>> map_;
};

} // namespace common
} // namespace horovod
",2
"// Set affinity function
void server_affinity_set(int affinity);
",2
"}

void ParameterManager::LogBestParameters() {
",2
"    def _do_allreduce(self, index, grad):
        if size() == 1: return

",2
"
#include <atomic>
#include <map>
#include <queue>
",2
"    elapsed = add_elapsed(train_df.select('Date', 'Store', *elapsed_cols)
                                  .unionAll(test_df.select('Date', 'Store', *elapsed_cols)),
",2
"
data, count, dictionary, reverse_dictionary = build_dataset(vocabulary,
                                                            vocabulary_size)
",2
"            return v.numpy()

    if rank() == root_rank:
        b = io.BytesIO()
        cloudpickle.dump(obj, b)
",2
"    log('Running warmup...')
    benchmark_step(first_batch=True)
",2
"    :rtype:
    """"""

",2
"
  private:
    void CompleteTuning();
    virtual void OnTune(double score, T& value) = 0;
",2
"                    setattr(self, name, attr)

        return RemoteStore()

    def _remote_attrs(self, run_id, dataset_idx):
",2
"        # command terminated, make sure this task service does not shutdown too quickly after
",2
"from horovod.torch.functions import broadcast_object, broadcast_optimizer_state, broadcast_parameters


",2
"                for r in rows:
                    if last_store != r.Store:
                        last_store = r.Store
",2
"from distutils.version import LooseVersion
if LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):
    from tensorflow import keras
    from tensorflow.python.keras import backend as K
",2
"        print('Usage: %s <service addresses> <settings> <host hash> '
              '<command...>' % sys.argv[0])
",2
"
  Status Execute(std::vector<TensorTableEntry>& entries, const Response& response) override;
",2
"    return fx;
  };
",2
"        return self._set(loss_constructors=value)

",2
"
def check_macro(macros, key):
    return any(k == key and v for k, v in macros)


",2
"
  // Compute cross-node allgather displacements and recvcounts for
",2
"    def getGradientCompression(self):
        return self.getOrDefault(self.gradient_compression)

    def setCompressSparseCols(self, value):
        return self._set(compress_sparse_cols=value)
",2
"
",2
"        # reachable within the cluster.
        next_task_index = (index + 1) % num_hosts
        next_task_addresses = driver.all_task_addresses(next_task_index)
",2
"}

Status Status::OK() {
  return Status();
",2
"    def getFeatureColumns(self):
",2
"    The concatenation is done on the first dimension, so the input tensors on the
    different processes must have the same rank and shape, except for the first
    dimension, which is allowed to be different.
",2
"        resp = urlopen(req)
        # TODO: remove base64 encoding because base64 is not efficient
        return codec.loads_base64(resp.read())
",2
"

    def add_elapsed(df, cols):
",2
"                assert not store.exists(ckpt_path)
                keras_estimator._load_model_from_checkpoint.assert_not_called()
                keras_model = keras_estimator.fit(df)

",2
"            print('INFO: Cannot find CMake, will skip compiling Horovod with Gloo.')
            have_cmake = False

",2
"  int cross_rank = GetIntEnvOrDefault(HOROVOD_CROSS_RANK, 0);
  int cross_size = GetIntEnvOrDefault(HOROVOD_CROSS_SIZE, 1);

  auto rendezvous_addr_env = std::getenv(HOROVOD_GLOO_RENDEZVOUS_ADDR);
  auto rendezvous_port = GetIntEnvOrDefault(HOROVOD_GLOO_RENDEZVOUS_PORT, -1);
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"def run_benchmark(state):
",2
"                         loss=None,
                         loss_constructors=None,
                         input_shapes=None)
",2
"    NullType, StructField, StructType

import horovod.spark
",2
"log('Model: %s' % args.model)
",2
"
#include <sstream>
#include <cassert>

",2
"            deserialized = {}
",2
"from horovod.spark.common.estimator import HorovodEstimator, HorovodModel
from horovod.spark.common.params import EstimatorParams
",2
"    log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))
    img_secs.append(img_sec)

# Results
",2
"        model1_weights = model1.state_dict().values()
        model2_weights = model2.state_dict().values()
",2
"  }
}

void MPIContextManager::EnvInitialize(int mpi_threads_required) {
",2
"                model.save(fname)

",2
"    timeline.ActivityEndAll(entries);
  }
",2
"
        for idx, col, output_shape in zip(range(label_count), label_columns, output_shapes):
            col_size = metadata[col]['shape']
            if col_size is None:
                # When training directly on Parquet, we do not compute shape metadata
",2
"        raise Exception('Could not find an active SparkContext, are you '
",2
"# if TORCH_VERSION >= 1001000000
  return tensor_.element_size() * tensor_.numel();
#else
",2
"        ['worker-0','worker-1']
        ['10.11.11.11', '10.11.11.12']
    :type host_addresses: list(strings)
",2
"  };
",2
"state.register_reset_callbacks([on_state_reset])
run_benchmark(state)

# Results
",2
"                                inputs, labels, sample_weights = prepare_batch(row)
",2
"    tensor_queue_.PushMessagesToQueue(messages_to_replace);
  }

  if (!message_queue_tmp.empty()) {
    LOG(TRACE, rank_) << ""Sent "" << message_queue_tmp.size()
",2
"    Args:
        settings: Settings for running jsrun.
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"                    grad_out = self.evaluate(grad)

            expected = np.ones([5] * dim) * size
            err = np.linalg.norm(expected - grad_out)
",2
"        return [mx.io.DataDesc('data', self.data.shape, self.dtype)]
",2
"
",2
"        hdfs_root = 'hdfs:///user/test/output'
        store = HDFSStore(hdfs_root)
        assert store.path_prefix() == 'hdfs://', hdfs_root
",2
"            print('Extension {ext_base_name} {flag} {fn_desc}.'.format(
                ext_base_name=ext_base_name, flag=('was' if result else 'was NOT'),
                fn_desc=fn_desc))
",2
"    def decompress(tensor, ctx):
        """"""Decompress the tensor with the given context.""""""
        pass


",2
"class ResponseList {
public:
  const std::vector<Response>& responses() const;

  void set_responses(const std::vector<Response>& value);
",2
"    Computes a hash that represents this host, a unit of processing power that shares memory.

    The hash contains the part of the hostname, e.g. `host` for hostname `host.example.com`,
    plus a hash derived from the full hostname and further information about this machine.

",2
"        if os.path.isdir(path_dir):
            for bin_file in sorted(os.listdir(path_dir)):
",2
"  root_rank_ = root_rank;
  if (rank_ == root_rank) {
    LOG(INFO) << ""Autotuner: Tunable params [hierarchical_allreduce,hierarchical_allgather,cache_enabled,cycle_time_ms,tensor_fusion_threshold] score"";
  }
",2
"import numpy as np
import timeit

import tensorflow as tf
",2
"        label_columns = ['y1', 'y_embedding']

        schema = StructType([StructField('x1', DoubleType()),
                             StructField('x2', IntegerType()),
                             StructField('features', VectorUDT()),
",2
"  auto& first_entry = entries[0];
",2
"            tensor = tensor.astype('float32')

        try:
",2
"

def get_mx_include_dirs():
    import mxnet as mx
",2
"        fn = mock.Mock()
        with pytest.raises(ValueError, match=""^args must be a tuple, not <(class|type) 'int'>, ""
                                             ""for a single argument use \\(arg,\\)$""):
",2
"  gpu_op_context_.InitGPUQueue(entries, response);
",2
"        input_shapes = [[-1, 1], [-1, 2, 5]]
        output_shapes = [[-1, 4], [-1, 2, 2]]
        output_names = ['label1', 'label2']
",2
"  auto event_category = Response::ResponseType_Name(response_type);
",2
"                                              sample_weight_col=sample_weight_col)

",2
"        if args.cuda:
            data, target = data.cuda(), target.cuda()
        output = model(data)
        # sum up batch loss
        test_loss += F.nll_loss(output, target, size_average=False).item()
",2
"                                 transforms.RandomResizedCrop(224),
                                 transforms.RandomHorizontalFlip(),
",2
"
#include ""nccl_operations.h""

namespace horovod {
namespace common {
",2
"                    help='number of warm-up batches that don\'t count towards benchmark')
parser.add_argument('--num-batches-per-iter', type=int, default=10,
                    help='number of batches per benchmark iteration')
",2
"            if sample_weight_col:
                new_row[sample_weight_col] = getattr(row, sample_weight_col)
",2
"                output = model(data_batch)
                train_accuracy.update(accuracy(output, target_batch))
                loss = F.cross_entropy(output, target_batch)
",2
"            next_task_addresses = req.all_task_addresses
            # We request interface matching to weed out all the NAT'ed interfaces.
",2
"} // namespace horovod# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"            logging.error(
",2
"           verifier.VerifyVectorOfStrings(tensor_names()) &&
           VerifyOffset(verifier, VT_ERROR_MESSAGE) &&
",2
"import torch.nn as nn
",2
"        super(SparkTorchTests, self).__init__(*args, **kwargs)
        warnings.simplefilter('module')

    def test_fit_model(self):
",2
"// limitations under the License.
// =============================================================================

#include ""common.h""
#include ""logging.h""
",2
"    def host_assignments(self):
",2
"    def sync_fn(self, run_id):
        class SyncState(object):
            def __init__(self):
                self.fs = None
",2
"  auto horovod_hierarchical_allgather =
      std::getenv(HOROVOD_HIERARCHICAL_ALLGATHER);
  state.parameter_manager.SetHierarchicalAllgather(false);
  if (horovod_hierarchical_allgather != nullptr) {
",2
" *       provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the names of its contributors may be used
",2
"      } else {
        recv_buffer = &grad_buffer[-nghrCount];
      }
      this->PointToPointSendRecv(grad_buffer, myCount * per_element_size,
                                 recv_buffer, nghrCount * per_element_size,
",2
"
            return model
",2
"
# Horovod: adjust learning rate based on number of GPUs.
",2
"        warnings.simplefilter('module')

    def test_gloo_built(self):
        """"""Test that Gloo has been built if env is set.""""""
        gloo_rank = int(os.getenv('HOROVOD_RANK', -1))
",2
"                                   std::vector<std::shared_ptr<AllreduceOp>> adasum_ops,
                                   std::shared_ptr<ErrorOp> error_op)
    : param_manager_(param_manager),
      allreduce_ops_(std::move(allreduce_ops)),
      allgather_ops_(std::move(allgather_ops)),
",2
"        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)
        driver.wait_for_available_slots(min_np=2)

        rank_results = {}

",2
"                serialized_model, lambda x: hvd.load_model(x))

        # Horovod: adjust learning rate based on number of processes.
",2
"
    def get_logs_subdir(self):
        """"""Returns the subdirectory name for the logs directory.""""""
",2
"  message.set_request_rank(horovod_global.controller->GetRank());
  message.set_tensor_name(name);
  message.set_tensor_type(tensor->dtype());
  message.set_device(device);
  
",2
"  // allgatherv
",2
"        assert len(rank_results) == 2
        for rank, (slot_info, updated_slot_info) in rank_results.items():
            assert updated_slot_info.size == 2, rank
            assert updated_slot_info.rank == slot_info.rank % 2, rank
",2
"                          mpi_context_->GetMPIDataType(horovod_datatype),
                          dst_src_rank, tag, communicator, MPI_STATUS_IGNORE);
",2
"           VerifyOffset(verifier, VT_REQUESTS) &&
           verifier.VerifyVector(requests()) &&
           verifier.VerifyVectorOfTables(requests()) &&
           VerifyField<uint8_t>(verifier, VT_SHUTDOWN) &&
",2
"                     Note: settings.num_proc and settings.hosts must not be None.
    :param nics: Interfaces to use by gloo.
    :param driver: The Spark driver service that tasks are connected to.
",2
"Status
",2
"# Unless required by applicable law or agreed to in writing, software
",2
"    if feature_columns is None:
        feature_columns = [col for col in df.columns if col not in set(label_columns)]
",2
"            self.skipTest(""MPI not enabled"")

        size = hvd.size()
        # TODO support testing with non-power 2 ranks
        if not is_power2(size):
",2
"verbose = 1 if hvd.rank() == 0 else 0

# Training data iterator.
train_gen = image.ImageDataGenerator(
    width_shift_range=0.33, height_shift_range=0.33, zoom_range=0.5, horizontal_flip=True,
",2
"                                    '>mpi-extra args go here< '
                                    'cmd arg1 arg2').format(mpi_flags=' '.join(mpi_flags))
                expected_env = {'env1': 'val1', 'env2': 'val2', 'PATH': os.environ.get('PATH')}
                execute.assert_called_once_with(expected_command, env=expected_env, stdout=stdout, stderr=stderr)

",2
"from horovod.spark.mpi_run import mpi_run
from horovod.run.runner import is_gloo_used, run_controller
from horovod.run.common.util import timeout, host_hash, secret
",2
"  // Get cross-node rank and size in case of hierarchical allreduce.
  MPI_Comm_rank(mpi_ctx_.cross_comm, &cross_rank_);
  MPI_Comm_size(mpi_ctx_.cross_comm, &cross_size_);

  // Construct a shorter local sizes vector with length cross size.
",2
"

def RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):
    # Estimator parameters
",2
"    def test_calculate_loss_without_sample_weight(self):
        calculate_loss = remote._calculate_loss_fn()

",2
"                else:
                    tensor = tf.ones([5] * dim) * rank
                if dtype == tf.bool:
                    tensor = tensor % 2
                if _executing_eagerly():
",2
"@_cache
def _make_broadcast_group_fn():
    if _executing_eagerly():
        # Eager mode will parallelize independent control flow
        def broadcast_group(variables, root_rank):
",2
"
  auto device = GetDeviceID(tensor);
",2
"        def as_tuple(v):
            return tuple(v) if len(v) > 1 else v[0]

        def prep(row):
            if sample_weight_col:
",2
"}

void StallInspector::SetPerformStallCheck(bool value) {
  perform_stall_check = value;
}
",2
"_import_symbols(locals())
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"            assert updated_slot_info.local_size == slot_info.local_size, rank
            assert updated_slot_info.local_rank == slot_info.local_rank, rank
            assert updated_slot_info.cross_size == 2, rank
",2
"    except RuntimeError as e:
        raise HorovodInternalError(e)
// Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
//
",2
"            raise ValueError('named_parameters should be a sequence of '
                             'tuples (name, parameter), usually produced by '
                             'model.named_parameters().')
",2
"  ErrorOp(HorovodGlobalState* global_state);

  virtual ~ErrorOp() = default;

  virtual Status Execute(std::vector<TensorTableEntry>& entries, const Response& response);
",2
"        super().__init__(num_features, eps, momentum, affine, track_running_stats)
",2
"    return device;
  }

  void SetDevice(int device) {
",2
"    throw std::logic_error(""Type "" + std::to_string(tensor->dtype()) +
",2
"                                                start_timeout=tmout,
                                                elastic_timeout=args.elastic_timeout,
",2
"    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using MPI.
    """"""
    def test_spark_run_with_non_zero_exit_with_mpi(self):
        expected = '^mpirun failed with exit code 1$'
        with mpi_implementation_flags():
",2
"            'Extension %s has not been built.  If this is not expected, reinstall '
            'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))

",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"
        return df.rdd.mapPartitions(predict).toDF()
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"  int32_t request_rank() const;

  void set_request_rank(int32_t value);

  RequestType request_type() const;
",2
"# limitations under the License.
# ==============================================================================

",2
"
    for col in label_columns:
        if col not in df.columns:
            raise ValueError('Label column {} does not exist in the DataFrame'.format(col))

",2
"
    # Keras automatically creates a cache directory in ~/.keras/datasets for
    # storing the downloaded MNIST data. This creates a race
",2
"
",2
"parser.add_argument('--local-checkpoint-file', default='checkpoint.h5',
                    help='model checkpoint on local filesystem (without file:// prefix)')

",2
"    if hvd.rank() == 0:
        print('\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\n'.format(
            test_loss, 100. * test_accuracy))

",2
"    # Input Tensor Shape: [batch_size, 28, 28, 32]
    # Output Tensor Shape: [batch_size, 14, 14, 32]
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

    # Convolutional Layer #2
",2
"
    def add_elapsed(df, cols):
        def add_elapsed_column(col, asc):
            def fn(rows):
                last_store, last_date = None, None
",2
"      }
    }

    return cudaEventCreateWithFlags(event, cudaEventBlockingSync | cudaEventDisableTiming);
",2
"  void Reset();

private:
",2
"# See the License for the specific language governing permissions and
",2
"
    def test_rsh_events(self):
        self.do_test_rsh_events(3)

",2
"  Status ExecuteError(std::vector<TensorTableEntry>& entries, const Response& response) const;
",2
"
#define TENSOR_UTIL_DEFINE_TYPE_H(HorovodType, DeviceType, THTensor)           \
",2
"    @mock.patch('horovod.run.gloo_run._get_min_start_hosts', return_value=1)
    def test_min_hosts_timeout(self, mock_get_min_start_hosts):
",2
"        super(UpdateBatchStateCallback, self).__init__(tf.keras.backend, state)
",2
"    validation_data_path = store.get_val_data_path(dataset_idx)

    if not store.exists(train_data_path):
        raise ValueError(""{} path does not exist in the store"".format(train_data_path))
",2
"
    if args.sample_rate:
        train_csv = train_csv.sample(withReplacement=False, fraction=args.sample_rate)
        test_csv = test_csv.sample(withReplacement=False, fraction=args.sample_rate)

",2
"    // for global removal from cache to trigger stall messaging.
    if (now - entry.second > stall_warning_time) {
      uint32_t cache_bit = response_cache_.peek_cache_bit(entry.first);
",2
"            expected = tensor * (i + 1) * size
            assert same(sum.asnumpy(), expected.asnumpy())

    def test_horovod_broadcast(self):
        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""
",2
"            torch_loader = importlib.util.find_spec(module_name)
        else:
            raise RuntimeError('Unsupported version of Python: {}'.format(platform.python_version()))

",2
"    }   
    delete[] entry_component_sizes;
",2
"MPI_GPUAllgather::MPI_GPUAllgather(MPIContext* mpi_context,
                                   GPUContext* gpu_context,
                                   HorovodGlobalState* global_state)
    : GPUAllgather(gpu_context, global_state),
      mpi_context_(mpi_context) {}
",2
"
        # if obj is a python 'type'
        if type(obj).__name__ == type.__name__:
            return obj.__name__
",2
"            mpi_show_args = mpi_show_args[1:]
        # strip off compiler call portion and always escape each arg
",2
"  void ErrorCheck(std::string op_name, ncclResult_t nccl_result, ncclComm_t& nccl_comm);

  void ShutDown();
};

",2
"#include ""ready_event.h""
",2
"                                    outputs, labels, loss_weights, loss_fns, sample_weights)
                                val_loss.update(loss)
                                update_metrics(metric_value_groups, outputs, labels)
                                print_metrics(batch_idx, val_loss, metric_value_groups, 'val')
                            return aggregate_metrics('val', epoch, val_loss, metric_value_groups)
",2
"            time=localtime,
            rank=str(rank),
            prefix=prefix,
",2
"        _HAS_AGGREGATE_GRAD = True

",2
"
class RunTests(unittest.TestCase):
    """"""
    Tests for horovod.run.
    """"""
",2
"                    help='the index of training data')
parser.add_argument('--rec-val', type=str, default='',
                    help='the validation data')
parser.add_argument('--rec-val-idx', type=str, default='',
                    help='the index of validation data')
",2
"
        def fn_add(output, label, reduction=None):
            losses = label+output
            if reduction == 'none':
",2
"        """"""Test that delta optimizer.""""""
",2
"    ""Horovod has not been initialized; use hvd.init()."");

",2
"                    SparseVector(2, {1: 1.0}),
                    SparseVector(2, {1: 1.0})
",2
"
            x = np.random.random((1, 3))
            y = np.random.random((1, 3, 3))
",2
"
import psutil
import queue
import socket
import socketserver
",2
"                                    '{binding_args} '
                                    '{mpi_flags}  '
                                    '-mca btl_tcp_if_include [^ ]+ -x NCCL_SOCKET_IFNAME=[^ ]+  '
                                    '{expected_env} '
                                    '{extra_mpi_args} '
",2
"  for (int i = 0; i < size_; ++i) {
    if (local_sizes[i] != local_size_) {
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"        def exec_command(slot_info, events):
            if slot_info.hostname == 'host-1':
                if slot_info.local_rank == 0:
                    return 1, time.time()
",2
"BROADCAST_H(torch_cuda_IntTensor, THCudaIntTensor)
",2
"        conf.setMaster(args.master)
    elif args.num_proc:
        conf.setMaster('local[{}]'.format(args.num_proc))
    spark = SparkSession.builder.config(conf=conf).getOrCreate()

",2
"  for (unsigned int i = 1; i < requests.size(); ++i) {
",2
"
        # Evaluate performance
",2
"    values_(values) {
  ResetState();
}

template <class T>
",2
"                -------
                out :
                    Shape (batch_size, seq_len, fea_dim)
",2
"                tensor = tensor % 2
",2
"def mpi_available():
",2
"  auto hvd_cpu_buffer = std::make_shared<MXTensor>(ops_param->cpu_tensor.get());
  auto hvd_context = std::make_shared<MXOpContext>(
",2
"    break;
  case mshadow::kInt8:
    element_size = kInt8Size;
    break;
",2
"
",2
"      (uint8_t*)buffer_data + buffer_len_per_rank * local_size;

  void* fused_input_data_remainder =
      (uint8_t*)fused_input_data + buffer_len_per_rank * local_size;

",2
"                .format(host=host_name,
                        ssh_port_arg=ssh_port_arg,
",2
"model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=opt,
              metrics=['accuracy'])
",2
"dataset = tf.data.Dataset.from_tensor_slices(
",2
"            np.testing.assert_allclose(w, np.ones_like(w))
        assert state.batch == 20
        assert state.epoch == 10

",2
"
#include ""gloo/common/error.h""

",2
"    train_df = train_df \
        .join(elapsed, ['Date', 'Store']) \
        .select(train_df['*'], *[prefix + col for prefix in ['Before', 'After'] for col in elapsed_cols])
",2
"                            metric_value_groups = construct_metric_value_holders(
                                metric_cls, metric_fn_groups, label_columns, hvd)

",2
"                var.assign(val)
        else:
",2
"
    :param driver_addresses: driver's addresses
    :param key: used for encryption of parameters passed across the hosts
    :param host_hash: host hash to connect to
",2
"                return 1, alloc_info.rank
            return _exec_command

",2
"    os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'


def _task_fn(index, driver_addresses, key, settings, use_gloo):
    # deserialized on Spark workers, settings do not contain the key, so it is given here explicitly
",2
"
  LOG(DEBUG) << ""Using "" << TypeName(controller)
            << "" to perform controller operations."";
  return controller;
}
",2
"def _make_subgraph(f):
    if hasattr(tf, 'function'):
        # TensorFlow 1.14.0+
",2
"

",2
"  timeline.ActivityStartAll(entries, MPI_ADASUM_ALLREDUCE);
  std::vector<int> tensor_counts;
",2
"  auto** entry_component_sizes = new int64_t*[entries.size()];
",2
"            for value in obj:
",2
"// C interface to return value of the ReduceOp::SUM enum field.
int horovod_reduce_op_sum();

// C interface to return value of the ReduceOp::ADASUM enum field.
int horovod_reduce_op_adasum();
",2
"

    def prepare_google_trend():
        # Extract week start date and state.
",2
"          response.add_tensor_name(std::move(new_response.tensor_names()[0]));
          response.add_tensor_size(new_response.tensor_sizes()[0]);
          responses.pop_front();
        } else {
",2
"  m.def(""horovod_torch_allgather_async_torch_cuda_FloatTensor"",
        &DoAllgatherCudaOnCPU);
  m.def(""horovod_torch_allgather_async_torch_cuda_DoubleTensor"",
        &DoAllgatherCudaOnCPU);
#endif
",2
"def validate(epoch):
",2
"
#define BROADCAST_CUDA_ON_CPU(torch_Tensor, HorovodType, THCTensor, THTensor)  \
  extern ""C"" int horovod_torch_broadcast_async_##torch_Tensor(                 \
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)
",2
"    return synchronize(handle)

",2
"    return NOT_INITIALIZED_ERROR;
  }
  return Status::OK();
}
",2
"
    The objects are serialized using cloudpickle. Serialized objects become
    the body of the message.

    Structure of the message is as follows:
",2
"                new_init = _append_broadcast_init(p, root_rank)
                p._init_impl = types.MethodType(new_init, p)
    else:
",2
"            ssh_successful_to_all_hosts = False
",2
"
class JoinOp : public HorovodOp {
public:
  JoinOp(HorovodGlobalState* global_state);

",2
"        with self.test_session(config=self.config) as sess:
",2
"                               cur_shard=hvd.rank(), shard_count=hvd.size(),
                               hdfs_driver=PETASTORM_HDFS_DRIVER) as train_reader:
            with make_batch_reader('%s/val_df.parquet' % args.data_dir, num_epochs=None,
",2
"
    def setFeatureColumns(self, value):
        return self._set(feature_columns=value)

",2
"            mean_all,
            invstd_all,
            running_mean,
",2
"    auto& e = entries[ec];
    // Every tensor participating in Allgather operation may have different
    // first dimension size, but the rest of dimensions are same for all
    // tensors.  Here we get shape of tensor sliced by first dimension.
    TensorShape single_slice_shape;
",2
"
        # Case 6: override paths, no prefix
        hdfs_root = '/user/prefix'
        store = HDFSStore(hdfs_root,
",2
"parser.add_argument('--num-batches-per-iter', type=int, default=10,
                    help='number of batches per benchmark iteration')
",2
"    case HOROVOD_INT8:
      static const std::string int8(""int8"");
      return int8;
    case HOROVOD_UINT16:
      static const std::string uint16(""uint16"");
",2
"
import tensorflow as tf

",2
"
#endif // HOROVOD_MPI_CONTEXT_H
// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"                            labels = [label.cuda() for label in labels]
                            if sample_weights:
                                sample_weights = sample_weights.cuda()
                        return inputs, labels, sample_weights
",2
"
    parser.add_argument('-p', '--ssh-port', action='store', dest='ssh_port',
",2
"        yield v
    while True:
        yield lst[-1]
",2
"            'Please specify correct DDL location with the HOROVOD_DDL_HOME '
            'environment variable or combination of HOROVOD_DDL_INCLUDE and '
            'HOROVOD_DDL_LIB environment variables.\n\n'
            'HOROVOD_DDL_HOME - path where DDL include and lib directories can be found\n'
",2
"                       gradtape._watch_accessed_variables)
        else:
            return cls(gradtape._tape, device_dense, device_sparse, compression,
                       sparse_as_dense, op, gradtape._persistent)
# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.
",2
"                },
            }

",2
"    if settings.run_func_mode:
        exit_code = safe_shell_exec.execute(jsrun_command, env=env, stdout=stdout, stderr=stderr)
        if exit_code != 0:
",2
"])
",2
"            raise Exception('Test Exception')

        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):
",2
"            grad_input = None

        # synchronizing of grad_weight / grad_bias is not needed as distributed
        # training would handle all reduce.
",2
"hvd.init()
num_workers = hvd.size()
",2
"               : CacheState::INVALID;
  } else {
    return CacheState::MISS;
  }
",2
"// See: http://krasserm.github.io/2018/03/21/bayesian-optimization
class BayesianOptimization {
public:
  // Performs binary optimization over the observed data by predicting the next sample to evaluate.
",2
"
",2
"        # Since all the addresses were vetted, use the first one.
        addr = list(self._addresses.values())[0][0]
        return self._send_one(addr, req)
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"        super(BasicTaskClient, self).__init__(service_name,
",2
"    buffer_data = (void*) first_entry.output->data();
    buffer_len = (size_t) first_entry.output->size();
",2
"    def test_calculate_shuffle_buffer_size_small_row_size(self):
        hvd_size = 4
        local_size = 2
",2
"
        key = (host, slot)
        with self._lock:
            if key in self._states:
                if state == FAILURE:
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"    VT_SHUTDOWN = 6
  };
  const flatbuffers::Vector<flatbuffers::Offset<Response>> *responses() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Response>> *>(VT_RESPONSES);
",2
"
from horovod.run.common.util import config_parser
from horovod.run.runner import parse_args, _run_elastic
",2
"Status ErrorOp::Execute(std::vector<TensorTableEntry>& entries, const Response& response) {
  return Status::PreconditionError(response.error_message());
}

",2
"        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
            with tf.device(""/cpu:0""):
                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"public:
  AllgatherOp(HorovodGlobalState* global_state);

  virtual ~AllgatherOp() = default;
",2
"            y = np.random.random((1, 3, 3))
            model.train_on_batch(x, y)

            with temppath() as fname:
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"# You may obtain a copy of the License at
",2
"indices = tf.random.uniform([batch_size], minval=0, maxval=2, dtype=tf.int64)
target = tf.one_hot(indices, 2)

",2
"  builder.Finish(obj);
",2
"// =============================================================================
",2
"        self._wait_cond.acquire()
        try:
",2
"
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"#endif
  }
}

",2
"        # We do not serialize backend and store. These params have to be regenerated for each
        # run of the pipeline
        return None
",2
"      c->set_output(0, c->input(0));
      return Status::OK();
    })
",2
"        tf.config.threading.set_intra_op_parallelism_threads(1)
    return fn
",2
"
#if HAVE_CUDA
",2
"
namespace horovod {
",2
"                                 : buffer_len_per_rank;

  auto& timeline = global_state_->timeline;
  if (num_elements_per_rank > 0) {
",2
"
",2
"            self.assertEqual(args.num_nccl_streams, 2)
            self.assertEqual(args.ccl_bgt_affinity, 1)
            self.assertEqual(args.gloo_timeout_seconds, 60)
",2
"        state.restore()

        for w1, w2 in zip(model1.get_weights(), model2_weights):
            self.assertAllClose(w1, w2)
        assert state.batch == 21
",2
"namespace horovod {
namespace common {
",2
"            df = create_xor_data(spark)

            with local_store() as store:
                torch_estimator = hvd.TorchEstimator(
                    num_proc=2,
",2
"                             .format(missing_labels))

    @keyword_only
    def setParams(self, **kwargs):
        return self._set(**kwargs)
",2
"    Perform an allreduce on a tensor-compatible value.
",2
"    // need to move input data to its corresponding location in the output
    sendbuf = (void*)first_entry.tensor->data();
    buffer_data = (void*)first_entry.output->data();
    int buffer_offset = displcmnts[gloo_context_->ctx->rank] * element_size;
",2
"            data = [
                [1.0, False], [1.0, False], [1.0, False], [1.0, False], [1.0, True]
            ]
",2
"      global_state_->controller->IsHomogeneous() ? local_size - 1 : 0;
  bool is_root_rank = local_rank == root_rank;

  int64_t total_num_elements =
",2
"                  tf.float64, tf.bool]
        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
",2
"                    help='input batch size')

parser.add_argument('--num-warmup-batches', type=int, default=10,
",2
"    index = codec.loads_base64(sys.argv[1])
    num_hosts = codec.loads_base64(sys.argv[2])
",2
"
    extdir = os.path.abspath(
        os.path.dirname(build_ext.get_ext_fullpath(ext.name)))
    config = 'Debug' if build_ext.debug else 'Release'
",2
"
enum class LogLevel {
",2
"                  ]

    cmake_build_args = [
        '--config', config,
",2
"
class Net(nn.Module):
",2
"  case mshadow::kFloat64:
    return static_cast<void*>(tensor->data().dptr<double>());
",2
"from common import tempdir, temppath

# Spark will fail to initialize correctly locally on Mac OS without this
if platform.system() == 'Darwin':
    os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")
",2
"
def check_exit(epoch, batch):
",2
"
if _global_variables is not None:
    def broadcast_global_variables(root_rank):
        """"""Broadcasts all global variables from root rank to all other processes.
",2
"            optimizer, named_parameters=model.named_parameters())

",2
"
    def get_runs_path(self):
        return self._runs_path

",2
"        keras.backend.set_session(tf.Session(config=config))
    return fn
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"}

int GlooController::GetTypeSize(DataType dtype) {
  switch (dtype) {
  case HOROVOD_FLOAT16:
",2
"
  // Timeline file.
  std::ofstream file_;
",2
"namespace common {

",2
"
  timeline_.NegotiateRankReady(name, msg.request_rank());

  std::vector<Request>& messages = table_iter->second;
  int count = (int)messages.size();
",2
"        hvd_output = std::make_shared<MXTensor>(output);
      }
",2
"        e.callback(status);
      }
    }
  }
",2
"
",2
"    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using Gloo.
",2
"    }
  }
",2
"
            tensor_sizes = [17, 32, 81, 12, 15, 23, 22] * 5
",2
"  }

  MX_API_END();
",2
"    # Compute the cosine similarity between minibatch examples and all embeddings.
",2
"                util.check_shape_compatibility(metadata, feature_columns, label_columns,
",2
"                     code=textwrap.dedent('''\
            #include <%s>
            #if NCCL_MAJOR < 2
            #error Horovod requires NCCL 2.0 or later version, please upgrade.
",2
"
batch_size = args.batch_size
num_classes = 10

# Enough epochs to demonstrate learning rate warmup and the reduction of
",2
"    const char *tensor_name = nullptr,
    int32_t root_rank = 0,
    int32_t device = 0,
",2
"            np.testing.assert_allclose(w1, w2)
        assert state.batch == 20
        assert state.epoch == 10

",2
"    VT_ROOT_RANK = 12,
    VT_DEVICE = 14,
    VT_TENSOR_SHAPE = 16
  };
",2
"    def __init__(self, num_classes, data_shape, max_iter, dtype, ctx):
        self.batch_size = data_shape[0]
        self.cur_iter = 0
        self.max_iter = max_iter
        self.dtype = dtype
",2
"                # All keys are distinct
                assert key != key2
                assert key != key3
                assert key2 != key3

",2
"  ResponseCache(const ResponseCache&) = delete;

  enum CacheState { MISS = 0, HIT = 1, INVALID = 2 };
",2
"                         (epoch, nbatch, name, acc))

    if hvd.rank() == 0:
",2
"                'Your MXNet version %s is outdated.  '
                'Horovod requires mxnet>=1.4.0' % mx.__version__)
    except ImportError:
        raise DistutilsPlatformError(
            'import mxnet failed, is it installed?\n\n%s' % traceback.format_exc())
",2
"    h_fc1 = layers.dropout(
        layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu),
        rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)
",2
"#if HAVE_CCL
  if (state.cpu_operation == LibType::CCL) {
",2
"        metadata = self._get_metadata()
",2
"            ElasticDriver._discover_hosts = wrapped_discover_hosts
            driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)
            with pytest.raises(RuntimeError):
",2
"
  // A LibType indicating what framework we are using to perform controller
  // operations.
",2
"                            print('testing with {}'.format(msg))
",2
"  assert(idx >= 0);
  assert(idx < shape_.size());
  return shape_[idx];
",2
"             The index of the list corresponds to the rank of each Horovod process.
",2
"                yield path_dir, bin_file


def determine_gcc_version(compiler):
    try:
",2
"    optimizer = Param(Params._dummy(), 'optimizer', 'optimizer')
    model = Param(Params._dummy(), 'model', 'model')
",2
"                                'NCCL_SOCKET_IFNAME=[^ ]+ '
                                '[^ ]+python[0-9.]* -m horovod.spark.task.gloo_exec_fn '
                                '[^ ]+ [^ ]+$'.format(rank=alloc_info.rank,
                                                      size=alloc_info.size,
                                                      local_rank=alloc_info.local_rank,
",2
"    return results


def in_thread(target, args=(), name=None, daemon=True, silent=False):
",2
"                                       char phase, const std::string& op_name,
                                       const std::string& args,
                                       long ts_micros) {
  TimelineRecord r{};
",2
"        for i in range(len(optimizer_state['param_groups'])):
            optimizer_state['param_groups'][i]['lr'] = \
                optimizer_state['param_groups'][i]['lr'] / hvd.size()
        optimizer = optimizer_cls(model.parameters(), lr=1)
        optimizer.load_state_dict(optimizer_state)
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================
",2
"#
# For alabaster: https://alabaster.readthedocs.io/en/latest/customization.html
#
html_theme_options = {
    'logo': 'logo.png',
",2
"                    'dtype': float,
",2
"

def _allgather_async(tensor, output, name):
    function = _check_function(_allgather_function_factory, tensor)
",2
"    pass


",2
"    try:
        yield path
    finally:
        if os.path.exists(path):
",2
"        self._handles.clear()
",2
"                        return True
                return False
",2
"            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")
",2
"template <DataType DT, DeviceType Dev, class T>
class TorchTensor : public Tensor {
",2
"        try:
",2
"                    fields[('After' if asc else 'Before') + col] = (r.Date - last_date).days
                    yield Row(**fields)
            return fn
",2
"    encoder = OneHotEncoderEstimator(inputCols=['label'],
                                     outputCols=['label_vec'],
                                     dropLast=False)
    model = encoder.fit(df)
",2
"
    def test_safe_shell_exec_captures_stderr(self):
        self.do_test_safe_shell_exec('echo hello >&2', 0, '', 'hello\n')
",2
"
",2
"    on_end_init();

    return status;
",2
"    config.gpu_options.allow_growth = True
    config.gpu_options.visible_device_list = str(hvd.local_rank())
",2
"            handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)

        for p, (handle, ctx) in self._handles.items():
            # This means step() is called before backward_passes_per_steps finished.
",2
"
  ThrowIfError(enqueue_result);
}

inline void PushHorovodOperation(OperationType op_type, NDArray* input,
",2
"  // Compute sufficient statistics for the observed locations.
  Eigen::VectorXd mu_sample;
  gpr_.Predict(x_sample, mu_sample);

  // Needed for noise-based model, otherwise use y_sample.maxCoeff().
",2
"  return false;
",2
"#
",2
"size = _basics.size
local_size = _basics.local_size
rank = _basics.rank
local_rank = _basics.local_rank
mpi_threads_supported = _basics.mpi_threads_supported
",2
"
    def filter_supported_types(self, types):
        if 'CCL_ROOT' in os.environ:
           types = [t for t in types if t in ccl_supported_types]
",2
"  return handle;
}


",2
"
extern ""C"" int horovod_torch_poll(int handle) {
  return handle_manager.PollHandle(handle) ? 1 : 0;
",2
"    default:
      return ""<unknown>"";
  }
}
",2
"                    help='number of batches per epoch')
parser.add_argument('--batches-per-commit', type=int, default=1,
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"for gpu in gpus:
",2
"from keras import backend as K
from keras import optimizers


def save_bare_keras_optimizer(optimizer, h5py_file):
",2
"                if intermediate_format == ARRAY:
                    converted[col] = col_data.toArray().tolist()
                elif intermediate_format == CUSTOM_SPARSE:
                    # Currently petastorm does not support reading pyspark sparse vector. We put
                    # the indices and values into one array. when consuming the data, we re-create
",2
"    if settings.output_filename:
        _mkdir_p(settings.output_filename)

    # start global rendezvous server and get port that it is listening on
    rendezvous = RendezvousServer(settings.verbose)
",2
"  LOG(DEBUG) << prefix << "" rendezvous started for rank="" << rank << "", size="" << size
",2
"    key = _training_cache.create_key(df, store, validation)
",2
"                threshold = 1e-4
            elif size < 15:
                threshold = 5e-4
",2
"
    gradients = tape.gradient(loss, model.trainable_variables)
    opt.apply_gradients(zip(gradients, model.trainable_variables))
",2
"  const std::set<uint32_t>& cache_hits() const;

  const std::set<uint32_t>& invalid_bits() const;
",2
"        print('off by: ', self.diff_ratio(expected,tensor.cpu().numpy()))
",2
"
    def _get_value(self, scope, key):
        with self.server.cache_lock:
",2
"
    args_list = [[host] for host in all_host_names]
    host_addresses = threads.execute_function_multithreaded(
",2
"
    def __init__(self, prefix_path,
                 host=None, port=None, user=None, kerb_ticket=None,
                 driver='libhdfs', extra_conf=None, temp_dir=None, *args, **kwargs):
        self._temp_dir = temp_dir
",2
"  //  x: Proposed points at which EI shall be computed (m x d).
  //  x_sample: Sample locations observed (n x d).
  //
",2
"      const Eigen::MatrixXd& x_sample, const Eigen::MatrixXd& y_sample, int n_restarts=25);

  // Computes the Expected Improvement at points X based on existing samples X_sample and Y_sample
  // using a Gaussian process surrogate model fitted to the samples.
  //
",2
"
    def register_task(self, index, task_addresses, host_hash):
        self._send(RegisterTaskRequest(index, task_addresses, host_hash))

    def all_task_addresses(self, index):
",2
"        if not state.warm:
",2
"    uint32_t cache_bit = it->second;
    auto& cache_params = std::get<1>(*cache_iters_[cache_bit]);
",2
"
    def getEpochs(self):
        return self.getOrDefault(self.epochs)

    def setTrainStepsPerEpoch(self, value):
",2
"                             [sum(tensor_sizes)] + [17] * (dim - 1))))

            for i in range(size):
                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)
                rank_tensor = tf.slice(
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================

",2
"    should_shut_down_ = true;
  }
  if (!cache_hits_.erase(StatusBit::UNCACHED_IN_QUEUE - NUM_STATUS_BITS)) {
    uncached_in_queue_ = true;
  }
",2
"        """"""Map of interface to list of (ip, port) pairs.""""""


class SparkTaskService(task_service.BasicTaskService):
    NAME_FORMAT = 'task service #%d'
",2
"
class PersistentBuffer {
public:
",2
"
class AllreduceOp : public HorovodOp {
public:
  AllreduceOp(HorovodGlobalState* global_state);
",2
"            if size() > 1 or os.environ.get('HOROVOD_ELASTIC') == '1':
                return self._allreduce_grads(gradients)
            else:
",2
"
        if max_local_size > TOTAL_BUFFER_MEMORY_CAP_GIB:
            shuffle_buffer_size = TOTAL_BUFFER_MEMORY_CAP_GIB * BYTES_PER_GIB / avg_row_size / max_local_size
",2
"            transform_spec = TransformSpec(transformation)

",2
"
callbacks = [
    # Horovod: broadcast initial variable states from rank 0 to all other processes.
    # This is necessary to ensure consistent initialization of all workers when
    # training is started with random weights or restored from a checkpoint.
",2
"        expected_env = '-x env1 -x env2'
        extra_mpi_args = '<extra args go here>'
        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):
            self._do_test_spark_run(num_proc=2, use_mpi=use_mpi, use_gloo=use_gloo,
                                    extra_mpi_args=extra_mpi_args,
",2
"        with self.test_session(config=self.config) as sess:
            K.set_session(sess)

            opt = keras.optimizers.RMSprop(lr=0.0001)
",2
"    def test_horovod_broadcast_grad_cpu(self):
        """"""Test the correctness of the broadcast gradient on CPU.""""""
",2
"            feature_cols=None,
            label_cols=None,
",2
"# Evaluate the model on the full data set.
score = model.evaluate(x_test, y_test, verbose=0)
",2
"
",2
"import numpy as np
import pytest
import tensorflow as tf
import warnings

",2
"    MemcpyOutFusionBuffer(buffer_data, entries);

    if (global_state_->timeline.Initialized()) {
",2
"      } else {
        bnormsq = normAndDots[i * 3 + 1];
",2
"            self.skipTest(""No GPUs available"")

        hvd.init()
",2
"                    help='use adasum algorithm to do reduction')

args = parser.parse_args()
args.cuda = not args.no_cuda and torch.cuda.is_available()
",2
"    timeline.ActivityStartAll(entries, ALLOCATE_SHARED_BUFFER);
    int64_t window_size = global_state_->controller->GetLocalRank() == 0 ? total_size_in_bytes : 0;
    MPI_Win_allocate_shared(window_size,
                            element_size,
                            MPI_INFO_NULL,
",2
"        val_reader_num_workers: Similar to the train_reader_num_workers.
    """"""

",2
"
void ResponseList::set_shutdown(bool value) { shutdown_ = value; }

void ResponseList::add_response(const Response& value) {
",2
"        with h5py.File(bio, 'w') as f:
            save_optimizer_fn(opt, f)
        return codec.dumps_base64(bio.getvalue())
    else:
",2
"  y_samples_.clear();
}

VectorXd BayesianOptimization::ProposeLocation(const MatrixXd& x_sample, const MatrixXd& y_sample, int n_restarts) {
",2
"    :param args: Arguments to pass to `func`.
    :param kwargs: Keyword arguments to pass to `func`.
    :param np: Number of Horovod processes.
",2
"    hvd.callbacks.MetricAverageCallback(),

    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final
    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during
",2
"                     help=None):
            super(StoreOverrideBoolAction, self).__init__(
                option_strings=option_strings,
                dest=dest,
",2
"  std::unordered_map<std::string, TensorTableEntry> tensor_table_;

  // Queue of MPI requests waiting to be sent to the coordinator node.
  std::queue<Request> message_queue_;
",2
"
                keras_model = keras_estimator.fit(df)

                trained_model = keras_model.getModel()
",2
"        def __init__(self, optimizer, name=None, use_locking=False, device_dense='',
",2
"    :type fn_cache: Horovod.run.util.cache.Cache
    :return: List of common interfaces
",2
"                          sample_weight_mode='temporal')

            x = np.random.random((1, 3))
            y = np.random.random((1, 3, 3))
",2
"# limitations under the License.
# ==============================================================================


class TaskInfo(object):
",2
"// limitations under the License.
// =============================================================================
",2
"        # interfaces that are not really connected to any external networks
        # such as lo0 with address 127.0.0.1.
        if settings.verbose >= 2:
            print('Waiting for hosts to perform host-to-host interface checking.')
",2
"      if comp:
        print('Stability test passed')
      else:
        print('computed: ', tensor)
        print('expected: ', expected)
",2
"        Args:
",2
"                schema_cols.append(validation)
            df = df[schema_cols]

            metadata = None
",2
"              << cache_enabled_.BestValue() << "", ""
              << joint_params_.BestValue(cycle_time_ms) << "" ms, ""
",2
"
void MPIContext::Initialize(const std::vector<int>& ranks,
                            MPIContextManager& ctx_manager) {

  if (!enabled_) {
",2
"    if len(state_dict['state']) == 0:
        for group in optimizer.param_groups:
            for p in group['params']:
                if p.requires_grad and id(p) not in state_dict['state']:
",2
"                        dest='start_timeout', type=int,
                        help='Horovodrun has to perform all the checks and '
                             'start the processes before the specified '
                             'timeout. The default value is 30 seconds. '
",2
"    # Create the Estimator
    mnist_classifier = tf.estimator.Estimator(
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"
#include ""collective_operations.h""
",2
"
",2
"    /* Cleanup */
    for (size_t ec = 0; ec < entries.size(); ++ec) {
",2
"
    if output_shapes is not None:
        label_count = len(label_columns)
",2
"  }

  int64_t num_elements = 0;
  for (auto& e : entries) {
",2
"            if reduction == 'none':
                return losses
            else:
",2
"
from horovod.spark.task import task_exec
from horovod.run.common.util import codec


",2
"// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"        conf.setMaster(args.processing_master)
    spark = SparkSession.builder.config(conf=conf).getOrCreate()

    train_csv = spark.read.csv('%s/train.csv' % args.data_dir, header=True)
    test_csv = spark.read.csv('%s/test.csv' % args.data_dir, header=True)
",2
"
                for label_col, output_col, pred in zip(label_cols, output_cols, preds):
                    meta = metadata[label_col]
                    col_type = meta['spark_data_type']
",2
"                                   '(default: 5')
    group_params.add_argument('--cache-capacity', action=make_override_action(override_args), type=int,
",2
"    @mock.patch('horovod.run.util.lsf.LSFUtils.get_num_gpus', MagicMock(return_value=2))
    @mock.patch('horovod.run.util.network.filter_local_addresses', MagicMock(return_value=['host1', 'host2']))
    @mock.patch('horovod.run.runner._check_all_hosts_ssh_successful', MagicMock())
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"                    raise RuntimeError('Job has been shutdown, see above error messages for details.')
",2
"        unnamed_param_ids = all_param_ids - named_param_ids
        if len(unnamed_param_ids):
            raise ValueError('named_parameters was specified, but one or more model '
                             'parameters were not named. Python object ids: '
",2
"
#include ""gloo/rendezvous/context.h""
#include ""gloo/rendezvous/file_store.h""
#include ""gloo/rendezvous/prefix_store.h""
",2
"        hvd_mock.allgather.return_value = [local_size for _ in range(hvd_size)]

        avg_row_size = 100
        train_row_count_per_worker = 100
",2
"            model2.build((2, 2))
            model2.set_weights(
                [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),
                 np.array([0.0, 0.0], dtype=np.float32)])
",2
" * \brief Protected CUDA call.
 * \param func Expression to call.
 *
",2
"                                                     verbose=settings.verbose)
",2
"    bool Tune(double score, double* best_score) override;
",2
"
    # Create Spark session for prediction.
    conf = SparkConf().setAppName('prediction') \
",2
"        metric12 = _generate_mock_metric('12', 12)
        metric21 = _generate_mock_metric('21', 21)
        metric22 = _generate_mock_metric('22', 22)

",2
"        for (k,v) in get_torch_rocm_macros():
            updated_macros = set_macro(updated_macros, k, v)

    # Export TORCH_VERSION equal to our representation of torch.__version__. Internally it's
    # used for backwards compatibility checks.
",2
"#include ""cuda_util.h""

",2
"  virtual const void* data() const override;
  virtual int64_t size() const override;

protected:
",2
"
parser.add_argument('--model', type=str, default='ResNet50',
                    help='model to benchmark')
parser.add_argument('--batch-size', type=int, default=32,
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"
    rank = ParseNextInt(ss);
    if (rank == -1) {
      // Signals that this host is not part of the job
      std::ostringstream out;
",2
"    GPU_INFERENCE_CLUSTER = 'local-cluster[2,1,1024]'  # or 'spark://hostname:7077'

    # ================ #
",2
"                                     'autotuning will take. (default: %(default)s)')
    group_autotune.add_argument('--autotune-bayes-opt-max-samples', action=make_override_action(override_args),
                                type=int, default=20,
",2
"      THTensor * tensor);                                                      \
",2
"
        df = df \
            .withColumn('Open', df.Open != '0') \
            .withColumn('Promo', df.Promo != '0') \
",2
"
        example 2:
        memory_cap_gb = 4
            machine1: 2 workers
            machine2: 3 workers
",2
"
    timeline.ActivityEndAll(entries);
  } else {
    buffer_data = (void*) first_entry.output->data();
",2
"
# The data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

",2
"//
",2
"            if self._verbose >= 2:
",2
"  return values;
}

",2
"        if _fp16_supported:
            dtypes += self.filter_supported_types([torch.HalfTensor])
        if torch.cuda.is_available():
            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,
                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"
if __name__ == '__main__':
",2
"  std::shared_ptr<Status> ReleaseHandle(int handle);

private:
  std::atomic_int last_handle_;
",2
"        """"""Test that the deferred initialized parameters are broadcasted.""""""
",2
"                keras_utils = BareKerasUtil
            elif keras_pkg_type == TF_KERAS:
                keras_utils = TFKerasUtil

        custom_objects = {}
",2
"  }

",2
"    return tensor.device().index();
  }
  return CPU_DEVICE_ID;
}
",2
"# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import threading
",2
"  VectorXd ei = imp.cwiseProduct(z.unaryExpr(cdf)) + sigma.cwiseProduct(z.unaryExpr(pdf));
",2
"        self._shutdown.set()
",2
"        assert mock_get_worker_client.call_count == 3
        assert mock_get_coordinator_info.call_count == 3

    def test_order_available_hosts(self):
",2
"
    def get_local_output_dir_fn(self, run_id):
        raise NotImplementedError()

    def sync_fn(self, run_id):
",2
"            assert updated_slot_info.cross_size == 1, rank
            assert updated_slot_info.cross_rank == 0, rank

    @mock.patch('horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)
",2
"    best_val_rmspe = min(history['val_exp_rmspe'])
    print('Best RMSPE: %f' % best_val_rmspe)

",2
"  template <>                                                                  \
",2
"
        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")
",2
"  // Pre-allocated output tensor.
  std::shared_ptr<Tensor> output;
  // Root rank for broadcast operation.
",2
"
        if not isinstance(text, str):
",2
"                    config_parser.set_env_from_args(env, args)
                    _run_elastic(args)

                    with open(logfile, 'r') as f:
                        lines = f.readlines()
",2
"  CCLContext* ccl_context_ ;
};

",2
"            - '10.11.11.11:4,10.11.11.12:4'
",2
"            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
",2
"        _SessionRunHook = tf.train.SessionRunHook
    except AttributeError:
        _SessionRunHook = None
",2
"                self.assertEqual(weights, new_weights)
            else:
",2
"
    run_controller(args.use_gloo, gloo_run_fn,
                   args.use_mpi, mpi_run_fn,
                   args.use_jsrun, js_run_fn,
",2
"import numpy as np

from pyspark.ml.linalg import VectorUDT
",2
"  } else {
    fused_input_data = first_entry.tensor->data();
",2
"
        if cc_compiler:
            print('INFO: Compilers %s and %s (version %s) selected for PyTorch plugin build.'
",2
"        Device to be used for dense tensors. Uses GPU by default
        if Horovod was built with HOROVOD_GPU_OPERATIONS.
      device_sparse:
        Device to be used for sparse tensors. Uses GPU by default
        if Horovod was built with HOROVOD_GPU_OPERATIONS.
",2
"            p = {
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"  }
  const flatbuffers::Vector<int64_t> *tensor_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_TENSOR_SHAPE);
",2
"
from horovod.run.common.service.task_service import BasicTaskClient, BasicTaskService
from horovod.run.common.util import network, secret
from horovod.run.util.threads import in_thread

",2
"    @staticmethod
",2
"    def wait_for_task_to_task_address_updates(self, timeout):
        self._wait_cond.acquire()
        try:
",2
"  best_value_ = value;
  if (fixed) {
    value_ = value;
    tunable_ = false;
  }
",2
"// See the License for the specific language governing permissions and
// limitations under the License.
",2
"
    def _send_one(self, addr, req):
        for iter in range(self._attempts):
",2
"#endif

extern ""C"" int horovod_torch_join(int device) {
",2
"        device_sparse: Device to be used for sparse tensors. Uses GPU by default
                       if Horovod was built with HOROVOD_GPU_OPERATIONS.
        compression: Compression algorithm used to reduce the amount of data
                     sent and received by each worker node.  Defaults to not
",2
"            'Your MXNet version is outdated.  Horovod requires mxnet>1.3.0')


",2
"      assert comp

if __name__ == ""__main__"":
",2
"

",2
"
",2
"
#include ""gloo_context.h""

#include <chrono>
",2
"#ifndef HOROVOD_ADASUM_MPI_H
#define HOROVOD_ADASUM_MPI_H

",2
"    """"""
    Tests for ops in horovod.tensorflow.
    """"""

    def __init__(self, *args, **kwargs):
",2
"  for (size_t i = 0; i < n; i++) {
    c[i] = a[i] | b[i];
  }
",2
"                expected_command = ('mpirun '
                                    '--allow-run-as-root --tag-output '
                                    '-np {expected_np} -H [^ ]+ '
",2
"#else
",2
"
  virtual void CrossRankBitwiseOr(std::vector<long long>& bitvector,
",2
"            with tf.device(""/gpu:%d"" % local_rank):
                tensor = tf.ones([17] * dim) * rank
",2
"      opts.setInput(&local_size_, 1);
      opts.setOutput(local_sizes.data(), size_);
      gloo::allgather(opts);
    }
    is_homogeneous_ = true;
",2
"            output.wait_to_read()
            assert False, 'hvd.allreduce did not throw error'
        except (MXNetError, RuntimeError):
            pass
",2
"            model.add(keras.layers.ThresholdedReLU(0.5))
",2
"local_size = _basics.local_size
rank = _basics.rank
local_rank = _basics.local_rank
mpi_threads_supported = _basics.mpi_threads_supported
mpi_enabled = _basics.mpi_enabled
",2
"
import horovod.mxnet as hvd
",2
"opt = hvd.DistributedOptimizer(opt)
",2
"                rank_tensor = tf.slice(gathered,
                                       [i * 17] + [0] * (dim - 1),
",2
"
    def _handle(self, req, client_address):
        if isinstance(req, PingRequest):
            return PingResponse(self._service_name, client_address[0])
",2
"            self.multiplier = multiplier

        if self.initial_lr is None:
            warnings.warn('Parameter `initial_lr` will be required in v0.21.0', DeprecationWarning)

",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"    size_t size = in.size();
    result_type seed = 0;
    for (size_t i = 0; i < size; i++)
      seed = hash_one<T>(in[i], seed);
",2
"                                   GetNCCLDataType(first_entry.tensor), ncclSum,
                                   *nccl_op_context_.nccl_comm_, *gpu_op_context_.stream);
  nccl_context_->ErrorCheck(""ncclAllReduce"", nccl_result, *nccl_op_context_.nccl_comm_);
  if (global_state_->timeline.Initialized()) {
    gpu_context_->RecordEvent(gpu_op_context_.event_queue, NCCL_ALLREDUCE, *gpu_op_context_.stream);
",2
"class MPITests(tf.test.TestCase):
    """"""
    Tests for ops in horovod.tensorflow.
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")

        ctx = self._current_context()
",2
"
  if (entries.size() > 1) {
",2
"            },
",2
"    group_elastic.add_argument('--slots-per-host', action='store', dest='slots', type=int,
                               help='Number of slots for processes per host. Normally 1 slot per GPU per host. '
                                    'If slots are provided by the output of the host discovery script, then '
                                    'that value will override this parameter.')
    group_elastic.add_argument('--elastic-timeout', action='store', dest='elastic_timeout', type=int,
",2
"        if os.environ.get('HOROVOD_MIXED_INSTALL'):
            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.
",2
"        construct_metric_value_holders = remote._construct_metric_value_holders_fn()
        metric_values = construct_metric_value_holders(metric_class, metric_fn_groups, label_columns,
                                                       hvd_mock)

        assert metric_values[0][0].name == 'group_0_l1'
",2
"
# Train the model. The training will randomly sample 1 / N batches of training data and
",2
"            'Horovod build with GPU support was requested, but this PyTorch '
            'installation does not support ROCm.')
    elif have_rocm and not have_rocm_macro:
        # ROCm PyTorch requires extensions to be hipified with the provided utility.
",2
"class ParameterManager {
public:
  ParameterManager();
  ParameterManager(const ParameterManager&) = delete;
",2
"from common import temppath
",2
"
        try:
            hvd.allgather(tensor)
            assert False, 'hvd.allgather did not throw error'
",2
"  with_device(int device);
  ~with_device();

private:
  int restore_device_;
",2
"    spark.stop()
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"        """"""Commits all modifications to state tracked by this object to host memory.

        This call will also check for any changes to known hosts, and raise a `HostsUpdatedInterrupt`
        if any were detected.

",2
"    def on_train_begin(self, logs=None):
",2
"        for use_gloo, use_mpi, use_js, \
            gloo_is_built, mpi_is_built, \
",2
"
",2
"# accuracy. Scale the learning rate `lr = base_lr` ---> `lr = base_lr * hvd.size()` during
# the first five epochs. See https://arxiv.org/abs/1706.02677 for details.
# After the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.
def adjust_learning_rate(epoch, batch_idx):
",2
"        self._barrier = None
",2
"  }
  return horovod_global.controller->GetLocalRank();
}
",2
"                size = data_col.indices.shape[0]
            elif isinstance(data_col, list):
                shape = size = len(data_col)
            else:
",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",2
"    rank = hvd.rank()

    for data_type in self.data_types:
      denominator = local_size if hvd.nccl_built() else 1
",2
"
    // Since Adasum is not a per-element operation, an allreduce for fused
    // tensors needs to know boundaries of tensors. Calculate here the count
    // of elements for each tensor owned by this rank.
",2
"    # Horovod: pin GPU to be used to process local rank (one GPU per process)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    config.gpu_options.visible_device_list = str(hvd.local_rank())
",2
"
import pyspark

from pyspark.ml.linalg import DenseVector, SparseVector, VectorUDT
from pyspark.sql.types import ArrayType, BooleanType, DoubleType, FloatType, IntegerType, \
",2
"        local_rank = hvd.local_rank()
",2
"        with tf.device(""/cpu:0""):
            expected_obj = {
                'hello': 123,
                0: [1, 2]
",2
"  // Kernel parameter that controls the vertical variation of functions drawn from the GP. Higher values lead to wider
",2
"  //  Whether the parameters need to be broadcasted to all ranks.
  bool Update(const std::vector<std::string>& tensor_names, int64_t bytes);
",2
"# ==============================================================================


class HorovodInternalError(RuntimeError):
",2
"                    if saved_state != state:
                        # This worker changed its state, so do not attempt to wait again to avoid double-counting
                        raise RuntimeError('State {} overridden by {}'.format(state, saved_state))

    def _action(self):
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"
  virtual Status Execute(std::vector<TensorTableEntry>& entries,
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"    throw std::runtime_error(
        ""MPI_AllReduce failed, see MPI output for details."");
  }
}

",2
"                    ]
                    self.assertEqual(expected, env)

    @pytest.mark.skipif(LooseVersion(pyspark.__version__) < LooseVersion('3.0.0'),
                        reason='get_available_devices only supported in Spark 3.0 and above')
",2
"
",2
"            hopt_copy1 = hopt.from_config(cfg)
            self.assertEqual(cfg, hopt_copy1.get_config())

            hopt_copy2 = hopt.__class__.from_config(cfg)
            self.assertEqual(cfg, hopt_copy2.get_config())
",2
"  double fx_min = std::numeric_limits<double>::max();
  for (int i = 0; i < n_restarts; ++i) {
    // Generate a random starting point by drawing from our bounded distributions.
    VectorXd x = VectorXd::Zero(d_);
",2
"
        Args:
            root_rank: Rank that will send data, other ranks will receive data.
            device: Device to be used for broadcasting. Uses GPU by default
                    if Horovod was build with HOROVOD_GPU_OPERATIONS.
",2
"import horovod.spark.common._namedtuple_fix

import contextlib

",2
"
        # Horovod: pin GPU to be used to process local rank (one GPU per process), if GPUs are available.
",2
"
",2
"                        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):
                            with pytest.raises(Exception, match=expected):
",2
"
  MPI_Datatype GetMPIDataType(DataType dtype);

",2
"        if args.eval_frequency and (epoch + 1) % args.eval_frequency == 0:
",2
"#include <utility>
#include <vector>
",2
"// Add a TensorTableEntry as well as its message to the queue.
Status TensorQueue::AddToTensorQueue(TensorTableEntry& e, Request& message) {
  std::lock_guard<std::mutex> guard(mutex_);
  if (tensor_table_.find(e.tensor_name) != tensor_table_.end()) {
    return DUPLICATE_NAME_ERROR;
",2
"            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"            def fn(rows):
                last_store, last_date = None, None
",2
"  total_bytes_ = 0;
  last_sample_start_ = std::chrono::steady_clock::now();
",2
"
    allreduce_ops.push_back(
",2
"                                           label_columns=['float'],
                                           compress_sparse=True) as dataset_idx:
                        mock_get_metadata.assert_called()
                        assert dataset_idx == 0

",2
"
    def getInputShapes(self):
        return self.getOrDefault(self.input_shapes)

",2
"
  // Copy memory into the fusion buffer.
",2
"            valid_word = reverse_dictionary[valid_examples[i]]
            top_k = 8  # number of nearest neighbors
            nearest = (-sim[i, :]).argsort()[1:top_k + 1]
            log_str = 'Nearest to %s:' % valid_word
",2
"  }                                                                            \
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"
        hvd.broadcast_parameters(tensor_dict, root_rank=root_rank)
        for i in range(count):
",2
"        return np.float64
",2
"                self._wait_cond.release()
            return network.AckResponse()
",2
"namespace horovod {
namespace common {
",2
"                        reason='Synchronizing state requires PyTorch 1.0 or above')
    def test_elastic_state(self):
        hvd.init()
",2
"                                               input_shapes, output_shapes)

                bad_input_shapes = [[1], [1], [-1, 3, 5]]
                with pytest.raises(ValueError):
",2
"    return true;
  }

  OnTune(score, value_);
  if (IsDoneTuning()) {
",2
"
    def getBatchSize(self):
        return self.getOrDefault(self.batch_size)

    def setEpochs(self, value):
",2
"            state.restore()

            for w1, w2 in zip(model1.get_weights(), model1_weights):
",2
"
            # Horovod: average metrics among workers at the end of every epoch.
",2
"        """"""
        mpi_enabled = self.MPI_LIB_CTYPES.horovod_mpi_enabled()
        return bool(mpi_enabled)

    def mpi_built(self):
",2
"
",2
" * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 **************************************************************************************************/
",2
"    std::deque<Request> messages_to_replace;
    size_t num_messages = message_queue_tmp.size();
    for (size_t i = 0; i < num_messages; ++i) {
",2
"        super(LocalStore, self).__init__(prefix_path, *args, **kwargs)

    def path_prefix(self):
        return self.FS_PREFIX

",2
"        &DoAllreduceCudaOnCPU);
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"    def synchronize(self):
        pass

",2
"    def setVerbose(self, value):
        return self._set(verbose=value)

    def getVerbose(self):
        return self.getOrDefault(self.verbose)
",2
"                         name, priority);
",2
"    return MPI_LIB.horovod_broadcast(tensor, name=name, root_rank=root_rank)


@ops.RegisterGradient('HorovodBroadcast')
def _broadcast_grad(op, grad):
",2
"  return Framework::PYTORCH;
}

",2
"                               transformations to it. Increasing this number
                               will generally increase the reading rate but will also
                               increase the memory footprint. More processes are
                               particularly useful if the bandwidth to the data store is not
                               high enough, or users need to apply transformation such as
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"  }
}

void Timeline::ActivityEnd(const std::string& tensor_name) {
",2
"        assert len(sparse_vector_values) == dense_shape

    def test_convert_custom_sparse_to_dense_bare_keras_fn(self):
",2
"                if dtype == tf.bool:
                    tensor = tensor % 2
",2
"                                                                               \
  template <>                                                                  \
  void                                                                         \
  TensorUtil::DivideTensorInPlace<HorovodType, DeviceType::CPU, THTensor>(     \
      THTensor * tensor, int value) {                                          \
",2
"  switch (tensor->dtype()) {
  case HOROVOD_FLOAT32:
",2
"            bn_out.mean(dim=0).sum().backward()
            assert (hvd.allreduce(sync_bn.weight.grad, name='sync_bn.weight.grad') - bn.weight.grad).abs().sum() < 1e-6
            assert (hvd.allreduce(sync_bn.bias.grad, name='sync_bn.bias.grad') - bn.bias.grad).abs().sum() < 1e-6
            assert (hvd.allreduce(ts1.grad, name='ts1.grad') - ts2.grad).abs().sum() < 1e-6
",2
"            task_exec_args, task_exec_kwargs = task_exec.call_args
",2
"del vocabulary  # Hint to reduce memory.
print('Most common words (+UNK)', count[:5])
print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])

",2
"  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
",2
"
class TaskIndexByRankRequest(object):
    """"""Request task index by Horovod rank.""""""
    def __init__(self, rank):
        self.rank = rank
",2
"                    help='random seed (default: 42)')
",2
"        if key in cache:
            return cache[key]
",2
"#include ""timeline.h""
",2
"    def __init__(self, delay):
",2
"        train_df = train_df.filter(
            ~f.col(validation) if bool_dtype else f.col(validation) == 0).drop(validation)
",2
"
        def exec_command(slot_info, events):
            driver.record_ready(slot_info.hostname, slot_info.local_rank)
            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)
",2
"        """"""Returns true if the key is in the cache and its paths exist in the store already.""""""
        if key not in self._key_to_dataset:
            return False
",2
"      }
      std::this_thread::sleep_for(std::chrono::nanoseconds(100));
    }
    for (auto& e : entries) {
",2
"# Copyright 2017 onwards, fast.ai, Inc.
# Modifications copyright (C) 2018 Uber Technologies, Inc.
#
",2
"import time
",2
"        def new_optimizer(cls, opt_params, model):
            p = {
                k: v for k, v in opt_params.items()
",2
"namespace torch {

with_device::with_device(int device) {
",2
"                                   DataType horovod_datatype,
                                   std::vector<int>& tensor_counts, int layerid,
                                   Communicator_type& comm, bool isLeftNeighbor,
                                   std::vector<double>& normAndDots,
                                   HorovodGlobalState* global_state) {
",2
"                    'shape': 2
                },
                'mixed': {
",2
"
        dataset_idx = self._key_to_dataset[key]
        _, _, _, validation = key
        train_data_path = store.get_train_data_path(dataset_idx)
",2
"    conf = SparkConf().setAppName(app).setMaster(master)

    with temppath() as temp_filename:
        if gpus > 0:
",2
"            diff = self.evaluate(max_difference)
",2
"from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables
from horovod.tensorflow.mpi_ops import _executing_eagerly, init, rank, shutdown


",2
"            addresses, secret_key, self._verbose)

",2
"

class KerasEstimatorParamsReadable(MLReadable):
    @classmethod
    def read(cls):
",2
"epochs = 24
",2
"        return JOB_ID
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"// =============================================================================

",2
"    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))

model.fit(x_train, y_train,
",2
"            import horovod.tensorflow.keras as hvd
            return hvd
",2
"        }
      }

      for (auto& tensor_name : ready_to_reduce) {
",2
"
        def add_host():
",2
"            '''%('rccl.h' if have_rocm else 'nccl.h')))
    except (CompileError, LinkError):
        raise DistutilsPlatformError(
            'NCCL 2.0 library or its later version was not found (see error above).\n'
            'Please specify correct NCCL location with the HOROVOD_NCCL_HOME '
",2
"    def __init__(self, *args, **kwargs):
        super(InteractiveRunTests, self).__init__(*args, **kwargs)
        warnings.simplefilter('module')

",2
"    : device_(device), output_(output) {}

template <DataType DT, DeviceType Dev, class T>
Status TorchOpContext<DT, Dev, T>::AllocatePersistent(
",2
"                    help='data type for training (default: float32)')
",2
"
",2
"
  timeline.ActivityStartAll(entries, ALLOCATE_OUTPUT);
",2
"  static void ParseFromBytes(ResponseList& response_list,
                             const uint8_t* input);

  static void SerializeToString(const ResponseList& response_list,
",2
"        return _SyncBatchNorm.apply(
            input, self.weight, self.bias, self.running_mean, self.running_var,
            self.eps, self.momentum)

",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"}

template <class T>
void ParameterManager::CategoricalParameter<T>::ResetState() {
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"  void* buffer_data;
  int64_t total_num_elements = NumElements(entries);

  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
",2
"  void PopMessagesFromQueue(std::deque<Request>& message_queue_buffer);

  void PushMessageToQueue(Request& message);

",2
"//
",2
"        if not loss:
            raise ValueError('Loss parameter is required for the model to compile')

        optimizer = self.getOptimizer()
        if not optimizer:
",2
"  switch (dtype) {
",2
"def check_build(verbose):
    def get_check(value):
",2
"    """"""
    Test that horovod.spark.run does not default to spark parallelism given num_proc using MPI.
",2
"
            test = max_difference <= threshold
",2
"        }
        torch.save(state, filepath)


",2
"            result = fn(ext)
",2
"        google_trend_all = prepare_google_trend()
",2
"img_sec_mean = np.mean(state.img_secs)
img_sec_conf = 1.96 * np.std(state.img_secs)
log('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))
log('Total img/sec on %d %s(s): %.1f +-%.1f' %
",2
"
    if rank() != root_rank:
        buf = io.BytesIO(t.numpy().tobytes())
        obj = cloudpickle.load(buf)
",2
"
    def test_horovod_allgather_variable_size(self):
        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors,
        even if those tensors have different sizes along the first dim.""""""
        hvd.init()
",2
"        exit_code = safe_shell_exec.execute(lscpu_cmd, stdout=output, stderr=output)
        if exit_code != 0:
",2
"}
",2
"    """"""
    if handle not in _handle_map:
        return

    try:
",2
"  }
}
Status AdasumGpuAllreduceOp::Execute(std::vector<TensorTableEntry>& entries,
                                     const Response& response) {
",2
"  auto& timeline = global_state_->timeline;
  if (ddl_context_->ddl_local_device_id != first_entry.device) {
    throw std::logic_error(""DDL does not support more than one GPU device per process."");
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"    if gpu_allreduce:
",2
"                        const int64_t* const* entry_component_sizes,
                        const void* buffer_data, int element_size,
                        std::vector<TensorTableEntry>& entries);

  virtual void
",2
"
    Args:
        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.
        model: Keras model to train.
        backend: Optional Backend object for running distributed training function. Defaults to SparkBackend with
",2
"    'mxnet.base',

    'horovod.common.util',
    'horovod.torch.mpi_lib_v2',
]
",2
"
    def convert_cpu_fp16_to_fp32(self, *values):
        # PyTorch doesn't support any CPU ops on FP16 tensors.
",2
"
    'pyspark',
    'pyspark.ml',
    'pyspark.ml.linalg',
",2
"                        with mock.patch('horovod.spark.task.mpirun_exec_fn.task_exec') as task_exec:
                            msg = 'work_dir_env_set={} python_path_is_set={} hvd_python_path_is_set={}'\
                                .format(work_dir_env_set, python_path_is_set, hvd_python_path_is_set)
",2
"    driver_addresses = codec.loads_base64(sys.argv[3])
    settings = codec.loads_base64(sys.argv[4])
",2
"    p.join()
",2
"# Default settings from https://arxiv.org/abs/1706.02677.
parser.add_argument('--batch-size', type=int, default=32,
                    help='input batch size for training')
parser.add_argument('--val-batch-size', type=int, default=32,
",2
"      return std::sqrt(x);
    };
    *sigma = cov.diagonal().unaryExpr(sqrt);
  }
}
",2
"  return tensor_name_to_bit_.at(tensor_name);
}

std::vector<uint32_t> ResponseCache::list_all_bits() const {
",2
"        actual_rsh_settings = codec.loads_base64(serialized_rsh_settings)
        self.assertIsNone(actual_rsh_settings.key)

        # for better comparison replace sections in actual_command that change across runs / hosts
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"
",2
"        df = df.withColumn('Promo2Weeks', (df.Promo2Days / 7).cast(T.IntegerType()))

        # Check that we did not lose any rows through inner joins.
        assert num_rows == df.count(), 'lost rows in joins'
",2
"    // All workers add supported responses to cache. This updates the cache
    // order consistently across workers.
    for (auto& response : response_list.responses()) {
      if ((response.response_type() == Response::ResponseType::ALLREDUCE ||
",2
"      message << "": ["";
      auto it = kv.second.begin();
      message << *it;
",2
"  }
  return device;
",2
"  // Set of invalid bits. After sync(), contains only common
",2
"    os.rename(filename_tmp, filename)

",2
"    Args:
        model: TensorFlow Keras model.
        optimizer: Optional optimizer, can be compiled into model instead.
        backend: For TensorFlow v1, backend used by Keras for obtaining the session.
        kwargs: Additional properties to sync, will be exposed as attributes of the object.
",2
"
parser.add_argument('--batches-per-epoch', type=int, default=10,
",2
"  assert(entries.size() == 1);
  auto e = entries[0];

  // On root rank, MPI_Bcast sends data, on other ranks it receives data.
",2
"  }

  *res = *reinterpret_cast<float const*>(&f);
}

",2
"
",2
"                if t.is_alive():
                    have_alive_child = True

        results = {}
        while not result_queue.empty():
",2
"            results = self._run(discovery_schedule, np=np, min_np=min_np, max_np=max_np)
            for result in results:
                print(result)

",2
"def spark_scalar_to_python_type(dtype):
    if dtype == IntegerType:
        return int
",2
"  RequestType_BROADCAST = 2,
  RequestType_JOIN = 3,
  RequestType_MIN = RequestType_ALLREDUCE,
",2
"        warnings.simplefilter('module')
        if _has_eager:
",2
"            optimizer, named_parameters=model.named_parameters())

",2
"                    help='learning rate for a single GPU')
parser.add_argument('--warmup-epochs', type=float, default=5,
",2
"                            ""error: %s"" % (grad_out, expected, str(err)))

    def test_horovod_allgather_cpu(self):
",2
"  tensor_sizes_ = value;
}
",2
"    to support several different implementation, but really it only needs to
    support whatever implementation we want to use for the TensorFlow test
",2
"
    VectorXd y_i(1);
",2
"
            # command fully derived from alloc_info
",2
"    def __init__(self, host_hash):
        self.host_hash = host_hash

",2
"  DataType tensor_type_ = DataType::HOROVOD_UINT8;
  std::string error_message_;
",2
"bool GlooAllgather::Enabled(const ParameterManager& param_manager,
",2
"                    keras_estimator.save(saved_path)
",2
"        known_hosts = set(host_assignment_order)
        for host in available_hosts:
            if host not in known_hosts:
                host_assignment_order.append(host)
        return host_assignment_order
",2
"  // Offset of each subcomponent of every entry in the final buffer after
  // allgatherv
",2
"            summed, = self.convert_cpu_fp16_to_fp32(summed)
",2
"        raise NotImplementedError()


class SparkBackend(Backend):
    """"""Uses `horovod.spark.run` to execute the distributed training `fn`.""""""
",2
"            rendezvous_id = self._worker_registry.record_failure(slot_info.hostname, slot_info.local_rank)

",2
"  auto size = builder.GetSize();
  output = std::string((char*) buf, size);
",2
"    }
  }

  // Copy memory out of the fusion buffer.
  if (entries.size() > 1) {
",2
"    train_df = df
    val_df = None
",2
"        resolve_host_address, args_list)

    # host_addresses is a map
    remote_host_names = []
    for i in range(len(all_host_names)):
",2
"        config.inter_op_parallelism_threads = 1
        config.intra_op_parallelism_threads = 1
",2
"                self.fc2 = torch.nn.Linear(H, D_out)
                self.fc3 = torch.nn.Linear(D_out, D_out)

",2
"        return _deserialize_keras_model(*args, **kwargs)

    @staticmethod
    def serialize_param_value(*args, **kwargs):
",2
"
#include ""ccl.h""
",2
"    return _eval(backend, hvd.allreduce(tf.constant(value, name=name), average=average))
",2
"  void ActivityStartAll(const std::vector<TensorTableEntry>& entries,
                        const std::string& activity);
  void ActivityStart(const std::string& tensor_name,
",2
"                run(fn, np=2, use_gloo=True)

        if mpi_built():
            with pytest.raises(RuntimeError, match='mpirun failed'):
",2
"#ifndef HOROVOD_GLOO_OPERATIONS_H
#define HOROVOD_GLOO_OPERATIONS_H

#include ""collective_operations.h""
",2
"  unsigned h = *src;
  int sign = ((h >> 15) & 1);
",2
"    def do_DELETE(self):
        paths = self.path.split('/')
        if len(paths) < 3:
",2
"//
// Unless required by applicable law or agreed to in writing, software
",2
"# you may not use this file except in compliance with the License.
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"
    def test_horovod_broadcast_cpu(self):
        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors on CPU.""""""
        hvd.init()
",2
"        y_dtypes, y_shapes, y_sizes = y
        dtypes = x_dtypes | y_dtypes
        shapes = x_shapes | y_shapes
        sizes = x_sizes | y_sizes
",2
"        try:
            self._driver.resume()
        except Exception:
            logging.exception('failed to activate new hosts -> stop running')
",2
"                             .format(type(validation)))
",2
"}

#if HAVE_CUDA
void DoHorovodOperationCudaOnCPU(void*, void* on_complete_ptr, void* param) {
",2
"        _set_arg_from_config(args, 'hierarchical_allgather', override_args, params)

",2
"# Create data iterator for synthetic data
class SyntheticDataIter(DataIter):
",2
"                    SparseVector(2, {1: 1.0}),
                    SparseVector(2, {1: 1.0})
                ]]
",2
"  if (reduce_op == ReduceOp::AVERAGE) {
    LOG(ERROR, horovod_global.controller->GetRank()) << ""Enqueuing AVERAGE allreduce is not allowed."";
    return status.Aborted(""AVERAGE not allowed."");
  }
  Request message;
",2
"                          timeout. The default value is 30 seconds.
                          Alternatively, The environment variable
",2
"bool GPUAllreduce::Enabled(const ParameterManager& param_manager,
",2
"
",2
"        names, tensors = zip(*params.items())
    elif isinstance(params, mx.gluon.parameter.ParameterDict):
",2
"ThreadPool::~ThreadPool() {
  reset();
}

void ThreadPool::execute(std::function<void(void)> f) {
",2
"      static const std::string unknown(""<unknown>"");
      return unknown;
  }
}
",2
"                    break
                assert max_difference_a <= threshold, 'hvd.join with hvd.allreduce produces incorrect results'
                assert max_difference_b <= threshold, 'hvd.join with hvd.allreduce produces incorrect results'
",2
"            discovery_schedule = [
",2
"
// C interface to get index of current Horovod process.
// Returns -1 if Horovod is not initialized.
int horovod_rank();
",2
"  return EnumNamesDataType()[index];
}
",2
"                self.assertEqual(name, name_after)
",2
"

",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"    num_elements += e.tensor->shape().num_elements();
  }
",2
"    return MPI_C_BOOL;
  default:
",2
"                                                name);                         \
  }

BROADCAST(torch_ByteTensor, DataType::HOROVOD_UINT8, DeviceType::CPU,
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"            if param.grad_req != 'null':
                allreduce_(param.list_grad()[0], average=False,
                           name=param.name, priority=-i)

",2
"        key = secret.make_secret_key()
        service_name = 'test-service'
        service = BasicTaskService(service_name, key, nics=None, verbose=2)
",2
"    def setOptimizer(self, value):
        return self._set(optimizer=value)

    def getOptimizer(self):
",2
"    Supports standalone `keras` and `tf.keras`, and TensorFlow 1.X and 2.X.
",2
"        host_manager.update_available_hosts()

        # First, check that nothing changed with our existing object, which is immutable
        assert current_hosts.available_hosts == set()
",2
"        try:
            output = hvd.allreduce(tensor)
            output.wait_to_read()
            assert False, 'hvd.allreduce did not throw cpu-gpu error'
",2
"                'third_party/eigen',
                'third_party/flatbuffers/include',
",2
"                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"import shutil
import tempfile

import pyarrow as pa
import pyarrow.parquet as pq
",2
"}
#endif

",2
"    :param args: function arguments
    :param stop: event to stop thread
    :type stop: threading.Event
    :param check_interval_seconds: interval in seconds to check the stop event
    :type check_interval_seconds: float
",2
"
class FakeEvent(object):
    def wait(self):
",2
"    for symbol in dir(_lib):
        fn = getattr(_lib, symbol)
        if callable(fn):
",2
"    parser.add_argument('--network-interface', action='store', dest='nics',
                        help='Network interfaces that can be used for communication separated by '
                             'comma. If not specified, Horovod will find the common NICs among all '
                             'the workers and use it; example, --network-interface ""eth0,eth1"".')

",2
"    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"
    if rank < min_np:
        raise ValueError('Requested more processes ({}) than there are available slots ({})'
                         .format(min_np, rank))
",2
"
            def forward(self, x):
                x = x.cuda(local_rank)
                x = self.conv1(x)
                x = x.cuda(local_rank)
",2
"                self.assertAllClose(w1, w2)
            assert state.batch == 20
            assert state.epoch == 10

",2
"                'Horovod has not been initialized; use hvd.init().')
        return local_size

",2
"
",2
"  std::shared_ptr<Tensor> hvd_output = nullptr;
  if (horovod_rank() == root_rank) {
    if (tensor != output) {
",2
"

",2
"

",2
"    elif dtype == BinaryType:
        return 'Binary'
",2
"
    def synchronize(self):
",2
"        probs = model(data, training=True)
        loss = tf.losses.categorical_crossentropy(target, probs)
",2
"    variables that contain the rank and size of the MPI_COMM_WORLD
    communicator. We can read those environment variables from Python in order
    to ensure that `hvd.rank()` and `hvd.size()` return the expected values.

",2
"        'rank': hvd.rank(),
",2
"    bnormsq = 0.;

    for (int i = 0; i < count; i++) {
      dotProduct += (double)a[i] * (double)b[i];
",2
"                                                                               \
  template <>                                                                  \
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"                K.set_session(sess)

                model = create_model()

                x = np.random.random((1, 3))
",2
"import unittest
",2
"  // Pointer to shared buffer for allgather
  void* shared_buffer = nullptr;

  // Current shared buffer size
",2
"        cuda_test_ext = create_extension(
            name='horovod.torch.test_cuda',
            headers=['horovod/torch/dummy.h'],
            sources=[],
",2
"        :type delay: float
",2
"    for (int i = 1; i < e.tensor->shape().dims(); ++i) {
      single_slice_shape.AddDim(e.tensor->shape().dim_size(i));
    }

    // Copy tensor sizes from the response into a vector of int64_t
",2
"            optimizer = model.optimizer

        if not optimizer:
",2
"  if (device_ == CPU_DEVICE_ID) {
",2
"  Status Execute(std::vector<TensorTableEntry>& entries, const Response& response) override;

  bool Enabled(const ParameterManager& param_manager,
               const std::vector<TensorTableEntry>& entries,
",2
"
    if (global_state_->timeline.Initialized()) {
      gpu_context_->RecordEvent(gpu_op_context_.event_queue, MEMCPY_IN_FUSION_BUFFER, *gpu_op_context_.stream);
    }
",2
"            continue
        for addr in addrs:
            if addr.family == AF_INET and addr.address == '127.0.0.1':
                common_intfs.add(iface)
                break
",2
"    elapsed = add_elapsed(train_df.select('Date', 'Store', *elapsed_cols)
                          .unionAll(test_df.select('Date', 'Store', *elapsed_cols)),
                          elapsed_cols)

",2
"    """"""
    Loads a saved Keras model with a Horovod DistributedOptimizer.

    The DistributedOptimizer will wrap the underlying optimizer used to train
",2
"    warmup_remaining_(warmups_),
    sample_(0),
    rank_(-1),
    root_rank_(0),
    writing_(false) {
",2
"            {
                'float': {
                    'spark_data_type': FloatType,
                    'is_sparse_vector_only': False,
",2
"    }

    for (unsigned int i = 1; i < requests.size(); ++i) {
      if (error) {
",2
"    .. warning::
        :class:'ImageChunkCrafter' is intended to be used internally.
",3
"_SPAWNREQUEST_PEASPAWNREQUEST = _descriptor.Descriptor(
  name='PeaSpawnRequest',
",3
"
_random_names = (('first', 'great', 'local', 'small', 'right', 'large', 'young', 'early', 'major', 'clear', 'black',
                  'whole', 'third', 'white', 'short', 'human', 'royal', 'wrong', 'legal', 'final', 'close', 'total',
                  'prime', 'happy', 'sorry', 'basic', 'aware', 'ready', 'green', 'heavy', 'extra', 'civil', 'chief',
                  'usual', 'front', 'fresh', 'joint', 'alone', 'rural', 'light', 'equal', 'quiet', 'quick', 'daily',
",3
"        # first scan, find if external modules are specified
",3
"import unittest

import numpy as np

from jina.executors import BaseExecutor
",3
"        getattr(req, self.body_tag).args.extend(kwargs2list(vars(self.args)))
",3
"        self.add_tmpfile(indexer.save_abspath, indexer.index_abspath)

",3
"
    def __init__(self, executor: str = None, method: str = 'craft', *args, **kwargs):
        super().__init__(executor, method, *args, **kwargs)
",3
"
from jina.drivers import BaseDriver
from jina.drivers.control import ControlReqDriver
",3
"
                def sayB(self):
                    print('B: im B')
",3
"            if self.is_trained:
                return func(self, *args, **kwargs)
            else:
",3
"            ``ernie``, ``ernie_tiny``, ``ernie_v2_eng_base``, ``ernie_v2_eng_large``,
",3
"if False:
    from ..drivers import BaseDriver
",3
"def _fill_in_host(bind_args, connect_args):
    from sys import platform

    bind_local = (bind_args.host == '0.0.0.0')
    bind_docker = (bind_args.image is not None and bind_args.image)
",3
"from jina.executors.encoders.nlp.flair import FlairTextEncoder
from tests.executors.encoders.nlp import NlpTestCase

",3
"                for _ in range(10):
                    yield b'abcdfeg'   # each yield generates a document for training

            with f.build(runtime='thread') as flow:
                flow.train(bytes_gen=my_reader())
",3
"    """"""Start a client connects to the gateway""""""
    from ..clients.python import PyClient
    PyClient(args)

",3
"        return img
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"    def attach(self, executor: 'AnyExecutor', *args, **kwargs):
        """"""Attach the driver to a :class:`jina.executors.BaseExecutor`""""""
        super().attach(*args, **kwargs)
        if self._executor_name and isinstance(executor, CompoundExecutor):
",3
"    if socket_type == SocketType.DEALER_CONNECT:
        sock.set_string(zmq.IDENTITY, identity)

    # if not socket_type.is_pubsub:
    #     sock.hwm = int(os.environ.get('JINA_SOCKET_HWM', 1))
",3
"        return np.split(_sorted_m, np.cumsum(_doc_counts))[:-1]

",3
"        'Development Status :: 5 - Production/Stable',
        'Intended Audience :: Developers',
        'Intended Audience :: Education',
        'Intended Audience :: Science/Research',
        'Programming Language :: Python :: 3.7',
",3
"    _descriptor.FieldDescriptor(
      name='flush', full_name='jina.Request.TrainRequest.flush', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
",3
"
    def attach(self, executor: 'AnyExecutor', *args, **kwargs):
        """"""Attach the driver to a :class:`jina.executors.BaseExecutor`""""""
        super().attach(*args, **kwargs)
        if self._executor_name and isinstance(executor, CompoundExecutor):
",3
"
",3
"
",3
"
    :param sock: the socket to pull from
",3
"                                     timeout=self.args.timeout_ctrl)

    @property
",3
"                self.assertTrue(hasattr(d.match_doc, 'weight'))
                self.assertIsNotNone(d.match_doc.weight)
                self.assertEqual(d.match_doc.meta_info, b'hello world')

        f = Flow().add(name='doc_pb', yaml_path='yaml/test-docpb.yml', replicas=replicas, separated_workspace=True)
",3
"    return x.reshape(blob.shape)

",3
"        for resp in self._stub.Call(req_gen()):
            self.logger.info(resp)
            return True

",3
"        """"""Gracefully close this pea and release all resources """"""
        if self.is_ready.is_set() and hasattr(self, 'ctrl_addr'):
            return send_ctrl_message(self.ctrl_addr, jina_pb2.Request.ControlRequest.TERMINATE,
",3
"  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
",3
"        if data._kwargs:
            r['with'] = data._kwargs

        if data._pod_nodes:
            r['pods'] = {}
",3
"        os.environ['JINA_CONTRIB_MODULE_IS_LOADING'] = 'true'

        modules = []
",3
"    def __init__(self,
",3
"

if __name__ == '__main__':
",3
"            ['--host', 'localhost', '--replicas', '3',
",3
"    def test_logging_message(self):
        os.environ['JINA_LOG_VERBOSITY'] = 'success'
",3
"        return tensor.cpu().numpy() if self.on_gpu else tensor.numpy()
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import numpy as np
",3
"            raise ValueError('target_size should be an integer or a tuple of two integers: {}'.format(target_size))
        w_beg = left
",3
"class RemotePea(BasePea):
",3
"            content['mode'] = ClientMode.from_string(mode)
",3
"    def start_section(self, heading):
        self._indent()
        section = self._Section(self, self._current_section, heading)
        self._add_item(section.format_help, [])
",3
"            for c in self.components:
                if c.name == item:
                    return c
        else:
            raise TypeError('CompoundExecutor only supports int or string index')
",3
"                            setattr(c, k, v)
                    c.length = len(ret)
                    c.chunk_id = self.first_chunk_id if not self.random_chunk_id else random.randint(0, ctypes.c_uint(
                        -1).value)
                    c.doc_id = d.doc_id
",3
"                for c in d.chunks:
                    for k in self.pruned:
                        c.ClearField(k)
",3
"    from . import default_logger

    @wraps(func)
    def arg_wrapper(*args, **kwargs):
",3
"    parser.add_argument('--refresh-time', type=int,
                        default=5,
                        help='refresh time interval in seconds, set to -1 to persist all grouped logs')
    return parser
",3
"        _center = self._crop_image(raw_img, self.target_size, how='center')
        center = self.restore_channel_axis(np.asarray(_center))
",3
"            kwargs.update(v._kwargs)

",3
"                self.logger.warning(
",3
"
def export_api(args):
",3
"                 b'tokenized in 2 sentences.'
        crafted_chunk_list = sentencizer.craft(buffer, 0)
        self.assertEqual(len(crafted_chunk_list), 2)
",3
"            first.tail_args.host_out = _fill_in_host(connect_args=first.tail_args,
",3
"        # reset the build level to the lowest
        op_flow._build_level = FlowBuildLevel.EMPTY

        return op_flow

",3
"        return [p.status for p in self.peas]

",3
"            self.assertEqual(f1.num_peas, 6)
            t1 = mp.Process(target=start_client, args=(f1,))
",3
"                     ctrl_with_ipc=True,  # otherwise ctrl port would be conflicted
                     read_only=True)
    gp1.add_argument('--prefetch', type=int, default=50,
                     help='the number of pre-fetched requests from the client')
",3
"  'Route' : _reflection.GeneratedProtocolMessageType('Route', (_message.Message,), {
    'DESCRIPTOR' : _ENVELOPE_ROUTE,
",3
"                    help += colored(' (type: %(type)s; default: %(default)s)', attrs=['dark'])
        return help

    def _get_default_metavar_for_optional(self, action):
",3
"class SchedulerType(BetterEnum):
    LOAD_BALANCE = 0  #: balance the workload between Peas, faster peas get more work
    ROUND_ROBIN = 1  #: workload are scheduled round-robin manner to the peas, assuming all peas have uniform processing speed.


",3
"                             'If you really want to save it, call ""touch()"" before ""save()"" to force saving')
            return False
",3
"
class NoIdleDealer(Exception):
    """"""All dealers are exhausted no more idle dealer""""""
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"from ...decorators import batching, as_ndarray


class OnnxImageEncoder(BaseOnnxEncoder):
",3
"        self.required_keys = {k for k in inspect.getfullargspec(self.craft).args if k != 'self'}
        if not self.required_keys:
            self.logger.warning(f'{self.__class__} works on keys, but no keys are specified')
",3
"        elif self.level == 'chunk':
",3
"            self.logger.error('zmqlet can not be initiated')
        except Exception as ex:
            self.logger.error('unknown exception: %s' % str(ex), exc_info=True)
        finally:
",3
"    @property
    def model(self):
        if self._model is None:
            self._model = self.get_model()
",3
"                else:
",3
"        json.dump(obj, self.write_handler)
        self.write_handler.write('\n')
",3
"        as the naive ``document-frequency``. Please refer to the functions for the details of calculating ``tf`` and
        ``idf``.
    """"""
",3
"        if not self.num_dim:
            self.num_dim = vectors.shape[1]
            self.dtype = vectors.dtype.name
        elif self.num_dim != vectors.shape[1]:
            raise ValueError(
",3
"            np.testing.assert_almost_equal(retr_idx, idx)
        self.assertEqual(idx.shape, dist.shape)
        self.assertEqual(idx.shape, (10, 4))
",3
"    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
",3
"                        FlowPod.connect(s_pod, e_pod, first_socket_type=SocketType.PUSH_BIND)
                else:
",3
"        if self._args.replicas > 1 and self.is_head_router:
",3
"                self.logger.debug('executor is not saved as ""read_only"" is set to true for this BasePea')
            elif not hasattr(self, 'executor'):
",3
"        return True

",3
"To use these enums in YAML config, following the example below:

",3
"    '__module__' : 'jina_pb2'
    # @@protoc_insertion_point(class_scope:jina.Request.SearchRequest)
    })
",3
"
    def test_remote_pod(self):
        f_args = set_gateway_parser().parse_args(['--allow-spawn'])
        p_args = set_pod_parser().parse_args(
",3
"    """"""
",3
"    return args

",3
"#         parser = set_base_parser()
#     set_pod_parser(parser)
",3
"            f_name = (jp % __version__) if '%s' in jp else jp
            import json
            with open(f_name, 'w', encoding='utf8') as fp:
",3
"                pass

    is equal to
",3
"
    def train(self, *args, **kwargs):
",3
"        return op_flow

",3
"  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
",3
"    """"""

",3
"                self.pea.zmqlet.resume_pollin()
                self.is_pollin_paused = False
            raise NoExplicitMessage
        else:
",3
"      name='description', full_name='jina.ScoredResult.Score.description', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
",3
"class MyTestCase(RankerTestCase):
",3
"
    @classmethod
",3
"
    .. warning::
        This driver loops over all chunk/chunk's top-K results, each step fires a query.
        This may not be very efficient, as the total number of queries depends on ``level``

",3
"
",3
"                     help='the strategy of scheduling workload among peas')
    gp4.add_argument('--reducing-yaml-path', type=str, default='_forward',
                     help='the executor used for reducing the result from all replicas, '
",3
"
from .zmq import send_ctrl_message, Zmqlet
from .. import __ready_msg__, __stop_msg__
from ..drivers.helper import routes2str, add_route
from ..enums import PeaRoleType
",3
"        self.tmp_files.append(a.config_abspath)
        a.touch()
        a.save()
",3
"from jina.helper import yaml, expand_dict
from jina.main.parser import set_pea_parser
from jina.peapods.pea import BasePea
from tests import JinaTestCase
",3
"        for k, v in data_dict.items():
            request.inputs[k].CopyFrom(tf.make_tensor_proto(v))
",3
"
        def validate(req):
            self.assertEqual(len(req.docs), 1)
",3
"            'bert-base-uncased': TFBertModel,
",3
"
        This returns ``None`` when ``num_part=1``.
        """"""
        return self.pea.prev_requests
",3
"def random_docs(num_docs, chunks_per_doc=5, embed_dim=10):
    c_id = 0
    for j in range(num_docs):
",3
"    def get_add_handler(self):
",3
"                    except (ImportError, ModuleNotFoundError):
",3
"            if args.name:
",3
"            strategies include ``mean``, ``min``, ``max``.
        """"""
        super().__init__(*args, **kwargs)
        self.embeddings = embeddings
        self.pooling_strategy = pooling_strategy
",3
"
    gp5 = add_arg_group(parser, 'pea messaging arguments')
    gp5.add_argument('--check-version', action='store_true', default=False,
                     help='comparing the jina and proto version of incoming message with local setup, '
                          'mismatch raise an exception')
",3
")

_SPAWNREQUEST_MUTABLEPODSPAWNREQUEST = _descriptor.Descriptor(
  name='MutablepodSpawnRequest',
",3
"        return
    if isinstance(data, np.ndarray):
",3
"    r.pod = pod_name
    r.start_time.GetCurrentTime()
    r.pod_id = identity
",3
"        if color:
            text = fmt_str % (_COLORS[color], text)

        if on_color:
            text = fmt_str % (_HIGHLIGHTS[on_color], text)
",3
"
",3
"
class BaseCraftDriver(BaseExecutableDriver):
    """"""Drivers inherited from this Driver will bind :meth:`craft` by default """"""
",3
"            return jsonify({'reason': reason}), code

        @app.route('/ready')
        @cross_origin()
        def is_ready():
",3
"                f'and will be removed in the next version; please use ""{new}"" instead')
            kwargs[new] = kwargs.pop(alias)


",3
"                return http_error('""data"" field is empty', 406)

",3
"      name='jina', full_name='jina.Envelope.Version.jina', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""".decode('utf-8'),
",3
"                do_busy()
",3
"            dict(doc_id=doc_id, offset=0, weight=1., blob=bl.astype('float32')),
            dict(doc_id=doc_id, offset=0, weight=1., blob=br.astype('float32')),
            dict(doc_id=doc_id, offset=0, weight=1., blob=center.astype('float32')),
        ]

",3
"      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"    def post_init(self):
        """"""
        Initialize class attributes/members that can/should not be (de)serialized in standard way.

",3
"                    c['doc_id'],
                    c['chunk_id'],
                    query_chunk_id,
",3
"        default_logger.error(ex)
",3
"              with:
                executor: BaseVectorIndexer
            - !PruneDriver
",3
"        for v in self._drivers.values():
            for d in v:
                d.attach(executor=self, *args, **kwargs)

",3
"        return dict(doc_id=doc_id, offset=0, weight=1., blob=img.astype('float32'))


",3
"from pathlib import Path
from types import SimpleNamespace
from typing import Dict, Any, Union, TypeVar, Type, TextIO, List

import ruamel.yaml.constructor
",3
"
class BasePea(metaclass=PeaMeta):
",3
"            with f.build(runtime='thread') as flow:
                flow.search(txt_file='aa.txt')
                flow.search(image_zip_file='aa.zip', batch_size=64)
",3
"        super().__init__(*args, **kwargs)
        self.level = level

    def __call__(self, *args, **kwargs):
",3
"        if self._tensor_func is None:
            self._tensor_func = self.get_tensor_func()
",3
"        with f:
            a = requests.post(f'http://0.0.0.0:{f.port_grpc}/api/index',
                              json={'data': [
                                  'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAIAAABLbSncAAAA2ElEQVR4nADIADf/AxWcWRUeCEeBO68T3u1qLWarHqMaxDnxhAEaLh0Ssu6ZGfnKcjP4CeDLoJok3o4aOPYAJocsjktZfo4Z7Q/WR1UTgppAAdguAhR+AUm9AnqRH2jgdBZ0R+kKxAFoAME32BL7fwQbcLzhw+dXMmY9BS9K8EarXyWLH8VYK1MACkxlLTY4Eh69XfjpROqjE7P0AeBx6DGmA8/lRRlTCmPkL196pC0aWBkVs2wyjqb/LABVYL8Xgeomjl3VtEMxAeaUrGvnIawVh/oBAAD///GwU6v3yCoVAAAAAElFTkSuQmCC',
",3
"    gp1.add_argument('--allow-spawn', action='store_true', default=False,
                     help='accept the spawn requests sent from other remote Jina')
    gp1.add_argument('--rest-api', action='store_true', default=False,
                     help='use REST-API as the interface instead of gRPC with port number '
",3
"if __name__ == '__main__':
    unittest.main()
import unittest
",3
"    np.random.seed(531)

    err = 0
",3
"    msg = jina_pb2.Message()

    num_bytes = sum(sys.getsizeof(m) for m in msg_data)

",3
"      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"        help = action.help
",3
"        """"""
        return self.get_file_from_workspace(self.index_filename)

    @property
    def query_handler(self):
",3
"
class MyTestCase(NlpTestCase):
    def _get_encoder(self, metas):
        return FlairTextEncoder(embeddings=('word:glove',), pooling_strategy='mean', metas=metas)
",3
"             )

        with f:
            f.index(input_fn=random_docs(10), input_type=ClientInputType.PROTOBUF)

",3
"    nB = B.shape[0]
    B_ext = np.ones((dim * 3, nB))
    B_ext[:dim] = (B ** 2).T
    B_ext[dim:2 * dim] = -2.0 * B.T
    return A_ext, B_ext
",3
"                                 'ip and grpc port number of the server'
                                 % (args.host, args.port_grpc, args.timeout_ready))
            raise GRPCServerError('can not connect to the server at %s:%d' % (args.host, args.port_grpc))

",3
"    EMPTY = 0  #: Nothing is built
",3
"        p = {k: getattr(data, k) for k, v in _defaults.items() if getattr(data, k) != v}
        a = {k: v for k, v in data._init_kwargs_dict.items() if k not in _defaults}
        r = {}
        if a:
",3
"                else:
                    ddd['type'] = a.type
                if ddd['choices']:
                    ddd['choices'] = [str(k) if isinstance(k, BetterEnum) else k for k in ddd['choices']]
",3
"

def get_tags_from_node(node) -> List[str]:
    """"""Traverse the YAML by node and return all tags
",3
"        # self.assertRaises(TypeError, PyClient.check_input, bad_input_fn)
",3
"        try:
",3
"    'jina_pb2.Message', int]:
    """""" Receive a protobuf message from a socket in async manner
",3
"class MyTestCase(RankerTestCase):
    def __init__(self, *args, **kwargs):
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import numpy as np
",3
"                _head_args.yaml_path = '_route'
    else:
        _head_args.socket_out = SocketType.PUB_BIND
        if as_router:
",3
"__license__ = ""Apache-2.0""

import numpy as np

",3
"        call_obj_fn(self._write_handler, 'close')
        call_obj_fn(self._query_handler, 'close')
",3
"    return colored('', 'green').join(route_str)


def add_route(evlp: 'jina_pb2.Envelope', name: str, identity: str) -> None:
",3
"        """"""
        Initialize an NmslibIndexer

",3
"                import lz4
                self.logger.success(f'compression is enabled and the high watermark is {args.compress_hwm} bytes')
            except ModuleNotFoundError:
",3
"import re
import sys
from copy import copy
from logging import Formatter
from logging.handlers import QueueHandler
",3
"            # no batching if b_size is None
",3
"

class PeaSpawnHelper(GrpcClient):
    body_tag = 'pea'

",3
"from typing import Dict, List

_defaults = {}

",3
"    n = np.array(n)
    # each chunk should return a list of top-100
    np.testing.assert_equal(n.shape[0], 5)
    np.testing.assert_equal(n.shape[1], 100)

",3
"
",3
"    _tail_args.port_ctrl = random_port()
",3
"        if self._query_handler is None:
            self.logger.warning(f'you can not query from {self} as its ""query_handler"" is not set. '
                                'If you are indexing data from scratch then it is fine. '
                                'If you are querying data then the index file must be empty or broken.')
        return self._query_handler
",3
"    def request(self) -> 'jina_pb2.Request':
        """"""Get the current request body inside the protobuf message""""""
        return self._request
",3
"                          'only effective when BasePod\'s `replicas` > 1')
",3
"

def random_docs():
    c_id = 0
",3
"    from ..helper import random_port, get_random_identity
    from .. import __default_host__
    import os
    if not parser:
        parser = set_base_parser()
",3
"

def clear_queue():
    """"""Clear the log queue and profile queue when the program exit

",3
"        if isinstance(self._args, argparse.Namespace) and getattr(self._args, 'shutdown_idle', False):
            self.sentinel_threads.append(Thread(target=self.close_if_idle,
",3
"  oneofs=[
  ],
  serialized_start=2100,
  serialized_end=2143,
)
",3
"    def get_output(self, response: grpc.UnaryUnaryMultiCallable):
        """"""
        Postprocess the response from the tf server
        """"""
",3
"  extensions=[
  ],
  nested_types=[],
  enum_types=[
",3
"        kwargs.update(op_flow._common_kwargs)
        kwargs['name'] = pod_name
        kwargs['num_part'] = len(needs)
",3
"
    For more information about the Faiss supported parameters and installation problems, please consult:
        - https://github.com/spotify/annoy
",3
"    def start(self):
        if self._args.host == __default_host__:
",3
"        :param kwargs:
        """"""
",3
"        else:
            raise TypeError(f'level={self.level} is not supported, must choose from ""chunk"" or ""doc"" ')

        super().__call__(*args, **kwargs)
",3
"
",3
"
    @staticmethod
",3
"    Internally, :class:`KerasImageEncoder` wraps the models from `tensorflow.keras.applications`.
",3
"from ..logging.base import get_logger
from ..logging.profile import TimeContext
",3
"    def __init__(self):
        self.accum_time = defaultdict(float)
        self.first_start_time = defaultdict(float)
        self.start_time = defaultdict(float)
",3
"    def from_yaml(cls, constructor, node):
",3
"
    def __init__(self, *args, **kwargs):
        """"""

        :param model_name: the name of the model. Supported models include
",3
"_sym_db.RegisterMessage(SpawnRequest.MutablepodSpawnRequest)


_REQUEST_CONTROLREQUEST_ARGSENTRY._options = None
",3
"             'source': 'https://github.com/jina-ai/jina/tree/' + os.environ.get('JINA_VCS_VERSION', 'master'),
",3
"
",3
"      type=None),
    _descriptor.EnumValueDescriptor(
",3
"            msg.request.control.command = jina_pb2.Request.ControlRequest.IDLE
        else:
            req = jina_pb2.Request()
            req.control.command = jina_pb2.Request.ControlRequest.IDLE
",3
"        self.is_closed = False

",3
"            cls.init_from_yaml = True

            if cls.store_args_kwargs:
                p = data.get('with', {})  # type: Dict[str, Any]
                a = p.pop('args') if 'args' in p else ()
",3
"        if self.args.yaml_path:
            try:
                self.executor = BaseExecutor.load_config(self.args.yaml_path,
",3
"
        :return: a paired
",3
"      name='scale', full_name='jina.NdArray.scale', index=6,
      number=7, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
",3
"    @property
    def is_shutdown(self) -> bool:
        return all(not p.is_ready.is_set() for p in self.peas)
",3
"                 the matched chunks.
        """"""
        _q_df, _q_id = self._get_df(match_idx)
        _total_df = np.sum(_q_df)
        return {idx: np.log10((_total_df + 1.) / (df + 0.5)) ** 2 for idx, df in zip(_q_id, _q_df)}
",3
"            (
",3
"                raise FlowTopologyError('found %d edges start with %s and %d edges end with %s, '
                                        'this type of topology is ambiguous and should not exist, '
                                        'i can not determine the socket type' % (
                                            len(edges_with_same_start), s_name, len(edges_with_same_end), e_name))
",3
"if False:
    # fix type-hint complain for sphinx and flake
",3
"        kwargs.update(default_kwargs)
        super().__init__(*args, **kwargs)


@unittest.skip('add grpc mocking for this test')
",3
"    def clear_stats(self):
        """"""Reset the internal counter of send and receive bytes to zero. """"""
        self.bytes_recv = 0
        self.bytes_sent = 0
",3
"      name='TERMINATE', index=0, number=0,
      serialized_options=None,
      type=None),
",3
"            self.envelope.status = jina_pb2.Envelope.SUCCESS
            raise RequestLoopEnd
        elif self.req.command == jina_pb2.Request.ControlRequest.STATUS:
            self.envelope.status = jina_pb2.Envelope.READY
",3
"        return 'Server shutting down...'
",3
"import unittest
from pathlib import Path

from jina.clients import py_client
from jina.flow import Flow
",3
"        """"""
        r = np.array(r, dtype=np.float64)
        r = r[r[:, -1].argsort()[::-1]]
",3
"def profiling(func):
    """"""Decorator to mark a function for profiling. The time and memory usage will be recorded and printed.

    Example:

",3
"                else:
                    raise UnattachedDriver(d)
        else:
",3
"

def hello_world(args):
",3
".. highlight:: yaml
.. code-block:: yaml

",3
"import signal

signal.signal(signal.SIGINT, signal.default_int_handler)

",3
"
        self.assertTrue(isinstance(b, KVSearchDriver))
        self.assertEqual(b._executor_name, a[0]._executor_name)

        self.add_tmpfile('test_driver.yml')
",3
"        """"""Required by :mod:`ruamel.yaml.constructor` """"""
        return representer.represent_scalar('!' + cls.__name__, str(data))
",3
"            SocketType.PUSH_BIND: SocketType.PULL_CONNECT,
            SocketType.PUB_CONNECT: SocketType.SUB_BIND,
            SocketType.PUB_BIND: SocketType.SUB_CONNECT,
            SocketType.PAIR_CONNECT: SocketType.PAIR_BIND
",3
"import os
import unittest
",3
"        FlowPod.__init__(self, kwargs, needs, parser=set_gateway_parser)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import argparse
",3
"    mask = np.rollaxis(mask, 0, 3)
    output = mask * data
    neg_mask = (mask_2d - 1) * (-1e10)
",3
"        """"""
        self.peas = []
",3
"        self.width = width

    def craft(self, blob: 'np.ndarray', chunk_id, doc_id, *args, **kwargs) -> Dict:
",3
"        output_dim = 20
",3
"
    @staticmethod
",3
"
from . import Pea
from .gateway import GatewayPea, RESTGatewayPea
from .pea import BasePea
",3
"
from typing import Tuple
",3
"        self.cls_pos = 'tail' if self.model_name == 'xlnet-base-cased' else 'head'
",3
"    def dry_run(self, **kwargs):
",3
"        :param compress_level: The compresslevel argument is an integer from 0 to 9 controlling the
                        level of compression; 1 is fastest and produces the least compression,
                        and 9 is slowest and produces the most compression. 0 is no compression
",3
"                     ('grpc.max_receive_message_length', self.args.max_message_size)])

        m = PathImporter.add_modules(self.args.pb2_path, self.args.pb2_grpc_path)

        # build stub
",3
"    def test_flow_topo_replicas(self):
        f = (Flow()
             .add(name='d1', image='jinaai/jina:devel', entrypoint='jina pod', yaml_path='_forward', replicas=3)
             .add(name='d2', yaml_path='_forward', replicas=3)
",3
"
",3
"      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
",3
"
class BaseTFServingClientEncoder(BaseTFServingClientExecutor, BaseEncoder):
    """"""
    :class:`BaseTFServingEncoder` is the base class for the encoders that wrap up a tf serving client. The client call
",3
"    def load_config(cls: Type[AnyExecutor], filename: Union[str, TextIO], separated_workspace: bool = False,
                    replica_id: int = 0) -> AnyExecutor:
        """"""Build an executor from a YAML file.

        :param filename: the file path of the YAML file or a ``TextIO`` stream to be loaded from
",3
"        from flask import Flask, Response, jsonify
        from flask_cors import CORS
    except ImportError:
        raise ImportError('Flask or its dependencies are not fully installed, '
                          'they are required for serving HTTP requests.'
",3
"            ``NASNetLarge``, ``NASNetMobile``,
            ``ResNet101``, ``ResNet152``, ``ResNet50``, ``ResNet101V2``, ``ResNet152V2``, ``ResNet50V2``,
            ``VGG16``, ``VGG19``,
",3
"async def send_message_async(sock: 'zmq.Socket', msg: 'jina_pb2.Message', timeout: int = -1,
                             array_in_pb: bool = False, compress_hwm: int = -1, compress_lwm: float = 1.,
                             **kwargs) -> int:
    """"""Send a protobuf message to a socket in async manner

",3
"import random
import re
",3
"
# some variables may be self-referred and they must be resolved at here
_ref_desolve_map = SimpleNamespace()
_ref_desolve_map.__dict__['metas'] = SimpleNamespace()
_ref_desolve_map.__dict__['metas'].__dict__['replica_id'] = 0
",3
"        self.extraction_strategy = extraction_strategy
        self.extraction_layer = extraction_layer

",3
"    :param msg: the protobuf message
    :param timeout: waiting time (in seconds) for sending
",3
"                endpoint = []
",3
"            raise ValueError('target_size should be an integer or a tuple of two integers: {}'.format(self.target_size))
        _tl = self._crop_image(raw_img, self.target_size, 0, 0)
        tl = self.restore_channel_axis(np.asarray(_tl))
        _tr = self._crop_image(raw_img, self.target_size, image_width - target_w, 0)
        tr = self.restore_channel_axis(np.asarray(_tr))
",3
"        if self.num_docs > 0:
",3
"
class SlidingWindowImageCropper(ImageChunkCrafter):
    """"""
    :class:`SlidingWindowImageCropper` crops the image with a sliding window.
",3
"
",3
"from tests.executors.encoders.video import VideoTestCase


class MyTestCase(VideoTestCase):
    def _get_encoder(self, metas):
",3
"        logger.warning('warn, warn, warn')
        time.sleep(.1)
",3
"            for c in self.components:
                c.close()

    @classmethod
",3
"        if not filename: raise FileNotFoundError
        try:
            with open(filename, 'rb') as fp:
                return pickle.load(fp)
",3
"from .queue import __sse_queue__, __profile_queue__
from .. import JINA_GLOBAL, __version__
",3
"if __name__ == '__main__':
    unittest.main()
",3
"    A :class:`BaseDriver` needs to be :attr:`attached` to a :class:`jina.peapods.pea.BasePea` before using. This is done by
    :func:`attach`. Note that a deserialized :class:`BaseDriver` from file is always unattached.
    """"""
",3
"    @property
    def status(self):
",3
"

class FlowOutputType(BetterEnum):
    """"""The enum for representing flow output config """"""
",3
"    def _set_comp_workspace(self):
",3
"            reg_cls_set.add(cls.__name__)
            setattr(cls, '_registered_class', reg_cls_set)
",3
"        # dealer consumes the first part of the message as id, we need to prepend it back
        msg_data = [' '] + msg_data
    elif sock.type == zmq.ROUTER:
        # the router appends dealer id when receive it, we need to remove it
",3
"        return np.array(response.result().outputs[self.output_name].float_val)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"import sys
import unittest
from os.path import dirname


",3
"
    def test_scipy_indexer(self):
        a = NumpyIndexer(index_filename='np.test.gz', backend='scipy')
        a.add(vec_idx, vec)
        a.save()
",3
"                 output_feature: str = None,
                 pool_strategy: str = None,
",3
"            self.bytes_recv += num_bytes
            self.msg_recv += 1
            if callback:
                return callback(msg)

",3
"        self.space = dist_calc_method
        self.num_threads = num_threads

    def get_query_handler(self):
",3
"def random_docs(num_docs, chunks_per_doc=5, embed_dim=10):
    c_id = 0
    for j in range(num_docs):
",3
"    :param docs: an iterable of protobuf documents
    :param embedding: an indicator of extracting embedding or not.
                    If ``True`` then all chunk-level embedding are extracted.
",3
"
",3
"            c = d.chunks.add()
            c.embedding.CopyFrom(array2pb(np.random.random([embed_dim])))
",3
"      name='body', full_name='jina.SpawnRequest.body',
",3
"    .. highlight:: python
    .. code-block:: python

        from jina.clients import py_client

",3
"    return base64.b64encode(png_bytes)


def input_fn(fp, index=True, num_doc=None):
",3
"              output_fn: Callable[['jina_pb2.Message'], None] = None,
              **kwargs):
        """"""Do indexing on the current flow

        Example,
",3
"        def bytes_fn():
",3
"  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
",3
"    def current_workspace(self) -> str:
        """""" Get the path of the current workspace.

",3
"                for idx in data:
                    data_encoded, *_ = self.model.run(
                        [self.outputs_name, ], {self.inputs_name: data})
",3
"        self.channel = grpc.insecure_channel(
            '%s:%s' % (self.args.host, self.args.port_grpc),
            options=[('grpc.max_send_message_length', self.args.max_message_size),
",3
"if __name__ == '__main__':
    unittest.main()
",3
"        return ImageTorchEncoder(metas=metas)
",3
"            serialized_response = _server._serialize_response(
                rpc_event, state, response, response_serializer)
            if serialized_response is not None:
                _server._status(rpc_event, state, serialized_response)

",3
"        self._timer = TimeDict()

        self._request = None
        self._message = None
        self._prev_requests = None
",3
"        model_dict = {
            'bert-base-uncased': BertModel,
            'openai-gpt': OpenAIGPTModel,
            'gpt2': GPT2Model,
            'xlnet-base-cased': XLNetModel,
",3
"        return representer.represent_mapping('!' + cls.__name__, tmp)

    @staticmethod
    def _dump_instance_to_yaml(data):
",3
"import json
from typing import Union

from google.protobuf.json_format import Parse
",3
"import numbers
",3
"        a = match_idx[match_idx[:, self.col_query_chunk_id].argsort()]
        q_id, q_df = np.unique(a[:, self.col_query_chunk_id], return_counts=True)
        return q_df, q_id

    def _get_tf(self, match_idx):
",3
"                d.attach(executor=self, *args, **kwargs)

    def __call__(self, req_type, *args, **kwargs):
        if req_type in self._drivers:
            for d in self._drivers[req_type]:
",3
"
",3
"
    .. highlight:: python
    .. code-block:: python

        class DummyTransformer(BaseDocCrafter):
",3
"            stream.close()
        };

    """"""
    try:
",3
"      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
",3
"        self.timeout = timeout if timeout >= 0 else 200


class BaseTFServingClientExecutor(BaseClientExecutor):
",3
"                        try:
                            asyncio.create_task(
",3
"  oneofs=[
  ],
  serialized_start=2494,
  serialized_end=2525,
",3
"
            if msg:
                self.zmqlet.send_message(msg)
",3
"        pass
",3
"        """"""
        pass
",3
"                 *args, **kwargs):
        """"""
        Initialize an NmslibIndexer

",3
"
",3
"
        with ContainerPea(args):
            time.sleep(2)

    def test_flow_with_one_container_pod(self):
",3
"                             B / np.linalg.norm(B, ord=2, axis=1, keepdims=True))
    return A_ext.dot(B_ext).clip(min=0) / 2
",3
"                tmp[k] = v

        if self.store_args_kwargs:
            if args: tmp['args'] = args
            if kwargs: tmp['kwargs'] = {k: v for k, v in kwargs.items() if k not in taboo}
",3
"        else:
            sock.setsockopt(zmq.RCVTIMEO, -1)

        msg_data = sock.recv_multipart()
",3
"    # run it!
",3
"                                                name='sentinel-shutdown-idle',
",3
"            raise TypeError('this decorator should only be used on __init__ method of an executor')
        taboo = {'self', 'args', 'kwargs'}
        _defaults = get_default_metas()
        taboo.update(_defaults.keys())
        all_pars = inspect.signature(func).parameters
",3
"    if namespace == 'jina.executors':
",3
"            'url': args.index_data_url,
            'filename': os.path.join(args.workdir, 'index-original')
",3
"            fetch_list=[self.outputs_name],
            feed={self.inputs_name: data.astype('float32')},
            return_numpy=True
",3
"        with RemotePea(p_args):
            pass
        t.join()

",3
"
import numpy as np

",3
"        which is inherited all the way from :class:`jina.peapods.peas.BasePea`
        """"""

",3
"            if self.is_idle:
                self.close()
",3
"    The :func:`send_message` and :func:`recv_message` works in the async manner.
    """"""

",3
"        }
    }

    # download the data
",3
"        if self._sess_func is None:
            self._sess_func = self.get_session()
",3
"from tests.executors.crafters.image import JinaImageTestCase

",3
"
                f = Flow()
",3
"        self._size += keys.shape[0]

    def query(self, keys: np.ndarray, top_k: int, *args, **kwargs) -> Tuple['np.ndarray', 'np.ndarray']:
        """""" Find the top-k vectors with smallest ``metric`` and return their ids.

",3
"
        needs = op_flow._parse_endpoints(op_flow, pod_name, needs, connect_to_last_pod=True)

",3
"    import logging

",3
"
  'Score' : _reflection.GeneratedProtocolMessageType('Score', (_message.Message,), {
    'DESCRIPTOR' : _SCOREDRESULT_SCORE,
    '__module__' : 'jina_pb2'
",3
"        def arg_wrapper(self, *args, **kwargs):
            if hasattr(self, '_build_level'):
                if self._build_level.value >= required_level.value:
                    return func(self, *args, **kwargs)
",3
"            self._input_fn = bytes_gen()
",3
"                # check if either node is gateway
                # this is the only place where gateway appears
                if s_name == 'gateway':
                    if self.args.optimize_level > FlowOptimizeLevel.IGNORE_GATEWAY and e_pod.is_head_router:
",3
"        version_info = '\n'.join(f'{k:30s}{v}' for k, v in info.items())
",3
"                        break
",3
"        pod_name = 'gateway'

",3
"        blob.quantization = jina_pb2.NdArray.UINT8
",3
"                  - blob
                  - text
            - !KVIndexDriver
              with:
",3
"        for k, v in kwargs.items():
            if k in tmp:
                tmp[k] = v

        if self.store_args_kwargs:
",3
"            c.chunk_id = c_id
",3
"        Serialize the object to a yaml file

        :param filename: file path of the yaml file, if not given then :attr:`config_abspath` is used
        :return: successfully dumped or not
",3
"
",3
"
    @property
    def yaml_spec(self):
",3
"                continue
            _chunks_to_add = []
",3
"    unittest.main()
from tests import JinaTestCase


class JinaImageTestCase(JinaTestCase):
",3
"def get_result(resp):
    n = []
",3
"from tests import JinaTestCase


",3
"    @is_trained.setter
    def is_trained(self, val: bool):
",3
"        d = jina_pb2.Document()
        for k in range(chunks_per_doc):
",3
"    def prev_reqs(self) -> List['jina_pb2.Request']:
        """"""Get all previous requests that has the same ``request_id``, shortcut to ``self.pea.prev_requests``
",3
"        self.assertEqual(b['components'][0]['metas']['bad_var'], 'real-compound')
        self.assertEqual(b['components'][1]['metas']['bad_var'], 2)
        self.assertEqual(b['components'][1]['metas']['float_var'], 0.232)
",3
"        self.assertEqual(encoder_loaded.channel_axis, encoder.channel_axis)
",3
"
    def get_cls_pos(self):
        return 'tail' if self.model_name == 'xlnet-base-cased' else 'head'

    def get_tmp_model_path(self):
",3
"        self.remote_logging(req, set_ready)
",3
"        from .remote import RemotePod
        return RemotePod(args)
    else:
        from .pod import BasePod
",3
"
        self._update_args(args, **kwargs)
",3
"                             a.current_workspace)

",3
"        '/jina.JinaRPC/Spawn',
",3
"        :mod:`jina.drivers.handlers.craft`
    """"""

",3
"from ..executors import BaseExecutor
from ..logging import get_logger
from ..logging.profile import used_memory, TimeDict
from ..proto import jina_pb2, is_data_request

",3
"                return np.array(response.result().outputs['output_feature'].float_val)
",3
"        :param max_sent_len: the maximal number of characters (including white spaces) of the sentence, by default 1e5.
        :param punct_chars: the punctuation characters to split on.
        """"""
        super().__init__(*args, **kwargs)
",3
"                if isinstance(req_type, str):
                    req_type = [req_type]
                for r in req_type:
                    if r not in self._drivers:
",3
"    def metas(self):
",3
"                 needs: Set[str] = None, parser: Callable = set_pod_parser):
        """"""
",3
"        e._set = e.set
        e._clear = e.clear
        e.changed = changed_callback
        e.set = lambda: or_set(e)
",3
"            PeaSpawnHelper(p_args).start()

",3
"    """"""

    def __init__(self, default_mime: str = 'application/octet-stream', *args, **kwargs):
        """"""
",3
"                    'host is set from %s to %s as the socket is in BIND type' % (host, __default_host__))
                host = __default_host__
            if port is None:
                sock.bind_to_random_port('tcp://%s' % host)
            else:
",3
"        p_args, unknown_args = parser.parse_known_args(args)
        if unknown_args:
            from .logging import default_logger
            default_logger.warning(
                f'parser {parser_name} can not '
",3
"import tempfile
",3
"        return _tokenizer
",3
"    def get_pooling(self, data: 'np.ndarray', axis=None) -> 'np.ndarray':
",3
"      type=None),
",3
"        self._p_servicer = self._Pea(args)
        self._stop_event = threading.Event()
        self.is_ready = threading.Event()
        self.init_server(args)

",3
"        try:
            r = next(getattr(request, 'index')(**kwargs))
            if r is not None:
                default_logger.success(f'input_fn is valid and the first request is as follows:\n{r}')
",3
"        f = Flow().add(yaml_path='_forward')
        with f:
            print(py_client(port_grpc=f.port_grpc).call_unary(b'a1234', mode=ClientMode.INDEX))

",3
"
            # add tag `all` at the end
",3
"              - !VectorIndexDriver
                with:
                  executor: vecidx_exec
",3
"            net_mode = 'host'
",3
"      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
",3
"
",3
"_REQUEST_CONTROLREQUEST_ARGSENTRY.containing_type = _REQUEST_CONTROLREQUEST
_REQUEST_CONTROLREQUEST.fields_by_name['command'].enum_type = _REQUEST_CONTROLREQUEST_COMMAND
_REQUEST_CONTROLREQUEST.fields_by_name['args'].message_type = _REQUEST_CONTROLREQUEST_ARGSENTRY
",3
"        """"""Required by :mod:`ruamel.yaml.constructor` """"""
        return cls._get_instance_from_yaml(constructor, node)

    @classmethod
    def _get_instance_from_yaml(cls, constructor, node):
",3
"
",3
"        else:
            raise ValueError('ambiguous head node, maybe it is deducted already?')

",3
"                 max_length: int = 64,
",3
"                self.logger.error(""pooling strategy not found: {}"".format(self.pooling_strategy))
                raise NotImplementedError
        return output

",3
"_sym_db.RegisterMessage(ScoredResult)
_sym_db.RegisterMessage(ScoredResult.Score)

Chunk = _reflection.GeneratedProtocolMessageType('Chunk', (_message.Message,), {
",3
"      number=7, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"    :param batch_size: size of each batch
    :param num_batch: number of batches to take, the rest will be ignored
",3
"
        f = Flow.load_config(resource_filename('jina', '/'.join(('resources', 'helloworld.flow.index.yml'))))

        targets = {
            'index': {
",3
"
    The example below shows a dummy transformer add ``doc_id`` to the ``chunk_id`` and use it as the new ``chunk_id``.

",3
"                flow.search(video_zip_file='aa.zip')
",3
"    _descriptor.FieldDescriptor(
",3
"    if platform == ""linux"" or platform == ""linux2"":
        local_host = '0.0.0.0'
    else:
        local_host = 'host.docker.internal'
",3
"
",3
"        """"""

        :param kwargs: unparsed argument in dict, if given the
        :param needs: a list of names this BasePod needs to receive message from
        """"""
",3
"                # tmp_p = {kk: expand_env_var(vv) for kk, vv in data.get('with', {}).items()}
                obj = cls(**data.get('with', {}), metas=data.get('metas', {}), requests=data.get('requests', {}))

",3
"        encoder = self.get_encoder()
        if encoder is None:
            return
",3
"  name='Document',
",3
"            o_sock = self.ctrl_sock

        self.bytes_sent += send_message(o_sock, msg, **self.send_recv_kwargs)
",3
"
        return _prepare_recv_msg(sock, msg_data, check_version)
",3
"        self._last_snapshot_ts = datetime.now()
        self._drivers = {}  # type: Dict[str, List['BaseDriver']]
        self._attached_pea = None

    def _post_init_wrapper(self, _metas: Dict = None, _requests: Dict = None, fill_in_metas: bool = True):
",3
"        self.min_sent_len = min_sent_len
        self.max_sent_len = max_sent_len
        self.punct_chars = punct_chars
        if not punct_chars:
            self.punct_chars = ['!', '.', '?', '', '', '', '', '', '', '', '', '', '', '', '', '', '',
",3
"    return out
",4
"    for op in ops:
",4
"        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
                dropout_prob=dropout_rate,
",4
"            pad_idx=self.pad_id,
",4
"  void Predict(std::vector<FaceResult>* faces);

",4
"                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
                    confidence (float): The confidence of detection result.
",4
"
        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

",4
"    return [records, cname2cid]


",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"# You may obtain a copy of the License at
",4
"

class MSRA_NER(BaseNLPDataset):
    """"""
",4
"			};
			this.addListenerInside('mouseover', escMuteOver, this.CB['escMute']);
			this.addListenerInside('mouseout', promptHide, this.CB['escMute']);
			var fullOver = function(event) {
",4
"    version=""1.0.0"")
class FixResnext10132x48dwslImagenet(hub.Module):
",4
"
    def setUp(self):
        ""Call setUp() to prepare environment\n""
        self.test_prog = fluid.Program()

",4
"        self.predictor_set = False

    def get_expected_image_width(self):
",4
"
    ckpt_meta_path = os.path.join(checkpoint_dir, CKPT_FILE_NAME)
    ckpt = checkpoint_pb2.CheckPoint()

    model_saved_dir = os.path.join(checkpoint_dir, ""step_%d"" % global_step)
",4
"

",4
"			var ad = this.advertisements['other'][i];
			var randomS = this.randomString(10); //
			var adDivID = 'adother' + randomS; //
			imgClassName = 'adimgother' + randomS;
			var adDiv = document.createElement('div');
",4
"		},
		/*
			
",4
"
",4
"        for param in params_list:
            print(param.name)

",4
"from chinese_bert_wwm.model.transformer_encoder import encoder, pre_process_layer

",4
"        _402,
        num_filters=4,
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
post_process_layer = pre_post_process_layer
",4
"        d_model,
        n_head,
        attention_dropout,
",4
"
",4
"from paddlehub.finetune.checkpoint import load_checkpoint, save_checkpoint
from paddlehub.finetune.config import RunConfig
",4
"        use_global_stats=False,
",4
"        if delete_file:
            os.remove(file)
",4
"from paddle.fluid.regularizer import L2Decay
from paddle.fluid.initializer import Constant

from .nonlocal_helper import add_space_nonlocal
",4
"        Run as a command.
        """"""
        self.parser = argparse.ArgumentParser(
            description=""Run the {} module."".format(self.name),
",4
"			adLink = document.createElement('div'),
			adPauseClose = document.createElement('div');
			/*
",4
"
DATA_DIM = 224
",4
"        input=out,
        size=d_model,
",4
"This file is expected to map question ID's to the model's predicted probability
",4
"    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"        size=d_model,
        num_flatten_dims=2,
        param_attr=fluid.ParamAttr(
",4
"                             dirname,
",4
"                 class_dim=1000):
",4
"    _454 = fluid.layers.assign(_451)
    _445 = fluid.layers.concat([_442, _443, _444], axis=0)
    _457 = fluid.layers.concat([_454, _455, _456], axis=0)
",4
"				space: true,///
				left: true,//
				right: true,//
				up: true,//
				down: true //
",4
"            placeholders=placeholders,
            title_colors=[""yellow"", None],
            title_aligns=[""^"", ""<""])
",4
"        num_classes=dataset.num_labels,
        config=config)

",4
"			adLinkID = 'adlink' + randomS,//
",4
"            segment_ids (tensor): the segment ids.
",4
"]

ssd_eval_fields = [
",4
"
    return param

",4
"        if phase == 'train':
",4
"        dataset=dataset,
        vocab_path=module.get_vocab_path(),
        max_seq_len=args.max_seq_len,
        sp_model_path=module.get_spm_path(),
        word_dict_path=module.get_word_dict_path())
",4
"			error: '',
",4
"    ):
",4
"                continue
            num_left_context = position - doc_span.start
            num_right_context = end - position
",4
"        input = self.conv_bn_layer(
            input,
",4
"import paddlehub as hub
",4
"
        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')
",4
"            im = im / 255.0
        im -= mean
",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
                        return b

",4
"                 weight_prefix_name='',
                 get_prediction=False,
",4
"                cur_con.request('POST', ""/BertService/inference"", request_msg,
",4
"        elif cmd == ""n"":  # add layer normalization
            out_dtype = out.dtype
            if out_dtype == fluid.core.VarDesc.VarType.FP16:
                out = layers.cast(x=out, dtype=""float32"")
            out = layers.layer_norm(
",4
"        max_shape[1] = int(
            np.ceil(max_shape_org[1] / coarsest_stride) * coarsest_stride)
",4
"            None,
            fx=im_scale,
            fy=im_scale,
",4
"        short = self._shortcut(
            input,
            num_filters * expand,
            stride,
            is_first=is_first,
",4
"        unhandled_paths = paths[handle_id:]
        unhandled_paths_num = len(unhandled_paths)
    else:
        unhandled_paths_num = 0
",4
"            stride,
            if_first=if_first,
            name=name + ""_branch1"")

",4
"    """"""
    RPN Head

    Args:
",4
"        results = self.classification(
            paths=[args.input_path],
",4
"    vocab = collections.OrderedDict()
    fin = io.open(vocab_file, ""r"", encoding=""UTF-8"")
",4
"        num_classes (int): number of classes in rpn output
    """"""
    __inject__ = [
",4
"                    f.write(""\t"".join(param) + ""\t"" + modeldir[0] + ""\n"")
",4
"            feature_maps = [feature_maps]

        assert depth in [34, 50], \
",4
"
    @property
    def run_func(self):
        return self._run_func

",4
"    predict_method = getattr(module, method_name)
    data_len = len(input_img) if input_img is not None else 0
    data = {}
    if input_img is not None:
        input_img = {""image"": input_img}
",4
"            aligns=[""^"", ""<""])
        tp.add_line(
            contents=[""Location"", module_dir[0]],
",4
"  float* data = output_data_.data();
  int batch_size = faces->size();
",4
"    step = 0

    # test_data = reader_creator_all_in_memory('./datasets/PetImages', is_test=True)
    for e_id in range(args.num_epoch):
",4
"    min_depth = min_depth or divisor
    new_filters = max(min_depth,
                      int(filters + divisor / 2) // divisor * divisor)
    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%
",4
"            params_filename=params_filename)

    @serving
",4
"            d_model,
",4
"                end = rec_idx_lod[rno + 1]
                rec_idx_tmp = rec_idx_batch[beg:end, 0]
                preds_text = self.char_ops.decode(rec_idx_tmp)
                beg = predict_lod[rno]
",4
"            'a': '',
            'ad': '',
",4
"                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
",4
"			height = this.PD.offsetHeight;
			var nw = 0,
			nh = 0;
			if (w >= width || h >= height) {
",4
"                    outputs = {
                        'head_features':
                        [var_prefix + var.name for var in head_features],
",4
"
",4
"                             dirname,
                             model_filename=None,
                             params_filename=None):
        with self.phase_guard(""predict""):
            fluid.io.save_inference_model(
",4
"        serving_func_name = self.desc.attr.map.data['default_signature'].s
        return serving_func_name if serving_func_name != """" else None

    @property
    def desc(self):
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
",4
"
    h_off = int(round((h - th) / 2.))
    w_off = int(round((w - tw) / 2.))

    img_crop = np_imgs[:, h_off:h_off + target_size, w_off:w_off +
",4
"from __future__ import print_function

import math
from collections import OrderedDict
",4
"
@moduleinfo(
",4
"        label, key = 1, ""porn""
    else:
        label, key = 0, ""not_porn""
    return label, key

",4
"                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def context(self, trainable=True, pretrained=True):
        """"""context for transfer learning.
",4
"            num_flatten_dims=2,
",4
"import paddle.fluid as fluid

from bert_multi_uncased_L_12_H_768_A_12.model.transformer_encoder import encoder, pre_process_layer
",4
"from __future__ import absolute_import
from __future__ import division
",4
"            d_value,
            d_model,
            d_inner_hid,
            prepostprocess_dropout,
",4
"                    # Only select the first answer
                    answer = qa[""answers""][0]
",4
"		/*
			
",4
"                      channels=None,
                      num_groups=1,
                      if_act=True,
                      name=None,
                      use_cudnn=True):
",4
"					this.needSeek = this.V.currentTime;
				}
",4
"
",4
"            calculator.clear()

    def is_empty(self):
        return ([calculator.heap_size for calculator in self._ap_calculators
                 ] == [0 for _ in range(self._num_class)])
",4
"                channel,
",4
"
        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

",4
"                sign_name=self.module.default_signature,
",4
"yaml_parser = YAMLFileParser()
txt_parser = TextFileParser()
#coding:utf-8
",4
"    sampledFrames = []
    for i in range(videolen):
        ret, frame = cap.read()
",4
"                    org_img, output_dir, 'image_numpy_{}'.format(
",4
"#Licensed under the Apache License, Version 2.0 (the ""License"");
#you may not use this file except in compliance with the License.
",4
"            # get predict index
            batch_result = np.argmax(batch_result, axis=2)[0]
",4
"from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay

__all__ = ['DarkNet']
",4
"        elif phase == 'val' or phase == 'dev':
            shuffle = False
            examples = self.get_dev_examples()
            self.num_examples['dev'] = len(examples)
",4
"def merge_eval(main_eval, new_eval, prefix):
    for k in new_eval:
        main_eval['%s_%s' % (prefix, k)] = new_eval[k]


",4
"    # Setup feed list for data feeder
    feed_list = [input_dict[""image""].name]
",4
"    """"""
    components = []
    if paths:
        for im_path in paths:
            each = OrderedDict()
",4
"            param_attr=parameter_attr,
            bias_attr=False)

        bn_name = name + ""_bn""
        norm_decay = self.norm_decay
",4
"        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')

        # extract the first token feature in each sentence
        self.next_sent_feat = self.get_pooled_output()
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"        num_filters=256,
        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
",4
"            label_names.append(info.strip())
        return label_names
",4
"
",4
"            n_head,
            d_key,
            d_value,
            d_model,
            d_inner_hid,
",4
"            name='PY_VERSION', index=4, number=4, options=None, type=None),
    ],
",4
"    suite.addTest(TestPyramidBoxLiteMobileMask('test_single_pic'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_batch'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_ndarray'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
",4
"        predictions, actuals = AveragePrecisionCalculator._shuffle(
",4
"        Change the channel.
        Args:
",4
"        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
            if i == 0:
                conv_name = name + ""a""
",4
"             emb_lr=30.0):
    """"""
    Lstm net
    """"""
    # embedding layer
",4
"            self.pred_out = outputs['pred_out']
        place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()
        exe = fluid.Executor(place)
",4
"                bias_attr=fluid.ParamAttr(
",4
"				width: '100px',
",4
"                img_size=im_size,
                anchors=self.mask_anchors[i],
                class_num=self.num_classes,
                conf_thresh=self.nms.score_threshold,
                downsample_ratio=downsample,
",4
"                title = self.title[index]
                self.content[title].append(item)
",4
"
",4
"            bboxes=yolo_boxes,
",4
"from faster_rcnn_resnet50_coco2017.bbox_head import MultiClassNMS, BBoxHead, SmoothL1Loss
",4
"    def __split_heads(x, n_head):
        """"""
        Reshape the last dimension of inpunt tensor x so that it becomes two
",4
"                 num_classes=80,
                 ignore_thresh=0.7,
",4
"    """"""Head block for YOLOv3 network
",4
"            dim_in = conv.shape[1]
            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
            if i % nonlocal_mod == nonlocal_mod - 1:
",4
"        _descriptor.FieldDescriptor(
            name='paddle_version',
            full_name='paddlehub.module.checkinfo.CheckInfo.paddle_version',
",4
"
    def classification(self,
                       paths=None,
                       images=None,
",4
"
    def is_stop(self):
",4
"import cv2
import numpy as np
from PIL import Image, ImageEnhance
from paddle import fluid
",4
"            attr=helper.param_attr,
            shape=shape,
            dtype=input.dtype,
            default_initializer=Constant(init_scale))
",4
"from __future__ import division
",4
"            trainable (bool): whether to set parameters trainable.
            pretrained (bool): whether to load default pretrained model.
            phase (str): optional choices are 'train' and 'predict'.

",4
"		/*
			
",4
"        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

        next_sent_fc_out = fluid.layers.fc(
",4
"from __future__ import division
",4
"        detected_faces (list): faces detected in a picture.
",4
"    def __repr__(self):
        return self.info(show_default=False)

",4
"            for n_hidden in self.hidden_units:
                cls_feats = fluid.layers.fc(
                    input=cls_feats, size=n_hidden, act=""relu"")
",4
"            tag_type = tag // 2
            tag_pos = tag % 2

",4
"        count = stages[stage_num - 2]

        ch_out = self.stage_filters[stage_num - 2]
        is_first = False if stage_num != 2 else True
        dcn_v2 = True if stage_num in self.dcn_v2_stages else False
",4
"        nonlocal_stages (list): index of stages who select nonlocal networks
    """"""
    __shared__ = ['norm_type', 'freeze_norm', 'weight_prefix_name']

    def __init__(self,
",4
"                        found = found + 1
            im = np.array(im)
            while sampled_bbox:
",4
"        name='_399')
    _400 = fluid.layers.relu(_399, name='_400')
    _401 = fluid.layers.conv2d(
        _400,
",4
"                name='mask_lm_trans_fc.w_0',
                initializer=self._param_initializer),
            bias_attr=fluid.ParamAttr(name='mask_lm_trans_fc.b_0'))
        # transform: layer norm
",4
"            step=self.round)
        for pop_num in range(self.popsize):
            params = self.evaluator.convert_params(params_list[pop_num])
",4
"    _275 = fluid.layers.conv2d(
        _274,
        num_filters=64,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"                is_test=False)
",4
"        feature_maps (list): index of stages whose feature maps are returned
",4
"                                          initializer = fluid.initializer.Constant(value = 0.)) \
                                           if (nonlocal_params[""no_bias""] == 0) else False, \
                                  name = prefix + '_out')
",4
"                # head_feat
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"        delta = np.random.uniform(low, high)
",4
"             inputs(dict): the input variables.
             outputs(dict): the output variables.
             context_prog (Program): the program to execute transfer learning.
        """"""
",4
"                 input_mask,
                 config,
                 weight_sharing=True,
                 use_fp16=False):

",4
"
",4
"				this.css(this.CB['full'], 'display', 'none');
				this.css(this.CB['escFull'], 'display', 'block');
				if (this.vars['live'] == 0) {
",4
"        new_dict = {}
        for i, j in _dict.items():
            new_dict[i.lower()] = j
        new_ops.append(new_dict)
",4
"        results = lac.lexical_analysis(data=inputs)
        self.assertEqual(results[0]['word'], ['', '', '', ''])
        self.assertEqual(results[0]['tag'], ['TIME', 'v', 'q', 'n'])
        self.assertEqual(results[1]['word'], ['', '', '', '', ''])
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            t1 = time.time()
            result = self.face_detector.face_detection(
",4
"        self.variance = variance
        self.stride = stride

",4
"    Args:
        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

    Yield:
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

",4
"                scores=cls_prob,
                score_threshold=.05,
                nms_top_k=-1,
                keep_top_k=100,
                nms_threshold=.5,
",4
"        pool = fluid.layers.pool2d(
            input=input,
            pool_size=2,
            pool_stride=2,
            pool_padding=0,
",4
"

",4
"    Args:
",4
"
import paddlehub as hub
from paddlehub.dataset.base_cv_dataset import BaseCVDataset

",4
"        try:
",4
"        super(BBoxAssigner, self).__init__()
        self.batch_size_per_im = batch_size_per_im
        self.fg_fraction = fg_fraction
",4
"#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#Unless required by applicable law or agreed to in writing, software
",4
"    """"""proxy method called to 'self._ds' when if not defined""""""

    def __init__(self, ds):
        super(ProxiedDataset, self).__init__()
",4
"            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]
        return fluid.layers.batch_norm(
            input=conv,
",4
"import paddle.fluid as fluid
import paddlehub as hub

pic_dir = '../image_dataset/face_detection'

",4
"        return normal_conv

    def __call__(self, input):
        scale = self.conv_group_scale
",4
"            postprocess_cmd=""dan"",
            param_initializer=self._param_initializer,
            name='encoder')
",4
"    suite.addTest(TestMobileNetV3SmallSSLD('test_context'))
    suite.addTest(TestMobileNetV3SmallSSLD('test_single_pic'))
    suite.addTest(TestMobileNetV3SmallSSLD('test_batch'))
",4
"            filter_size=1,
            num_filters=num_mid_filter,
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))

",4
"    int ymax = (output_data_[5 + j * 6] * rh) / shrink;
    int wd = xmax - xmin;
    int hd = ymax - ymin;
",4
"        result_i = {'processed': []}
        result_i['origin'] = data_dict[text_b_key][index]
        for word in text_b['word']:
            _index = word_dict.get(word, unk_id)
",4
"        self._model_type = 'ResNet'
",4
"            paths=self.test_images, use_gpu=True)
        results_2 = self.module.recognize_text(
",4
"    """"""
    for cmd in process_cmd:
",4
"    if not isExists:
        os.makedirs(path)
    fps = 30
    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
",4
"        postprocess_cmd,
",4
"        return results
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"							color: '0xFFFFFF',
							size: 14,
							font: this.fontFamily,
							leading: 0,
",4
"from __future__ import print_function
",4
"            index=0,
            number=1,
            type=11,
            cpp_type=10,
",4
"        Returns:
            Type: dict
                rpn_cls_loss(Variable): RPN classification loss.
",4
"            # load the senta_bow pretrained model
            def if_exist(var):
                return os.path.exists(
                    os.path.join(self.pretrained_model_path, var.name))

",4
"                trainable=False, pretrained=True, get_prediction=True)
            self.infer_prog = self.infer_prog.clone(for_test=True)
            self.pred_out = outputs['pred_out']

        place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()
",4
"def reader(paths=[], images=None):
    """"""
    data generator

",4
"        self.parser = argparse.ArgumentParser(
            description=""Run the {}"".format(self.name),
            prog=""hub run {}"".format(self.name),
            usage='%(prog)s',
",4
"        paddings=[1, 1, 1, 1],
        name='x2paddle_42')
    x2paddle_43 = fluid.layers.conv2d(
        x2paddle_42,
",4
"    print(""first 10 test"")
    for e in ds.get_test_examples()[:10]:
        print(e)
    print(ds)
#coding:utf-8
",4
"			}
			if (this.vars['cktrack']) {
				this.loadTrack();
",4
"        d_inner_hid,
",4
"                except:
",4
"
from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo

",4
"                    os.path.abspath(sys.modules[cls.__module__].__file__))
",4
"        [score, pos] records
",4
"from __future__ import print_function

from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.initializer import Normal
",4
"                name_prefix = '@HUB_{}@'.format(self.name)
                inputs = {'image': name_prefix + image.name}
                outputs = {
                    'classification': name_prefix + output.name,
                    'feature_map': name_prefix + feature_map.name
",4
"
        self_attn_mask = fluid.layers.matmul(
",4
"        dataset_dir = os.path.join(DATA_HOME, ""chnsenticorp"")
        base_path = self._download_dataset(
            dataset_dir,
",4
"        layers = []
        for k, v in enumerate(cfg):
            assert len(v) == 5, ""extra_block_filters size not fix""
            conv = self._extra_block(
",4
"			}
		},
		/*
			
			ajax
",4
"
",4
"    if isinstance(predict_method, functools.partial):
",4
"            body_input = body_dict[body_name]
",4
"os.environ['CUDA_VISIBLE_DEVICES'] = '0'
",4
"            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
",4
"            input,
            num_filters * 4,
            stride,
            if_first=if_first,
            name=name + ""_branch1"")
",4
"            tips += '-%s' % module_version
        module_dir = self.modules_dict[module_name][0]
        shutil.rmtree(module_dir)
",4
"def add_space_nonlocal(input, dim_in, dim_out, prefix, dim_inner):
    '''
    add_space_nonlocal:
",4
"            help=""whether use GPU or not."")
        self.arg_config_group.add_argument(
            '--batch_size',
",4
"
        logits = fluid.layers.fc(
",4
"
",4
"        visualization (bool): Whether to save image or not.
        score_thresh (float): the low limit of bounding box.
        label_names (list[str]): label names.
        handle_id (int): The number of images that have been handled.

",4
"        """"""
        if self.exist(hook_type, name):
",4
"import paddle.fluid as fluid
import paddle.fluid.layers as layers


def multi_head_attention(queries,
",4
"            result['data'] = rgba[:, :, 3]
    return result


",4
"                int(num_filters / 2), 1, stride1, 'relu', 1, conv_name1
",4
"from __future__ import division

import os
from collections import OrderedDict
",4
"            detect_faces = list()
            for scale in multi_scales:
                _detect_res = face_detector.face_detection(
",4
"                break
            if len(tokens_a) > len(tokens_b):
                tokens_a.pop()
            else:
",4
"        self._feeding_ev.set()

",4
"    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"    proj_out = layers.fc(
",4
"            type=str,
            default='humanseg_output',
            help=""The directory to save output images."")
",4
"            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
",4
"             texts(list): each element's type is unicode in python2.7
        """"""
        if six.PY2:
            unicode_texts = []
            for text in texts:
",4
"        return OrderedDict([('res{}_sum'.format(self.feature_maps[idx]), feat)
                            for idx, feat in enumerate(res_endpoints)])


class ResNetC5(ResNet):
",4
"            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
",4
"
        probs = []
        for i in range(self.num_classes):
            probs.append(
",4
"        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing

        self._word_emb_name = ""word_embedding""
",4
"    fluid.core.VarDesc.VarType.INT64: ""int64"",
    fluid.core.VarDesc.VarType.BOOL: ""bool"",
    fluid.core.VarDesc.VarType.INT16: ""int16"",
    fluid.core.VarDesc.VarType.UINT8: ""uint8"",
",4
"from paddlehub.dataset.base_cv_dataset import BaseCVDataset


",4
"
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an 'AS IS' BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"    def __init__(self, name, version=None):
        self.name = name
        self.version = version

",4
"import paddlehub as hub
from paddlehub.common.paddle_helper import add_vars_prefix
",4
"        return res_list

    def add_module_config_arg(self):
        """"""
",4
"            if img.mode == ""RGB"" or img.mode == ""L"":
                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
                ext = '.png'
",4
"                    inplace=True,
                    need_log=True):

    if not isinstance(pre_program, fluid.Program):
        raise TypeError(""pre_program shoule be an instance of fluid.Program"")
",4
"        super(BoxCoder, self).__init__()
        self.prior_box_var = prior_box_var
",4
"                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
                inputs = {
                    key: global_vars[value]
",4
"                stride=s,
                act='relu',
",4
"                ""Set maximum sequence length of input tensor to {}"".format(
                    max_seq_len))
            if self.name.startswith(""ernie_v2""):
                feed_list = [
                    ""input_ids"", ""position_ids"", ""segment_ids"", ""input_mask"",
",4
"			this.css(this.CB['timeButton'], 'left', parseInt(timeBOW) + 'px');
		},
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"
",4
"                        if not has_warned:
                            logger.warning(
",4
"        result_data = []
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"            gpu_config.disable_glog_info()
",4
"        local_min_reward = min(reward_list)
        local_min_reward_index = reward_list.index(local_min_reward)
",4
"        d_key,
        d_value,
",4
"    def add_module_input_arg(self):
        """"""
        Add the command input options
        """"""
        self.arg_input_group.add_argument(
",4
"from paddle.fluid.dygraph.base import to_variable
from paddle.fluid.optimizer import AdamOptimizer

# yapf: disable
",4
"                if 'help' in expect_data_format[key]:
                    help_str = expect_data_format[key]['help']
                self.arg_input_group.add_argument(
                    ""--%s"" % key, type=str, default=None, help=help_str)
",4
"            if isinstance(feat, OrderedDict):
",4
"
def postprocess(data_out, org_im, org_im_path, image_height, image_width,
                output_dir, visualization, shrink, confs_threshold):
    """"""
",4
"        cv2.imwrite(save_im_path, org_im)
        draw_bounding_box_on_image(save_im_path, output['data'])

    return output
",4
"            size=self._emb_size,
            act=""tanh"",
",4
"    @property
",4
"        if isinstance(self.target_size, list):
            # Case for multi-scale training
            selected_size = random.choice(self.target_size)
        else:
",4
"        topdown_name = 'fpn_topdown_' + body_name
",4
"            shuffle = True
            examples = self.get_train_examples()
            self.num_examples['train'] = len(examples)
",4
"    Args:
        paths (list[str]): The paths of images.
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
",4
"                                        pool_padding = [0, 0], \
                                        name = prefix + '_pool')
    else:
",4
"                if pretrained:

                    def _if_exist(var):
                        b = os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
",4
"            max_level=5,
            min_level=2,
            box_resolution=7,
",4
"                avg_acc = acc_sum / run_examples
                scores[""acc""] = avg_acc
            elif metric == ""f1"":
                f1 = calculate_f1_np(all_infers, all_labels)
",4
"                memory_pool_init_size_mb=1000, device_id=0)
",4
"            'https://paddlemodels.bj.bcebos.com/video_classification/ResNet50_pretrained.tar.gz'
        )

    def weights_info(self):
",4
"            input=pool,
            num_filters=num_filters,
            filter_size=filter_size,
            stride=1,
            padding=(filter_size - 1) // 2,
",4
"                inputs = {'image': name_prefix + image.name}
                outputs = {'feature_map': name_prefix + feature_map.name}
                add_vars_prefix(context_prog, name_prefix)
                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
",4
"            padding=padding,
            param_attr=ParamAttr(initializer=Constant(0.0), name=name + "".w_0""),
",4
"            cls_score(Variable): Output of rpn head with shape of
",4
"            result = self.animal_classify.classification(
                paths=pics_path_list, batch_size=3, use_gpu=False)
            print(result)

",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"			this.PD.appendChild(timeProgressBg);
			this.PD.appendChild(timeBoBg);
			this.PD.appendChild(promptBg);
			this.PD.appendChild(prompt);
			this.PD.appendChild(definitionP);
",4
"						b = parseInt(start) * w * 0.01;
					} else {
						b = parseInt(start);
					}
",4
"                      input,
                      filter_size,
                      num_filters,
                      stride,
                      padding,
",4
"        tmp = np.max(x)
        x -= tmp
",4
"    @runnable
    def run_cmd(self, argvs):
        args = self.parser.parse_args(argvs)
        texts = [args.input_text]
",4
"#You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
",4
"            name=""conv1"")  #debug
        conv = fluid.layers.pool2d(
            input=conv,
            pool_size=3,
            pool_stride=2,
",4
"            '--top_k',
            type=ast.literal_eval,
            default=1,
",4
"            int(_places[0])
        except:
            use_gpu = False

        if texts != [] and isinstance(texts, list) and data == {}:
",4
"def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs,
",4
"                        predicate=_if_exist)
                else:
                    exe.run(startup_prog)
                # trainable
                for param in context_prog.global_block().iter_parameters():
",4
"HubDataset = BaseDataset
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"    for token in tokens:
",4
"        if dropout_rate:
            weights = layers.dropout(
",4
"				var callbackName = 'callback' + new Date().getTime();
				var params = this.formatParams(obj.data) + '&callback=' + callbackName; //
				callback = obj.success;
				//src
				oScript.src = obj.url.split('?') + '?' + params;
",4
"            lod.append(len(text_inds) + lod[i])
",4
"
from paddlehub import version
",4
"        if len(x.shape) == 3: return x
",4
"        moving_mean_name='_base_net_6_4_running_mean',
        moving_variance_name='_base_net_6_4_running_var',
",4
"        'anno_file' which is a pickled file.
        And the records should has a structure:
",4
"        _291,
        momentum=0.9900000095367432,
        epsilon=9.999999747378752e-06,
",4
"                im_path), ""The {} isn't a valid file path."".format(im_path)
",4
"    lac = LAC(user_dict=""user.dict"")
    # or use the fuction user_dict to set
    # lac.set_user_dict(""user.dict"")
",4
"					width: pW + 'px'
",4
"        with open(output_file, ""w"") as file:
            file.write(pycode)
        utils.from_pyobj_to_module_attr(
",4
"    """"""
    load the given vocabulary
    """"""
    vocab = {}
    with io.open(file_path, 'r', encoding='utf8') as f:
",4
"

class ResNet(object):
    """"""
    Residual Network, see https://arxiv.org/abs/1512.03385
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"                self.env.labels = self._rcnn_add_label()
",4
"        dilation=[1, 1],
        groups=1,
        param_attr='_classification_headers_3_weight',
",4
"                    orig_text = "" "".join(orig_tokens)
                else:
                    orig_text = """".join(orig_tokens)

",4
"                dtype=self._dtype,
                attr=mask_lm_out_bias_attr,
                is_bias=True)

        else:
",4
"            ]
            t1 = time.time()
",4
"
  // Load image
",4
"    def create_reader(self):
        """"""Not implemented""""""
        pass

",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
                        return b

",4
"                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
",4
"    if (index >= dst.shape[dim]).any() or (index < 0).any():
        raise IndexError(""The values of index must be between 0 and {}."".format(
            dst.shape[dim] - 1))
",4
"        image_height (int): height of preprocessed image.
        image_width (int): width of preprocessed image.
",4
"            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]

",4
"        d_model,
",4
"				cPauseCenter.fillStyle = bOverColor;
				cPauseCenter.strokeStyle = bOverColor;
",4
"            break
        current_box = boxes[current, :]
        # indexes = indexes[1:]
        indexes = indexes[:-1]
",4
"                             dirname,
                             model_filename=None,
                             params_filename=None,
",4
"            use_gpu (bool): Whether to use gpu.
            output_dir (str): The path to store output images.
            visualization (bool): Whether to save image or not.
            score_thresh (float): threshold for object detecion.
",4
"    def __combine_heads(x):
        """"""
        Transpose and then reshape the last two dimensions of inpunt tensor x
        so that it becomes one dimension, which is reverse to __split_heads.
",4
"            description=
            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
",4
"        if self._load_img:
            sample['image'] = self._load_image(sample['im_file'])
        else:
            sample['im_file'] = os.path.join(self._image_dir, sample['im_file'])

",4
"                 num_classes,
                 feed_list,
",4
"			y270 = n % 270;
			var ys = false;
",4
"                origin_ims[base_name],
                None,
                None,
",4
"    argv = []
",4
"            cv2.circle(rendered_im, (x, y), 3, icolor, -1, 16)
            cv2.circle(rendered_im, (x, y), 6, ocolor, 1, 16)
        check_dir(output_dir)
        save_im_name = get_save_image_name(org_im, org_im_path, output_dir)
",4
"                act='relu',
",4
"                _index = word_dict[word]
            else:
                _index = unk_id
            result_i['processed'].append(_index)
",4
"    type=""CV/keypoint_detection"",
    author=""paddlepaddle"",
    author_email=""paddle-dev@baidu.comi"",
    summary=
",4
"            param_initializer=None,
            name=''):
",4
"                1,
                param_attr=ParamAttr(
                    name=lateral_name + ""_w"", initializer=Xavier(fan_out=fan)),
",4
"                examples.append(example)
",4
"    aspect_ratio = np.random.uniform(sampler[4], sampler[5])
    aspect_ratio = max(aspect_ratio, (scale**2.0))
",4
"            return False

        def _tokenize_chinese_chars(text):
            """"""Because Chinese (and Japanese Kanji and Korean Hanja) does not have whitespace
            characters, we add spaces around every character in the CJK Unicode range before
",4
"        if ch_in != ch_out or stride != 1:
            if if_first:
                return self.conv_bn_layer(input, ch_out, 1, stride, name=name)
            else:
                return self.conv_bn_layer_new(
",4
"            x_squeezed,
            num_filters=num_squeezed_channels,
            filter_size=1,
            use_bias=True,
            padding_type=self.padding_type,
",4
"        max_score = np.max(det_accu[:, 4])
        det_accu_sum = np.zeros((1, 5))
        det_accu_sum[:, 0:4] = np.sum(
            det_accu[:, 0:4], axis=0) / np.sum(det_accu[:, -1:])
        det_accu_sum[:, 4] = max_score
",4
"        assert len(self.anchor_masks) > 0, ""ANCHOR_MASKS not set.""

        for anchor in anchors:
",4
"            with fluid.program_guard(predictor_main_prog,
                                     predictor_startup_prog):
                # parse config
                predictor_config = parse_config(args.predictor_config)
",4
"                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
",4
"                        self.device_count)

        if self.is_train_phase:
            loss_name = self.env.loss.name
",4
"
            for j, item in enumerate(res['data']):
                self.assertEqual(item['confidence'],
                                 results_2[i]['data'][j]['confidence'])
                self.assertEqual(item['confidence'],
",4
"        self.anchor_generator = anchor_generator
        self.rpn_target_assign = rpn_target_assign
        self.train_proposal = train_proposal
        self.test_proposal = test_proposal
        self.num_classes = num_classes
",4
"
",4
"                print(result)
",4
"				var imgClass = 'adimg' + this.randomString(10);
				var imgHtml = '<img src=""' + ad['file'] + '"" class=""' + imgClass + '"">';
				if (ad['link']) {
					imgHtml = '<a href=""' + ad['link'] + '"" target=""_blank"">' + imgHtml + '</a>';
				}
",4
"  cv::Mat roi_rect;
  // Classification result: confidence
  float confidence;
  // Classification result : class id
  int class_id;
",4
"        self.layers = layers
        self.test_mode = test_mode
",4
"            print(e)
            print(
",4
"            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
",4
"from paddlehub.common.decorator_utils import singleton
from paddlehub.common.server_config import default_server_config
from paddlehub.io.parser import yaml_parser
from paddlehub.common.lock import lock
",4
"
",4
"    :type images: numpy.ndarray
    """"""
    img_list = []
    if paths:
",4
"
@register_op
class Permute(BaseOperator):
    def __init__(self, to_bgr=True, channel_first=True):
        """"""
",4
"        diff = np.abs(results[0][1] - results_3[0][1])
        self.assertTrue((diff < 1e-6).all)
",4
"parser.add_argument(""--batch_size"",         type=int,               default=16,                                 help=""Total examples' number in batch for training."")
parser.add_argument(""--log_interval"",       type=int,               default=10,                                 help=""log interval."")
parser.add_argument(""--save_interval"",      type=int,               default=10,                                 help=""save interval."")
",4
"            title=""Config options"",
            description=
            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
",4
"                name=_name + '.conv2d.output.1')
",4
"
        im_scale_x = float(target_size) / float(im_shape[1])
        im_scale_y = float(target_size) / float(im_shape[0])
        im = cv2.resize(
",4
"        super(ClassifierTask, self).__init__(
            data_reader=data_reader,
",4
"    return image_saturation_adjust(img, delta)
",4
"#coding:utf-8
",4
"    """""" Load data records from 'fnames'

    Args:
",4
"    def invresi_blocks(self, input, in_c, t, c, n, s, name=None):
        first_block = self.inverted_residual_unit(
            input=input,
",4
"            texts=self.test_text, use_gpu=False, batch_size=1)
        self.assertEqual(results, self.results)
        results = self.module.sentiment_classify(
",4
"            conv_name = str(stage_num + 2) + '_' + str(i + 1)
",4
"				y: 0
			};
			if (this.isUndefined(tweenFun)) {
				return false;
			}
",4
"                input=input,
                num_filters=c,
",4
"#
",4
"            type=ast.literal_eval,
            default=False,
            help=""whether to save output as images."")
        self.arg_config_group.add_argument(
            '--batch_size',
",4
"        param_attr='_base_net_7_branch2_0_bn_weight',
        bias_attr='_base_net_7_branch2_0_bn_bias',
        moving_mean_name='_base_net_7_branch2_0_bn_running_mean',
        moving_variance_name='_base_net_7_branch2_0_bn_running_var',
        use_global_stats=False,
",4
"    full_name='paddlehub.module.desc.DataType',
    filename=None,
",4
"
    return white_space_fix(remove_articles(remove_punc(lower(s))))


",4
"# -*- coding:utf8 -*-
import argparse
import os
import ast

",4
"        """"""API of Object Detection.

        Args:
            paths (list[str]): The paths of images.
            images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
",4
"        if mem_mgr is not None:
            self._shared_mem = mem_mgr
",4
"
        bn_name = name + ""_bn""
        norm_decay = self.norm_decay
        bn_param_attr = ParamAttr(
",4
"            score_pred, loc_pred, score_tgt, loc_tgt, bbox_weight = \
                self.rpn_target_assign(
",4
"        if metrics_choices == ""default"":
",4
"            self.dish_classify.save_inference_model(
                dirname='mobilenet_v2_dishes',
                model_filename='model',
                combined=True)

",4
"                }
                add_vars_prefix(context_prog, name_prefix)
",4
"    """"""

",4
"        self.fetch_names = fetch_names
        self.for_predict = for_predict
",4
"                yield self._pad_batch_records(batch_records, phase)
                batch_records, max_len = [record], len(record.token_ids)

        if batch_records:
            yield self._pad_batch_records(batch_records, phase)
",4
"    proj_out = layers.fc(
",4
"
def finetune(args):
",4
"    idx = idx.reshape((batch_size, num_joints, 1))
    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)
",4
"        conv = fluid.layers.sigmoid(conv, name=name + '_sigmoid')
    elif act == 'swish':
        conv = fluid.layers.swish(conv, name=name + '_swish')
",4
"        self.animal_classify = hub.Module(name=""resnet50_vd_animals"")

    @classmethod
",4
"    # save image path
",4
"                    print_progress=True)

            if module_package:
                with tarfile.open(module_package, ""r:gz"") as tar:
",4
"            default='yolov3_vehicles_detect_output',
            help=""The directory to save output images."")
",4
"

def predict(args):
    # Load Paddlehub  pretrained model
    module = hub.Module(name=args.module)
",4
"
    @property
    def labels(self):
",4
"        self.anchors = []
        self.mask_anchors = []
",4
"
",4
"                outputs = {'pred_out': out[-1]}
            else:
                outputs = {'body_feats': out}

            place = fluid.CPUPlace()
",4
"			this.deleteChild(ele);
		},
		/*
			--------------------------------------------------------------
",4
"            152: 8,
            200: 12,
",4
"    type=""nlp/semantic_model"",
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
",4
"                     act=None,
",4
"		/*
			
",4
"                      attr=ParamAttr(name=prefix + '_affine' + '_b'), \
                      default_initializer = fluid.initializer.Constant(value = 0.))
        blob_out = fluid.layers.affine_channel(blob_out, scale = affine_scale, \
                      bias = affine_bias, name = prefix + '_affine')   # add affine
",4
"                score_thresh,
                label_names,
                output_dir,
                handle_id,
                visualization=True):
",4
"                profiler.stop_profiler(""total"", profiler_path)
                return

",4
"					thisTemp.runing = false;
					window.clearInterval(thisTemp.timeObj);
					thisTemp.timeObj = null;
",4
"					this.css(ele[i][0], 'display', 'block');
					if (ele[i].length == 3) {
						var name = ele[i][2];
						switch (name) {
",4
"            size=class_dim,
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv)))
",4
"        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""

",4
"

def encoder_layer(enc_input,
",4
"            padding=1,
            act='relu',
            name='conv_rpn',
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
",4
"            50: ([3, 4, 6, 3], self.bottleneck),
        }
        self.stage_filters = [64, 128, 256, 512]
",4
"    def run_cmd(self, argvs):
",4
"        if phase == 'train':
            shuffle = True
            examples = self.get_train_examples()
            self.num_examples['train'] = len(examples)
",4
"            component.append(each)
",4
"
from faster_rcnn_resnet50_coco2017.processor import load_label_info, postprocess, base64_to_cv2
from faster_rcnn_resnet50_coco2017.data_feed import test_reader, padding_minibatch
from faster_rcnn_resnet50_coco2017.resnet import ResNet, ResNetC5
from faster_rcnn_resnet50_coco2017.rpn_head import AnchorGenerator, RPNTargetAssign, GenerateProposals, RPNHead
",4
"    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None

",4
"                               params_filename=None,
                               combined=True):
        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
",4
"        if type(value) is dict:
            yaml_config[key] = value = AttrDict(value)
",4
"            paths=[args.input_path],
",4
"
    @property
    def main_program(self):
        if not self.env.is_inititalized:
",4
"from .transformer import ProxiedDataset

logger = logging.getLogger(__name__)

",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"@moduleinfo(
",4
"            # fpn
            fpn = FPN(
                max_level=7,
                min_level=3,
                num_chan=256,
",4
"			try {
				if (this.V.currentSrc) {
",4
"        for param in module_program.global_block().iter_parameters():
            param.trainable = trainable
            match = re.match(r'.*layer_(\d+).*', param.name)
",4
"    def basicblock(self,
                   input,
",4
"    orig_shape = x.shape
    if len(x.shape) > 1:
        tmp = np.max(x, axis=1)
        x -= tmp.reshape((x.shape[0], 1))
",4
"
    assert type(paths) is list, ""type(paths) is not list.""
",4
"# limitations under the License.
import os
from unittest import TestCase, main
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

",4
"
        self._emb_size = config['hidden_size']
        self._n_layer = config['num_hidden_layers']
        self._n_head = config['num_attention_heads']
        self._voc_size = config['vocab_size']
",4
"                                power=1.0,
                                cycle=False)
                            fluid.layers.assign(decayed_lr, scheduled_lr)

        # slanted_triangle
",4
"# You may obtain a copy of the License at
#
",4
"        param_attr='_base_net_3_4_weight',
        bias_attr='_base_net_3_4_bias',
",4
"
    def _build_model(self, src_ids, position_ids, sentence_ids, input_mask):
        # padding id in vocabulary must be set to 0
        emb_out = fluid.layers.embedding(
",4
"
",4
"        return True


",4
"        if os.path.exists(home_path) and os.path.isdir(home_path):
            return home_path
",4
"        scaled_batch = []
        for data in batch_data:
            im = cv2.resize(
                data[0].transpose((1, 2, 0)),
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"        if len(epoch_periods) < 1:
            logger.info(
                'No iteration was executed, please check the data reader')
            sys.exit(1)
",4
"        if sampler[7] != 0 and \
",4
"import numpy as np
import os
",4
"                 freeze_at=2,
                 norm_type='affine_channel',
                 freeze_norm=True,
",4
"
        # Initialize all weigths by truncated normal initializer, and all biases
",4
"                filter_size=filter_size,
                stride=stride,
                padding=(filter_size - 1) // 2,
",4
"            index = phrase.rfind(""/"")
            word = phrase[0:index]
            self.seg_query_list.append(word)
        self.seg_query_str = "" "".join(self.seg_query_list)
",4
"                    name='image', shape=[3, 608, 608], dtype='float32')
                # backbone
                backbone = ResNet(
                    norm_type='bn',
                    freeze_at=0,
",4
"                fpn_output = ConvNorm(
",4
"        if item in module_info.keys():
            predict_args.update({item: module_info[item]})
",4
"                        predicate=_if_exist)
                return inputs, outputs, context_prog

    def rpn_head(self):
        return FPNRPNHead(
",4
"
    @runnable
",4
"                        'body_features':
                        [var_prefix + var.name for var in body_feats]
                    }
",4
"    return proj_out

",4
"			this.getByElement(timeBOBGID).innerHTML = '<div class=""' + timeBOID + '""><div class=""' + timeBWID + '""></div></div>';
			//
			this.getByElement(pauseCenterID).innerHTML = this.newCanvas(pauseCenterID, 80, 80); //
			this.getByElement(loadingID).innerHTML = this.newCanvas(loadingID, 60, 60); //
			this.getByElement(errorTextID).innerHTML = this.language['error']; //
",4
"
    def __init__(self):
        super(ArrangeYOLO, self).__init__()

    def __call__(self, sample, context=None):
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"                                fluid.CPUPlace())
",4
"        is_test=True,
        param_attr='_base_net_7_branch2_2_bn_weight',
        bias_attr='_base_net_7_branch2_2_bn_bias',
",4
"                 end_position=None,
                 is_impossible=False):
",4
"			if (!this.showFace) {
				return;
			}
			var thisTemp = this;
			var vArr = this.VA;
",4
"                im_info = fluid.layers.data(
                    name='im_info', shape=[3], dtype='float32', lod_level=0)
                im_shape = fluid.layers.data(
                    name='im_shape', shape=[3], dtype='float32', lod_level=0)
                body_feat_names = list(body_feats.keys())
",4
"             data(dict): key must be 'text_1' and 'text_2', value is the texts(list) to be predicted
        Returns:
",4
"            product += attn_bias
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
",4
"        default_initializer=Constant(0.0))
    _478 = fluid.layers.fill_constant(shape=[1], dtype='float32', value=2.0)
    _483 = fluid.layers.fill_constant(shape=[1], dtype='float32', value=2.0)
    _input = fluid.layers.data(
",4
"    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    elif os.path.isfile(dir_path):
",4
"				}
			};
			this.timerBuffer = new this.timer(200, bufferFun);
",4
"        self._initialize(**kwargs)
        self._is_initialize = True
        self._code_version = ""v2""

",4
"
",4
"        self.bert_config = BertConfig(bert_config_path)

    def net(self, input_ids, position_ids, segment_ids, input_mask):
        """"""
",4
"                if layers in [101, 152] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
",4
"
",4
"from collections import OrderedDict

from paddle import fluid
",4
"        if not self._train_data:
",4
"				this.adIsPause = false;
				if (this.adPlayerPlay) {
",4
"    _463 = fluid.layers.fill_constant(
",4
"                    regularization_coeff=0.0)),
",4
"        return getattr(self.model, '_model_type', '')

",4
"class PornDetectionLSTM(hub.NLPPredictionModule):
    def _initialize(self):
        """"""
        initialize with the necessary elements
        """"""
",4
"        Returns:
",4
"        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

    Yield:
",4
"        keep = nms(dets_j, cfg.MultiScaleTEST['nms_thresh'])
",4
"				var referXY = thisTemp.getCoor(obj['refer']);
",4
"        data_reader=data_reader,
        feed_list=feed_list,
        feature=feature_map,
        num_classes=dataset.num_labels,
        config=config)
",4
"                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
",4
"			this.css(adBackgroundID, {
				width: '100%',
",4
"                    )
                examples.append(item_i)
",4
"                b_body = str(b_body).replace(""b'"", """").replace(""'"", """")
",4
"                im = cv2.imread(pic_path)
                result = self.animal_classify.classification(
",4
"
    def test_ndarray(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"    """"""

    def __init__(self,
                 depth=53,
",4
"            dropout_prob=0.1,
            dropout_implementation=""upscale_in_train"")

        if self.hidden_units is not None:
            for n_hidden in self.hidden_units:
",4
"        if len(input_data) == 0:
            self.parser.print_help()
",4
"    def _project_conv_norm(self, inputs, block_args, is_test, name=None):
        final_oup = block_args.output_filters
        conv = self.conv_bn_layer(
            inputs,
            num_filters=final_oup,
",4
"        res_dict = OrderedDict([(k, fpn_dict[k]) for k in fpn_name_list])
        return res_dict, spatial_scale
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"        name='_350')
    _327_cast = fluid.layers.cast(_327, dtype='int32')
    _328 = fluid.layers.reshape(
        _318, name='_328', actual_shape=_327_cast, shape=[1, -1, 2])
",4
"                bn_name = 'bn' + name[-1]
            else:
                bn_name = (name[:10] if name[7:9].isdigit() else
                           name[:9]) + 'bn' + name[-1]
",4
"    operator_list = []
",4
"                import math
                ap = 0.
                prev_recall = 0.
",4
"				} else {
",4
"                bias_attr=fluid.param_attr.ParamAttr(
                    name=fc_name[2] + ""_offset""))
            out = fluid.layers.softmax(out)
",4
"        output_i = {}
",4
"                             dirname,
                             model_filename=None,
",4
"            ""predict"": predict_file_with_header
        }

        if train_file:
",4
"            regularizer=L2Decay(norm_decay), name=bn_name + '_scale')
        bn_bias_attr = ParamAttr(
            regularizer=L2Decay(norm_decay), name=bn_name + '_offset')
        return fluid.layers.batch_norm(
            input=conv,
",4
"from paddlehub.module.module import moduleinfo, runnable
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
from paddlehub.io.parser import txt_parser

",4
"
    # We first tokenize `orig_text`, strip whitespace from the result
    # and `pred_text`, and check if they are the same length. If they are
    # NOT the same length, the heuristic has failed. If they are the same
    # length, we assume the characters are one-to-one aligned.
",4
"                        prev_is_whitespace = True
                    else:
",4
"        act=None,
        name='Dense1',
        size=512,
        bias_attr='Dense1_bias')
",4
"			switch (obj['vAlign']) {
			case 'top':
				y = obj['offsetY'];
				break;
",4
"			}
			if (this.adPlayerPlay) {
",4
"            org_img = org_img.astype(np.uint8)
            org_img = Image.fromarray(org_img[:, :, ::-1])
            if visualization:
                org_img_path = get_save_image_name(
",4
"        postprocess_cmd,
        prepostprocess_dropout,
",4
"    def _upsample(self, input, scale=2, name=None):
        out = fluid.layers.resize_nearest(
",4
"        x /= tmp.reshape((x.shape[0], 1))
    else:
        tmp = np.max(x)
        x -= tmp
",4
"        for key, value in zip(config_list[0::2], config_list[1::2]):
            options_str += ""--"" + key + ""="" + value + "" ""
        return options_str

",4
"        mask_trans_feat = fluid.layers.fc(
            input=mask_feat,
",4
"        for i, (input_dim, feature) in enumerate(
                zip(self.feature_dims, self.feature_input)):
            att = LSTMAttentionModel(input_dim, self.embedding_size,
                                     self.lstm_size, self.drop_rate)
            att_out = att.forward(feature, is_training=(self.mode == 'train'))
",4
"                    i, self.min_level)
",4
"        filter_size=[3, 3],
        stride=[1, 1],
",4
"                if not self._predictor:
                    self._predictor = self._create_predictor()
                run_states = self._run_with_predictor()
",4
"        if self.regularization[""L2""]:
            for param in self.main_program.global_block().all_parameters():
                param.regularizer = fluid.regularizer.L2Decay(
                    regularization_coeff=self.regularization[""L2""])
",4
"
        if output_dir is None:
",4
"        self.rpn_batch_size_per_im = rpn_batch_size_per_im
        self.rpn_straddle_thresh = rpn_straddle_thresh
",4
"    return model
",4
"				height: '100%',
",4
"
    @runnable
    def run_cmd(self, argvs):
        self.parser = argparse.ArgumentParser(
",4
"        """"""Get the first feature of each sequence for classification""""""

        next_sent_feat = fluid.layers.slice(
            input=self._enc_out, axes=[1], starts=[0], ends=[1])
",4
"import json

import paddle.fluid as fluid

",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"        if sampler[6] != 0 and \
                overlap < sampler[6]:
            satisfied.append(False)
            continue
",4
"# coding=utf-8
",4
"            num_filters=self.num_chan,
",4
"            name='rgb_lstm_backward')
",4
"        param_attr='_base_net_7_branch2_3_bn_weight',
        bias_attr='_base_net_7_branch2_3_bn_bias',
        moving_mean_name='_base_net_7_branch2_3_bn_running_mean',
        moving_variance_name='_base_net_7_branch2_3_bn_running_var',
        use_global_stats=False,
",4
"            handle_id = iter_id * batch_size
",4
"                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"                  d_inner_hid,
                  prepostprocess_dropout,
                  attention_dropout,
",4
"
            objs = tree.findall('object')
            im_w = float(tree.find('size').find('width').text)
            im_h = float(tree.find('size').find('height').text)
",4
"            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)
",4
"                                (self._sample_num, self._pos))
                    self._sample_num = self._pos

                self._data_iter = None
                self._drained = True
",4
"                1,
                'max',
",4
"                paths=paths,
                images=images,
",4
"                            if 'bbox_pred' in var.name or 'cls_score' in var.name:
                                return False
                        return os.path.exists(
",4
"        """"""
        Run as a service.
        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.classification(images=images_decode, **kwargs)
",4
"				var ele = document.createElement('div');
				ele.className = random;
",4
"
        # Make the layer name and parameter name consistent
        # with ImageNet pre-trained model
        conv = input
        for i in range(count):
",4
"        emb_out = emb_out + position_emb_out
",4
"                doc_tokens = []
                char_to_word_offset = []
                prev_is_whitespace = True
",4
"        top_k (int): Return top k results.
    """"""
    output = []
    for result in data_out:
        result_i = softmax(result)
",4
"        for i, (c, k, s, act, g, _name) in enumerate(conv_def):
            residual = self._conv_norm(
                input=residual,
",4
"                main_program.global_block().vars[prefix_name + data_name]
            }
            outputs = {
                ""class_probs"":
                main_program.global_block().vars[prefix_name + pred_name],
",4
"
    # running
",4
"
",4
"        h, w = batch_data[0][0].shape[1:3]
        scale_x = float(shape) / w
        scale_y = float(shape) / h
        for data in batch_data:
            im = cv2.resize(
",4
"    ymin = max(min(bbox[1], img_height), 0.)
    xmax = max(min(bbox[2], img_width), 0.)
    ymax = max(min(bbox[3], img_height), 0.)
",4
"    img_mean = np.array([0.406, 0.456, 0.485]).reshape((1, 1, 3))
",4
"			}
",4
"            in_c = int(c * scale)
        #last_conv
        input = self.conv_bn_layer(
",4
"import cv2
import numpy as np
",4
"        param_attr='Dense3_weights',
",4
"        name='_473',
",4
"            model_filename=model_filename,
            params_filename=params_filename)

    def object_detection(self,
",4
"				this.eliminateAd(); //
				return;
			}
",4
"                    while paragraph_text[answer_offset] in [
                            "" "", ""\t"", ""\r"", ""\n"", """", """", """", "":"", ""."", "",""
                    ]:
                        answer_offset += 1
",4
"            batch_data = list()
",4
"                model_filename='model',
                combined=True)

",4
"        int(img.size[0] / 10), img.size[0])
    height = height if height else np.random.randint(
        int(img.size[1] / 10), img.size[1])
    return image_resize(img, width, height, interpolation_method)

",4
"        else:
            return ret

",4
"        if phase == 'train':
",4
"        name='_311',
        bias_attr=False)
    _285 = fluid.layers.batch_norm(
",4
"                for input in signature.inputs
            ]
            outputs = [
",4
"from __future__ import absolute_import
from __future__ import division
",4
"                                        else fluid.initializer.Normal(loc = 0.0,
",4
"            if output_directory:
",4
"
    def _add_extras_block(self, input):
        cfg = self.extra_block_filters
        conv = input
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"        param_attr='_classification_headers_0_2_weight',
",4
"
",4
"        aggregated_precision += item_precision
    aggregated_precision /= num_videos
",4
"		//
		this.timerBuffer = null;
",4
"        img = img.convert('RGB')
    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = np.array(img).astype('float32').transpose((2, 0, 1)) / 255
    img -= img_mean
",4
"                sub_label = label
                if label.startswith(""B-""):
                    sub_label = ""I-"" + label[2:]
                ret_labels.extend([sub_label] * (len(sub_token) - 1))
",4
"            epoch_info_dict = self.calculator.get()
",4
"
        Returns:
             inputs(dict): the input variables.
             outputs(dict): the output variables.
",4
"            act=act,
            name=self.global_name + bn_name + '.output.1',
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"                                    initializer = fluid.initializer.Normal(loc = 0.0,
                                    scale = nonlocal_params[""conv_init_std""])), \
                                bias_attr = ParamAttr(name = prefix + '_theta' + ""_b"", \
",4
"        pre_process_layer(
            enc_input,
            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_att'),
",4
"                dropout_prob=dropout_rate,
",4
"    type=str,
    default="""",
    help=""Directory for saving model"")
parser.add_argument(
    ""--model_path"", type=str, default="""", help=""load model path"")
",4
"    author_email="""",
",4
"                handle_id,
                visualization=True):
",4
"            'v': '',
            'vd': '',
            'vn': '',
",4
"        recall = num_correct * 1.0 / num_label

",4
"import requests
",4
"        padding=[5, 5],
        dilation=[5, 5],
        groups=1,
        param_attr='_base_net_7_branch2_3_conv_weight',
",4
"        """"""
",4
"
            eval_result = []
            tmp_file = os.path.join(TMP_HOME, 'tmp.txt')
",4
"    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

    if cache is not None:  # use cache and concat time steps
",4
"        if not self._check_module_proto_version():
            result = False

",4
"            self._predict_data = None
            if return_result:
                return self._postprocessing(run_states)
        return run_states
",4
"        else:
            score_pred, loc_pred, score_tgt, loc_tgt, bbox_weight = \
                self.rpn_target_assign(
                    bbox_pred=rpn_bbox,
                    cls_logits=rpn_cls,
",4
"                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"        return image_paths, labels, len(class_names)
# Configuration file for the Sphinx documentation builder.
#
",4
"    output = dict()
",4
"        #   Question: What year was John Smith born?
        #   Context: The leader was John Smith (1895-1943).
        #   Answer: 1895
",4
"                        'head_features':
",4
"            'is_crowd': bool,
            'gt_class': list of np.ndarray, # classids info
",4
"        self.stage_filters = [64, 128, 256, 512]
",4
"                    padding=1,
",4
"    Position-wise Feed-Forward Networks.
",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
    return out
",4
"			this.css(controlBarID, {
				width: '100%',
				height: bHeight + 'px',
",4
"		//
		this.isClick = false;
		//
",4
"            each['org_im'] = Image.fromarray(im[:, :, ::-1])
            each['org_im_path'] = 'ndarray_time={}'.format(
                round(time.time(), 6) * 1e6)
",4
"import numpy as np
from PIL import Image

__all__ = ['reader']
",4
"			var i = 0;
			var k = '';
			if (typeof(elem) == 'object') { //
				if (!this.isUndefined(typeof(elem.length))) { //
					for (i = 0; i < elem.length; i++) {
",4
"        """"""
        Run as a service.
        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.object_detection(images=images_decode, **kwargs)
",4
"					if (logoFile.substr(0, 15) == 'data:image/png;' || logoFile.substr(0, 15) == 'data:image/jpg;' || logoFile.substr(0, 16) == 'data:image/jpeg;') {
						this.getByElement(logoID).innerHTML = '<img src=""' + logoFile + '"" border=""0"">'; //logo
					}
",4
"        },
",4
")
class SentaTest(hub.Module):
    def _initialize(self):
        # add arg parser
",4
"				newCanvas.width = this.V.videoWidth;
",4
"
",4
"
            # postprocess one by one
            for i in range(len(batch_data)):
                out = postprocess(
",4
"    for e in ds.get_dev_examples()[:10]:
        print(e)
",4
"				quality: 'high',
",4
"        self.question_text = question_text
        self.doc_tokens = doc_tokens
",4
"        max_level (int): highest level of FPN layer
",4
"                    normalizations=[20., -1, -1, -1, -1, -1])
",4
"
class RoIAlign(object):
    def __init__(self, resolution=7, spatial_scale=0.0625, sampling_ratio=0):
        super(RoIAlign, self).__init__()
",4
"                name='mask_lm_trans_layer_norm_scale',
",4
"            out = fluid.layers.softmax(out)
            return out
        else:
            return blocks
# coding=utf-8
",4
"
pic_dir = '../image_dataset/classification/animals/'


",4
"            gt_class[:gt_num] = sample['gt_class'][:gt_num, 0]
",4
"    width, height = img.size
    size = target_size
    if center == True:
",4
"        module_attr.type = module_desc_pb2.STRING
        module_attr.s = pyobj
    elif isinstance(pyobj, six.binary_type):
        module_attr.type = module_desc_pb2.STRING
",4
"        assert isinstance(string_list, list)
        blocks_args = []
        for block_string in string_list:
",4
"        return self.check_info.module_code_version

    @property
    def module_proto_version(self):
",4
"    size = target_size
    if center == True:
        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
",4
"        self.face_detector = hub.Module(name=""pyramidbox_lite_mobile"")

    @classmethod
",4
"        bias_attr=name + '_output_fc.b_0')
    return proj_out


def positionwise_feed_forward(x,
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"            feeded_var_names=feeded_var_names,
            target_vars=target_vars,
",4
"from __future__ import division

import os

",4
"from functools import partial

import paddle.fluid as fluid
",4
"        name=name + '_post_ffn')


def encoder(enc_input,
            attn_bias,
",4
"				thisTemp.sendJS('buffer', buffer);
			};
",4
"
    # Use ""sequence_output"" for token-level output.
    seq_output = outputs[""sequence_output""]

    # Setup feed list for data feeder
",4
"            if position < doc_span.start:
                continue
            if position > end:
",4
"import six

os.environ[""FLAGS_eager_delete_tensor_gb""] = ""0.0""

",4
"                 value_func=None):
",4
"
        prop_op = self.train_proposal if mode == 'train' else self.test_proposal
        if self.num_classes == 1:
            rpn_cls_prob_fpn = fluid.layers.sigmoid(
                rpn_cls_score_fpn, name='rpn_cls_prob_fpn' + str(feat_lvl))
",4
"                ind = np.argmax(probs, axis=1)
",4
"
    if cats[0] != 'background' and with_background:
        cats.insert(0, 'background')
",4
"        return fluid.layers.batch_norm(
            input=conv,
",4
"                 task_ids,
                 input_mask,
                 config,
                 weight_sharing=True,
                 use_fp16=False):
",4
"					easeInOut: function(t, b, c, d) {
						if (t == 0) return b;
						if (t == d) return b + c;
						if ((t /= d / 2) < 1) return c / 2 * Math.pow(2, 10 * (t - 1)) + b;
						return c / 2 * ( - Math.pow(2, -10 * --t) + 2) + b;
",4
"        results = []
        result_len = 0
        start_time = time.time()
        while result_len != data_num:
",4
"        mbox_locs, mbox_confs, box, box_var = self.env.mid_vars
",4
"            'negative_probs': 0.0593
        },
                        {
                            'text': '',
",4
"        startup_program = fluid.Program()
        with fluid.program_guard(context_prog, startup_program):
            with fluid.unique_name.guard():
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"                        }]
        self.labels = {""porn"": 1, ""not_porn"": 0}

",4
"                        global_run_states += period_run_states
                        period_run_states = []

                    if self.config.save_ckpt_interval and self.current_step % self.config.save_ckpt_interval == 0:
",4
"            org_img = Image.fromarray(org_img[:, :, ::-1])
            if visualization:
                org_img_path = get_save_image_name(
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"        for index, hparam_name in enumerate(self.hparams_name_list):
            print(""%s=%s"" % (hparam_name, local_hparams[index]))

        if local_min_reward <= self.best_reward_all_pop:
",4
"    else:
",4
"def encoder_layer(enc_input,
                  attn_bias,
                  n_head,
",4
"            except:
                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"        prepostprocess_dropout,
        name=name + '_post_ffn')


def encoder(enc_input,
",4
"        if name == ""conv1"":
",4
"    return tp.get_text()
# coding: utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"    if len(cls) != 0:
        values = []
        for i in range(len(cls)):
            _, accum_map = cls[i].get_map_var()
            cls[i].reset(exe)
",4
"import sys
import signal
import logging

",4
"        :param batch_size: batch size.
        :type batch_size: int
        :param top_k : top k
        :type top_k : int
",4
"                    self.env.current_epoch += 1

",4
"    g = fluid.layers.conv2d(input = max_pool, num_filters = dim_inner, \
                 filter_size = [1, 1], stride = [1, 1], \
",4
"    with open(file_path, 'r') as fr:
        text = fr.readlines()
        label_names = []
        for info in text:
            label_names.append(info.strip())
",4
"list. After processing all the parts, we call peek_map_at_n
to calculate the mean average precision.

```
import random
",4
"                data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
                    left (float): The X coordinate of the upper left corner of the bounding box;
                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
",4
"
        if self._is_no_log():
",4
"                 src_ids,
",4
"                    logger.warning(
                        ""Module integrity check failed! Missing file [%s]"" %
                        file_path)
                    result = False
",4
"        _436, name='_446', actual_shape=_445_cast, shape=[1, -1, 2])
    _457_cast = fluid.layers.cast(_457, dtype='int32')
",4
"                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
            return config_dict

",4
"        anchor_generator (object): `AnchorGenerator` instance
        rpn_target_assign (object): `RPNTargetAssign` instance
        train_proposal (object): `GenerateProposals` instance for training
",4
"    dict(op='ResizeImage', target_size=800, max_size=1333, interp=1),
",4
"				dataType: 'json',
				//
				charset: 'utf-8',
				async: false,
				//truefalse
",4
"    """"""
    get sum(version), eg: version_sum(1.4.5) = 1*100*100*100 + 4*100*100 + 5*100
",4
"

",4
"    runner.run(suite)
from __future__ import print_function
from __future__ import division
from __future__ import print_function
",4
"    name = ""hub""

",4
"    def get_labels(self):
        """"""
        Get the labels which was used when pretraining
",4
"                out = postprocess(
                    data_out=data_out[0].as_ndarray()[i],
                    org_im=batch_data[i]['org_im'],
",4
"        Returns:
",4
"                    name=self.global_name + 'fc_0.b_0'),
                param_attr=fluid.param_attr.ParamAttr(
",4
"
        # permute
        im = np.swapaxes(im, 1, 2)
        im = np.swapaxes(im, 1, 0)

",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# Export inference model for deployment
module.processor.save_inference_model(""./pyramidbox_lite_server_mask"")
print(""pyramidbox_lite_server_mask module export done!"")
",4
"        groups=1,
        param_attr='_base_net_3_3_weight',
        name='_263',
",4
"        return im_std
",4
"        return results
",4
"        Get the input ,output and program of the pretrained lac

        Args:
             trainable(bool): whether fine-tune the pretrained parameters of lac or not

",4
"                            results_pack.append(results[index])
                        os.remove(item)
",4
"    Args:
",4
"from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo

",4
"        map_type (string): method for mAP calcualtion,
",4
"    Args:
        class_num (int): the class number.
        overlap_thresh (float): The threshold of overlap
            ratio between prediction bounding box and
            ground truth bounding box for deciding
",4
"
def Res2Net50_vd_26w_8s():
    model = Res2Net_vd(layers=50, scales=8, width=26)
",4
"        rpn_cls_score = fluid.layers.reshape(
            x=rpn_cls_score, shape=(0, -1, self.num_classes))
",4
"        im_size = np.array([im_shape[0], im_shape[1]], dtype=np.int32)

        # decode image
        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
",4
"                  relu_dropout,
                  hidden_act,
                  preprocess_cmd=""n"",
                  postprocess_cmd=""da"",
",4
"from paddlehub.commands.base_command import BaseCommand, ENTRY
from paddlehub.common.cml_utils import TablePrinter
from paddlehub.common.hub_server import CacheUpdater
",4
"        num_anchor = self.anchor.shape[2]
",4
"            label_cn = """"

        cv2.rectangle(frame_copy, (left, top), (right, bottom), color, 3)
        cv2.putText(frame_copy, label, (left, top - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
",4
"def convert_to_unicode(text):
    """"""Converts `text` to Unicode (if it's not already), assuming utf-8 input.""""""
    if six.PY3:
",4
"                outputs = {
                    out_key: [
                        context_prog.global_block().vars[varname]
                        for varname in out_value
                    ]
",4
"            filter_size=filter_size,
            stride=1,
",4
"            if args.input_text.strip() != '':
                if six.PY2:
",4
"        API for human pose estimation and tracking.
",4
"            keep_top_k=self.nms.keep_top_k,
            nms_threshold=self.nms.nms_threshold,
            normalized=self.nms.normalized,
            nms_eta=self.nms.nms_eta,
            background_label=self.nms.background_label)
",4
"    def conv_bn_layer(self,
",4
"        bn_name = prefix + ""_bn""
        blob_out = fluid.layers.batch_norm(blob_out, \
                      # is_test = test_mode, \
                      momentum = nonlocal_params[""bn_momentum""], \
",4
"                if self._base_data_reader.get_dev_examples() != []:
",4
"                             params_filename=None,
                             combined=True):
        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
",4
"
def reader(paths=[], images=None):
    """"""
    data generator

",4
"                num_filters=oup,
                filter_size=1,
                bn_act=None,
",4
"
        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
            executor=exe,
",4
"    type=""nlp/sentiment_analysis"")
class SentaCNN(hub.NLPPredictionModule):
    def _initialize(self, user_dict=None):
",4
"                         cache=None,
                         param_initializer=None,
                         name='multi_head_att'):
    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"                org_img_path = get_save_image_name(
",4
"
def parse_args():
    parser = argparse.ArgumentParser('mask detection.')
    parser.add_argument(
",4
"    if args.dataset.lower() == ""flowers"":
        dataset = hub.dataset.Flowers()
    elif args.dataset.lower() == ""dogcat"":
        dataset = hub.dataset.DogCat()
",4
"        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
",4
"                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
            except:
                raise RuntimeError(
",4
"                 metrics_choices=None,
                 sub_task=""squad"",
                 null_score_diff_threshold=0.0,
",4
"                      if_act=True,
                      act=None,
                      name=None,
",4
"        return self.check_info.file_infos

",4
"        stride=[1, 1],
",4
"        )

        self.add_params_file_arg()
",4
"				}
				delayTimeTemp--;
			};
",4
"
def encoder_layer(enc_input,
                  attn_bias,
",4
"        Add the command config options.
",4
"        groups=1,
        param_attr='_classification_headers_2_2_weight',
        name='_403',
",4
"                    if param.name in self.scheduler[""gradual_unfreeze""][
                            ""params_layer""]:
",4
"        # self.mobilenet_v1 = hub.Module(name=""mobilenet_v1"")
        self.vgg16 = hub.Module(name='vgg16_imagenet')
",4
"			if (skipConfig['skipButtonShow']) {
				this.css(thisTemp.CB['adSkip'], 'display', 'block');
				if (skipConfig[this.adType + 'SkipButtonDelay'] > 0 && this.isUndefined(this.adSkipButtonTime)) {
					timeFun();
",4
"    name='Requires',
    full_name='paddlehub.module.checkinfo.Requires',
",4
"        if not version_2_with_negative:
",4
"
    def setUp(self):
",4
"                token_feature.shape
",4
"    __shared__ = ['norm_type', 'freeze_norm', 'weight_prefix_name']

    def __init__(self,
                 depth=50,
                 freeze_at=0,
",4
"

def encoder_layer(enc_input,
",4
"from __future__ import unicode_literals

import paddle.fluid as fluid
from paddle.fluid import ParamAttr

",4
"        p = fluid.layers.softmax(
            theta_phi_sc, name=prefix + '_affinity' + '_prob')
    else:
",4
"            param_attr=fluid.ParamAttr(
                name=""pooled_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""pooled_fc.b_0"")
",4
"        self.label_names = load_label_info(
            os.path.join(self.directory, ""label_file.txt""))
        self._set_config()
",4
"        results = self.classification(
",4
"                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
__all__ = ['create_list']


",4
"            '--input_path', type=str, help=""path to image."")
",4
"
        return res

    def add_module_config_arg(self):
",4
"import time
",4
"
    def __init__(self,
                 depth=53,
",4
"        self.get_prediction = get_prediction
        self.class_dim = class_dim

",4
"        max_level (int): highest level of the backbone feature map to use
        spatial_scale (list): feature map scaling factor
",4
"        self._type = utils.from_module_attr_to_pyobj(
            module_info.map.data['type'])
        self._summary = utils.from_module_attr_to_pyobj(
",4
"logger = logging.getLogger(__name__)


def box_flip(boxes, im_shape):
",4
"        else:
            features = self._convert_examples_to_records(
                examples, self.max_seq_len, self.tokenizer, phase)
            self.all_features[phase] = features

",4
"			var objClickEvent = this.clickEvent(obj['clickEvent']);
			/*if(objClickEvent['type']=='link'){
				html = '<a href=""'+objClickEvent['link']+'"" target=""'+objClickEvent['target']+'"">' + html + '</a>';
",4
"            num_filters=num_filters,
            filter_size=3,
",4
"            r = requests.get(url, stream=True)
            total_length = r.headers.get('content-length')

            if total_length is None:
",4
"                        continue
",4
"        ...

        root/test/dog/xxx.jpg
        ...
        root/test/cat/123.jpg
",4
"from __future__ import division
from __future__ import print_function

import os

",4
"        result_i = {}
        result_i['text'] = texts[index]['origin']
        label = int(np.argmax(predict_out[index]))
        if label == 0:
            key = 'negative'
",4
"                    max_prob = res[k]
                    res_dict[class_name] = max_prob
                res_list.append(res_dict)
",4
"                sample['gt_score'] = crop_score
                return sample
            return sample

",4
"                    ""name""].s
                return True, info
            else:
                module_file = os.path.realpath(
                    os.path.join(module_path, 'module.py'))
",4
"        conv = self.conv_bn_layer(
            input=input,
            num_filters=32,
            filter_size=3,
",4
"                paragraph_text = paragraph[""context""]
                context = _tokenize_chinese_chars(paragraph_text)

                doc_tokens = []
                char_to_word_offset = []
",4
"import time
from collections import OrderedDict

",4
"    """"""
    num_boxes = dt_boxes.shape[0]
    sorted_boxes = sorted(dt_boxes, key=lambda x: x[0][1])
",4
"        if not argv:
            print(""ERROR: Please specify a module or a model\n"")
",4
"        Args:
",4
"                dt_i['left'] = float(detect_face[0])
                dt_i['top'] = float(detect_face[1])
                dt_i['right'] = float(detect_face[2])
                dt_i['bottom'] = float(detect_face[3])
                dt_i['confidence'] = float(detect_face[4])
",4
"                if return_list:
                    # for DataFeeder
",4
"import argparse
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"class MultiClassNMS(object):
    # __op__ = fluid.layers.multiclass_nms
    def __init__(self,
",4
"                        'image': var_prefix + image.name,
                        'im_info': var_prefix + im_info.name,
",4
"        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.face_detection(images_decode, **kwargs)
        return results
",4
"        """"""
        Add the command input options.
        """"""
",4
"            outputs (list): Variables of each output layer
        """"""

        outputs = []
",4
"nonlocal_params = {
    ""use_zero_init_conv"": False,
    ""conv_init_std"": 0.01,
    ""no_bias"": True,
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not."")
",4
"        label_names = []
        for info in text:
            label_names.append(info.strip())
        return label_names
",4
"import hashlib
import platform
import base64

import paddle.fluid as fluid
",4
"				this.addListenerInside('mouseout', adOtherCloseOut, this.getByElement(closeAdDivID + '-canvas'));
			}
			this.addListenerInside('load',
",4
"                }
                # names of outputs
                if get_prediction:
                    locs, confs, box, box_var = fluid.layers.multi_box_head(
                        inputs=body_feats,
",4
"                file_info.file_name = file
                file_info.type = check_info_pb2.FILE
                file_info.is_need = True

",4
"            input=position_ids,
            size=[self._max_position_seq_len, self._emb_size],
            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))
",4
"# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"                top (float): The Y coordinate of the upper left corner of the bounding box;
                right (float): The X coordinate of the lower right corner of the bounding box;
                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
",4
"        paths = paths if paths else list()
        data_reader = partial(reader, paths, images)
",4
"# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"        result_i['porn_detection_key'] = key
        result_i['porn_probs'] = float('%.4f' % predict_out[index, 1])
        result_i['not_porn_probs'] = float('%.4f' % (predict_out[index, 0]))
        result.append(result_i)
    return result
",4
"                  fill='red')
        draw.line([(box[1][0] - 1, box[1][1] + 1),
",4
"                results_pack.append(results[index])
",4
"                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
                    initializer=fluid.initializer.Constant(1.)),
",4
"    def accumulate(self, predictions, actuals, num_positives=None):
        """"""Accumulate the predictions and their ground truth labels.

",4
"#   Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

",4
"def get_save_image_name(img, output_dir, image_path):
    """"""Get save image name from source image path.
    """"""
",4
"						if (va[1]) {
							type = ' type=""' + va[1] + '""';
							if (type == ' type=""video/m3u8""' || type == ' type=""m3u8""') {
",4
"        next_sent_fc_out = fluid.layers.fc(
            input=next_sent_feat,
",4
"				if (buLeft < 0) {
					buLeft = 0;
				}
",4
"                        gt_boxes=gt_bbox,
",4
"				return null;
",4
"								});
								ele.setAttribute('data-x', '0');
								ele.setAttribute('data-y', eleTop);
								var ele2 = document.createElement('div');
								ele2.className = random + 'd2';
",4
"
    @classmethod
    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.""""""
",4
"            default=False,
            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
            '--output_dir',
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import json
",4
"            description=
            ""Run configuration for controlling module behavior, not required."")

",4
"                predictor_config.switch_ir_optim(True)
            else:
                predictor_config.disable_gpu()
            predictor_config.enable_memory_optim()
",4
"            results += batch_result

        for index in empty_str_indexes:
",4
"            _file = os.path.realpath(sys.modules[_item.__module__].__file__)
",4
"                  preprocess_cmd=""n"",
                  postprocess_cmd=""da"",
                  param_initializer=None,
                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
",4
"                elif module_type.startswith(""nlp""):
                    input_data[key] = [self.args.input_text]
        else:
            for key in expect_data_format.keys():
",4
"            ""ImageClassificationDataset is no longer recommended from PaddleHub v1.5.0, ""
            ""please use BaseCVDataset instead of ImageClassificationDataset. ""
            ""It's more easy-to-use with more functions and support evaluating test set ""
",4
"
import six
import json
",4
"
__all__ = ['DarkNet']


",4
"
    return pretrained_parameters
",4
"    }
    im.convertTo(im, CV_32FC3, 1.0 / 256.0);
    rc = im.channels();
    rw = im.cols;
",4
"        if not isinstance(name, str) or name.strip() == """":
            raise TypeError(""The hook name must be a non-empty string"")
",4
"        predict_out = predict_out[1:]
        # postprocess one by one
        res = list()
        for i in range(len(all_element)):
",4
"    def format_params_str(self, params):
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"                    alpha=0.8,
",4
")
class BertWwm(TransformerModule):
    def _initialize(self):
",4
"                       top_k=1):
        """"""
        API for image classification.
",4
"import copy

",4
"            title=""Config options"",
            description=
",4
"
        logger.warning(""%i bad examples has been dropped"" % drop)
        return examples


",4
"    }
}


class MobileNetV2():
",4
"                size=self.class_dim,
                param_attr=ParamAttr(
                    initializer=fluid.initializer.Uniform(-stdv, stdv),
                    name='fc_weights'),
                bias_attr=ParamAttr(name='fc_offset'))
",4
"        if os.path.exists(self.filepath):
",4
"        self.test_prog = None

    def test_context(self):
        with fluid.program_guard(self.test_prog):
",4
"            n_head,
            d_key,
            d_value,
",4
"                name = os.path.join(pretrained_model, p.name)
                loading_parameters[name] = p
                print(name, p.name)
        else:
",4
"        org_img_height = org_img.height
        org_img_width = org_img.width
        result_i = results[lod[index]:lod[index + 1]]
        for row in result_i:
",4
"    p = fluid.layers.transpose(p, [0, 2, 1])
",4
"                pool_type='avg',
                global_pooling=True,
                name=self.global_name + 'global_pooling',
",4
"        for k, v in self.metrics_zoo.items():
            if k == name:
                return v(name, mode, cfg)
        raise KeyError(name, self.metrics_zoo.keys())
",4
"			}
			return {
				x: eve.clientX + (document.documentElement.scrollLeft || this.body.scrollLeft) - this.pdCoor['x'],
",4
"        self.mobilenet_v1 = hub.Module(name='mobilenet_v1_imagenet')

    @classmethod
    def tearDownClass(self):
",4
"        Get mAP result
        """"""
        if self.mAP is None:
            logger.error(""mAP is not calculated."")
",4
"				var pW = (zlen * 10) + 20;
				this.css(this.CB['definitionP'], {
					width: pW + 'px'
				});
				this.css(this.CB['definition'], {
",4
"        override_params=override_params,
        use_se=use_se)
",4
"
from __future__ import absolute_import
",4
"            extension_scope=None,
            options=None),
        _descriptor.FieldDescriptor(
            name='data',
            full_name='paddlehub.module.desc.KVData.data',
",4
"                conv,
",4
"import six
import sentencepiece as spm
import pickle
",4
"        feed_list = [image.name, image_shape.name]
    elif 'rcnn' in module_name:
        image = input_dict['image']
",4
"        # transform: fc
        mask_trans_feat = fluid.layers.fc(
            input=mask_feat,
",4
"					});
					break;
				case 'text':
					this.css(idArr[i] + '_text', {
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
        is_test=True,
",4
"            assert os.path.isfile(
",4
"        ...
",4
"                        if_first=block == i == 0,
                        reduction_ratio=reduction_ratio,
                        name=conv_name)

",4
"            true/false positive. Default 0.5.
        map_type (str): calculation method of mean average
",4
"from paddle.fluid.initializer import Normal
from paddle.fluid.regularizer import L2Decay
",4
"    ctx_multiheads = scaled_dot_product_attention(q, k, v, attn_bias, d_key,
                                                  dropout_rate)

    out = __combine_heads(ctx_multiheads)
",4
"        self.rpn_negative_overlap = rpn_negative_overlap
        self.use_random = use_random


class GenerateProposals(object):
",4
"                      name=None):
        # Expansion and Depthwise Convolution
        oup = block_args.input_filters * block_args.expand_ratio  # number of output channels
",4
"            self.gpu_predictor = create_paddle_predictor(gpu_config)

        # model config setting.
        if not self.model_config:
",4
"    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"                input=out,
                size=self.class_dim,
                param_attr=ParamAttr(
                    initializer=fluid.initializer.MSRA(), name=""fc7_weights""),
",4
"                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
",4
"        Returns:
            inputs (dict): key is 'image', corresponding vaule is image tensor.
            outputs (dict): key is :
                'classification', corresponding value is the result of classification.
",4
"
from __future__ import absolute_import
",4
"        attn_output,
",4
"    def sigma(self):
        return self._sigma

",4
"        conv_2 = self._conv_layer(
",4
"                    rpn_straddle_thresh=self.rpn_target_assign.rpn_straddle_thresh,
                    rpn_fg_fraction=self.rpn_target_assign.rpn_fg_fraction,
                    rpn_positive_overlap=self.rpn_target_assign.rpn_positive_overlap,
",4
"					}
				}
",4
"            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
",4
"                name=conv_share_name + '_b',
                learning_rate=2.,
",4
"        poscount = 0.0

",4
"        n_head_self_attn_mask.stop_gradient = True

",4
"				endFun: function(time) {
					if (thisTemp.V) {
						if (thisTemp.V.duration > 0) {
							thisTemp.needSeek = 0;
							thisTemp.videoSeek(parseInt(time));
",4
"				return;
			}
			if (this.playerType == 'flashplayer') {
",4
"        self.use_flip = use_flip

        if not isinstance(target_size, list):
",4
"from __future__ import print_function

import json
import math
import os
",4
"                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))

        return BlockArgs(
            kernel_size=int(options['k']),
",4
"    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"    # save image path
    save_im_path = os.path.join(output_dir, im_prefix + ext)
    if os.path.exists(save_im_path):
",4
"            inplace=True)

",4
"					}
				}
			}
			this.PD.oncontextmenu = function(event) {
",4
"                org_im_path=element['org_im_path'],
                org_im_width=element['org_im_width'],
",4
"            total_length = r.headers.get('content-length')
",4
"        assert depth in [34, 50], \
            ""depth {} not in [34, 50]""
        assert variant in ['a', 'b', 'c', 'd'], ""invalid ResNet variant""
        assert 0 <= freeze_at <= 4, ""freeze_at should be 0, 1, 2, 3 or 4""
",4
"                )
                self.start_single_app_with_file()
            else:
                self.start_app_with_file()

",4
"        self.with_extra_blocks = with_extra_blocks
        self.extra_block_filters = extra_block_filters
        self.prefix_name = weight_prefix_name

    def _conv_norm(self,
",4
"                for _batch in batched_ds:
                    yield _batch
                    n += 1
                    if maxit > 0 and n == maxit:
                        return
",4
"				}
			}
			return {
				type: type,
",4
"        self._recover_variable_info(self.program)

    @property
    def serving_func_name(self):
",4
"        each (collections.OrderedDict): info of original image, preprocessed image.
    """"""
    component = list()
    if paths:
        for im_path in paths:
",4
"            prog='hub run {}'.format(self.name),
            usage='%(prog)s',
            add_help=True)

        self.arg_input_group = self.parser.add_argument_group(
",4
"
# regist reader, sort by alphabet
",4
"                padding=1,
                act='relu',
                name=name + str(i + 1))
",4
"			if (index > -1) {
				this.animateArray[index].callBackFunction();
				this.animateArray.splice(index, 1);
",4
"
    def _postprocessing(self, run_states):
        results = []
",4
"    """"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
",4
"                logger.warning(""Infer Error with server {} : {}"".format(
                    self.serving_list[self.con_index], err))
",4
"#        for p in params_list:
#            if p.name in state_dict.keys():
#                print('########### load param {} from file'.format(p.name))
#            else:
",4
"
",4
"            input=input,
            num_filters=64,
",4
"                    rpn_straddle_thresh=self.rpn_target_assign.rpn_straddle_thresh,
                    rpn_fg_fraction=self.rpn_target_assign.rpn_fg_fraction,
                    rpn_positive_overlap=self.rpn_target_assign.rpn_positive_overlap,
                    rpn_negative_overlap=self.rpn_target_assign.rpn_negative_overlap,
",4
"  Raises:
",4
"                n=n,
                s=s,
                name='conv' + str(i))
            in_c = int(c * scale)
",4
"        for epoch in range(args.num_epoch):
            # 
            for batch_id, data in enumerate(train_reader()):
",4
"        """""" Init

            Args:
",4
"                add_vars_prefix(context_prog, name_prefix)
",4
"					});
",4
"        self.num_examples = 0
# Copyright 2016 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"# coding=utf-8
",4
"        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')

        # extract the first token feature in each sentence
        next_sent_feat = self.get_pooled_output()
",4
"            each = OrderedDict()
            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
",4
"                place = fluid.CPUPlace()
                exe = fluid.Executor(place)
",4
"        if self._emb_size != self._hidden_size:
            emb_out = fluid.layers.fc(
                input=emb_out,
",4
"					for (var i = 0; i < arr.length; i++) {
						this.css(arr[i], 'display', show == true ? 'block': 'none');
					}
				}
			}
",4
"            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
",4
"def get_image_ext(image):
    if image.shape[2] == 4:
",4
"                name=self._pos_emb_name, initializer=self._param_initializer))

",4
"        """"""
        if use_gpu:
            try:
                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
",4
"    suite.addTest(TestResNet('test_classification'))
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# coding=utf-8
",4
"        use_data_parallel=args.use_data_parallel,
",4
"        self.model = model

    @property
    def model_type(self):
",4
"            help=""whether use GPU for prediction"")

",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"        }
",4
"            shuffle = False
            if hasattr(self.dataset, ""validate_data""):
                # Compatible with ImageClassificationDataset
                self.dataset.validate_data()
",4
"					this.addNum--;
					o.removeEventListener(e, f, t);
				} catch(e) {}
",4
"    init_range = 1.0 / math.sqrt(n)

    param_attr = fluid.ParamAttr(
",4
"        label_names = []
        for info in text:
            label_names.append(info.strip())
        return label_names
",4
"					x = 0;
				}
",4
"                 src_ids,
                 position_ids,
",4
"    # save image path
    save_im_path = os.path.join(output_dir, im_prefix + ext)
    if os.path.exists(save_im_path):
",4
"  // Prediction result
  std::vector<FaceResult> results;
  // Stage1: Face detection
  detector.Predict(img, &results, det_shrink);
  // Stage2: Mask wearing classification
",4
"

def test_reader(paths=None, images=None):
    """"""
    data generator
",4
"        return 224

    def get_expected_image_height(self):
        return 224
",4
"            logits=task_fc_out, label=task_labels, return_softmax=True)
        task_acc = fluid.layers.accuracy(input=task_softmax, label=task_labels)
        mean_task_loss = fluid.layers.mean(task_loss)
        return mean_task_loss, task_acc
",4
"    @abc.abstractmethod
    def _inference(self, data):
",4
"			this.addListenerInside('mouseout', defMouseOut, thisTemp.CB['definitionP']);
			var defMouseOver = function(event) {
				if (setTimeOutP) {
					window.clearTimeout(setTimeOutP);
",4
"if six.PY3:
    INF = math.inf
else:
    INF = float(""inf"")

",4
"
",4
"        param_attr='_regression_headers_3_weight',
        name='_447',
",4
"
    for data in picked_box_probs:
",4
"                batch_size=2)
            print(classification_results)


if __name__ == ""__main__"":
",4
"            stride,
",4
"                             params_filename=None,
",4
"            train_file=""train.tsv"",
            dev_file=""dev.tsv"",
            test_file=""test.tsv"",
",4
"        config_with_file(configs)
    else:
        print(""Start failed cause of missing configuration."")
",4
"                                        pool_type = 'max', \
                                        pool_stride = [max_pool_stride, max_pool_stride], \
                                        pool_padding = [0, 0], \
",4
"        input=rfc0, size=hid_dim * 4, is_reverse=True)

",4
"    author=""baidu-nlp"",
",4
"def check_cuda(use_cuda, err = \
    ""\nYou can not set use_gpu = True in the model because you are using paddlepaddle-cpu.\n \
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import base64
",4
"                ""Dataset is None or it has not any labels, label map = {}"".
                format(self.label_map))
",4
"    extension_ranges=[],
    oneofs=[],
    serialized_start=334,
",4
"            cudas=[""0""],
            popsize=5,
            output_dir=None,
    ):
        self._num_thread = len(cudas)
",4
"
@moduleinfo(
    name=""faster_rcnn_resnet50_fpn_coco2017"",
    version=""1.0.0"",
    type=""cv/object_detection"",
",4
"				pauseStretched: 2,
				endStretched: 2
			},
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"            '--styles', type=str, help=""path to styles."")
        self.arg_input_group.add_argument(
            '--weights',
",4
"                    [image_tensor, im_size_tensor])

            output = postprocess(
",4
"                       shuffle=True,
                       data=None,
                       return_list=True):
        if phase != 'predict' and not self.dataset:
            raise ValueError(""The dataset is none and it's not allowed."")
",4
"        for im_path in paths:
",4
"        self.test_prog = fluid.Program()
",4
"
        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"        name='_281',
        bias_attr=False)
    _282 = fluid.layers.batch_norm(
        _281,
        momentum=0.8999999761581421,
",4
"        s += "", doc_tokens: [%s]"" % ("" "".join(self.doc_tokens))
        if self.start_position is not None:
            s += "", orig_answer_text: %s"" % (self.orig_answer_text)
",4
"                act='relu',
                name=_name)
",4
"        moving_mean_name='_base_net_10_4_running_mean',
",4
"                task_ids,
",4
"        param_attr='_base_net_3_0_weight',
        name='_260',
        bias_attr=False)
    _261 = fluid.layers.batch_norm(
",4
"        cardinality = self.cardinality
        width = self.width

        depth = [3, 4, 23, 3]
",4
"    theta = fluid.layers.reshape(theta, shape=(0, 0, -1))
    theta = fluid.layers.transpose(theta, [0, 2, 1])
",4
"                       phase='train',
                       shuffle=True,
",4
"    LoadModel(model_dir, use_gpu, &predictor_);
  }
",4
"        place = fluid.CPUPlace()
        exe = fluid.Executor(place)
",4
"				textAlign: 'center',
				zIndex: '995',
",4
"            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
            '--output_dir',
            type=str,
",4
"            if i > 0:  # perform concat in first 2 detection_block
                block = fluid.layers.concat(input=[route, block], axis=1)
            route, tip = self._detection_block(
                block,
                channel=512 // (2**i),
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"                    return os.path.exists(
                        os.path.join(self.default_pretrained_model_path,
                                     var.name))

",4
"            (6, 320, 1, 1),
        ]

        #conv1
        input = self.conv_bn_layer(
",4
"
",4
"        filter_size=[3, 3],
",4
"						marginRight: list[i]['marginRight'] + 'px',
						marginTop: list[i]['marginTop'] + 'px',
						marginBottom: list[i]['marginBottom'] + 'px'
",4
"                name=fpn_inner_name,
",4
"from __future__ import division
from __future__ import print_function

",4
"        attn_output,
        postprocess_cmd,
",4
"                 freeze_at=0,
",4
"            number=3,
            type=8,
",4
"        for im_path in paths:
            each = OrderedDict()
            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
            im = cv2.imread(im_path).astype('float32')
",4
"        self.character_type = config['character_type']
        self.loss_type = config['loss_type']
        if self.character_type == ""en"":
            self.character_str = ""0123456789abcdefghijklmnopqrstuvwxyz""
",4
"			if (this.adPlayerPlay) {
				this.adI++;
",4
"            relu_dropout,
            hidden_act,
            preprocess_cmd,
",4
"
",4
"            num_filters=int(num_filters2),
            stride=2,
",4
"        if use_gpu:
",4
"                deformable_groups=1,
                im2col_step=1,
                param_attr=ParamAttr(name=_name + ""_weights""),
                bias_attr=False,
",4
"    def __init__(self, owner, capacity, pos, size=0, alloc_status=''):
",4
"
",4
"        x -= tmp
        x = np.exp(x)
        tmp = np.sum(x)
        x /= tmp
",4
"    def __init__(self,
                 stride=[16.0, 16.0],
                 anchor_sizes=[32, 64, 128, 256, 512],
                 aspect_ratios=[0.5, 1., 2.],
",4
"
        output = fluid.layers.pool2d(
            input=input,
            pool_size=3,
",4
"    """"""resize image

",4
"                                        pool_size = [max_pool_stride, max_pool_stride], \
                                        pool_type = 'max', \
                                        pool_stride = [max_pool_stride, max_pool_stride], \
                                        pool_padding = [0, 0], \
",4
"    for index, text in enumerate(test_text):
        results[index][""text""] = text
    for index, result in enumerate(results):
        if six.PY2:
",4
"        use_global_stats=False,
        name='_255')
    _256 = fluid.layers.relu(_255, name='_256')
",4
"        module17 = self._extra_block(module16, num_filters[3][0],
",4
"        for index in indexs:
            label = label_list[index]
",4
"				cLoading.stroke(); //
				cLoading.beginPath(); //
",4
"        if not self.config.use_data_parallel:
            self.env.main_program_compiled = None
",4
"                int(_places[0])
",4
"    def directory(self):
        return self._directory
",4
"    Args:
        paths (list[str]): the path of images.
        images (list(numpy.ndarray)):  list of images, shape of each is [H, W, C].
        data_out (lod_tensor): data produced by executor.run.
",4
"                _ph = 0
",4
"                cnt += imgs.shape[0]
                if batch_id % args.log_interval == 0:
",4
"
    # Construct transfer learning network
",4
"                # pretrained
",4
"        global_stats = True if freeze_norm else False
        out = fluid.layers.batch_norm(
            input=conv,
            act=act,
            name=norm_name + '.output.1',
",4
"
    def _pooling_block(self,
                       conv,
                       pool_size,
                       pool_stride,
",4
"                gt_bbox[i] = [x1, y1, x2, y2]
",4
"    'ModuleAttr',
",4
"        mean_task_loss = fluid.layers.mean(task_loss)
        return mean_task_loss, task_acc
",4
"    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# coding=utf-8
from __future__ import absolute_import
",4
"    intersect_ymax = min(sample_bbox[3], object_bbox[3])
    intersect_size = (intersect_xmax - intersect_xmin) * (
        intersect_ymax - intersect_ymin)
    sample_bbox_size = bbox_area(sample_bbox)
",4
"                if layers in [101, 152] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
",4
"        count = 0
        for idx, txt in enumerate(txts):
            if scores[idx] < drop_score:
",4
"            text = data['label'] + "": %.2f%%"" % (100 * data['confidence'])
            textsize_width, textsize_height = draw.textsize(text=text)
            draw.rectangle(
                xy=(left, top - (textsize_height + 5),
                    left + textsize_width + 10, top),
",4
"                channel,
",4
"            output_dir (str): The path to store output images.
",4
"        # draw label
        if image.mode == 'RGB':
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
",4
"        """"""
        Add the command input options.
        """"""
        self.arg_input_group.add_argument(
            '--input_path', type=str, help=""path to image."")
",4
"            args_num = len(get_args(func).args)
            if args_num != self._hook_params_num[hook_type]:
                raise ValueError(
                    ""The number of parameters to the hook hook_type:%s should be %i""
                    % (hook_type, self._hook_params_num[hook_type]))
",4
"from mobilenet_v1_imagenet.processor import load_label_info
from mobilenet_v1_imagenet.data_feed import test_reader

",4
"
    best_indexes = []
    for i in range(len(index_and_score)):
",4
"        'name': 'is_crowd',
        'shape': [1],
        'dtype': 'int32',
        'lod_level': 1
",4
"
    Args:
        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
        paths (list[str]): paths to images.
",4
"        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
        w_start = np.random.randint(0, width - size + 1)
",4
"                attr=battr,
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"    def add_module_input_arg(self):
        """"""
        Add the command input options.
",4
"				left: eidCoor['x'] + 'px',
				top: eidCoor['y'] + 'px'
",4
"        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
                image = fluid.layers.data(
",4
"def unique_name():
    return ''.join(random.sample(string.ascii_letters + string.digits, 8))

",4
"
        Operators:
            1.(optional) Scale the image to [0,1]
            2. Each pixel minus mean and is divided by std
",4
"            pool_type='avg')
",4
"        checkpoint_dir=args.checkpoint_dir,
        strategy=hub.AdamWeightDecayStrategy())

    # Define a classfication fine-tune task by PaddleHub's API
",4
"        resize_h = int(resize_h * ratio)
        resize_w = int(resize_w * ratio)
",4
"            title=""Input options"", description=""Input data. Required"")
",4
"        Returns:
            inputs (dict): key is 'image', corresponding vaule is image tensor.
",4
"        self.cv_module_method = {
            ""vgg19_imagenet"": ""predict_classification"",
",4
"class MultiClassNMS(object):
",4
"
    def check_input_data(self, args):
        input_data = list()
        if args.input_path:
",4
"
        Args:
            data (str): data to be stored in this buffer

        Returns:
",4
"            ch_out=32,
            filter_size=3,
",4
"        attn_output,
        postprocess_cmd,
        prepostprocess_dropout,
        name=name + '_post_att')
    ffd_output = positionwise_feed_forward(
",4
"            return self._conv_norm(input, ch_out, 1, stride, name=name)
        else:
            return input

",4
"                total_infer += infer_num
",4
"import paddle.fluid as fluid

from chinese_electra_base.model.transformer_encoder import encoder, pre_process_layer
",4
"        """"""
",4
"            name='INT', index=1, number=1, options=None, type=None),
        _descriptor.EnumValueDescriptor(
",4
"        Get the sentiment prediction results results with the texts as input

",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
",4
"__all__ = [
",4
"from __future__ import division
from __future__ import print_function
",4
"        """"""
        self.arg_config_group.add_argument(
",4
"        Run as a command.
        """"""
        self.parser = argparse.ArgumentParser(
",4
"            raise Exception(""No language type of data set is sepecified"")

        self.null_score_diff_threshold = null_score_diff_threshold
        self.n_best_size = n_best_size
        self.max_answer_length = max_answer_length
",4
"        loop_num = int(np.ceil(total_num / batch_size))

        res = []
        for iter_id in range(loop_num):
",4
"def get_category_info_from_anno(anno_file, with_background=True):
    """"""
    Get class id to category id map and category id
",4
"        bias_attr=False)
    _300 = fluid.layers.conv2d(
        _299,
        num_filters=12,
        filter_size=[3, 3],
",4
"            conv,
            channel,
            filter_size=1,
            stride=1,
            padding=0,
",4
"    serialized_end=317,
)

_CHECKINFO = _descriptor.Descriptor(
    name='CheckInfo',
",4
"            self.has_processed[phase] = True

        def _data_reader():
",4
"        next_sent_feat = fluid.layers.slice(
",4
"        Scaled Dot-Product Attention
        """"""
        scaled_q = layers.scale(x=q, scale=d_key**-0.5)
        product = layers.matmul(x=scaled_q, y=k, transpose_y=True)
        if attn_bias:
",4
"        for im_path in paths:
            each = OrderedDict()
            assert os.path.isfile(
",4
"# coding=utf-8
from __future__ import absolute_import
",4
"                feature_maps=[3, 4, 5])
            body_feats = backbone(image)
            # retina_head
            retina_head = RetinaHead(
",4
"        # will be initialized by constant zero by default.
",4
"            print('%s: %s' % (arg, value))
",4
"            url=url, save_path=_dir, print_progress=True)
",4
"                            break
                        gt_segm.append(np.array(poly).reshape(-1, 2))
",4
"
class CharacterOps(object):
",4
"    with open(osp.join(output_dir, 'trainval.txt'), 'w') as ftrainval:
",4
"from __future__ import print_function
from __future__ import unicode_literals

",4
"#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"			adpause: '',
			adpausetime: '',
			adpauselink: '',
			adinsert: '',
",4
"
def _is_whitespace(char):
",4
"            pool_size=pool_size,
            pool_type='max',
",4
"        if mod_type == ""module"":
            mod_type = ""Module""
        elif mod_type == ""model"":
            mod_type = ""Model""
",4
"                    output_dir='transfer_out',
                    visualization=True)

",4
"        if self._roidb is None:
            self._roidb = self._load()
",4
"                and isinstance(self.channel_first, bool)):
            raise TypeError(""{}: input type is invalid."".format(self))

    def __call__(self, sample, context=None):
        assert 'image' in sample, ""image data not found""
",4
"                resource_type is None
                or self.resource_list_file['type'][index] == resource_type)
        ]
",4
"        bert = BertModel(
            src_ids=input_ids,
            position_ids=position_ids,
",4
"    """"""
    result = []
    input_dict = {'text': texts}
    processed = lac.lexical_analysis(
",4
"		},
		/*
			
			
		*/
",4
"                 canonical_size=224,
                 box_resolution=7,
                 mask_resolution=14):
        super(FPNRoIAlign, self).__init__()
",4
"            help=""file contain input data"")
        self.arg_input_group.add_argument(
            '--text_1', type=str, default=None, help=""text to predict"")
        self.arg_input_group.add_argument(
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"                num_filters=64,
",4
"			
",4
"                body_features = outputs['body_features']

",4
"
    def test_context(self):
        with fluid.program_guard(self.test_prog):
            get_prediction = True
",4
"from . import show
",4
"            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.

",4
"
    @serving
",4
"
import os
import numpy as np

from paddlehub.dataset import BaseDataset
",4
"import paddle.fluid as fluid
",4
"        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"
    Args:
      predictions: A numpy matrix containing the outputs of the model.
",4
"                             param_attr = ParamAttr(name = prefix + '_phi' + ""_w"", \
                                 initializer = fluid.initializer.Normal(loc = 0.0,
                                 scale = nonlocal_params[""conv_init_std""])), \
                             bias_attr = ParamAttr(name = prefix + '_phi' + ""_b"", \
                                 initializer = fluid.initializer.Constant(value = 0.)) \
",4
"

def get_sub_feed(input, place):
",4
"					this.addListenerInside('click', clickHandler, this.getByElement(idArr[i]))
",4
"        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
",4
"
if __name__ == '__main__':
    test_module = Electra()
",4
"        except Exception:
            raise IOError(
                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
            return config_dict
",4
"        batch_size=args.batch_size,
        checkpoint_dir=args.checkpoint_dir,
        strategy=hub.AdamWeightDecayStrategy())
",4
"            keep_top_k=self.nms.keep_top_k,
            nms_threshold=self.nms.nms_threshold,
",4
"        print(""PaddleHub Serving has been stopped."")

    def start_app_with_args(self, workers):
        module = self.args.modules
",4
"			if (y90 == -0 && y180 == -90 && y270 == -0) {
				ys = true;
",4
"    they will not considered in attention weights.
    """"""
    keys = queries if keys is None else keys
    values = keys if values is None else values

",4
"from paddlehub.dataset.base_nlp_dataset import BaseNLPDataset

_DATA_URL = ""https://bj.bcebos.com/paddlehub-dataset/lcqmc.tar.gz""

",4
"        assert magic == self._magic_num, \
            'invalid header magic[%d] in shared memory' % (magic)
",4
"    # Setup RunConfig for PaddleHub Fine-tune API
",4
"			
			
			len
		*/
",4
"        sequence_output = electra.get_sequence_output()
        return pooled_output, sequence_output

",4
"            if i == 0:
                name = ""res"" + str(block + 2) + ""a""
            else:
                name = ""res"" + str(block + 2) + ""b"" + str(i)
        else:
",4
"		this.loadTime = 0;
",4
"            roi_feat (Variable): RoI feature from RoIExtractor.
            rois (Variable): Output of generate_proposals in rpn head.
",4
"        API for face detection.
",4
"            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
                try:
                    batch_data.append(all_images[handle_id + image_id])
                except:
",4
"        reshaped_emb_out = fluid.layers.reshape(
            x=self._enc_out, shape=[-1, self._emb_size])
",4
"        [""      "", ""    ""],
        [""     "", ""   ,     ""],
",4
"            self._predict_start_event()
",4
"            save_path (str): The path to save output images.
    """"""
    lod_tensor = data_out[0]
    lod = lod_tensor.lod[0]
",4
"        except:
            use_gpu = False

        if texts != [] and isinstance(texts, list) and data == {}:
            predicted_data = texts
",4
"            post_nms_top_n=prop_op.post_nms_top_n,
            nms_thresh=prop_op.nms_thresh,
",4
"            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
",4
"    if module_name in nlp_module:
        predict_nlp(input_data, module_name, batch_size)
    elif module_name in cv_module:
",4
"                             model_filename=None,
                             params_filename=None,
",4
"                x=self._enc_out, dtype=self._emb_dtype)

",4
"					} else if (end.substring(0, 1) == '-' || end.substring(0, 1) == '+') {
						if (typeof(obj['end']) == 'number') {
							c = parseInt(obj['end']) - b;
						} else {
",4
"		*/
		newVideo: function(c) {
			if (this.playerType == 'flashplayer') {
				this.V.newVideo(c);
				return;
",4
"    writer.release()


if __name__ == ""__main__"":
    args = parse_args()
",4
"                 is_scale=True,
                 is_channel_first=True):
",4
"            dev_file=""dev.tsv"",
            test_file=""test.tsv"",
            label_file=None,
",4
"        if len(sample['gt_bbox']) != len(sample['gt_class']):
            raise ValueError(""gt num mismatch: bbox and class."")
        for field in self.fields:
            if field == 'im_shape':
                h = sample['h']
",4
"        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
",4
"    """""" This class specifies the configurations for PaddleHub to finetune """"""

    def __init__(self,
                 log_interval=10,
",4
"    def __init__(self, num_class):
",4
"            try:
",4
"
    output = list()
    for index in range(len(lod) - 1):
",4
"                     initializer = fluid.initializer.Constant(value = 0.)) if (nonlocal_params[""no_bias""] == 0) else False, \
                 name = prefix + '_g')
    g_shape = g.shape
    # we have to use explicit batch size (to support arbitrary spacetime size)
",4
"                segment_ids = np.array(data[0][2]).astype(np.int64)
                input_mask = np.array(data[0][3]).astype(np.float32)
                labels = np.array(data[0][4]).astype(np.int64)
",4
"        shape=[1], dtype='float32', value=0.10000000149011612)
    _465 = fluid.layers.create_parameter(
        dtype='float32',
        shape=[1, 4420, 2],
",4
"    def __str__(self):
",4
"                    cur_chunk[""en""] = index + 1
                else:
                    chunks.append(cur_chunk)
                    cur_chunk = {""st"": index, ""en"": index + 1, ""type"": tag_type}
",4
"
			};
			clearTimerClick();
			if (this.isClick) {
",4
"
",4
"        x = np.exp(x)
        tmp = np.sum(x)
        x /= tmp
    return x

",4
"    if isinstance(img, str):
        utils.check_path(img)
        img = Image.open(img)
    return img

",4
"            target_vars=target_vars,
            model_filename=model_filename,
",4
"        return (None, None)

    def load_pretrain_params(self, exe, pretrain, prog, place):
",4
"
def MobileNetV3_large_x0_5():
    model = MobileNetV3(model_name='large', scale=0.5)
    return model

",4
"                visualization=True,
                output_dir='batch_out',
                use_multi_scale=True,
",4
"        if self.freeze_norm:
",4
"
    def _add_extras_block(self, input):
",4
"			/////
			this.css([playID, pauseID, frontID, nextID], {
				width: bWidth + 'px',
				height: bHeight + 'px',
				float: 'left',
",4
"        preprocessed_img = permute_image(preprocessed_img)
        preprocessed_img = normalize_image(preprocessed_img)
        yield [preprocessed_img]
# coding=utf-8
",4
"                          input,
                          num_filters,
",4
"
        Args:
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
",4
"        return layers.reshape(
            x=trans_x,
            shape=[0, 0, trans_x.shape[2] * trans_x.shape[3]],
            inplace=True)
",4
"            points, sside = self.get_mini_boxes(contour)
            if sside < self.min_size:
",4
"				}
			}
			if (this.adTimeAllTotal > 0) {
",4
"                attr=mask_lm_out_bias_attr,
                is_bias=True)

",4
"""""""BERT model.""""""

from __future__ import absolute_import
from __future__ import division
",4
"        """"""
        Tranform the texts(dict) to PaddleTensor
        Args:
             texts(list): each element is a dict that must have a named 'processed' key whose value is word_ids, such as
                          texts = [{'processed': [23, 89, 43, 906]}]
",4
"                data = line.strip().split(""_!_"")
                try:
                    example = InputExample(
",4
"    vocab = load_vocab(module.get_vocab_path())
",4
"    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
        """"""
        q = layers.fc(
",4
"                    left (float): The X coordinate of the upper left corner of the bounding box;
                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
",4
"        if cmd == ""a"":  # add residual connection
            out = out + prev_out if prev_out else out
        elif cmd == ""n"":  # add layer normalization
",4
"
    def get_pretraining_output(self, mask_label, mask_pos, labels):
        """"""Get the loss & accuracy for pretraining""""""

        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')
",4
"                with_extra_blocks=not get_prediction,
                yolo_v3=yolo_v3)
",4
"    Args:
        results (list): prediction bounding box results.
        class_num (int): evaluation class number.
        overlap_thresh (float): the postive threshold of
                        bbox overlap
",4
"

class VGG(object):
",4
"            for i, res in enumerate(result[0].as_ndarray()):
                res_dict = {}
                pred_label = np.argsort(res)[::-1][:top_k]
",4
"        """"""
        predictor config setting
        """"""
",4
"            scale=config['initializer_range'])

        self._build_model(src_ids, position_ids, sentence_ids, input_mask)

    def _build_model(self, src_ids, position_ids, sentence_ids, input_mask):
",4
"            stride=stride,
            padding=padding,
            act=None,
            param_attr=ParamAttr(name=name + "".conv.weights""),
",4
"        """"""clean up the environment after the execution of all tests.""""""
",4
"        im -= mean
        im /= std

        target_size = 800
        max_size = 1333
",4
"
",4
"			var adPauseCloseClick = function(event) {
				thisTemp.adPauseCloseFunction();
			};
			this.addListenerInside('click', adPauseCloseClick, this.CB['adPauseClose']);
			///
",4
"        param_attr='_base_net_2_3_weight',
        name='_257',
        bias_attr=False)
",4
"                last_bound = bound
                last_phrase_list = new_phrase_list
                last_lm_score = new_lm_score
            else:
",4
"        get vdl_writer for visualization.
        """"""
        if not os.path.exists(self.config.checkpoint_dir):
            mkdir(self.config.checkpoint_dir)
        tb_log_dir = os.path.join(self.config.checkpoint_dir, ""visualization"")
",4
"        input_filters, output_filters = block_args.input_filters, block_args.output_filters
        if id_skip and block_args.stride == 1 and input_filters == output_filters:
",4
"                fy=im_scale_y,
                interpolation=self.interp)
        else:
            if self.max_size != 0:
                raise TypeError(
",4
"
    def tokenize(self, text):
        """"""Tokenizes a piece of text.""""""
        text = convert_to_unicode(text)
        text = self._clean_text(text)
",4
"# you may not use this file except in compliance with the License.
",4
"        return results


",4
"            name=bn_name + '_offset',
            learning_rate=norm_lr,
",4
"            name=name + "".conv1"")
",4
"            top_output = self.fpn_inner_output[i - 1]
            fpn_inner_single = self._add_topdown_lateral(
                body_name, body_input, top_output)
            self.fpn_inner_output[i] = fpn_inner_single
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"def reader(images=None, paths=None):
    """"""
    Preprocess to yield image.
",4
"        stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)

        out = fluid.layers.fc(
            input=pool,
",4
"    Notes:
    ${anno_path} must contains xml file and image file path for annotations

",4
"from PIL import Image, ImageDraw

__all__ = ['base64_to_cv2', 'postprocess']
",4
"
        all_data = list()
        for yield_data in reader(images, paths):
            all_data.append(yield_data)
",4
"        self._set_config()

    def _set_config(self):
",4
"

if __name__ == ""__main__"":
",4
"                          original_image,
                          detection_boxes,
                          rec_results,
",4
"			}
		},
		/*
			
",4
"            act=act,
            num_groups=num_mid_filter,
",4
"            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

",4
"

command = ListCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"                filter_size=3,
                stride=1,
                padding=1,
",4
"            else:
                solut[i] = (
                    self.init_input[i] + 1.0) * ratio + self.init_input[i]
        return solut
",4
"            title=""Config options"",
",4
"        ""train"": {
            ""fields"":
            ['image', 'im_info', 'im_id', 'gt_box', 'gt_label', 'is_crowd'],
            ""OPS"":
",4
"                    input_data = [args.input_text]
",4
"        filter_size=[1, 1],
",4
"        name='x2paddle_36',
",4
"if __name__ == '__main__':
    ocr = ChineseOCRDBCRNN()
",4
"                         keys,
                         values,
                         attn_bias,
                         d_key,
",4
"
from functools import cmp_to_key
import tarfile
import sys
",4
"            padding=1,
",4
"        if max_score is None or score > max_score:
            max_score = score

    exp_scores = []
    total_sum = 0.0
",4
"    if freeze_norm:
        scale.stop_gradient = True
",4
"            precision, currently support '11point' and
            'integral'. Default '11point'.
        is_bbox_normalized (bool): whther bounding boxes
            is normalized to range[0, 1]. Default False.
",4
"            out = fluid.layers.fc(
                input=pool,
                size=self.class_dim,
                param_attr=fluid.param_attr.ParamAttr(
",4
"            ext = '.png'
        elif img.format == 'JPEG':
            ext = '.jpg'
",4
"                    num_filters=self.num_chan,
                    filter_size=3,
                    stride=2,
                    padding=1,
",4
"    def fix_layer_warp_name(self, stage_num, count, i):
        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
",4
"            filter_size=filter_size,
            stride=1,
            padding=(filter_size - 1) // 2,
            groups=groups,
            act=None,
",4
"                 norm_type='sync_bn',
                 norm_decay=0.,
",4
"import argparse
",4
"            im_shape (Variable): Actual shape of original image with shape
                [B, 3]. B is the number of images, each element consists of
                original_height, original_width, 1

        Returns:
",4
"        None,
        attn_bias,
        d_key,
",4
"            attn_bias,
",4
"        elif cmd == ""n"":  # add layer normalization
            out_dtype = out.dtype
",4
"        for i, output in enumerate(outputs):
            box, score = fluid.layers.yolo_box(
                x=output,
                img_size=im_size,
                anchors=self.mask_anchors[i],
",4
"def area_of(left_top, right_bottom):
    hw = np.clip(right_bottom - left_top, 0.0, None)
    return hw[..., 0] * hw[..., 1]


",4
"          hid_dim=128,
          channel_size=250,
          emb_dim=1024,
",4
"    data generator

    Args:
        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]
",4
"                 config,
                 weight_sharing=True,
",4
"        for data in batch_data:
            im_c, im_h, im_w = data[0].shape[:]
            padding_im = np.zeros((im_c, max_shape[1], max_shape[2]),
                                  dtype=np.float32)
            padding_im[:, :im_h, :im_w] = data[0]
",4
"            name='value',
            full_name='paddlehub.module.desc.ModuleDesc.Sign2varEntry.value',
            index=1,
",4
"        size=136,
        bias_attr='Dense3_bias')
    return Dense3
# coding=utf-8
",4
"            box[:, 0] = np.clip(
                np.round(box[:, 0] / width * dest_width), 0, dest_width)
            box[:, 1] = np.clip(
                np.round(box[:, 1] / height * dest_height), 0, dest_height)
            boxes[index, :, :] = box.astype(np.int16)
",4
"    def test_ndarray(self):
",4
"
from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
",4
"        return conv

    def _extra_block(self,
                     input,
                     num_filters1,
",4
"            containing_type=None,
            is_extension=False,
",4
"            modeldir = output_dir + ""/model-"" + str(idx) + ""/""
            log_file = output_dir + ""/log-"" + str(idx) + "".info""
            params_cudas_dirs.append([solution, cuda, modeldir, log_file])
",4
"    def _conv_bn(self,
                 input,
                 ch_out,
",4
"parser.add_argument(""--batch_size"",         type=int,               default=8,                         help=""Total examples' number in batch for training."")
parser.add_argument(""--module"",             type=str,               default=""ssd"",                 help=""Module used as feature extractor."")
",4
"
if __name__ == ""__main__"":
",4
"        else:
            self._sent_types = config['type_vocab_size']

",4
"        'SourceHanSansSC-Medium.otf', fontsize, encoding=""utf-8"")
    #color = (255,0,0) # 
    #position = (100,100)# 
    color = color_bgr[::-1]
",4
"                    if i == 0:
",4
"        dilation=[1, 1],
        groups=64,
        param_attr='_base_net_5_0_weight',
        name='_272',
",4
"    """"""
",4
"
        if self.num_classes == 1:
            rpn_cls_prob = fluid.layers.sigmoid(
                rpn_cls_score, name='rpn_cls_prob')
",4
"            variance=self.anchor_generator.variance)

        cls_num_filters = num_anchors * self.num_classes
        self.rpn_cls_score = fluid.layers.conv2d(
            input=conv_rpn_fpn,
",4
"				bottom: '34px',
				cursor: 'pointer',
				zIndex: '992'
			});
",4
"        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
        return im_mean

    def get_pretrained_images_std(self):
        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
",4
"            fc7 = self._conv_layer(fc6, 1024, 1, 1, 0, name=""fc7"")
",4
"            num_groups=int(num_groups),
",4
"        if module_version and module_version != self.modules_dict[module_name][
",4
"                im -= mean
                im /= std
                sample[k] = im
",4
"			this.css(this.CB['menu'], {
",4
"        if type(src) is str and six.PY3:
",4
"
    def add_module_config_arg(self):
        """"""
",4
"        self.seg_num = self.get_config_from_sec(mode, 'seg_num', self.seg_num)
        self.short_size = self.get_config_from_sec(mode, 'short_size')
        self.target_size = self.get_config_from_sec(mode, 'target_size')
        self.num_reader_threads = self.get_config_from_sec(
",4
"            pool_stride=2,
            pool_padding=1,
            pool_type='max')
        return output
",4
"                        predicate=_if_exist)
                else:
                    exe.run(startup_program)

                return inputs, outputs, context_prog
",4
"						}
						break;
					default:
						break;
					}
",4
"            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
",4
"			this.adOtherCloseAll();
			this.adTimeTotal = -1;
		},
		/**/
",4
"

class RegressionTask(BaseTask):
    def __init__(self,
                 feature,
",4
"        assert type(capacity) is int, ""invalid type of capacity[%s]"" \
            % (str(capacity))

        assert capacity > 0, '""size of shared memory should be greater than 0'
        self._released = False
",4
"        self.test_image_dir = test_image_dir
        self.test_list_file = test_list_file
",4
"        self.data_augmentation = data_augmentation
        self.images_std = images_std
        self.images_mean = images_mean
",4
"            sequence_output (tensor): token-level output for sequence task.
        """"""
",4
"        else:
            if img.mode == ""RGB"" or img.mode == ""L"":
                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
",4
"		},
",4
"			}
			if (typeof(c) != 'object') {
				this.eject(this.errorList[1]);
			}
			this.vars = this.standardization(this.varsConfig, c);
",4
"            name='MAP', index=6, number=6, options=None, type=None),
        _descriptor.EnumValueDescriptor(
            name='SET', index=7, number=7, options=None, type=None),
",4
"    x2paddle_24 = fluid.layers.relu(x2paddle_23, name='x2paddle_24')
    x2paddle_25 = fluid.layers.pad2d(
        x2paddle_24,
        pad_value=0.0,
",4
"
",4
"    keys = queries if keys is None else keys
    values = keys if values is None else values

",4
"        except Exception:
            raise IOError(
                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
",4
"def get_save_image_name(img, output_dir, image_path):
    """"""Get save image name from source image path.
    """"""
    image_name = os.path.split(image_path)[-1]
",4
"      int base = h * width + w;
      input_buffer[base + 0 * stride] =
          (im.at<cv::Vec3f>(h, w)[0] - mean[0]) * scale[0];
",4
"
    return blob_out


",4
"        res = []
        for iter_id, feed_data in enumerate(batch_reader()):
",4
"                 doc_tokens,
                 orig_answer_text=None,
                 start_position=None,
",4
"                        end_position=end_position)
",4
"            token_list = batch[0][0].reshape(-1).tolist()
            pos_list = batch[0][1].reshape(-1).tolist()
",4
"                          act=None,
                          name=None):
        pool = fluid.layers.pool2d(
            input=input,
",4
"        # get all data
        all_data = []
        for yield_data in reader(self.face_detector, images, paths, use_gpu):
            all_data.append(yield_data)

",4
"    def __init__(self):
        self.params = train_parameters
",4
"        self._model_type = 'ResNet'
        self.feature_maps = feature_maps
        self.dcn_v2_stages = dcn_v2_stages
        self.depth_cfg = {
",4
"            target_vars=target_vars,
            model_filename=model_filename,
            params_filename=params_filename)

    @serving
",4
"        self.test_prog = None

",4
"        """"""
        Add the command config options
        """"""
        self.arg_config_group.add_argument(
",4
"    ""GRB"": [1, 0, 2],
    ""BGR"": [2, 1, 0],
    ""BRG"": [2, 0, 1]
",4
"        run_step = run_time_used = run_examples = 0
        precision_sum = recall_sum = f1_score_sum = 0
",4
"                 sentence_ids,
                 task_ids,
                 input_mask,
",4
"    @runnable
    def run_cmd(self, argvs):
        """"""
        Run as a command.
        """"""
",4
"        bias_attr='_base_net_7_branch1_2_bn_bias',
",4
"        out = fluid.layers.resize_nearest(
",4
"                    visualization=True)

    def test_save_inference_model(self):
",4
"        if self.model_type == 'SEResNeXt':
            bn_name = name + ""_bn""
",4
"            num_filters=oup,
            filter_size=k,
            stride=s,
            num_groups=oup,
            bn_act=None,
",4
"        self.arg_config_group.add_argument(
",4
"                is_bbox_normalized=is_bbox_normalized)

",4
"		},
",4
"            for idx, sample in enumerate(batch_data):
                sample['points'] = points[idx].reshape(68, -1)
            res += batch_data

        res = postprocess(res, output_dir, visualization)
",4
"                input=subnet_blob,
",4
"# coding=utf-8
",4
"            input=next_sent_feat,
            size=2,
            param_attr=fluid.ParamAttr(
",4
"                num_filters=num_filter,
                filter_size=3,
                stride=1,
                padding=1,
",4
"    q = __split_heads(q, n_head)
    k = __split_heads(k, n_head)
",4
"            'https://paddlemodels.bj.bcebos.com/video_classification/TSN.pdparams'
        )

",4
"				ele.push([[this.CB['volume']], this.buttonWidth['volume']]);
				ele.push([[this.CB['mute'], this.CB['escMute'], this.CB['muteLine']], this.buttonWidth['mute'] + 2, 'mute']);
			}
			ele.push([[this.CB['timeText']], this.buttonWidth['timeText']]);
			ele.push([[this.CB['play'], this.CB['pause'], this.CB['playLine']], this.buttonWidth['play'] + 2, 'play']);
",4
"    """"""

    def __init__(self, ds, batchsize, drop_last=False, drop_empty=True):
        super(BatchedDataset, self).__init__(ds)
",4
"            filter_size=3,
",4
"
        assert self._cap % self._page_size == 0, \
            ""capacity[%d] and pagesize[%d] are not consistent"" \
",4
"            gpu_config.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def set_face_detector_module(self, face_detector_module):
",4
"            True,
",4
"
if __name__ == '__main__':
    main()
# coding=utf-8
from __future__ import absolute_import
",4
"            module_info.update({""cv_module"": [{""Choose..."": ""Choose...""}]})
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)

    for element in component:
        element['image'] = process_image(element['org_im'])
",4
"
    def find_module(self, module_name):
",4
"        pointwise_conv = self._conv_norm(
",4
"                                 initializer = fluid.initializer.Normal(loc = 0.0,
                                 scale = nonlocal_params[""conv_init_std""])), \
                             bias_attr = ParamAttr(name = prefix + '_phi' + ""_b"", \
                                 initializer = fluid.initializer.Constant(value = 0.)) \
",4
"
#include ""mask_detector.h"" // NOLINT

",4
"
        return out
",4
"        :param images: data of images, [N, H, W, C]
        :type images: numpy.ndarray
",4
"                examples.append(example)

            return examples
",4
"import requests
import tarfile

from paddlehub.common import utils
",4
"        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
                image = fluid.layers.data(
                    name=""image"", shape=[3, 224, 224], dtype=""float32"")
                resnet_vd = Res2Net101_vd_26w_4s()
",4
"		/*
			
			
		*/
		getNewUrl: function(url) {
",4
"    type=""nlp/semantic_model"",
)
class BertWwm(TransformerModule):
    def _initialize(self):
",4
"    object_bbox_size = bbox_area(object_bbox)
    overlap = intersect_size / (
        sample_bbox_size + object_bbox_size - intersect_size)
    return overlap

",4
"		},
",4
"      dictionary: A dictionary storing the metrics for the mini-batch.

",4
"                data_out=data_out,
                score_thresh=score_thresh,
",4
"        size=d_hid,
",4
"from paddlehub.module.module import serving
from paddlehub.module.module import moduleinfo
",4
"    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
",4
"parser.add_argument(""--batch_size"",         type=int,               default=16,                         help=""Total examples' number in batch for training."")
parser.add_argument(""--module"",             type=str,               default=""resnet50"",                 help=""Module used as a feature extractor."")
",4
"            return bn
",4
"        name=name + '_multi_head_att')
    attn_output = post_process_layer(
",4
"img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))


def resize_short(img, target_size):
    percent = float(target_size) / min(img.size[0], img.size[1])
",4
"  auto in_tensor = predictor_->GetInputTensor(input_names[0]);
  in_tensor->Reshape(input_shape_);
  in_tensor->copy_from_cpu(input_data_.data());
",4
"        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
        w_start = np.random.randint(0, width - size + 1)
",4
"
        cls_num_filters = num_anchors * self.num_classes
",4
"                    finally:
",4
"    test_iter = 0
",4
"        norm_type (str): normalization type, 'bn'/'sync_bn'/'affine_channel'
        freeze_norm (bool): freeze normalization layers
        norm_decay (float): weight decay for normalization layer weights
        variant (str): ResNet variant, supports 'a', 'b', 'c', 'd' currently
        feature_maps (list): index of stages whose feature maps are returned
",4
"                name=self.prefix_name + ""yolo_box"" + str(i))
            boxes.append(box)
",4
"# You may obtain a copy of the License at
#
",4
"
from chinese_ocr_db_crnn.character import CharacterOps
from chinese_ocr_db_crnn.utils import draw_ocr, get_image_ext, sorted_boxes


",4
"    return post_process_layer(
",4
"        # Since the inplace reshape in __split_heads changes the shape of k and
        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
        k = cache[""k""] = layers.concat(
            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
",4
"        trainable=True, max_seq_len=args.max_seq_len)
",4
"
",4
"            fc_out = fluid.layers.fc(
                input=mask_trans_feat,
                size=self._voc_size,
",4
"			
			animate
		*/
		animatePause: function(id) {
",4
"            return {""error"": ""Module {} is not available."".format(module_name)}
",4
"        if self.norm_type:
            initializer = Xavier(fan_out=fan)
            self.fpn_inner_output[0] = ConvNorm(
                body_input,
",4
"import cv2
import numpy as np
from PIL import Image

__all__ = ['reader']
",4
"

",4
"            logger.info('%s: %s' % (arg, value))
        logger.info('------------------------------------------------')


class ErnieModel(object):
",4
"    ""SE_ResNet18_vd is a image classfication model, this module is trained with imagenet datasets."",
    version=""1.0.0"")
",4
"                                bias_attr = ParamAttr(name = prefix + '_theta' + ""_b"", \
                                    initializer = fluid.initializer.Constant(value = 0.)) \
                                        if not nonlocal_params[""no_bias""] else False, \
                                name = prefix + '_theta')
    theta_shape = theta.shape
",4
"        inputs[""segment_ids""].name,
        inputs[""input_mask""].name,
    ]

",4
"        strategy=hub.AdamWeightDecayStrategy())

    # Define a reading comprehension fine-tune task by PaddleHub's API
",4
"
                # add_vars_prefix
                add_vars_prefix(context_prog, var_prefix)
",4
"        ffd_output,
        postprocess_cmd,
        prepostprocess_dropout,
",4
"        for index in indexs:
",4
"                                           if (nonlocal_params[""no_bias""] == 0) else False, \
                                  name = prefix + '_out')
",4
"    def init_with_name(cls, name, version=None, **kwargs):
        fp_lock = open(os.path.join(CACHE_HOME, name), ""a"")
        lock.flock(fp_lock, lock.LOCK_EX)
        log_msg = ""Installing %s module"" % name
        if version:
",4
"            org_img = Image.open(org_img_path)
",4
"            ]
            interval_left = sum(element_image_num[0:i])
            interval_right = interval_left + element_image_num[i]
",4
"            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv)))

",4
"        Args:
            prob (float): the probability of flipping image
            is_normalized (bool): whether the bbox scale to [0,1]
            is_mask_flip (bool): whether flip the segmentation
        """"""
",4
"					var subtitle = {
						sn: sn,
						startTime: startTime,
						endTime: endTime,
",4
"            gt_box=gt_box,
            gt_label=gt_label,
            prior_box=box,
",4
"        input=hidden,
",4
"import os
import time
from collections import OrderedDict

import cv2
",4
"        if six.PY2:
",4
"            usage='%(prog)s',
",4
"
    @app_instance.route(""/predict/image/<module_name>"", methods=[""POST""])
",4
"        """"""
        rpn_cls, rpn_bbox, anchor, anchor_var = self._get_loss_input()
",4
"        raise NotImplementedError(
            'model name is not pre-defined: %s' % model_name)
    if override_params:
        global_params = global_params._replace(**override_params)
",4
"    _269 = fluid.layers.conv2d(
        _268,
        num_filters=64,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"    return keys, values, cls


",4
"    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
",4
"        conv1_name = self.na.fix_c1_stage_name()

",4
"from paddlehub.common.paddle_helper import add_vars_prefix
",4
"from paddle.fluid.regularizer import L2Decay

",4
"
    def context(self, trainable=True, pretrained=True, get_prediction=False):
        """"""
        Distill the Head Features, so as to perform transfer learning.

",4
"
",4
"			}
",4
"import numpy as np
import string

",4
"        if self.norm_type:
",4
"        num_filters = [64, 128, 256, 512]

        conv = self.conv_bn_layer(
",4
"                                         -num_labels)[-num_labels:]
        item_precision = 0.0
        for label_index in top_indices:
",4
"        self.normalized = normalized
        self.score_threshold = score_threshold


class YOLOv3Head(object):
",4
"            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
            each['org_im_width'], each['org_im_height'] = each['org_im'].size
",4
"    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"    def classification(self,
                       images=None,
                       paths=None,
                       batch_size=1,
                       use_gpu=False,
",4
"                 weight_prefix_name=''):
",4
"
        rpn_cls = fluid.layers.concat(rpn_clses, axis=1)
        rpn_bbox = fluid.layers.concat(rpn_bboxes, axis=1)
",4
"    ctx_multiheads = scaled_dot_product_attention(q, k, v, attn_bias, d_key,
",4
"            background_label=self.nms.background_label)
",4
"                  n_head,
                  d_key,
",4
"
        img = img.astype(np.float32)
        gray = img * np.array([[[0.299, 0.587, 0.114]]], dtype=np.float32)
",4
"        for iter_id in range(loop_num):
            batch_data = list()
            handle_id = iter_id * batch_size
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"                    or (cp >= 0x3400 and cp <= 0x4DBF)
                    or (cp >= 0x20000 and cp <= 0x2A6DF)
",4
"        'enable_eval_rst': True,
        'enable_auto_toc_tree': False,
    }, True)
    app.add_transform(AutoStructify)
#coding:utf-8
",4
"            ""eval_interval_event"": 1,
",4
"    def __combine_heads(x):
",4
"            act='relu')
        conv2 = self.conv_bn_layer(
            input=conv1, num_filters=num_filters * 4, filter_size=1, act=None)
",4
"
import cv2
",4
"            return gen_result(""-1"", msg, """")
        inputs = request.json
        if inputs is None:
            results = ""This usage is out of date, please use 'application/json' as content-type to post to /predict/%s. See 'https://github.com/PaddlePaddle/PaddleHub/blob/release/v1.6/docs/tutorial/serving.md' for more details."" % (
",4
"            params_filename=params_filename)

",4
"
    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
        """"""
",4
"    Returns:
        img: cropped image data
",4
"    def setUpClass(self):
",4
"                coco_res = {
                    'image_id': im_id,
",4
"                    'category_id': catid,
                    'segmentation': segm,
                    'score': score
                }
",4
"    package_data={
        'paddlehub/serving/templates': [
            'paddlehub/serving/templates/serving_config.json',
            'paddlehub/serving/templates/main.html'
        ]
",4
"            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"    # Load Paddlehub ERNIE Tiny pretrained model
    module = hub.Module(name=""ernie_tiny"")
    inputs, outputs, program = module.context(
        trainable=True, max_seq_len=args.max_seq_len)

",4
"
        Returns:
            pred (Variable): The prediction result after non-max suppress.

        """"""
",4
"    version2 = version2.split(""."")
",4
"            pool_padding=1,
            pool_type='max')
        if layers >= 50:
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"				return;
			}
			if (this.playerType == 'flashplayer') {
",4
"            has_default_value=False,
            default_value=[],
            message_type=None,
",4
"    for more information
    """"""
",4
"
        self._enc_out = encoder(
            enc_input=emb_out,
",4
"
",4
"            input,
",4
"            seq_st = base_index + i * max_len + 1
            seq_en = seq_st + (lens[i] - 2)
",4
"            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
        v = cache[""v""] = layers.concat(
            [layers.reshape(cache[""v""], shape=[0, 0, d_model]), v], axis=1)

",4
"            label_list=[""0"", ""1"", ""2""],
",4
"            caffe_bn_name = 'BatchNormBackward' + str(layer_index) + '_bn'
            caffe_param_list.append(caffe_bn_name + '_scale')
            caffe_param_list.append(caffe_bn_name + '_offset')
            caffe_param_list.append(caffe_bn_name + '_mean')
            caffe_param_list.append(caffe_bn_name + '_variance')
",4
"                   stride,
                   padding,
                   act='leaky',
                   name=None):
        conv = fluid.layers.conv2d(
",4
"        _306,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
""""""BERT model.""""""
",4
"            postprocess_cmd=""da"",
            param_initializer=None,
            name=''):
",4
"        blocks_args, global_params = efficientnet(
            width_coefficient=w, depth_coefficient=d, dropout_rate=p)
    else:
",4
"
def predict_v2_advanced(module_info, input):
    serving_method_name = module_info[""method_name""]
",4
"            preprocess_cmd=""n"",
",4
"class NameAdapter(object):
    """"""Fix the backbones variable names for pretrained weight""""""

",4
"        self.scale = np.array(scale).reshape((3, 1, 1))
        self.threshold = threshold
        self.predictor = LoadModel(model_dir, use_gpu)
",4
"                for qa in paragraph[""qas""]:
                    qas_id = qa[""id""]
                    question_text = qa[""question""]
",4
"        ""is_bbox_normalized"": False,
        # ""norm_type"": ""affine_channel"",
",4
"                print(result)

    def test_batch(self):
        with fluid.program_guard(self.test_prog):
",4
"            stride=stride,
            padding=padding,
            dilation=dilation,
            act=act,
            use_cudnn=use_cudnn,
",4
"        gt_num = min(50, len(sample['gt_bbox']))
        if gt_num > 0:
            gt_bbox[:gt_num, :] = sample['gt_bbox'][:gt_num, :]
",4
"        return

    if not hub.HubServer()._server_check():
        raise ServerConnectionError

",4
"                        exe,
",4
"			
		*/
		canvasFillRect: function(name, path) {
",4
"        elif (groups * group_width) == 256:
            expand = 1
",4
"            return examples


if __name__ == ""__main__"":
    ds = INews()
",4
"                 sampling_ratio=0,
                 min_level=2,
                 max_level=5,
",4
"            if phase == ""predict"":
                for image_path in data:
                    image = preprocess(image_path)
                    images.append(image.astype('float32'))
                    if len(images) == batch_size:
",4
"            rois (Variable): Output of generate_proposals in rpn head.
            im_info (Variable): A 2-D LoDTensor with shape [B, 3]. B is the
                number of input images, each element consists of im_height,
                im_width, im_scale.
",4
"    model = SE_ResNet_vd(layers=34, is_3x3=True)
    return model

",4
"            'w': im_w, # width
            'is_crowd': is_crowd,
",4
"        for im in images:
            each = OrderedDict()
",4
"                    run_states = self._run(do_eval=do_eval)
",4
"            'paddlehub.module.checkinfo.CheckInfo.module_proto_version',
",4
"            n_head=self._n_head,
            d_key=self._emb_size // self._n_head,
            d_value=self._emb_size // self._n_head,
            d_model=self._emb_size,
",4
"            fc1 = fluid.layers.fc(
                input=conv,
                size=fc_dim,
                act='relu',
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS-IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"    preds *= pred_mask
    return preds, maxvals
",4
"            if len(tokens) > max_seq_length - 2:
",4
"
",4
"            use_gpu=args.use_gpu)
        return results

",4
"        29: 33,
        30: 34,
        31: 35,
        32: 36,
",4
"            type=ast.literal_eval,
",4
"        # Initialize all weigths by truncated normal initializer, and all biases
",4
"            stride=2,
            padding=1,
            if_act=True,
            name='conv1_1')
",4
"            file = request.files.getlist(""image"")
            for item in file:
",4
"        self.sum_perr = 0.0
",4
"    _379 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
",4
"    Conv2 = fluid.layers.conv2d(
        Pool1,
        param_attr='Conv2_weights',
        name='Conv2',
",4
"    summary=""This is a PaddleHub Module. Just for test."",
",4
"    elif img.format == 'BMP':
        ext = '.bmp'
    else:
        if img.mode == ""RGB"" or img.mode == ""L"":
",4
"from __future__ import division
from __future__ import print_function

import os
",4
"# coding=utf-8
def load_label_info(file_path):
    with open(file_path, 'r') as fr:
",4
"                data (numpy.ndarray): data of post processed image.
        """"""
",4
"            help=""confidence threshold."")
# coding=utf-8
import os
import math
import time
",4
"                int(_places[0])
            except:
                raise RuntimeError(
",4
"
",4
"
class YAMLFileParser(object):
",4
"        bias_attr='_base_net_7_branch1_0_bn_bias',
        moving_mean_name='_base_net_7_branch1_0_bn_running_mean',
",4
"class MultiClassNMS(object):
    # __op__ = fluid.layers.multiclass_nms
",4
"            filter_size=filter_size,
            stride=stride,
",4
"
",4
"from __future__ import division
from __future__ import print_function

import os

",4
"            '--input_file',
            type=str,
",4
"            height, width = pred.shape[-2:]
            tmp_boxes, tmp_scores = self.boxes_from_bitmap(
",4
"        with fluid.program_guard(context_prog, startup_program):
            with fluid.unique_name.guard():
                # image
                image = fluid.layers.data(
",4
"                best_hparams_origin)]

",4
"

def compute_f1(a_gold, a_pred):
    gold_toks = get_tokens(a_gold)
",4
"                ymin = int(sample_bbox[1] * image_height)
                ymax = int(sample_bbox[3] * image_height)
",4
"        return output

    def __call__(self, input):
        assert isinstance(input, Variable)
",4
"        bboxes = []
        for inst in instances:
",4
"
    @runnable
    def run_cmd(self, argvs):
        """"""
        Run as a command.
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"    Args:
      num_class: A positive Integer specifying the number of classes.
      top_n_array: A list of positive integers specifying the top n for each
",4
"                            progress(
                                '[%-50s] %.2f%%' %
                                ('=' * done, float(dl / total_length * 100)))
                if print_progress:
",4
"        sent_emb_out = fluid.layers.embedding(
",4
"                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
                    self._word_emb_name),
                transpose_y=True)
",4
"import paddle.fluid as fluid

from ..utils.voc_eval import bbox_eval as voc_bbox_eval
",4
"        param_attr='x2paddle_15',
        name='x2paddle_47',
",4
"        h_start = (height - size) // 2
    else:
        w_start = np.random.randint(0, width - size + 1)
        h_start = np.random.randint(0, height - size + 1)
",4
"				this.numberTotal = number;
			}
			this.start();
",4
"    ""resnet50"": ""resnet_v2_50_imagenet"",
    ""resnet101"": ""resnet_v2_101_imagenet"",
",4
"                image = fluid.layers.data(
                    name=""image"", shape=[3, 224, 224], dtype=""float32"")
",4
"    suite.addTest(TestResNet50vdDish('test_ndarray'))
    suite.addTest(TestResNet50vdDish('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
",4
"        },
        ""predict"": {
            ""fields"": ['image', 'im_info', 'im_id', 'im_shape'],
            ""OPS"": rcnn_predict_ops,
            ""IS_PADDING"": True,
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"import numpy as np
",4
"    ],
    license='Apache 2.0',
    keywords=('paddlehub paddlepaddle fine-tune transfer-learning'),
    entry_points={'console_scripts': ['hub=paddlehub.commands.hub:main']})
",4
"        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
",4
"
",4
"                module_package=argv[0], extra=extra)
        elif os.path.exists(argv[0]) and os.path.isdir(argv[0]):
            result, tips, module_dir = default_module_manager.install_module(
",4
"    with open(file_path, 'r') as fr:
",4
"            ""--workers"", ""-w"", nargs=""?"", default=number_of_workers())
        self.modules_info = {}

    def dump_pid_file(self):
        pid = os.getpid()
",4
"            input,
            num_filters * expand,
            stride,
            is_first=is_first,
            name=shortcut_name)
",4
"        """"""
        with tmp_dir() as _dir:
            self.save_inference_model(dirname=_dir)
",4
"        self.arg_input_group = self.parser.add_argument_group(
",4
"        return features

    def improve_answer_span(self, doc_tokens, input_start, input_end, tokenizer,
                            orig_answer_text):
        """"""Returns tokenized answer spans that better match the annotated answer.""""""
",4
"        self.feature_num = self.cfg.MODEL.feature_num
        self.feature_names = self.cfg.MODEL.feature_names
        self.feature_dims = self.cfg.MODEL.feature_dims
        self.num_classes = self.cfg.MODEL.num_classes
        self.embedding_size = self.cfg.MODEL.embedding_size
",4
"            use_gpu=args.use_gpu)
        return results
",4
"import json
import math
",4
"				thisTemp.V.removeAttribute('poster');
				thisTemp.resetPlayer();
			};
			var errorListenerFun = function(event) {
				setTimeout(function() {
",4
"                    if overlap > max_overlap:
",4
"            'sentiment_label': 1,
",4
"            label = label_list[index]
            output_i[label] = float(result_i[index])
",4
"                from queue import Queue
            else:
                from Queue import Queue
            from threading import Thread as Worker
",4
"                example = InputExample(
                    guid=seq_id, label=line[2], text_a=line[0], text_b=line[1])
                seq_id += 1
                examples.append(example)

",4
"    finally:
        base64_list = []
",4
"

if __name__ == ""__main__"":
",4
"    elif img.mode == 'L':  # black and white
",4
"				this.PD = thisPd; //PD:
			} else {
				var playerID = 'ckplayer' + this.randomString();
				var playerDiv = document.createElement('div');
				playerDiv.className = playerID;
",4
"        main_program = fluid.Program()
        startup_program = fluid.Program()
        with fluid.program_guard(main_program, startup_program):
",4
"        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing
",4
"from __future__ import division
from __future__ import print_function

import argparse
import ast
",4
"                         param_initializer=None,
                         name='multi_head_att'):
    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"            # feed batch image
            batch_image = np.array([data['image'] for data in batch_data])
            batch_image = PaddleTensor(batch_image.copy())
",4
"    for t in results:
        bboxes = t['bbox'][0]
",4
"            im = cv2.resize(
                im,
                None,
                None,
                fx=im_scale_x,
",4
"            moving_mean_name=bn_name + '.mean',
            moving_variance_name=bn_name + '.var')

        if act == 'leaky':
            out = fluid.layers.leaky_relu(x=out, alpha=0.1)
",4
"        if nonlocal_params[""use_scale""]:
            theta_phi_sc = fluid.layers.scale(theta_phi, scale=dim_inner**-.5)
",4
"				Quintic: {
",4
"
",4
"			}
",4
"
from .nonlocal_helper import add_space_nonlocal
from .name_adapter import NameAdapter

",4
"            prepostprocess_dropout=self._prepostprocess_dropout,
",4
"        cname2cid (dict): the mapping of category name to id
",4
"				}
				var data = {
					duration: duration,
",4
"        act=hidden_act,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
",4
"        if input_img is not None:
",4
"                name='conv1_1')
            conv = self.conv_bn_layer(
",4
"                       shape=[blob_out_shape[1]], dtype = blob_out.dtype, \
                       attr=ParamAttr(name=prefix + '_affine' + '_s'), \
                       default_initializer = fluid.initializer.Constant(value = 1.))
        affine_bias = fluid.layers.create_parameter(\
",4
"        self.batch_size = self.get_config_from_sec(self.mode, 'batch_size', 1)
        self.num_gpus = self.get_config_from_sec(self.mode, 'num_gpus', 1)

",4
"        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
",4
"        else:
            # predict phase
",4
"
",4
"        fpn_dict = {}
        fpn_name_list = []
",4
"        if self._dtype == ""float16"":
            emb_out = fluid.layers.cast(x=emb_out, dtype=self._dtype)
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)
        self_attn_mask = fluid.layers.matmul(
            x=input_mask, y=input_mask, transpose_y=True)
",4
"					callBack();
				}
			};
			var tweenAlpha = function() {
				if (t < d) {
",4
"        name='x2paddle_25',
        bias_attr='x2paddle_4')
    x2paddle_26 = fluid.layers.relu(x2paddle_25, name='x2paddle_26')
",4
"            num_filters=num_filters1,
            filter_size=1,
            stride=1,
",4
"            seq_id = 0

",4
"        return im_std

    def _set_config(self):
",4
"        pad_value=0.0,
        mode='reflect',
        paddings=[1, 1, 1, 1],
        name='x2paddle_22')
",4
"        max_query_length=64)

    seq_output = outputs[""sequence_output""]
",4
"
    def context(
            self,
",4
"        draw.line([(left, top), (left, bottom), (right, bottom), (right, top),
",4
"            name=""mask_lm_out_fc.b_0"",
            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"    for index, e in enumerate(examples):
        if index < 10:
",4
"    def net(self, input_ids, position_ids, segment_ids, input_mask):
        """"""
",4
"        prop_op = self.train_proposal if mode == 'train' else self.test_proposal
        # prop_op
        rpn_rois, rpn_roi_probs = fluid.layers.generate_proposals(
",4
"
        else:
            fc_out = fluid.layers.fc(
                input=mask_trans_feat,
                size=self._voc_size,
",4
"                images += data['data']

        res = list()
        # process one by one
        for element in reader(images, paths, shrink):
",4
"
",4
"					reg = 0;
				} else {
					reg = n;
",4
"
        next_sent_fc_out = fluid.layers.fc(
            input=next_sent_feat,
            size=2,
",4
"			if (this.html5Video) {
				var arr = this.playbackRateArr;
				n = parseInt(n);
				if (n < arr.length) {
",4
"                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
",4
"            im = np.array(im)
",4
"						c = parseInt(end) * w * 0.01 - b;
					} else if (end.substring(0, 1) == '-' || end.substring(0, 1) == '+') {
						if (typeof(obj['end']) == 'number') {
							c = parseInt(obj['end']) - b;
						} else {
",4
"			if (!this.loaded) {
",4
"            input=position_ids,
            size=[self._max_position_seq_len, self._emb_size],
            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))
",4
"            mask_trans_feat, 'n', name='mask_lm_trans')

",4
"            params_filename=params_filename)

    @serving
",4
"
def ResNet101_vd():
    model = ResNet(layers=101, is_3x3=True)
    return model

",4
"        boxes = rois / im_scale
        cls_prob = fluid.layers.softmax(cls_score, use_cudnn=False)
        bbox_pred = fluid.layers.reshape(bbox_pred, (-1, self.num_classes, 4))
        # self.box_coder
        decoded_box = fluid.layers.box_coder(
",4
"
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"            fy=im_scale,
            interpolation=cv2.INTER_LINEAR)

",4
"    name=""resnet18_vd_imagenet"",
    type=""CV/image_classification"",
    author=""paddlepaddle"",
    author_email=""paddle-dev@baidu.com"",
    summary=
",4
"
    in_str = str(in_str).lower().strip()
    segs_out = []
    temp_str = """"
",4
"            os.remove(item)
            os.remove(os.path.join(output_folder, item))
",4
"				}
				switch (list[i]['type']) {
				case 'image':
				case 'png':
				case 'jpg':
",4
"    """"""
    postprocess ouput of network, one face at a time.
    """"""
",4
"            input=next_sent_feat,
            size=self._emb_size,
",4
"                key, value = splits[:2]
                options[key] = value

",4
"        # transform: layer norm
        mask_trans_feat = pre_process_layer(
            mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
",4
"            prepostprocess_dropout,
            name=name + '_pre_ffn'),
",4
"            main_program=self.main_program)

    def load_checkpoint(self):
",4
"                regularizer=L2Decay(0.)))
        return self.rpn_cls_score, self.rpn_bbox_pred
",4
"        out = layers.matmul(weights, v)
        return out
",4
"    valid_cnt = 0
    for i in range(len(gt_box)):
        if gt_box[i, 0] == 0 and gt_box[i, 1] == 0 and \
                gt_box[i, 2] == 0 and gt_box[i, 3] == 0:
            break
",4
"        my_solutions = solutions[range_start:range_end]

        for idx, solution in enumerate(my_solutions):
",4
"from paddle.fluid.regularizer import L2Decay

__all__ = ['MultiClassNMS', 'YOLOv3Head']


",4
"
    image.save(save_name)
",4
"        else:
            self._predict_base_main_program = None
        self._predict_base_feed_list = predict_feed_list
",4
"            fpn_feats(dict): A dictionary represents the output feature map
                of FPN with their name.
            im_info(Variable): The information of image with shape [N, 3] with
",4
"				}
				var vid = this.randomString();
				var controls = '';
				if (!this.showFace) {
",4
"            containing_type=None,
",4
"            batch_end_position = np.array(batch_end_position).astype(
                ""int64"").reshape([-1, 1])
",4
"    def object_detection(self,
",4
"
    def __call__(self, sample, context=None):
        img = sample['image']
        if self.random_apply:
            distortions = np.random.permutation([
",4
"    def __init__(self,
                 depth=50,
",4
"                var_prefix = '@HUB_{}@'.format(self.name)
                # name of inputs
",4
"            pretrained (bool) : Whether to load pretrained model.
",4
"			len = len || 16;
			var chars = 'abcdefghijklmnopqrstuvwxyz';
			var maxPos = chars.length;
			var val = '';
",4
"            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
",4
"def base64_to_cv2(b64str):
",4
"            draw.rectangle(
                xy=(bbox['left'], bbox['top'] - (textsize_height + 5),
                    bbox['left'] + textsize_width + 10, bbox['top'] - 3),
                fill=box_fill)
            draw.text(
",4
"				prompt: this.getByElement(promptID, pd),
",4
"    ""input_size"": [3, 224, 224],
    ""input_mean"": [0.485, 0.456, 0.406],
    ""input_std"": [0.229, 0.224, 0.225],
    ""learning_strategy"": {
",4
"                        exe,
                        self.default_pretrained_model_path,
",4
"
def face_detector_320():
    _319 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
    _322 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _323 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=2)
",4
"# limitations under the License.

",4
"        bn_name = self.prefix_name + bn_name if self.prefix_name != '' else bn_name

",4
"
def clip_bbox(bbox, img_width, img_height):
    xmin = max(min(bbox[0], img_width), 0.)
    ymin = max(min(bbox[1], img_height), 0.)
",4
"                im2col_step=1,
                param_attr=ParamAttr(name=_name + ""_weights""),
",4
"            use_gpu = True
        except:
",4
"			if (nVArr.length < 1) {
",4
"        """"""
        self.arg_input_group.add_argument(
            '--input_path', type=str, default=None, help=""diretory to image"")


",4
"            conv = block_func(
",4
"            prog=""hub run {}"".format(self.name),
            usage='%(prog)s',
            add_help=True)
",4
"				cPlayFillRect();
			};

			this.addListenerInside('mouseover', cPlayOver, this.getByElement(playID + '-canvas'));
",4
"        else:
            resized_w = int(math.ceil(imgH * ratio))
",4
"            '--visualization',
",4
"					y: timeBoBgXY['y']
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
from __future__ import absolute_import
",4
"            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not"")
",4
"                             model_filename=None,
                             params_filename=None,
",4
"            gpu_config.disable_glog_info()
",4
"        self.has_processed = {
            ""train"": False,
            ""dev"": False,
            ""val"": False,
",4
"                pos = self._header_pages
",4
"                     data=None,
",4
"				cFull.clearRect(0, 0, bWidth, bHeight);
				cFull.fillStyle = bOverColor;
				cFullFillRect();
			};
",4
"    if not np.isscalar(src):
        if index.shape[dim] > src.shape[dim]:
            raise IndexError(""Dimension "" + str(dim) +
                             ""of index can not be bigger than that of src "")
",4
"            image = input_image if input_image else fluid.data(
                name='image',
                shape=[-1, 3, 224, 224],
                dtype='float32',
                lod_level=0)
",4
"from __future__ import print_function

import math
from collections import OrderedDict
from numbers import Integral
",4
"
    def __init__(self, name):
        super(HelpCommand, self).__init__(name)
        self.show_in_help = True
        self.description = ""Show help for commands.""
",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
        self.face_detector = None
",4
"
from yolov3_darknet53_coco2017.darknet import DarkNet
",4
"        self.params_layer = {}
",4
"__all__ = [
    ""ResNet"", ""ResNet50_vd"", ""ResNet101_vd"", ""ResNet152_vd"", ""ResNet200_vd""
]

",4
"            out = layers.layer_norm(
                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"
        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

",4
"
import cv2
import numpy as np
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
",4
"
def is_windows():
    return get_platform().lower().startswith(""windows"")
",4
"        eval_feed = Feed()
        eval_feed.with_background = dconf.conf[
",4
"
@register_op
class NormalizeBox(BaseOperator):
    """"""Transform the bounding box's coornidates to [0,1].""""""

",4
"            ""gap"": gap
        }

    def clear(self):
",4
"                self.num_chan,
                1,
                initializer=initializer,
",4
"        ceil_mode=True,
        pool_size=[3, 3])
    Conv4 = fluid.layers.conv2d(
        Pool3,
",4
"    m = len(predictions)
",4
"            print('%s: %s' % (arg, value))
        print('------------------------------------------------')


class BertModel(object):
",4
"			};
			var promptHide = function(event) {
				thisTemp.promptShow(false);
				if (thisTemp.previewDiv != null) {
",4
"
    def _parse(self, config_path):
        try:
            with open(config_path) as json_file:
                config_dict = json.load(json_file)
",4
"    """"""
",4
"        init_params = []
        for param in self.params[""param_list""]:
",4
"        # ensure fetch loss at last element in train/test phase
        # ensure fetch 'im_shape', 'im_id', 'bbox' at first three elements in test phase
        return self._fetch_list(False)

",4
"                self.fpn_rpn_list[i][0], self.fpn_rpn_list[i][1],
",4
"        data_layout='NCHW',
",4
"            hidden,
            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
            is_test=False)
    out = layers.fc(
",4
"

class LocalModuleManager(object):
    def __init__(self, module_home=None):
        self.local_modules_dir = module_home if module_home else MODULE_HOME
",4
"
    g = fluid.layers.conv2d(input = max_pool, num_filters = dim_inner, \
                 filter_size = [1, 1], stride = [1, 1], \
                 padding = [0, 0], \
                 param_attr = ParamAttr(name = prefix + '_g' + ""_w"", \
",4
"        self.learning_rate = learning_rate
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            input=position_ids,
",4
"        assert 0 <= freeze_at <= 4, ""freeze_at should be 0, 1, 2, 3 or 4""
",4
"

def ConvNorm(input,
",4
"def encoder_layer(enc_input,
                  attn_bias,
",4
"			if (this.playerType == 'flashplayer') {
				this.V.videoZoom(n);
",4
"        supported_layers = [50, 101, 152]
        assert layers in supported_layers, \
            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)

",4
"                         ['f', 'm', 'n', 'd', 'v', 'v', 'xc'])

    def test_senta(self):
        senta = hub.Module(name=""senta_bilstm"")
",4
"    def setUpClass(self):
",4
"
_PUNKT_URL = ""https://paddlehub.bj.bcebos.com/paddlehub-thirdparty/punkt.tar.gz""


# split Chinese with English
",4
"            try:
                random.seed()
                self.con_index = random.randint(0, len(self.serving_list) - 1)
                logger.info(self.con_index)
                cur_con = httplib.HTTPConnection(
",4
"                                     ""yolo_output.{}.conv.weights"".format(i)),
                bias_attr=ParamAttr(
                    regularizer=L2Decay(0.),
",4
"			//
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"            input=src_ids,
            size=[self._voc_size, self._emb_size],
            dtype=self._emb_dtype,
",4
"    if main_program is None:
        main_program = fluid.default_main_program()
",4
"            mask_feat = fluid.layers.cast(x=mask_feat, dtype=self._emb_dtype)

        # transform: fc
        mask_trans_feat = fluid.layers.fc(
",4
"        return self.evolution_stratefy.ask()

    def is_stop(self):
        return self.evolution_stratefy.stop()

",4
"            pool_stride=2,
            pool_padding=1,
            pool_type='max')
        for block in range(len(depth)):
            for i in range(depth[block]):
",4
"

class AnchorGenerator(object):
    # __op__ = fluid.layers.anchor_generator
    def __init__(self,
",4
"                )
        for resource_name, resource_type, resource_version, resource_summary in resource_list:
            if resource_type == ""Module"":
",4
"        if item[""category""] == ""CV"":
",4
"        fpn_name_list = []
        for i in range(num_backbone_stages):
            fpn_name = 'fpn_' + body_name_list[i]
            fan = self.fpn_inner_output[i].shape[1] * 3 * 3
            if self.norm_type:
",4
"
def MobileNetV2_x0_5():
    model = MobileNetV2(scale=0.5)
    return model
",4
"                       pool_stride,
                       pool_padding=0,
                       ceil_mode=True):
        pool = fluid.layers.pool2d(
            input=conv,
",4
"            print(results[index])
# -*- coding: utf-8 -*-
import io
import numpy as np
",4
"# -*- coding:utf-8 -*-
import io
import numpy as np


",4
"        mask_trans_feat = fluid.layers.layer_norm(
",4
"				ph = this.PD.offsetHeight;
				this.css(this.CB['adElement'], {
					top: (ph - h) * 0.5 + 'px',
					left: (pw - w) * 0.5 + 'px'
				});
",4
"            self._word_seg_module = hub.Module(name=""lac"")
",4
"            config=self.ernie_config,
            use_fp16=False)
        pooled_output = ernie.get_pooled_output()
        sequence_output = ernie.get_sequence_output()
        return pooled_output, sequence_output
",4
"
        Returns:
            pooled_output (tensor):  sentence-level output for classification task.
",4
"    """"""

    batch_src_ids = [inst[0] for inst in insts]
",4
"            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
",4
"                initializer=fluid.initializer.Uniform(-stdv, stdv),
                name='fc_weights'),
            bias_attr=fluid.param_attr.ParamAttr(name='fc_offset'))
        return out, pool
",4
"					color: '#FFFFFF',
					textDecoration: 'none'
				});
",4
"                               centers < crop[2:]).all(axis=1)
        valid = np.logical_and(
            valid, (cropped_box[:, :2] < cropped_box[:, 2:]).all(axis=1))

        return cropped_box, np.where(valid)[0]
",4
"        self.show_in_help = True
        self.name = name
        self.description = ""PaddleHub helps to finetune a task by searching hyperparameters automatically.""
",4
"import os
import codecs
",4
"def expand_boxes(boxes, scale):
    """"""
    Expand an array of boxes by a given scale.
    """"""
    w_half = (boxes[:, 2] - boxes[:, 0]) * .5
",4
"            conv_name1 = 'conv' + name + '_x1'
            conv_name2 = 'conv' + name + '_x2'
",4
"    if ext == '':
        if img.format == 'PNG':
            ext = '.png'
",4
"            sentence_ids=segment_ids,
            input_mask=input_mask,
",4
"from paddlehub.module.module import moduleinfo, serving
",4
"import six
import numpy as np
import cv2
",4
"        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
",4
"		addDefListener: function() {
			var thisTemp = this;
			var setTimeOutP = null;
			var defClick = function(event) {
",4
"        Returns:
            res (list[dict]): The result of face detection and save path of images.
",4
"        images_decode = [base64_to_cv2(image) for image in images]
",4
"
",4
"    results = senta.sentiment_classify(data=input_dict)
    for index, result in enumerate(results):
        if six.PY2:
            print(
                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
",4
"    predict_method = getattr(module_info[""module""], method_name)
",4
"                    num_per_cls[c] = 1
                else:
                    num_per_cls[c] += 1

        for i in range(len(self._roidb)):
",4
"        bias_attr=False)
    _373 = fluid.layers.concat([_370, _371, _372], axis=0)
    _387 = fluid.layers.concat([_384, _385, _386], axis=0)
    _396 = fluid.layers.batch_norm(
        _395,
",4
"    _438 = fluid.layers.shape(_436)
    _450 = fluid.layers.shape(_448)
    _439 = fluid.layers.gather(input=_438, index=_437)
    _451 = fluid.layers.gather(input=_450, index=_449)
    _442 = fluid.layers.assign(_439)
",4
"        conv = input
        for j in range(2):
            conv = self._conv_bn(
",4
"
        # limit the max side
        if max(resize_h, resize_w) > self.max_side_len:
            if resize_h > resize_w:
",4
"import numpy as np
import paddle.fluid as fluid
import paddlehub as hub
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
",4
"    data = base64.b64decode(b64str.encode('utf8'))
",4
"        header_pages = int(
            math.ceil((total_pages + self.s_allocator_header) / page_size))

        self._header_pages = header_pages
        self._free_pages = total_pages - header_pages
",4
"                                          int(dim_in / 2))
        return conv

",4
"    return clean_result
",4
"                    ) * ratio * self.epsilon + self.current_hparams[i][j]
                else:
",4
"        raise NotImplementedError

    # NOTE: current saved checkpoint machanism is not completed,
",4
"            image_tensor = PaddleTensor(image_arr.copy())
            data_out = self.gpu_predictor.run([
                image_tensor
",4
"            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR.
            paths (list[str]): The paths of images.
            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"        self.num_classes = num_classes
",4
"        if not os.path.exists(filepath):
            print(
",4
"            product += attn_bias
        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
",4
"    def get_pretrained_images_std(self):
        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
        return im_std

    def _set_config(self):
",4
"        self._emb_size = config['hidden_size']
        self._n_layer = config['num_hidden_layers']
",4
"                return x

    max_shrink = get_round(min(max_shrink_v1, max_shrink_v2), 2) - 0.3
",4
"    Returns:
        res (list[dict]): The result of vehicles detecion. keys include 'data', 'save_path', the corresponding value is:
            data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"        conv1 = self.conv_bn_layer(
            input=conv0,
            num_filters=num_filters,
            filter_size=3,
",4
"            lr_count = np.array(lr_count_var.get_tensor())
        logger.info(
            ""------- learning rate {}, learning rate counter {} -----"".format(
                np.array(lr), np.array(lr_count)))
",4
"    def owner(self):
        """""" get owner
",4
"        
        """"""
",4
"
    if ext == '':
        if img.format == 'PNG':
            ext = '.png'
        elif img.format == 'JPEG':
",4
"    ""no_bias"": True,
    ""use_maxpool"": False,
    ""use_softmax"": True,
",4
"        self.server_url = self.config['server_url']
        self.request()
        self._load_resource_list_file_if_valid()
",4
"        Args:
            outputs (list): list of Variables, return from _get_outputs
            im_size (Variable): Variable of size([h, w]) of each image

        Returns:
",4
"		this.videoScale = 1;
",4
"        for arg, value in sorted(six.iteritems(self._config_dict)):
",4
"        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

        if self._dtype == ""float16"":
",4
"        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        im = im.astype(np.float32, copy=False)
",4
"        stages, block_func = self.depth_cfg[self.depth]
        stages = stages[0:5]
",4
"        }
        'cname2id' is a dict to map category name to class id
    """"""

    txt_file = anno_path
",4
"                        'generate_proposal_labels':
                        [var_prefix + var.name for var in outs]
                    }
",4
"import os
",4
"        return next_sent_acc, mean_mask_lm_loss, loss
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"
",4
"
def _handle_single(im_path=None, im_arr=None):
    """"""
",4
"        x /= tmp.reshape((x.shape[0], 1))
",4
"        train_data_path = os.path.join(self.base_path, self.train_list_file)
        train_image_dir = os.path.join(self.base_path, self.train_image_dir)
",4
"    values=[
",4
"                   max_pool_stride=2):
",4
"    with io.open(file_path, 'r', encoding='utf8') as f:
        wid = 0
        for line in f:
            parts = line.rstrip().split('\t')
",4
"			var tweenObj = null;
			var start = obj['start'] == null ? '': obj['start'].toString();
			var end = obj['end'] == null ? '': obj['end'].toString();
			switch (obj['parameter']) {
			case 'x':
",4
"    component = list()
    if paths:
",4
"        curr = sorted(curr, key=lambda x: x[0], reverse=True)
        if curr[k - 1][0] <= pos_score:
            return 1
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import print_function
",4
"            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR. .
            paths (list[str]): The paths of images.
            batch_size (int): batch size.
",4
"    def fix_layer_warp_name(self, stage_num, count, i):
        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
            if i == 0:
                conv_name = name + ""a""
",4
"			this.playShow(true);
			//
			if (this.isFirstTimePlay && !this.isUndefined(this.advertisements['front'])) {
",4
"        Returns:
",4
"        """"""
        Add the command config options
",4
"
",4
"        startup_program = fluid.Program()
        with fluid.program_guard(main_program, startup_program):
            data = fluid.layers.data(
",4
"        scale = fluid.framework._get_var(pattr.name)
        bias = fluid.framework._get_var(battr.name)
    elif norm_type == 'gn':
        out = fluid.layers.group_norm(
            input=conv,
",4
"				var have = false;
",4
"                    outputs = {
                        'head_features':
                        [var_prefix + var.name for var in head_features],
                        'body_features':
                        [var_prefix + var.name for var in body_features]
",4
"    def get_prediction(self, body_feats, spatial_scale, im_info):
        """"""
        Get prediction bounding box in test stage.

        Args:
",4
"    if image.shape[-1] == 1:
        image = np.repeat(image, axis=2)
    h, w, c = image.shape
    image = np.transpose(image, (2, 0, 1))
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"        Add the command config options
",4
"        if self.mode != 'infer':
            label = fluid.data(name='label', shape=[None, 1], dtype='int64')
        else:
            label = None

",4
"        op_repr.append('{{{}}}'.format(str(o)))
",4
"			}
",4
"    'EfficientNetB6', 'EfficientNetB7'
]
",4
"from .sharedmemory import SharedBuffer
",4
"             hid_dim=128,
",4
"                if layers in [101, 152, 200] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
",4
"        gt_masks = []
        if self.is_mask and len(sample['gt_poly']) != 0 \
",4
"
class EndSignal(object):
    def __init__(self, errno=0, errmsg=''):
        self.errno = errno
",4
"_FETCHDESC = _descriptor.Descriptor(
    name='FetchDesc',
    full_name='paddlehub.module.desc.FetchDesc',
    filename=None,
    file=DESCRIPTOR,
",4
"
                resized_mask = cv2.resize(padded_mask, (w, h))
",4
"            train_iter += 1

            # NOTE: profiler tools, used for benchmark
",4
"
    def __init__(self, config):
",4
"        bias.stop_gradient = True
    return out


",4
"		/*
			
			
",4
"
        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
        return layers.reshape(
",4
"        for iter_id in range(loop_num):
",4
"        sample.pop('mixup')
        return sample
",4
"
        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
            size=[self._sent_types, self._emb_size],
            dtype=self._dtype,
",4
"                name=""rpn_cls_logits_w"", initializer=Normal(loc=0.,
                                                            scale=0.01)),
            bias_attr=ParamAttr(
                name=""rpn_cls_logits_b"",
                learning_rate=2.,
",4
"        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        data_out (lod_tensor): data output of predictor.
",4
"@register_op
class Resize(BaseOperator):
    """"""Resize image and bbox.

    Args:
",4
"		isContains: function(str, key) {
			return str.indexOf(key) > -1;
		},
",4
"        indexs = np.argsort(result_i)[::-1][0:top_k]
        for index in indexs:
            label = label_list[index].split(',')[0]
",4
"            borderMode=cv2.BORDER_REPLICATE)
        dst_img_height, dst_img_width = dst_img.shape[0:2]
",4
"            colors=[""light_red"", None],
            aligns=[""^"", ""<""])
        tp.add_line(
            contents=[""Author"", module.author],
            colors=[""light_red"", None],
",4
"        _296,
        momentum=0.9900000095367432,
",4
"
",4
"        """"""
        Get the input ,output and program of the pretrained senta_gru
",4
"                    is_crowd=is_crowd,
                    im_info=im_info,
                    rpn_batch_size_per_im=self.rpn_target_assign.rpn_batch_size_per_im,
",4
"    if module_attr.type == module_desc_pb2.BOOLEAN:
        result = module_attr.b
    elif module_attr.type == module_desc_pb2.INT:
        result = module_attr.i
",4
"        return self.labels


if __name__ == ""__main__"":
    senta = SentaGRU()
",4
"        std=[0.229, 0.224, 0.225],
        is_scale=True,
        is_channel_first=False),
",4
"        yield element
# coding=utf-8
from __future__ import absolute_import
",4
"if __name__ == '__main__':
    # Load Paddlehub ERNIE 2.0 pretrained model
    module = hub.Module(name=""ernie_v2_eng_base"")
    inputs, outputs, program = module.context(
        trainable=True, max_seq_len=args.max_seq_len)
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"            filter_size=1,
",4
"            self.Postprocess(output_data, faces)


class FaceDetector:
    def __init__(self, model_dir, mean, scale, use_gpu=False, threshold=0.7):
",4
"            fg_fraction=0.25,
            fg_thresh=0.5,
            class_nums=num_classes)

",4
"        avg_loss = loss_sum / run_examples
",4
"    type=""cv/classification"",
    summary=
    ""ResNet34 is a image classfication model trained with ImageNet-2012 dataset."",
    author=""paddlepaddle"",
",4
"        DESCRIPTOR=_FEEDDESC,
        __module__='module_desc_pb2'
        # @@protoc_insertion_point(class_scope:paddlehub.module.desc.FeedDesc)
    ))
",4
"    aspect_ratio = min(aspect_ratio, 1 / (scale**2.0))
    bbox_width = scale * (aspect_ratio**0.5)
    bbox_height = scale / (aspect_ratio**0.5)
    if image_height < image_width:
",4
"		this.varsConfig = {
",4
"            each['orig_im'] = im
            each['orig_im_shape'] = im.shape
            each['orig_im_path'] = im_path
            components.append(each)
",4
"
",4
"                    cls_logits=rpn_cls,
                    anchor_box=anchor,
                    anchor_var=anchor_var,
",4
"		prompt: function() {
			if (!this.showFace) {
",4
"    else:
        # not clear about what is doing in xlw's code
        p = None  # not implemented
        raise ""Not implemented when not use softmax""
",4
"			var controlBarW = this.CB['controlBar'].offsetWidth;
			var ele = [];
			ele.push([[this.CB['full'], this.CB['escFull'], this.CB['fullLine']], this.buttonWidth['full'] + 2, 'full']);
			if (this.vars['front'] != '') {
",4
"
def convert_rec_label_to_lod(ori_labels):
",4
"            options = {""bind"": ""0.0.0.0:%s"" % port, ""workers"": workers}
",4
"            name='value',
",4
"                     act=None,
                     name=None):
        out_channel = filter_size * filter_size * 3
        out = fluid.layers.conv2d(
            input,
",4
"                   stride,
                   is_first,
",4
"                    num_filters=self.num_chan,
                    filter_size=3,
                    stride=1,
                    padding=1,
                    act='relu',
",4
"    """"""
    Transform samples to mapped samples which is similar to 'basic.MappedDataset',
",4
"    def _get_output(self, input, feat_lvl):
        """"""
        Get anchor and FPN RPN head output at one level.

        Args:
",4
"            act='sigmoid',
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv),
",4
"            name=name + ""_branch2a"")
        conv1 = self.conv_bn_layer(
",4
"							arr[1]();
							break;
						}
",4
"
        return result
# coding: utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"                    ""sentence_feature"": var
                }
        return inputs, outputs, program

    @serving
",4
"				this.css(this.V, 'backgroundColor', '#000000');
				//
				if (this.config['videoDrawImage']) {
					var canvasID = 'vcanvas' + this.randomString();
",4
"            self.add_module_input_arg()

",4
"        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"        reshaped = layers.reshape(
            x=x, shape=[0, 0, n_head, hidden_size // n_head], inplace=True)

        # permuate the dimensions into:
",4
"    width, height = img.size
    size = target_size
",4
"        x2paddle_48,
        pad_value=0.0,
",4
"    def run_cmd(self, argvs):
        self.parser = argparse.ArgumentParser(
",4
"    def get_prediction(self, outputs, im_size):
        """"""
        Get prediction result of YOLOv3 network

        Args:
",4
"        scores = []
        downsample = 32
",4
"            if i == 0:
                conv_name = name + ""a""
",4
"            body_name = body_name_list[i]
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
post_process_layer = pre_post_process_layer
",4
"				bgcolor: '#000'
			};
			for (var e in o) {
				w += e + '=""' + o[e] + '"" ';
				v += '<param name=""' + e + '"" value=""' + o[e] + '"" />';
",4
"
def save_model(exe,
               program,
",4
"        elif self.mode == 'test':
            #losses = self.loss()
",4
"            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_att'),
        None,
        None,
",4
"		},
",4
"            'gt_poly': gt_poly,
        }
        'cname2id' is a dict to map category name to class id
    """"""

",4
"DATA_DIM = 224
img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))
img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))

",4
"        return self.__class__._author_email

",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"    Residual Network, see https://arxiv.org/abs/1512.03385
    Args:
        depth (int): ResNet depth, should be 34, 50.
        freeze_at (int): freeze the backbone at which stage
",4
"		this.trackIndex = 0;
		//
		this.nowTrackShow = {
",4
"return(!i||i!==r&&!b.contains(r,i))&&(e.type=o.origType,n=o.handler.apply(this,arguments),e.type=t),n}}}),b.support.submitBubbles||(b.event.special.submit={setup:function(){return b.nodeName(this,""form"")?!1:(b.event.add(this,""click._submit keypress._submit"",function(e){var n=e.target,r=b.nodeName(n,""input"")||b.nodeName(n,""button"")?n.form:t;r&&!b._data(r,""submitBubbles"")&&(b.event.add(r,""submit._submit"",function(e){e._submit_bubble=!0}),b._data(r,""submitBubbles"",!0))}),t)},postDispatch:function(e){e._submit_bubble&&(delete e._submit_bubble,this.parentNode&&!e.isTrigger&&b.event.simulate(""submit"",this.parentNode,e,!0))},teardown:function(){return b.nodeName(this,""form"")?!1:(b.event.remove(this,""._submit""),t)}}),b.support.changeBubbles||(b.event.special.change={setup:function(){return Z.test(this.nodeName)?((""checkbox""===this.type||""radio""===this.type)&&(b.event.add(this,""propertychange._change"",function(e){""checked""===e.originalEvent.propertyName&&(this._just_changed=!0)}),b.event.add(this,""click._change"",function(e){this._just_changed&&!e.isTrigger&&(this._just_changed=!1),b.event.simulate(""change"",this,e,!0)})),!1):(b.event.add(this,""beforeactivate._change"",function(e){var t=e.target;Z.test(t.nodeName)&&!b._data(t,""changeBubbles"")&&(b.event.add(t,""change._change"",function(e){!this.parentNode||e.isSimulated||e.isTrigger||b.event.simulate(""change"",this.parentNode,e,!0)}),b._data(t,""changeBubbles"",!0))}),t)},handle:function(e){var n=e.target;return this!==n||e.isSimulated||e.isTrigger||""radio""!==n.type&&""checkbox""!==n.type?e.handleObj.handler.apply(this,arguments):t},teardown:function(){return b.event.remove(this,""._change""),!Z.test(this.nodeName)}}),b.support.focusinBubbles||b.each({focus:""focusin"",blur:""focusout""},function(e,t){var n=0,r=function(e){b.event.simulate(t,e.target,b.event.fix(e),!0)};b.event.special[t]={setup:function(){0===n++&&o.addEventListener(e,r,!0)},teardown:function(){0===--n&&o.removeEventListener(e,r,!0)}}}),b.fn.extend({on:function(e,n,r,i,o){var a,s;if(""object""==typeof e){""string""!=typeof n&&(r=r||n,n=t);for(a in e)this.on(a,n,r,e[a],o);return this}if(null==r&&null==i?(i=n,r=n=t):null==i&&(""string""==typeof n?(i=r,r=t):(i=r,r=n,n=t)),i===!1)i=ot;else if(!i)return this;return 1===o&&(s=i,i=function(e){return b().off(e),s.apply(this,arguments)},i.guid=s.guid||(s.guid=b.guid++)),this.each(function(){b.event.add(this,e,i,r,n)})},one:function(e,t,n,r){return this.on(e,t,n,r,1)},off:function(e,n,r){var i,o;if(e&&e.preventDefault&&e.handleObj)return i=e.handleObj,b(e.delegateTarget).off(i.namespace?i.origType+"".""+i.namespace:i.origType,i.selector,i.handler),this;if(""object""==typeof e){for(o in e)this.off(o,n,e[o]);return this}return(n===!1||""function""==typeof n)&&(r=n,n=t),r===!1&&(r=ot),this.each(function(){b.event.remove(this,e,r,n)})},bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,""**""):this.off(t,e||""**"",n)},trigger:function(e,t){return this.each(function(){b.event.trigger(e,t,this)})},triggerHandler:function(e,n){var r=this[0];return r?b.event.trigger(e,n,r,!0):t}}),function(e,t){var n,r,i,o,a,s,u,l,c,p,f,d,h,g,m,y,v,x=""sizzle""+-new Date,w=e.document,T={},N=0,C=0,k=it(),E=it(),S=it(),A=typeof t,j=1<<31,D=[],L=D.pop,H=D.push,q=D.slice,M=D.indexOf||function(e){var t=0,n=this.length;for(;n>t;t++)if(this[t]===e)return t;return-1},_=""[\\x20\\t\\r\\n\\f]"",F=""(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+"",O=F.replace(""w"",""w#""),B=""([*^$|!~]?=)"",P=""\\[""+_+""*(""+F+"")""+_+""*(?:""+B+_+""*(?:(['\""])((?:\\\\.|[^\\\\])*?)\\3|(""+O+"")|)|)""+_+""*\\]"",R="":(""+F+"")(?:\\(((['\""])((?:\\\\.|[^\\\\])*?)\\3|((?:\\\\.|[^\\\\()[\\]]|""+P.replace(3,8)+"")*)|.*)\\)|)"",W=RegExp(""^""+_+""+|((?:^|[^\\\\])(?:\\\\.)*)""+_+""+$"",""g""),$=RegExp(""^""+_+""*,""+_+""*""),I=RegExp(""^""+_+""*([\\x20\\t\\r\\n\\f>+~])""+_+""*""),z=RegExp(R),X=RegExp(""^""+O+""$""),U={ID:RegExp(""^#(""+F+"")""),CLASS:RegExp(""^\\.(""+F+"")""),NAME:RegExp(""^\\[name=['\""]?(""+F+"")['\""]?\\]""),TAG:RegExp(""^(""+F.replace(""w"",""w*"")+"")""),ATTR:RegExp(""^""+P),PSEUDO:RegExp(""^""+R),CHILD:RegExp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+_+""*(even|odd|(([+-]|)(\\d*)n|)""+_+""*(?:([+-]|)""+_+""*(\\d+)|))""+_+""*\\)|)"",""i""),needsContext:RegExp(""^""+_+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+_+""*((?:-\\d)?\\d*)""+_+""*\\)|)(?=[^-]|$)"",""i"")},V=/[\x20\t\r\n\f]*[+~]/,Y=/^[^{]+\{\s*\[native code/,J=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,G=/^(?:input|select|textarea|button)$/i,Q=/^h\d$/i,K=/'|\\/g,Z=/\=[\x20\t\r\n\f]*([^'""\]]*)[\x20\t\r\n\f]*\]/g,et=/\\([\da-fA-F]{1,6}[\x20\t\r\n\f]?|.)/g,tt=function(e,t){var n=""0x""+t-65536;return n!==n?t:0>n?String.fromCharCode(n+65536):String.fromCharCode(55296|n>>10,56320|1023&n)};try{q.call(w.documentElement.childNodes,0)[0].nodeType}catch(nt){q=function(e){var t,n=[];while(t=this[e++])n.push(t);return n}}function rt(e){return Y.test(e+"""")}function it(){var e,t=[];return e=function(n,r){return t.push(n+="" "")>i.cacheLength&&delete e[t.shift()],e[n]=r}}function ot(e){return e[x]=!0,e}function at(e){var t=p.createElement(""div"");try{return e(t)}catch(n){return!1}finally{t=null}}function st(e,t,n,r){var i,o,a,s,u,l,f,g,m,v;if((t?t.ownerDocument||t:w)!==p&&c(t),t=t||p,n=n||[],!e||""string""!=typeof e)return n;if(1!==(s=t.nodeType)&&9!==s)return[];if(!d&&!r){if(i=J.exec(e))if(a=i[1]){if(9===s){if(o=t.getElementById(a),!o||!o.parentNode)return n;if(o.id===a)return n.push(o),n}else if(t.ownerDocument&&(o=t.ownerDocument.getElementById(a))&&y(t,o)&&o.id===a)return n.push(o),n}else{if(i[2])return H.apply(n,q.call(t.getElementsByTagName(e),0)),n;if((a=i[3])&&T.getByClassName&&t.getElementsByClassName)return H.apply(n,q.call(t.getElementsByClassName(a),0)),n}if(T.qsa&&!h.test(e)){if(f=!0,g=x,m=t,v=9===s&&e,1===s&&""object""!==t.nodeName.toLowerCase()){l=ft(e),(f=t.getAttribute(""id""))?g=f.replace(K,""\\$&""):t.setAttribute(""id"",g),g=""[id='""+g+""'] "",u=l.length;while(u--)l[u]=g+dt(l[u]);m=V.test(e)&&t.parentNode||t,v=l.join("","")}if(v)try{return H.apply(n,q.call(m.querySelectorAll(v),0)),n}catch(b){}finally{f||t.removeAttribute(""id"")}}}return wt(e.replace(W,""$1""),t,n,r)}a=st.isXML=function(e){var t=e&&(e.ownerDocument||e).documentElement;return t?""HTML""!==t.nodeName:!1},c=st.setDocument=function(e){var n=e?e.ownerDocument||e:w;return n!==p&&9===n.nodeType&&n.documentElement?(p=n,f=n.documentElement,d=a(n),T.tagNameNoComments=at(function(e){return e.appendChild(n.createComment("""")),!e.getElementsByTagName(""*"").length}),T.attributes=at(function(e){e.innerHTML=""<select></select>"";var t=typeof e.lastChild.getAttribute(""multiple"");return""boolean""!==t&&""string""!==t}),T.getByClassName=at(function(e){return e.innerHTML=""<div class='hidden e'></div><div class='hidden'></div>"",e.getElementsByClassName&&e.getElementsByClassName(""e"").length?(e.lastChild.className=""e"",2===e.getElementsByClassName(""e"").length):!1}),T.getByName=at(function(e){e.id=x+0,e.innerHTML=""<a name='""+x+""'></a><div name='""+x+""'></div>"",f.insertBefore(e,f.firstChild);var t=n.getElementsByName&&n.getElementsByName(x).length===2+n.getElementsByName(x+0).length;return T.getIdNotName=!n.getElementById(x),f.removeChild(e),t}),i.attrHandle=at(function(e){return e.innerHTML=""<a href='#'></a>"",e.firstChild&&typeof e.firstChild.getAttribute!==A&&""#""===e.firstChild.getAttribute(""href"")})?{}:{href:function(e){return e.getAttribute(""href"",2)},type:function(e){return e.getAttribute(""type"")}},T.getIdNotName?(i.find.ID=function(e,t){if(typeof t.getElementById!==A&&!d){var n=t.getElementById(e);return n&&n.parentNode?[n]:[]}},i.filter.ID=function(e){var t=e.replace(et,tt);return function(e){return e.getAttribute(""id"")===t}}):(i.find.ID=function(e,n){if(typeof n.getElementById!==A&&!d){var r=n.getElementById(e);return r?r.id===e||typeof r.getAttributeNode!==A&&r.getAttributeNode(""id"").value===e?[r]:t:[]}},i.filter.ID=function(e){var t=e.replace(et,tt);return function(e){var n=typeof e.getAttributeNode!==A&&e.getAttributeNode(""id"");return n&&n.value===t}}),i.find.TAG=T.tagNameNoComments?function(e,n){return typeof n.getElementsByTagName!==A?n.getElementsByTagName(e):t}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if(""*""===e){while(n=o[i++])1===n.nodeType&&r.push(n);return r}return o},i.find.NAME=T.getByName&&function(e,n){return typeof n.getElementsByName!==A?n.getElementsByName(name):t},i.find.CLASS=T.getByClassName&&function(e,n){return typeof n.getElementsByClassName===A||d?t:n.getElementsByClassName(e)},g=[],h=["":focus""],(T.qsa=rt(n.querySelectorAll))&&(at(function(e){e.innerHTML=""<select><option selected=''></option></select>"",e.querySelectorAll(""[selected]"").length||h.push(""\\[""+_+""*(?:checked|disabled|ismap|multiple|readonly|selected|value)""),e.querySelectorAll("":checked"").length||h.push("":checked"")}),at(function(e){e.innerHTML=""<input type='hidden' i=''/>"",e.querySelectorAll(""[i^='']"").length&&h.push(""[*^$]=""+_+""*(?:\""\""|'')""),e.querySelectorAll("":enabled"").length||h.push("":enabled"","":disabled""),e.querySelectorAll(""*,:x""),h.push("",.*:"")})),(T.matchesSelector=rt(m=f.matchesSelector||f.mozMatchesSelector||f.webkitMatchesSelector||f.oMatchesSelector||f.msMatchesSelector))&&at(function(e){T.disconnectedMatch=m.call(e,""div""),m.call(e,""[s!='']:x""),g.push(""!="",R)}),h=RegExp(h.join(""|"")),g=RegExp(g.join(""|"")),y=rt(f.contains)||f.compareDocumentPosition?function(e,t){var n=9===e.nodeType?e.documentElement:e,r=t&&t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&&16&e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},v=f.compareDocumentPosition?function(e,t){var r;return e===t?(u=!0,0):(r=t.compareDocumentPosition&&e.compareDocumentPosition&&e.compareDocumentPosition(t))?1&r||e.parentNode&&11===e.parentNode.nodeType?e===n||y(w,e)?-1:t===n||y(w,t)?1:0:4&r?-1:1:e.compareDocumentPosition?-1:1}:function(e,t){var r,i=0,o=e.parentNode,a=t.parentNode,s=[e],l=[t];if(e===t)return u=!0,0;if(!o||!a)return e===n?-1:t===n?1:o?-1:a?1:0;if(o===a)return ut(e,t);r=e;while(r=r.parentNode)s.unshift(r);r=t;while(r=r.parentNode)l.unshift(r);while(s[i]===l[i])i++;return i?ut(s[i],l[i]):s[i]===w?-1:l[i]===w?1:0},u=!1,[0,0].sort(v),T.detectDuplicates=u,p):p},st.matches=function(e,t){return st(e,null,null,t)},st.matchesSelector=function(e,t){if((e.ownerDocument||e)!==p&&c(e),t=t.replace(Z,""='$1']""),!(!T.matchesSelector||d||g&&g.test(t)||h.test(t)))try{var n=m.call(e,t);if(n||T.disconnectedMatch||e.document&&11!==e.document.nodeType)return n}catch(r){}return st(t,p,null,[e]).length>0},st.contains=function(e,t){return(e.ownerDocument||e)!==p&&c(e),y(e,t)},st.attr=function(e,t){var n;return(e.ownerDocument||e)!==p&&c(e),d||(t=t.toLowerCase()),(n=i.attrHandle[t])?n(e):d||T.attributes?e.getAttribute(t):((n=e.getAttributeNode(t))||e.getAttribute(t))&&e[t]===!0?t:n&&n.specified?n.value:null},st.error=function(e){throw Error(""Syntax error, unrecognized expression: ""+e)},st.uniqueSort=function(e){var t,n=[],r=1,i=0;if(u=!T.detectDuplicates,e.sort(v),u){for(;t=e[r];r++)t===e[r-1]&&(i=n.push(r));while(i--)e.splice(n[i],1)}return e};function ut(e,t){var n=t&&e,r=n&&(~t.sourceIndex||j)-(~e.sourceIndex||j);if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function lt(e){return function(t){var n=t.nodeName.toLowerCase();return""input""===n&&t.type===e}}function ct(e){return function(t){var n=t.nodeName.toLowerCase();return(""input""===n||""button""===n)&&t.type===e}}function pt(e){return ot(function(t){return t=+t,ot(function(n,r){var i,o=e([],n.length,t),a=o.length;while(a--)n[i=o[a]]&&(n[i]=!(r[i]=n[i]))})})}o=st.getText=function(e){var t,n="""",r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if(""string""==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else for(;t=e[r];r++)n+=o(t);return n},i=st.selectors={cacheLength:50,createPseudo:ot,match:U,find:{},relative:{"">"":{dir:""parentNode"",first:!0},"" "":{dir:""parentNode""},""+"":{dir:""previousSibling"",first:!0},""~"":{dir:""previousSibling""}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(et,tt),e[3]=(e[4]||e[5]||"""").replace(et,tt),""~=""===e[2]&&(e[3]="" ""+e[3]+"" ""),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),""nth""===e[1].slice(0,3)?(e[3]||st.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*(""even""===e[3]||""odd""===e[3])),e[5]=+(e[7]+e[8]||""odd""===e[3])):e[3]&&st.error(e[0]),e},PSEUDO:function(e){var t,n=!e[5]&&e[2];return U.CHILD.test(e[0])?null:(e[4]?e[2]=e[4]:n&&z.test(n)&&(t=ft(n,!0))&&(t=n.indexOf("")"",n.length-t)-n.length)&&(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){return""*""===e?function(){return!0}:(e=e.replace(et,tt).toLowerCase(),function(t){return t.nodeName&&t.nodeName.toLowerCase()===e})},CLASS:function(e){var t=k[e+"" ""];return t||(t=RegExp(""(^|""+_+"")""+e+""(""+_+""|$)""))&&k(e,function(e){return t.test(e.className||typeof e.getAttribute!==A&&e.getAttribute(""class"")||"""")})},ATTR:function(e,t,n){return function(r){var i=st.attr(r,e);return null==i?""!=""===t:t?(i+="""",""=""===t?i===n:""!=""===t?i!==n:""^=""===t?n&&0===i.indexOf(n):""*=""===t?n&&i.indexOf(n)>-1:""$=""===t?n&&i.slice(-n.length)===n:""~=""===t?("" ""+i+"" "").indexOf(n)>-1:""|=""===t?i===n||i.slice(0,n.length+1)===n+""-"":!1):!0}},CHILD:function(e,t,n,r,i){var o=""nth""!==e.slice(0,3),a=""last""!==e.slice(-4),s=""of-type""===t;return 1===r&&0===i?function(e){return!!e.parentNode}:function(t,n,u){var l,c,p,f,d,h,g=o!==a?""nextSibling"":""previousSibling"",m=t.parentNode,y=s&&t.nodeName.toLowerCase(),v=!u&&!s;if(m){if(o){while(g){p=t;while(p=p[g])if(s?p.nodeName.toLowerCase()===y:1===p.nodeType)return!1;h=g=""only""===e&&!h&&""nextSibling""}return!0}if(h=[a?m.firstChild:m.lastChild],a&&v){c=m[x]||(m[x]={}),l=c[e]||[],d=l[0]===N&&l[1],f=l[0]===N&&l[2],p=d&&m.childNodes[d];while(p=++d&&p&&p[g]||(f=d=0)||h.pop())if(1===p.nodeType&&++f&&p===t){c[e]=[N,d,f];break}}else if(v&&(l=(t[x]||(t[x]={}))[e])&&l[0]===N)f=l[1];else while(p=++d&&p&&p[g]||(f=d=0)||h.pop())if((s?p.nodeName.toLowerCase()===y:1===p.nodeType)&&++f&&(v&&((p[x]||(p[x]={}))[e]=[N,f]),p===t))break;return f-=i,f===r||0===f%r&&f/r>=0}}},PSEUDO:function(e,t){var n,r=i.pseudos[e]||i.setFilters[e.toLowerCase()]||st.error(""unsupported pseudo: ""+e);return r[x]?r(t):r.length>1?(n=[e,e,"""",t],i.setFilters.hasOwnProperty(e.toLowerCase())?ot(function(e,n){var i,o=r(e,t),a=o.length;while(a--)i=M.call(e,o[a]),e[i]=!(n[i]=o[a])}):function(e){return r(e,0,n)}):r}},pseudos:{not:ot(function(e){var t=[],n=[],r=s(e.replace(W,""$1""));return r[x]?ot(function(e,t,n,i){var o,a=r(e,null,i,[]),s=e.length;while(s--)(o=a[s])&&(e[s]=!(t[s]=o))}):function(e,i,o){return t[0]=e,r(t,null,o,n),!n.pop()}}),has:ot(function(e){return function(t){return st(e,t).length>0}}),contains:ot(function(e){return function(t){return(t.textContent||t.innerText||o(t)).indexOf(e)>-1}}),lang:ot(function(e){return X.test(e||"""")||st.error(""unsupported lang: ""+e),e=e.replace(et,tt).toLowerCase(),function(t){var n;do if(n=d?t.getAttribute(""xml:lang"")||t.getAttribute(""lang""):t.lang)return n=n.toLowerCase(),n===e||0===n.indexOf(e+""-"");while((t=t.parentNode)&&1===t.nodeType);return!1}}),target:function(t){var n=e.location&&e.location.hash;return n&&n.slice(1)===t.id},root:function(e){return e===f},focus:function(e){return e===p.activeElement&&(!p.hasFocus||p.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:function(e){return e.disabled===!1},disabled:function(e){return e.disabled===!0},checked:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&!!e.checked||""option""===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,e.selected===!0},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeName>""@""||3===e.nodeType||4===e.nodeType)return!1;return!0},parent:function(e){return!i.pseudos.empty(e)},header:function(e){return Q.test(e.nodeName)},input:function(e){return G.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&""button""===e.type||""button""===t},text:function(e){var t;return""input""===e.nodeName.toLowerCase()&&""text""===e.type&&(null==(t=e.getAttribute(""type""))||t.toLowerCase()===e.type)},first:pt(function(){return[0]}),last:pt(function(e,t){return[t-1]}),eq:pt(function(e,t,n){return[0>n?n+t:n]}),even:pt(function(e,t){var n=0;for(;t>n;n+=2)e.push(n);return e}),odd:pt(function(e,t){var n=1;for(;t>n;n+=2)e.push(n);return e}),lt:pt(function(e,t,n){var r=0>n?n+t:n;for(;--r>=0;)e.push(r);return e}),gt:pt(function(e,t,n){var r=0>n?n+t:n;for(;t>++r;)e.push(r);return e})}};for(n in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})i.pseudos[n]=lt(n);for(n in{submit:!0,reset:!0})i.pseudos[n]=ct(n);function ft(e,t){var n,r,o,a,s,u,l,c=E[e+"" ""];if(c)return t?0:c.slice(0);s=e,u=[],l=i.preFilter;while(s){(!n||(r=$.exec(s)))&&(r&&(s=s.slice(r[0].length)||s),u.push(o=[])),n=!1,(r=I.exec(s))&&(n=r.shift(),o.push({value:n,type:r[0].replace(W,"" "")}),s=s.slice(n.length));for(a in i.filter)!(r=U[a].exec(s))||l[a]&&!(r=l[a](r))||(n=r.shift(),o.push({value:n,type:a,matches:r}),s=s.slice(n.length));if(!n)break}return t?s.length:s?st.error(e):E(e,u).slice(0)}function dt(e){var t=0,n=e.length,r="""";for(;n>t;t++)r+=e[t].value;return r}function ht(e,t,n){var i=t.dir,o=n&&""parentNode""===i,a=C++;return t.first?function(t,n,r){while(t=t[i])if(1===t.nodeType||o)return e(t,n,r)}:function(t,n,s){var u,l,c,p=N+"" ""+a;if(s){while(t=t[i])if((1===t.nodeType||o)&&e(t,n,s))return!0}else while(t=t[i])if(1===t.nodeType||o)if(c=t[x]||(t[x]={}),(l=c[i])&&l[0]===p){if((u=l[1])===!0||u===r)return u===!0}else if(l=c[i]=[p],l[1]=e(t,n,s)||r,l[1]===!0)return!0}}function gt(e){return e.length>1?function(t,n,r){var i=e.length;while(i--)if(!e[i](t,n,r))return!1;return!0}:e[0]}function mt(e,t,n,r,i){var o,a=[],s=0,u=e.length,l=null!=t;for(;u>s;s++)(o=e[s])&&(!n||n(o,r,i))&&(a.push(o),l&&t.push(s));return a}function yt(e,t,n,r,i,o){return r&&!r[x]&&(r=yt(r)),i&&!i[x]&&(i=yt(i,o)),ot(function(o,a,s,u){var l,c,p,f=[],d=[],h=a.length,g=o||xt(t||""*"",s.nodeType?[s]:s,[]),m=!e||!o&&t?g:mt(g,f,e,s,u),y=n?i||(o?e:h||r)?[]:a:m;if(n&&n(m,y,s,u),r){l=mt(y,d),r(l,[],s,u),c=l.length;while(c--)(p=l[c])&&(y[d[c]]=!(m[d[c]]=p))}if(o){if(i||e){if(i){l=[],c=y.length;while(c--)(p=y[c])&&l.push(m[c]=p);i(null,y=[],l,u)}c=y.length;while(c--)(p=y[c])&&(l=i?M.call(o,p):f[c])>-1&&(o[l]=!(a[l]=p))}}else y=mt(y===a?y.splice(h,y.length):y),i?i(null,a,y,u):H.apply(a,y)})}function vt(e){var t,n,r,o=e.length,a=i.relative[e[0].type],s=a||i.relative["" ""],u=a?1:0,c=ht(function(e){return e===t},s,!0),p=ht(function(e){return M.call(t,e)>-1},s,!0),f=[function(e,n,r){return!a&&(r||n!==l)||((t=n).nodeType?c(e,n,r):p(e,n,r))}];for(;o>u;u++)if(n=i.relative[e[u].type])f=[ht(gt(f),n)];else{if(n=i.filter[e[u].type].apply(null,e[u].matches),n[x]){for(r=++u;o>r;r++)if(i.relative[e[r].type])break;return yt(u>1&&gt(f),u>1&&dt(e.slice(0,u-1)).replace(W,""$1""),n,r>u&&vt(e.slice(u,r)),o>r&&vt(e=e.slice(r)),o>r&&dt(e))}f.push(n)}return gt(f)}function bt(e,t){var n=0,o=t.length>0,a=e.length>0,s=function(s,u,c,f,d){var h,g,m,y=[],v=0,b=""0"",x=s&&[],w=null!=d,T=l,C=s||a&&i.find.TAG(""*"",d&&u.parentNode||u),k=N+=null==T?1:Math.random()||.1;for(w&&(l=u!==p&&u,r=n);null!=(h=C[b]);b++){if(a&&h){g=0;while(m=e[g++])if(m(h,u,c)){f.push(h);break}w&&(N=k,r=++n)}o&&((h=!m&&h)&&v--,s&&x.push(h))}if(v+=b,o&&b!==v){g=0;while(m=t[g++])m(x,y,u,c);if(s){if(v>0)while(b--)x[b]||y[b]||(y[b]=L.call(f));y=mt(y)}H.apply(f,y),w&&!s&&y.length>0&&v+t.length>1&&st.uniqueSort(f)}return w&&(N=k,l=T),x};return o?ot(s):s}s=st.compile=function(e,t){var n,r=[],i=[],o=S[e+"" ""];if(!o){t||(t=ft(e)),n=t.length;while(n--)o=vt(t[n]),o[x]?r.push(o):i.push(o);o=S(e,bt(i,r))}return o};function xt(e,t,n){var r=0,i=t.length;for(;i>r;r++)st(e,t[r],n);return n}function wt(e,t,n,r){var o,a,u,l,c,p=ft(e);if(!r&&1===p.length){if(a=p[0]=p[0].slice(0),a.length>2&&""ID""===(u=a[0]).type&&9===t.nodeType&&!d&&i.relative[a[1].type]){if(t=i.find.ID(u.matches[0].replace(et,tt),t)[0],!t)return n;e=e.slice(a.shift().value.length)}o=U.needsContext.test(e)?0:a.length;while(o--){if(u=a[o],i.relative[l=u.type])break;if((c=i.find[l])&&(r=c(u.matches[0].replace(et,tt),V.test(a[0].type)&&t.parentNode||t))){if(a.splice(o,1),e=r.length&&dt(a),!e)return H.apply(n,q.call(r,0)),n;break}}}return s(e,p)(r,t,d,n,V.test(e)),n}i.pseudos.nth=i.pseudos.eq;function Tt(){}i.filters=Tt.prototype=i.pseudos,i.setFilters=new Tt,c(),st.attr=b.attr,b.find=st,b.expr=st.selectors,b.expr["":""]=b.expr.pseudos,b.unique=st.uniqueSort,b.text=st.getText,b.isXMLDoc=st.isXML,b.contains=st.contains}(e);var at=/Until$/,st=/^(?:parents|prev(?:Until|All))/,ut=/^.[^:#\[\.,]*$/,lt=b.expr.match.needsContext,ct={children:!0,contents:!0,next:!0,prev:!0};b.fn.extend({find:function(e){var t,n,r,i=this.length;if(""string""!=typeof e)return r=this,this.pushStack(b(e).filter(function(){for(t=0;i>t;t++)if(b.contains(r[t],this))return!0}));for(n=[],t=0;i>t;t++)b.find(e,this[t],n);return n=this.pushStack(i>1?b.unique(n):n),n.selector=(this.selector?this.selector+"" "":"""")+e,n},has:function(e){var t,n=b(e,this),r=n.length;return this.filter(function(){for(t=0;r>t;t++)if(b.contains(this,n[t]))return!0})},not:function(e){return this.pushStack(ft(this,e,!1))},filter:function(e){return this.pushStack(ft(this,e,!0))},is:function(e){return!!e&&(""string""==typeof e?lt.test(e)?b(e,this.context).index(this[0])>=0:b.filter(e,this).length>0:this.filter(e).length>0)},closest:function(e,t){var n,r=0,i=this.length,o=[],a=lt.test(e)||""string""!=typeof e?b(e,t||this.context):0;for(;i>r;r++){n=this[r];while(n&&n.ownerDocument&&n!==t&&11!==n.nodeType){if(a?a.index(n)>-1:b.find.matchesSelector(n,e)){o.push(n);break}n=n.parentNode}}return this.pushStack(o.length>1?b.unique(o):o)},index:function(e){return e?""string""==typeof e?b.inArray(this[0],b(e)):b.inArray(e.jquery?e[0]:e,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){var n=""string""==typeof e?b(e,t):b.makeArray(e&&e.nodeType?[e]:e),r=b.merge(this.get(),n);return this.pushStack(b.unique(r))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),b.fn.andSelf=b.fn.addBack;function pt(e,t){do e=e[t];while(e&&1!==e.nodeType);return e}b.each({parent:function(e){var t=e.parentNode;return t&&11!==t.nodeType?t:null},parents:function(e){return b.dir(e,""parentNode"")},parentsUntil:function(e,t,n){return b.dir(e,""parentNode"",n)},next:function(e){return pt(e,""nextSibling"")},prev:function(e){return pt(e,""previousSibling"")},nextAll:function(e){return b.dir(e,""nextSibling"")},prevAll:function(e){return b.dir(e,""previousSibling"")},nextUntil:function(e,t,n){return b.dir(e,""nextSibling"",n)},prevUntil:function(e,t,n){return b.dir(e,""previousSibling"",n)},siblings:function(e){return b.sibling((e.parentNode||{}).firstChild,e)},children:function(e){return b.sibling(e.firstChild)},contents:function(e){return b.nodeName(e,""iframe"")?e.contentDocument||e.contentWindow.document:b.merge([],e.childNodes)}},function(e,t){b.fn[e]=function(n,r){var i=b.map(this,t,n);return at.test(e)||(r=n),r&&""string""==typeof r&&(i=b.filter(r,i)),i=this.length>1&&!ct[e]?b.unique(i):i,this.length>1&&st.test(e)&&(i=i.reverse()),this.pushStack(i)}}),b.extend({filter:function(e,t,n){return n&&(e="":not(""+e+"")""),1===t.length?b.find.matchesSelector(t[0],e)?[t[0]]:[]:b.find.matches(e,t)},dir:function(e,n,r){var i=[],o=e[n];while(o&&9!==o.nodeType&&(r===t||1!==o.nodeType||!b(o).is(r)))1===o.nodeType&&i.push(o),o=o[n];return i},sibling:function(e,t){var n=[];for(;e;e=e.nextSibling)1===e.nodeType&&e!==t&&n.push(e);return n}});function ft(e,t,n){if(t=t||0,b.isFunction(t))return b.grep(e,function(e,r){var i=!!t.call(e,r,e);return i===n});if(t.nodeType)return b.grep(e,function(e){return e===t===n});if(""string""==typeof t){var r=b.grep(e,function(e){return 1===e.nodeType});if(ut.test(t))return b.filter(t,r,!n);t=b.filter(t,r)}return b.grep(e,function(e){return b.inArray(e,t)>=0===n})}function dt(e){var t=ht.split(""|""),n=e.createDocumentFragment();if(n.createElement)while(t.length)n.createElement(t.pop());return n}var ht=""abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video"",gt=/ jQuery\d+=""(?:null|\d+)""/g,mt=RegExp(""<(?:""+ht+"")[\\s/>]"",""i""),yt=/^\s+/,vt=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/gi,bt=/<([\w:]+)/,xt=/<tbody/i,wt=/<|&#?\w+;/,Tt=/<(?:script|style|link)/i,Nt=/^(?:checkbox|radio)$/i,Ct=/checked\s*(?:[^=]|=\s*.checked.)/i,kt=/^$|\/(?:java|ecma)script/i,Et=/^true\/(.*)/,St=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,At={option:[1,""<select multiple='multiple'>"",""</select>""],legend:[1,""<fieldset>"",""</fieldset>""],area:[1,""<map>"",""</map>""],param:[1,""<object>"",""</object>""],thead:[1,""<table>"",""</table>""],tr:[2,""<table><tbody>"",""</tbody></table>""],col:[2,""<table><tbody></tbody><colgroup>"",""</colgroup></table>""],td:[3,""<table><tbody><tr>"",""</tr></tbody></table>""],_default:b.support.htmlSerialize?[0,"""",""""]:[1,""X<div>"",""</div>""]},jt=dt(o),Dt=jt.appendChild(o.createElement(""div""));At.optgroup=At.option,At.tbody=At.tfoot=At.colgroup=At.caption=At.thead,At.th=At.td,b.fn.extend({text:function(e){return b.access(this,function(e){return e===t?b.text(this):this.empty().append((this[0]&&this[0].ownerDocument||o).createTextNode(e))},null,e,arguments.length)},wrapAll:function(e){if(b.isFunction(e))return this.each(function(t){b(this).wrapAll(e.call(this,t))});if(this[0]){var t=b(e,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstChild&&1===e.firstChild.nodeType)e=e.firstChild;return e}).append(this)}return this},wrapInner:function(e){return b.isFunction(e)?this.each(function(t){b(this).wrapInner(e.call(this,t))}):this.each(function(){var t=b(this),n=t.contents();n.length?n.wrapAll(e):t.append(e)})},wrap:function(e){var t=b.isFunction(e);return this.each(function(n){b(this).wrapAll(t?e.call(this,n):e)})},unwrap:function(){return this.parent().each(function(){b.nodeName(this,""body"")||b(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,!0,function(e){(1===this.nodeType||11===this.nodeType||9===this.nodeType)&&this.appendChild(e)})},prepend:function(){return this.domManip(arguments,!0,function(e){(1===this.nodeType||11===this.nodeType||9===this.nodeType)&&this.insertBefore(e,this.firstChild)})},before:function(){return this.domManip(arguments,!1,function(e){this.parentNode&&this.parentNode.insertBefore(e,this)})},after:function(){return this.domManip(arguments,!1,function(e){this.parentNode&&this.parentNode.insertBefore(e,this.nextSibling)})},remove:function(e,t){var n,r=0;for(;null!=(n=this[r]);r++)(!e||b.filter(e,[n]).length>0)&&(t||1!==n.nodeType||b.cleanData(Ot(n)),n.parentNode&&(t&&b.contains(n.ownerDocument,n)&&Mt(Ot(n,""script"")),n.parentNode.removeChild(n)));return this},empty:function(){var e,t=0;for(;null!=(e=this[t]);t++){1===e.nodeType&&b.cleanData(Ot(e,!1));while(e.firstChild)e.removeChild(e.firstChild);e.options&&b.nodeName(e,""select"")&&(e.options.length=0)}return this},clone:function(e,t){return e=null==e?!1:e,t=null==t?e:t,this.map(function(){return b.clone(this,e,t)})},html:function(e){return b.access(this,function(e){var n=this[0]||{},r=0,i=this.length;if(e===t)return 1===n.nodeType?n.innerHTML.replace(gt,""""):t;if(!(""string""!=typeof e||Tt.test(e)||!b.support.htmlSerialize&&mt.test(e)||!b.support.leadingWhitespace&&yt.test(e)||At[(bt.exec(e)||["""",""""])[1].toLowerCase()])){e=e.replace(vt,""<$1></$2>"");try{for(;i>r;r++)n=this[r]||{},1===n.nodeType&&(b.cleanData(Ot(n,!1)),n.innerHTML=e);n=0}catch(o){}}n&&this.empty().append(e)},null,e,arguments.length)},replaceWith:function(e){var t=b.isFunction(e);return t||""string""==typeof e||(e=b(e).not(this).detach()),this.domManip([e],!0,function(e){var t=this.nextSibling,n=this.parentNode;n&&(b(this).remove(),n.insertBefore(e,t))})},detach:function(e){return this.remove(e,!0)},domManip:function(e,n,r){e=f.apply([],e);var i,o,a,s,u,l,c=0,p=this.length,d=this,h=p-1,g=e[0],m=b.isFunction(g);if(m||!(1>=p||""string""!=typeof g||b.support.checkClone)&&Ct.test(g))return this.each(function(i){var o=d.eq(i);m&&(e[0]=g.call(this,i,n?o.html():t)),o.domManip(e,n,r)});if(p&&(l=b.buildFragment(e,this[0].ownerDocument,!1,this),i=l.firstChild,1===l.childNodes.length&&(l=i),i)){for(n=n&&b.nodeName(i,""tr""),s=b.map(Ot(l,""script""),Ht),a=s.length;p>c;c++)o=l,c!==h&&(o=b.clone(o,!0,!0),a&&b.merge(s,Ot(o,""script""))),r.call(n&&b.nodeName(this[c],""table"")?Lt(this[c],""tbody""):this[c],o,c);if(a)for(u=s[s.length-1].ownerDocument,b.map(s,qt),c=0;a>c;c++)o=s[c],kt.test(o.type||"""")&&!b._data(o,""globalEval"")&&b.contains(u,o)&&(o.src?b.ajax({url:o.src,type:""GET"",dataType:""script"",async:!1,global:!1,""throws"":!0}):b.globalEval((o.text||o.textContent||o.innerHTML||"""").replace(St,"""")));l=i=null}return this}});function Lt(e,t){return e.getElementsByTagName(t)[0]||e.appendChild(e.ownerDocument.createElement(t))}function Ht(e){var t=e.getAttributeNode(""type"");return e.type=(t&&t.specified)+""/""+e.type,e}function qt(e){var t=Et.exec(e.type);return t?e.type=t[1]:e.removeAttribute(""type""),e}function Mt(e,t){var n,r=0;for(;null!=(n=e[r]);r++)b._data(n,""globalEval"",!t||b._data(t[r],""globalEval""))}function _t(e,t){if(1===t.nodeType&&b.hasData(e)){var n,r,i,o=b._data(e),a=b._data(t,o),s=o.events;if(s){delete a.handle,a.events={};for(n in s)for(r=0,i=s[n].length;i>r;r++)b.event.add(t,n,s[n][r])}a.data&&(a.data=b.extend({},a.data))}}function Ft(e,t){var n,r,i;if(1===t.nodeType){if(n=t.nodeName.toLowerCase(),!b.support.noCloneEvent&&t[b.expando]){i=b._data(t);for(r in i.events)b.removeEvent(t,r,i.handle);t.removeAttribute(b.expando)}""script""===n&&t.text!==e.text?(Ht(t).text=e.text,qt(t)):""object""===n?(t.parentNode&&(t.outerHTML=e.outerHTML),b.support.html5Clone&&e.innerHTML&&!b.trim(t.innerHTML)&&(t.innerHTML=e.innerHTML)):""input""===n&&Nt.test(e.type)?(t.defaultChecked=t.checked=e.checked,t.value!==e.value&&(t.value=e.value)):""option""===n?t.defaultSelected=t.selected=e.defaultSelected:(""input""===n||""textarea""===n)&&(t.defaultValue=e.defaultValue)}}b.each({appendTo:""append"",prependTo:""prepend"",insertBefore:""before"",insertAfter:""after"",replaceAll:""replaceWith""},function(e,t){b.fn[e]=function(e){var n,r=0,i=[],o=b(e),a=o.length-1;for(;a>=r;r++)n=r===a?this:this.clone(!0),b(o[r])[t](n),d.apply(i,n.get());return this.pushStack(i)}});function Ot(e,n){var r,o,a=0,s=typeof e.getElementsByTagName!==i?e.getElementsByTagName(n||""*""):typeof e.querySelectorAll!==i?e.querySelectorAll(n||""*""):t;if(!s)for(s=[],r=e.childNodes||e;null!=(o=r[a]);a++)!n||b.nodeName(o,n)?s.push(o):b.merge(s,Ot(o,n));return n===t||n&&b.nodeName(e,n)?b.merge([e],s):s}function Bt(e){Nt.test(e.type)&&(e.defaultChecked=e.checked)}b.extend({clone:function(e,t,n){var r,i,o,a,s,u=b.contains(e.ownerDocument,e);if(b.support.html5Clone||b.isXMLDoc(e)||!mt.test(""<""+e.nodeName+"">"")?o=e.cloneNode(!0):(Dt.innerHTML=e.outerHTML,Dt.removeChild(o=Dt.firstChild)),!(b.support.noCloneEvent&&b.support.noCloneChecked||1!==e.nodeType&&11!==e.nodeType||b.isXMLDoc(e)))for(r=Ot(o),s=Ot(e),a=0;null!=(i=s[a]);++a)r[a]&&Ft(i,r[a]);if(t)if(n)for(s=s||Ot(e),r=r||Ot(o),a=0;null!=(i=s[a]);a++)_t(i,r[a]);else _t(e,o);return r=Ot(o,""script""),r.length>0&&Mt(r,!u&&Ot(e,""script"")),r=s=i=null,o},buildFragment:function(e,t,n,r){var i,o,a,s,u,l,c,p=e.length,f=dt(t),d=[],h=0;for(;p>h;h++)if(o=e[h],o||0===o)if(""object""===b.type(o))b.merge(d,o.nodeType?[o]:o);else if(wt.test(o)){s=s||f.appendChild(t.createElement(""div"")),u=(bt.exec(o)||["""",""""])[1].toLowerCase(),c=At[u]||At._default,s.innerHTML=c[1]+o.replace(vt,""<$1></$2>"")+c[2],i=c[0];while(i--)s=s.lastChild;if(!b.support.leadingWhitespace&&yt.test(o)&&d.push(t.createTextNode(yt.exec(o)[0])),!b.support.tbody){o=""table""!==u||xt.test(o)?""<table>""!==c[1]||xt.test(o)?0:s:s.firstChild,i=o&&o.childNodes.length;while(i--)b.nodeName(l=o.childNodes[i],""tbody"")&&!l.childNodes.length&&o.removeChild(l)
}b.merge(d,s.childNodes),s.textContent="""";while(s.firstChild)s.removeChild(s.firstChild);s=f.lastChild}else d.push(t.createTextNode(o));s&&f.removeChild(s),b.support.appendChecked||b.grep(Ot(d,""input""),Bt),h=0;while(o=d[h++])if((!r||-1===b.inArray(o,r))&&(a=b.contains(o.ownerDocument,o),s=Ot(f.appendChild(o),""script""),a&&Mt(s),n)){i=0;while(o=s[i++])kt.test(o.type||"""")&&n.push(o)}return s=null,f},cleanData:function(e,t){var n,r,o,a,s=0,u=b.expando,l=b.cache,p=b.support.deleteExpando,f=b.event.special;for(;null!=(n=e[s]);s++)if((t||b.acceptData(n))&&(o=n[u],a=o&&l[o])){if(a.events)for(r in a.events)f[r]?b.event.remove(n,r):b.removeEvent(n,r,a.handle);l[o]&&(delete l[o],p?delete n[u]:typeof n.removeAttribute!==i?n.removeAttribute(u):n[u]=null,c.push(o))}}});var Pt,Rt,Wt,$t=/alpha\([^)]*\)/i,It=/opacity\s*=\s*([^)]*)/,zt=/^(top|right|bottom|left)$/,Xt=/^(none|table(?!-c[ea]).+)/,Ut=/^margin/,Vt=RegExp(""^(""+x+"")(.*)$"",""i""),Yt=RegExp(""^(""+x+"")(?!px)[a-z%]+$"",""i""),Jt=RegExp(""^([+-])=(""+x+"")"",""i""),Gt={BODY:""block""},Qt={position:""absolute"",visibility:""hidden"",display:""block""},Kt={letterSpacing:0,fontWeight:400},Zt=[""Top"",""Right"",""Bottom"",""Left""],en=[""Webkit"",""O"",""Moz"",""ms""];function tn(e,t){if(t in e)return t;var n=t.charAt(0).toUpperCase()+t.slice(1),r=t,i=en.length;while(i--)if(t=en[i]+n,t in e)return t;return r}function nn(e,t){return e=t||e,""none""===b.css(e,""display"")||!b.contains(e.ownerDocument,e)}function rn(e,t){var n,r,i,o=[],a=0,s=e.length;for(;s>a;a++)r=e[a],r.style&&(o[a]=b._data(r,""olddisplay""),n=r.style.display,t?(o[a]||""none""!==n||(r.style.display=""""),""""===r.style.display&&nn(r)&&(o[a]=b._data(r,""olddisplay"",un(r.nodeName)))):o[a]||(i=nn(r),(n&&""none""!==n||!i)&&b._data(r,""olddisplay"",i?n:b.css(r,""display""))));for(a=0;s>a;a++)r=e[a],r.style&&(t&&""none""!==r.style.display&&""""!==r.style.display||(r.style.display=t?o[a]||"""":""none""));return e}b.fn.extend({css:function(e,n){return b.access(this,function(e,n,r){var i,o,a={},s=0;if(b.isArray(n)){for(o=Rt(e),i=n.length;i>s;s++)a[n[s]]=b.css(e,n[s],!1,o);return a}return r!==t?b.style(e,n,r):b.css(e,n)},e,n,arguments.length>1)},show:function(){return rn(this,!0)},hide:function(){return rn(this)},toggle:function(e){var t=""boolean""==typeof e;return this.each(function(){(t?e:nn(this))?b(this).show():b(this).hide()})}}),b.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=Wt(e,""opacity"");return""""===n?""1"":n}}}},cssNumber:{columnCount:!0,fillOpacity:!0,fontWeight:!0,lineHeight:!0,opacity:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{""float"":b.support.cssFloat?""cssFloat"":""styleFloat""},style:function(e,n,r,i){if(e&&3!==e.nodeType&&8!==e.nodeType&&e.style){var o,a,s,u=b.camelCase(n),l=e.style;if(n=b.cssProps[u]||(b.cssProps[u]=tn(l,u)),s=b.cssHooks[n]||b.cssHooks[u],r===t)return s&&""get""in s&&(o=s.get(e,!1,i))!==t?o:l[n];if(a=typeof r,""string""===a&&(o=Jt.exec(r))&&(r=(o[1]+1)*o[2]+parseFloat(b.css(e,n)),a=""number""),!(null==r||""number""===a&&isNaN(r)||(""number""!==a||b.cssNumber[u]||(r+=""px""),b.support.clearCloneStyle||""""!==r||0!==n.indexOf(""background"")||(l[n]=""inherit""),s&&""set""in s&&(r=s.set(e,r,i))===t)))try{l[n]=r}catch(c){}}},css:function(e,n,r,i){var o,a,s,u=b.camelCase(n);return n=b.cssProps[u]||(b.cssProps[u]=tn(e.style,u)),s=b.cssHooks[n]||b.cssHooks[u],s&&""get""in s&&(a=s.get(e,!0,r)),a===t&&(a=Wt(e,n,i)),""normal""===a&&n in Kt&&(a=Kt[n]),""""===r||r?(o=parseFloat(a),r===!0||b.isNumeric(o)?o||0:a):a},swap:function(e,t,n,r){var i,o,a={};for(o in t)a[o]=e.style[o],e.style[o]=t[o];i=n.apply(e,r||[]);for(o in t)e.style[o]=a[o];return i}}),e.getComputedStyle?(Rt=function(t){return e.getComputedStyle(t,null)},Wt=function(e,n,r){var i,o,a,s=r||Rt(e),u=s?s.getPropertyValue(n)||s[n]:t,l=e.style;return s&&(""""!==u||b.contains(e.ownerDocument,e)||(u=b.style(e,n)),Yt.test(u)&&Ut.test(n)&&(i=l.width,o=l.minWidth,a=l.maxWidth,l.minWidth=l.maxWidth=l.width=u,u=s.width,l.width=i,l.minWidth=o,l.maxWidth=a)),u}):o.documentElement.currentStyle&&(Rt=function(e){return e.currentStyle},Wt=function(e,n,r){var i,o,a,s=r||Rt(e),u=s?s[n]:t,l=e.style;return null==u&&l&&l[n]&&(u=l[n]),Yt.test(u)&&!zt.test(n)&&(i=l.left,o=e.runtimeStyle,a=o&&o.left,a&&(o.left=e.currentStyle.left),l.left=""fontSize""===n?""1em"":u,u=l.pixelLeft+""px"",l.left=i,a&&(o.left=a)),""""===u?""auto"":u});function on(e,t,n){var r=Vt.exec(t);return r?Math.max(0,r[1]-(n||0))+(r[2]||""px""):t}function an(e,t,n,r,i){var o=n===(r?""border"":""content"")?4:""width""===t?1:0,a=0;for(;4>o;o+=2)""margin""===n&&(a+=b.css(e,n+Zt[o],!0,i)),r?(""content""===n&&(a-=b.css(e,""padding""+Zt[o],!0,i)),""margin""!==n&&(a-=b.css(e,""border""+Zt[o]+""Width"",!0,i))):(a+=b.css(e,""padding""+Zt[o],!0,i),""padding""!==n&&(a+=b.css(e,""border""+Zt[o]+""Width"",!0,i)));return a}function sn(e,t,n){var r=!0,i=""width""===t?e.offsetWidth:e.offsetHeight,o=Rt(e),a=b.support.boxSizing&&""border-box""===b.css(e,""boxSizing"",!1,o);if(0>=i||null==i){if(i=Wt(e,t,o),(0>i||null==i)&&(i=e.style[t]),Yt.test(i))return i;r=a&&(b.support.boxSizingReliable||i===e.style[t]),i=parseFloat(i)||0}return i+an(e,t,n||(a?""border"":""content""),r,o)+""px""}function un(e){var t=o,n=Gt[e];return n||(n=ln(e,t),""none""!==n&&n||(Pt=(Pt||b(""<iframe frameborder='0' width='0' height='0'/>"").css(""cssText"",""display:block !important"")).appendTo(t.documentElement),t=(Pt[0].contentWindow||Pt[0].contentDocument).document,t.write(""<!doctype html><html><body>""),t.close(),n=ln(e,t),Pt.detach()),Gt[e]=n),n}function ln(e,t){var n=b(t.createElement(e)).appendTo(t.body),r=b.css(n[0],""display"");return n.remove(),r}b.each([""height"",""width""],function(e,n){b.cssHooks[n]={get:function(e,r,i){return r?0===e.offsetWidth&&Xt.test(b.css(e,""display""))?b.swap(e,Qt,function(){return sn(e,n,i)}):sn(e,n,i):t},set:function(e,t,r){var i=r&&Rt(e);return on(e,t,r?an(e,n,r,b.support.boxSizing&&""border-box""===b.css(e,""boxSizing"",!1,i),i):0)}}}),b.support.opacity||(b.cssHooks.opacity={get:function(e,t){return It.test((t&&e.currentStyle?e.currentStyle.filter:e.style.filter)||"""")?.01*parseFloat(RegExp.$1)+"""":t?""1"":""""},set:function(e,t){var n=e.style,r=e.currentStyle,i=b.isNumeric(t)?""alpha(opacity=""+100*t+"")"":"""",o=r&&r.filter||n.filter||"""";n.zoom=1,(t>=1||""""===t)&&""""===b.trim(o.replace($t,""""))&&n.removeAttribute&&(n.removeAttribute(""filter""),""""===t||r&&!r.filter)||(n.filter=$t.test(o)?o.replace($t,i):o+"" ""+i)}}),b(function(){b.support.reliableMarginRight||(b.cssHooks.marginRight={get:function(e,n){return n?b.swap(e,{display:""inline-block""},Wt,[e,""marginRight""]):t}}),!b.support.pixelPosition&&b.fn.position&&b.each([""top"",""left""],function(e,n){b.cssHooks[n]={get:function(e,r){return r?(r=Wt(e,n),Yt.test(r)?b(e).position()[n]+""px"":r):t}}})}),b.expr&&b.expr.filters&&(b.expr.filters.hidden=function(e){return 0>=e.offsetWidth&&0>=e.offsetHeight||!b.support.reliableHiddenOffsets&&""none""===(e.style&&e.style.display||b.css(e,""display""))},b.expr.filters.visible=function(e){return!b.expr.filters.hidden(e)}),b.each({margin:"""",padding:"""",border:""Width""},function(e,t){b.cssHooks[e+t]={expand:function(n){var r=0,i={},o=""string""==typeof n?n.split("" ""):[n];for(;4>r;r++)i[e+Zt[r]+t]=o[r]||o[r-2]||o[0];return i}},Ut.test(e)||(b.cssHooks[e+t].set=on)});var cn=/%20/g,pn=/\[\]$/,fn=/\r?\n/g,dn=/^(?:submit|button|image|reset|file)$/i,hn=/^(?:input|select|textarea|keygen)/i;b.fn.extend({serialize:function(){return b.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=b.prop(this,""elements"");return e?b.makeArray(e):this}).filter(function(){var e=this.type;return this.name&&!b(this).is("":disabled"")&&hn.test(this.nodeName)&&!dn.test(e)&&(this.checked||!Nt.test(e))}).map(function(e,t){var n=b(this).val();return null==n?null:b.isArray(n)?b.map(n,function(e){return{name:t.name,value:e.replace(fn,""\r\n"")}}):{name:t.name,value:n.replace(fn,""\r\n"")}}).get()}}),b.param=function(e,n){var r,i=[],o=function(e,t){t=b.isFunction(t)?t():null==t?"""":t,i[i.length]=encodeURIComponent(e)+""=""+encodeURIComponent(t)};if(n===t&&(n=b.ajaxSettings&&b.ajaxSettings.traditional),b.isArray(e)||e.jquery&&!b.isPlainObject(e))b.each(e,function(){o(this.name,this.value)});else for(r in e)gn(r,e[r],n,o);return i.join(""&"").replace(cn,""+"")};function gn(e,t,n,r){var i;if(b.isArray(t))b.each(t,function(t,i){n||pn.test(e)?r(e,i):gn(e+""[""+(""object""==typeof i?t:"""")+""]"",i,n,r)});else if(n||""object""!==b.type(t))r(e,t);else for(i in t)gn(e+""[""+i+""]"",t[i],n,r)}b.each(""blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu"".split("" ""),function(e,t){b.fn[t]=function(e,n){return arguments.length>0?this.on(t,null,e,n):this.trigger(t)}}),b.fn.hover=function(e,t){return this.mouseenter(e).mouseleave(t||e)};var mn,yn,vn=b.now(),bn=/\?/,xn=/#.*$/,wn=/([?&])_=[^&]*/,Tn=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Nn=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Cn=/^(?:GET|HEAD)$/,kn=/^\/\//,En=/^([\w.+-]+:)(?:\/\/([^\/?#:]*)(?::(\d+)|)|)/,Sn=b.fn.load,An={},jn={},Dn=""*/"".concat(""*"");try{yn=a.href}catch(Ln){yn=o.createElement(""a""),yn.href="""",yn=yn.href}mn=En.exec(yn.toLowerCase())||[];function Hn(e){return function(t,n){""string""!=typeof t&&(n=t,t=""*"");var r,i=0,o=t.toLowerCase().match(w)||[];if(b.isFunction(n))while(r=o[i++])""+""===r[0]?(r=r.slice(1)||""*"",(e[r]=e[r]||[]).unshift(n)):(e[r]=e[r]||[]).push(n)}}function qn(e,n,r,i){var o={},a=e===jn;function s(u){var l;return o[u]=!0,b.each(e[u]||[],function(e,u){var c=u(n,r,i);return""string""!=typeof c||a||o[c]?a?!(l=c):t:(n.dataTypes.unshift(c),s(c),!1)}),l}return s(n.dataTypes[0])||!o[""*""]&&s(""*"")}function Mn(e,n){var r,i,o=b.ajaxSettings.flatOptions||{};for(i in n)n[i]!==t&&((o[i]?e:r||(r={}))[i]=n[i]);return r&&b.extend(!0,e,r),e}b.fn.load=function(e,n,r){if(""string""!=typeof e&&Sn)return Sn.apply(this,arguments);var i,o,a,s=this,u=e.indexOf("" "");return u>=0&&(i=e.slice(u,e.length),e=e.slice(0,u)),b.isFunction(n)?(r=n,n=t):n&&""object""==typeof n&&(a=""POST""),s.length>0&&b.ajax({url:e,type:a,dataType:""html"",data:n}).done(function(e){o=arguments,s.html(i?b(""<div>"").append(b.parseHTML(e)).find(i):e)}).complete(r&&function(e,t){s.each(r,o||[e.responseText,t,e])}),this},b.each([""ajaxStart"",""ajaxStop"",""ajaxComplete"",""ajaxError"",""ajaxSuccess"",""ajaxSend""],function(e,t){b.fn[t]=function(e){return this.on(t,e)}}),b.each([""get"",""post""],function(e,n){b[n]=function(e,r,i,o){return b.isFunction(r)&&(o=o||i,i=r,r=t),b.ajax({url:e,type:n,dataType:o,data:r,success:i})}}),b.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:yn,type:""GET"",isLocal:Nn.test(mn[1]),global:!0,processData:!0,async:!0,contentType:""application/x-www-form-urlencoded; charset=UTF-8"",accepts:{""*"":Dn,text:""text/plain"",html:""text/html"",xml:""application/xml, text/xml"",json:""application/json, text/javascript""},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:""responseXML"",text:""responseText""},converters:{""* text"":e.String,""text html"":!0,""text json"":b.parseJSON,""text xml"":b.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(e,t){return t?Mn(Mn(e,b.ajaxSettings),t):Mn(b.ajaxSettings,e)},ajaxPrefilter:Hn(An),ajaxTransport:Hn(jn),ajax:function(e,n){""object""==typeof e&&(n=e,e=t),n=n||{};var r,i,o,a,s,u,l,c,p=b.ajaxSetup({},n),f=p.context||p,d=p.context&&(f.nodeType||f.jquery)?b(f):b.event,h=b.Deferred(),g=b.Callbacks(""once memory""),m=p.statusCode||{},y={},v={},x=0,T=""canceled"",N={readyState:0,getResponseHeader:function(e){var t;if(2===x){if(!c){c={};while(t=Tn.exec(a))c[t[1].toLowerCase()]=t[2]}t=c[e.toLowerCase()]}return null==t?null:t},getAllResponseHeaders:function(){return 2===x?a:null},setRequestHeader:function(e,t){var n=e.toLowerCase();return x||(e=v[n]=v[n]||e,y[e]=t),this},overrideMimeType:function(e){return x||(p.mimeType=e),this},statusCode:function(e){var t;if(e)if(2>x)for(t in e)m[t]=[m[t],e[t]];else N.always(e[N.status]);return this},abort:function(e){var t=e||T;return l&&l.abort(t),k(0,t),this}};if(h.promise(N).complete=g.add,N.success=N.done,N.error=N.fail,p.url=((e||p.url||yn)+"""").replace(xn,"""").replace(kn,mn[1]+""//""),p.type=n.method||n.type||p.method||p.type,p.dataTypes=b.trim(p.dataType||""*"").toLowerCase().match(w)||[""""],null==p.crossDomain&&(r=En.exec(p.url.toLowerCase()),p.crossDomain=!(!r||r[1]===mn[1]&&r[2]===mn[2]&&(r[3]||(""http:""===r[1]?80:443))==(mn[3]||(""http:""===mn[1]?80:443)))),p.data&&p.processData&&""string""!=typeof p.data&&(p.data=b.param(p.data,p.traditional)),qn(An,p,n,N),2===x)return N;u=p.global,u&&0===b.active++&&b.event.trigger(""ajaxStart""),p.type=p.type.toUpperCase(),p.hasContent=!Cn.test(p.type),o=p.url,p.hasContent||(p.data&&(o=p.url+=(bn.test(o)?""&"":""?"")+p.data,delete p.data),p.cache===!1&&(p.url=wn.test(o)?o.replace(wn,""$1_=""+vn++):o+(bn.test(o)?""&"":""?"")+""_=""+vn++)),p.ifModified&&(b.lastModified[o]&&N.setRequestHeader(""If-Modified-Since"",b.lastModified[o]),b.etag[o]&&N.setRequestHeader(""If-None-Match"",b.etag[o])),(p.data&&p.hasContent&&p.contentType!==!1||n.contentType)&&N.setRequestHeader(""Content-Type"",p.contentType),N.setRequestHeader(""Accept"",p.dataTypes[0]&&p.accepts[p.dataTypes[0]]?p.accepts[p.dataTypes[0]]+(""*""!==p.dataTypes[0]?"", ""+Dn+""; q=0.01"":""""):p.accepts[""*""]);for(i in p.headers)N.setRequestHeader(i,p.headers[i]);if(p.beforeSend&&(p.beforeSend.call(f,N,p)===!1||2===x))return N.abort();T=""abort"";for(i in{success:1,error:1,complete:1})N[i](p[i]);if(l=qn(jn,p,n,N)){N.readyState=1,u&&d.trigger(""ajaxSend"",[N,p]),p.async&&p.timeout>0&&(s=setTimeout(function(){N.abort(""timeout"")},p.timeout));try{x=1,l.send(y,k)}catch(C){if(!(2>x))throw C;k(-1,C)}}else k(-1,""No Transport"");function k(e,n,r,i){var c,y,v,w,T,C=n;2!==x&&(x=2,s&&clearTimeout(s),l=t,a=i||"""",N.readyState=e>0?4:0,r&&(w=_n(p,N,r)),e>=200&&300>e||304===e?(p.ifModified&&(T=N.getResponseHeader(""Last-Modified""),T&&(b.lastModified[o]=T),T=N.getResponseHeader(""etag""),T&&(b.etag[o]=T)),204===e?(c=!0,C=""nocontent""):304===e?(c=!0,C=""notmodified""):(c=Fn(p,w),C=c.state,y=c.data,v=c.error,c=!v)):(v=C,(e||!C)&&(C=""error"",0>e&&(e=0))),N.status=e,N.statusText=(n||C)+"""",c?h.resolveWith(f,[y,C,N]):h.rejectWith(f,[N,C,v]),N.statusCode(m),m=t,u&&d.trigger(c?""ajaxSuccess"":""ajaxError"",[N,p,c?y:v]),g.fireWith(f,[N,C]),u&&(d.trigger(""ajaxComplete"",[N,p]),--b.active||b.event.trigger(""ajaxStop"")))}return N},getScript:function(e,n){return b.get(e,t,n,""script"")},getJSON:function(e,t,n){return b.get(e,t,n,""json"")}});function _n(e,n,r){var i,o,a,s,u=e.contents,l=e.dataTypes,c=e.responseFields;for(s in c)s in r&&(n[c[s]]=r[s]);while(""*""===l[0])l.shift(),o===t&&(o=e.mimeType||n.getResponseHeader(""Content-Type""));if(o)for(s in u)if(u[s]&&u[s].test(o)){l.unshift(s);break}if(l[0]in r)a=l[0];else{for(s in r){if(!l[0]||e.converters[s+"" ""+l[0]]){a=s;break}i||(i=s)}a=a||i}return a?(a!==l[0]&&l.unshift(a),r[a]):t}function Fn(e,t){var n,r,i,o,a={},s=0,u=e.dataTypes.slice(),l=u[0];if(e.dataFilter&&(t=e.dataFilter(t,e.dataType)),u[1])for(i in e.converters)a[i.toLowerCase()]=e.converters[i];for(;r=u[++s];)if(""*""!==r){if(""*""!==l&&l!==r){if(i=a[l+"" ""+r]||a[""* ""+r],!i)for(n in a)if(o=n.split("" ""),o[1]===r&&(i=a[l+"" ""+o[0]]||a[""* ""+o[0]])){i===!0?i=a[n]:a[n]!==!0&&(r=o[0],u.splice(s--,0,r));break}if(i!==!0)if(i&&e[""throws""])t=i(t);else try{t=i(t)}catch(c){return{state:""parsererror"",error:i?c:""No conversion from ""+l+"" to ""+r}}}l=r}return{state:""success"",data:t}}b.ajaxSetup({accepts:{script:""text/javascript, application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/(?:java|ecma)script/},converters:{""text script"":function(e){return b.globalEval(e),e}}}),b.ajaxPrefilter(""script"",function(e){e.cache===t&&(e.cache=!1),e.crossDomain&&(e.type=""GET"",e.global=!1)}),b.ajaxTransport(""script"",function(e){if(e.crossDomain){var n,r=o.head||b(""head"")[0]||o.documentElement;return{send:function(t,i){n=o.createElement(""script""),n.async=!0,e.scriptCharset&&(n.charset=e.scriptCharset),n.src=e.url,n.onload=n.onreadystatechange=function(e,t){(t||!n.readyState||/loaded|complete/.test(n.readyState))&&(n.onload=n.onreadystatechange=null,n.parentNode&&n.parentNode.removeChild(n),n=null,t||i(200,""success""))},r.insertBefore(n,r.firstChild)},abort:function(){n&&n.onload(t,!0)}}}});var On=[],Bn=/(=)\?(?=&|$)|\?\?/;b.ajaxSetup({jsonp:""callback"",jsonpCallback:function(){var e=On.pop()||b.expando+""_""+vn++;return this[e]=!0,e}}),b.ajaxPrefilter(""json jsonp"",function(n,r,i){var o,a,s,u=n.jsonp!==!1&&(Bn.test(n.url)?""url"":""string""==typeof n.data&&!(n.contentType||"""").indexOf(""application/x-www-form-urlencoded"")&&Bn.test(n.data)&&""data"");return u||""jsonp""===n.dataTypes[0]?(o=n.jsonpCallback=b.isFunction(n.jsonpCallback)?n.jsonpCallback():n.jsonpCallback,u?n[u]=n[u].replace(Bn,""$1""+o):n.jsonp!==!1&&(n.url+=(bn.test(n.url)?""&"":""?"")+n.jsonp+""=""+o),n.converters[""script json""]=function(){return s||b.error(o+"" was not called""),s[0]},n.dataTypes[0]=""json"",a=e[o],e[o]=function(){s=arguments},i.always(function(){e[o]=a,n[o]&&(n.jsonpCallback=r.jsonpCallback,On.push(o)),s&&b.isFunction(a)&&a(s[0]),s=a=t}),""script""):t});var Pn,Rn,Wn=0,$n=e.ActiveXObject&&function(){var e;for(e in Pn)Pn[e](t,!0)};function In(){try{return new e.XMLHttpRequest}catch(t){}}function zn(){try{return new e.ActiveXObject(""Microsoft.XMLHTTP"")}catch(t){}}b.ajaxSettings.xhr=e.ActiveXObject?function(){return!this.isLocal&&In()||zn()}:In,Rn=b.ajaxSettings.xhr(),b.support.cors=!!Rn&&""withCredentials""in Rn,Rn=b.support.ajax=!!Rn,Rn&&b.ajaxTransport(function(n){if(!n.crossDomain||b.support.cors){var r;return{send:function(i,o){var a,s,u=n.xhr();if(n.username?u.open(n.type,n.url,n.async,n.username,n.password):u.open(n.type,n.url,n.async),n.xhrFields)for(s in n.xhrFields)u[s]=n.xhrFields[s];n.mimeType&&u.overrideMimeType&&u.overrideMimeType(n.mimeType),n.crossDomain||i[""X-Requested-With""]||(i[""X-Requested-With""]=""XMLHttpRequest"");try{for(s in i)u.setRequestHeader(s,i[s])}catch(l){}u.send(n.hasContent&&n.data||null),r=function(e,i){var s,l,c,p;try{if(r&&(i||4===u.readyState))if(r=t,a&&(u.onreadystatechange=b.noop,$n&&delete Pn[a]),i)4!==u.readyState&&u.abort();else{p={},s=u.status,l=u.getAllResponseHeaders(),""string""==typeof u.responseText&&(p.text=u.responseText);try{c=u.statusText}catch(f){c=""""}s||!n.isLocal||n.crossDomain?1223===s&&(s=204):s=p.text?200:404}}catch(d){i||o(-1,d)}p&&o(s,c,p,l)},n.async?4===u.readyState?setTimeout(r):(a=++Wn,$n&&(Pn||(Pn={},b(e).unload($n)),Pn[a]=r),u.onreadystatechange=r):r()},abort:function(){r&&r(t,!0)}}}});var Xn,Un,Vn=/^(?:toggle|show|hide)$/,Yn=RegExp(""^(?:([+-])=|)(""+x+"")([a-z%]*)$"",""i""),Jn=/queueHooks$/,Gn=[nr],Qn={""*"":[function(e,t){var n,r,i=this.createTween(e,t),o=Yn.exec(t),a=i.cur(),s=+a||0,u=1,l=20;if(o){if(n=+o[2],r=o[3]||(b.cssNumber[e]?"""":""px""),""px""!==r&&s){s=b.css(i.elem,e,!0)||n||1;do u=u||"".5"",s/=u,b.style(i.elem,e,s+r);while(u!==(u=i.cur()/a)&&1!==u&&--l)}i.unit=r,i.start=s,i.end=o[1]?s+(o[1]+1)*n:n}return i}]};function Kn(){return setTimeout(function(){Xn=t}),Xn=b.now()}function Zn(e,t){b.each(t,function(t,n){var r=(Qn[t]||[]).concat(Qn[""*""]),i=0,o=r.length;for(;o>i;i++)if(r[i].call(e,t,n))return})}function er(e,t,n){var r,i,o=0,a=Gn.length,s=b.Deferred().always(function(){delete u.elem}),u=function(){if(i)return!1;var t=Xn||Kn(),n=Math.max(0,l.startTime+l.duration-t),r=n/l.duration||0,o=1-r,a=0,u=l.tweens.length;for(;u>a;a++)l.tweens[a].run(o);return s.notifyWith(e,[l,o,n]),1>o&&u?n:(s.resolveWith(e,[l]),!1)},l=s.promise({elem:e,props:b.extend({},t),opts:b.extend(!0,{specialEasing:{}},n),originalProperties:t,originalOptions:n,startTime:Xn||Kn(),duration:n.duration,tweens:[],createTween:function(t,n){var r=b.Tween(e,l.opts,t,n,l.opts.specialEasing[t]||l.opts.easing);return l.tweens.push(r),r},stop:function(t){var n=0,r=t?l.tweens.length:0;if(i)return this;for(i=!0;r>n;n++)l.tweens[n].run(1);return t?s.resolveWith(e,[l,t]):s.rejectWith(e,[l,t]),this}}),c=l.props;for(tr(c,l.opts.specialEasing);a>o;o++)if(r=Gn[o].call(l,e,c,l.opts))return r;return Zn(l,c),b.isFunction(l.opts.start)&&l.opts.start.call(e,l),b.fx.timer(b.extend(u,{elem:e,anim:l,queue:l.opts.queue})),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always)}function tr(e,t){var n,r,i,o,a;for(i in e)if(r=b.camelCase(i),o=t[r],n=e[i],b.isArray(n)&&(o=n[1],n=e[i]=n[0]),i!==r&&(e[r]=n,delete e[i]),a=b.cssHooks[r],a&&""expand""in a){n=a.expand(n),delete e[r];for(i in n)i in e||(e[i]=n[i],t[i]=o)}else t[r]=o}b.Animation=b.extend(er,{tweener:function(e,t){b.isFunction(e)?(t=e,e=[""*""]):e=e.split("" "");var n,r=0,i=e.length;for(;i>r;r++)n=e[r],Qn[n]=Qn[n]||[],Qn[n].unshift(t)},prefilter:function(e,t){t?Gn.unshift(e):Gn.push(e)}});function nr(e,t,n){var r,i,o,a,s,u,l,c,p,f=this,d=e.style,h={},g=[],m=e.nodeType&&nn(e);n.queue||(c=b._queueHooks(e,""fx""),null==c.unqueued&&(c.unqueued=0,p=c.empty.fire,c.empty.fire=function(){c.unqueued||p()}),c.unqueued++,f.always(function(){f.always(function(){c.unqueued--,b.queue(e,""fx"").length||c.empty.fire()})})),1===e.nodeType&&(""height""in t||""width""in t)&&(n.overflow=[d.overflow,d.overflowX,d.overflowY],""inline""===b.css(e,""display"")&&""none""===b.css(e,""float"")&&(b.support.inlineBlockNeedsLayout&&""inline""!==un(e.nodeName)?d.zoom=1:d.display=""inline-block"")),n.overflow&&(d.overflow=""hidden"",b.support.shrinkWrapBlocks||f.always(function(){d.overflow=n.overflow[0],d.overflowX=n.overflow[1],d.overflowY=n.overflow[2]}));for(i in t)if(a=t[i],Vn.exec(a)){if(delete t[i],u=u||""toggle""===a,a===(m?""hide"":""show""))continue;g.push(i)}if(o=g.length){s=b._data(e,""fxshow"")||b._data(e,""fxshow"",{}),""hidden""in s&&(m=s.hidden),u&&(s.hidden=!m),m?b(e).show():f.done(function(){b(e).hide()}),f.done(function(){var t;b._removeData(e,""fxshow"");for(t in h)b.style(e,t,h[t])});for(i=0;o>i;i++)r=g[i],l=f.createTween(r,m?s[r]:0),h[r]=s[r]||b.style(e,r),r in s||(s[r]=l.start,m&&(l.end=l.start,l.start=""width""===r||""height""===r?1:0))}}function rr(e,t,n,r,i){return new rr.prototype.init(e,t,n,r,i)}b.Tween=rr,rr.prototype={constructor:rr,init:function(e,t,n,r,i,o){this.elem=e,this.prop=n,this.easing=i||""swing"",this.options=t,this.start=this.now=this.cur(),this.end=r,this.unit=o||(b.cssNumber[n]?"""":""px"")},cur:function(){var e=rr.propHooks[this.prop];return e&&e.get?e.get(this):rr.propHooks._default.get(this)},run:function(e){var t,n=rr.propHooks[this.prop];return this.pos=t=this.options.duration?b.easing[this.easing](e,this.options.duration*e,0,1,this.options.duration):e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):rr.propHooks._default.set(this),this}},rr.prototype.init.prototype=rr.prototype,rr.propHooks={_default:{get:function(e){var t;return null==e.elem[e.prop]||e.elem.style&&null!=e.elem.style[e.prop]?(t=b.css(e.elem,e.prop,""""),t&&""auto""!==t?t:0):e.elem[e.prop]},set:function(e){b.fx.step[e.prop]?b.fx.step[e.prop](e):e.elem.style&&(null!=e.elem.style[b.cssProps[e.prop]]||b.cssHooks[e.prop])?b.style(e.elem,e.prop,e.now+e.unit):e.elem[e.prop]=e.now}}},rr.propHooks.scrollTop=rr.propHooks.scrollLeft={set:function(e){e.elem.nodeType&&e.elem.parentNode&&(e.elem[e.prop]=e.now)}},b.each([""toggle"",""show"",""hide""],function(e,t){var n=b.fn[t];b.fn[t]=function(e,r,i){return null==e||""boolean""==typeof e?n.apply(this,arguments):this.animate(ir(t,!0),e,r,i)}}),b.fn.extend({fadeTo:function(e,t,n,r){return this.filter(nn).css(""opacity"",0).show().end().animate({opacity:t},e,n,r)},animate:function(e,t,n,r){var i=b.isEmptyObject(e),o=b.speed(t,n,r),a=function(){var t=er(this,b.extend({},e),o);a.finish=function(){t.stop(!0)},(i||b._data(this,""finish""))&&t.stop(!0)};return a.finish=a,i||o.queue===!1?this.each(a):this.queue(o.queue,a)},stop:function(e,n,r){var i=function(e){var t=e.stop;delete e.stop,t(r)};return""string""!=typeof e&&(r=n,n=e,e=t),n&&e!==!1&&this.queue(e||""fx"",[]),this.each(function(){var t=!0,n=null!=e&&e+""queueHooks"",o=b.timers,a=b._data(this);if(n)a[n]&&a[n].stop&&i(a[n]);else for(n in a)a[n]&&a[n].stop&&Jn.test(n)&&i(a[n]);for(n=o.length;n--;)o[n].elem!==this||null!=e&&o[n].queue!==e||(o[n].anim.stop(r),t=!1,o.splice(n,1));(t||!r)&&b.dequeue(this,e)})},finish:function(e){return e!==!1&&(e=e||""fx""),this.each(function(){var t,n=b._data(this),r=n[e+""queue""],i=n[e+""queueHooks""],o=b.timers,a=r?r.length:0;for(n.finish=!0,b.queue(this,e,[]),i&&i.cur&&i.cur.finish&&i.cur.finish.call(this),t=o.length;t--;)o[t].elem===this&&o[t].queue===e&&(o[t].anim.stop(!0),o.splice(t,1));for(t=0;a>t;t++)r[t]&&r[t].finish&&r[t].finish.call(this);delete n.finish})}});function ir(e,t){var n,r={height:e},i=0;for(t=t?1:0;4>i;i+=2-t)n=Zt[i],r[""margin""+n]=r[""padding""+n]=e;return t&&(r.opacity=r.width=e),r}b.each({slideDown:ir(""show""),slideUp:ir(""hide""),slideToggle:ir(""toggle""),fadeIn:{opacity:""show""},fadeOut:{opacity:""hide""},fadeToggle:{opacity:""toggle""}},function(e,t){b.fn[e]=function(e,n,r){return this.animate(t,e,n,r)}}),b.speed=function(e,t,n){var r=e&&""object""==typeof e?b.extend({},e):{complete:n||!n&&t||b.isFunction(e)&&e,duration:e,easing:n&&t||t&&!b.isFunction(t)&&t};return r.duration=b.fx.off?0:""number""==typeof r.duration?r.duration:r.duration in b.fx.speeds?b.fx.speeds[r.duration]:b.fx.speeds._default,(null==r.queue||r.queue===!0)&&(r.queue=""fx""),r.old=r.complete,r.complete=function(){b.isFunction(r.old)&&r.old.call(this),r.queue&&b.dequeue(this,r.queue)},r},b.easing={linear:function(e){return e},swing:function(e){return.5-Math.cos(e*Math.PI)/2}},b.timers=[],b.fx=rr.prototype.init,b.fx.tick=function(){var e,n=b.timers,r=0;for(Xn=b.now();n.length>r;r++)e=n[r],e()||n[r]!==e||n.splice(r--,1);n.length||b.fx.stop(),Xn=t},b.fx.timer=function(e){e()&&b.timers.push(e)&&b.fx.start()},b.fx.interval=13,b.fx.start=function(){Un||(Un=setInterval(b.fx.tick,b.fx.interval))},b.fx.stop=function(){clearInterval(Un),Un=null},b.fx.speeds={slow:600,fast:200,_default:400},b.fx.step={},b.expr&&b.expr.filters&&(b.expr.filters.animated=function(e){return b.grep(b.timers,function(t){return e===t.elem}).length}),b.fn.offset=function(e){if(arguments.length)return e===t?this:this.each(function(t){b.offset.setOffset(this,e,t)});var n,r,o={top:0,left:0},a=this[0],s=a&&a.ownerDocument;if(s)return n=s.documentElement,b.contains(n,a)?(typeof a.getBoundingClientRect!==i&&(o=a.getBoundingClientRect()),r=or(s),{top:o.top+(r.pageYOffset||n.scrollTop)-(n.clientTop||0),left:o.left+(r.pageXOffset||n.scrollLeft)-(n.clientLeft||0)}):o},b.offset={setOffset:function(e,t,n){var r=b.css(e,""position"");""static""===r&&(e.style.position=""relative"");var i=b(e),o=i.offset(),a=b.css(e,""top""),s=b.css(e,""left""),u=(""absolute""===r||""fixed""===r)&&b.inArray(""auto"",[a,s])>-1,l={},c={},p,f;u?(c=i.position(),p=c.top,f=c.left):(p=parseFloat(a)||0,f=parseFloat(s)||0),b.isFunction(t)&&(t=t.call(e,n,o)),null!=t.top&&(l.top=t.top-o.top+p),null!=t.left&&(l.left=t.left-o.left+f),""using""in t?t.using.call(e,l):i.css(l)}},b.fn.extend({position:function(){if(this[0]){var e,t,n={top:0,left:0},r=this[0];return""fixed""===b.css(r,""position"")?t=r.getBoundingClientRect():(e=this.offsetParent(),t=this.offset(),b.nodeName(e[0],""html"")||(n=e.offset()),n.top+=b.css(e[0],""borderTopWidth"",!0),n.left+=b.css(e[0],""borderLeftWidth"",!0)),{top:t.top-n.top-b.css(r,""marginTop"",!0),left:t.left-n.left-b.css(r,""marginLeft"",!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent||o.documentElement;while(e&&!b.nodeName(e,""html"")&&""static""===b.css(e,""position""))e=e.offsetParent;return e||o.documentElement})}}),b.each({scrollLeft:""pageXOffset"",scrollTop:""pageYOffset""},function(e,n){var r=/Y/.test(n);b.fn[e]=function(i){return b.access(this,function(e,i,o){var a=or(e);return o===t?a?n in a?a[n]:a.document.documentElement[i]:e[i]:(a?a.scrollTo(r?b(a).scrollLeft():o,r?o:b(a).scrollTop()):e[i]=o,t)},e,i,arguments.length,null)}});function or(e){return b.isWindow(e)?e:9===e.nodeType?e.defaultView||e.parentWindow:!1}b.each({Height:""height"",Width:""width""},function(e,n){b.each({padding:""inner""+e,content:n,"""":""outer""+e},function(r,i){b.fn[i]=function(i,o){var a=arguments.length&&(r||""boolean""!=typeof i),s=r||(i===!0||o===!0?""margin"":""border"");return b.access(this,function(n,r,i){var o;return b.isWindow(n)?n.document.documentElement[""client""+e]:9===n.nodeType?(o=n.documentElement,Math.max(n.body[""scroll""+e],o[""scroll""+e],n.body[""offset""+e],o[""offset""+e],o[""client""+e])):i===t?b.css(n,r,s):b.style(n,r,i,s)},n,a?i:t,a,null)}})}),e.jQuery=e.$=b,""function""==typeof define&&define.amd&&define.amd.jQuery&&define(""jquery"",[],function(){return b})})(window);

/*! jQuery Migrate v1.2.2-pre | (c) 2005, 2013 jQuery Foundation, Inc. and other contributors | jquery.org/license */
",4
"    f1 = (2 * p * r) / (p + r) if p + r else 0
",4
"        if if_act:
",4
"        if self.scheduler[""gradual_unfreeze""][
                ""params_layer""] and self.scheduler[""gradual_unfreeze""][""blocks""]:
            logger.warning(
                ""Both params_layer and blocks have been set in gradual_unfreeze, only params_layer will take effect""
            )
",4
"
",4
"    }
",4
"    return data
",4
"        data_layout='NCHW',
        is_test=True,
",4
"    _440 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _441 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=2)
    _449 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
    _452 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _453 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=4)
",4
"
    def predict(self,
                data,
",4
"        self.nms_threshold = nms_threshold
        self.normalized = normalized
        self.nms_eta = nms_eta
        self.background_label = background_label
",4
"                      width=2,
                      fill='red')
        # draw label
        text = bbox['label'] + "": %.2f%%"" % (100 * bbox['confidence'])
",4
"    depth_list = sorted(depth_params_dict.keys())
    len_depth_list = len(depth_list)
    for index, depth in enumerate(depth_list):
",4
"        for var_info in var_infos.map.data:
",4
"            '--confs_threshold',
            type=ast.literal_eval,
            default=0.6,
            help=""confidence threshold."")
# coding=utf-8
",4
"    Yield:
",4
"def image_saturation_adjust(img, delta):
    delta = _check_range_0_1(delta)
    img = _check_img(img)
",4
"                       images=None,
                       paths=None,
                       data=None,
                       use_gpu=False,
                       output_dir='detection_result',
",4
"            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(memory_pool_init_size_mb=500, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)
",4
"                param_attr=fluid.ParamAttr(
                    name=""mask_lm_out_fc.w_0"",
                    initializer=self._param_initializer),
                bias_attr=mask_lm_out_bias_attr)
",4
"            if not self.load_checkpoint():
                self.exe.run(self._base_startup_program)
",4
"import time
import sys
import paddle.fluid as fluid
",4
"		},
		/**/
",4
"        create neural network.

        Args:
",4
"            print('\n')
            result = self.classifier.classification(
                paths=pics_path_list, batch_size=3, use_gpu=False, top_k=2)
            print(result)

",4
"        for token in tokens_a:
            tokens.append(token)
            text_type_ids.append(0)
        tokens.append(""[SEP]"")
",4
"

def multi_head_attention(queries,
",4
"        if np.round(im_scale * im_size_max) > max_size:
            im_scale = float(max_size) / float(im_size_max)

        resize_w = np.round(im_scale * float(shape[1]))
",4
"
            fluid.io.load_vars(
                exe, self.pretrained_model_path, predicate=if_exist)

            inputs = {
",4
"        self.num_epochs = self.get_config_from_sec('train', 'epoch')
        self.total_videos = self.get_config_from_sec('train', 'total_videos')
        self.base_learning_rate = self.get_config_from_sec(
",4
"            self.args.type = ""Module""
            if search_result == {}:
                search_result = hub.HubServer().get_resource_url(
",4
"                    def _if_exist(var):
                        b = os.path.exists(
",4
"            mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
            name=""mask_lm_out_fc.b_0"",
",4
"
class AnchorGenerator(object):
    # __op__ = fluid.layers.anchor_generator
",4
"                offset=offset,
",4
"                ""words"":
                main_program.global_block().vars[prefix_name + data_name]
            }
            outputs = {
                ""class_probs"":
",4
"    if len(image.shape) == 3:
        image = np.swapaxes(image, 1, 2)
        image = np.swapaxes(image, 1, 0)
    # RBG to BGR
",4
"            prog='hub run {}'.format(self.name),
            usage='%(prog)s',
            add_help=True)
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"        # HWC --> CHW
",4
"            result = self.animal_classify.classification(
",4
"            position_ids (tensor): the position ids.
            segment_ids (tensor): the segment ids.
            input_mask (tensor): the padding mask.
",4
"            help=""Return top k results."")

    def add_module_input_arg(self):
        """"""
        Add the command input options.
",4
"
def _load_file_list(input_txt):
",4
"        args = self.parser.parse_args(argvs)
        texts = [args.input_text]
        return self.sentiment_classify(texts)
def load_vocab(vocab_path):
    with open(vocab_path) as file:
",4
"				textAlign: 'center',
				position: 'absolute',
				display: 'none',
				zIndex: '101',
",4
"                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
",4
"					paddingRight: '30px'
",4
"        # input from the previous time step first.
        k = cache[""k""] = layers.concat(
",4
"			};
			this.addListenerInside('mouseover', cAdEscMuteOver, this.getByElement(adEscMuteID + '-canvas'));
",4
"from __future__ import division

import os
from collections import OrderedDict

",4
"    if paths:
        for img_path in paths:
            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"                 use_fp16=False):
",4
"    ""ResNet"", ""ResNet18"", ""ResNet34"", ""ResNet50"", ""ResNet101"", ""ResNet152""
]
",4
"                    os.path.join(image_dir, 'dog.jpg'),
                    os.path.join(image_dir, 'giraffe.jpg')
                ],
                images=zebras,
                batch_size=2)
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"						case 'mute':
",4
"        API for image classification.

",4
"        if self._dtype == ""float16"":
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)

",4
"
    def get_expected_image_width(self):
        return 224

    def get_expected_image_height(self):
",4
"            type=ast.literal_eval,
            default=1,
            help=""Return top k results."")

    def add_module_input_arg(self):
",4
"    def del_user_dict(self, ):
        """"""
        Delete the costomized dictionary if you don't wanna exploit the self-defined dictionary any longer
",4
"            stride=stride,
            padding=padding,
            name=name)

",4
"					if (this.isUndefined(position[i]) || position[i] == null || position[i] == 'null' || position[i] == '') {
						position[i] = null;
					} else {
						position[i] = parseFloat(position[i]);
",4
"            key
            for key in sorted(
                self.model_rewards, key=self.model_rewards.get, reverse=False)
            [:half_size]
",4
"
",4
"            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

        self._enc_out = encoder(
            enc_input=emb_out,
",4
"					easeInOut: function(t, b, c, d) {
						return c * t / d + b;
					}
				},
				Quadratic: {
",4
"

",4
"					}
				}
			}
			var html = '';
",4
"            org_img_path = unhandled_paths[index]
            org_img = Image.open(org_img_path)
",4
"            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            visualization (bool): Whether to save image or not.
",4
"            params_filename=params_filename)

    @serving
    def serving_method(self, images, **kwargs):
",4
"            config=self.bert_config,
            use_fp16=False)
        pooled_output = bert.get_pooled_output()
        sequence_output = bert.get_sequence_output()
        return pooled_output, sequence_output
",4
"            ]

        # im_shape, im_id, bbox
        if for_export:
            return [self.outputs[0].name]
",4
"                 ch_out,
                 filter_size,
",4
"        self.anchor_sizes = anchor_sizes
        self.aspect_ratios = aspect_ratios
        self.variance = variance
        self.stride = stride

",4
"            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"            is_test=is_test,
            name='{}.2'.format(name))
",4
"        else:
            return linear_out

    def invresi_blocks(self, input, in_c, t, c, n, s, name=None):
",4
"
",4
"        k = layers.fc(
            input=keys,
            size=d_key * n_head,
",4
"            ]
            if use_gpu:
",4
"    """"""
    Preprocess to yield image.
",4
"        saturation_delta = np.random.uniform(self.saturation_lower,
                                             self.saturation_upper)
        prob = np.random.uniform(0, 1)
",4
"
    def data_format(self, sign_name):
",4
"        return module_config

",4
"		/*
			
			loading
		*/
		loadingStart: function(rot) {
",4
"# You may obtain a copy of the License at
#
",4
"			adBackgroundID = 'background' + randomS,//
			adElementID = 'adelement' + randomS,//
			adBarID = 'adBar' + randomS,//
			adSkipID = 'adskip' + randomS,//
			adTimeID = 'adtime' + randomS,//
",4
"        Args:
            input_ids (tensor): the word ids.
            position_ids (tensor): the position ids.
",4
"# you may not use this file except in compliance with the License.
",4
"                [5, 144, 48, True, 'hard_swish', 1],
                [5, 288, 96, True, 'hard_swish', 2],
                [5, 576, 96, True, 'hard_swish', 1],
",4
"    if module_attr.map.data['regularizer'].type != module_desc_pb2.NONE:
        regularizer_type = module_attr.map.data['regularizer'].name
        regularization_coeff = from_module_attr_to_pyobj(
            module_attr.map.data['regularizer'].object.
",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
",4
"
",4
"      larger than 0 will be treated as positives, otherwise as negatives.
      n: the top n items to be considered in ap@n.
",4
"        norm_decay (float): weight decay for normalization layer weights
        variant (str): ResNet variant, supports 'a', 'b', 'c', 'd' currently
",4
"		getXY: function(obj) {
			var parObj = obj;
			var left = obj.offsetLeft;
			var top = obj.offsetTop;
",4
"    component = list()
",4
"            self.directory, ""se_resnet18_vd_imagenet_model"")
        label_file = os.path.join(self.directory, ""label_list.txt"")
        with open(label_file, 'r', encoding='utf-8') as file:
",4
"
    def get_expected_image_height(self):
",4
"					css = {
						left: Math.ceil(tweenFun(t, b, c, d)) + 'px'
					};
					if (obj['static']) {
						eleCoor = thisTemp.calculationCoor(obj['element']);
",4
"                    text=final_text,
",4
"            labels.append(l)
        return labels

",4
"        """"""
        Run as a command.
",4
"                    bbox_out = yolo_head.get_prediction(head_features, im_size)
                    outputs = {'bbox_out': [var_prefix + bbox_out.name]}
                else:
                    outputs = {
",4
"        ""Call tearDown to restore environment.\n""
",4
"                contrast_lower and contrast_lower
            saturation_lower/ saturation_upper (float): the saturation
                between saturation_lower and saturation_upper
            hue_lower/ hue_upper (float): the hue between
                hue_lower and hue_upper
",4
"            name=name + '.conv2d.output.1',
            data_format=data_format)

        if name == ""conv1"":
",4
"                .format(len(batch_data)))
        if coarsest_stride > 1:
            padding_batch = []
",4
"					}
",4
"
    def _add_topdown_lateral(self, body_name, body_input, upper_output):
        lateral_name = 'fpn_inner_' + body_name + '_lateral'
",4
"
",4
"    return output
# coding=utf-8
",4
"            theta_phi_sc = theta_phi
",4
"        max_seq_len=max_seq_len,
        return_pos=False,
        return_input_mask=False)
",4
"    package='paddlehub.module.desc',
    syntax='proto3',
    serialized_pb=_b(
        '\n\x11module_desc.proto\x12\x15paddlehub.module.desc\""\x9e\x02\n\x06KVData\x12<\n\x08key_type\x18\x01 \x03(\x0b\x32*.paddlehub.module.desc.KVData.KeyTypeEntry\x12\x35\n\x04\x64\x61ta\x18\x02 \x03(\x0b\x32\'.paddlehub.module.desc.KVData.DataEntry\x1aO\n\x0cKeyTypeEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0e\x32\x1f.paddlehub.module.desc.DataType:\x02\x38\x01\x1aN\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x30\n\x05value\x18\x02 \x01(\x0b\x32!.paddlehub.module.desc.ModuleAttr:\x02\x38\x01\""\xb7\x02\n\nModuleAttr\x12-\n\x04type\x18\x01 \x01(\x0e\x32\x1f.paddlehub.module.desc.DataType\x12\t\n\x01i\x18\x02 \x01(\x03\x12\t\n\x01\x66\x18\x03 \x01(\x01\x12\t\n\x01\x62\x18\x04 \x01(\x08\x12\t\n\x01s\x18\x05 \x01(\t\x12*\n\x03map\x18\x06 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12+\n\x04list\x18\x07 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12*\n\x03set\x18\x08 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12-\n\x06object\x18\t \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12\x0c\n\x04name\x18\n \x01(\t\x12\x0c\n\x04info\x18\x0b \x01(\t\""+\n\x08\x46\x65\x65\x64\x44\x65sc\x12\x10\n\x08var_name\x18\x01 \x01(\t\x12\r\n\x05\x61lias\x18\x02 \x01(\t\"",\n\tFetchDesc\x12\x10\n\x08var_name\x18\x01 \x01(\t\x12\r\n\x05\x61lias\x18\x02 \x01(\t\""u\n\tModuleVar\x12\x34\n\nfetch_desc\x18\x01 \x03(\x0b\x32 .paddlehub.module.desc.FetchDesc\x12\x32\n\tfeed_desc\x18\x02 \x03(\x0b\x32\x1f.paddlehub.module.desc.FeedDesc\""\xd3\x01\n\nModuleDesc\x12\x41\n\x08sign2var\x18\x02 \x03(\x0b\x32/.paddlehub.module.desc.ModuleDesc.Sign2varEntry\x12/\n\x04\x61ttr\x18\x03 \x01(\x0b\x32!.paddlehub.module.desc.ModuleAttr\x1aQ\n\rSign2varEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .paddlehub.module.desc.ModuleVar:\x02\x38\x01*i\n\x08\x44\x61taType\x12\x08\n\x04NONE\x10\x00\x12\x07\n\x03INT\x10\x01\x12\t\n\x05\x46LOAT\x10\x02\x12\n\n\x06STRING\x10\x03\x12\x0b\n\x07\x42OOLEAN\x10\x04\x12\x08\n\x04LIST\x10\x05\x12\x07\n\x03MAP\x10\x06\x12\x07\n\x03SET\x10\x07\x12\n\n\x06OBJECT\x10\x08\x42\x02H\x03\x62\x06proto3'
",4
"                self.writer_pop_trails[pop_num].add_scalar(
                    tag=""population_transformation/"" + name,
",4
"# You may obtain a copy of the License at
#
",4
"    def get_beg_end_flag_idx(self, beg_or_end):
        if self.loss_type == ""attention"":
            if beg_or_end == ""beg"":
                idx = np.array(self.dict[self.beg_str])
            elif beg_or_end == ""end"":
",4
"            is_extension=False,
",4
"        results = []
        for text in texts:
            sentiment = ""positive""
            for word in self.vocab:
",4
"
    def __init__(self, errmsg=''):
",4
"					});
",4
"            else:
                return self.conv_bn_layer_new(
                    input, ch_out, 1, stride, name=name)
        elif if_first:
",4
"        self.fpn_inner_output = [[] for _ in range(num_backbone_stages)]
        fpn_inner_name = 'fpn_inner_' + body_name_list[0]
        body_input = body_dict[body_name_list[0]]
        fan = body_input.shape[1]
        if self.norm_type:
",4
"                fpn_name = 'fpn_' + str(i)
                if i > highest_backbone_level + 1:
                    fpn_blob_in = fluid.layers.relu(fpn_blob)
                fan = fpn_blob_in.shape[1] * 3 * 3
                fpn_blob = fluid.layers.conv2d(
",4
"            dirname=dirname,
            main_program=program,
            executor=exe,
            feeded_var_names=feeded_var_names,
            target_vars=target_vars,
",4
"            size=self.lstm_size * 4,
",4
"        # characters in the vocabulary because Wikipedia does have some Chinese
        # words in the English Wikipedia.).
        text = self._tokenize_chinese_chars(text)
",4
"        Run as a service.
",4
"								var eleTop = (obj['y'] - parseInt(imgH * 0.1) + 2);
								thisTemp.css(thisTemp.previewDiv, {
",4
"            raise ValueError(""Image width and height should not be negative."")

    def data_generator(self,
                       batch_size=1,
                       phase=""train"",
",4
"        filter_size=[3, 3],
        stride=[1, 1],
",4
"        # Choose dataset: GLUE/XNLI/ChinesesGLUE/NLPCC-DBQA/LCQMC
        # metric should be acc, f1 or matthews
        metrics_choices = [""acc""]

",4
"        self.assertEqual(self.module.interventer, None)
",4
"            else:
                cls_feats = net_func(unpad_feature)
            logger.info(
                ""%s has been added in the TextClassifierTask!"" % self.network)
",4
"            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
",4
"    Add residual connection, layer normalization and droput to the out tensor
",4
"        """"""proxy to self._ds.next""""""

        def empty(x):
            if isinstance(x, np.ndarray) and x.size == 0:
",4
"                            conv_name = ""res"" + str(block + 2) + ""a""
",4
"
import numpy as np
",4
"
",4
"        else:
            precision, recall, f1 = calculate_f1(total_label, total_infer,
                                                 total_correct)
",4
"    def add_module_config_arg(self):
        """"""
        Add the command config options
        """"""
        self.arg_config_group.add_argument(
",4
"					}
				};
",4
"				this.V.animateResume(this.isUndefined(id) ? '': id);
				return;
			}
			var arr = [];
			if (id != '' && !this.isUndefined(id) && id != 'pause') {
",4
"                              d_hid,
                              dropout_rate,
                              hidden_act,
                              param_initializer=None,
",4
"        n_head_self_attn_mask = fluid.layers.stack(
            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

",4
"    while len(indexes) > 0:
        # current = indexes[0]
        current = indexes[-1]
        picked.append(current)
        if 0 < top_k == len(picked) or len(indexes) == 1:
",4
"    return enc_output
",4
"
    return result

",4
"				if (obj.currentStyle) {
					return obj.currentStyle[attr];
				} else {
					return getComputedStyle(obj, false)[attr];
",4
"                    param.trainable = trainable
        return inputs, outputs, context_prog

",4
"                img_path), ""The {} isn't a valid file path."".format(img_path)
            img = Image.open(img_path)
            #img = cv2.imread(img_path)
",4
"                nms_thresh=0.7,
                post_nms_top_n=1000,
                pre_nms_top_n=1000),
            anchor_start_size=32,
            num_chan=256,
",4
"
import base64
import cv2
",4
"            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2
",4
"        images_decode = [base64_to_cv2(image) for image in images]
",4
"
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"registerGame(GameInfo(108, Rainbow, ""Rainbow"",
                      GI.GT_CANFIELD, 1, 0, GI.SL_BALANCED))
",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s
",5
"

",5
"        c1 = cards[0]
        for c2 in cards[1:]:
            if not (c1.suit == c2.suit and c1.rank + dir == c2.rank):
",5
"    return e.type == gdk.BUTTON_PRESS and e.button == 2


def _wrap_b3_press(e):
    return (e.type == gdk.BUTTON_PRESS and e.button == 3 and
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
",5
"# * Puss in the Corner
# ************************************************************************

class PussInTheCorner_Talon(OpenTalonStack):
",5
"            return (card1.rank == card2.rank and
",5
"        for i in range(9):
            self.s.talon.dealRow(rows=self.s.rows[:i], flip=flip, frames=0)
        self._startAndDealRowAndCards()

",5
"        return len(cards) <= max_move and AC_RowStack.canMoveCards(self, cards)


# A Freecell_SameSuit_RowStack (i.e. Baker's Game)
",5
"
        data = []
        for label, vg in GI.GAMES_BY_COMPATIBILITY:
",5
"    def __init__(self, x, y, suit=None):
        self.x = int(round(x))
        self.y = int(round(y))
",5
"            def callback(w, n=n):
                sp = self.widgets_tree.get_widget(n+'_spinbutton')
                sc = self.widgets_tree.get_widget(n+'_scale')
",5
"                values = [_(v) for v in w.values]
                om = tkinter.OptionMenu(frame, w.variable, *values)
",5
"    def currentForce(self, card):
        force = self._getForce(card)
        hour = time.localtime(time.time())[3]
",5
"        # Define stack groups
        l.defaultStackGroups()

",5
"        else:
",5
"                    None, togglebutton, ""buttondefault"", 0, 0, w, h)
    save_image(""button-pa"", w, h)
",5
"from six.moves import tkinter_ttk as ttk

from .selecttree import SelectDialogTreeCanvas
from .selecttree import SelectDialogTreeLeaf, SelectDialogTreeNode
from .tkwidget import MfxDialog, MfxScrolledCanvas, PysolScale
",5
"
        self.bind(on_release=self.on_released)
        self.bind(is_selected=self.onSelect)
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
",5
"        frame = tkinter.Frame(top_frame)
        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

",5
"
# imports
import os

import gobject
",5
"# * Klondike Plus 16
# ************************************************************************

class KlondikePlus16(Game):
",5
"
# ************************************************************************
# * Hiranyaksha
# ************************************************************************
",5
"
",5
"
    def canSaveGame(self):
        return 0
",5
"        # print('writer: anchor_bgn %s - %s' % (href, name))
        if href:
",5
"    xa = 0
    ya = 0
",5
"    Talon_Class = InitialDealTalonStack
    RowStack_Class = StackWrapper(AC_RowStack, max_move=1)
    Hint_Class = CautiousDefaultHint
",5
"#    ""bDlbEfcEhbEj"")
# r(5503, ""Cobweb"", layout=""0aacaafhagaahoah"" +
",5
"                max_accept=0, max_cards=104))
        l.createText(s.foundations[0], ""s"")

        # define stack-groups
",5
"        else:
            for c in self.cards[self.game.drag.index+1:]:
                c.moveBy(0, -self.CARD_YOFFSET[0])
",5
"
# register the game
registerGame(GameInfo(257, Numerica, ""Numerica"",
                      GI.GT_NUMERICA | GI.GT_CONTRIB, 1, 0, GI.SL_BALANCED,
",5
"    ""fpugauhhvgawdawf"" +
    ""awhawjjxgdycdyea"" +
    ""ygdyidykjzgaAdaA"" +
    ""faAhaAj"")
",5
"
    def fillStack(self, stack):
        if self.num_dealled == -1 and stack in self.s.rows and not stack.cards:
",5
"        for stack in self.allstacks:
",5
"            deal=None,
        )
",5
"            label = label.replace('&', '')
        return name, label, underline

    def add_cascade(self, cnf={}, **kw):
        self.add('cascade', cnf or kw)
",5
"    else:
        root.option_add('*Entry.background', 'white', 60)
        root.option_add('*Entry.foreground', 'black', 60)
",5
"
    def undo(self, game):
",5
"                                  values=(t2, t3, t4, t5, t6, t7))
            self.parent_window.tree_items.append(id)
            self.parent_window.games[id] = t8

        total, played, won, lost, time_, moves, perc = self.getStatSummary()
",5
"        def delayedRebuild(dt):
            # Clock.schedule_once(self.delayedRebuild, 0.01)
            Clock.schedule_once(self.delayedRebuild, 0.5)
        return delayedRebuild

",5
"    widget='spin',
    label=_('Number of reserves:'),
    var_name='reserves_num',
    )
ReservesMaxAccept = WizSetting(
",5
"                stack.group.tkraise()
        if self.preview <= 1:
            for t in (self.texts.score, self.texts.base_rank,):
",5
"
",5
"
        # set window
        self.size = (XM + maxrows * XS, YM + YS + yextra + h)

",5
"        aspect = (400, 300)[size != 0]
        label.config(aspect=aspect)
",5
"        self.setSize(l.XM+9*l.XS, l.YM+3*l.YS+7*l.YOFFSET+2*l.TEXT_HEIGHT)
",5
"    shade_img = attr.ib(default=None)
",5
"        self.moveMove(1, self.s.talon, to_stack, frames=0)
        for s in self.s.foundations[:4]:
            s.cap.base_rank = c.rank
        for s in self.s.foundations[4:]:
            s.cap.base_rank = (c.rank+1) % 13
",5
"        RK_RowStack, \
",5
"            self.height = 16        # height of symbol
            self.originx = 0
            self.originy = 0
",5
"# ************************************************************************
# * Apophis
# ************************************************************************

",5
"        self.startDealSample()
",5
"        else:
            dirname = os.path.join('images', 'dialog', 'bluecurve')
        for f in ('error', 'info', 'question', 'warning'):
",5
"                return self.id in (1, 2, 13, 14)
",5
"                if r.canFlipCard():
                    self.addHint(self.SCORE_FLIP, 1, r, r)
",5
"

class ZeroFcFreeCell(FreeCell):
",5
"        for r in l.s.rows:
            s.rows.append(
                self.RowStack_Class(r.x, r.y, self, yoffset=l.YOFFSET))
",5
"
class Peek(Osmosis):
    def startGame(self):
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"
",5
"        self.game.updateMenus()
",5
"            v = v + 5 * len(s.cards)
        return v
",5
"    fillTexture(texture, fill, outline, outwidth)
    image = LImage(texture=texture)
    # logging.info(""createImage: LImage create %s"" % image)
    return image

",5
"            self._stopDrag()
",5
"        l.defaultAll()

    #
    # game overrides
    #
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"# ************************************************************************


",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"    #        for Russian Solitaire
    def _getMovePileScore(self, score, color, r, t, pile, rpile):
        s, color = YukonType_Hint._getMovePileScore(
            self, score, color, r, t, pile, rpile)
        bonus = s - score
",5
"                      altnames=(""Scarab"",)))
",5
"            shuffle=0,
            autodeal=0,
            quickplay=0,
            demo=0,
",5
"# * Idle Aces
# ************************************************************************
",5
"
    def __init__(self, x, y, game, suit, **cap):
",5
"        x, y = l.XM, l.YM
        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, ""s"")
",5
"        if (onlyone):
            onlyone.parent.pushWork('AboutDialog', onlyone.window)
            onlyone.running = True
            return

",5
"        for i in range(8):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
            x += l.XS
        x, y = l.XM, self.height-l.YS
",5
"
",5
"        playcards = 10
        w0 = l.XS+(playcards-1)*l.XOFFSET
",5
"                ):
                    self.app.stats.resetStats(player, self.game.id)
                    self.game.updateStatus(stats=self.app.stats.getStats(
",5
"    def _loadExpandedRows(self):
        for path in self._expanded_rows:
            self.treeview.expand_to_path(path)

",5
"        return piles


class Yukon_Hint(YukonType_Hint):
    BONUS_FLIP_CARD = 9000
",5
"
    def createGame(self):
        l, s = Layout(self), self.s
",5
"    BaseRank = ANY_RANK


# ************************************************************************
# * Oonsoo Times Two
",5
"        dialog.set_transient_for(parent)

        self.status = -1
        self.button = -1
",5
"
class NewYork(Dover):
",5
"                'app': PACKAGE,
                'ver': version})
        game_version = 1
",5
"            win.draw_arc(gc, False, x, y+dy, w, h, (s+ewon)*64, elost*64)
",5
"    def anchor_end(self):
",5
"                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))


# ************************************************************************
",5
"            try:
                from random import choice
                im = choice(images)
                f = os.path.join(cardset.dir, cardset.backname)
                self.back_image = loadImage(file=f)
",5
"    ""hodaogooghohaoka"" +
",5
"            w = tkinter.Scale(frame, from_=0, to=128, resolution=1,
",5
"        # We do not accept any cards - pairs will get
        # delivered by _dropPairMove() below.
        return 0
",5
"    DATE = {
",5
"registerGame(GameInfo(486, ImperialGuards, ""Imperial Guards"",
",5
"    def page_up(self, *event):
        return self._yview('scroll', -1, 'page')

    def page_down(self, *event):
",5
"        return True

    getBottomImage = Stack._getTalonBottomImage

",5
"        return 1

    def fillStack(self, stack):
",5
"  GI.SL_MOSTLY_SKILL)
r(12372, MatsuKiriStrict, 'MatsuKiri Strict', GI.GT_HANAFUDA | GI.GT_OPEN, 1,
",5
"    def _getContents(self):
        contents = []
        for obj in self.tree.data.all_objects:
            if self.select_func(obj):
",5
"    #
    # game layout
    #
",5
"        Gaji_RowStack, \
        GreatWall_FoundationStack, \
        GreatWall_RowStack, \
        Hanafuda_SS_FoundationStack, \
",5
"        x += 2*l.XS
",5
"
    #
",5
"            # right blockers
",5
"            s.rows.append(Dikapala_RowStack(x, y, self, max_accept=1))
            x = x + l.XS
        x = self.width - l.XS
",5
"        self.canvas.busy = False
        if DEBUG >= 4:
",5
"    def __init__(self, x, y, game, **cap):
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(None, None, _(""&Cancel""),), default=0,
                      resizable=True,
",5
"        s.talon = self.Talon_Class(x, y, self)
        l.createText(s.talon, 'sw')
",5
"        # define stack-groups
        self.sg.openstacks = s.foundations + s.rows
        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.rows
",5
"            item = c.item
            if not view.can_hide_cards:
                d = self.shrink_face_down
                if c.face_up:
                    x += self.CARD_XOFFSET[ix]
",5
"            kw = kw.copy()
            for k, v in defaults.items():
                if k not in kw:
                    kw[k] = v
        self.__dict__.update(kw)
",5
"        StackWrapper, \
        TalonStack, \
",5
"                card1.color != card2.color)

",5
"    # disable menu items and toolbar
    def disableMenus(self):
        if self.game is None:
",5
"            # that the music order is not random.
",5
"            x += l.XS

        x, y = l.XM+rows*l.XS//2, h-l.YS
",5
"            label = _(""Bookmark %d"") % (i + 1)
            acc = m + ""%d"" % (i + 1)
",5
"
    def _sleepEvent(self, *args):
        return
        print('_sleepEvent', args)
",5
"from pysollib.acard import AbstractCard
from pysollib.kivy.LApp import LImage
from pysollib.kivy.LApp import LImageItem
",5
"
    def getHighlightPilesStacks(self):
        return ()

    shallHighlightMatch = Game._shallHighlightMatch_RK
",5
"
    def createGame(self):
        reserves = 8
        rows = 10
        max_rows = max(8, rows, reserves)
",5
"        # self.steps_sum += step
        # print self.steps_sum, self.norm
",5
"        return self.writeLog(player, header, prev_games)
",5
"            if not agames[n:n + d]:
                break
            m = min(n + d - 1, len(agames) - 1)
",5
"
def _wrap_b1_motion(e):
    return e.type == gdk.MOTION_NOTIFY and (e.state & gdk.BUTTON_PRESS_MASK)

",5
"            ('status', None,
             ltk2gtk('S&tatus...'),  'T',
             None, self.mStatus),
            ('hint', None,
",5
"                node.updateSymbol()
                node.updateText()
        self.selection_key = key
",5
"        pass

    def on_start(self):
",5
"                self.animatedMoveTo(
",5
"    def createGame(self):
        Batsford.createGame(self, max_rounds=2)


# ************************************************************************
",5
"# *
",5
"            self.texts.list[i+2].config(text=str(value))
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"        # set size so that at least 2//3 of a card is visible with 12 cards
        h = CH * 2 // 3 + (playcards - 1) * self.YOFFSET
        h = max(h, 2 * YS)

        # create talon
",5
"    def createGame(self):
        l, s = Layout(self), self.s
        self.setSize(l.XM+10*l.XS, l.YM+2*l.YS+18*l.YOFFSET)

        x, y = l.XM+2*l.XS, l.YM
",5
"
    def saveStatistics(self):
",5
"        'rows_max_move': 'Top card',
        'rows_super_move': 1,
        'deal_face_up': 6,
        },
",5
"

class LTopLine(ButtonBehavior, Label, LBase):

    def __init__(self, **kw):
",5
"        x, y = l.XM, l.YM+2*l.YS
",5
"from . import hanafuda  # noqa: F401
from . import hanafuda1  # noqa: F401
from . import hexadeck  # noqa: F401
",5
"    ""cchcdacgocghchac"" +
    ""kadahdbadeodehdf"" +
    ""adiodihdjaecoech"" +
    ""edaegoeghehaekaf"" +
",5
"        self.bindings = []
        self.bindings.append(self.widget.bind(""<Enter>"", self._enter))
",5
"            x, y = x0 + d[0] * l.XS, y0 + d[1] * l.YS
            s.foundations.append(Windmill_Foundation(x, y, self,
                                 max_cards=7, base_rank=6, mod=13))

",5
"    ""ncsbcshcsncuacuc"" +
    ""cuecugcuicukcumc"" +
    ""wbcwhcwncybcyhcy"" +
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return ((card1.rank + 1 == card2.rank) or
                (card1.rank - 1 == card2.rank))

",5
"        suits = len(self.game.gameinfo.suits) + bool(self.game.gameinfo.trumps)
        foundrows = 1 + (suits > 5)
        frows = decks * suits // foundrows
",5
"    return True

",5
"                      GI.GT_2DECK_TYPE, 2, 3))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
",5
"        if ('size_hint' not in kw):
",5
"    PYRAMID_Y_FACTOR = 2

",5
"        self._bindKey(ctrl, ""g"", self.mRestart)
        self._bindKey("""",   ""space"", self.mDeal)        # undocumented
        self._bindKey(ctrl, ""y"", lambda e: self.mPlayerStats(mode=100))
",5
"
# ************************************************************************
# * Pas de Deux
# ************************************************************************
",5
"from pysollib.ui.tktile.tkutil import makeToplevel, setTransient
",5
"    def __enterEventHandler(self, event):
        if self.game.drag.stack:
",5
"        self.setSize(l.XM + 7*l.XS, l.YM + 5*l.YS)

        # create stacks
",5
"            return EVENT_HANDLED
        if self.game.app.opt.mouse_type == 'drag-n-drop':
",5
"    '''
    '''
",5
"        s.talon = InitialDealTalonStack(w-l.XS, h-l.YS, self)

        # default
",5
"    ""jghjhakahkbokcak"" +
    ""ehkfokgakialchld"" +
    ""vldoleClevlfalgh"" +
    ""lhamahmbomcamehm"" +
",5
"            # self.app.game._cancelDrag()
            # pass
",5
"    #

",5
"        button.pack(side=tkinter.LEFT, fill='y')
        om = tkinter.OptionMenu(
            b_frame, filter_var,
            'NEAREST', 'BILINEAR', 'BICUBIC', 'ANTIALIAS',
            command=show_cardset)
",5
"            percent = ""0.0""
",5
"
    base_init_root_window(root, app)

    # root.self.wm_maxsize(9999, 9999) # unlimited
",5
"    ""haehtehvehdfhlfh"" +
    ""pfhaghsghughwghd"" +
    ""hhlhhphhaihtihvi"" +
    ""hejhljhpjhukhwkh"" +
    ""ykhdmhfmhhmhjmhl"" +
",5
"
        # tv.add_node(LTreeNode(
        #   text='All games ...',
        #   command=self.make_command(102, self.menubar.mPlayerStats)), None)
",5
"        gamenames.sort()
        self.gamenames = gamenames
        self.games_var = self._createGamesVar(frame, row)
",5
"                FCS_VERSION = (int(m.group(1)), int(m.group(2)),
                               int(m.group(3)))
            else:
                FCS_VERSION = (0, 0, 0)
",5
"    def mOptEnableHint(self, *args):
        if self._cancelDrag(break_pause=False):
            return
        self.app.opt.hint = self.tkopt.hint.get()
        self.game.updateMenus()
",5
"    # ------ Methods used internally; some may be overridden

    # --- Formatter interface, taking care of 'savedata' mode;
    # shouldn't need to be overridden

",5
"Copyright (C) 1998 - 2003 Markus F.X.J. Oberhumer.
Copyright (C) 2003 Mt. Hood Playing Card Co.
Copyright (C) 2005 - 2009 Skomoroh.
All Rights Reserved.
",5
"
    def mapEvent(self, *args):
        if not self.tree_items:
",5
"
class Golf(Game):
    Solver_Class = BlackHoleSolverWrapper(preset='golf', base_rank=0,
",5
"            self.s.talon.dealRow(rows=self.s.rows[i:], flip=0, frames=0)
        self.startDealSample()
        self.s.talon.dealRow(reverse=reverse)
        self.s.talon.dealCards()
",5
"
        # Create reserve
        x = l.XM
        y = l.YM + l.YS + l.TEXT_HEIGHT
        s.reserves.append(OpenStack(x, y, self))
",5
"                self.addRadioNode(
                    tv, rg1,
",5
"                stack = RK_RowStack(x, y, self, max_move=1, mod=13)
                s.rows.append(stack)
",5
"class SelectDialogTreeCanvas(MfxTreeInCanvas):
    def __init__(self, dialog, parent, key, default,
",5
"                if in_sequence:
                    if (not r.cards or
                            not self._inSequence(r.cards[-1], suit, RBASE+j)):
",5
"registerGame(GameInfo(50, SimpleSimon, ""Simple Simon"",
                      GI.GT_SPIDER | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"                    self.canvas.before.add(
",5
"# ************************************************************************
# *
# ************************************************************************
",5
"        if color is None:
            if self.expanded:
",5
"                self.clear_widgets([itm])
                self.add_widget(itm)
            else:
",5
"        # hbox
        hbox = gtk.HBox(spacing=5)
        hbox.set_border_width(10)
        hbox.show()
        self.top.table.attach(hbox,
",5
"        self.s.talon.dealRow()
",5
"        self.avrg_moves = moves
        self.percent = perc
        # yield (_(""Total (%d out of %d games)"") % (tgames, len(g)),
        #       won+lost, won, lost, time, moves, perc, '')
",5
"registerGame(GameInfo(616, LaggardLady, ""Laggard Lady"",
",5
"                              self.menubar.mOptNegativeBottom)

",5
"        # load canvas images
        dirname = ""images""
        # for f in (""noredeal"", ""redeal"",):
        for f in (""stopsign"", ""redeal"",):
",5
"    def redealCards3(self, face_up=1):
        for r in self.game.s.rows:
            while len(r.cards) < 3:
                self.dealToStacks([r], frames=4)
                if not self.cards:
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
",5
"        x, y = l.XM, l.YM+l.YS
",5
"        return self._yview('moveto', 1)
",5
"            hint=0,
            autofaceup=0,
            autodrop=0,
",5
"                g0 += g1
                c1 = c
        add_menu(g0, c0, c1)

",5
"                t = t + _("" Ascending"")
",5
"        return image

    def _createButton(self, label, command, check=False, tooltip=None):
",5
"    #

    def createGame(self, rows=9, max_rounds=1, num_deal=1, playcards=16):
        # create layout
",5
"from pysollib.pysoltk import TimeoutsDialog
from pysollib.pysoltk import create_find_card_dialog
from pysollib.pysoltk import create_solver_dialog
from pysollib.settings import DEBUG
",5
"    shallHighlightMatch = Game._shallHighlightMatch_AC

",5
"            if len(pg) == 5:
",5
"                    self.s.talon.dealRow(rows=[stack])
                self.leaveState(old_state)

    shallHighlightMatch = Game._shallHighlightMatch_RK

",5
"        game.loadinfo.talon_round = pload()
",5
"    def endGame(self, restart=0, bookmark=0, holdgame=0):
        if self.preview:
",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"

# ************************************************************************
# * Shamrocks
",5
"        dialog.set_title(title)
        dialog.set_transient_for(parent)
",5
"        submenu = MfxMenu(menu, label=n_(""Set t&heme""))
",5
"gameperfect = boolean
deal = boolean
gamelost = boolean
",5
"
",5
"
# ************************************************************************
# * Triangle
",5
"# register the game

registerGame(GameInfo(307, HeadsAndTails, ""Heads and Tails"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(708, Barrier, ""Barrier"",
",5
"        m = m[:len(m) - 1]
        self.moves.state = self.S_REDO
        for atomic_move in m:
            atomic_move.redo(self)
",5
"            s_by_type,
            s_all_games,
            SelectGameNode(None, _('by Skill Level'), (
                SelectGameNode(None, _('Luck only'),
",5
"
",5
"                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_BALANCED,
                      altnames=('Banner',)))
registerGame(GameInfo(728, ThirtyTwoCards, ""Thirty Two Cards"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_LUCK))
registerGame(GameInfo(731, ThreeFirTrees, ""Three Fir-trees"",
",5
"            'label12',
",5
"            child_iter = model.append(iter)
            model.set(child_iter, 0, _('(no tiles)'), 1, -1)

",5
"# ************************************************************************


class Sanibel(Gypsy):
    Layout_Method = staticmethod(Layout.klondikeLayout)
",5
"
        # create stacks
        if texts:
",5
"
class MfxDialog(_MyDialog):
    img = {}
",5
"        AbstractFlowerGame, \
        FlowerClock_Foundation, \
        FlowerClock_RowStack, \
",5
"                        category=category, skill_level=skill_level,
                        suits=tuple(suits), ranks=tuple(ranks),
                        trumps=tuple(trumps),
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"            self.CARD_XOFFSET.append(int(math.cos(j) * xoffset))
            j = j + .9
",5
"            else:
",5
"        nx = nx - self.style.distx
        ny = ny + self.style.height // 2
        for node in self.rootnodes:
            # update tree
            node.tree = self
",5
"# ************************************************************************
#  *
#  ***********************************************************************/

def r(id, gameclass, name, game_type, decks, redeals, skill_level):
",5
"        AC_RowStack, \
        BasicRowStack, \
        DealRowTalonStack, \
",5
"        self.backButton = tkinter.Button(parent, text=_(""Back""),
",5
"        # create stacks
        x, y = self.width - l.XS, self.height - l.YS
        s.talon = InitialDealTalonStack(x, y, self)

        x, y = l.XM+l.XS, l.YM
",5
"                                foundation_class=self.Foundation_Class,
                                row_class=self.RowStack_Class,
                                reserve_class=OpenStack,
                                **kw
",5
"class AlgerianPatience3(Carthage):
    Foundation_Classes = (SS_FoundationStack,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"                try:
",5
"        #
",5
"
    def cget(self, key):
",5
"        elif s == CSI.TYPE_TAROCK:
",5
"    def setCallback(self, func):
        self.callback = func

    def getSelected(self):
",5
"            to_stack.round = to_stack.round + 1
        self._doMove(from_stack, to_stack, 0)

    def undo(self, game):
        from_stack = game.allstacks[self.from_stack_id]
",5
"        l.defaultStackGroups()

",5
"# ************************************************************************

class Ponytail(Tarock_GameMethods, Braid):

    #
",5
"
# ************************************************************************
# * a simple tooltip
",5
"        if not self.hints and self.level >= 1:
            self.step030(game.s.foundations, game.s.rows, game.sg.dropstacks)

        # 4) try if we can move a card from a RowStack to a ReserveStack
        if not self.hints or self.level == 0:
",5
"
class Spoilt(Game):
    RSTEP, RBASE = 8, 6
",5
"            for i in self.highlight_items:
                i.delete()
        tkinter.Toplevel.destroy(self)
",5
"        # print ""unhide:"", self.id, self.item.coords()
        self.item.config(state=""normal"")
        self.hide_stack = None
        return 1

",5
"            # self.addRadioNode(tv, rg,
            #   'Top',
            #   self.menubar.tkopt.toolbar, 1,
            #   self.menubar.mOptToolbar)
            # self.addRadioNode(tv, rg,
",5
"
        # create stacks
        x, y = w-l.XS, h-l.YS
        s.talon = Toad_TalonStack(x, y, self)
        l.createText(s.talon, ""n"")
",5
"            LTreeNode(
                text=_(""Games""),
                command=self.make_game_command(
                    self.menubar.mSelectGameDialog)))
        rg = tv.add_node(
",5
"
",5
"            if self.card is None:
",5
"                    continue
                s += alpha[i_0*7+(i_n-i_0)] + alpha[x] + alpha[y]
                i_0 = i_n = i
            s += alpha[i_0*7+(i_n-i_0)] + alpha[x] + alpha[y]
",5
"            return (s.num_won+s.num_perfect,
                    s.num_lost,
                    s.time_result.average,
                    s.moves_result.average,)
",5
"    def redealCards2(self):
",5
"    def fillStack(self, stack):
        if stack in self.s.rows[:8] and not stack.cards:
            rows = self.s.rows
",5
"
import logging
import math
import traceback
",5
"                                              suit=ANY_SUIT, base_rank=15))

        # Create reserve
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"    def mSave(self, *args):
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank + card2.rank == 12


",5
"    def initKw(self, kw):
",5
"    # Lokale.
",5
"    def start_h2(self, attrs):
        self.formatter.end_paragraph(1)
        self.formatter.push_font(('h2', 0, 1, 0))

",5
"        #
        row += 1
        self.progress_var = tkinter.BooleanVar()
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# PySol imports
",5
"            self.texts.ncards.config(text='')

",5
"            return False
        if abs(self.id - from_stack.id) != 1:
",5
"            anchor=""center"",
            font=self.app.getFont(""canvas_default""))
        x += l.XS * 2
",5
"
class Tarock_GameMethods:
    SUITS = (_(""Wand""), _(""Sword""), _(""Cup""), _(""Coin""), _(""Trump""))
    RANKS = (_(""Ace""), ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"",
             _(""Page""), _(""Valet""), _(""Queen""), _(""King""))
",5
"
    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(frames=4)
        self.s.talon.dealCards()          # deal first card to WasteStack

",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"            return 0
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"        canvas = self.canvas
        canvas.delete(*self.win_animation.canvas_images)
        self.win_animation.canvas_images = []

",5
"
    #
    # game extras
    #
",5
"            iter = self.store.append(None)
",5
"        for i in range(10):
",5
"
",5
"            self._item = None
            return
        anchor = anchor_tk2gtk(anchor)
",5
"
    def _createPyramid(self, l, x0, y0, size):
        rows = []
",5
"    # logging.info(""fillImage: t=%s, f=%s o=%s, w=%s"" %
    #              (texture, fill, outline, owidth))
",5
"        moves = str(round(moves, 1))
",5
"
",5
"
    getBottomImage = Stack._getReserveBottomImage
",5
"    def createGame(self):
        Klondike.createGame(self, num_deal=3)

    def startGame(self):
",5
"# * Spike
# ************************************************************************
",5
"        WasteTalonStack
from pysollib.util import ACE, ANY_SUIT, KING, UNLIMITED_CARDS

",5
"
    def goForward(self, *event):
        if self.history.index < len(self.history.list):
",5
"        # create stacks
        x, y, = w-l.XS*self.gameinfo.decks*4, l.YM
        for j in range(self.gameinfo.decks):
            for i in range(4):
",5
"            s.rows.append(SS_RowStack(x, y, self))
",5
"        l, s = Layout(self), self.s
        grid = math.sqrt(self.gameinfo.ncards)
        assert grid == int(grid)
        grid = int(grid)

",5
"                                          % (d, f))
                                pass
                        except Exception:
                            # traceback.print_exc()
                            pass
",5
"        x, y = l.XM+l.XS, l.YM
        for i in range(5):
            stack = WasteStack(x, y, self)
            l.createText(stack, 's', text_format='%D')
",5
"

class Phoenix(Klondike):

",5
"        # print 'enterEvent', suit, rank, self.busy
        if self.busy:
            return
        if self.game.demo:
            return
",5
"        dialog.set_position(gtk.WIN_POS_CENTER_ON_PARENT)
        dialog.set_transient_for(parent)
        dialog.resize(500, 340)
",5
"
",5
"registerGame(GameInfo(527, Doorway, ""Doorway"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_BALANCED,
                      altnames=('Solstice',)))
",5
"    ""ameomfamgomhCmha"" +
    ""miomjCmjamkomlam"" +
    ""mhnehngvnghnivni"" +
    ""hnkvnkhnmaodaofo"" +
    ""ofaohoohCohaojoo"" +
",5
"        pixbuf = self.pixbuf.scale_simple(w, h, gdk.INTERP_BILINEAR)
",5
"
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"        if waste:
            x += XS
            self.s.waste = s = S(x, y)
            if texts:
",5
"                    topcards[c.rank] = c
                    cards.remove(c)
        return topcards + cards
",5
"
",5
"        s_game.random = constructRandom('Custom')
",5
"    ""fhnhaoaaocaoeooe"" +
",5
"    # redeal step 3) - redeal cards to stacks
    def redealCards3(self, face_up=1):
        # deal 3 cards to each row, and 1-3 cards to last row
        to_stacks = self.game.s.rows
",5
"#
# ---------------------------------------------------------------------------

import re
",5
"            card = r.getCard()
            if not card or not r.canMoveCards([card]):
",5
"

",5
"                                   padx=padx, pady=pady)
            self._updateAutoScale()
        #
",5
"            ms.save = 1
        if opt.undo:
            if game.canUndo() and game.moves.index > 0:
                ms.undo = 1
",5
"            stack = BasicRowStack(x, y, self, max_move=1, max_accept=0)
            stack.CARD_YOFFSET = l.YOFFSET
",5
"
",5
"# import pychecker.checker
import sys
",5
"            x -= l.XS
",5
"
class NapoleonsTomb(pysollib.game.StartDealRowAndCards, Game):

    #
    # game layout
",5
"    def __init__(self, widget):
",5
"    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"# ************************************************************************
",5
"                                   lambda gi: gi.si.ncards == 32),
                    SelectGameNode(None, _(""48 cards""),
",5
"        l.createText(s.reserves[0], ""se"")

",5
"    def _calcToolkit(self):
        return tkinter

",5
"                    break
                c = self.s.talon.cards[-1]
                t = r
                if c.rank == ACE:
",5
"

# ************************************************************************
# * Interment
",5
"    window.show()


def makeToplevel(parent, title=None, class_=None, gtkclass=gtk.Window):
    window = gtkclass()
",5
"    ""qdaqfoqfoqhvrahr"" +
    ""cvrchrevrehrgvrg"" +
    ""vriosbasdosdasfo"" +
    ""sfoshvtahtcvtcht"" +
    ""evtehtgvtgvtioub"" +
",5
"class Neighbour_Foundation(AbstractFoundationStack):
    def acceptsCards(self, from_stack, cards):
        if not AbstractFoundationStack.acceptsCards(self, from_stack, cards):
            return False
        # We accept any King. Pairs will get delivered by _dropPairMove.
",5
"    ""eacealeateaCeaEe"" +
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"        # move 5's and 6's to top of the Talon (i.e. first cards to be dealt)
        return self._shuffleHookMoveToTop(
            cards,
            lambda c: (c.rank in (4, 5), (c.rank, c.suit)))
",5
"        kw = KwStruct(
            kw,
",5
"        # set window
",5
"    # create a GTK-like path
",5
"            self.s.talon.dealRow(rows=self.s.reserves[:2], frames=0)
        self.s.talon.dealRow(rows=self.s.reserves, frames=0)
",5
"class TowerOfHanoy(Game):
    RowStack_Class = TowerOfHanoy_RowStack
",5
"        #
",5
"# ************************************************************************
# * Win32 winsound audio
# ************************************************************************
",5
"    def __init__(self, parent, pageNames=[], **kw):
        """"""
",5
"    def Deal_Rows(self, i):
        return 16

",5
"                name = ""shadow%02d.%s"" % (i, ext)
                im = self.__loadCard(name, check_w=0, check_h=0)
                self._shadow.append(im)
                if i > 0:  # skip 0
                    name = ""xshadow%02d.%s"" % (i, ext)
",5
"            ('aboutpysol', None,
             ltk2gtk('&About ')+TITLE+'...',
",5
"        if not self.cards:
",5
"                return 0
            c1 = c2
        return 1
",5
"    # The DefaultHint is optimized for Klondike type games
    # and also deals quite ok with other simple variants.
    #
    # But it completely lacks any specific strategy about game
",5
"        for i in range(4):
            s.foundations.append(self.Foundation_Class(x, y, self, suit=i))
            x += lay.XS
        x0, y0, w = lay.XM, lay.YM+lay.YS+2*lay.TEXT_HEIGHT,\
            lay.XS+2*lay.XOFFSET
",5
"registerGame(GameInfo(580, Trapdoor, ""Trapdoor"",
                      GI.GT_GYPSY | GI.GT_ORIGINAL, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(581, Flamenco, ""Flamenco"",
                      GI.GT_GYPSY | GI.GT_ORIGINAL, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(584, Eclipse, ""Eclipse"",
",5
"            if self.preview_app:
                destruct(self.preview_app)
            self.preview_app = None
",5
"# * Intrigue
# * Laggard Lady
# * Glencoe
# ************************************************************************

",5
"
",5
"from pysol_cards.cards import ms_rearrange
from pysol_cards.random import random__int2str

from pysollib.game.dump import pysolDumpGame
from pysollib.gamedb import GI
",5
"                       (0.5, 3),
                       ):
            x, y = x0+xx*l.XS, y0+yy*l.YS
            stack = Hemispheres_RowStack(x, y, self,
",5
"    th = 1                              # thickness
",5
"                frow += 1
        if images:
            try:
                from random import choice
                im = choice(images)
",5
"    GI.GT_TERRACE: ""Terrace"",
    GI.GT_YUKON: ""Yukon"",
    GI.GT_1DECK_TYPE: ""One-Deck game"",
    GI.GT_2DECK_TYPE: ""Two-Deck game"",
    GI.GT_3DECK_TYPE: ""Three-Deck game"",
",5
"            LTreeNode(
                text=_(""Assist""),
                command=self.make_game_command(
                    self.menubar.mAssistMenuDialog)))
        rg = tv.add_node(
",5
"        158,   # Imperial Trumps
        279,   # Kings
",5
"#    ""akhokiakjaklhlfh"" +
#    ""lhhljameamgomgam"" +
",5
"
",5
"        frame = tkinter.Frame(**cnf)
",5
"            self.stats.gameid_balance = 0
            self.game.newGame(random=random, autoplay=0)
            autoplay = 1
        self.nextgame.loadedgame = None
        self.nextgame.bookmark = None
",5
"    ""q"")
r(5240, ""Mini Traditional"", ncards=48, layout=""0aaeacdacfhdeaec"" +
    ""aeeoeeaeghfdvfeh"" +
",5
"            # delete piles descriptions
            return True
        if self.demo:
            self.stopDemo()
",5
"                    if self.s.waste.cards:
                        self.s.waste.moveMove(1, stack)
                self.leaveState(old_state)
",5
"
",5
"            cards, lambda c: (c.rank == ACE, (c.deck, c.suit)))
",5
"        p.dump(self.active_row)

",5
"        other_stack.fillStack()
",5
"                l.createText(stack, 'n')

",5
"
    def register(self, cs):
",5
"        WasteStack, \
        WasteTalonStack
from pysollib.util import ACE, KING, QUEEN

# ************************************************************************
",5
"    RowStack_Class = Yukon_SS_RowStack


class BimBom(AustralianPatience):
    RowStack_Class = Yukon_SS_RowStack
",5
"registerGame(GameInfo(664, SpanishPatienceII, ""Spanish Patience II"",
                      GI.GT_BAKERS_DOZEN | GI.GT_OPEN, 1, 0,
",5
"
    #
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"            self.texts.info = MfxCanvasText(self.canvas, tx, ty,
                                            anchor=ta, font=font)
        x, y = lay.XM, lay.YM + lay.YS + lay.TEXT_HEIGHT
        if round_text:
            y += lay.TEXT_HEIGHT
",5
"        old_state = self.game.enterState(self.game.S_DEAL)
",5
"            CARD_YOFFSET=0,
            SHADOW_XOFFSET=0,
",5
"    RLEN, RSTEP, RBASE = 56, 14, 0
",5
"            canvas.update_idletasks()
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(765, Foothold, ""Foothold"",
",5
"    ""eoeeoAeoCeopiocm"" +
    ""oemoAmoCmocooeoo"" +
    ""AooCovddvBdvdnvB"" +
    ""n"")
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"        games_list[gi.name] = ''
        if gi.name != gi.short_name:
            games_list[gi.short_name] = ''
",5
"        'redeals': 'Unlimited redeals',
        'rows_num': 7,
        'rows_base_card': 'King',
        'reserves_num': 0,
        'deal_type': 'Triangle',
",5
"class FourColours(FreeCell):
    Solver_Class = None
",5
"            s.rows.append(ThreePeaks_RowStack(x, y, self))
            x = x + l.XS
",5
"
    def createGame(self):
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
        self.s.talon.dealCards()
",5
"# ************************************************************************

class Hypotenuse(Gypsy):
    Layout_Method = staticmethod(Layout.klondikeLayout)
",5
"from pysollib.games.bisley import Bisley
from pysollib.layout import Layout
from pysollib.stack import \
        InitialDealTalonStack, \
        SS_FoundationStack, \
",5
"    def __init__(self, **kw):
",5
"    def acceptsCards(self, from_stack, cards):
",5
"                    if ret[0] and ret[1]:
                        top_msg = _(
",5
"<html>
",5
"        else:
            return _('Foundation. Build by same rank.')


",5
"                file.close()
            self.errorDialog(_(""Unable to service request:\n"") + url +
                             ""\n\n"" + str(ex))
            return
        except Exception:
",5
"            if s is None:
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"        x, y, = l.XM, l.YM
        for i in range(8):
            if self.Foundation_Class is RK_FoundationStack:
",5
"    def __init__(self, parent, title, app, player, **kw):
",5
"        if self.face_up:
            self.__image.config(image=self.__back_image)
            self.tkraise(unhide)
            self.face_up = 0
",5
"

done = False


",5
"        selection = treeview.get_selection()
        selection.connect('changed', parent.showSelected)
        treeview.connect('unrealize', self._unrealizeEvent)

",5
"            return 1
        return 0

    def _dropPairMove(self, n, other_stack, frames=-1, shadow=-1):
        if not self.game.demo:
",5
"                               Spider_RK_Foundation,):
            kw['suit'] = ANY_SUIT
        # fix dir and base_rank for Spider foundations
",5
"        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM+13*l.XS, l.YM+3*l.YS+12*l.YOFFSET)
",5
"    ""pmvpoCpqvqaoqchq"" +
    ""eaqghqiaqkhqmoqo"" +
    ""vqqorahrcarehrgo"" +
    ""rihrkarmhroorqhs"" +
    ""aaschseosgvsiosk"" +
",5
"# * canvas items
# ************************************************************************

class MfxCanvasGroup(Group):
    def __init__(self, canvas, tag=None):
",5
"
    def dealCards(self, sound=False):
        num_cards = 0
        if sound and self.game.app.opt.animations:
",5
"

class DutchSolitaire(Windmill):
",5
"    ""aiaciaoiaqiaakac"" +
",5
"        for r in self.game.s.reserves:
            if r.cards:
                r_ranks.append(r.cards[0].rank)
        if not r_ranks:
",5
"# it under the terms of the GNU General Public License as published by
",5
"        # create stacks
        for i in range(7):
",5
"        self._columnspan = columnspan
",5
"        # this stack accepts any one card from the Talon
        return from_stack is self.game.s.talon and len(cards) == 1
",5
"
",5
"from pysollib.mfxutil import kwdefault
from pysollib.mygettext import _
from pysollib.pysoltk import MfxCanvasText
",5
"                       (2, 2.8),
                       (1, 2.6),
",5
"            return
        if not self.app.statusbar:
",5
"# * Miss Milligan
# * Imperial Guards
# ************************************************************************
",5
"        self._startDealNumRowsAndDealRowAndCards(3)

",5
"    #
",5
"    # game overrides
    #

    def startGame(self):
        self.startDealSample()
",5
"                    rid, self.menubar._mSelectGame)
                tv.add_node(
                    LTreeNode(text=gi.name, command=command), rg)
",5
"                rpile = r.cards[:(lr-lp)]   # remaining pile
                if not pile or len(pile) != 1 or len(pile) == len(r.cards):
                    continue
",5
"            #   and has some other re-display annoyances
            # print 'style.font:', style.font
            self.text_id = canvas.create_text(x + 1, y, text=self.text,
                                              anchor=""w"", justify=""left"",
                                              font=style.font,
",5
"
from .tkwidget import MfxScrolledCanvas
",5
"    #

    def deleteAllItems(self):
        logging.info('MfxRoot: deleteAllItems')
        # self.parent.getWork()
",5
"        if not (1 <= category <= 9):
            if game_type == GI.GT_HANAFUDA:
                category = GI.GC_HANAFUDA
",5
"    def _enter(self, *event):
        after_cancel(self.timer)
        after_cancel(self.cancel_timer)
        self.cancel_timer = None
",5
"
from kivy.animation import Animation
from kivy.app import App
from kivy.base import EventLoop
from kivy.base import stopTouchApp
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"        style.paint_option(drawing_area.window, state, shadow,
",5
"                self.opt.colors['table'] = tile.color
                self.opt.tabletile_name = None
",5
"        canvas.create_line(x1, y0, x1, y1, width=3)
        canvas.create_text(x1+4, y1-4, anchor='s', text=_('% won'))

        # caption
        d = self.text_height
",5
"class Well(Game):
    Hint_Class = CautiousDefaultHint
",5
"        funcid = self._register(func, self._substitute, needcleanup)
        cmd = ('%sif {""[%s %s]"" == ""break""} break\n' %
               (add and '+' or '', funcid, ""%x %y""))
        self.tk.call(what + (sequence, cmd))
",5
"            y = l.YM + yy*l.YS
            stack = Clock_RowStack(x, y, self, max_move=0)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"        s.talon = Matriarchy_Talon(x, y, self, max_rounds=VARIABLE_REDEALS)
        l.createText(s.talon, ""n"")
",5
"            if i % columns == 0:
                x, y = 10, y + dy
            else:
                x = x + dx
        canvas.config(scrollregion=(0, 0, sx+dx, sy+dy),
",5
"                        game.busy = False
                        game.endGame()
                        game.newGame()
",5
"
",5
"        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
        self.createBitmaps(top_frame, kw)
        #
",5
"        return self.get_size()[1]

    def configure(self, **kw):
        height, width = -1, -1
        for k, v in kw.items():
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"#!/usr/bin/env python
# -*- mode: python; coding: koi8-r; -*-
",5
"        self.__back.config(image=image)
",5
"registerGame(GameInfo(732, Wave, ""Wave"",
                      GI.GT_2DECK_TYPE | GI.GT_ORIGINAL, 2, 0, GI.SL_BALANCED))
#!/usr/bin/env python
",5
"        lay = VegasKlondike.createGame(self, max_rounds=3)
        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)
",5
"        try:
            img = tkinter.PhotoImage(master=self.parent, file=fn)
        except Exception:
            img = None
        self.images[fn] = img
",5
"class Jane(Klondike):
    Talon_Class = Jane_Talon
    Foundation_Class = StackWrapper(
        SS_FoundationStack, mod=13, base_rank=NO_RANK, min_cards=1)
",5
"        num_cards = 0
        old_state = self.game.enterState(self.game.S_DEAL)
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"        rank = cards[-1].rank
        return self._shuffleHookMoveToBottom(
            cards, lambda c, rank=rank: (c.rank == rank, c.suit))
",5
"def requestStoragePerm():
    ap = AndroidPerms()
    # ap.requestPerms(
    #    [""android.permission.READ_EXTERNAL_STORAGE"",""android.permission.WRITE_EXTERNAL_STORAGE""])
",5
"        self.redo(game)

    def __repr__(self):
        return str(self.__dict__)
",5
"            frames, max_cards = deal(self.s.reserves[:max_cards],
                                     True, frames, max_cards)

        # deal to rows
",5
"            pysollib.settings.FCS_COMMAND = fcs_command
            f = os.path.join('freecell-solver', 'presetrc')
            os.environ['FREECELL_SOLVER_PRESETRC'] = f
    if os.name in ('posix', 'nt'):
",5
"            if a == 'type':
",5
"
# Abstract class.
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(615, BritishBlockade, ""British Blockade"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"    ""hghagivgihgjagkh"" +
",5
"                closest, cdist = stack, dist
        return closest

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        s.foundations.append(SS_FoundationStack(x, y, self, suit=3,
                             base_rank=JACK, mod=13, dir=-1))
",5
"                        # do not move a card that is already in correct place
                        continue
                    base_score = 80000 + (4 - r.cap.base_suit)
                else:
",5
"    def _shuffleHook(self, cards):
        # prepare first cards
",5
"        l, s = Layout(self), self.s
        font = self.app.getFont(""canvas_default"")
",5
"    ""hlbhnbhpbhbdhddh"" +
    ""fdhhdhjdhldhndhp"" +
    ""dhbfhdfhnfhpfhbh"" +
",5
"        url = self.basejoin(url, relpath=relpath)

",5
"                      GI.GT_YUKON | GI.GT_CONTRIB | GI.GT_ORIGINAL, 2, 0,
                      GI.SL_MOSTLY_SKILL))
#!/usr/bin/env python
",5
"        Flower_FoundationStack.__init__(self, x, y, game, suit, **cap)
        self.CARD_YOFFSET = self.game.app.images.CARDH // 20

",5
"    def startGame(self):
",5
"                              _('Show removed tiles (in Mahjongg games)'),
                              self.menubar.tkopt.mahjongg_show_removed,
                              self.menubar.mOptMahjonggShowRemoved)
",5
"            x = x + l.XS

",5
"    style = ttk.Style(top)
    try:
        style.theme_use(theme)
    except Exception:
",5
"    def startGame(self):
",5
"        self.game.saveStateMove(2 | 16)            # for undo
        if old_state == self.game.S_PLAY and to_stack in self.game.s.rows:
            n = self.game.num_dealled
            if n < 0:
",5
"
",5
"                s.foundations.append(
                    SS_FoundationStack(x, y, self, suit=j % 4))
                y += l.YS
            x += l.XS
        x, y = l.XM, self.height-l.YS
",5
"    ""easeaweacfagfakf"" +
    ""aqfaufayfaagaega"" +
    ""igamgaogasgawgaA"" +
    ""gachaghakhaqhauh"" +
",5
"    RowStack_Class = Spider_RowStack
",5
"class StHelena_Talon(TalonStack):

    def canDealCards(self):
        if self.round == self.max_rounds:
",5
"    ('intro.html', 'PySol - Introduction'),
    ('license.html', 'PySol Software License'),
",5
"        return sep

    def _createFlatSeparator(self):
        position = len(self._widgets)
        sep = ToolbarFlatSeparator(self.frame,
",5
"                    name = gi.name
                    node = SelectGameLeaf(self.tree, self, name, key=gi.id)
                    contents.append(node)
",5
"        else:
            if orient == gtk.ORIENTATION_VERTICAL:
                w, h = h, w
            style.paint_box(drawing_area.window, state, shadow,
                            None, drawing_area, ""stepper"", 0, 0, w, h)
",5
"#
",5
"        self.canvas = app.canvas
        self.filename = """"
        self.drag = GameDrag()
",5
"        x, y, = l.XM, h-2*l.YS-3*l.YOFFSET
",5
"                    if m and m.cards:
                        rows.append(r)
        return ((rows, 1),)
",5
"        # set window
        self.setSize(lay.XM + 9*lay.XS + lay.XM, lay.YM + 4*lay.YS)

        # extra settings
        self.base_card = None
",5
"            return
",5
"    if (sequence == '<Unmap>'):
",5
"        l.createText(s.talon, 's')
        x += l.XS
        s.waste = WasteStack(x, y, self)
",5
"            (_(""64 cards""), lambda gi: gi.si.ncards == 64),
            (_(""78 cards""), lambda gi: gi.si.ncards == 78),
            (_(""104 cards""), lambda gi: gi.si.ncards == 104),
            (_(""144 cards""), lambda gi: gi.si.ncards == 144),
",5
"        self._startAndDealRow()


class SimpleSimonII(SimpleSimon):
    Solver_Class = None
",5
"        self.flipMove(self.s.talon)
",5
"        self.parent = parent
        self.progress = PysolProgressBar(
            None, parent, title=""Progress"", color=""#008200"")
        self.progress.pack(ipadx=10, ipady=10)
",5
"    ""debbrbbBbdccbvcc"" +
    ""addcecheckecnebD"" +
    ""ecafbtfbAfdcgdjg"" +
    ""dlgbxgcahchhcnhd"" +
",5
"    ""oeeaegoegCegaeio"" +
",5
"class RedMoon(BlueMoon):
    def _shuffleHook(self, cards):
        # move Aces to top of the Talon (i.e. first cards to be dealt)
",5
"from __future__ import division
",5
"    ""omopdopjaqahqbaq"" +
    ""chqdaqeiqfaqgvqg"" +
",5
"    Hint_Class = Pyramid_Hint
    Foundation_Class = Pyramid_Foundation
",5
"#
# This program is distributed in the hope that it will be useful,
",5
"                       (2.5, 1.5),
                       ):
",5
"                                                      suit=ANY_SUIT))
            x += l.XS
",5
"        #
        self.rootnodes = [_f for _f in (
",5
"

class SanJuanHill(FortyThieves):

    def _shuffleHook(self, cards):
",5
"    #
    # Pause support
    #

    def hideAllItems(self):
",5
"#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
",5
"        from pysollib.kivy.LApp import get_platform
        plat = get_platform()
        if plat == 'android':
            os.environ['HOME'] = '/sdcard'
",5
"                      suits=(0, 0, 0, 0),
                      rules_filename=""spider.html""))
registerGame(GameInfo(270, Spider2Suits, ""Spider (2 suits)"",
                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL,
                      suits=(0, 0, 2, 2),
",5
"            return 0
        if self.app.audio:
            return self.app.audio.playSample(
                name,
",5
"        s.addattr(braidstrong=None)      # register extra stack variable
",5
"                ret = self.app.stats.updateStats(
                    self.app.opt.player, self, status)
",5
"        # we need to override this because the shade may be hiding
        # the tile (from Tk's stacking view)
        return len(self.cards) - 1

",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"class TripleWakeRobin(WakeRobin):
    def createGame(self):
        Trillium.createGame(self, rows=13)

",5
"                ((card1.suit == 4 or card2.suit == 4) or
                 card1.color != card2.color))
",5
"
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    # FIXME
    return None
",5
"        for s in self.s.rows:
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"                isinstance(state, int)):
            game.random.setstate(state)
        # if not hasattr(game.random, ""origin""):
",5
"            self.radius = kw['radius']

        self.fcolor = (0.9, 0.1, 0.3, 0.5)
",5
"
    # font skalierung.

    def scaleFont(self, value):
        self.font_size = int(self.coreFont * value / 550.0)
",5
"        # user overrideable settings
        self.timeout = 800                    # milliseconds
        self.cancel_timeout = 5000
        self.leave_timeout = 400
        self.relief = 'solid'
",5
"class DoubleSamuri(Samuri):
    Rows = 11


# ************************************************************************
",5
"            return False
        if self in self.game.s.rows[4:10]:
            alt_rows = self.game.s.rows[10:]
            color = RED
        else:
",5
"        #
        model.id = id
",5
"        for s in self.s.foundations[4:]:
            s.cap.base_rank = (self.base_rank+1) % 13

    def _loadGameHook(self, p):
",5
"        # create stacks
        x, y = l.XM, l.YM
        for i in range(2):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
",5
"                x = l.XM + j*w
                s.rows.append(self.RowStack_Class(x, y, self))
        y = y + l.YS
",5
"        Klondike.createGame(self, max_rounds=1, waste=0)

",5
"                stack = OpenStack(x, y, self, max_accept=0)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, lay.YOFFSET
                s.reserves.append(stack)
",5
"        self.CARD_YOFFSET = 0
        self.blockmap = []
",5
"# ************************************************************************
# *
# ************************************************************************
",5
"
gc = None

",5
"# ************************************************************************
# * Fascination Fan
",5
"        submenu.add_radiobutton(
            label=n_(""&Drag-and-Drop""), variable=self.tkopt.mouse_type,
",5
"            self.addRadioNode(tv, rg,
                              _('Left'),
                              self.menubar.tkopt.toolbar, 3,
",5
"        if straight:
",5
"        # check the rank
",5
"    Solver_Class = FreeCellSolverWrapper(sbb='rank', esf='kings')


# register the game
registerGame(GameInfo(146, StreetsAndAlleys, ""Streets and Alleys"",
",5
"                            '%(tops)d of playing time.') % {
                                'timerank': ret[0],
                                'tops': TOP_SIZE}
                    elif ret[1]:        # moves
",5
"    # init samples / music
    #

    def initResource(self, manager, dirs, ext_re, Resource_Class):
",5
"
        if update:
            view.updateText()
        self.unshadeStack()
",5
"            # 1b) try if we can move cards to one of the RowStacks
            for pile in self.step010b_getPiles(r):
",5
"        self.__storeMove(am)
",5
"        stack = Clock_RowStack(x, y, self, max_move=1)
        stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"    ret.update(y)
    return ret
",5
"        self._cmp_board(game.calc_layout_string(ren), '''5S AH 4H TD 4S JD JS
3C 8C 4C AC JC AS QS
",5
"
    #
    # Game layout
    #
",5
"        kw = KwStruct(kw,
                      strings=((_(""&Solid color...""), 10),
",5
"            while self.s.talon.cards:
                frames, max_cards = deal(self.s.rows, True, frames, max_cards)
",5
"        self.s.talon.dealRow(rows=self.s.rows[7:])


class Morehead(Somerset):
    RowStack_Class = StackWrapper(BO_RowStack, max_move=1)
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"#                  else:
#                      print gi.id
            if hasattr(gi.gameclass, 'Solver_Class') and \
               gi.gameclass.Solver_Class is not None:
                self.__games_for_solver.append(gi.id)
",5
"        dialog.destroy()

",5
"                    return nc
            return None                 # try another way

        new_cards = create_solvable(cards, [None]*len(cards))
",5
"        InvisibleStack, \
        ReserveStack, \
        SS_FoundationStack, \
        Stack, \
",5
"class ImperialTrumps(AbstractTarockGame):

",5
"            '<span foreground=""blue"" underline=""single"">%s</span>' % kw['url'])

        event_box = gtk.EventBox()
        box.pack_start(event_box)
",5
"gdk = gtk.gdk

# ************************************************************************
# * canvas items
# *
",5
"                    c = di[0]
                    sub_pile = pile[di[3]+1:]
                    # print ""trying drop move"", c, pile, sub_pile
                    # assert r.canMoveCards(sub_pile)
                    if not r.canMoveCards(sub_pile):
",5
"        if self.app.opt.mahjongg_create_solvable == 1:
            # easy
",5
"        if not rows:
            # deal to the waste
            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(535, ExiledKings, ""Exiled Kings"",
                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"    def page_up(self, *event):
        return self._yview('scroll', -1, 'page')

    def page_down(self, *event):
",5
"from tkwidget import MfxDialog
",5
"                self.addHint(score, ncards, r, t, color)
                if score >= 90000 and self.level >= 1:
",5
"                 (self._shallHighlightMatch_SS,
                  self._shallHighlightMatch_SSW)),
",5
"        return MfxDialog.initKw(self, kw)

    def updateGraph(self, *args):
        interval = self.variable.get()
        canvas = self.canvas
",5
"    # Do not destroy game structure (like stacks and cards) here !
    def reset(self, restart=0):
        self.filename = """"
        self.demo = None
        self.solver = None
",5
"# * Fan
# ************************************************************************
",5
"                 None, None,
                 lambda w, o=opt_name, u=update_game: self.mOptToggle(w, o, u),
",5
"        config = CardsetConfig()
        if not self._parseCardsetConfig(config, lines):
            # print filename, 'invalid config'
",5
"        self.cframe = tkinter.Frame(self.frame, relief='sunken', bd=1,
                                    takefocus=0)
        self.canvas = tkinter.Canvas(self.cframe, width=width, height=height,
                                     takefocus=0, bd=0, highlightthickness=0)
        self.scale = self.canvas.create_rectangle(-10, -10, 0, height,
",5
"
        # print('LImage: touch_down on %s' % str(touch.pos))
        if self.collide_point(*touch.pos):
",5
"    # free game
    def freeGame(self):
",5
"        g.append(gg)
        if g[0]:
            s_by_type = SelectGameNode(None, _(""French games""),
                                       tuple(g[0]), expanded=1)
        if g[1]:
",5
"class BasicStatusbar:
    def __init__(self, top, row, column, columnspan):
        self.top = top
",5
"        if self.list_box.curselection():
            self.font_family = self.list_box.get(self.list_box.curselection())
        self.font_weight = self.weight_var.get() and 'bold' or 'normal'
        self.font_slant = self.slant_var.get() and 'italic' or 'roman'
        self.font_size = self.size_var.get()
",5
"    def createGame(self, rows=7):
        # create layout
        l, s = Layout(self), self.s
        l.yukonLayout(rows=rows, texts=0, playcards=25)
        self.setSize(l.size[0], l.size[1])
",5
"# ************************************************************************
# *
# ************************************************************************

",5
"
",5
"                      ranks=(0, 5, 6, 7, 8, 9, 10, 11, 12),
                      rules_filename=""pileon.html""))
registerGame(GameInfo(554, Foursome, ""Foursome"",
",5
"            # (_('Number of cards:'), str(cardset.ncards)),
            (_('Size:'), '%d x %d' % (cardset.CARDW, cardset.CARDH)),
                ):
",5
"    def acceptsCards(self, from_stack, cards):
        if self.game.getState() == 0:
",5
"            return self.dealCards(sound=sound)
",5
"            text=_('Save'), command=self.menubar.mSaveAs))

",5
"# * Desert Island
",5
"
# ************************************************************************
# * Montana
# ************************************************************************

",5
"                      GI.GT_NUMERICA | GI.GT_ORIGINAL, 2, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(623, PrincessPatience, ""Princess Patience"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"                   reserve_class=None,
                   **kw
",5
"        # create stacks
",5
"        l.defaultStackGroups()

    #
    # Game over rides
    #
",5
"    ""obycayfhygayhoyh"" +
    ""hyiayjbymozcvzho"" +
    ""zmaAbhAcvAcaAdhA"" +
    ""eaAfcAhCAhaAjhAk"" +
    ""aAlhAmvAmaAnoBcC"" +
",5
"        Hanafuda_SequenceStack, \
        MatsuKiri_Foundation, \
",5
"        layout=""0daadacdaedagdai"" +
",5
"            variable=self.tkopt.negative_bottom,
",5
"            self.s.talon.dealRow(rows=[self.s.braidweak])
        self.s.talon.dealRow()
        # deal base_card to foundations, update cap.base_rank
        self.base_card = self.s.talon.getCard()
",5
"            return (s1, s2)
        return ()

    # handle shade within a drag operation
",5
"
class Interchange(FortyThieves):

    RowStack_Class = StackWrapper(SS_RowStack, base_rank=KING)
",5
"            # move all cards to talon
            num_cards = self._redeal(rows=rows, frames=4)
            if shuffle:
                # shuffle
",5
"    #

    DEFAULTEXTENSION = "".pso""
    # TRANSLATORS: Usually, 'PySol files'
    FILETYPES = ((_(""%s files"") % TITLE, ""*"" + DEFAULTEXTENSION),
",5
"            stack.CARD_YOFFSET = 0
            x += w0
        x, y = lay.XM, lay.YM+3*lay.YS
        for i in range(5):
            stack = self.RowStack_Class(x, y, self, max_move=1)
",5
"from pysollib.ui.tktile.tkcanvas import MfxCanvasImage
from pysollib.ui.tktile.tkutil import loadImage
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"

# ************************************************************************
#  * Pagoda
",5
"    RowStack_Class = KingAC_RowStack

    def createGame(self):
        Gypsy.createGame(self, rows=10)

",5
"        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == ACE, (c.deck, c.suit)))
",5
"
",5
"class SC_FoundationStack(SS_FoundationStack):
    def __init__(self, x, y, game, suit, **cap):
        kwdefault(cap, base_suit=suit)
        SS_FoundationStack.__init__(self, x, y, game, ANY_SUIT, **cap)
",5
"    def clickHandler(self, event):
        if self._dropKingClickHandler(event):
",5
"            command=self.mSelectGameById, accelerator=m+""M"")
        menu.add_separator()
        submenu = MfxMenu(menu, label=n_(""Fa&vorite games""))
        menu.add_command(label=n_(""A&dd to favorites""), command=self.mAddFavor)
        menu.add_command(
",5
"                stack = SS_RowStack(x, y, self, max_move=1)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, 0
                s.rows.append(stack)
                x += l.XS
",5
"
",5
"

# ************************************************************************
# * Pas Seul
",5
"    def destroy(self):
        pass

",5
"    def startGame(self):
        self._startAndDealRow()
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"                self.s.waste.moveMove(1, stack)
            self.leaveState(old_state)

",5
"            else:
                suit = int(i//2)
            s.foundations.append(self.Foundation_Class(x, y, self,
                                 suit=suit, max_move=0))
            x += l.XS
",5
"    def updateGamesMenu(self, menu, games):
        menu.delete(0, 'last')
        if len(games) == 0:
            menu.add_radiobutton(label=_('<none>'), name=None,
                                 state='disabled')
",5
"            if c.suit != r.id // 13 or c.rank != r.id % 13:
                return False
        return True
",5
"            x = x + l.XS

        # define stack-groups
        l.defaultStackGroups()

",5
"            self.statusbar.pop(0)
        return False
",5
"        x0 -= (width-cw)/2
        y0 -= (height-ch)/2
",5
"            return cards[0].rank == 11 or self.cap.base_rank == ANY_RANK
        return self.isSuitSequence([stackcards[-1], cards[0]])

",5
"    ""upawpaoqaqqhbihD"" +
    ""iCphCpj"")
r(5048, ""Inner Circle"", layout=""0aaaacaayaaAaaac"" +
",5
"registerGame(GameInfo(144, Maze, ""Maze"",
                      GI.GT_MONTANA | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
",5
"        self.vbar_show = False
        self.createCanvas(kw)
        # self.frame.grid_rowconfigure(0, weight=1)
        # self.frame.grid_columnconfigure(0, weight=1)
",5
"            x += l.XS
        x, y = l.XM+2.75*l.XS, l.YM+3*l.YS
",5
"
        x, y = l.XM, self.height-l.YS
",5
"        frame = ttk.LabelFrame(self, text=_('All games'),
                               padding=(10, 5, 10, 10))
        frame.pack(side='top', expand=True, fill='x', padx=10, pady=10)
",5
"    ""aafcafehfjhflvfl"" +
    ""hfnhgchgeaghagjo"" +
    ""gkaglCglogmagnah"" +
    ""bohcahdoheahfhhi"" +
    ""hhkvhlhhmhibhidv"" +
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"        side = self.menubar.tkopt.toolbar.get()
        self.win.setTool(None, side)
        return False

",5
"        self.write('\n')
",5
"        self._width, self._height = width, height
        self.set_size_request(width, height)
        # self.set_size(width, height)
",5
"        self.texts.info.config(text=t)

",5
"
class LTopLevel0(BoxLayout, LBase):
",5
"from pysollib.hint import Yukon_Hint
from pysollib.layout import Layout
",5
"            except Exception:
                traceback.print_exc()
",5
"        if pc and nc:
",5
"

",5
"# ************************************************************************
",5
"

def reset_wizard(game):
    for w in WizardWidgets:
        if isinstance(w, six.string_types):
",5
"                         ipadx=padx, ipady=pady, sticky='nws')
        # Info
        self.info_labels = {}
        for n, t, f, row in (
",5
"    def updateSettings(self):
        if self.audiodev is None or not self.app:
            return
        s, m = 0, 0
",5
"    if (sequence == '<KeyPress-Right>'):
        return
",5
"        vsb = ttk.Scrollbar(frame)
        vsb.grid(row=0, column=1, sticky='ns')
        self.tree = ttk.Treeview(frame, columns=self.COLUMNS,
                                 selectmode='browse')
        self.tree.grid(row=0, column=0, sticky='nsew')
",5
"#
",5
"        #      drag.event = event
        #  else:
        #      # update now
        #      self.keepDrag(event)
",5
"            return True
        if self.game.s.talon.cards:
            if from_stack in self.game.s.rows[4:]:
                i = list(self.game.s.foundations).index(self)
",5
"        x, y = l.XM, l.YM
        for i in range(10):
            s.rows.append(self.RowStack_Class(x, y, self, dir=1))
",5
"    Hint_Class = FreeCellType_Hint
    Solver_Class = FreeCellSolverWrapper(sbb='rank')

",5
"    def hide(self):
        if not self.visible:
",5
"
    def mPlayNextMusic(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"                    continue
                if t is r:
",5
"class Alaska_RowStack(Yukon_SS_RowStack):
    def _isSequence(self, c1, c2):
        return (c1.suit == c2.suit and
                ((c1.rank + self.cap.dir) % self.cap.mod == c2.rank or
                 (c2.rank + self.cap.dir) % self.cap.mod == c1.rank))
",5
"        # 2)See if we can move a card to the tableaux
        if not self.hints:
            for r in game.sg.dropstacks:
                pile = r.getPile()
                if not pile or len(pile) != 1:
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"        #         Gay gordons, Helsinki,
",5
"        # focus = self.tree.frame
        self.mainloop(focus, kw.timeout)

    def initKw(self, kw):
",5
"            s.cap.base_rank = self.base_card.rank
        n = self.base_card.suit * self.gameinfo.decks
        if self.s.foundations[n].cards:
",5
"# it under the terms of the GNU General Public License as published by
",5
"
import math
",5
"#    ""ojhpfhphhpjaqeaq"" +
#    ""goqgaqioqiaqkhrf"" +
#    ""hrhhrjasdasfosga"" +
",5
"            command=self.mUndo, accelerator=""Z"")
        menu.add_command(
            label=n_(""&Redo""),
",5
"# ************************************************************************
",5
"        self.timeout = 800                    # milliseconds
        self.cancel_timeout = 5000
        self.leave_timeout = 400
",5
"
",5
"class Matrix6(Matrix3):
",5
"
",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            s.foundations.append(SS_FoundationStack(x+4*lay.XS, y, self,
",5
"
        tv.add_node(LTreeNode(
            text=_('Demo'), command=self.menubar.mDemo))

",5
"
    def moveMove(self, ncards, to_stack, frames=-1, shadow=-1):
        if to_stack is not self.game.s.foundations[0]:
            self._dropPairMove(ncards, to_stack, frames=-1, shadow=shadow)
",5
"
    #
    # Mahjongg special overrides
    #

",5
"        s.talon = self.Talon_Class(x, y, self, max_rounds=max_rounds)
",5
"    #
    # game overrides
    #

",5
"    elif TOOLKIT == ""wx"":
        t = ""wxPython""
    elif TOOLKIT == ""kivy"":
        t = ""kivy""
",5
"                fd.write(""        '%s': %i,\n"" % (w.var_name, v))
",5
"        x += 3.5*l.XS
",5
"            return
",5
"        if 'fg' in kw:
            kw['foreground'] = kw['fg']
            del kw['fg']
        label = getattr(self, name + '_label')
        label.config(**kw)
",5
"            # rightclickHandler
",5
"        else:
            if sx0 > 0:
                # left to right
                x2 += sx0
",5
"            for j in range(i+1):
",5
"        else:
            self.values = self.values_map
        self.var_name = var_name
",5
"
    def updateText(self):
        decks = self.gameinfo.decks
",5
"                s.foundations.append(
                    Queue_Foundation(
                        x + l.XS * (9.5 - j * 2),
",5
"r(5041, ""Glade"", layout=""0aaaacaaCaaEaaac"" +
    ""accaCcaEcahdejdc"" +
    ""ldcndbpdcrdctdev"" +
    ""daxddhfcjfblfbnf"" +
",5
"    ""amebmgbmiamkbogo"" +
    ""ohboicqfcqhcqjas"" +
    ""ejsfasgjshasijsj"" +
    ""askCtgCtibuddufd"" +
    ""uhdujbulovdCvgCv"" +
",5
"    def tkraise(self, positions=None):
        # print 'tkraise', positions
        if positions is None:
            self._item.raise_to_top()
            self._item.get_property('parent').raise_to_top()
",5
"    registerGame(gi)
    return gi
",5
"
",5
"        self.sg.openstacks = s.tableaux + s.rows + s.reserves
        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.tableaux + s.rows

",5
"# ************************************************************************
# * Bastille Day
# ************************************************************************

class BastilleDay_BastilleStack(Stack):
",5
"class MatsuKiri(AbstractFlowerGame):
",5
"        # os.path.join(app.dn.config, ""screenshots""),
",5
"    def updateGameStat(self, player, game, status):
        #
        if player not in self.games_stats:
            self.games_stats[player] = {}
        if game.id not in self.games_stats[player]:
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"    #

    def mOptTheme(self, *event):
        theme = self.tkopt.theme.get()
",5
"        self.setSize(l.XM + 7*l.XS, l.YM + 4*l.YS)

",5
"                if c.suit == 3 and c.deck == 0:
",5
"    def getDemoInfoText(self):
        return ""Der letzte\nMonarch""

",5
"            if self.app.setTile(i):
",5
"

",5
"        with open(os.path.join(dir, filename), 'r', encoding='utf-8') as file:
            print(file.read(), file=outfile)
        print(_fmt(rules_footer, {'footer': footer}), file=outfile)
",5
"    def resizeImages(self):
        # resizing images and cards
",5
"                    Dikapala_TableauStack(
                        x, y, self, i - 1, TABLEAU_YOFFSET))
                x = x + l.XS
            x = x + l.XM
",5
"            self.bindings.append(
                label.bind('<ButtonPress>', self._buttonPressEvent))
",5
"
",5
"        for i in range(12):  # deal to Bastille
            self.s.talon.dealRow(flip=0, rows=[self.s.reserves[0]], frames=0)
        for i in range(9):
            self.s.talon.dealRow(rows=[self.s.reserves[-1]], frames=0)
        for i in range(3):
",5
"
",5
"        cim.lower()
        #
",5
"
    def canDealCards(self):
        if self.game.base_rank is None:
            return False
        if self.round == self.max_rounds:
",5
"class SevenDevils_RowStack(AC_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not AC_RowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        for i in range(3):
            j, k = (i+1) % 3, (i+2) % 3
            if ((r_ranks[i]+1) % 13 == r_ranks[j] and
                    (r_ranks[j]+1) % 13 == r_ranks[k]):
",5
"            all_games_stat = self.games_stats[player]['all']
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"                            game.flipMove(r)
",5
"
class RawPrawn(AustralianPatience):
",5
"                          ('small',          _('Small: ')),
",5
"    RowStack_Class = UnionSquare_RowStack
",5
"            # self.text = '[size='+fs+'][b]'+self.title+'[/b][/size]'
            # self.text = 'o '+self.title
",5
"    def deleteAllItems(self):
        self._text_items = []
",5
"            if self.level <= 1 and len(rpile) == 0:
                return True
            return False
",5
"            s.rows.append(
                Journey_ReserveStack(x + l.XS * (1 + decks), y, self))
            y = y + l.YS
",5
"        # create layout
",5
"                        Rectangle(texture=texture, pos=tpos, size=tsize))

    def setBackgroundImage(self, event=None):

",5
"        if (c1.rank + dir) % mod != c2.rank or c1.suit != c2.suit:
",5
"
",5
"    print('<h2>Categories</h2>')
",5
"        if self._updateMaxRounds():
            self.updateText()
        if not self.cards and not self.game.s.waste.cards:
            return False
",5
"#
# ---------------------------------------------------------------------------##

from pysollib.game import Game
",5
"

# ************************************************************************
# * Der freie Napoleon (completely equivalent to Der kleine Napoleon,
",5
"        y = int(int(self.canvas.cget('height'))*(self.canvas.yview()[0]))
        w, h = self.canvas.winfo_width(), self.canvas.winfo_height()

        color = self.app.opt.colors['not_matching']
",5
"        self._tooltips = []
        for w in self._widgets:
",5
"
",5
"        if random is not None:
            if ((random.__class__ is not self.random.__class__) or
                    random.initial_seed != self.random.initial_seed):
                f |= 16
        return f
",5
"        cnf['text'] = _('Game number')
        label = ttk.Label(**cnf)
        label.grid(row=0, column=2, sticky='ew')
        cnf['text'] = _('Started at')
        label = ttk.Label(**cnf)
",5
"        x2, y2 = x2 + dx, y2 + dy
        if ncards == 1:
            x1 += cw // 2
            y1 += ch // 2
",5
"from pysollib.help import help_about
from pysollib.hint import DefaultHint
",5
"        timediff = time.time() - MfxTooltip.last_leave_time
        if timediff < self.leave_timeout / 1000.:
            self._showTip()
        else:
            self.timer = after(self.widget, self.timeout, self._showTip)
",5
"        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)


",5
"    ""ebyfbymayohzobAc"" +
    ""aAobBjbCdoCebCfo"" +
    ""CgbCh"")
",5
"    startGame = RedMoon.startGame


",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"            text=_('Quit'), command=self.menubar.mHoldAndQuit))

# ************************************************************************


",5
"    def _saveGameHook(self, p):
",5
"
",5
"# Copyright (C) 2016-2017 LB
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))

        x, y = l.XM+rows*l.XS//2, l.YM
        s.reserves.append(Backbone_BraidStack(x, y, self, max_accept=0))
",5
"            i = i + 1
",5
"
class FileStatsFormatter(PysolStatsFormatter):

    def __init__(self, app, file):
        self.app = app
",5
"
class Statistics:
    def __init__(self):
",5
"        y = l.YM+l.YS
",5
"
    def _fillOne(self):
        for r in self.s.rows:
            for s in self.s.foundations:
                if s.acceptsCards(r, r.cards[-1:]):
",5
"
        x, y = l.XM+3*l.XS, l.YM+4*l.YS
        for i in range(4):
            s.reserves.append(OpenStack(x, y, self))
",5
"        x += l.XS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 's')
",5
"                      bitmap_padx=10, bitmap_pady=20,
                      image=None, image_side=""left"",
                      image_padx=10, image_pady=20,
",5
"        top = []
        ranks = []
        for c in cards[:]:
            if c.rank in range(8) and c.rank not in ranks:
                ranks.append(c.rank)
",5
"
    def createGame(self):
        Fan.createGame(self, playcards=8)
    shallHighlightMatch = Game._shallHighlightMatch_RK
",5
"    #
    # Game layout
    #

",5
"class GreatWheel_Foundation(PictureGallery_Foundation):
    def acceptsCards(self, from_stack, cards):
",5
"        if self.game.app.opt.dragcursor:
            self.canvas.config(cursor='')
        drag = self.game.drag.copy()
",5
"
    _resizeHandlerID = None

    def _resizeHandler(self):
",5
"# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"
class Flourish(WaveMotion):
    RowStack_Class = AC_RowStack
",5
"        else:
            l.createText(s.talon, 'n')
        anchor = 'nn'
",5
"
    def wm_minsize(self, w, h):
        pass
",5
"        stretch = self._stretch_bg_image
        save_aspect = self._save_aspect_bg_image
        if Image:
",5
"            s.cap.base_rank = self.base_card.rank
",5
"    ""awnaEnadoafoaooa"" +
    ""qoazoaBoheahpahA"" +
    ""ahcdhedhgdhndhpd"" +
    ""hrdhydhAdhCdhdhh"" +
",5
"

class Numerica2Decks(Numerica):
",5
"    except:
        pass
    '''
",5
"
",5
"                      iters_step=iters_step)
",5
"# This program is distributed in the hope that it will be useful,
",5
"    TreeDataHolder_Class = SelectCardsetTree
    TreeData_Class = SelectCardsetData

",5
"# ************************************************************************

class BusyCards_FreeCell(ReserveStack):
",5
"        # 1) check Tableau piles
        self.step010(game.sg.dropstacks, game.s.rows)

        # 2) try if we can move part of a pile within the RowStacks
",5
"        # FIXME
        pass

    def _setPauseMenu(self, v):
",5
"
    def anchor_bgn(self, href, name, type):
        """"""This method is called at the start of an anchor region.

",5
"                s.foundations.append(SS_FoundationStack(x, y, self,
                                     suit=j*2+i//2, base_rank=KING, dir=-1))
                x += l.XS

        s.reserves.append(ReserveStack(l.XM, l.YM, self))
",5
"        min_cards = max(len(self.s.rows), 8)
        max_rows = s['deal_face_down'] + s['deal_face_up'] \
            + s['deal_to_reserves']
",5
"        if self.s.foundations:
            ncards = 0
            for stack in self.s.foundations:
                ncards += stack.cap.max_cards
            if ncards != self.gameinfo.ncards:
",5
"                      GI.GT_GYPSY, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"        if self.app.opt.animations:
            self.preview_app.opt.animations = 10
        else:
            self.preview_app.opt.animations = 0
",5
"            return
        self.fail(""No exception thrown."")

    def test_throw_error_on_missing_cards(self):
",5
"            'fixed',
            'canvas_default',
            'canvas_fixed',
            'canvas_large',
            'canvas_small',
",5
"        self.setSize(w, h)

        # create stacks
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"    def collapseChildren(self, deep=False):

        def cc(p, n):
            for c in n.nodes:
                if c.is_open:
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self))
",5
"        if not idir:
            idir = self.app.dn.savegames
        d = tkinter_tkfiledialog.Open()
",5
"        self.frame.pack(**kw)

    def grid(self, **kw):
        self.frame.grid(**kw)

",5
"            s.reserves.append(ReserveStack(x, y, self))
            x = x + l.XS
        x, y = l.XM + (maxrows - rows) * l.XS // 2, l.YM + l.YS
        self.setRegion(s.reserves, (-999, -999, 999999, y - l.YM // 2))
",5
"        self.stats._reset_statistics()

    def __storeMove(self, am):
        if self.S_DEAL <= self.moves.state <= self.S_PLAY:
            self.moves.current.append(am)
",5
"registerGame(GameInfo(149, Diplomat, ""Diplomat"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(151, LadyPalk, ""Lady Palk"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
",5
"        sep.bind(""<1>"", self.clickHandler)
        sep.bind(""<3>"", self.rightclickHandler)
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"        oldcur = self.canvas[""cursor""]
        self.canvas[""cursor""] = ""watch""
        self.canvas.update_idletasks()
        self.clear()
",5
"                RK_FoundationStack(
                    x, y, self,
                    # suit=ANY_SUIT,
                    base_rank=KING, dir=-1, max_move=0))
            k += 1
",5
"
    def startGame(self):
        self._startDealNumRows(6)
        self.s.talon.dealRowAvail()

",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        # check that the base card is correct
",5
"                text = _(""\nGame finished\n"")
                if DEBUG:
",5
"
        self.workStack = LStack()
",5
"            #         if c.isHidden():
            #             assert c.hide_stack is not None
            #         else:
",5
"
        # neuen Dialog aufbauen.

        window = LTopLevel(parent, title)
",5
"                                   lambda gi: gi.si.ncards == 64),
                    SelectGameNode(None, _(""78 cards""),
                                   lambda gi: gi.si.ncards == 78),
",5
"        self.preview.unbind_all()
        MfxDialog.destroy(self)
",5
"    Foundation_Class = SS_FoundationStack
",5
"        if rg:
            self.addRadioNode(tv, rg,
",5
"        for i in range(2):
            self.s.talon.dealRow(flip=0, frames=0)
",5
"
",5
"
    def createGame(self, max_rounds=-1, num_deal=1, **layout):
",5
"    #

    def startGame(self):
",5
"            for i in range(6):
",5
"                      GI.GT_TERRACE, 2, 0, GI.SL_BALANCED))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
",5
"# ************************************************************************
",5
"                label = gi.short_name
            else:
",5
"                if not openURL(url):
                    self.errorDialog(_('''%(app)s HTML limitation:
The %(protocol)s protocol is not supported yet.
",5
"    def clickHandler(self, event):
        if self.cards and not self.cards[-1].face_up:
            return self.game.dealCards(sound=True)
        return OpenStack.clickHandler(self, event)
",5
"

# register the game
registerGame(GameInfo(7, PictureGallery, ""Picture Gallery"",
",5
"# * Tam O'Shanter
# ************************************************************************

class TamOShanter(Game):
",5
"    ""vkhwghwjawnawpbx"" +
    ""daxjoxkayfaymayo"" +
    ""aCdaCiaEiaFe"")
",5
"        return len(self.s.talon.cards) == 0 and len(self.s.waste.cards) == 0

    def getAutoStacks(self, event=None):
",5
"import os

from pysollib.mfxutil import Image, ImageTk
from pysollib.mygettext import _, n_
from pysollib.settings import TITLE
",5
"        self.formatter.pop_margin()
",5
"    values_map=(0, 20),
    default=1,
",5
"    def createGame(self):
",5
"        l.klondikeLayout(rows=rows, waste=0, playcards=25)
        self.setSize(l.size[0], l.size[1])
        s.talon = WaveTalon(l.s.talon.x, l.s.talon.y, self)
",5
"    ""oagoaooaqoayoaAo"" +
    ""aCoaEoaaqacqaeqa"" +
    ""gqaoqaqqayqaAqaC"" +
",5
"# ************************************************************************
# * Heads and Tails
",5
"
        # Create talon
        s.talon = InitialDealTalonStack(
            self.width - l.XS, self.height - l.YS, self)

",5
"            widget.grid(row=row, column=1)
            row += 1
        #
",5
"        y1 += ch
        xx0, yy0 = x0, y0
        w, h = x1-x0, y1-y0
        #
        if TOOLKIT == 'gtk' or not Image:
",5
"
# ************************************************************************
# * Phoenix
# * Arizona
# ************************************************************************
",5
"            CSI.TYPE_MUGHAL_GANJIFA: (""Mughal Ganjifa"", """"),
            # CSI.TYPE_NAVAGRAHA_GANJIFA: (""Navagraha Ganjifa"", """"),
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(556, Junction, ""Junction"",
                      GI.GT_FORTY_THIEVES, 4, 0, GI.SL_MOSTLY_SKILL,
                      ranks=(0, 6, 7, 8, 9, 10, 11, 12)))
",5
"def help_html(app, document, dir_, top=None):
    global help_html_viewer, help_html_index
    if not document:
        return None
",5
"class BlindPatience_RowStack(AC_RowStack):
    def acceptsCards(self, from_stack, cards):
        if self.cards and not self.cards[-1].face_up:
            return True
        return AC_RowStack.acceptsCards(self, from_stack, cards)
",5
"    def delete_deferred(self, seconds):
        # self.canvas.canvas.ask_update()
        # print ('MfxCanvasRectangle: delete_deferred(%s)' % seconds)
        Clock.schedule_once(
",5
"                     ('Type:', type),
                     ('Flags:', '\n'.join(flags)),
                     ('Skill level:', skill_level),
",5
"                 (card2.rank + 1) % 13 == card1.rank))

    def _shallHighlightMatch_SC(self, stack1, card1, stack2, card2):
",5
"    ""jawkowkcyihAgaAh"" +
    ""iAiaAjhAkaBfaBlh"" +
    ""CeiCihCmaDdoDdoD"" +
    ""faDhvDhCDiaDjvDj"" +
",5
"        self.startDealSample()
",5
"                return
            # print dx, dy
        # get destination stack
        if self.game.app.opt.mouse_type == 'point-n-click':
",5
"    def labeltoname(self, label):
        name = re.sub(r""[^0-9a-zA-Z]"", """", label).lower()
        label = _(label)
        underline = label.find('&')
",5
"        button_relief = TkSettings.toolbar_button_relief
",5
"    ROW_MAX_MOVE = UNLIMITED_MOVES
    DEAL = (0, 1)

    def createGame(self):
        FortyThieves.createGame(self, rows=6)
",5
"            strings=(_(""&OK""), (_(""&Full log...""), 103),
                     (_(""&Save to file""), 204)),
            default=0,)
        return FullLog_StatsDialog.initKw(self, kw)
",5
"        # games = map(self.app.gdb.get,
        #   self.app.gdb.getGamesIdSortedByShortName())
        games = list(map(
            self.app.gdb.get, self.app.gdb.getGamesIdSortedByName()))
",5
"        self.foundations = [
",5
"
    def destroy(self):
        self.tree.updateNodesWithTree(self.tree.rootnodes, None)
",5
"# This layouts converted from Kyodai Mahjongg game
# http://www.kyodai.com/index.en.html
# http://files.cyna.net/layouts.zip
",5
"# it under the terms of the GNU General Public License as published by
",5
"        font_name = (fa['family'],
                     fa['size'],
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()

    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"    def startGame(self):
        self.startDealSample()
        i = 0
        while self.s.talon.cards:
",5
"        # self.connect('destroy', self.destroyEvent)

",5
"        if from_stack is self.game.s.braid or from_stack in self.game.s.rows:
            return False
        return ReserveStack.acceptsCards(self, from_stack, cards)
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:21], flip=0)
        self.s.talon.dealRow(rows=self.s.rows[21:])
        self.s.talon.dealCards()          # deal first card to WasteStack
",5
"
class DoubleBlueMoon(DoubleMontana, BlueMoon):
    Talon_Class = StackWrapper(Montana_Talon, max_rounds=3)
",5
"
",5
"            dx = l.XOFFSET
            dy = -l.YOFFSET
            d_x = cs.SHADOW_XOFFSET
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"

class Midshipman(Indian):
    DEAL = (2, 2)
",5
"        l.createText(s.foundations[0], 'nw')

",5
"        # create stacks
        s.addattr(tableaux=[])     # register extra stack variable
        x = l.XM + 8 * l.XS + l.XS // 2
",5
"        x = l.XM
        s.talon = WasteTalonStack(x, y, self, num_deal=1, max_rounds=-1)
        l.createText(s.talon, ""s"")
        x = x + l.XS
        s.waste = WasteStack(x, y, self)
",5
"        gi_si.update(si)
        #
        Struct.__init__(self, id=id, gameclass=gameclass,
                        name=name, short_name=short_name,
",5
"#
# ---------------------------------------------------------------------------##
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return 0


# ************************************************************************
",5
"
    Hint_Class = Spider_Hint
",5
"        for p in self.path:
            if all(os.path.isfile(os.path.join(p, fn)) for fn in filenames):
                self.dir = p
                break
",5
"        aspect = (400, 300)[self.getSize() != 0]
        position = len(self._widgets)
",5
"            command=self.mHelp, accelerator=m+""F1"")
        menu.add_command(
            label=n_(""&How to play""),
",5
"                min_size = h/10
                shrink_dx = 0
                shrink_dy = (h-min_size) / (frames-1)
            else:
",5
"# * Unlimited
",5
"                self._highlighted_images[card] = shade
        if not shade:
            # we have not PIL
            return self.getShade()
        return shade
",5
"            c += 13
",5
"# ************************************************************************
# *
# ************************************************************************

",5
"
",5
"    return window.content

",5
"    def page_down(self, *event):
        return self._yview('scroll', 1, 'page')

    def unit_up(self, *event):
        return self._yview('scroll', -1, 'unit')
",5
"        #              % (sequence, widget, func, add))
        widget.bindings[sequence] = func
    else:
        # logging.info('tkutil: bind failed %s %s' % (sequence, widget))
        pass
",5
"        self.reset()
",5
"            s.rows.append(stack)

        # Reserves
        x, y = l.XM, l.YM+1.5*l.YS
        for i in range(3):
",5
"            else:
",5
"        x += lay.XS
        s.waste = WasteStack(x, y, self)
        lay.createText(s.waste, 'n')

        lay.defaultStackGroups()
",5
"# * toolbar
# ************************************************************************

class PysolToolbar(PysolToolbarTk):
",5
"            LTreeNode(
                text=_(""Tools""),
                command=self.make_game_command(self.menubar.mEditMenuDialog)))
        rg = tv.add_node(
            LTreeNode(
",5
"                      anchor=""nw"", font=tfont, fill=fg)
        x = tx[1] - 16
        c.create_text(x, ty[0] - dy, text=""%d"" %
                      won, anchor=""ne"", font=tfont, fill=fg)
        c.create_text(x, ty[1] - dy, text=""%d"" %
",5
"                       (x - l.CW // 2, -999, 999999, y), priority=1)
        x, y = self.width-3*l.XS//2, self.height-l.YS
        s.talon = InitialDealTalonStack(x, y, self)
",5
"        piles = []
        while p:
            piles.append(p)
            p = p[1:]       # note: we need a fresh shallow copy
",5
"    Foundation_Classes = [SS_FoundationStack, SS_FoundationStack]
",5
"        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

        self.demo_sleep_var = tkinter.DoubleVar()
        self.demo_sleep_var.set(app.opt.timeouts['demo'])
",5
"            self.s.talon.dealRow(rows=self.s.rows[i:], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[6:])
",5
"        l.createText(s.waste, ""s"")

        # Define stack-groups
        l.defaultStackGroups()

",5
"                    self.game.quitGame(gameid)
            elif mode == 402:
                # start a new game with a gameid / gamenumber
                # TODO
",5
"            self.__addBack(im, name)
",5
"    pass
#!/usr/bin/env python
",5
"
    def fillStack(self, stack):
        if not stack.cards and stack is self.s.waste:
",5
"        (n_(""Memory type""), lambda gi, gt=GT_MEMORY: gi.si.game_type == gt),
        (n_(""Poker type""), lambda gi, gt=GT_POKER_TYPE: gi.si.game_type == gt),
        (n_(""Puzzle type""),
            lambda gi, gt=GT_PUZZLE_TYPE: gi.si.game_type == gt),
",5
"        self.max_iters_var = tkinter.IntVar()
        self.max_iters_var.set(self.app.opt.solver_max_iterations)
        self._calcToolkit().Label(
            frame, text=_('Max iterations:'), anchor='w').grid(
",5
"        self.loadinfo.addattr(draw_done=p.load())

    def _saveGameHook(self, p):
",5
"                                 max_move=0, base_rank=KING, dir=-1))
            x += l.XS
        x, y, = l.XM+(8-reserves)*l.XS//2, y+l.YS
",5
"        self.s.talon.dealRow()
        # deal one card to foundation
        self.s.talon.dealRow(rows=self.s.foundations[:1])
        # deal cards to WasteStack
",5
"# ************************************************************************
# * Applegate
",5
"            for j in range(i+1):
",5
"            return
        self.game.setCursor(cursor=CURSOR_WATCH)
        after_idle(self.top, self.__restoreCursor)
        EditMenuDialog(self, self.top, title=_(""Tools""), app=self.app)
",5
"            if name is None or not list(filter(
                    select_func, self.all_games_gi)):
                continue
",5
"
    # --- Horizontal Rule

    def do_hr(self, attrs):
",5
"
        # define stack-groups
        l.defaultStackGroups()

",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"    CFBundleVersion='%s' % VERSION,
    CFBundleShortVersionString='%s' % VERSION,
    NSHumanReadableCopyright=""Copyright (C) 1998-2003 Markus F.X.J. Oberhumer"",
",5
"            r = r % 13
            r = RANKS[r]
            t = '%s (%d)' % (r, n)
        f.texts.misc.config(text=t)
",5
"                            return 1
            # b) drop cards
            if autodrop and dropstacks:
                for s in dropstacks:
                    to_stack, ncards = s.canDropCards(self.s.foundations)
",5
"                    cards[i], cards[j] = cards[j], cards[i]
                    break
                j = j + n
        cards.reverse()
        return cards
",5
"                break
            m = min(n+d-1, len(games)-1)
            n1, n2 = games[n].name, games[m].name
            label = n1[:3]+' - '+n2[:3]
",5
"    Foundation_Class = AC_FoundationStack
    Solver_Class = None
",5
"
    def defaultText(self, layout_stack):
        if self.canvas.preview > 1:
            return None
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"
    # toolbar
    w, h = 16, 16
    w, h = 24, 24

",5
"class SlyFox_Foundation(SS_FoundationStack):
",5
"    Hint_Class = CautiousDefaultHint

    def createGame(self):

",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            x += l.XS
",5
"# * Double Drawbridge
# ************************************************************************

",5
"                t = t + _("" Ascending"")
            elif dir == 11:
                t = t + _("" Descending"")
        self.texts.info.config(text=t)
",5
"def setTransient(window, parent, relx=None, rely=None, expose=1):
    # Make an existing toplevel window transient for a parent.
    #
    # The window must exist but should not yet have been placed; in
    # other words, this should be called after creating all the
",5
"from pysollib.settings import VERSION_TUPLE

",5
"                column, text=text,
                command=lambda par=self.parent_window, col=column:
",5
"
    def _createTop(self):
        for n in ('top_10_time_treeview',
                  'top_10_moves_treeview',
                  'top_10_total_moves_treeview'):
",5
"                return False
",5
"            idir, ifile = """", """"
        if not idir:
            idir = self.app.dn.savegames
",5
"        else:
",5
"            self.game.s.talon.playMoveMove(1, self)
            return 1
        return ReserveStack.clickHandler(self, event)

    rightclickHandler = clickHandler
",5
"
    #
    # menu actions
    #
",5
"
",5
"
        # self.addCheckNode(tv, None,
        #   'Demo logo',
        #   self.menubar.tkopt.demo_logo,
        #   self.menubar.mOptDemoLogo)
",5
"        if seconds > 0:
",5
"        return cmp(self.state, other.state)


# ************************************************************************
# * Shuffle all cards of a stack. Saves the seed. Does not flip any cards.
",5
"        l.defaultStackGroups()

",5
"        self.s.talon.dealCards()

    def fillStack(self, stack):
        if not stack.cards and stack is self.s.waste:
            if self.canDealCards():
",5
"    # init tiles
    #
    def _init_tiles_process_dir(self, dirname, found, t):
        """"""docstring for _init_tiles_process_die""""""
",5
"        game.updateStackMove(game.s.talon, 1 | 16)            # for redo
        game.leaveState(old_state)
",5
"

def getStoragePerm():
    ap = AndroidPerms()
    return ap.getPerms(
",5
"    def destroy(self):
        after_cancel(self.timer)
        unbind_destroy(self.top)
        try:
",5
"        self.foundations = [
            pysollib.stack.SS_FoundationStack(0, 0, self, s) for s in range(4)]
        self.rows = [pysollib.stack.AC_RowStack(0, 0, self) for s in range(8)]
        self.reserves = [
",5
"a solvable configuration.'''),
                                 bitmap='warning')
",5
"        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
        for r in l.s.foundations:
            s.foundations.append(
                self.Foundation_Class(r.x, r.y, self, suit=r.suit))
",5
"                self.s.foundations.append(S(x+i*XS, y, suit=suit))
            y += YS

        # create talon and waste
        x, y = x + (decks-1)*XS, h - YS
",5
"# ************************************************************************
# * Dial
# ************************************************************************

",5
"class BasicRowStack(OpenStack):
    def __init__(self, x, y, game, **cap):
        kwdefault(cap, dir=-1, base_rank=ANY_RANK)
        OpenStack.__init__(self, x, y, game, **cap)
        self.CARD_YOFFSET = game.app.images.CARD_YOFFSET
",5
"        FreeCell.createGame(self, rows=7)
        suit = 0
        for r in self.s.reserves:
",5
"                self.flipMove(stack)
",5
"                ((BO_RowStack, SuperMoveBO_RowStack),
",5
"        if to_stack.cards:
",5
"                      GI.GT_KLONDIKE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(51, Steps, ""Steps"",
",5
"        # super(MfxCanvas, self).__init__(**kw)
        super(MfxCanvas, self).__init__()
",5
"#      if not _wrap_handlers.has_key(seq):
#          _wrap_handlers[seq] = lambda e, key=c: _wrap_key_press(e, key)
#  import pprint; pprint.pprint(_wrap_handlers)
",5
"            self.s.talon.dealRow(frames=4)

    def _autoDeal(self, sound=True):
        # don't deal a card to the waste if the waste is empty
        return 0
",5
"    autoplay_moves = attr.ib(default=0)         # number of moves
    quickplay_moves = attr.ib(default=0)        # number of quickplay moves
    goto_bookmark_moves = attr.ib(default=0)    # number of goto bookmark
    shuffle_moves = attr.ib(default=0)          # number of shuffles (Mahjongg)
    # did this game already update the demo stats ?
",5
"#    ""ofaohoohaojoojao"" +
#    ""loolaonaophpchpe"" +
",5
"        if self.compound == 'text':
            return 0
        size = self.size
",5
"        for i in (2, 3, 4, 5):
            x = l.XM+(1.5+i)*l.XS
            s.foundations.append(SS_FoundationStack(x, y, self, suit=suit))
            suit += 1
        y += l.YS
",5
"#  Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
#  Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"                cond = ((c.rank == ACE and c.color == RED) or
                        (c.rank == KING and c.color == BLACK))
",5
"        except Exception:
",5
"
",5
"                category = GI.GC_NAVAGRAHA_GANJIFA
",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"            (0.0, 0.0), (self.border, self.border))
        border = brd[1]

        self.canvas.clear()
        with self.canvas:
",5
"    ""gcaicbocaqcdscdw"" +
    ""caycbAcdudbaeace"" +
",5
"

# ************************************************************************
",5
"                color = ""red""
            else:
                color = ""pink""
",5
"            command=self.mRedo, accelerator=""R"")
",5
"class SimonJester(Spider):
",5
"        if not RK_RowStack.acceptsCards(self, from_stack, cards):
            return False
        if not self.cards:
            return (from_stack is self.game.s.talon or
",5
"                            self, rows=[s],
                            frames=frames, sound=sound)
                        n += 1
",5
"    for i in games_by_type_list:
        print('<li>%s (%s games)</li>' % i)
    print('</ul>')
    return
",5
"
class EiffelTower(pysollib.game.StartDealRowAndCards, Game):
",5
"    ""oaiaoiaaicoicaie"" +
    ""oieaigoigaiioiia"" +
    ""ikoikaimoimaiooi"" +
",5
"        c = self.s.talon.getCard()
",5
"        for i in range(8):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
            x += l.XS
",5
"
class BusyAces(FortyThieves):
    DEAL = (0, 1)

",5
"
    def getHelp(self):
        if self.cap.dir > 0:
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED,
                      altnames=(""The Four Continents"",)))
registerGame(GameInfo(697, BigBen, ""Big Ben"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(737, Clock, ""Clock"",
",5
"    getBottomImage = Stack._getReserveBottomImage

",5
"
        # 3)See if we can move a card from the tableaux
        #    to a row stack. This can only happen if there are
        #    no more cards to deal.
",5
"        return self.canSaveGame()

    def canUndo(self):
",5
"        lx, ly, nx, ny = MfxTreeBaseNode.draw(self, x, y, ilastx, ilasty)
        if self.expanded:
            style = self.tree.style
            childx = nx + style.distx + style.width // 2
            childy = ny
",5
"                ((card1.rank + dir) % mod == card2.rank or
",5
"            self.mahjongg_create_solvable = 1  # 0 - none, 1 - easy, 2 - hard
        self.shisen_show_hint = True
        self.shisen_show_matching = False
        self.animations = 3             # default to Medium
        self.redeal_animation = True
",5
"            self.game.nextRoundMove(self)
            if sound:
",5
"                      '%s' % class_name, 2)

    def initBindings(self):
        # note: a Game is only allowed to bind self.canvas and not to self.top
        # bind(self.canvas, ""<Double-1>"", self.undoHandler)
",5
"    def getQuickPlayScore(self, ncards, from_stack, to_stack):
        return int(to_stack in self.s.rows)

",5
"    ""bdhbfhbhhbjhblhb"" +
    ""nhbpacaoccoceocg"" +
",5
"            if self.app.opt.auto_scale:
",5
"    SELECT_SPECIAL_GAME_BY_TYPE = (
        (n_(""Shisen-Sho""), lambda gi, gt=GT_SHISEN_SHO: gi.si.game_type == gt),
        (n_(""Hex A Deck type""),
            lambda gi, gt=GT_HEXADECK: gi.si.game_type == gt),
        (n_(""Matrix type""), lambda gi, gt=GT_MATRIX: gi.si.game_type == gt),
",5
"            self.tree_items = []
        self.formatter.writeStats(player, sort_by=self.sort_by)
",5
"            yy = -999
        self.setRegion(self.s.rows, (-999, yy, 999999, y - YS // 2))
        if waste:
            x = w - 2*XS
            self.s.waste = s = S(x, y)
",5
"# ************************************************************************

class RelaxedKatrinasGame(KatrinasGame):
    Reserve_Class = LarasGame_Reserve
    Reserve_Cards = 2
",5
"        w, h = l.XM+10*l.XS, l.XM+2*l.XS+15*l.YOFFSET
        self.setSize(w, h)
",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 'n')

        l.defaultStackGroups()

",5
"# import pychecker.checker

",5
"        self.game.finishMove()
        self.game.checkForWin()
        return 1
",5
"    pass

",5
"            assert self.max_rounds == n + 1

",5
"    def startGame(self):
        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
",5
"
        # Create foundation
        x, y = w // 2 - l.CW // 2, h - l.YS
        s.foundations.append(AppachansWaterfall_Foundation(x, y, self, -1))
",5
"        kwdefault(cap, base_suit=0, mod=12, max_cards=120, max_move=0)
        AbstractFoundationStack.__init__(self, x, y, game, suit, **cap)

",5
"# * Gloria
# ************************************************************************

class Gloria(Game):
",5
"registerGame(GameInfo(549, Wheatsheaf, ""Wheatsheaf"",
",5
"                                            anchor=ta, font=font)

        x, y = w-rows*l.XS, l.YM+l.YS
",5
"
# ************************************************************************
",5
"class SiebenBisAs_Hint(CautiousDefaultHint):
    def computeHints(self):
        game = self.game
        freerows = [s for s in game.s.rows if not s.cards]
        # for each stack
",5
"    def createGame(self, **layout):
        Matsya.createGame(self, max_rounds=-1, num_deal=3)


# ************************************************************************
",5
"#
",5
"            opt_cfg=os.path.join(self.dn.config, ""options.cfg""),
            stats=os.path.join(self.dn.config, ""statistics.dat""),
",5
"    ""ighkgohdojdoldoh"" +
    ""fojfolfohhojholh"" +
    ""oBkoFloAnvievkev"" +
    ""igvkgvBlvFmCjdCh"" +
",5
"    def __init__(self, parent, title, app, manager, key=None, **kw):
        kw = self.initKw(kw)
",5
"        return ''

    # def getBaseCard(self):
    #    return self._getBaseCard()
",5
"        if c and c[0] == cs.ident:
            # print 'load from cache', c
            self.images, self.subsampled_images = c[1], c[2]
            self.updateCardset(id, update=update)
",5
"    ""ekaemacoabqaasaa"" +
    ""acccceeceoccqcas"" +
    ""caaecceeeeeoecqe"" +
    ""aseaagccgeegeogc"" +
    ""qgasgaaiccieeieo"" +
",5
"                                  max_rounds=max_rounds, num_deal=num_deal)
        l.createText(s.talon, ""sw"")
        y = y + l.YS
        s.waste = WasteStack(x, y, self)
",5
"
    def fillStack(self, stack):
        old_state = self.enterState(self.S_FILL)
        if stack in self.s.rows and not stack.cards:
            if not self.s.waste.cards:
",5
"DATA_DIRS = []
# you can add your extra directories here
if os.name == 'posix':
    DATA_DIRS = [
        '/usr/share/PySolFC',
",5
"                self.dialog.mDone(self.default)
        elif isinstance(node, self._calc_MfxTreeNode()):
",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s
        Layout.bakersDozenLayout(l, rows=13)
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_SSW


",5
"        s.foundations.append(FourByFour_Foundation(x, y, self,
",5
"                        break
",5
"    RowStack_Class = Paganini_RowStack
",5
"        h = l.YM + 5*l.YS
        self.setSize(w, h)
",5
"        frame.columnconfigure(0, weight=1)
        frame.columnconfigure(1, weight=1)
        #
        row = 0
",5
"    def handle_image(self, src, alt, *args):
        """"""This method is called to handle images.

        The default implementation simply passes the alt value to the
        handle_data() method.
",5
"                result = m.group(1)
                break

        self.dialog.setText(iter=iter_, depth=depth, states=states)
        self.solver_state = result.lower()
",5
"            top_frame, text=_('Progress'))
",5
"
# ************************************************************************
# * Robert
# * Wasatch
# ************************************************************************
",5
"        w, h = x1-x0, y1-y0
        if (w, h) in self._pil_shadow:
",5
"
    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"            for i in range(len(r.cards)):
                num_cards = num_cards + 1
                self.game.moveMove(1, r, self, frames=0)
        assert len(self.cards) == num_cards
",5
"        Klondike.createGame(self, rows=8, max_rounds=1, waste=0, playcards=20)


",5
"
# ************************************************************************
# * Blue Moon
",5
"                else:
",5
"    # game extras
    #

",5
"        self._startDealNumRowsAndDealRowAndCards(5)
",5
"
# ************************************************************************
",5
"class GreatWheel_RowStack(BasicRowStack):
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        x += l.XS
        for i in range(4):
            s.foundations.append(Rittenhouse_Foundation(x, y, self,
",5
"        self.setMenuState(ms.find_card, ""assist.findcard"")
        self.setMenuState(ms.demo, ""assist.demo"")
        self.setMenuState(ms.demo, ""assist.demoallgames"")
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"
from pysollib.mygettext import _
from pysollib.settings import TITLE
from pysollib.ui.tktile.tkcanvas import MfxCanvas, MfxCanvasGroup
from pysollib.ui.tktile.tkcanvas import MfxCanvasImage, MfxCanvasRectangle
",5
"        queen_stack.cap.base_rank = QUEEN

",5
"        # define stack-groups
        l.defaultStackGroups()

",5
"        return 0
",5
"
",5
"                    continue
                if self.nextgame.holdgame:
                    assert self.nextgame.id <= 0
",5
"                cards.remove(c)
",5
"            # images.destruct()
            destruct(images)
",5
"        if stack is self.hide_stack:
            return
        self.item.hide()
",5
"
",5
"
",5
"        else:
            self.progress.pack(expand=True, fill='x')
        self.frame.pack(expand=True, fill='both')
",5
"    def startGame(self):
        self.s.talon.dealRow(frames=0)
",5
"#    ""sjisl"")
# r(5062, ""Naoki Haga Traditional"", layout=""0acaaeaagaaiaaka"" +
#    ""amaaoaaqaasaauaa"" +
#    ""waayadgcaicakcdm"" +
#    ""caocaqcascaucaee"" +
",5
"    Reserve_Cards = 2
",5
"            if s.cards:
                return RK_RowStack.canDropCards(self, stacks)
        return (None, 0)
",5
"    def getGamesIdSortedByName(self):
        if self.__games_by_name is None:
",5
"                                 suit=r.suit, base_rank=3))

        # Create row stacks
        for r in l.s.rows:
",5
"
        # define stack-groups
",5
"    ""hhbhkbhnbhqbjdbj"" +
    ""gbjjbjmbjpbmcbme"" +
    ""bmgbmibmkbmmbmoc"" +
",5
"        SelectDialogTreeData.__init__(self)
        self.all_games_gi = list(map(
            app.gdb.get,
",5
"                        self.addHint(score, 1, r, t)
                        break

        # 3)See if we can move a card from the tableaux
",5
"             variable=self.tkopt.statusbar,
",5
"    def controlclickHandler(self, event):
        # highlight matching cards
        if self.game.app.opt.highlight_cards:
",5
"
def init_root_window(root, app):
    base_init_root_window(root, app)
    if TOOLKIT == 'tk':
        hideTkConsole(root)
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[39:])

    def isGameWon(self):
",5
"        # bottom
",5
"        self.setSize(w, h)

        # Create row stacks
",5
"@attr.s
class GameTexts(NewStruct):
    info = attr.ib(default=None)
    help = attr.ib(default=None)
",5
"    def getBottomImage(self):
        return self.game.app.images.getSuitBottom(self.cap.suit)


class MatsuKiri_Foundation(Flower_FoundationStack):
",5
"from pysollib.stack import \
        AC_RowStack, \
",5
"        l.createText(s.talon, ""s"")
        x = x + l.XS
",5
"            language=StringVar(),
",5
"
def make_help_toplevel(app, title=None):
",5
"            if h >= 2*l.YS:
                ta = ""e""
                t.move(0, -l.YS)
",5
"        decks = self.gameinfo.decks
        h = max(5 * l.YS + 35, 2*l.YM + 2*l.YS +
                (self.BRAID_CARDS - 1) * l.YOFFSET*self.BRAID_OFFSET)
        self.setSize(l.XM + l.XS * (7 + decks * 2), l.YM + h)

",5
"            #    item.config(fill=self._text_color)
",5
"            y = y + th
        x, y = l.XM, y + l.YM
        for i in range(10):
",5
"    def playMoveMove(self, ncards, to_stack, frames=-1, shadow=-1, sound=True):
        if sound:
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"        # optimisation
        sn = hash(sn)
        return sn
",5
"                                       for i in cardset.si.nationalities])
        if cardset.year:
            year = str(cardset.year)
        row = 0
",5
"
    #
    # Yukon layout
    #  - left: rows
",5
"            holdgame=os.path.join(self.dn.config, ""holdgame.dat""),
            comments=os.path.join(self.dn.config, ""comments.dat""),
        )
",5
"
class Osmosis_Foundation(AbstractFoundationStack):
",5
"    ROW_MAX_MOVE = 1
    FILL_EMPTY_ROWS = 1

",5
"
",5
"    #
    # menu actions
",5
"
Please use your standard web browser
",5
"#    ""cgecieakeameaoea"" +
#    ""qeasecueaweacgae"" +
#    ""gcggcigakgcmgaog"" +
#    ""aqgasgcugawgayga"" +
#    ""ahaAhaciaeicgiai"" +
",5
"                    SelectGameNode(None, _(""48 cards""),
                                   lambda gi: gi.si.ncards == 48),
                    SelectGameNode(None, _(""52 cards""),
                                   lambda gi: gi.si.ncards == 52),
                    SelectGameNode(None, _(""64 cards""),
",5
"        self.canvas.xview_moveto(-dx)
",5
"        for i in range(8):
            s.foundations.append(DieRussische_Foundation(x, y, self,
                                 suit=i % 4, max_cards=8))
            x += l.XS
",5
"            to_stack = self.s.foundations[c.suit * self.gameinfo.decks]
            self.flipMove(self.s.talon)
            self.moveMove(1, self.s.talon, to_stack, frames=0)
",5
"    def _wait(self, s):
        # sometime time or time.wait is None (threading)
",5
"    def updateProgress(self):
        if self.progress:
            self.progress.update(step=1)

    #
",5
"
    def getDemoInfoTextAttr(self, tinfo):
        return tinfo[1]     # ""se"" corner


",5
"        game.leaveState(old_state)
",5
"# ************************************************************************

class DoubleBisley(Bisley):
",5
"        InvisibleStack, \
",5
"    if k in __mfx_bindings:
        __mfx_bindings[k].append((sequence, funcid))
    else:
        __mfx_bindings[k] = [(sequence, funcid)]

",5
"# ************************************************************************

class SelectTileLeaf(SelectDialogTreeLeaf):
    pass

",5
"
",5
"        w1 = (_(""Highlight piles: "") + str(stats.highlight_piles) + ""\n"" +
              _(""Highlight cards: "") + str(stats.highlight_cards) + ""\n"" +
              _(""Highlight same rank: "") +
",5
"
",5
"            nodes.append(
                SelectCardsetNode(
",5
"    ""akcamcaocaqcasca"" +
    ""eeageaieakeameao"" +
    ""eaqeaseaueadgafg"" +
    ""ahgajgalgangapga"" +
    ""rgatgavgaeiagiai"" +
",5
"
    # for closeStack
",5
"# ************************************************************************

",5
"                i += 1
",5
"                self.game.playSample(""move"", priority=10)
        self.singleCardMove(index, to_stack, frames=frames, shadow=shadow)
",5
"        after_cancel(self.cancel_timer)
        self.cancel_timer = None
        if time.time() - MfxTooltip.last_leave_time < self.leave_timeout/1000.:
",5
"    #

    def _shuffleHook(self, cards):
        # move Ace to bottom of the Talon (i.e. last cards to be dealt)
        return self._shuffleHookMoveToBottom(
",5
"        # bind(group, ""<B1-Motion>"", self.__motionEventHandler)
",5
"        self.preview_key = key
",5
"        from pysollib.tk.progressbar import *  # noqa: F401,F403
        from pysollib.tk.menubar import *  # noqa: F401,F403
        from pysollib.tk.selectcardset import *  # noqa: F401,F403
        from pysollib.tk.selecttree import *  # noqa: F401,F403
",5
"class Pegged6x6(Pegged):
",5
"                   texts=False):
        # create layout
        l, s = Layout(self), self.s
",5
"4D JS AD 6S JH JC JD
KH 3H KS AS TC 5D AC
TD 7C 9C 7H 3C 3S
",5
"        elif max_len > 6:
            button_width = max_len+2
        else:
            button_width = 8
        # print 'button_width =', button_width
",5
"        store.set(iter, 0, root_label, 1, -1)
        for index, name in cardsets:
",5
"
class UnionSquare_Foundation(AbstractFoundationStack):
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        if topmenu:
            master.setMenu(self.menu)

# ************************************************************************
# * - create menubar
",5
"    def reset(self):
        self.play_button.config(state='disabled')

    def startSolving(self):
        from pysollib.mygettext import ungettext
",5
"    GAME_VERSION = 2
    RowStack_Class = Yukon_AC_RowStack
    Hint_Class = YukonType_Hint

    def getHighlightPilesStacks(self):
",5
"        if sound:
            game.startDealSample()
        # shuffle
        game.shuffleStackMove(self)
        # redeal
",5
"        if from_stack is self or not self.cards or len(cards) != 1:
            return False
        c = self.cards[-1]
        return (c.face_up and cards[0].face_up and
",5
"        frame.columnconfigure(sep_column, weight=1)
        return focus

",5
"    def _shuffleHook(self, cards):
",5
"                    redo = 1
        # add current move to history (which is a list of lists)
        if redo:
            # print ""detected redo:"", current
",5
"        # yy = self.yy
    '''
    if 'source' in kw:
        logging.info (""makeImage: "" + kw[""source""])
    if 'texture' in kw:
",5
"                      GI.GT_1DECK_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(753, Flourish, ""Flourish"",
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"    # move cards to the Foundations during dealing
    def startGame(self):
        frames = 4
",5
"from pysoltree import PysolTreeView

from tkcanvas import MfxCanvas

from tkutil import unbind_destroy
",5
"    def highlightMatchingCards(self, event):
        i = self._findCard(event)
        if i < 0:
            return 0
",5
"
",5
"    def winfo_height(self):
",5
"from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
",5
"            suit += 1

",5
"    shallHighlightMatch = Game._shallHighlightMatch_RK
    getQuickPlayScore = Game._getSpiderQuickPlayScore


# register the game
",5
"# * Dialog
",5
"# ************************************************************************
# * Forty and Eight
",5
"        ctrl = ""Control-""
",5
"
        # Create talon
        s.talon = self.Talon_Class(
            l.s.talon.x, l.s.talon.y, self,
            max_rounds=max_rounds, num_deal=num_deal)
",5
"# ************************************************************************
# * Storehouse (aka Straight Up)
# ************************************************************************


",5
"            s.foundations.append(Braid_Foundation(x, y, self, suit=i))
            x += l.XS
        tx, ty, ta, tf = l.getTextAttr(s.foundations[-1], ""se"")
",5
"                if ti.is_open:
                    lastopen = ti
",5
"class Jungle(BlueMoon):
    Talon_Class = StackWrapper(Montana_Talon, max_rounds=2)
    RowStack_Class = Jungle_RowStack
",5
"        strings = [_('&Start'), _('&Play'), _('&New'), 'sep', _('&Close'), ]
        kw = KwStruct(kw,
                      strings=strings,
                      default=0,
                      )
",5
"            y += l.YS
        x, y = l.XM + 3*l.XS, l.YM + 5*l.YS
        for i in (0, 1):
            stack = SS_RowStack(x, y, self, max_move=1, base_rank=KING)
",5
"        return self.game.app.images.getSuitBottom(suit)

    def quickPlayHandler(self, event, from_stacks=None, to_stacks=None):
        # find the single stack that can currently move a card
",5
"        frame = self._calcToolkit().Frame(top_frame)
        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

",5
"            config = configobj.ConfigObj(configspec=configspec,
                                         encoding=self._config_encoding)
",5
"    RowStack_Class = SS_RowStack
    BASE_RANK = ANY_RANK
    MAX_MOVE = 1

    #
",5
"    game_type = game_type | GI.GT_DASHAVATARA_GANJIFA
    gi = GameInfo(id, gameclass, name, game_type, decks, redeals, skill_level,
                  suits=list(range(10)), ranks=list(range(12)))
    registerGame(gi)
",5
"                ((card1.rank + 1) % 13 == card2.rank or
                 (card2.rank + 1) % 13 == card1.rank))
",5
"    def scaleFontCB(self, instance, value):
        self.scaleFont(value[1])

",5
"        for r in s.rows:
            r.CARD_XOFFSET, r.CARD_YOFFSET = 0, l.YOFFSET

",5
"                return gi.id in games
            if name is None or not list(filter(
                    select_func, self.all_games_gi)):
                continue
            gg.append(SelectGameNode(None, name, select_func))
",5
"
    dialogCache = {}

    def make_pop_command(self, parent, title):
        def pop_command(event):
",5
"
    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
",5
"from pysol_cards.random import LCRandom31, match_ms_deal_prefix  # noqa: I100
from pysol_cards.random import CUSTOM_BIT, MS_LONG_BIT  # noqa: I100

",5
"
    def option_get(self, a, b):
        return 0
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"                x = l.XM + (j*5)*l.XS//2
                stack = RK_RowStack(x, y, self,  base_rank=NO_RANK, max_move=1)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"    ""ahfajfavfaxfazfa"" +
    ""BfaDfaahachaehag"" +
    ""haihakhamhaohaqh"" +
    ""ashauhawhayhaAha"" +
    ""ChaEhabjadjafjah"" +
",5
"
        lwidth = 10
",5
"            ""\n"" +
            w1 + w2,
            strings=((_(""&Statistics...""), 101),
                     'sep',
",5
"        )
        Resource.__init__(self, **kw.getKw())

",5
"    ""hbahbcvbchbeobfv"" +
    ""bgobhhbihbkvbkhb"" +
    ""macbacdacjaclhdb"" +
    ""hddodevdfCdgvdho"" +
",5
"        dx, dy = x - c0.x, y - c0.y
        for card in cards:
            card.moveBy(dx, dy)
        self.canvas.update_idletasks()
",5
"# ************************************************************************
# * Triple Canfield
",5
"        if self._cancelDrag(break_pause=False):
            return
",5
"        gi = self.getGameInfo(id)
        if gi:
            if update & 256:
",5
"        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, 'nw')
        x += l.XS
        s.waste = WasteStack(x, y, self)
",5
"#  Copyright (C) 2005-2009 Skomoroh
",5
"        iw, ih = image.width(), image.height()
",5
"
    def drawHintArrow(self, from_stack, to_stack, ncards, sleep):
",5
"            return self._shuffleHook1(cards[:])
        # hard
        new_cards = self._shuffleHook2(self.s.rows, cards)
        if new_cards is None:
",5
"        self.setSize(l.XM+5*l.XS, l.YM+5*l.YS)

        suit = 0
        for x, y in ((0, 0), (4, 0), (0, 4), (4, 4)):
            x, y = l.XM+x*l.XS, l.YM+y*l.YS
",5
"            filename = None
        d.destroy()
",5
"        layout=""0eaabacbaebagbai"" +
    ""bakbameaoacaacoa"" +
    ""eaaeoagaagoaiaai"" +
    ""oakaakoamaamoaoa"" +
",5
"            x += l.XS

        x, y = l.XM, l.YM+l.YS//2
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------#
",5
"            node.expanded = not node.expanded
            self.redraw()
        return ""break""


",5
"        self.flipMove(self.s.talon)
        self.moveMove(1, self.s.talon, to_stack)
        self.updateText()
",5
"        if not node:
            return
        print(""Clicked node %s %s"" % (node.text, node.key))
        if isinstance(node, MfxTreeLeaf):
",5
"        button.connect(""clicked"", self.quit)
        button.set_flags(gtk.CAN_DEFAULT)
        self.action_area.pack_start(button)
        button.show()

",5
"        # self.bind('<ButtonPress>', self._sleepEvent, add=True)
",5
"            self._bindKey(ctrl, ""equal"", self.mIncreaseCardset)
            self._bindKey(ctrl, ""minus"", self.mDecreaseCardset)
            self._bindKey(ctrl, ""0"", self.mOptAutoScale)
        self._bindKey(ctrl, ""b"", self.mOptChangeCardback)  # undocumented
",5
"
    def createGame(self):
        dx = self.app.images.CARDW//10
        BigDeal.createGame(self, rows=12, max_rounds=1, XOFFSET=dx)

",5
"            ""default"": None,
            # ""default"": (""helvetica"", 12),
",5
"
    def createGame(self, reserves=6):
        # create layout
        l, s = Layout(self), self.s
",5
"class MyPysolScale:
    def __init__(self, parent, **kw):
        if 'resolution' in kw:
",5
"            self.anchor = None
        self.formatter.writer.anchor_end()
",5
"        # create stacks
        x, y = l.XM, l.YM
        for i in range(4):
",5
"            if cr == KING:
                return self.id in (0, 3, 12, 15)
            elif cr == QUEEN:
",5
"class SuperChallengeFreeCell(ChallengeFreeCell):
    RowStack_Class = StackWrapper(FreeCell_AC_RowStack, base_rank=KING)
    Solver_Class = FreeCellSolverWrapper(esf='kings')
",5
"            while j < i:
                if cards[j].rank != KING:
                    cards[j], cards[i] = cards[i], cards[j]
                    break
",5
"r(5078, ""Squaring"", layout=""0caaacaceaciaaka"" +
    ""cmacqaasacuacyaa"" +
    ""AacCaaacaecaicdk"" +
",5
"#    ""yaaycoydayeaykoy"" +
#    ""laymayohzbhzdhzl"" +
",5
"            for j in range(4):
                s.foundations.append(TwilightZone_Foundation(x, y, self,
                                                             suit=j))
                x += l.XS
            y += l.YS
",5
"            self.grid(row=self.position,
                      column=0,
                      ipadx=padx, ipady=pady,
                      sticky='nsew')

",5
"    ""mkbmmampcocaopdq"" +
",5
"
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
",5
"            LTreeNode(text=_('Animations')))
        if rg:
            self.addRadioNode(tv, rg,
                              _('None'),
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"            return 1
        # deal to the rows
        if sound and self.game.app.opt.animations:
            self.game.startDealSample()
        ncards = 0
",5
"
class _OneImageCard(_HideableCard):
    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
        _HideableCard.__init__(self, id, deck, suit, rank, game, x=x, y=y)
",5
"from pysollib.stack import \
        OpenStack, \
        SS_FoundationStack, \
        Stack, \
        WasteTalonStack
",5
"        # check the rank
        if self.cards[-1].rank + cards[0].rank != 11:
            return False
        # now look if the stacks are neighbours
",5
"class Yukon_AC_RowStack(BasicRowStack):
    def __init__(self, x, y, game, **cap):
        kwdefault(cap, max_move=999999, max_accept=999999)
        BasicRowStack.__init__(self, x, y, game, **cap)
",5
"
",5
"    Hint_Class = CautiousDefaultHint
    Layout_Method = staticmethod(Layout.harpLayout)
    Talon_Class = WasteTalonStack
",5
"    def getHighlightPilesStacks(self):
        # Pas de Deux special: highlight all moveable cards
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:4])
",5
"

",5
"
class FreeFan(Fan):
    RowStack_Class = FullStackWrapper(SuperMoveSS_RowStack, base_rank=KING)
    Solver_Class = FreeCellSolverWrapper(esf='kings', sbb='suit')
",5
"            progress = PysolProgressBar(self, self.top, title=title,
                                        color=color,
                                        images=self.progress_images)
        images = Images(self.dataloader, cs)
        try:
",5
"            # return -1                   # continue this event (start a drag)
",5
"        x, y = l.XM, l.YM
",5
"
    # Memory special: check score for a perfect game
    def getWinStatus(self):
",5
"                    None, _('Mostly skill'),
",5
"        #   command=self.makeHtmlCommand(self.menubar, ""kivy.html"")))
",5
"    def _getMaxIters(self):
        try:
            i = self.max_iters_var.get()
        except Exception:
            i = 100000
",5
"

",5
"        column = stack2.id % 13
        diff = stack1.id - stack2.id
        if column == 0:
            return diff in (-13, 1, 13)
",5
"        self.startDealSample()
        self.s.talon.dealRow()
",5
"registerGame(GameInfo(6, RelaxedSeahavenTowers, ""Relaxed Seahaven Towers"",
                      GI.GT_FREECELL | GI.GT_RELAXED | GI.GT_OPEN, 1, 0,
                      GI.SL_SKILL))
",5
"class Memory24(Game):
    Hint_Class = None
",5
"                     (0, 1.5),
                     ):
            x, y = l.XM+i*l.XS, l.YM+j*l.YS
            stack = RK_RowStack(x, y, self, dir=1, mod=13, max_move=0)
",5
"            self.assertEqual(err.msg, ""Duplicate cards in input"")
            self.assertEqual(err.cards, [""KC""])
            self.assertEqual(err.line_num, 1)
",5
"#
# ---------------------------------------------------------------------------##

from pysollib.game import Game
",5
"        game_number = game.getGameNumber(format=0)
        game_start_time = game.gstats.start_time
        # update number of games
",5
"        _CanvasItem.__init__(self, canvas)
        kwargs = {}
",5
"
    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(_(""&OK""), (_(""Session &log...""), 104),
",5
"    #

    def createGame(self, **layout):
        Matsya.createGame(self, max_rounds=-1, num_deal=3)
",5
"            x += l.XS
",5
"registerGame(GameInfo(64, Penguin, ""Penguin"",
",5
"            if not self.s.waste.cards:
",5
"class CanvasText(CanvasItem):
    def __init__(self, canvas, *args, **kw):
        CanvasItem.__init__(self, canvas, 'text', *args, **kw)

",5
"    ""pause"",
    ""statistics"",
    ""rules"",
",5
"            cards = [self.cards[i]]
",5
"        x += l.XS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, ""s"")

        # define stack-groups
",5
"    # Game layout
",5
"
class PortugueseSolitaire(BakersDozen):
    RowStack_Class = StackWrapper(RK_RowStack, base_rank=KING, max_move=1)
    Solver_Class = FreeCellSolverWrapper(sbb='rank', esf='kings')
",5
"#
",5
"        if self.basicIsBlocked():
            return False
        if from_stack is self or not self.cards or len(cards) != 1:
            return False
",5
"            SelectTileNode(None, _(""Solid Colors""), (
                SelectTileLeaf(None, None, _(""Blue""), key=""#0082df""),
                SelectTileLeaf(None, None, _(""Green""), key=""#008200""),
",5
"            if rg1:
                tm = self.app.tabletile_manager
                # cnt = tm.len()
                i = 1
",5
"
        (""arrowdown-n"", 0, y1, sn, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
        (""arrowdown-a"", 0, y1, sp, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
        (""arrowdown-p"", 0, y1, sa, gtk.SHADOW_IN,  gtk.ARROW_DOWN, vscroll),
        (""arrowdown-d"", 0, y1, si, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return ((card1.suit == card2.suit) and
                ((card1.rank + 1 == card2.rank) or
                 (card1.rank - 1 == card2.rank)))

",5
"        decks = self.gameinfo.decks
        foundations = 4*decks

        # set window
",5
"                    self.newGame()
        else:
            # game not finished yet
            self.top.busyUpdate()
            if self.demo:
",5
"# *
",5
"            x += XS + XM
        self.setRegion(self.s.rows, (XS + XM, -999, 999999, 999999))
",5
"            x += l.XS
",5
"
class Shifting_RowStack(Numerica_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        Grandee.createGame(self, rows=12)

    def fillStack(self, stack):
        if not stack.cards:
",5
"                text=_(""\nGame finished, but not without my help...\n""),
                strings=(_(""&New game""), _(""&Restart""), _(""&Cancel"")))
",5
"# ************************************************************************
# * Glenwood
",5
"
",5
"            return False
        return cardsFaceUp(cards)

    #
    # Capabilities - important for game logic {model}
",5
"        th = l.YS + 3 * TABLEAU_YOFFSET
        # (set piles so that at least 2/3 of a card is visible with 10 cards)
        h = (10-1)*l.YOFFSET + l.CH*2//3
        self.setSize(10*l.XS+l.XM, l.YM + 3*th + l.YM + h)

",5
"        for k in self.app.opt.colors:
            self.tkopt.color_vars[k] = StringVar()

    def _setOptions(self):
        tkopt, opt = self.tkopt, self.app.opt
",5
"#    ""gaugaygachaghbkh"" +
",5
"            kw['indicatoron'] = False
            kw['selectcolor'] = ''

            button = MyCheckButton(**kw)
",5
"
The Python, %(gui_library)s, SDL & Linux crews
for making this program possible''') % {'app': TITLE, 'gui_library': t},
        image=app.gimages.logos[3], image_side=""right"",
        separator=True)
",5
"
        sc = PysolScale(frame, from_=6, to=40, resolution=1,
                        label=_('Size:'), orient='horizontal',
                        command=self.fontupdate, variable=self.size_var)
",5
"        # for a card in stack t.
        tpile = t.getPile()
",5
"        padx, pady = 5, 5
",5
"        self.s.talon.dealRow(rows=self.s.reserves[8:], frames=0)
        self.s.talon.dealRow(frames=0)
        self.startDealSample()
        self.s.talon.dealCards()

",5
"                # print('MfxCanvas: tag_raise: to top')
",5
"        self.preview.setTile(app, app.tabletile_index, force=True)
        self.preview.pack(fill='both', expand=True, padx=padx, pady=pady)
        self.preview.canvas.preview = 1
",5
"        tx, ty, ta, tf = l.getTextAttr(stack, 'se')
        font = self.app.getFont('canvas_default')
        stack.texts.misc = MfxCanvasText(self.canvas, tx, ty,
                                         anchor=ta, font=font)
        x, y = self.width-l.XS, self.height-l.YS
",5
"
",5
"        tkinter.Checkbutton.__init__(self, parent, kwargs)
        AbstractToolbarButton.__init__(
            self, parent, toolbar, toolbar_name, position)


",5
"class Fifteens_RowStack(Elevens_RowStack):
    ACCEPTED_SUM = 13
",5
"class LRectangle(Widget, LBase):
    def __init__(self, prnt, args, **kw):
        super(LRectangle, self).__init__(**kw)
        self.prnt = prnt
",5
"        elif button == 2:
            self.app.opt = self.saved_opt
        if self.app.audio:
",5
"r(5271, ""Trika"", layout=""0hagaahiaiaajhak"" +
    ""abfablhceicihcma"" +
    ""ddoddodfadhvdhCd"" +
    ""iadjvdjodladnodn"" +
    ""heeieihemaffaflh"" +
",5
"#          #  draw_line(3, 7)     # test
#          draw_line(4, 5)
#          draw_line(5, 6)
#          draw_line(6, 7)
#          draw_line(7, 4)
",5
"        self.initBindings()


# ************************************************************************
# *
",5
"
class FourWinds(AbstractFlowerGame):

    #
    # Game layout
",5
"
    #
    # game overrides
    #
",5
"            return

        s = s[self.player][gameid]

",5
"        sequence = ""<"" + modifier + ""KeyPress-"" + key + "">""
        bind(self.top, sequence, func)
        if len(key) == 1 and key != key.upper():
            key = key.upper()
            sequence = ""<"" + modifier + ""KeyPress-"" + key + "">""
",5
"        # print ('MfxMenubar: _addPath %s, %s' % (path, menu))
        # y = self.yy
        if path not in self.__menupath:
            # print path, menu, index, submenu
",5
"        header = self.formatter.getStatHeader()
        self.formatter.createHeader(player, header)

",5
"        y = l.YM
        for i in range(2):
            x = l.XM+3*l.XS
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.color != card2.color and \
            abs(card1.rank-card2.rank) in (0, 1)


",5
"        newscale = self.scalefactor()
",5
"    def show(self):
",5
"        # set window
",5
"from . import headsandtails  # noqa: F401
from . import katzenschwanz  # noqa: F401
from . import klondike  # noqa: F401
",5
"    def getDemoInfoText(self):
        h = self.Hint_Class is None and 'None' or self.Hint_Class.__name__
        return '%s (%s)' % (self.gameinfo.short_name, h)
",5
"        menu.add_command(
",5
"
    #
    # game overrides
    #

",5
"class FredsSpider3Decks(FredsSpider):

    def createGame(self):
        Spidike.createGame(self, rows=13, playcards=26)

",5
"        if self.collide_point(*touch.pos):

            for c in self.children:
",5
"    def _setHbar(self, first, last):
        if self.canvas.busy:
            return
",5
"                     ('Hint:', hint),
                     ):
            if t:
                self._calcToolkit().Label(
                    frame, text=n, anchor='w').grid(
",5
"            row += 1
",5
"# (at your option) any later version.
#
",5
"
        def _key(a):
            wa, la, ta, ma = self.stats.getFullStats(player, a)
",5
"        UNLIMITED_ACCEPTS, \
        UNLIMITED_CARDS, \
        UNLIMITED_MOVES
",5
"                return 0
        return 1


",5
"        return from_stack in self.game.s.rows
",5
"class GameGlobalSaveInfo(NewStruct):
    bookmarks = attr.ib(factory=dict)
    comment = attr.ib(default="""")


",5
"        game.leaveState(old_state)


class Accordion2(Accordion):
    RowStack_Class = Accordion2_RowStack
",5
"        AC_RowStack, \
        BO_RowStack, \
        RK_FoundationStack, \
        RK_RowStack, \
        ReserveStack, \
",5
"            menu.add_command(label=n_(""&Solver""), command=self.mSolver)
        else:
            menu.add_command(label=n_(""&Solver""), state='disabled')
",5
"            dir = self.getFoundationDir()
",5
"            for j in range(5):
                k = i*5+j
",5
"        game_cols = self.game.cols
        x1, y1 = self.coln+1, self.rown+1
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"r(14411, Dhanpati, 'Dhanpati', GI.GT_MUGHAL_GANJIFA, 1, 1, GI.SL_BALANCED)
r(14412, AkbarsTriumph, 'Akbar\'s Triumph', GI.GT_MUGHAL_GANJIFA, 1, 2,
  GI.SL_BALANCED)
",5
"                          max_cards=1, max_move=0, base_rank=QUEEN))
            x += l.XS
",5
"        x = self.width - l.XS
        y = l.YM
        for i in range(4):
            s.foundations.append(
                SS_FoundationStack(
",5
"        logging.info('mw = %s,  w = %s' % (self.mainWindow, Window))
",5
"        logging.info('LTkBase: mainquit')
        lapp = App.get_running_app()
",5
"    #   __face, __back -- the canvas items making up the card
    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
",5
"    def getHelp(self):
        return _('Tableau. Build regardless of rank and suit.')


",5
"            return
        if not self.game.s.waste.cards:
",5
"# ************************************************************************
",5
"class Matrix8(Matrix3):
",5
"r(13164, DoubleCockroach, 'Double Cockroach', GI.GT_TAROCK, 2, 0,
  GI.SL_MOSTLY_SKILL)
r(13165, Corkscrew, 'Corkscrew', GI.GT_TAROCK, 2, 0, GI.SL_MOSTLY_SKILL)
",5
"
    def mOptAutoDrop(self, *args):
        if self._cancelDrag():
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        # FIXME
        return False

",5
"#    ""iomiamkhnfhnhhnj"" +
#    ""aofoofaohoohaojo"" +
",5
"            s.rows.append(self.RowStack_Class(x, y, self))
",5
"from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.hint import CautiousDefaultHint
",5
"def unbind_destroy(widget):
    k = id(widget)
    if k in __bindings:
        #  FIXME
",5
"

class LMenuDialog(object):
",5
"        # self.canvas.pack(expand=True, fill='both')

    def createHbar(self):
        pass
        '''
",5
"
    def setMenu(self, menu):
",5
"import gtk
import gtk.glade

import pango
",5
"        x = self.widget.winfo_pointerx()
        y = self.widget.winfo_rooty() + self.widget.winfo_height()
",5
"
# ************************************************************************
# * Flourish
# ************************************************************************
",5
"        self.s.talon.dealRow(frames=0, flip=0)
        self.s.talon.dealRow(frames=0)
",5
"
    def cget(self, strg):
        return False

",5
"# * 8 x 8
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"            score = score + value
        t = '\n'.join(map(str, count))
        self.texts.misc.config(text=t)
        #
",5
"
class _HideableCard(AbstractCard):
    def hide(self, stack):
",5
"    RowsType,
    RowsBaseCard,
    RowsDir,
    RowsMaxMove,
    RowsWrap,
",5
"        return []

",5
"        if from_stack is to_stack or \
",5
"    #
",5
"        if not len(stackcards):
",5
"                                 base_rank=KING, max_move=0, dir=-1))
            y += l.YS
",5
"        if not self.app.opt.animations or not self.app.opt.redeal_animation:
            return
        cards = []
",5
"
        # default
        l.defaultAll()

",5
"# * - create menubar
# * - update menubar
# * - menu actions
",5
"    shallHighlightMatch = Game._shallHighlightMatch_SSW

",5
"        event_box.window.set_cursor(gdk.Cursor(gdk.HAND2))
        gtk.main()

    def initKw(self, kw):
",5
"            self.preview_app = Struct(
                # variables
                audio=self.app.audio,
                canvas=canvas,
",5
"# ************************************************************************

class Nestor_RowStack(MonteCarlo_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"    ""hckhcmhcohcqhcsh"" +
    ""cuhbwhaAhdeiayia"" +
    ""gjbijbkjbmjbojbq"" +
    ""jbsjbujbwjaAjack"" +
    ""aykcalailaklamla"" +
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit != card2.suit and
                abs(card1.rank-card2.rank) == 1)

",5
"        x, y = l.XM, l.YM
        s.talon = SlyFox_Talon(x, y, self)
        s.waste = s.talon
",5
"        if y == 20:
            y = 0
            z += 1
",5
"
",5
"
        # Create clock
        xoffset = (1, 2, 2.5, 2, 1, 0, -1, -2, -2.5, -2, -1, 0)
",5
"                continue
",5
"    Talon_Class = WasteTalonStack
    Waste_Class = WasteStack

    #
",5
"        x, y = l.XM, l.YM
        s.talon = WasteTalonStack(x, y, self, max_rounds=3)
",5
"        dx, dy = 4, 0
        self.canvas.config(scrollregion=(-dx, -dy, bbox[2]+dx, bbox[3]+dy))
",5
"class Journey_BraidStack(OpenStack):
",5
"
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"            mouse_undo=BooleanVar(),
            negative_bottom=BooleanVar(),
            display_win_message=BooleanVar(),
            pause=BooleanVar(),
",5
"
PY_VERS = ([] if _has_tag('SKIP_PY2') else [2])+[3]
SKIP_GTK = _has_tag('SKIP_GTK')
module_names = []
for d, _, files in os.walk(""pysollib""):
",5
"        label = getattr(self, name + '_label')
        label.config(**kw)
",5
"        # friend MfxCanvasText
        self._text_color = ""#000000""
        self._stretch_bg_image = 0
",5
"            label=n_(""&Clear bookmarks""), command=self.mClearBookmarks)
",5
"            for c in n.nodes:
                if c.is_open:
                    cc(p, c)
                    p.toggle_node(c)
",5
"            ('deal',          _('Deal'),           tkinter.BooleanVar()),
            ('dealwaste',     _('Deal waste'),     tkinter.BooleanVar()),

            ('turnwaste',     _('Turn waste'),     tkinter.BooleanVar()),
",5
"    talon_round = attr.ib(default=1)
",5
"                    s.cards[-1].rank - 1 == cards[0].rank:
                return True
        return False
",5
"                relx = 0.5
            if rely is None:
                rely = 0.3
        else:
            if relx is None:
",5
"        self.subnodes = None
        # canvas item ids
        self.symbol_id = None
        self.text_id = None
",5
"        for gi in games:
",5
"
        # default
        l.defaultAll()

",5
"            ms = ms or s
",5
"# the Free Software Foundation, either version 3 of the License, or
",5
"        # bind(group, ""<Leave>"", self._Stack__leaveEventHandler)

    def __defaultClickEventHandler(self, event, handler):
        self.game.event_handled = True  # for Game.undoHandler
        if self.game.demo:
",5
"    menu.add_separator()
    submenu = MfxMenu(menu, label=n_('Visible buttons'), tearoff=tearoff)
    for w in TOOLBAR_BUTTONS:
        submenu.add_checkbutton(
",5
"        y = l.YM
",5
"            except Exception:
                traceback.print_exc()
",5
"    def startGame(self):
        self._startAndDealRow()

    shallHighlightMatch = Game._shallHighlightMatch_SS
",5
"    def resetGame(self):
        # Called when starting a new game.
",5
"            stack.CARD_YOFFSET = yoffset
            s.rows.append(stack)
            x += l.XS
        x, y = l.XM + rows*l.XS, l.YM
",5
"    def acceptsCards(self, from_stack, cards):
",5
"    def lower(self, positions=None):
",5
"
    # Add a card add the top of a stack. Also update display. {model -> view}
    def addCard(self, card, unhide=1, update=1):
        model, view = self, self
        model.cards.append(card)
",5
"
            url = self.anchor[0]
            fg = '0000cc'
            u = self.viewer.normurl(url, with_protocol=False)
            if u in self.viewer.visited_urls:
",5
"    def end_strong(self): self.end_b()
",5
"                return 0
",5
"# Copyright (C) 2005-2009 Skomoroh
#
",5
"        return self.__dict__.get(key, default)

    def getKw(self):
        return self.__dict__

",5
"                      GI.SL_SKILL))
registerGame(GameInfo(148, Chessboard, ""Chessboard"",
                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
",5
"
    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(3)
",5
"            self.game.stopSamples()
        return num_cards


",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
                (card1.rank + 3 == card2.rank or card2.rank + 3 == card1.rank))
",5
"                (r2 == JACK and r1 == KING)):
            return True
        return ((r1+1) % 13 == r2 or (r2+1) % 13 == r1)

",5
"        for i in range(8):
",5
"
import gtk
from gtk import gdk

",5
"                break
",5
"
    def createGame(self):
        Fan.createGame(self, rows=(4, 4, 4, 4), playcards=10, texts=True)

",5
"            diff = (r1_0 - r2[0])**2 + (r1_1 - r2[1])**2
            if diff < sdiff:
                sstack, sdiff, sx, sy = s, diff, r2[0], r2[1]
        if sstack is drag.shade_stack:
            return
",5
"        if button == 1:        # ""Solid color...""
            try:
                c = tkinter_colorchooser.askcolor(
                    master=self.top,
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"
# register the game
registerGame(GameInfo(13, FortyThieves, ""Forty Thieves"",
",5
"    #
    # game layout
    #

    def createGame(self):
",5
"        self.window = None
",5
"        if self._cancelDrag():
            return
        if self.changed():
",5
"        x, y = (w1 - w0) // 2, (h1 - h0) // 2
        out.paste(back, (x, y), back)
    return out

",5
"                                    *won_coords)
            self.items.append(id)
",5
"    ""eeaegaeiaekaemae"" +
",5
"    def harpLayout(self, rows, waste, reserves=0,
                   texts=1, reserve_texts=False, playcards=19):
",5
"        #
        self.app = app
",5
"        self.text_var = tkinter.StringVar()
",5
"# * New implementation since 2.10
# *
# * We use a single CanvasImage and call CanvasImage.config() to
",5
"                # apparent size of canvas
                vw = self.canvas.winfo_width()
                vh = self.canvas.winfo_height()
            else:
",5
"
        writer = tkHTMLWriter(self.textbuffer, self, self.app)
        fmt = formatter.AbstractFormatter(writer)
",5
"            ('tabletile', None,
             ltk2gtk('Table t&ile...'), None,
             None, self.mOptTableTile),
            ('fonts', None,
",5
"            self.realize()
            # return False
",5
"        y = l.YM
        for i in range(2):
            x = l.XM+2*l.XS
",5
"        table.attach(combo,
                     x, x+1,                y, y+1,
                     gtk.FILL | gtk.EXPAND,   0,
                     4,                     4)
        #
",5
"                            tmp.paste(im, (1, 1), im)
                            im = tmp.resize((int(w*z), int(h*z)),
                                            resample=filter)
",5
"        # traceback.print_exc()
",5
"    ""dogeaghogiagjogm"" +
    ""agnhhdhhivhihhna"" +
    ""ieoifaiioiioilai"" +
",5
"
    def canFlipCard(self):
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"        if self.level >= 2:
",5
"    ""aemagmapmaymaAma"" +
",5
"        self.__back.addtag(self.item)

    def showFace(self, unhide=1):
        if not self.face_up:
            self.__back.move(0, 10000)
",5
"    def startGame(self):
",5
"        x, y, = l.XM+1.5*l.XS, l.YM
        for i in range(6):
",5
"        resize = not self.app.opt.save_games_geometry
        if self.app.helpbar.show(show, resize=resize):
            self.top.update_idletasks()

",5
"
",5
"        playcards = 4 * l.YS // l.YOFFSET
        xoffset, yoffset = [], []
        for i in range(playcards):
            xoffset.append(0)
            yoffset.append(l.YOFFSET)
",5
"        return True

    def getHelp(self):
        return _('Foundation. Build in suit regardless of rank.')

",5
"                self.game.flipMove(self)
            self.game.moveMove(1, self, r, frames=frames)
        self.game.leaveState(old_state)
",5
"                if edit:
                    gameid = write_game(self.app, game=self.game)
                else:
",5
"
        # undocumented, devel
        self._bindKey(ctrl, ""End"", self.mPlayNextMusic)
        self._bindKey(ctrl, ""Prior"", self.mSelectPrevGameByName)
        self._bindKey(ctrl, ""Next"", self.mSelectNextGameByName)
",5
"                 'pysollib.kivy',
                 'pysollib.game',
",5
"    )

    SELECT_ORIGINAL_GAME_BY_TYPE = (
",5
"        The arguments correspond to the attributes of the <A> tag with
        the same names.  The default implementation maintains a list of
        hyperlinks (defined by the HREF attribute for <A> tags) within
",5
"        self.setSize(w, h)

        # create stacks
        s.talon = self.Talon_Class(l.XM, h-l.YS, self)

",5
"        self.gamerandom = PysolRandom()
        self.miscrandom = PysolRandom()
        # player
        player = getusername()
        if not player:
",5
"    # Game overrides
    #

    def getCardFaceImage(self, deck, suit, rank):
",5
"            'h3': (default_font[0], size + 6*sign, 'bold'),
            'h4': (default_font[0], size + 4*sign, 'bold'),
            'h5': (default_font[0], size + 2*sign, 'bold'),
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"
",5
"        GT_MONTANA:             n_(""Montana""),
        GT_NAPOLEON:            n_(""Napoleon""),
        GT_NUMERICA:            n_(""Numerica""),
        GT_PAIRING_TYPE:        n_(""Pairing""),
        GT_RAGLAN:              n_(""Raglan""),
",5
"                xbutton += 1
                button = xbutton
",5
"#    ""vylCaeCyeCagCygC"" +
#    ""aiCyiCakCyk"")
r(5047, ""Inca"", layout=""0aoaaqaaibakbamb"" +
    ""asbaubawbbocbqca"" +
    ""idbkdbmdbsdbudaw"" +
",5
"    ""weaEeagfbkfbofbq"" +
",5
"        right_frame.columnconfigure(1, weight=1)
        right_frame.rowconfigure(1, weight=1)
",5
"
        suit = 0
        for xx, yy in ((1.5, 1.5),
                       (1,   2.5),
                       (6.5, 1.5),
",5
"solver_dialog = solver_dialog


",5
"
    getBottomImage = Stack._getBlankBottomImage
",5
"

",5
"    ""vjivjkajoojphkav"" +
",5
"
    def connect(self, signal, func, args):
        # print '_CanvasItem.connect:', self, signal
        self._item.connect('event', func, args)
",5
"        # create stacks
",5
"        return pwon, plost

    def _createChartInit(self, text):
",5
"
    def createGame(self, max_rounds=1):
        lay = Klondike.createGame(self, max_rounds=max_rounds)
        self.texts.score = MfxCanvasText(self.canvas,
                                         8, self.height - 8, anchor=""sw"",
",5
"from pysollib.gamedb import GI, loadGame
from pysollib.layout import Layout
from pysollib.mygettext import _, n_
from pysollib.stack import AC_FoundationStack, \
        AC_RowStack, \
",5
"        x, y = l.XM, l.YM
        s.talon = Strategerie_Talon(x, y, self)
        l.createText(s.talon, 'ne')
",5
"    def _shuffleHook(self, cards):
        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == 0, c.suit))

",5
"                self.sound_samples[key] = val

        # fonts
        for key in self.fonts:
",5
"                       (7,   2),
",5
"            x += l.XS

        if texts:
            stack = s.reserves[0]
            tx, ty, ta, tf = l.getTextAttr(stack, ""n"")
",5
"
    #
    # game layout
    #

",5
"                return False
",5
"            ny = self.drawChildren(childx, childy, clastx, clasty)
        return lx, ly, x, ny

",5
"    ""EmeEo"")
",5
"        x += l.XS
        for i in range(7):
            s.rows.append(Chelicera_RowStack(x, y, self, base_rank=KING))
",5
"
        # set window
        self.setSize(l.XM+9*l.XS, l.YM+3*l.YS+12*l.YOFFSET)

        # create stacks
",5
"
",5
"        # self.game.updateMenus()
",5
"                    # score = 10000 + r.id + t.id
                    rb = r.blockmap
                    tb = t.blockmap
",5
"            x = x + 4 * l.XS
        x = l.XM + 5*l.XS//2
        y = l.YM
        s.braid = Ponytail_PonytailStack(x, y, self, sine=1)
        x = l.XM + 7 * l.XS
",5
"                for r in self.s.foundations:
                    s.foundations.append(foundation_class(r.x, r.y, game,
                                                          suit=r.suit))
",5
"        l, s = Layout(self), self.s

        # set window
        n = 52//reserves+1
",5
"                self.s.talon.moveMove(1, stack)
                self.leaveState(old_state)
",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 'se')
        y = 2*l.YM+l.YS
        for i in range(2):
",5
"# ************************************************************************

class ScotchPatience(Fan):
    Foundation_Classes = [AC_FoundationStack]
    RowStack_Class = StackWrapper(RK_RowStack, base_rank=NO_RANK)
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    # KMahjongg
    fd = open(filename)
    fd.readline()
    lines = fd.readlines()
    level = 0
",5
"Guido van Rossum for the initial example program
T. Kirk for lots of contributed games and cardsets
",5
"        i, n = 0, 17
        kings = []
        for c in cards:
            if c.rank == KING:
",5
"    Hint_Class = KlondikeType_Hint

    def createGame(self, **layout):
        # create layout
        l, s = Layout(self), self.s
",5
"        self.viewer = viewer
",5
"

",5
"                s1 = game.s.reserves[i]
                s2 = self.s.reserves[i]
                s1.texts.ncards = self.defaultText(s2)

",5
"            dy = int(dy*yf)
            self.scale_images = []
        for image in self.preview_images:
",5
"        self.write('\n')
",5
"    ag = array('B', g)
    gw, gh = texture.size

    # print('size:',width,height)
",5
"class Marshal(Game):
",5
"        self.stopSamples()
",5
"# * Nodes
# ************************************************************************

class SelectCardsetLeaf(SelectDialogTreeLeaf):
    pass
",5
"            x, y = x0+xx*l.XS, y0+yy*l.YS
",5
"            game.flipMove(self)
",5
"        if s['found_type'] in (Spider_SS_Foundation,
                               Spider_AC_Foundation,
                               Spider_RK_Foundation,):
            kw['dir'] = -kw['dir']
            if s['found_base_card'] == KING:
",5
"        waste_cards = 0
",5
"        return ()

    def _restoreGameHook(self, game):
        self.base_card = self.cards[game.loadinfo.base_card_id]
",5
"class _TopDialog(MfxDialog):
    def __init__(self, parent, title, top, **kw):
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
",5
"                (n_('Deal to waste'),         WasteTalonStack),
                (n_('Deal to tableau'),       DealRowRedealTalonStack),
                (n_('Deal to reserves'),      DealReserveRedealTalonStack),
                (n_('Spider'),                SpiderTalonStack),
                (n_('Grounds for a Divorce'), GroundsForADivorceTalonStack),
",5
"            y = y + l.YS
        s.foundations.append(
            Ponytail_Foundation(x, y, self, 4, mod=22, max_cards=22))
",5
"def after_cancel(t):
    if t is not None:
",5
"        for label, select_func in select_data:
",5
"
",5
"

",5
"        cs.updateCardback(backindex=val)
        # ANM: wir knnen den Background nur fr das aktuell
        # selektierte Cardset wirklich ndern. Nur dieses wird
        # wird in den Optionen gespeichert.
",5
"    ""aoaaqaasaauaawaa"" +
",5
"# ************************************************************************
# * Eight Packs (ex. Four Packs)
# * Four Packs
# ************************************************************************
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC


",5
"    }

",5
"            self.s.talon.dealCards()


def registerCustomGame(gameclass):
",5
"        for i in range(3):
            self.s.talon.dealRow()

",5
"<head>
<title>%(title)s</title>
<meta name=""license"" content=""GNU General Public License"">
<meta http-equiv=""content-type"" content=""text/html; charset=utf-8"">
",5
"        # if parent and parent.winfo_screenheight() < 600:
        #    lines = 20
        #
",5
"                    return True, c.suit
            return False, None
",5
"            if clock:
                endtime = starttime + i*SPF
",5
"    # button
    w, h = 32, 32
    w, h = 28, 28
    for fn, state, shadow in (
        (""button-n"", gtk.STATE_NORMAL,      gtk.SHADOW_OUT),
",5
"    RowStack_Class = StackWrapper(Hanafuda_SequenceStack, base_rank=NO_RANK)

    #
",5
"        # note: best results if height is a multiple of style.disty
        MfxTreeInCanvas.__init__(self, parent, nodes, height=25*18)
        self.draw()

    def addNode(self, list, node, filename, text):
",5
"        clock, delay, skip = None, 1, 1
        if self.app.opt.animations >= 2:
            clock = uclock
        SPF = 0.15 / 8          # animation speed - seconds per frame
",5
"        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.reserves)
",5
"
",5
"        self.__topimage = image
",5
"            self.face_up = 0
",5
"        # (max_move defaults to 1)
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank)

",5
"                      GI.GT_PAIRING_TYPE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(657, Baroness, ""Baroness"",
",5
"            return n
        return 0

",5
"            y += YS
        x, y = w - XS, YM + YS * decks
        for i in range(reserves // 2):
            self.s.reserves.append(S(x, y))
            y += YS
",5
"from pysollib.pysoltk import get_text_width
from pysollib.pysoltk import markImage
",5
"#
",5
"        s = cs.si.size
        self.registered_sizes[s] = self.registered_sizes.get(s, 0) + 1
        cs.updateCardback()
        ResourceManager.register(self, cs)

",5
"
    def _shuffleHook(self, cards):
",5
"# ---------------------------------------------------------------------------

import os
import traceback
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(frames=4)
        self.s.talon.dealCards()          # deal first card to WasteStack

",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"

",5
"
        # set window
        playcards = 5
",5
"# This program is distributed in the hope that it will be useful,
",5
"            try:
                s = six.text_type(s, 'utf-8')
",5
"
    def _setVbar(self, first, last):
        if self.canvas.busy:
            return
        sb = self.vbar
",5
"        # create stacks and layout
",5
"
    It supports all entity names required by the XHTML 1.0 Recommendation.
    It also defines handlers for all HTML 2.0 and many HTML 3.0 and 3.2
",5
"        if self.s.talon.cards or self.s.waste.cards:
            return False
",5
"            bsiz = c.coreSize
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"            # for backwards compatibility
            opt = unpickle(self.fn.opt)
",5
"        y = l.YM
        s.foundations.append(SS_FoundationStack(x, y, self, 4, max_cards=22))
        y = y + l.YS
        for i in range(4):
            s.foundations.append(
",5
"class MissMilligan_ReserveStack(AC_RowStack):
",5
"

",5
"
    #
    # Game layout
    #
",5
"    ""oaopooqaorvosaot"" +
",5
"    Talon_Class = Camelot_Talon
    RowStack_Class = StackWrapper(Camelot_RowStack, max_move=0)
    Hint_Class = Camelot_Hint

",5
"
        # Create talon
        x, y = -2*l.XS, 0               # invisible
",5
"            self.CARDW, self.CARDH = w, h
        else:
            if ((check_w and w != self.CARDW) or
",5
"                              self.menubar.mOptEnableHighlightCards)

            self.addCheckNode(tv, rg,
                              _('Enable highlight same rank'),
                              self.menubar.tkopt.highlight_samerank,
",5
"                      GI.GT_PAIRING_TYPE, 2, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(212, Weddings, ""Weddings"",
                      GI.GT_PAIRING_TYPE, 1, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(90, SimpleCarlo, ""Simple Carlo"",
",5
"            if font.lower() == self.font_family.lower():
                selected = n
                break
",5
"        GT_FAN_TYPE:            n_(""Fan""),
        GT_FORTY_THIEVES:       n_(""Forty Thieves""),
        GT_FREECELL:            n_(""FreeCell""),
        GT_GOLF:                n_(""Golf""),
",5
"        logging.info(""LApp: on_stop"")
        if self.startCode > 0:
            return
        # lapp: erweiterte klasse dieser (mit pysolfc app members).
        lapp = App.get_running_app()
",5
"            if 0:
                import urllib
                file = urllib.urlopen(url)
            else:
",5
"    def draw(self):
        nx, ny = self.style.originx, self.style.originy
        # Account for initial offsets, see topleft[xy] in BaseNode.draw().
        # We do this so that our bounding box always starts at (0,0)
        # and the yscrollincrement works nicely.
",5
"        self.game.updateMenus()

    def mOptEnableHighlightSameRank(self, *args):
",5
"
    def _isSequence(self, c1, c2):
        return ((c1.rank + self.cap.dir) % self.cap.mod == c2.rank and
                c1.color != c2.color)
",5
"            x += l.XS
",5
"        cards = self._shuffleHookMoveToTop(
            cards,
            lambda c: (c.rank == ACE, (c.deck, c.suit)))
        return cards

",5
"        # for InvisibleStack, etc
        # x, y = -500, -500 - len(game.allstacks)
        cardw, cardh = self.app.images.CARDW, self.app.images.CARDH
        x, y = cardw + self.canvas.xmargin, cardh + self.canvas.ymargin
        return -x-10, -y-10
",5
"        self.s.talon.dealCards()

",5
"                              self.menubar.mOptShisenShowHint)

            # submenu.add_separator()

        # -------------------------------------------
",5
"                    if r.acceptsCards(s, s.cards):
                        self.addHint(5000, 1, s, r)


",5
"class ProgressionFormatter:

    def __init__(self, app, player, gameid):
",5
"    ""ahsbascbsgasmaso"" +
    ""auaaughuhauiawih"" +
",5
"        self.registered_types = {}
        self.registered_sizes = {}
        self.registered_styles = {}
        self.registered_nationalities = {}
        self.registered_dates = {}
",5
"#  This program is free software: you can redistribute it and/or modify
",5
"    ""scoscasgasiaskas"" +
    ""oosohtdhtnaueoue"" +
    ""auiaumoumhvfhvla"" +
    ""wgowghwhawiowihw"" +
",5
"        lay, s = Layout(self), self.s
        self.setSize(lay.XM + 10*lay.XS, lay.YM + 4*(lay.YS+lay.YM))

        for i in range(2):
            x = lay.XM + i*lay.XS
",5
"        return ""break""


if __name__ == ""__main__"":
    tk = tkinter.Tk()
",5
"        for i in range(rows):
            s.rows.append(UD_AC_RowStack(x, y, self, mod=13))
            x += l.XS
",5
"        self.cardset = None             # current cardset
        self.cardsets_cache = {}
        self.tabletile_manager = TileManager()
        self.tabletile_index = 0        # current table tile
        self.sample_manager = SampleManager()
",5
"        # Do we accept receiving `cards' from `from_stack' ?
        return False
",5
"# ************************************************************************
# not used with kivy. dummy def.


",5
"            color = self.opt.colors['table']
            if self.tabletile_index > 0:
                color = ""#008200""
",5
"        recent_gameid = self._getOption('general', 'recent_gameid', 'list')
",5
"
# ************************************************************************
# * Batsford
# * Batsford Again
# ************************************************************************
",5
"        from pysollib.tk.fontsdialog import *  # noqa: F401,F403
        from pysollib.tk.solverdialog import *  # noqa: F401,F403
        from pysollib.tk.gameinfodialog import *  # noqa: F401,F403
        from pysollib.tk.toolbar import *  # noqa: F401,F403
        from pysollib.tk.statusbar import *  # noqa: F401,F403
",5
"            tag = ""href_"" + url
            self.text.tag_add(tag, self.anchor_mark, ""insert"")
            self.text.tag_bind(tag, ""<1>"", self.createCallback(url))
            self.text.tag_bind(
",5
"        if (len(cards) > 0):
            board += ' '.join(['Talon:'] +
",5
"        items.sort(key=lambda x: x[1])
        nodes = []
",5
"# ---------------------------------------------------------------------------#

",5
"        SS_FoundationStack, \
        SS_RowStack, \
",5
"    pass
",5
"        return _('Waste.')

",5
"    # game overrides
    #
",5
"                cap = Struct(base_rank=c.rank)
                self.game.saveinfo.stack_caps.append((s.id, cap))
",5
"        rows = self.s.rows[:4]
",5
"

# ************************************************************************
",5
"    #
    # wrappers
    #

    def _busy(self):
",5
"        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
        if self.cards:
",5
"#
# You should have received a copy of the GNU General Public License
",5
"    return platform

# =============================================================================
",5
"    label=_('Layout:'),
",5
"                s.foundations.append(
                    SS_FoundationStack(x, y, self, j, max_cards=14))
                x = x + l.XS
",5
"            self.fillTreeview(self.player)

    def headerClick(self, column):
        if column == '#0':
",5
"        for s in self.allstacks:
            for c in s.cards:
                if c.suit == suit and c.rank == rank:
                    if s.basicShallHighlightSameRank(c):
                        info.append((s, c, c, col))
",5
"        rows = []
",5
"  1, 0, GI.SL_MOSTLY_SKILL)
r(15414, Balarama, ""Balarama"", GI.GT_DASHAVATARA_GANJIFA, 1, 0,
  GI.SL_MOSTLY_SKILL)
r(15415, Hayagriva, ""Hayagriva"", GI.GT_DASHAVATARA_GANJIFA, 1, 0,
  GI.SL_MOSTLY_SKILL)
",5
"        self.prepareView()
        if self.is_visible:
            self.initBindings()
",5
"
    def getBaseCard(self):
        return self._getBaseCard()
",5
"        game = self.game
        row = game.s.rows
        if not self.cards or game.drag.stack is self or self.basicIsBlocked():
            return 1
        game.playSample(""move"", priority=10)
",5
"        got_s = game.calc_layout_string(ren)
        self.assertEqual(got_s, '''QD TC AS KC AH KH 6H
",5
"

class Canfield_RK_RowStack(RK_RowStack):
    def basicAcceptsCards(self, from_stack, cards):
",5
"                return
            old_state = self.enterState(self.S_FILL)
            from_stack.flipMove()
",5
"
        suit = 0
",5
"            elif stack in self.s.reserves and self.s.waste.cards:
                self.s.waste.moveMove(1, stack)
            self.leaveState(old_state)

",5
"class SelectGameNode(SelectDialogTreeNode):
",5
"        GT_SPIDER:              n_(""Spider""),
        GT_TERRACE:             n_(""Terrace""),
        GT_YUKON:               n_(""Yukon""),
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"            self.moveMove(1, talon, r, frames=0)

        self.leaveState(old_state)
",5
"        self.url = None
",5
"        self.version = VERSION
        self.version_tuple = VERSION_TUPLE
        self.cards = []
",5
"                if sequence in __mfx_wm_protocols:
",5
"
        s.talon = Tournament_Talon(l.XM, l.YM, self, max_rounds=3)
        l.createText(s.talon, ""se"")
        l.createRoundText(s.talon, 'ne')
",5
"
from pysollib.mygettext import n_

",5
"
",5
"[timeouts]
highlight_samerank = float(0.2, 9.9)
raise_card = float(0.2, 9.9)
demo = float(0.2, 9.9)
highlight_cards = float(0.2, 9.9)
",5
"            if stack in self.s.rows and len(stack.cards) == 0:
                self.s.talon.dealRow(rows=[stack])

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
",5
"    def hide(self, stack):
",5
"
",5
"
    def clear(self):
        self.nodes = {}
        self.keys = {}
        self.canvas.delete(""all"")
",5
"        if not c.face_up:
",5
"            return
        if self.getStuck():
            text = ''
        else:
            text = 'x'
",5
"        return self.canvas.itemconfig(self.id, _cnfmerge((cnf, kw)))

    def coords(self, pts=()):
        flat = ()
        for x, y in pts:
",5
"
    #
",5
"                    rw, tw = 4, 2
                c = self.game.cards[t.cards[-1].id - 52]
                if 1 and c in self.game.s.waste.cards:
                    rw = rw - 1
                #
",5
"            al = AnchorLayout()
",5
"            (_('Nationality:'),   nationalities),
            (_('Year:'),          year),
            # (_('Number of cards:'), str(cardset.ncards)),
",5
"from pysollib.settings import VERSION, VERSION_TUPLE


def pysolDumpGame(game_, p, bookmark=0):
",5
"        layout_stack.text_args[""font""] = \
            self.game.app.getFont(""canvas_default"")
        t = MfxCanvasText(self.game.canvas, **layout_stack.text_args)
        t.text_format = layout_stack.text_format
        return t
",5
"            # print ""end_font(%s)"" % `self.font`
            self.text.tag_add(self.font, self.font_mark, ""insert"")
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_SS

",5
"            return self._objects[index]
        return None

",5
"        )),

        #  KDE Patience 0.7.3 from KDE 1.1.2 (we have 6 out of 9 games)
",5
"            self.fillStack(stack)
        self.leaveState(old_state)


",5
"
# ************************************************************************
# * Three Fir-trees
# ************************************************************************
",5
"                              self.menubar.mOptEnableHint)

            self.addCheckNode(tv, rg,
                              _('Enable shuffle'),
                              self.menubar.tkopt.shuffle,
",5
"        # self.frame.config(cursor=self.defcursor)
        # self.frame.update_idletasks()
        self.text.config(state=""normal"")
",5
"from pysollib.mfxutil import KwStruct
from pysollib.mygettext import _
",5
"
        # Create foundations
        for r in l.s.foundations:
",5
"        ('animations', 'int'),
        ('redeal_animation', 'bool'),
",5
"            self.setBookmark(-1, confirm=0)
        except Exception:
",5
"        lay = Klondike.createGame(self, max_rounds=2, rows=10,
                                  playcards=24, round_text=True)
        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)


",5
"            s.rows.append(
",5
"                except Exception:
",5
"        self.setSize(l.XM + rows*l.XS, l.YM + 2*l.YS + playcards*l.XOFFSET)
",5
"    doubleclickHandler = OpenStack.doubleclickHandler


class Interment_Reserve(OpenStack):
    def canFlipCard(self):
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self,
                                              suit=ANY_SUIT,
                                              base_rank=ANY_RANK))
",5
"        for i in range(5):
            s.reserves.append(DoubleFives_WasteStack(x, y, self))
",5
"

class Hanafuda_SequenceStack(Flower_OpenStack):

    def acceptsCards(self, from_stack, cards):
",5
"                if not c.face_up:
                    cs = '<%s>' % cs
                b += cs + ' '
",5
"            return False
        # when empty, only accept a single card
        return self.cards or len(cards) == 1
",5
"        pout, perr = p.communicate(bytes_board)
        if p.returncode in (127, 1):
            # Linux and Windows return codes for ""command not found"" error
            raise RuntimeError('Solver exited with {}'.format(p.returncode))
        return BytesIO(pout), BytesIO(perr)
",5
"                l.XM + l.XS * 3, h - l.YM,
                anchor=""sw"",
                font=self.app.getFont(""canvas_default""))

",5
"            x0 += 2.5*l.XS

        x, y = l.XM, self.height - l.YS
        s.talon = Golf_Talon(x, y, self, max_rounds=1)
        l.createText(s.talon, 'n')
",5
"# ************************************************************************
# Kivy implementation of MfxScrolledCanvas.
",5
"        return -1, 0


# ************************************************************************
",5
"

",5
"
",5
"        RelaxedSpider.createGame(self, rows=13, playcards=24, texts=0)

    def startGame(self):
",5
"        '''
        buttonline.add_widget(self.homeButton)
        buttonline.add_widget(self.backButton)
        buttonline.add_widget(self.forwardButton)
",5
"        if texts:
            l.createText(s.talon, 'ne')
",5
"        geom = (self.app.canvas.winfo_width(),
                self.app.canvas.winfo_height())
        self.app.opt.game_geometry = geom
        self.app.game.resizeGame()
",5
"        if not ReserveStack.acceptsCards(self, from_stack, cards):
            return False
        return from_stack is self.game.s.talon
",5
"        if card1.suit != card2.suit:
            return 0
        if card1.suit == 3:
            if card1.rank >= 8:
                return card2.rank >= 8
",5
"                # if func and (event.state & ~2) == 0:
",5
"        InitialDealTalonStack, \
        OpenStack, \
        OpenTalonStack, \
",5
"        self.setRegion(self.s.rows, (0, 0, XS * rows // 2 + XM // 2, 999999))

        # create reserves
        x, y = w - XS * decks, YM + YS * 4
        for i in range(decks):
",5
"        l, s = Layout(self), self.s
",5
"    def createGame(self):
",5
"                stack = Mahjongg_Foundation(x, y, self)
                if show_removed:
                    stack.CARD_XOFFSET = dx
                    stack.CARD_YOFFSET = dy
                s.foundations.append(stack)
",5
"        # add to regions
        self.regions.data.append(
            (priority, -len(self.regions.data), tuple(stacks), tuple(rect)))

    # as getClosestStack() is called within the mouse motion handler
",5
"    GT_GOLF = 11
    GT_GYPSY = 12
    GT_HANAFUDA = 13
",5
"        for i in range(reserves//2):
            s.rows.append(ReserveStack(x, y, self))
            y += l.YS
",5
"    def __init__(self, x, y, game, xoffset, yoffset):
        OpenStack.__init__(self, x, y, game)
        self.CARD_YOFFSET = int(self.game.app.images.CARD_YOFFSET * yoffset)
        # use a sine wave for the x offsets
        self.CARD_XOFFSET = []
",5
"
",5
"        x1, x2 = l.XM, self.width - 2*l.XS
        for i in range(2):
            y = l.YM
",5
"    ""AabCabacbecbicbm"" +
    ""cbqcbucbycbCcbae"" +
",5
"    ""ocvAcvaevoevAeva"" +
    ""gvogvAgvaivoivAi"" +
    ""CadCodCAdCafCofC"" +
    ""AfCahCohCAh"")
",5
"        self.preview_game = gi.gameclass(gi)
",5
"    else:
        assert data is not None
        kw[""texture""] = data
        # ob das geht ?? - kommt das vor ?
",5
"    #

",5
"        BetsyRoss_Foundation.updateText(self, update_empty=False)


class One234_RowStack(BasicRowStack):
    # clickHandler = BasicRowStack.doubleclickHandler
",5
"        l.defaultStackGroups()

",5
"
    #
    # Game layout
    #
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()

    def _shuffleHook(self, cards):
",5
"        if (not self.basicAcceptsCards(from_stack, cards) or
                not self.isSuitSequence(cards)):
            return 0
",5
"# You should have received a copy of the GNU General Public License
",5
"
    def mOptFonts(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"            lost=lost, percentlost=int(round(100.0 * plost)))
        # text2 = 'Current Session:\n   won=%s, lost=%s\n' % (won, lost)

#        createChart(app, won, lost, _(""Current session""))

",5
"        elif br == 10:
            s = s % _('Jack')
        elif br == 11:
",5
"# -*- mode: python; coding: utf-8; -*-
",5
"    ""cAmcCmdEmeaodcoc"" +
    ""eocgobiobkoamoao"" +
",5
"    ""ahqhibhiihipajba"" +
",5
"        tx, ty = x + tx + lay.XM, y + ty
        font = self.app.getFont(""canvas_default"")
        self.texts.info = MfxCanvasText(
",5
"        self.closeButton.grid(row=0, column=3, sticky='e')
",5
"class Pantagruel(DoubleKlondike):
    RowStack_Class = AC_RowStack

",5
"                                        manager=self.app.tabletile_manager,
                                        key=key)
",5
"        l.createText(s.talon, 's')
        y += l.YS+2*l.YM
        for i in range(4):
            s.reserves.append(OpenStack(x, y, self, max_accept=0))
            y += l.YS
",5
"
    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"        # register tiles
        found.sort()
        for f in found:
            obj = f[1]
",5
"        return MfxDialog.initKw(self, kw)

    def destroy(self):
        self.app = None
",5
"        else:
            pixbuf = image.pixbuf
        w, h = self.get_size()
        iw, ih = pixbuf.get_width(), pixbuf.get_height()
",5
"        # cb = (25, self.cb_max) [ len(g) > 4 * 25 ]
",5
"
        text1 = _('Total:\n' +
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"
",5
"            self.tkraise(unhide)
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED,
                      altnames=(""Maria Luisa"",)))
registerGame(GameInfo(70, NumberTen, ""Number Ten"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
",5
"    pass
",5
"            self.gameid = self.tree.selection_key
",5
"# ************************************************************************
# * window manager util
",5
"        self.setSize(l.XM + maxrows*l.XS, l.YM + l.YS + h + l.YS)

",5
"        # define stack-groups
",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        # check that the base card is correct
        suits = list(range(self.cap.mod, (self.cap.mod + 4)))
        if self.cards and (self.cards[0].rank == 3 and
",5
"class Hurricane_Hint(DefaultHint):
    def step010(self, dropstacks, rows):
        rows = rows + self.game.s.reserves
",5
"    L = (14, 6)
    NCARDS = 84
",5
"            self.s.talon.dealRow(rows=self.s.rows[:17], flip=0, frames=0)
        self._startAndDealRow()

",5
"            Color(self.bcolor[0], self.bcolor[1],
                  self.bcolor[2], self.bcolor[3])
            Line(points=poly, width=wpoly, cap='none', joint='bevel')
            if (len(atrio) > 2):
",5
"                      GI.GT_KLONDIKE, 2, 1, GI.SL_BALANCED))
registerGame(GameInfo(333, OpenJumbo, ""Open Jumbo"",
",5
"                (self.base_cards[i].rank + 1) % 13
            self.flipMove(self.s.talon)
            self.moveMove(1, self.s.talon, self.s.reserves[i])

    def getAutoStacks(self, event=None):
",5
"
",5
"# * Tree database
# ************************************************************************
",5
"        d = GameDrag()
        d.shadows.append(""test"")
",5
"    data = None


class SelectGameTree(SelectGameTreeWithPreview):
    def singleClick(self, event=None):
",5
"registerGame(GameInfo(77, Stalactites, ""Stalactites"",
                      GI.GT_FREECELL | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
                      altnames=(""Grampus"", ""Old Mole"")))
registerGame(GameInfo(264, DoubleFreecell, ""Double FreeCell"",
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"        game.moveMove(1, swap2, self, frames=0)
        for i in range(ncards):
            game.moveMove(1, swap, self, frames=0)
        if not self.cards[-1].face_up:
            game.flipMove(self)
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
",5
"

",5
"
class ColorsDialog:
",5
"            if relpath and baseurl and not os.path.isabs(url):
                h1, t1 = os.path.split(url)
                h2, t2 = os.path.split(baseurl)
",5
"                    ((((card1.suit + 1) % 12) == card2.suit) or
                     (((card1.suit - 1) % 12) == card2.suit)))
        else:
",5
"            for t in s.blockmap.right:
",5
"
",5
"            rows = self.game.s.rows
        return self.dealRowAvail(rows=rows, sound=sound)
",5
"        self.event_handled = False      # if click event handled by Stack (???)
",5
"# ************************************************************************
# * Barrier
",5
"        x, y = lay.XM+(max_rows-rows)*lay.XS//2, lay.YM+lay.YS+lay.TEXT_HEIGHT
        for i in range(rows):
            s.rows.append(self.RowStack_Class(x, y, self))
",5
"            raise OSError(str(argv0)+"": DataLoader could not find "" +
                          str(filenames))
",5
"from .selecttree import SelectDialogTreeLeaf, SelectDialogTreeNode
from .tkwidget import MfxDialog, MfxScrolledCanvas
",5
"        else:
            t = gettext.translation(
",5
"    Result := False;
  end;
 end;
",5
"            self.app.opt.scale_y += 0.1
        else:
            return
        self.app.opt.auto_scale = False
",5
"registerGame(GameInfo(525, Queensland, ""Queensland"",
                      GI.GT_YUKON, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(530, RussianSpider, ""Russian Spider"",
                      GI.GT_SPIDER, 1, 0, GI.SL_BALANCED,
                      altnames=('Ukrainian Solitaire',)))
",5
"                stack = UD_SS_RowStack(x, y, self, base_rank=NO_RANK)
",5
"# * Note: Applications should call show/hide after constructor.
",5
"        self.pbar.set_text(str(percent)+'%')
",5
"# GNU General Public License for more details.
",5
"            return
        self.app.opt.highlight_not_matching = \
            self.tkopt.highlight_not_matching.get()
        # self.game.updateMenus()
",5
"#    ""eieeigdiieikekae"" +
#    ""kkemadmcemeemgdm"" +
#    ""iemkeoaeokeqadqc"" +
",5
"class SeniorWrangler(Game):

    def createGame(self):
        l, s = Layout(self), self.s
",5
"        l.createText(s.talon, anchor=""n"", text_format=""%D"")
        s.internals.append(InvisibleStack(self))

        # define stack-groups
        l.defaultStackGroups()
",5
"from pysollib.mfxutil import KwStruct
from pysollib.mygettext import _
",5
"        l.defaultStackGroups()
",5
"# ************************************************************************

class Skippy(Canfield):
    FILL_EMPTY_ROWS = 0
",5
"        self.formatter.push_font((AS_IS, AS_IS, AS_IS, 1))
",5
"        for c in cards[:]:
            if c.rank == KING:
",5
"            self.game.moveMove(1, self.game.s.braid, self)

    getBottomImage = Stack._getBraidBottomImage
",5
"                                                   yoffset=l.CH//4,
                                                   max_cards=8, max_accept=8))
                x = x + l.XS
        self.setRegion(s.rows, (0, 0, l.XS * 4, 999999))
",5
"        Mississippi.startGame(self, flip=1)


# ************************************************************************
# * Blockade
",5
"    values_map=((n_('Up'), 1), (n_('Down'), -1)),
    default=n_('Down'),
    label=_('Direction:'),
    var_name='rows_dir',
",5
"# ************************************************************************

class SPatience(Game):
    Hint_Class = Calculation_Hint
",5
"                           self.cards[-1].suit in suits):
            return self.isHanafudaSequence([self.cards[-1], cards[0]])
        return not self.cards and cards[0].rank == 3 and cards[0].suit in suits

    def getBottomImage(self):
",5
"
    def dealCards(self, sound=False):
        n = self.redealCards1()
        if n == 0:
",5
"        return None

    # get the largest moveable pile {model} - uses canMoveCards()
",5
"# ************************************************************************
# * Mount Olympus
# * Zeus
# ************************************************************************

",5
"
    def isGameWon(self):
",5
"    def __init__(self, x, y, game, **cap):
        kwdefault(cap, max_move=999999, max_accept=999999)
        BasicRowStack.__init__(self, x, y, game, **cap)
",5
"class PictureGallery_Hint(AbstractHint):
    def computeHints(self):
        game = self.game

",5
"
    #
",5
"        if d.status == 0 and d.button == 0 and d.gameid != self.game.id:
            self.tkopt.gameid.set(d.gameid)
            self.tkopt.gameid_popular.set(d.gameid)
",5
"    ""evfgvhgvjgvlgvng"" +
    ""vpgvrgvhivjivliv"" +
",5
"            dx = event.x - (x_offset+cw+sx) - game.canvas.xmargin
            dy = event.y - (y_offset+ch+sy) - game.canvas.ymargin
            if dx < 0:
                dx = 0
            if dy < 0:
",5
"# * Osmosis
# ************************************************************************

",5
"
        x, y = 3*l.XM+4*l.XS, l.YM
        for i in range(reserves//2):
            s.rows.append(ReserveStack(x, y, self))
",5
"            ('file',           None, ltk2gtk('&File')),
            ('recentgames',    None, ltk2gtk('R&ecent games')),
            ('favoritegames',  None, ltk2gtk('Fa&vorite games')),
            ('select',         None, ltk2gtk('&Select')),
            ('edit',           None, ltk2gtk('&Edit')),
",5
"        self.sample_loop = 0

    def stopSamplesLoop(self):
",5
"                deck, suit, rank), anchor=""nw"")
        self.__back = MfxCanvasImage(
            game.canvas, self.x, self.y, image=game.getCardBackImage(
",5
"        if not self.game.s.talon.cards:
            return
        c = self.game.s.talon.cards[-1].rank
",5
"        for i in range(len(s) - 1):
            if s[i].suit != s[i + 1].suit:
",5
"            elif self.game.s.braidstrong.cards:
                self.game.moveMove(1, self.game.s.braidstrong, self)

    def getBottomImage(self):
",5
"    #

    def startGame(self):
        n = 1
        for i in range(4):
",5
"    # return Image(source=image.source)
    # return Image(texture=image.texture)
",5
"            self.moveMove(n, self.s.talon, self.s.internals[0], frames=0)
        self.startDealSample()
        rows = list(self.s.rows[:])
        rows.remove(rows[self.EMPTY_STACK_ID])
",5
"        # print('writer: anchor_end')
        if self.anchor:

            self.anchor = None
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"    def __init__(self, values_map, default, var_name,
",5
"from __future__ import division

import logging
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"            return False

        self_index, self_row = self._getStackIndex(self)

        if self_row in (1, 2):
",5
"            r.delete_deferred(self.app.opt.timeouts['highlight_cards'])
            return

        self.canvas.update_idletasks()
        self.sleep(self.app.opt.timeouts['highlight_cards'])
",5
"    Hint_Class = ShadyLanes_Hint

    def createGame(self):
",5
"            kw['width_pixels'] = width
        if fill:
",5
"    def createGame(self, **layout):
        Balarama.createGame(self, reserves=4)
",5
"        for r in self.s.rows[:8]:
            for j in range(6):
                self.s.talon.dealRow(rows=[r], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[8:])
",5
"
",5
"        Stack
from pysollib.util import ACE, JACK, KING, QUEEN
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"Straight Flush
Four of a Kind
Full House
Flush
Straight
",5
"        if rg:
            self.addCheckNode(tv, rg,
",5
"                not stack.acceptsCards(self, pile[-1:])):
            return (None, 0)
",5
"
    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
            return False
        # [topcard + card[0]] must be acceptable
",5
"        self.top_bg = None              # default background
        self.top_cursor = None          # default cursor
        self.menubar = None
        self.toolbar = None
",5
"            self.s.talon.dealRow(rows=r[i:len(r)-i], flip=0, frames=0)
        self._startAndDealRow()

",5
"                 'any face-up cards regardless of sequence.')
",5
"        if list(filter(select_mahjongg_game, self.all_games_gi)):
            gg = SelectGameNode(None, _(""Mahjongg Games""),
                                select_mahjongg_game)
        g.append(gg)
",5
"            traceback.print_exc()
            default_font = ('times new roman', 12)
            fixed_font = ('courier', 12)
        size = default_font[1]
        sign = 1
",5
"        WasteTalonStack
",5
"
# ************************************************************************
# * House in the Wood
# * House on the Hill
",5
"                app.tabletile_index = tile.index
                break

",5
"    TYPE_NAMES = {
        GT_BAKERS_DOZEN:        n_(""Baker's Dozen""),
",5
"
class Cruel(CastlesInSpain):
    Talon_Class = StackWrapper(Cruel_Talon, max_rounds=-1)
    RowStack_Class = StackWrapper(SS_RowStack, base_rank=NO_RANK)
    # Solver_Class = FreeCellSolverWrapper(preset='cruel')
",5
"            im.set_property('xpad', kw['bitmap_padx'])
            im.set_property('ypad', kw['bitmap_pady'])
",5
"    #  - center: two groups of rows
    #  - lower right: talon
    #
",5
"        x = l.XM
        y = l.YM
        for i in range(4):
            s.foundations.append(
                SS_FoundationStack(
",5
"        root.option_add('*Scrollbar.borderWidth', 1, 60)
        root.option_add('*Menu.borderWidth', 1, 60)
        root.option_add('*Menu.activeBorderWidth', 1, 60)
        # root.option_add('*Button.HighlightBackground', '#595d59')
",5
"        for r in game.s.rows:
            if r.cards:
                stacks.append(r)
        # find matching tiles
        i = 0
",5
"            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
",5
"    def createGame(self):
        Klondike.createGame(self, max_rounds=1, num_deal=3)
",5
"        print('MfxCanvas: wmain = %s' % self.wmain)

        # Tkinter.Canvas.__init__(self, *args, **kw)
        self.preview = 0
",5
"            return
        self.game.setCursor(cursor=CURSOR_WATCH)
        bookmark = None
",5
"            cards, lambda c: (c.rank == 0, c.suit), 1)
",5
"        self.p(s)

    def plog(self, gamename, gamenumber, date, status, gameid=-1, won=-1):
        self.p(""%-25s %-20s  %17s  %s\n"" %
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"            100, 105, 111, 112, 113, 130, 139, 144, 146, 147, 148, 200,
            201, 206, 224, 225, 229, 230, 233, 257, 258, 280, 281, 282,
",5
"    def new_font(self, font):
",5
"                    lambda cs: not cs.si.nationalities))
",5
"class Rushdike(RussianSolitaire):
    Layout_Method = staticmethod(Layout.klondikeLayout)
    Talon_Class = DealRowTalonStack

",5
"    def initBindings(self):
        bind(self.group, ""<1>"", self._Stack__clickEventHandler)
        bind(self.group, ""<Control-1>"", self._Stack__controlclickEventHandler)
",5
"        self.fillStack()

    def fillStack(self, stack=None):
        old_state = self.enterState(self.S_FILL)
",5
"
    def acceptsCards(self, from_stack, cards):
",5
"# register the game
registerGame(GameInfo(35, UnionSquare, ""Union Square"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_SKILL,
                      altnames=('British Square',),
",5
"    default=0,
    label=_('Use ""Super Move"" feature:'),
    var_name='rows_super_move',
    widget='check',
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------#
# Note:
# Many classes or some methods of classes are dead code resulting from the tk
",5
"            cards, lambda c: (c.rank == ACE, c.suit))

    def fillStack(self, stack):
",5
"            s.rows.append(stack)

        # southern hemisphere (black)
        for xx, yy in ((6.5, 3),
",5
"        self.s.talon.dealCards()

    shallHighlightMatch = Game._shallHighlightMatch_SS


",5
"            if len(cards) != 1 and len(cards) != len(from_stack.cards):
",5
"        return self.size[1]

# =============================================================================


",5
"    # other utility methods
    #
",5
"        # random generators
",5
"class SelectDialogTreeNode(MfxTreeNode):
    def __init__(self, tree, text, select_func, expanded=0, parent_node=None):
",5
"    Talon_Class = GroundsForADivorce_Talon
    Foundation_Class = StackWrapper(
        Spider_SS_Foundation, base_rank=ANY_RANK, mod=13)
    RowStack_Class = StackWrapper(Spider_RowStack, mod=13)

",5
"    Foundation_Class = SS_FoundationStack
    # RowStack_Class = RK_RowStack
    RowStack_Class = SuperMoveRK_RowStack

    #
",5
"# This program is free software; you can redistribute it and/or modify
",5
"            return False
        for w in self._widgets:
            if w.visible:
",5
"        # create layout
        l, s = Layout(self), self.s
        kwdefault(layout, rows=10, waste=0, texts=1, playcards=23)
        self.Layout_Method(l, **layout)
",5
"    ""opehpgapiopihpko"" +
",5
"        if not self.cards and self.game.s.braid.cards:
",5
"        return ""disabled""

",5
"KH 6H 6C TC 2C 7D
''', 'ms100001')
",5
"            x = l.XM
            for j in range(4):
                s.foundations.append(SS_FoundationStack(x, y, self,
",5
"                return
        self.top.screenshot(fn)
",5
"class Realm(Game):

    Hint_Class = CautiousDefaultHint
    RowStack_Class = StackWrapper(UD_AC_RowStack, base_rank=NO_RANK)

",5
"
class MfxDialog:  # ex. _ToplevelDialog
    img = {}
    button_img = {}
",5
"        if from_stack in self.game.s.rows and \
                len(cards) != len(from_stack.cards):
",5
"    def do_p(self, attrs):
        self.formatter.end_paragraph(1)

    def start_pre(self, attrs):
        self.formatter.end_paragraph(1)
",5
"    def createGame(self):
        # create layout
",5
"
class BaseSelectDialogTreeNode:
    def __init__(self, tree, text, select_func, expanded=0, parent_node=None):
",5
"        self._item.set(pixbuf=image.pixbuf)


class MfxCanvasLine(_CanvasItem):
",5
"
class OddAndEven(RoyalCotillion):
    def createGame(self):
        # create layout
",5
"        idir, ifile = os.path.split(os.path.normpath(filename))
        if not idir:
",5
"#    ""aChcCheChghiavia"" +
#    ""aicpichievieaigp"" +
#    ""igakaqkahkcwkcak"" +
#    ""eqkehkgwkghmawma"" +
",5
"            all_games_stat = GameStat('all')
            self.games_stats[player]['all'] = all_games_stat
",5
"        # default: all Foundations must be filled
",5
"
    def createGame(self, **layout):
",5
"        return False


",5
"        self.s.talon.dealRow()
        self.s.talon.dealCards()

    def fillStack(self, stack):
",5
"
class KivyAudioClient(AbstractAudioClient):

",5
"    if TOOLKIT == 'gtk':
        pass
    elif USE_TILE:
",5
"            self.s.talon.dealRow(rows=r, frames=0)
        self.startDealSample()
",5
"    return normalize(layout)
",5
"
class Shisen_RowStack(Mahjongg_RowStack):

    def basicIsBlocked(self):
",5
"            self, parent, title=_(""Game status""),
            text=game.getTitleName() + ""\n"" +
            game.getGameNumber(format=1) + ""\n"" +
            _(""Playing time: "") + game.getTime() + ""\n"" +
",5
"# ************************************************************************

class Aglet(Game):
",5
"            if r.cards and stack.acceptsCards(r, r.cards[-1:]):
                r.moveMove(1, stack)
        if r.canFlipCard():
            r.flipMove()

",5
"
",5
"

# ************************************************************************
# * Toni
",5
"            pass
        return True
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"    #

    def startMoves(self):
        self.moves = GameMoves()
",5
"
    def gotoBookmark(self, n, confirm=-1, update_stats=1):
        self.finishMove()       # just in case
        bm = self.gsaveinfo.bookmarks.get(n)
        if not bm:
",5
"    # return n
    n = n.encode('iso8859-1', 'replace')
    # FIXME: rewrite this for better speed
",5
"    def isGameWon(self):
",5
"# GNU General Public License for more details.
#
",5
"            y += h0

        x, y = l.XM, self.height-l.YS
",5
"        return ReserveStack.acceptsCards(self, from_stack, cards)

    def getBottomImage(self):
        return self.game.app.images.getTalonBottom()
",5
"registerGame(GameInfo(630, BigBertha, ""Big Bertha"",
                      GI.GT_RAGLAN | GI.GT_OPEN, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(633, Athena, ""Athena"",
                      GI.GT_KLONDIKE, 1, -1, GI.SL_BALANCED))
",5
"                s.rows.append(stack)
",5
"        WasteTalonStack, \
        Yukon_AC_RowStack, \
        Yukon_RK_RowStack, \
        Yukon_SS_RowStack
",5
"                self.showTop(gameid, top)
            b = ttk.Button(frame, text=TOP_TITLE+' ...',
                           width=10, command=command)
            b.grid(row=row, column=5)
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.games.spider import Spider_Hint, Spider_RowStack, \
        Spider_SS_Foundation
from pysollib.hint import KlondikeType_Hint, YukonType_Hint
",5
"                                  font=self.app.getFont(""canvas_default""))
                self.texts.list.append(t)
            for i in range(20, 25):
",5
"            # solid color
            canvas.config(bg=key)
            canvas.setTile(None)
            canvas.setTextColor(None)
",5
"            ('name',        name),
            ('altnames',    altnames),
            ('category',    category),
            ('type',        type),
            ('skill_level', skill_level),
",5
"        if isinstance(node, self._calc_MfxTreeLeaf()):
            if node.key is not None:
                self.n_selections = self.n_selections + 1
                self.updateSelection(node.key)
",5
"        return r

",5
"                rows.append(stack)
                x = x + l.XS
        # compute blocking
        n = 0
        for i in range(size-1):
",5
"registerGame(GameInfo(620, LesQuatreCoins, ""Les Quatre Coins"",
                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_MOSTLY_SKILL))
",5
"    ""kdqaaqcdqeaqgdqi"" +
",5
"                  max_accept=UNLIMITED_ACCEPTS, base_rank=0, dir=-1)
        OpenStack.__init__(self, x, y, game, **cap)
        self.CARD_YOFFSET = yoffset

",5
"        x, y = l.XM, l.YM
        for j in range(5):
",5
"        for s in self.allstacks:
            sd = (s.__class__.__name__, s.cap.base_rank, s.cap.dir)
",5
"        self.Layout_Method(l, **layout)
",5
"        if stack_dir == 0:
",5
"
class ThreePirates(Game):
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"
class RoyalAids(Game):
",5
"                s.rows.append(
                    PasDeDeux_RowStack(x, y, self, max_accept=1, max_cards=2))
        x, y = self.width - 2*l.XS, self.height - l.YS
        s.talon = WasteTalonStack(x, y, self, max_rounds=2)
        l.createText(s.talon, ""se"")
",5
"        if self.list_box.curselection():
            self.font_family = self.list_box.get(self.list_box.curselection())
",5
"from pysollib.mygettext import _
from pysollib.options import Options
from pysollib.pysolrandom import PysolRandom, constructRandom
from pysollib.pysoltk import HTMLViewer
",5
"                self.corePoly.append(y)
                if x < xmin:
                    xmin = x
",5
"            helpbar=BooleanVar(),
            save_games_geometry=BooleanVar(),
            splashscreen=BooleanVar(),
            demo_logo=BooleanVar(),
            mouse_type=StringVar(),
",5
"from pysollib.layout import Layout
from pysollib.stack import \
",5
"# (at your option) any later version.
",5
"                self.s.talon.flipMove()
                self.s.talon.moveMove(1, stack)
",5
"        for s in game.s.foundations:
            n = n + len(s.cards)
        w1 = (_(""Highlight piles: "") + str(stats.highlight_piles) + ""\n"" +
",5
"        for r in l.s.foundations:
",5
"    def _playSample(self, filename, priority, loop, volume):
        # print '_playSample:', filename, priority, loop, volume
        if self.sound_channel and self.sound_channel.get_busy():
            if self.sound_priority >= priority:
",5
"            # ch = max(int(self.cget(""height"")),  self.winfo_height())
            ch = self.winfo_height()
        # print iw, ih, cw, ch
",5
"    def send_flowing_data(self, data):
",5
"        for s in self.s.rows:
            s.cap.update(cap.__dict__)
",5
"    def getLogResults(self, player, prev_games):
        t_won, tlost = 0, 0
",5
"                    event.y = ppos[1]
                    event.cardid = i
                    stack._motionEventHandler(event)
                    return True

",5
"    button.pack(side=tkinter.RIGHT)
    if Image:
        global rotate_var, filter_var
        rotate_var = tkinter.IntVar(root)
",5
"#
#   - Each card is a canvas group consisting of a background and foreground
#     image. Turning a card raises the respective image within that group.
#
",5
"        self._startDealNumRows(3)
        for i in range(2):
            self.s.talon.dealRow()
",5
"            if len(s.cards) == len(self.cards) and isRankSequence(s.cards):
                return 1
        return 0


",5
"    def calc_info(self, xf, yf):
        """"""docstring for calc_info""""""
",5
"            self.top, title=_(""Incompatible cardset""),
            bitmap=""warning"",
            text=_('''The currently selected cardset %(cardset)s
is not compatible with the game
%(game)s
",5
"
        # set window
        w, h = max(2*l.XM+2*l.XS+(5+13)*l.XOFFSET, l.XM + 8*l.XS), l.YM+8*l.YS
",5
"
",5
"        # set window
        w, h = 3*l.XM+6*l.XS, 3*l.YM+4*l.YS
        self.setSize(w, h)

        # create stacks
",5
"        # and the yscrollincrement works nicely.
",5
"from . import osmosis  # noqa: F401
from . import parallels  # noqa: F401
from . import pasdedeux  # noqa: F401
",5
"        if d.gameid != self.game.id:
            self.tkopt.gameid.set(d.gameid)
            self.tkopt.gameid_popular.set(d.gameid)
            self._cancelDrag()
",5
"                        return self._returnHints()
        # 3) ask subclass to do something useful
",5
"class TwoRings(Game):

    def createGame(self, max_rounds=2):
",5
"        return 1

",5
"        # filename = self.game.filename
        filename = ""lastgame.pso""
        if filename:
            idir, ifile = os.path.split(os.path.normpath(filename))
        else:
",5
"            win.draw_arc(gc, False, x, y+dy, w, h, s*64, ewon*64)
",5
"        info_frame.grid(row=0, column=0, columnspan=2, sticky='ew',
                        padx=0, pady=5, ipadx=5, ipady=5)
",5
"        if path in path_map:
            path = path_map[path]
        else:
            path = '/menubar/'+path.replace('.', '/')
        menuitem = self.top.ui_manager.get_widget(path)
",5
"        if os.name == 'nt':
            lang, enc = locale.getdefaultlocale()
",5
"        # print '_sizeAllocate', rect.x, rect.y, rect.width, rect.height
        if self._width > 0:
            w = self._width
            h = min(self._height, rect.height)
",5
"
",5
"            x += l.XS
        tx, ty, ta, tf = l.getTextAttr(s.foundations[0], ""sw"")
",5
"# * Selective Castle
# ************************************************************************

class SelectiveCastle_RowStack(RK_RowStack):
",5
"            return
        side = self.tkopt.statusbar.get()
        self.app.opt.statusbar = side
        resize = not self.app.opt.save_games_geometry
",5
"
",5
"
    def createText(self, stack, anchor, dx=0, dy=0, text_format=""""):
        if self.canvas.preview > 1:
",5
"
    def _getMoveCardBonus(self, r, t, pile, rpile):
",5
"        return self.__all_games.get(key)

    def _check_game(self, gi):
        # print 'check game:', gi.id, gi.short_name.encode('utf-8')
        if gi.id in self.__all_games:
",5
"        self.preview.canvas.preview = 2
        # create a preview of the current game
        self.preview_key = -1
",5
"            self.preview_app.opt.shadow = 0
            self.preview_app.opt.shade = 0
        #
        self.preview_app.audio = None    # turn off audio for initial dealing
        if animations >= 0:
",5
"            return
        if not self.texts.info:
",5
"            x += l.XS
        x, y = self.width-rows*l.XS, l.YM+l.YS
        for i in range(rows):
",5
"
    def fillStack(self, stack):
",5
"    ""mhjmhnmhtmhxmhDm"" +
    ""hgphqphApogcoqco"" +
    ""Acoceokeomeoueow"" +
    ""eoEeoggoqgoAgoci"" +
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"    ""hhhjhhvhhxhhfihl"" +
    ""ihtihzihblhhlhxl"" +
    ""hDlhdmhfmhzmhBmh"" +
",5
"                    SelectGameNode(None, _(""No redeal""),
                                   lambda gi: gi.si.redeals == 0),
",5
"def zoom_in(*args):
    global zoom
    zoom += 1
    show_cardset()

",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"        return 1
",5
"r(5227, ""Kyodai 18"", layout=""0daidchdcjdegdek"" +
",5
"            s.rows.append(LadiesBattle_RowStack(x, y, self,
                                                max_move=1, mod=13))
            x = x + l.XS
        x, y = l.XM, l.YM+l.YS//2
",5
"
class Repair(FreeCell):
",5
"        for i in range(4):
            s.foundations.append(RK_FoundationStack(x, y, self, suit=ANY_SUIT))
            x += l.XS

",5
"                    self.make_vars_command(self.menubar.mOptSoundSample, key))
                key = 'startdrag'
                self.addCheckNode(
",5
"
",5
"
class TopsyTurvyQueens(LockedCards):
    Foundation_Class = StackWrapper(LockedCards_Foundation,
                                    base_rank=KING, mod=13)
",5
"    def send_hor_rule(self, *args):
        width = int(int(self.text[""width""]) * 0.9)
        self.write(""_"" * width)
        self.write(""\n"")
",5
"        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == KING and c.deck == 0, c.suit))
",5
"        return self.game.dealCards(sound=True)

    def rightclickHandler(self, event):
        return self.clickHandler(event)
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"                         if f not in icon_blacklist]
            except OSError:
                icons = []
        return filter(os.path.isfile, icons)
",5
"        self.version = game.version
        self.version_tuple = game.version_tuple
",5
"        for i in range(rows):
            stack = self.RowStack_Class(x, y, self, mod=13, max_accept=1)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, 0
            s.rows.append(stack)
",5
"                    continue
                rr = self.ClonedStack(r, stackcards=r.cards[:-1])
                if rr.acceptsCards(None, pile):
                    # do not move a card that is already in correct place
                    continue
",5
"            'the': game.s.foundations,
            'stack': game.s.rows,
            'freecell': game.s.reserves,
            }
        if DEBUG:
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"            return 0
        return self.cardsMatch(card1, card2)

    def getAutoStacks(self, event=None):
",5
"
pysollib.stack.MfxCanvasGroup = _empty_override
# Written by Shlomi Fish, under the MIT Expat License.

import unittest
",5
"

class Roslin(Yukon):
    RowStack_Class = StackWrapper(Roslin_RowStack, base_rank=KING)

",5
"                      GI.GT_FAN_TYPE, 2, 0, GI.SL_BALANCED))
",5
"from torch_geometric.datasets import Planetoid
from torch_geometric.nn import Node2Vec

",6
"    out_2 = set2set(x_2, batch_2).view(-1)
",6
"        assert is_debug_enabled() is True
    assert is_debug_enabled() is False
import torch
",6
"def test_to_networkx():
",6
"        log_prob_sub = F.log_softmax(self.obj_lin(h_obj), dim=1)

        return log_prob_obj, log_prob_sub

",6
"
    @property
    def raw_dir(self):
        return osp.join(self.root, 'raw')
",6
"                x, adj, _, _ = dense_diff_pool(x, adj, s)

        x = self.jump(xs)
        x = F.relu(self.lin1(x))
",6
"    accs = test()
    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, '
          f'Val: {accs[1]:.4f}, Test: {accs[2]:.4f}')
import os.path as osp
",6
"
        edge_index = pandas.read_csv(edges_file, sep=' ', header=None,
",6
"          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))
import os.path as osp

",6
"from .linear_transformation import LinearTransformation
from .random_scale import RandomScale
from .random_rotate import RandomRotate
from .random_shear import RandomShear
from .normalize_features import NormalizeFeatures
",6
"import torch
import torch.nn.functional as F
from torch_sparse import coalesce
from torch_geometric.io import parse_txt_array
from torch_geometric.data import Data
",6
"
    edge_index = torch.tensor([[0, 2, 1, 0], [2, 0, 1, 0]])
    edge_attr = torch.tensor([1, 2, 3, 4])
    x = torch.tensor([[1], [2], [3]])
",6
"
    otherwise.
    In case :obj:`first_aggr` is :obj:`False`, the layer expects :obj:`x` to be
    a tensor where :obj:`x[:, :in_channels]` denotes the positive node features
    :math:`\mathbf{X}^{(\textrm{pos})}` and :obj:`x[:, in_channels:]` denotes
",6
"        return F.log_softmax(x, dim=-1)


",6
"        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

",6
"    data = Data(pos=pos)
    data = RandomTranslate(0)(data)
    assert len(data) == 1
    assert data.pos.tolist() == pos.tolist()
",6
"    loss = total_loss / len(train_loader)
    approx_acc = total_correct / train_idx.size(0)
",6
"    def __repr__(self):
        return (f'{self.__class__.__name__}('
",6
"                        self.cached_num_edges, edge_index.size(1)))

        if not self.cached:
            x = self.lin(x)
",6
"
def test_set2set():
    set2set = Set2Set(in_channels=2, processing_steps=1)
    assert set2set.__repr__() == 'Set2Set(2, 4)'
",6
"        self.nn = nn
        self.initial_eps = eps
",6
"    assert data.edge_attr.tolist() == [[1, 0.5], [0.25, 0.5], [1, 0.5],
                                       [0, 0.5]]

",6
"
    :rtype: (:class:`Tensor`, :class:`LongTensor`) if :attr:`size` is
        :obj:`None`, else :class:`Tensor`
    """"""
    if size is not None:
",6
"    assert data.pos.tolist() == [[-2, 0], [0, 0], [2, 0]]
    assert data.edge_index.tolist() == [[0, 0, 1, 1, 1, 2, 2],
                                        [0, 1, 0, 1, 2, 1, 2]]
",6
"    hidden_channels=200,
    seq_len=seq_len,
    dropout=0.5,
).to(device)
optimizer = torch.optim.Adam(
",6
"
    loop_index = torch.arange(0, num_nodes, dtype=row.dtype, device=row.device)
    loop_index = loop_index.unsqueeze(0).repeat(2, 1)
    edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)

",6
"
",6
"        x, edge_index = data.x, data.edge_index
        x = F.dropout(x, p=0.6, training=self.training)
        x = F.elu(self.conv1(x, edge_index))
        x = F.dropout(x, p=0.6, training=self.training)
",6
"import torch
import torch.nn as nn
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv, DeepGraphInfomax
",6
"class GraphSAINTEdgeSampler(GraphSAINTSampler):
    r""""""The GraphSAINT edge sampler class (see
    :class:`torch_geometric.data.GraphSAINTSampler`).

",6
"    Args:
",6
"        self.up_convs = torch.nn.ModuleList()
        for i in range(depth - 1):
            self.up_convs.append(GCNConv(in_channels, channels, improved=True))
",6
"        assert key.size(-2) == value.size(-2)

        query = self.lin_q(query)
        key = self.lin_k(key)
        value = self.lin_v(value)
",6
"
    .. math::
        \mathbf{x}^{\prime}_i = h_{\mathbf{\Theta}} \left( (1 + \epsilon) \cdot
        \mathbf{x}_i + \sum_{j \in \mathcal{N}(i)} \mathbf{x}_j \right)
",6
"            cached version for further executions.
",6
"    def raw_file_names(self):
        return '{}.npz'.format(self.name)

    @property
    def processed_file_names(self):
",6
"            N = row.size(0) // 2
            joints, _ = coalesce(joints, None, N, N)

",6
"    def forward(self, edge_index, edge_type, edge_norm):
",6
"    def coalesce(self):
",6
"
class RandomScale(object):
",6
"
    data = Data(pos=pos)
    data = transform(data)
    assert len(data) == 1
",6
"    assert data.y.size() == (5, )
",6
"            version. The data object will be transformed before every access.
",6
"from .node2vec import Node2Vec
",6
"            root, pre_transform=RENet.pre_transform(seq_len))
        self.data, self.slices = torch.load(self.processed_paths[0])

",6
"

def test_instance_norm():
",6
"
",6
"
            out1 = F.interpolate(vgg16_outputs[0], (256, 256), mode='bilinear',
                                 align_corners=False)
            out2 = F.interpolate(vgg16_outputs[0], (256, 256), mode='bilinear',
                                 align_corners=False)
",6
"            test_ratio (float, optional): The ratio of test edges.
                (default: :obj:`0.2`)
        """"""
",6
"        row, col, mask = read_txt_array(path, sep='\t', dtype=torch.long).t()
        mask = mask.to(torch.bool)
",6
"import torch
from torch_geometric.nn.conv.ppf_conv import point_pair_features

",6
"    assert data.edge_index.tolist() == edge_index.tolist()
    assert torch.allclose(
",6
"            self.convs.append(
                GINConv(Sequential(
                    Linear(hidden, hidden),
                    ReLU(),
                    Linear(hidden, hidden),
",6
"        self.atomref = None
        if atomref is not None:
            self.atomref = Embedding(100, 1)
            self.atomref.weight.data.copy_(atomref)
",6
"            gaussian = gaussian.sum(dim=-1)  # [E, F, M]

            return (x_j.view(E, F, 1) * gaussian).sum(dim=-2)  # [E, M]

    def __repr__(self):
",6
"        x = self.lin3(x)
        return F.log_softmax(x, dim=-1)
",6
"            pred_label = log_logits.argmax(dim=-1)
",6
"from .num_nodes import maybe_num_nodes_dict


def group_hetero_graph(edge_index_dict, num_nodes_dict=None):
    num_nodes_dict = maybe_num_nodes_dict(edge_index_dict, num_nodes_dict)
",6
"    into memory.
",6
"train_loader = DataLoader(dataset[:30000], batch_size=60, shuffle=True)
",6
"
",6
"
        return x_j * alpha.view(-1, self.heads, 1)

",6
"    if (len(src) < length):
        return src + list(itertools.repeat(src[-1], length - len(src)))
    return src
",6
"    edge_type = torch.cat(edge_types, dim=0)

    return (edge_index, edge_type, node_type, local_node_idx, local2global,
            key2int)
from copy import copy
",6
"            loop_weight[row[inv_mask]] = remaining_edge_weight
        edge_weight = torch.cat([edge_weight[mask], loop_weight], dim=0)
",6
"from .dna_conv import DNAConv
from .point_conv import PointConv
from .gmm_conv import GMMConv
from .spline_conv import SplineConv
from .nn_conv import NNConv, ECConv
",6
"    for data in loader:
",6
"            data.edge_attr = deg

",6
"        get_angle(norm_j, pseudo),
        get_angle(norm_i, norm_j)
    ],
                       dim=1)

",6
"        [2, 2, 4, 4, 6, 6],
    ])

    subset, edge_index, mapping, edge_mask = k_hop_subgraph(
",6
"    optimizer.step()


",6
"from torch_geometric.utils import to_undirected

",6
"
    .. note::

",6
"                for j in range(i + 2, k):
                    P_l_m[j][i] = sym.simplify(
                        ((2 * j - 1) * z * P_l_m[j - 1][i] -
                         (i + j - 1) * P_l_m[j - 2][i]) / (j - i))

",6
"    row = torch.tensor([0, 1, 1, 1, 2, 2, 3, 3, 4, 4])
",6
"        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"    'Data',
",6
"    assert adj.size() == (1, 5, 5)
",6
"    <https://arxiv.org/abs/1711.08920>`_ paper

    .. math::
        \mathbf{x}^{\prime}_i = \frac{1}{|\mathcal{N}(i)|} \sum_{j \in
        \mathcal{N}(i)} \mathbf{x}_j \cdot
",6
"from torch_scatter import scatter_add
from torch_geometric.utils import softmax

from ..inits import reset
",6
"

def test_delaunay():
    assert Delaunay().__repr__() == 'Delaunay()'

",6
"        row, col = edge_index
        edge_index = torch.cat([edge_index, torch.stack([col, row])], dim=1)
        val = torch.cat([val, val], dim=0)

        edge_index, val = coalesce(edge_index, val, N, N)
",6
"    assert LocalDegreeProfile().__repr__() == 'LocalDegreeProfile()'
",6
"        with torch.no_grad():
            log_logits = self.model(x=x, edge_index=edge_index, **kwargs)
",6
"    expected = 5 - torch.arange(6)
    assert out[1, :6, -1].argsort().tolist() == expected.tolist()
import torch
from torch_geometric.nn import (global_add_pool, global_mean_pool,
",6
"
        return x_j

    def aggregate(self, inputs, index, ptr=None, dim_size=None):
",6
"        elif split == 'val':
            path = self.processed_paths[1]
        elif split == 'test':
            path = self.processed_paths[2]
        elif split == 'trainval':
",6
"            batch = edge_index.new_zeros(x.size(0))
        edge_weight = x.new_ones(edge_index.size(1))

        x = self.down_convs[0](x, edge_index, edge_weight)
        x = self.act(x)
",6
"    data = cluster_data[1]
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
",6
"    assert out[2].tolist() == [[0], [0]]
    assert out[3] is None

    edge_attr = torch.tensor([1, 2, 3])
    out = segregate_self_loops(edge_index, edge_attr)
",6
"
names = [
    'A', 'graph_indicator', 'node_labels', 'node_attributes'
    'edge_labels', 'edge_attributes', 'graph_labels', 'graph_attributes'
",6
"
        if self.min_score is None:
            score = self.nonlinearity(score)
        else:
            score = softmax(score, batch)
",6
"    num_nodes = edge_index.max().item() + 1
",6
"        edge_index, edge_weight = get_laplacian(edge_index, edge_weight,
",6
"def voxel_grid(pos, batch, size, start=None, end=None):
",6
"        glorot(self.weight)
        zeros(self.bias)

    def gcn_msg(self, edge):
        return {'m': edge.src['x'] * edge.src['norm']}
",6
"                                               train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(),
                         test_y.detach().cpu().numpy())

",6
"            u = self.global_model(x, edge_index, edge_attr, u, batch)

        return x, edge_attr, u
",6
"        M, N = int(paper_author[0].max() + 1), int(paper_author[1].max() + 1)
        paper_author, _ = coalesce(paper_author, None, M, N)
        author_paper, _ = transpose(paper_author, None, M, N)

",6
"
try:
",6
"                'delete `{}` first.'.format(self.processed_dir))

        if files_exist(self.processed_paths):  # pragma: no cover
            return
",6
"    if force_undirected:
",6
"    conv = copy.deepcopy(conv)
    assert conv != conv2
    assert conv.weight.data_ptr != conv2.weight.data_ptr
",6
"
    x = model.create_spectral_features(train_pos_index, train_neg_index, 10)
",6
"        return self.propagate(edge_index, x=x, norm=norm)

    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j if norm is not None else x_j

",6
"    return out
",6
"    def num_classes(self):
        r""""""The number of classes in the dataset.""""""
        y = self.data.y
",6
"import networkx as nx
",6
"    edge_attr = torch.tensor([[1], [2], [3], [4]])

",6
"    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j

    def update(self, aggr_out):
",6
"        for param_group in optimizer.param_groups:
",6
"        super(GCNSPMVConv, self).__init__()
",6
"import torch
",6
"    'FeaStConv',
    'HypergraphConv',
",6
"        edge_index (LongTensor): The edge indices of the full-graph.
        size ([int]): The number of neighbors to
            sample for each node in each layer. If set to :obj:`sizes[i] = -1`,
",6
"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
",6
"            alpha = torch.softmax(alpha, dim=-1)
            return (x * alpha.unsqueeze(-1)).sum(dim=1)
",6
"

",6
"import random
import os.path as osp
import shutil

",6
"            data_list.append(Data(pos=pos, face=face))

        if self.pre_filter is not None:
",6
"                               [1, 2, 0, 2, 0, 1, 4, 3]])

",6
"    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])
    face = torch.tensor([[0], [1], [2]])

    data = Data(x=x, edge_index=edge_index, y=2)
    assert data.__repr__() == 'Data(edge_index=[2, 4], x=[3, 1], y=2)'
",6
"    G.add_nodes_from(range(data.num_nodes))

",6
"
    conv = DynamicEdgeConv(nn, k=6, aggr='max')
",6
"

def test_k_hop_subgraph():
    edge_index = torch.tensor([
        [0, 1, 2, 3, 4, 5],
",6
"
import torch
",6
"    ])

",6
"class FPModule(torch.nn.Module):
    def __init__(self, k, nn):
        super(FPModule, self).__init__()
        self.k = k
",6
"    assert len(dataset.shuffle(return_perm=True)) == 2
    assert len(dataset[:100]) == 100
",6
"    Args:
        root (string): Root directory where the dataset should be saved.
        edge_window_size (int, optional): The window size for the existence of
            an edge in the graph sequence since its initial creation.
            (default: :obj:`10`)
",6
"        return data

    def __repr__(self):
        return '{}(axis={}, p={})'.format(self.__class__.__name__, self.axis,
                                          self.p)
",6
"        edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]
",6
"        if x is not None and self.cat:
            x = x.view(-1, 1) if x.dim() == 1 else x
            data.x = torch.cat([x, deg.to(x.dtype)], dim=-1)
",6
"        # edge_index: [2, num_edges]
        # edge_weight: [num_edges]
",6
"    A = A.tocoo()
",6
"        self.data = self.__permute_data__(data, perm, adj)
        self.partptr = partptr
",6
"    pseudo = torch.rand((edge_index.size(1), 3))

    conv = SplineConv(in_channels, out_channels, dim=3, kernel_size=5)
    assert conv.__repr__() == 'SplineConv(16, 32, dim=3)'
    with torch_geometric.debug():
",6
"
        # L = I - A_norm.
        edge_index, edge_weight = add_self_loops(edge_index, -edge_weight,
",6
"
",6
"
__all__ = [
    'train_runtime',
]
import time
",6
"                    param_group['lr'] = lr_decay_factor * param_group['lr']

        if torch.cuda.is_available():
            torch.cuda.synchronize()

",6
"        replace (bool, optional): If set to :obj:`False`, samples fixed
            points without replacement. In case :obj:`num` is greater than
            the number of points, duplicated points are kept to a
",6
"        normalization_in (str, optional): Normalization of the transition
            matrix on the original (input) graph. Possible values:
",6
"        **kwargs (optional): Additional parameters for initializing the graph
            neural network layer.
    """"""

    def __init__(self, in_channels, ratio=0.5, GNN=GraphConv, min_score=None,
",6
"    optimizer.step()


def test(pos_edge_index, neg_edge_index):
    model.eval()
",6
"            data.edge_attr = cart

",6
"        polar = torch.cat([rho, theta], dim=-1)

        if pseudo is not None and self.cat:
            pseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo
",6
"    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])

    data = Data(edge_index=edge_index, pos=pos)
",6
"
",6
"    N_1, N_2 = 4, 6
    x = torch.randn(N_1 + N_2, 4)
    batch = torch.tensor([0 for _ in range(N_1)] + [1 for _ in range(N_2)])
",6
"                                         num_nodes)
    return edge_index, edge_attr


def pool_batch(perm, batch):
",6
"import torch
from torch_geometric.transforms import RemoveIsolatedNodes
",6
"        accs.append(acc)
    return accs

",6
"                model = MetaLayer(em, nm, gm)
                out = model(mock.MagicMock(), edge_index=(""row"", ""col""),
                            edge_attr=""edge_attr"", u=""u"",
                            batch=mock.MagicMock())

",6
"
",6
"        self.lin2 = torch.nn.Linear(128, 64)
        self.lin3 = torch.nn.Linear(64, dataset.num_classes)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
",6
"            lin.bias.data.fill_(0)
",6
"        assert matrix.size(0) == matrix.size(1), (
            'Transformation matrix should be square. Got [{} x {}] rectangular'
            'matrix.'.format(*matrix.size()))

        self.matrix = matrix
",6
"        return F.log_softmax(x, dim=1)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model, data = Net().to(device), data.to(device)
",6
"    assert data.pos.max().item() < 1
from math import sqrt
",6
"import torch
from torch_geometric.nn import RGCNConv


",6
"        self.corruption = corruption

        self.weight = Parameter(torch.Tensor(hidden_channels, hidden_channels))

        self.reset_parameters()
",6
"            'Dataset not found. Please download {} from {} and move it to {}'.
            format(self.raw_file_names, self.url, self.raw_dir))

",6
"        [[7, 8], [9, 10], [11, 12]],
    ]
    assert out.size() == (3, 3, 2)
    assert out.tolist() == expected
",6
"                 **kwargs):
        super(DataLoader,
              self).__init__(dataset, batch_size, shuffle,
",6
"
    for GNN in [GraphConv, GCNConv]:
        pool = ASAPooling(in_channels, ratio=0.5, GNN=GNN,
",6
"    for fold, (train_idx, test_idx,
",6
"        target (LongTensor): The targets.
        num_classes (int): The number of classes.
        batch (LongTensor): The assignment vector which maps each pred-target
",6
"
try:
",6
"        zeros(self.bias)

    def forward(self, x, edge_index, pseudo):
        """"""""""""
        x = x.unsqueeze(-1) if x.dim() == 1 else x
",6
"        return self


",6
"        """"""""""""
        j, i = edge_index
        idx_i, idx_j, idx_k, idx_kj, idx_ji = self.triplets(
            edge_index, num_nodes=x.size(0))

",6
"            degrees = (-abs(degrees), abs(degrees))
        assert isinstance(degrees, (tuple, list)) and len(degrees) == 2
        self.degrees = degrees
",6
"
        rws = [batch]
        for i in range(self.walk_length):
            keys = self.metapath[i % len(self.metapath)]
",6
"    'ICEWS18',
    'GDELT',
    'DBP15K',
",6
"        adjs = [adj.to(device) for adj in adjs]
",6
"    CiteSeer = citation_graph.load_citeseer()
    PubMed = citation_graph.load_pubmed()
    MUTAG = load_data('mutag')  # fair comparison
",6
"    """"""
",6
"            transformed version. The data object will be transformed before
            being saved to disk. (default: :obj:`None`)
        pre_filter (callable, optional): A function that takes in an
            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
",6
"        idx_2 = i[rest] * num_nodes + tmp
        mask = torch.from_numpy(np.isin(idx_2, idx_1)).to(torch.bool)
        k[rest] = tmp
        rest = rest[mask.nonzero().view(-1)]

",6
"
    loss = model.loss(pos_rw, neg_rw)
    assert 0 <= loss.item()
",6
"    tutorial.

    Args:
        root (string, optional): Root directory where the dataset should be
",6
"
    return score


",6
"        # and the size/shape `size` of the bipartite graph.
        # Target nodes are also included in the source nodes so that one can
",6
"        r""""""Calculate the approximate, sparse diffusion on a given sparse
        matrix.
",6
"            batch.batch = None

        for key in batch.keys:
",6
"    x = torch.Tensor([[1, -1], [1, 2], [2, 1]])
    model.encode(x)
    model.reparametrize(model.__mu__, model.__logvar__)
",6
"                          'your data to the GPU.')

        if torch_geometric.is_debug_enabled():
",6
"        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/
        gnn_explainer.py>`_.

    Args:
",6
"    Args:
        value (int, optional): The value to add. (default: :obj:`1`)
",6
"    node-pairs.

",6
"                                     dtype=np.int64)
        edge_index = torch.from_numpy(edge_index.values).t()
        edge_index = edge_index.flatten()
",6
"    assert data.edge_index.tolist() == [[], []]
import sys
",6
"@torch.no_grad()
def test():
",6
"
        if mp_type == 'adj_t' and self.flow == 'target_to_source':
            raise ValueError(
                ('Flow direction ""target_to_source"" is invalid for message '
",6
"            sample = self.__sample_queue__.get()
",6
"train_dataset = dataset[:110000]
val_dataset = dataset[110000:120000]
",6
"

def test_spline_conv():
",6
"
    expected_pos = torch.Tensor([
        [-2 * sqrt(2), 0],
        [-sqrt(2), 0],
",6
"        data = read_npz(self.raw_paths[0])
        data = data if self.pre_transform is None else self.pre_transform(data)
",6
"    assert data.num_faces is None
    assert data.num_node_features == 2
    assert data.num_features == 2

    data.edge_attr = torch.randn(data.num_edges, 2)
",6
"
    def __contains__(self, key):
        r""""""Returns :obj:`True`, if the attribute :obj:`key` is present in the
        data.""""""
",6
"                                     completeness_score)
from sklearn.manifold import TSNE
",6
"        [0, 0],
        [sqrt(2), 0],
        [2 * sqrt(2), 0],
    ])
    expected_norm = [[0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]
",6
"
",6
"        assert edge_weight.numel() == edge_index.size(1)
        inv_mask = ~mask

        loop_weight = torch.full(
",6
"
def topk(x, ratio, batch, min_score=None, tol=1e-7):
    if min_score is not None:
",6
"                        self.in_channels, x.size(1)))
",6
"
    link_logits = model(pos_edge_index, neg_edge_index)
    link_labels = get_link_labels(pos_edge_index, neg_edge_index)

    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)
",6
"
        x = x.view(-1, self.fc1.weight.size(1))
        x = F.elu(self.fc1(x))
        x = F.dropout(x, training=self.training)
",6
"        arg = torch.randn(4, 3)
        return MyData(x, edge_index, arg)


",6
"    for data in loader:
        data = data.to(device)
        out = model(data.x, data.pos, data.edge_index, data.batch)
        total_mae += (out.squeeze(-1) - data.y).abs().sum().item()
",6
"            [1, 0, 1],
            [1, 1, 0],
",6
"    Args:
        hidden_channels (int, optional): Hidden embedding size.
",6
"from torch_geometric.transforms import Polar
from torch_geometric.data import Data
",6
"    """"""
    def __init__(self, data, batch_size, num_steps=1, sample_coverage=50,
                 save_dir=None, num_workers=0, log=True):
",6
"            dataset.transform = T.Compose(
                [dataset.transform, T.ToDense(num_nodes)])

",6
"    return index, value
",6
"        self.lin2 = Linear(hidden, dataset.num_classes)

",6
"
    ent_loss = (-s * torch.log(s + EPS)).sum(dim=-1).mean()

    return out, out_adj, link_loss, ent_loss
import torch
",6
"

def test_sag_pooling():
    in_channels = 16
",6
"    data.norm = norm
    data = NormalizeRotation(max_points=3)(data)
",6
"        return x


",6
"        return '{}()'.format(self.__class__.__name__)
import os
",6
"        loss = ((out - data.y).pow(2) + 100 * attn_loss).mean()
        loss.backward()
        total_loss += loss.item() * data.num_graphs
        optimizer.step()
",6
"            out = pickle.load(f)

",6
"    def raw_file_names(self):
        return [
            'bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor',
            'night_stand', 'sofa', 'table', 'toilet'
",6
"            an additive bias. (default: :obj:`True`)
        **kwargs (optional): Additional arguments of
",6
"    def raw_file_names(self):
        names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']
        return ['ind.{}.{}'.format(self.name.lower(), name) for name in names]

",6
"

class Coauthor(InMemoryDataset):
    r""""""The Coauthor CS and Coauthor Physics networks from the
    `""Pitfalls of Graph Neural Network Evaluation""
",6
"            g1_path, x1_path, embs)
        x2, edge_index2, rel2, assoc2 = self.process_graph(
            g2_path, x2_path, embs)

",6
"    out = global_sort_pool(x, batch, k=10)
    assert out.size() == (2, 10 * 4)
",6
"        eps (float, optional): (Initial) :math:`\epsilon` value.
",6
"                  num_nodes=None):
",6
"
",6
"    assert conv(x, edge_index, edge_weight,
",6
"        optimizer.step()

        total_loss += loss.item() * data.num_graphs
        pbar.set_description(f'Loss: {loss:.4f}')
",6
"test_acc = torch.tensor(test_accs)
print('============================')
print(f'Final Test: {test_acc.mean():.4f}  {test_acc.std():.4f}')
import os.path as osp
",6
"        return F.log_softmax(self.fc2(x), dim=1)


",6
"        with gzip.open(graph_file, 'rb') as f:
            g.parse(file=f, format='nt')
",6
"    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
",6
"            m, n = y.size(0), 75
            x, pos = x.view(m * n, 1), pos.view(m * n, 2)
            node_slice = torch.arange(0, (m + 1) * n, step=n, dtype=torch.long)
            graph_slice = torch.arange(m + 1, dtype=torch.long)
",6
"    url = 'https://github.com/kimiyoung/planetoid/raw/master/data'

",6
"def test_rgcn_conv():
    in_channels, out_channels = (16, 32)
    num_relations = 8
",6
"    assert data.seg.max().item() + 1 == data.x.size(0)
    assert y == 7

",6
"        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
    """"""
",6
"        # Target nodes are also included in the source nodes so that one can
        # easily apply skip-connections or add self-loops.
        for i, (edge_index, _, size) in enumerate(adjs):
            x_target = x[:size[1]]  # Target nodes are always placed first.
            x = self.convs[i]((x, x_target), edge_index)
",6
"                                         avg_degree=2), exact=True)
    data = gdc(data)
",6
"        return batch

    def __call__(self, batch):
        return self.collate(batch)

",6
"        assert len(data) == 7
        assert list(data.x.size()) == [data.num_nodes, 3703]
        assert list(data.y.size()) == [data.num_nodes]
",6
"        return 'data.pt'

",6
"    into positive and negative train/val/test edges, and adds attributes of
    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,
    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`
    to :attr:`data`.
",6
"    r""""""Translates node positions by randomly sampled translation values
    within a given interval. In contrast to other random transformations,
",6
"
    edge_index = torch.tensor([[0, 1, 2, 0], [1, 0, 2, 0]])
",6
"        ),
                             train_eps=False)
",6
"        [0, 1, 2, 3],
        [4, 0, 0, 0],
",6
"
import torch
",6
"    if hasattr(data, 'features'):
        x = torch.tensor(data.features, dtype=torch.float, device=device)
    else:
        x = None
    mask = data.train_mask if hasattr(data, 'train_mask') else data.train_idx
",6
"            vgg16_outputs.clear()

",6
"        (row, col), pos, pseudo = data.edge_index, data.pos, data.edge_attr
        assert pos.dim() == 2 and pos.size(1) == 3

        cart = pos[col] - pos[row]
",6
"        loss.backward()
        optimizer.step()

        total_loss += float(loss)
        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())
",6
"
    z = model('author', batch=data.y_index_dict['author'])
    y = data.y_dict['author']

    perm = torch.randperm(z.size(0))
",6
"
",6
"        :class:`Tensor`)
",6
"def train():
    model.train()
",6
"parser.add_argument('--lr', type=float, default=0.001)
parser.add_argument('--lr_decay_factor', type=float, default=0.5)
parser.add_argument('--lr_decay_step_size', type=int, default=50)
parser.add_argument('--weight_decay', type=float, default=0)
",6
"    pre_transform, transform = T.NormalizeScale(), T.SamplePoints(1024)
    train_dataset = ModelNet(path, '10', True, transform, pre_transform)
    test_dataset = ModelNet(path, '10', False, transform, pre_transform)
",6
"        optimizer.zero_grad()
        data = data.to(device)
",6
"import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn import DenseSAGEConv, dense_diff_pool, JumpingKnowledge

",6
"
        eig_fn = eigs
        if self.is_undirected and self.normalization != 'rw':
",6
"import torch
from torch_scatter import scatter_add


def to_dense_adj(edge_index, batch=None, edge_attr=None):
",6
"                                                       factor=0.7, patience=5,
                                                       min_lr=0.00001)


",6
"    <https://arxiv.org/abs/1905.05178>`_, `""Towards Sparse
",6
"    model.eval()

    correct_nodes = total_nodes = 0
",6
"        \mathbf{q}_t &= \mathrm{LSTM}(\mathbf{q}^{*}_{t-1})

        \alpha_{i,t} &= \mathrm{softmax}(\mathbf{x}_i \cdot \mathbf{q}_t)

",6
"    # Compute Mean Reciprocal Rank (MRR) and Hits@1/3/10.
    result = torch.tensor([0, 0, 0, 0], dtype=torch.float)
",6
"            N = mol.GetNumAtoms()

            pos = text.split('\n')[4:4 + N]
            pos = [[float(x) for x in line.split()[:3]] for line in pos]
            pos = torch.tensor(pos, dtype=torch.float)
",6
"model = RENet(
",6
"    num_nodes = cluster.size(0)
",6
"from torch_geometric.datasets import FAUST
import torch_geometric.transforms as T
",6
"x = data.x.to(device)
",6
"                1 - momentum
            ) * self.running_var + momentum * unbiased_var.mean(dim=0)

        if not self.training and self.track_running_stats:
            mean = self.running_mean.view(1, -1).expand(batch_size, -1)
",6
"        \mathbf{f}(y) = \frac{\sum_{i=1}^k w(x_i) \mathbf{f}(x_i)}{\sum_{i=1}^k
        w(x_i)} \textrm{, where } w(x_i) = \frac{1}{d(\mathbf{p}(y),
        \mathbf{p}(x_i))^2}

",6
"    assert dataset[0].num_nodes == 10
    assert len(dataset[0]) == 5
    assert dataset[1].num_nodes == 5
",6
"        lambda_max = 2.0 if lambda_max is None else lambda_max

        edge_index, norm = self.norm(edge_index, x.size(self.node_dim),
",6
"

def test_one_hot_degree():
    assert OneHotDegree(max_degree=3).__repr__() == 'OneHotDegree(3)'
",6
"                else:
                    data[key] = torch.cat([d[key] for d in data_list],
                                          dim=ref.__cat_dim__(key, ref[key]))
",6
"        self.edge_mask = None

    def __num_hops__(self):
        num_hops = 0
",6
"        return '{}()'.format(self.__class__.__name__)
",6
"def test_contains_isolated_nodes():
",6
"
setup(
    name='torch_geometric',
    version=__version__,
    description='Geometric Deep Learning Extension Library for PyTorch',
",6
"    acc_mean = acc.mean().item()
",6
"                ('venue', 'published', 'paper'): venue_paper,
            },
",6
"        optimizer.step()
",6
"        zeros(self.bias)

    def forward(self, x, edge_index, return_attention_weights=False):
        """"""""""""
",6
"    events collected from 1/1/2018 to 10/31/2018 (24 hours time granularity).

    Args:
        root (string): Root directory where the dataset should be saved.
        split (string): If :obj:`""train""`, loads the training dataset.
",6
"        C = torch.matmul(pos.t(), pos)
        e, v = torch.eig(C, eigenvectors=True)  # v[:,j] is j-th eigenvector

        data.pos = torch.matmul(data.pos, v)
",6
"    return data
",6
"        \mathbf{X}_k^{(t+1)} = \sigma \left( \mathbf{\hat{L}}
        \mathbf{X}_k^{(t)} \mathbf{W} + \mathbf{X}^{(0)} \mathbf{V} \right),

",6
"
def test_erdos_renyi_graph():
",6
"            def forward(self, src, dest, edge_attr, u, batch):
                # source, target: [E, F_x], where E is the number of edges.
                # edge_attr: [E, F_e]
                # u: [B, F_u], where B is the number of graphs.
                # batch: [E] with max entry B - 1.
",6
"        path = osp.join(self.raw_dir, self.name, 'ged.pickle')
        mat = torch.full((len(assoc), len(assoc)), float('inf'))
        with open(path, 'rb') as f:
            obj = pickle.load(f)
            xs, ys, gs = [], [], []
",6
"import torch
import torch.nn.functional as F
",6
"        events = glob.glob(osp.join(self.raw_dir, 'event*-hits.csv'))
        events = [e.split(osp.sep)[-1].split('-')[0][5:] for e in events]
        self.events = sorted(events)
",6
"
",6
"    r""""""A plain old python object modeling a batch of graphs as one big
    (dicconnected) graph. With :class:`torch_geometric.data.Data` being the
    base class, all its methods can also be used here.
    In addition, single graphs can be reconstructed via the assignment vector
    :obj:`batch`, which maps each node to its respective graph identifier.
",6
"    bipartite edges between source and target nodes, :obj:`e_id` denotes the
",6
"        r""""""Precomputes history objects

        .. math::
            \{ \mathcal{O}^{(t-k-1)}_r(s), \ldots, \mathcal{O}^{(t-1)}_r(s) \}
",6
"    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.mlp[0].weight)
",6
"
import torch
",6
"                                         num_steps=4, log=False)

    for sample in loader:
",6
"
def test_dense_sage_conv():
    channels = 16
    nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, channels))
",6
"            batch.debug()
",6
"    if torch.cuda.is_available():
        torch.cuda.synchronize()
    t_start = time.perf_counter()

    for epoch in range(epochs):
",6
"
    categories = [
        'bareteeth',
        'cheeks_in',
        'eyebrow',
",6
"            all neighbors are included in layer :obj:`l`.
        node_idx (LongTensor, optional): The nodes that should be considered
            for creating mini-batches. If set to :obj:`None`, all nodes will be
            considered.
",6
"    in_channels, out_channels = (16, 32)
    pos_ei = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    neg_ei = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    num_nodes = pos_ei.max().item() + 1
",6
"            :math:`\mathbf{i} = \mathbf{y}_i > \tilde{\alpha}`.
            When this value is not :obj:`None`, the :obj:`ratio` argument is
            ignored. (default: :obj:`None`)
",6
"            data.edge_index = torch.stack([row, col], dim=0)
",6
"    assert data_list[0].s == ['1']
",6
"                             f[order].subs(x, zeros[order, i] * x))
            ]
        bess_basis += [bess_basis_tmp]
    return bess_basis

",6
"                if self.pre_filter is not None and not self.pre_filter(data):
                    continue
",6
"try:
    import torch_cluster  # noqa
    random_walk = torch.ops.torch_cluster.random_walk
",6
"class SchNet(torch.nn.Module):
",6
"        super(DeepGraphInfomax, self).__init__()
        self.hidden_channels = hidden_channels
        self.encoder = encoder
        self.summary = summary
",6
"    r""""""Saves the spherical coordinates of linked nodes in its edge attributes.

    Args:
        norm (bool, optional): If set to :obj:`False`, the output will not be
",6
"        if to_undirected and v > u:
            continue

",6
"        return node_sample.unbind(dim=0)


",6
"
    def process(self):
        with open(self.raw_paths[0], 'r') as f:
            data = f.read().split('\n')[:-1]
",6
"            recursive bisection instead of multilevel k-way partitioning.
            (default: :obj:`False`)
        save_dir (string, optional): If set, will save the partitioned data to
            the :obj:`save_dir` directory for faster re-use.
",6
"                              net.interactions):
",6
"        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

",6
"    In short, a score is computed for each edge.
    Edges are contracted iteratively according to that score unless one of
    their nodes has already been part of a contracted edge.

",6
"    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]
    data.test_neg_edge_index = torch.stack([row, col], dim=0)

    return data
import torch
",6
"    data2 = Data(edge_index=edge_index, x=x2)
",6
"import torch
from torch_geometric.utils import dense_to_sparse
",6
"    undirected.
",6
"
    conv = GATConv(in_channels, out_channels, heads=2, concat=False)
    assert conv(x, edge_index).size() == (num_nodes, out_channels)
",6
"    print('Nodes', data.num_nodes)
",6
"    def process(self):
",6
"    assert conv((x, x), edge_index).size() == (num_nodes, out_channels)

    out = conv(x, edge_index, return_attention_weights=True)
    assert out[0].size() == (num_nodes, out_channels)
    assert out[1][1].size() == (edge_index.size(1) + num_nodes, 2)
",6
"
    def __call__(self, data):
        assert data.edge_index is not None

        orig_num_nodes = data.num_nodes
",6
"        self.out_channels = out_channels
        self.K = K
        self.normalize = normalize

        self.lin = Linear(in_channels * (self.K + 1), out_channels, bias=bias)
",6
"        super(SuiteSparseMatrixCollection,
              self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
",6
"        assert out[1].size() == (2, 2)

        pool = ASAPooling(in_channels, ratio=0.5, GNN=GNN, add_self_loops=True)
        assert pool.__repr__() == ('ASAPooling(16, ratio=0.5)')
",6
"            mask = ~torch.isnan(pos[:, 0])
",6
"train_pos_edge_index, test_pos_edge_index = model.split_edges(pos_edge_index)
train_neg_edge_index, test_neg_edge_index = model.split_edges(neg_edge_index)
",6
"    assert len(data) == 3
",6
"
        self.mlp2 = S(
            L(D * K, K**2),
            ELU(),
            BN(K**2),
",6
"                                 skiprows=skiprows, dtype=np.int64)
    edge_index = torch.from_numpy(edge_index.values).t()
",6
"
        return data
",6
"        N = torch.tensor(Ns, dtype=torch.float)
        norm_mat = mat / (0.5 * (N.view(-1, 1) + N.view(1, -1)))

        path = osp.join(self.processed_dir, '{}_norm_ged.pt'.format(self.name))
",6
"    def forward(self):
",6
"        for r_path, p_path in zip(self.raw_paths, self.processed_paths):
            names = glob.glob(osp.join(r_path, '*.gexf'))
            ids.append(sorted([int(i.split(os.sep)[-1][:-5]) for i in names]))

",6
"        form mini-batches of clusters.
        For an example of using Cluster-GCN, see `examples/cluster_gcn.py
        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/
        cluster_gcn.py>`_.
",6
"                the complete batch.
",6
"        '  (2): Linear(in_features=16, out_features=16, bias=True)\n'
        '))')
",6
"    """"""

    def __init__(self):
        self.prev = is_debug_enabled()

",6
"    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=3)
    out = LaplacianLambdaMax(normalization='sym', is_undirected=True)(data)
",6
"        [1, 1, 1, 0, 1, 0],
        [1, 1, 0, 1, 0, 1],
        [1, 0, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 1],
        [1, 0, 1, 0, 1, 0],
",6
"    link_labels = torch.zeros(pos_edge_index.size(1) +
",6
"
    @property
    def num_node_attributes(self):
",6
"        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, p=args.dropout, training=self.training)
        x = self.conv2(x, edge_index)
",6
"    Args:
",6
"        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
",6
"import torch
from torch_geometric.nn import LEConv
",6
"                    if self[key].dtype != torch.bool:
                        data[key] = data[key] - cumsum[key]
                else:
                    data[key] = self[key][self.__slices__[key][i]:self.
                                          __slices__[key][i + 1]]
",6
"    train()
    results = test(test_loader)
    print('Epoch: {:02d}, MRR: {:.4f}, Hits@1: {:.4f}, Hits@3: {:.4f}, '
",6
"        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)
        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()

        cum_num_nodes = torch.cat(
",6
"            up runtime dramatically. (default: :obj:`None`)
        num_workers (int, optional): How many subprocesses to use for
            calculating geodesic distances.
",6
"    assert edge_index.size() == (2, 26)
import torch
from torch_geometric.utils import (contains_self_loops, remove_self_loops,
                                   segregate_self_loops, add_self_loops,
",6
"    url = ('https://www.di.ens.fr/willow/research/proposalflow/dataset/'
           'PF-dataset-PASCAL.zip')

    categories = [
        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',
",6
"                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\mathbf{A} \in \mathbb{R}^{B
                \times N \times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
",6
"except ImportError:
    spline_basis = None
",6
"        path = self.processed_paths[0] if train else self.processed_paths[1]
        self.data, self.slices = torch.load(path)

    @property
    def raw_dir(self):
",6
"                                     sym.sin(theta) * sym.cos(phi)).subs(
                                         y,
",6
"                                  heads))
        for _ in range(num_layers - 2):
            self.convs.append(
",6
"            edge features. (default: :obj:`None`)
        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting
            :obj:`edge_index` will be relabeled to hold consecutive indices
            starting from zero. (default: :obj:`False`)
",6
"        Args:
",6
"        in_channels (int): Size of each input sample.
",6
"def MLP(channels, batch_norm=True):
",6
"        super(TopKPooling, self).__init__()

        self.in_channels = in_channels
        self.ratio = ratio
",6
"    assert conv.__repr__() == 'HypergraphConv(16, 32)'
    out = conv(x, hyperedge_index)
    assert out.size() == (num_nodes, out_channels)
    out = conv(x, hyperedge_index, hyperedge_weight)
",6
"import torch.nn.functional as F
from torch_scatter import scatter_add
",6
"    assert contains_isolated_nodes(edge_index)
",6
"    Nodes represent goods and edges represent that two goods are frequently
    bought together.
    Given product reviews as bag-of-words node features, the task is to
",6
"        return self.apply(lambda x: x.contiguous(), *keys)
",6
"parser.add_argument('--weight_decay', type=float, default=0)
args = parser.parse_args()


",6
"from torch_geometric.data import InMemoryDataset, download_url
from torch_geometric.io import read_npz

",6
"
    @property
",6
"    def edge_attention(self, edge):
        a = F.leaky_relu(edge.src['a1'] + edge.dst['a2'], self.negative_slope)
        return {'a': a}
",6
"    partialities = ['holes', 'cuts']

    def __init__(self, root, partiality, category, train=True, transform=None,
",6
"    and :math:`\{ x_1, \ldots, x_k \}` denoting the :math:`k` nearest points
    to :math:`y`.

",6
"        self.reg_params = self.conv1.parameters()
        self.non_reg_params = self.conv2.parameters()

",6
"    if tensor is not None:
        tensor.data.fill_(1)


def normal(tensor, mean, std):
",6
"                Ns.append(G.number_of_nodes())
                edge_index = torch.tensor(list(G.edges)).t().contiguous()
",6
"        self.lin1.reset_parameters()
        self.lin2.reset_parameters()
",6
"        num_nodes, num_edges = x.size(0), edge_index.size(1)

        subset, edge_index, mapping, edge_mask = k_hop_subgraph(
            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,
",6
"import os.path as osp

import torch
",6
"        cat (bool, optional): If set to :obj:`False`, all existing edge
            attributes will be replaced. (default: :obj:`True`)
    """"""
    def __init__(self, norm=True, max_value=None, cat=True):
        self.norm = norm
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"        assert self.flow in ['source_to_target', 'target_to_source']

",6
"    mae = torch.cat(maes, dim=0)
    print(f'Target: {target:02d}, MAE: {mae.mean():.5f}  {mae.std():.5f}')
",6
"
    conv = GraphConv(in_channels, out_channels)
    assert conv.__repr__() == 'GraphConv(16, 32)'
    assert conv(x, edge_index).size() == (num_nodes, out_channels)
",6
"        loop_weight = edge_weight.new_full((num_nodes, ), fill_value)
        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)

",6
"from torch_geometric.nn.models.re_net import RENet

seq_len = 10

# Load the dataset and precompute history objects.
",6
"
explainer = GNNExplainer(model, epochs=200)
node_idx = 10
node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)
ax, G = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)
",6
"
    if force_undirected:
        row, col, edge_attr = filter_adj(row, col, edge_attr, row < col)

    mask = edge_index.new_full((row.size(0), ), 1 - p, dtype=torch.float)
",6
"from .dataset import Dataset
from .in_memory_dataset import InMemoryDataset
from .dataloader import DataLoader, DataListLoader, DenseDataLoader
from .sampler import NeighborSampler
",6
"        influences.append(influence / influence.sum())

    return torch.stack(influences, dim=0)
",6
"dataset = 'Cora'
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
",6
"        self.flow = flow

    def __call__(self, data):
",6
"    if dest is None:
        out = out.view(-1, pos.shape[0])
",6
"    Args:
        nn (torch.nn.Module): A neural network :math:`h_{\mathbf{\Theta}}` that
            maps node features :obj:`x` of shape :obj:`[-1, in_channels]` to
",6
"    data = gdc(data)
    mat = to_dense_adj(data.edge_index, edge_attr=data.edge_attr).squeeze()
    assert torch.all(mat >= -1e-8)
    assert torch.allclose(mat, mat.t(), atol=1e-4)

",6
"
",6
"                 act=swish):
        super(OutputBlock, self).__init__()
        self.act = act

        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)
",6
"    def process(self):
",6
"import torch_geometric.transforms
import torch_geometric.utils

__version__ = '1.5.0'
",6
"        self.conv1 = DenseSAGEConv(in_channels, hidden_channels)
        self.conv2 = DenseSAGEConv(hidden_channels, out_channels)
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
",6
"
        return out

    def message(self, x_j, edge_weight):
        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j
",6
"
            def __repr__(self):  # pragma: no cover
                return '{}(seq_len={})'.format(self.__class__.__name__,
                                               self.seq_len)

",6
"        data.x = F.elu(self.conv2(data.x, data.edge_index, data.edge_attr))
        cluster = voxel_grid(data.pos, data.batch, size=7, start=0, end=28)
        data.edge_attr = None
        data = max_pool(cluster, data, transform=transform)
",6
"            an :obj:`torch_geometric.data.Data` object and returns a
",6
"
    Args:
",6
"        x = F.relu(self.conv1(x, edge_index))
",6
"                '    node_model={},\n'
                '    global_model={}\n'
                ')').format(self.__class__.__name__, self.edge_model,
                            self.node_model, self.global_model)
",6
"    def inference(self, x_all):
        pbar = tqdm(total=x_all.size(0) * len(self.convs))
        pbar.set_description('Evaluating')

",6
"        print('Epoch: {:03d}, Test: {:.4f}, Duration: {:.2f}'.format(
            epoch, test_acc, t_end - t_start))

",6
"        # `train_loader` computes the k-hop neighborhood of a batch of nodes,
        # and returns, for each layer, a bipartite graph object, holding the
        # bipartite edges `edge_index`, the index `e_id` of the original edges,
        # and the size/shape `size` of the bipartite graph.
",6
"                data = self.pre_transform(data)
",6
"
    def forward(self, data):
        x, edge_index, pseudo = data.x, data.edge_index, data.edge_attr
        x = F.elu(self.conv1(x, edge_index, pseudo))
",6
"model = model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

x = data.x.to(device)
y = data.y.squeeze().to(device)
",6
"                        r[vnode] = _val

                    res_vnode = r[vnode] if vnode in r else 0
                    if res_vnode >= alpha_eps * out_degree[vnode]:
",6
"        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [x]
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
",6
"        self.num_layers = num_layers

        self.weight = Param(Tensor(num_layers, out_channels, out_channels))
",6
"    data = Data(pos=pos)
",6
"
import torch
import torch.nn.functional as F
from torch import tensor
",6
"                # batch: [N] with max entry B - 1.
                out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)
                return self.global_mlp(out)

",6
"        idx_kj = adj_t_row.storage.value()[mask]
",6
"        '40': 'http://modelnet.cs.princeton.edu/ModelNet40.zip'
    }

    def __init__(self, root, name='10', train=True, transform=None,
                 pre_transform=None, pre_filter=None):
",6
"            alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)
            alpha = F.leaky_relu(alpha, self.negative_slope)
            alpha = softmax(alpha, hyperedge_index[0], x.size(0))
            alpha = F.dropout(alpha, p=self.dropout, training=self.training)

",6
"        x = x.unsqueeze(-1) if x.dim() == 1 else x
        if edge_attr.dim() == 1:
            edge_attr = edge_attr.unsqueeze(-1)
        assert x.size(-1) == edge_attr.size(-1)
",6
"
    pbar.close()
",6
"    norm = torch.pow(g.in_degrees().float(), -0.5)
    norm[torch.isinf(norm)] = 0
",6
"        [1, 0, 1],
        [1, 1, 0],
    ])

",6
"    # Train model via multi-class classification against the corresponding
",6
"

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"                # edge_index: [2, E] with max entry N - 1.
                # edge_attr: [E, F_e]
",6
"        else:
            A = A.remove_diag()

        row, col, edge_weight = A.coo()
        edge_index = torch.stack([row, col], dim=0)
",6
"            **kwargs: Any additional data which is needed to construct and
                aggregate messages, and to update node embeddings.
        """"""
",6
"
def dropout_adj(edge_index, edge_attr=None, p=0.5, force_undirected=False,
                num_nodes=None, training=True):
",6
"@torch.no_grad()
def plot_points(colors):
    model.eval()
    z = model.encode(data.x, data.train_pos_edge_index)
",6
"
    edge_attr = torch.Tensor([1, 2, 3])
",6
"    'read_ply',
    'read_obj',
    'read_sdf',
    'parse_sdf',
",6
"
",6
"
        data = data if self.pre_transform is None else self.pre_transform(data)

        torch.save(self.collate([data]), self.processed_paths[0])
",6
"    <https://arxiv.org/abs/1907.04931>`_ paper.
    Given a graph in a :obj:`data` object, this class samples nodes and
    constructs subgraphs that can be processed in a mini-batch fashion.
    Normalization coefficients for each mini-batch are given via
    :obj:`node_norm` and :obj:`edge_norm` data attributes.
",6
"        x = self.conv2(x, edge_index, edge_type)
",6
"    assert len(data_list[0]) == 3
    assert data_list[0].x.tolist() == [1, 2, 3]
    assert data_list[0].edge_index.tolist() == [[0, 1, 1, 2], [1, 0, 2, 1]]
",6
"optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)


",6
"

data = gen_uniform_20_20_60_split(data)

",6
"
                1. :obj:`""ppr""`: Use personalized PageRank as diffusion.
                   Additionally expects the parameter:

",6
"    edge_slice = torch.cumsum(torch.from_numpy(np.bincount(batch[row])), 0)
",6
"            return 'qm9_v1.pt'
        else:
            return ['gdb9.sdf', 'gdb9.sdf.csv', 'uncharacterized.txt']
",6
"        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_dir(self):
        return osp.join(self.root, self.name, 'raw')
",6
"        elif key == 'circle_batch':
            return item.max().item() + 1 if item.numel() > 0 else 0
        else:
",6
"        out, attn_loss, _ = model(data)
        loss = ((out - data.y).pow(2) + 100 * attn_loss).mean()
        loss.backward()
        total_loss += loss.item() * data.num_graphs
",6
"    T.RandomRotate(15, axis=1),
    T.RandomRotate(15, axis=2)
",6
"                   add_remaining_self_loops)
from .isolated import contains_isolated_nodes, remove_isolated_nodes
from .subgraph import subgraph, k_hop_subgraph
from .get_laplacian import get_laplacian
from .to_dense_batch import to_dense_batch
",6
"
        self.skips = torch.nn.ModuleList()
        self.skips.append(Lin(dataset.num_features, hidden_channels * heads))
        for _ in range(num_layers - 2):
",6
"        data_list.append(data)

",6
"class GraphSAINTNodeSampler(GraphSAINTSampler):
    r""""""The GraphSAINT node sampler class (see
    :class:`torch_geometric.data.GraphSAINTSampler`).
",6
"        out = {}
        for key, param in params.items():
            data = kwargs.get(key, inspect.Parameter.empty)
            if data is inspect.Parameter.empty:
                if param.default is inspect.Parameter.empty:
",6
"    writer.add_scalar('Accuracy/test', test_acc, epoch)
import os.path as osp

import torch
",6
"            data_list = [data for data in data_list if self.pre_filter(data)]

        if self.pre_transform is not None:
            data_list = [self.pre_transform(data) for data in data_list]

",6
"

best_val_mae = test_mae = float('inf')
for epoch in range(1, 501):
",6
"transform = T.Cartesian(cat=False)
",6
"
            remaining = (~data.train_mask).nonzero().view(-1)
            remaining = remaining[torch.randperm(remaining.size(0))]
",6
"        self.data.edge_index = None
        self.data.edge_attr = None

        self.batch_size = batch_size
        self.num_steps = num_steps
",6
"import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
",6
"    return loss_all / len(train_dataset)


@torch.no_grad()
def test(loader):
",6
"transform = T.Compose([
    T.RandomTranslate(0.01),
",6
"    def __init__(self):
        super(Net, self).__init__()

",6
"        return F.log_softmax(x, dim=-1)

    def __repr__(self):
",6
"    return zerosj


def spherical_bessel_formulas(n):
    x = sym.symbols('x')
",6
"    ys, preds = [], []
    for data in loader:
        ys.append(data.y)
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
",6
"    neg_edge_index = negative_sampling(edge_index, num_neg_samples=2)
    assert neg_edge_index.size(1) <= 2
",6
"        N = data.num_nodes
        edge_index, edge_attr = data.edge_index, data.edge_attr
        (row, col), edge_attr = coalesce(edge_index, edge_attr, N, N)

",6
"
    train_acc = train_correct.sum().item() / train_correct.size(0)
    val_acc = val_correct.sum().item() / val_correct.size(0)
",6
"            1. :obj:`None`: No normalization
            :math:`\mathbf{L} = \mathbf{D} - \mathbf{A}`

",6
"        super(MetaPath2Vec, self).__init__()

        if num_nodes_dict is None:
            num_nodes_dict = {}
",6
"    out = MessagePassing(flow='source_to_target').propagate(edge_index, x=x)
",6
"
from torch_geometric.data import Data, Batch
from torch._six import container_abcs, string_classes, int_classes
",6
"
    def download(self):
        path = osp.join(self.raw_dir, 'adj_full.npz')
        gdd.download_file_from_google_drive(self.adj_full_id, path)

",6
"        path,
",6
"        'soc-pokec': ['soc-pokec-relationships.txt.gz'],
        'soc-slashdot0811': ['soc-Slashdot0811.txt.gz'],
        'soc-slashdot0922': ['soc-Slashdot0902.txt.gz'],
        'wiki-vote': ['wiki-Vote.txt.gz'],
",6
"        t_start = time.perf_counter()
",6
"    def __call__(self, data):
        edge_index, edge_attr = data.edge_index, data.edge_attr
        N = data.num_nodes

",6
"    def reset_parameters(self):
        self.gnn.reset_parameters()
",6
"
class GCNConv(torch.nn.Module):
    def __init__(self, g, in_channels, out_channels):
",6
"
    assert sorted(data.keys) == ['edge_index', 'x']
    assert len(data) == 2
",6
"        scale /= ((tensor.size(-2) + tensor.size(-1)) * tensor.var())
        tensor.data *= scale.sqrt()


def zeros(tensor):
",6
"            target = f.read().split('\n')[1:-1]
            target = [[float(x) for x in line.split(',')[1:20]]
",6
"            up[perm] = x
            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)

            x = self.up_convs[i](x, edge_index, edge_weight)
",6
"    assert data.pos.tolist() == pos.tolist()
    assert data.norm.tolist() == norm.tolist()
",6
"    Args:
        dataset (Dataset): The dataset from which to load the data.
        batch_size (int, optional): How many samples per batch to load.
            (default: :obj:`1`)
",6
"
",6
"        x = F.relu(self.conv2(x, edge_index))
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
            transformed version. The data object will be transformed before
",6
"
",6
"class Reshape(torch.nn.Module):
    def __init__(self, *shape):
",6
"    path = osp.join('/', 'tmp', '{}.off'.format(name))
    write_off(Data(pos=pos, face=face), path)
    data = read_off(path)
    os.unlink(path)

",6
"            :obj:`""MUTAG""`, :obj:`""BGS""`, :obj:`""AM""`).
        transform (callable, optional): A function/transform that takes in an
",6
"
",6
"        'Chair': [12, 13, 14, 15],
        'Earphone': [16, 17, 18],
        'Guitar': [19, 20, 21],
        'Knife': [22, 23],
        'Lamp': [24, 25, 26, 27],
",6
"
",6
"    # Filter edges.
    mask = torch.rand(idx.size(0)) < edge_prob
    idx = idx[mask]
",6
"        adj_dict = {}
        for keys, edge_index in edge_index_dict.items():
            sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])
            row, col = edge_index
",6
"        :math:`\gamma_{\mathbf{\Theta}}` for each node
        :math:`i \in \mathcal{V}`.
",6
"    args.early_stopping, permute_masks)
import os.path as osp

from torch_geometric.datasets import Planetoid
import torch_geometric.transforms as T
",6
"    'get_laplacian',
",6
"
",6
"    @property
    def raw_file_names(self):
        return ['2d_circle']
",6
"        self.lin0 = torch.nn.Linear(dataset.num_features, dim)

        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))
        self.conv = NNConv(dim, dim, nn, aggr='mean')
        self.gru = GRU(dim, dim)
",6
"
                1. :obj:`""sym""`: Symmetric normalization
                   :math:`\mathbf{T} = \mathbf{D}^{-1/2} \mathbf{A}
                   \mathbf{D}^{-1/2}`.
                2. :obj:`""col""`: Column-wise normalization
",6
"        super(DenseDataLoader, self).__init__(
            dataset, batch_size, shuffle, collate_fn=DenseCollater(), **kwargs)
from __future__ import print_function
",6
"            :obj:`""Cat""`, :obj:`""Chair""`, :obj:`""Diningtable""`, :obj:`""Dog""`,
            :obj:`""Horse""`, :obj:`""Motorbike""`, :obj:`""Person""`,
            :obj:`""Pottedplant""`, :obj:`""Sheep""`, :obj:`""Sofa""`,
            :obj:`""Train""`, :obj:`""TVMonitor""`)
",6
"        self.__clear_masks__()

        return node_feat_mask, edge_mask

    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,
",6
"        assert self.name in ['computers', 'photo']
        super(Amazon, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

",6
"from torch_geometric.nn import FeaStConv


def test_feast_conv():
",6
"        self.out_channels = out_channels
",6
"        if self.num_workers > 0:
",6
"            data.edge_attr = torch.cat([pseudo, cart.type_as(pseudo)], dim=-1)
        else:
",6
"        use_attention (bool, optional): If set to :obj:`True`, attention
",6
"
            data = read_txt_array(osp.join(self.raw_dir, name))
",6
"import torch
from torch_geometric.datasets import Planetoid, Entities

from runtime.gcn import GCN
from runtime.gat import GAT
",6
"        face = face.t().contiguous()

        data_list = []
        for (sid, cat) in product(self.subjects, self.categories):
",6
"
",6
"data.train_mask = data.val_mask = data.test_mask = data.y = None
data = train_test_split_edges(data)
x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

",6
"
        Args:
",6
"def test(loader):
",6
"
            edge_index = torch.tensor([row, col], dtype=torch.long)
",6
"        from torch_scatter import scatter_mean
",6
"        raw_files = sorted([osp.join(raw_dir, f) for f in os.listdir(raw_dir)])

",6
"
    model = model.to(device)
    model.train()
",6
"
    Args:
        in_channels (int): Size of each input sample.
        ratio (float): Graph pooling ratio, which is used to compute
            :math:`k = \lceil \mathrm{ratio} \cdot N \rceil`.
",6
"from torch_geometric.data import DataLoader
from torch_geometric.nn import SplineConv

path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'FAUST')
",6
"
        fp3_out = self.fp3_module(*sa3_out, *sa2_out)
        fp2_out = self.fp2_module(*fp3_out, *sa1_out)
        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)
",6
"    loop_index = torch.arange(0, num_nodes, dtype=torch.long,
",6
"            ys += torch.from_numpy(f['label'][:]).to(torch.long).unbind(0)

        test_area = 'Area_{}'.format(self.test_area)
        train_data_list, test_data_list = [], []
",6
"
    def unpool(self, x, unpool_info):
        r""""""Unpools a previous edge pooling step.
",6
"            c2 = len(cliques) - 1
",6
"        self.value = value
",6
"                             normalize=not args.use_gdc)
        # self.conv1 = ChebConv(data.num_features, 16, K=2)
        # self.conv2 = ChebConv(16, data.num_features, K=2)

",6
"
import argparse
import torch
import torch.nn.functional as F
",6
"        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin3(x)
",6
"from .tree_decomposition import tree_decomposition
from .convert import to_scipy_sparse_matrix, from_scipy_sparse_matrix
from .convert import to_networkx, from_networkx
",6
"        summary=lambda z, *args: z.mean(dim=0),
        corruption=lambda x: x + 1)

    assert model.__repr__() == 'DeepGraphInfomax(16)'
",6
"    out, _, mask = remove_isolated_nodes(edge_index)
    assert out.tolist() == [[0, 1, 0], [1, 0, 0]]
    assert mask.tolist() == [1, 1]

    out, _, mask = remove_isolated_nodes(edge_index, num_nodes=3)
",6
"    assert len(data) == 2
    assert data.edge_index.tolist() == [[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],
                                        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]
    assert data.edge_attr.tolist() == [1, 2, 3, 1, 0, 0, 2, 0, 0, 3, 0, 0]

",6
"
    x, adj, link_loss, ent_loss = dense_diff_pool(x, adj, s, mask)
    assert x.size() == (2, 10, 16)
    assert adj.size() == (2, 10, 10)
    assert link_loss.item() >= 0
",6
"    def __init__(self, in_channels, out_channels, dim, kernel_size,
                 is_open_spline=True, degree=1, aggr='mean', root_weight=True,
                 bias=True, **kwargs):
        super(SplineConv, self).__init__(aggr=aggr, **kwargs)

",6
"
",6
"

class GridSampling(object):
",6
"        batch = torch.tensor([0, 0, 0, 0])
        edge_index = radius_graph(x, r=1.5, batch=batch, loop=False)
    """"""
    if torch_cluster is None:
",6
"        optimizer.zero_grad()
",6
"    :math:`\mathcal{C}`.

    Args:
        hidden_channels (int): The latent space dimensionality.
        encoder (Module): The encoder module :math:`\mathcal{E}`.
",6
"        # Positive loss.
        start, rest = pos_rw[:, 0], pos_rw[:, 1:].contiguous()

        h_start = self.embedding(start).view(pos_rw.size(0), 1,
",6
"
import torch

",6
"    raw = torch.randn(edge_index.size(1))
",6
"from ..inits import reset


class PointConv(MessagePassing):
",6
"        self.min_score = min_score
        self.multiplier = multiplier
        self.nonlinearity = nonlinearity

        self.reset_parameters()
",6
"        # This is the default configuration in the GraphSAINT implementation.
        edge_sample = torch.randint(0, self.E, (num_examples, self.batch_size),
                                    dtype=torch.long)
",6
"                                     edge_weight, self.normalization,
",6
"import torch.nn.functional as F
from tqdm import tqdm
from ogb.nodeproppred import PygNodePropPredDataset, Evaluator
",6
"        self.lin_v.reset_parameters()
",6
"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

for target in range(12):
    model, datasets = SchNet.from_qm9_pretrained(path, dataset, target)
",6
"        net.lin1.bias = state.output_modules[0].out_net[1].out_net[0].bias
        net.lin2.weight = state.output_modules[0].out_net[1].out_net[1].weight
        net.lin2.bias = state.output_modules[0].out_net[1].out_net[1].bias

",6
"
        face = torch.from_numpy(fm['faces'][()]).to(torch.long)
",6
"
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.normalize = normalize
",6
"def test_stochastic_blockmodel_graph():
    torch.manual_seed(12345)

    block_sizes = [2, 2, 4]
",6
"    if val_acc > best_val_acc:
        best_val_acc = val_acc
        test_acc = tmp_test_acc
",6
"    def __repr__(self):
        return '{}(normalization={})'.format(self.__class__.__name__,
",6
"
        self.reset_parameters()

    def reset_parameters(self):
",6
"            this operator in case the normalization is non-symmetric.
",6
"colors = [
    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535', '#ffd700'
]
plot_points(colors)
import os.path as osp
",6
"

best_val_acc = test_acc = 0
for epoch in range(1, 101):
    train()
",6
"
    def __repr__(self):
        return self.__class__.__name__
",6
"    r""""""Writes a :class:`torch_geometric.data.Data` object to an OFF (Object
    File Format) file.

    Args:
",6
"    def reset_parameters(self):
        reset(self.encoder)
",6
"    with open(path, 'rb') as f:
        data = PlyData.read(f)

    pos = ([torch.tensor(data['vertex'][axis]) for axis in ['x', 'y', 'z']])
    pos = torch.stack(pos, dim=-1)
",6
"        loss_all += data.num_graphs * loss.item()
",6
"    Projections scores are learned based on a graph neural network layer.

    Args:
        in_channels (int): Size of each input sample.
        ratio (float): Graph pooling ratio, which is used to compute
",6
"    within the same cluster, node positions are averaged and edge indices are
    defined to be the union of the edge indices of all nodes within the same
    cluster.

",6
"        data = Data(x=x, edge_index=edge_index, y=y)
        data.train_mask = split == 1
        data.val_mask = split == 2
",6
"
class ASAP(torch.nn.Module):
    def __init__(self, dataset, num_layers, hidden, ratio=0.8, dropout=0):
",6
"args = parser.parse_args()
",6
"        self.reset_parameters()

",6
"            :class:`torch_geometric.nn.conv.MessagePassing`.
    """"""

",6
"        row, col, value = adj.coo()
",6
"    In addition, we provide the atom features from the `""Neural Message
    Passing for Quantum Chemistry"" <https://arxiv.org/abs/1704.01212>`_ paper.
",6
"        num_edges += data.num_edges
    for data in test_dataset:
        data = RadiusGraph(0.2)(data)
        num_nodes += data.num_nodes
",6
"    def __call__(self, *keys):
",6
"        path = osp.join(save_dir or '', filename)
        if save_dir is not None and osp.exists(path):
",6
"        out = '{\n' + ',\n'.join(lines) + '\n' + indent_str + '}'
",6
