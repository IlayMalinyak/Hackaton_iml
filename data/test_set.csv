sample,label
"    ""blender"": (2, 80, 0),
",0
"    ""location"": ""View3D > Toolshelf > Building Tools"",
",0
"    ""description"": ""Building Creation Tools"",
    ""warning"": """",
    ""wiki_url"": """",
    ""tracker_url"": """",
    ""category"": ""Mesh"",
",0
"        row = col.row(align=True)
        row.operator(""btools.add_floors"")
",0
"
    bl_label = ""Material Tools""
",0
"    bl_space_type = ""VIEW_3D""
    bl_region_type = ""UI""
    bl_category = ""Building Tools""
",0
"    bl_options = {""DEFAULT_CLOSED""}

    @classmethod
    def poll(cls, context):
        obj = context.object
",0
"            rows = 4

        if not len(ob.face_maps):
            return
",0
"        col.operator(""btools.face_map_clear"", icon=""TRASH"", text="""")

",0
"classes = (BTOOLS_PT_mesh_tools, BTOOLS_PT_material_tools)

",0
"
def register():
",0
"    for cls in classes:
        bpy.utils.register_class(cls)
",0
"

def unregister():
    unregister_core()
",0
"
if __name__ == ""__main__"":
",0
"    import os
    os.system(""clear"")

    # -- custom unregister for script watcher
    for tp in dir(bpy.types):
",0
"    SLABS = auto()
    WALLS = auto()

",0
"    WINDOW = auto()
    WINDOW_BARS = auto()
    WINDOW_PANES = auto()
    WINDOW_LOUVERS = auto()

",0
"        see map_new_faces for the option *skip*
",0
"
def add_facemap_for_groups(groups):
    """""" Creates a face_map called group.name.lower if none exists
",0
"
def set_material_for_active_facemap(material, context):
    obj = context.object
    index = obj.face_maps.active_index
    active_facemap = obj.face_maps[index]
",0
"    ].pop()

    me = get_edit_mesh()
    bm = bmesh.from_edit_mesh(me)
",0
"

def ifeven(number, value_even, value_odd):
    """""" Return value_even if number is an even number else value_odd
",0
"        str,
        bool,
        float,
",0
"    limit_x = (parent_dimensions[0]-size[0]) / 2
    limit_y = (parent_dimensions[1]-size[1]) / 2
    x = clamp(offset[0], -limit_x, limit_x)
    y = clamp(offset[1], -limit_y, limit_y)
",0
"
def local_xyz(face):
    """""" Get local xyz directions
    """"""
",0
"import heapq
import operator
import itertools as it
",0
"from collections import namedtuple

",0
"
class Vector2:
    __slots__ = [""x"", ""y""]
    __hash__ = None
",0
"        return self.__class__(self.x, self.y)

    copy = __copy__

    def __repr__(self):
",0
"        else:
",0
"
",0
"    def __getattr__(self, name):
",0
"        else:
            assert hasattr(other, ""__len__"") and len(other) == 2
            return Vector2(self.x - other[0], self.y - other[1])
",0
"        return Vector2(self.x * other, self.y * other)

    __rmul__ = __mul__

    def __imul__(self, other):
",0
"
",0
"
    def __truediv__(self, other):
        assert type(other) in (int, float)
        return Vector2(operator.truediv(self.x, other), operator.truediv(self.y, other))
",0
"
",0
"        """"""Return the angle to the vector other""""""
",0
"        return math.acos(self.dot(other) / (self.magnitude() * other.magnitude()))

    def project(self, other):
",0
"    def _connect_unimplemented(self, other):
",0
"    _connect_line2 = _connect_unimplemented

",0
"    def intersect(self, other):
        raise NotImplementedError

",0
"        return None

    dy = A.p.y - B.p.y
    dx = A.p.x - B.p.x
",0
"    return Point2(A.p.x + ua * A.v.x, A.p.y + ua * A.v.y)
",0
"

def _connect_point2_line2(P, L):
    d = L.v.magnitude_squared()
",0
"    )


class Point2(Vector2, Geometry):
    def __repr__(self):
",0
"        return LineSegment2(other, self)

    def _connect_line2(self, other):
        c = _connect_point2_line2(self, other)
        if c:
",0
"    __slots__ = [""p"", ""v""]

",0
"                isinstance(args[0], Point2)
                and isinstance(args[1], Vector2)
                and type(args[2]) == float
            )
",0
"            self.p = args[0].copy()
",0
"                self.v = args[1].copy()
            else:
                raise AttributeError(""%r"" % (args,))
",0
"        else:
            raise AttributeError(""%r"" % (args,))

        if not self.v:
",0
"            self.v.x,
",0
"        return other._connect_line2(self)

",0
"def cross(a, b):
    res = a.x * b.y - b.x * a.y
    return res

",0
"
def approximately_equals(a, b):
    return a == b or (abs(a - b) <= max(abs(a), abs(b)) * 0.001)
",0
"

# -- Event Type (etype) is 0
",0
"class EdgeEvent(
",0
"    namedtuple(""EdgeEvent"", ""distance intersection_point etype vertex_a vertex_b"")
):
",0
"        self.edge_right = edge_right
        self.prev = None
",0
"        self.lav = None
        self._valid = True
        # this should be handled better. Maybe membership in lav implies validity?
",0
"
    @property
",0
"                rightdot = abs(
",0
"                    self.edge_right.v.normalized().dot(edge.edge.v.normalized())
                )
                selfedge = self.edge_left if leftdot < rightdot else self.edge_right
",0
"                        continue
",0
"                    xedge = (
                        cross(edge.edge.v.normalized(), (b - edge.edge.p).normalized())
                        < 0
",0
"        if i_next is not None:
            events.append(
                EdgeEvent(
                    Line2(self.edge_right).distance(i_next), i_next, 1, self, self.next
                )
",0
"        ev = min(
            events, key=lambda event: self.point.distance(event.intersection_point)
        )

",0
"        return ev

    def invalidate(self):
        if self.lav is not None:
",0
"
",0
"
",0
"    def __lt__(self, other):
        if isinstance(other, LAVertex):
            return self.point.x < other.point.x

    def __repr__(self):
",0
"class SLAV:
",0
"                LineSegment2(vertex.prev.point, vertex.point),
",0
"
    def __iter__(self):
        for lav in self._lavs:
            yield lav

",0
"                sinks.append(vertex.point)
                vertex.invalidate()
",0
"                events.append(next_event)
",0
"
",0
"            ):
                y = v
                x = y.next

",0
"                        x.bisector.v.normalized(),
                        (event.intersection_point - x.point).normalized(),
                    )
                    <= 0
",0
"
",0
"                if xleft and xright:
",0
"                    y = None
",0
"        v2.next = event.vertex.next
        event.vertex.next.prev = v2
",0
"        for l in new_lavs:
",0
"                self._lavs.append(l)
",0
"

class LAV:
",0
"        lav = cls(slav)
        for prev, point, next in window(polygon):
            lav._len += 1
            vertex = LAVertex(
                point, LineSegment2(prev, point), LineSegment2(point, next)
",0
"            )
            vertex.lav = lav
            if lav.head is None:
",0
"                vertex.next = lav.head
                vertex.prev = lav.head.prev
",0
"        lav = cls(slav)
        lav.head = head
",0
"        for vertex in lav:
            lav._len += 1
            vertex.lav = lav
        return lav
",0
"        vertex._valid = False
        if self.head == vertex:
",0
"            (vertex_b.bisector.v.normalized(), vertex_a.bisector.v.normalized()),
        )
        replacement.lav = self

        if self.head in [vertex_a, vertex_b]:
",0
"    def __repr__(self):
        return ""{} = {}"".format(str(self), [vertex for vertex in self])

    def __len__(self):
",0
"            yield cur
            cur = cur.next
            if cur == self.head:
",0
"        while True:
            print(cur.__repr__())
",0
"            cur = cur.next
            if cur == self.head:
",0
"                break


class EventQueue:
    def __init__(self):
",0
"        for item in self.__data:
            print(item)


def skeletonize(polygon, holes=None):
",0
"        if arc is not None:
            output.append(arc)

    return output
import bmesh
",0
"

",0
"    """""" Create circle in the bmesh
    """"""
    return bmesh.ops.create_circle(
",0
"    )


def cone(bm, r1=0.5, r2=0.01, height=2, segs=32):
",0
"    """""" Create a cone in the bmesh
",0
"        diameter1=r1 * 2,
        diameter2=r2 * 2,
        depth=height,
        cap_ends=True,
",0
"        cap_tris=True,
        segments=segs,
",0
"    """"""
    geom = cube(bm, *size)
    bmesh.ops.translate(bm, verts=geom[""verts""], vec=position)
    return geom
",0
"    """"""
    cy = cylinder(bm, radius, height, segs)
    bmesh.ops.translate(bm, verts=cy[""verts""], vec=position)
    return cy
",0
"

def create_cube_without_faces(bm, size, position=Vector(), **directions):
    """""" Create cube without faces in the given directions
    """"""
",0
"
    def D(direction):
",0
"            faces.append(face_with_verts(bm, vts[_slice]))

",0
"    bmesh.ops.delete(bm, geom=faces, context=""FACES_ONLY"")
",0
"
from .util_mesh import select

",0
"
def create_object(name, data=None):
    """""" Make new object data
    """"""
    return bpy.data.objects.new(name, data)
",0
"    """"""
    bm.to_mesh(obj.data)
    bm.free()


",0
"    """""" Link object to active scene
    """"""
",0
"
def obj_clear_data(obj):
    """""" Removes mesh geometry data from obj
    """"""
    bm = bm_from_obj(obj)
",0
"
def get_edit_mesh():
    """""" Get editmode mesh
",0
"    """""" Find all elements of type _type in geom iterable
    """"""
    return list(filter(lambda x: isinstance(x, _type), geom))
",0
"    for l in edge.link_loops:
        t = edge.calc_tangent(l)
",0
"def edge_vector(edge):
    """""" Return the normalized vector between edge vertices
    """"""
    v1, v2 = edge.verts
",0
"    angles = [math.pi - l.calc_angle() for l in face.loops]
    right_angles = len([a for a in angles if math.pi/2-0.001 < a < math.pi/2+0.001])
    straight_angles = len([a for a in angles if -0.001 < a < 0.001])
",0
"
def is_parallel(a, b):
",0
"
    for e in edges:
        if rnd(normal.x):
            s = set([rnd(v.co.y) for v in e.verts])
        else:
",0
"            s = set([rnd(v.co.x) for v in e.verts])

        if len(s) == 1:
            res.append(e)
    return res
",0
"
        if len(s) == 1:
            res.append(e)
    return res
",0
"def calc_verts_median(verts):
    """""" Determine the median position of verts
    """"""
",0
"    width = sum(e.calc_length() for e in horizontal_edges)/2
    height = sum(e.calc_length() for e in vertical_edges)/2
",0
"    verts = sort_verts(
        list({v for e in filter_geom(ret[""geom_split""], bmesh.types.BMEdge) for v in e.verts}),
        xyz[0]
    )
    theta = math.pi / (len(verts) - 1)
",0
"
    def arc_sine(verts):
",0
"
    def arc_sphere(verts):
        for idx, v in enumerate(verts):
            angle = math.pi - (theta * idx)
",0
"            v.co = median + xyz[0] * math.cos(angle) * length/2
",0
"    return extruded_face, surrounding_faces


def extrude_face_region(bm, faces, depth, normal):
    """"""extrude a face and delete redundant faces
",0
"    unregister_door,
    unregister_floor,
    unregister_window,
    unregister_floorplan,
",0
"    BoolProperty,
    FloatProperty,
    PointerProperty,
    CollectionProperty,
    FloatVectorProperty,
",0
"    get_edit_mesh,
    restricted_size,
",0
"            return self.get(""size"", restricted_size(
                self['parent_dimensions'], self.offset, (0.1, 0.1), self['default_size']
            ))
        else:
",0
"        description=""Size of geometry"",
    )

",0
"    def get_offset(self):
        return self.get(""offset"", self['default_offset'])
",0
"    )

    show_props: BoolProperty(default=False)
",0
"
class ArchProperty(bpy.types.PropertyGroup):
",0
"    )

    height: FloatProperty(
        name=""Arc Height"",
",0
"        description=""Type of offset for arch"",
    )

    def init(self, parent_height):
",0
"        self['parent_height'] = parent_height
        self['default_height'] = 0.4

",0
"            layout.alignment = ""CENTER""
            layout.label(text="""", icon_value=icon)

",0
"    """""" Tracks materials for each facemap created for an object
    """"""

",0
"    sort_verts,
    filter_geom,
    map_new_faces,
    FaceMap,
",0
"        *upper_arc,
        *lower_arc,
",0
"    """""" Add depth to arch face
    """"""
    if depth > 0.0:
        arch_faces, frame_faces = extrude_face_region(bm, [arch_face], -depth, normal)
        return arch_faces[0], frame_faces
",0
"    else:
",0
"        return arch_face, []
import bmesh
import mathutils
from mathutils import Vector, Matrix
",0
"    FaceMap,
    validate,
",0
"
",0
"    """"""Create a gable roof
    """"""
",0
"    if len(faces) > 1:
",0
"            return not all([f in roof_faces for f in e.link_faces])

",0
"
",0
"    Current strategies may fail, when that happens, consider strategies from
",0
"    loops = list({loop for v in face.verts for loop in v.link_loops if loop.face == face})
",0
"    # -- strategy A (only 4 right angled verts, others colinear)
",0
"    verts = sorted(verts, key=lambda v: (v.co.x, v.co.y))
    _min_x, _max_x = verts[0], verts[-1]

    verts = sorted(verts, key=lambda v: (v.co.y, v.co.x))
",0
"    start_loop = max(face.loops, key=lambda loop: loop.vert.co.to_tuple()[:2])

    verts = []
    current_loop = start_loop
",0
"    hang_edges = list(
",0
"        {e for v in verts for e in v.link_edges if all([v in verts for v in e.verts])}
    )

    # -- fix roof slope at bottom edges
",0
"    min_loc_z = min([v.co.z for e in hang_edges for v in e.verts])
    min_verts = list({v for e in hang_edges for v in e.verts if v.co.z == min_loc_z})
    bmesh.ops.translate(bm, verts=min_verts, vec=(0, 0, -size))
",0
"    """"""
    # -- extrude edges upwards
",0
"
    min_z = min([v.co.z for e in edges for v in e.verts])
",0
"    valid_edges = list(filter(lambda e: calc_edge_median(e).z != min_z, edges))
    ret = bmesh.ops.bridge_loops(bm, edges=valid_edges, use_pairs=True)
    add_faces_to_map(bm, ret[""faces""], FaceMap.ROOF)
    bmesh.ops.recalc_face_normals(bm, faces=bm.faces)

",0
"            source_height = [arc.height for arc in skeleton if arc.source == source]
            ht = source_height.pop() * height_scale
            vsource = make_vert(bm, Vector((source.x, source.y, median.z + ht)))
            skeleton_verts.append(vsource)
",0
"    O_verts = {v for e in original_edges for v in e.verts}
    skeleton_verts = [v for v in skeleton_verts if v in S_verts and v not in O_verts]
",0
"            if v in e.verts:
                continue

            v1, v2 = e.verts
",0
"                split_vert = v1
",0
"    linked_edges = [e for v in verts for e in v.link_edges]
    return list(filter(lambda e: e in filter_edges, linked_edges))


",0
"def find_closest_pair_edges(edges_a, edges_b):
",0
"        e1, e2 = pair
",0
"    return list(set(e for v in skeleton_verts for e in v.link_edges))

",0
"
def dissolve_lone_verts(bm, face, original_edges):
    """""" Find all verts only connected to two edges and dissolve them
    """"""
    loops = {loop for v in face.verts for loop in v.link_loops if loop.face == face}
",0
"def cycle_edges_form_polygon(bm, verts, skeleton_edges, linked_edges):
    """""" Move in opposite directions along edges linked to verts until
    you form a polygon
",0
"import bpy
from bpy.props import EnumProperty, FloatProperty, BoolProperty


",0
"        description=""Thickness of roof hangs"",
",0
"        max=1000.0,
        default=1,
        description=""Height of entire roof"",
    )
",0
"
    roof_hangs: BoolProperty(
        name=""Roof Hangs"", default=True, description=""Whether to add roof hangs""
    )
",0
"    )
",0
"            row = box.row(align=True)
            row.prop(self, ""flip_direction"", toggle=True)

",0
"            col = box.column(align=True)
",0
"from .roof_ops import BTOOLS_OT_add_roof
from .roof_props import RoofProperty
",0
"    for cls in classes:
        bpy.utils.register_class(cls)


def unregister_roof():
",0
"
        if cls.validate(bm):
",0
"    @classmethod
    def validate(cls, bm):
        faces = [f for f in bm.faces if f.select]
        if faces:
",0
"    circle(bm, prop.radius, prop.segments, prop.cap_tris)
",0
"

def create_composite_floorplan(bm, prop):
    """"""Create a fan shape from a rectangle
",0
"    |   .    .   |
",0
"    |   .    .   |
    .___......___.
        |    |
        |    |
",0
"
def create_hshaped_floorplan(bm, prop):
    """"""Create H_shaped geometry from a rectangle

    .___.      .___.
",0
"    face = list(bm.faces).pop()
    normal = face.normal
    median_reference = face.calc_center_median()

    extrude_left_and_right_edges(bm, normal, median_reference)
",0
"    for idx, edge in enumerate(extreme_edges):
        length, width = extrusion_lengths[idx], extrusion_widths[idx]

",0
"                vec=Vector((-math.copysign(1.0, v.x), 0, 0)) * (width - 1.0)
            )

",0
"    """"""
    random.seed(prop.seed)
",0
"        list(bm.edges), random.randrange(len(bm.edges) // 3, len(bm.edges))
    )
    median_reference = list(bm.faces).pop().calc_center_median()
",0
"
def random_scale_and_translate(bm, middle_edge):
    """"""scale and translate an edge randomly along its axis
    """"""
    verts = list(middle_edge.verts)
",0
"    axis = Vector((1, 0, 0)) if verts[0].co.y == verts[1].co.y else Vector((0, 1, 0))
",0
"        bm, verts=verts, vec=axis * scale_factor, space=Matrix.Translation(-median)
    )

",0
"    if random.choice([0, 1]):
        rand_offset = random.random() * length
        bmesh.ops.translate(bm, verts=verts, vec=axis * rand_offset)


",0
"    create_rectangular_floorplan,
)
",0
"
        bm = bm_from_obj(obj)
",0
"        elif prop.type == ""CIRCULAR"":
            create_circular_floorplan(bm, prop)

        elif prop.type == ""COMPOSITE"":
",0
"
        elif prop.type == ""RANDOM"":
            create_random_floorplan(bm, prop)

",0
"        items=fp_types, default=""RECTANGULAR"", description=""Type of floorplan""
",0
"        description=""Base Length of floorplan"",
    )
",0
"        name=""Segments"",
        min=3,
        max=100,
        default=32,
        description=""Number of segments in the circle"",
",0
"    def set_segment_width(self, value, propname):
",0
"        Clamp the segment width to less than default_width + base width
",0
"        ONLY for H-Shaped floorplan
        """"""
        default_width = 1.0
        maximum_width = default_width + self.width

",0
"        if self.type == ""H-SHAPED"":
            self[propname] = clamp(value, 0.0, maximum_width)
        else:
",0
"        min=0.0,
        max=100.0,
        description=""Width of floorplan segment"",
        get=lambda self : self.get_segment_width(""tw1""),
        set=lambda self, value : self.set_segment_width(value, ""tw1""),
",0
"    )

    tl1: FloatProperty(
        name=""Tail Length 1"",
        min=0.0,
",0
"        max=100.0,
        default=1,
        description=""Length of floorplan segment"",
    )
",0
"        description=""Width of floorplan segment"",
",0
"
    tl2: FloatProperty(
        name=""Tail Length 2"",
        min=0.0,
        max=100.0,
",0
"        default=1,
        description=""Length of floorplan segment"",
    )

",0
"        get=lambda self : self.get_segment_width(""tw3""),
        set=lambda self, value : self.set_segment_width(value, ""tw3""),
    )
",0
"        min=0.0,
        max=100.0,
",0
"        box = layout.box()
        if self.type == ""RECTANGULAR"":
            col = box.column(align=True)
",0
"            col.prop(self, ""width"")
            col.prop(self, ""length"")
",0
"            col = box.column(align=True)
",0
"        elif self.type == ""H-SHAPED"":
            row = box.row(align=True)
",0
"            row.prop(self, ""width"")
            row.prop(self, ""length"")
",0
"            col.prop(self, ""tl2"")
            col.prop(self, ""tl3"")
            col.prop(self, ""tl4"")
",0
"
def register_floorplan():
    for cls in classes:
        bpy.utils.register_class(cls)
",0
"

def unregister_floorplan():
",0
"    for cls in classes:
        bpy.utils.unregister_class(cls)
import bpy
from .floorplan import Floorplan
from .floorplan_props import FloorplanProperty
",0
"from .floor_props import FloorProperty


class BTOOLS_OT_add_floors(bpy.types.Operator):
    """"""Create floors from the current edit mesh""""""
",0
"    def draw(self, context):
        self.props.draw(context, self.layout)
import bmesh
",0
"    equal,
    FaceMap,
    filter_geom,
",0
"    filter_vertical_edges,
)
",0
"from mathutils import Vector


def create_floors(bm, faces, prop):
    """"""Create extrusions of floor geometry from a floorplan
",0
"    """"""
    slabs, walls, roof = extrude_slabs_and_floors(bm, faces, prop)
",0
"    add_faces_to_map(bm, slabs, FaceMap.SLABS)
    add_faces_to_map(bm, walls, FaceMap.WALLS)
    add_faces_to_map(bm, roof, FaceMap.ROOF)


",0
"def extrude_slabs_and_floors(bm, faces, prop):
    """"""extrude edges alternating between slab and floor heights
",0
"    faces = bmesh.ops.dissolve_faces(bm, faces=faces)[""region""]

    # extrude vertically
    if prop.add_slab:
        offsets = [prop.slab_thickness, prop.floor_height] * prop.floor_count
",0
"
        # extrude slabs horizontally
",0
"        slabs += bmesh.ops.inset_region(
",0
"            bm, faces=slabs, depth=prop.slab_outset, use_even_offset=True, use_boundary=True)[""faces""]

    else:
        offsets = [prop.floor_height] * prop.floor_count
",0
"            if i == 0:
                dissolve_flat_edges(bm, surrounding_faces)
                surrounding_faces = filter_geom(bmesh.ops.region_extend(bm, geom=faces, use_faces=True)[""geom""], BMFace)
            walls += surrounding_faces
",0
"                flat_faces += get_flat_faces([f], visited)
    return list(set(faces + flat_faces))
import bpy
",0
"        max=1000.0,
        default=2.0,
        description=""Height of each floor"",
    )
",0
"    slab_outset: FloatProperty(
",0
"    FaceMap,
",0
"
",0
"    @classmethod
    def validate(cls, bm):
        if any([f for f in bm.faces if f.select]):
            selection = [f for f in bm.faces if f.select]
",0
"                return True
        elif len({round(v.co.z, 4) for v in bm.verts}) == 1:
            return True
",0
"        return False
import bpy

",0
"import bmesh

from mathutils import Vector, Quaternion
from bmesh.types import BMFace, BMEdge
",0
"    FaceMap,
    valid_ngon,
    filter_geom,
",0
"        normal = f.normal.copy()
        top_faces = create_steps(bm, f, prop)

        if prop.has_railing:
",0
"def create_blocked_steps(bm, face, step_widths, step_height):
    """""" Create blocked steps with landing""""""

",0
"            top_faces.append(top_face)

    return top_faces


",0
"    normal = face.normal.copy()
    top_faces = []

    # create steps
    front_face = face
",0
"            e1 = sort_edges(bottom_face.edges, normal)[0]
            edges = filter_parallel_edges(bottom_face.edges, normal)
            widths = [edges[0].calc_length() - step_height, step_height]
            inner_edges = subdivide_edges(bm, edges, normal, widths=widths)
",0
"
            bmesh.ops.translate(bm, verts=e2.verts, vec=-2*normal*step_width/2)
            bmesh.ops.remove_doubles(bm, verts=list(e1.verts)+list(e2.verts), dist=0.001)

    return top_faces
",0
"    """"""
",0
"    if not vec_equal(f.normal, face.normal):
        bmesh.ops.reverse_faces(bm, faces=[f])
    return f
",0
"

def add_railing_to_stairs(bm, top_faces, normal, prop):
    steps = sort_faces(top_faces, normal)
",0
"    first_step = steps[0]
    last_step = steps[-1]
",0
"        v3, v4 = railing_verts(bm, sort_verts(first_step.verts, normal)[-2:], normal, prop.rail.offset, -prop.step_width/2)
        v5, v6 = railing_verts(bm, sort_verts(last_step.verts, normal)[:2], normal, prop.rail.offset, prop.step_width/2)
        e1 = bmesh.ops.contextual_create(bm, geom=(v1, v3))[""edges""][0]
        e2 = bmesh.ops.contextual_create(bm, geom=[v3, v5])[""edges""][0]
        e3 = bmesh.ops.contextual_create(bm, geom=[v2, v4])[""edges""][0]
",0
"

def railing_verts(bm, verts, normal, offset, depth):
    tangent = normal.copy()
",0
"import bpy
from .stairs import Stairs
from .stairs_props import StairsProperty
from ...utils import get_selected_face_dimensions

",0
"
class BTOOLS_OT_add_stairs(bpy.types.Operator):
    """"""Create stairs from selected faces""""""

    bl_idname = ""btools.add_stairs""
",0
"        description=""Depth offset of stairs"",
    )
",0
"
    landing_width: FloatProperty(
        name=""Landing Width"",
",0
"        default=""FILLED"",
        description=""Bottom type of stairs"",
    )
",0
"                bmesh.update_edit_mesh(me, True)
                return {""FINISHED""}
        return {""CANCELLED""}
",0
"
    @classmethod
",0
"    def add_stairs_facemaps(cls):
        add_facemap_for_groups(FaceMap.STAIRS)
",0
"        min=0.01,
        max=1.0,
        default=0.1,
",0
"        default=""NONE"",
        description=""Type of fill for window"",
    )

",0
"
        box = layout.box()
",0
"        prop_name = ""Fill Type"" if self.fill_type == ""NONE"" else self.fill_type.title().replace('_', ' ')
",0
"    get_bottom_faces,
",0
"            return False

        face.select = False
",0
"    # create arch
",0
"    # add depths
    if prop.add_arch:
        _, [window_face], [arch_face], frame_faces = add_frame_depth(bm, [], [window_face], [arch_face], frame_faces, prop.frame_depth, normal)
        arch_face, new_frame_faces = add_arch_depth(bm, arch_face, prop.arch.depth, normal)
        frame_faces += new_frame_faces
",0
"    add_faces_to_map(bm, [window_face], FaceMap.WINDOW)
    add_faces_to_map(bm, validate(frame_faces), FaceMap.FRAME)
    if prop.add_arch:
",0
"
",0
"def fill_window_face(bm, face, prop):
    """"""Create extra elements on face
    """"""
    if prop.fill_type == ""GLASS_PANES"":
        add_facemap_for_groups(FaceMap.WINDOW_PANES)
",0
"    elif prop.fill_type == ""LOUVER"":
        add_facemap_for_groups(FaceMap.WINDOW_LOUVERS)
        fill_louver(bm, face, prop.louver_fill, user=FillUser.WINDOW)
import bpy

",0
"        if cls.validate(faces):
            cls.add_window_facemaps()
            if create_window(bm, faces, prop):
                bmesh.update_edit_mesh(me, True)
",0
"        return {""CANCELLED""}
",0
"
    @classmethod
    def validate(cls, faces):
        if faces:
",0
"classes = (FillBars, FillPanel, FillLouver, FillGlassPanes)


def register_fill():
",0
"        default=0.1,
        description=""Border for panels"",
",0
"        default=0.1,
        description=""Margins of each panel"",
    )

    panel_depth: FloatProperty(
",0
"    pane_count_y: IntProperty(
        name=""Vertical glass panes"",
        min=0,
",0
"        max=100.0,
        default=0.05,
        step=1,
",0
"        min=0,
        max=100,
        default=1,
",0
"
    bar_width: FloatProperty(
",0
"    )

    bar_depth: FloatProperty(
        name=""Bar Depth"",
        min=0.01,
",0
"        row = col.row(align=True)
        row.prop(self, ""bar_count_x"")
        row.prop(self, ""bar_count_y"")
",0
"@map_new_faces(FaceMap.FRAME, skip=FaceMap.DOOR_PANELS)
def fill_panel(bm, face, prop):
",0
"    quads = subdivide_face_into_quads(bm, face, prop.panel_count_x, prop.panel_count_y)
    bmesh.ops.inset_individual(bm, faces=quads, thickness=prop.panel_margin / 2)
",0
"    """"""Create glass panes on face
    """"""
    if prop.pane_count_x + prop.pane_count_y == 0:
",0
"    except IndexError:
        # -- face is too small / has no width or height after sizeoffset prop adjusted
        return
    face_center = face.calc_center_median()

",0
"            (0, 0, -height / 2 + (i + 1) * offset)
        )
        depth = -face.normal * prop.bar_depth / 2
        create_bar_from_face(bm, face, face_center, position, scale, depth)

",0
"        inset(bm, faces=[face], thickness=prop.louver_margin)

    segments = double_and_make_even(prop.louver_count)
    faces = subdivide_face_into_vertical_segments(bm, face, segments)
    faces.sort(key=lambda f: f.calc_center_median().z)
",0
"        edges.extend(filter_geom(res[""geom_inner""], BMEdge))
    bmesh.ops.remove_doubles(bm, verts=bm.verts, dist=0.01)
",0
"def duplicate_face_translate_scale(bm, face, position, scale, scale_center):
    """"""Duplicate a face and transform it
",0
"    """"""
    ret = bmesh.ops.duplicate(bm, geom=[face])
    verts = filter_geom(ret[""geom""], BMVert)

",0
"    bmesh.ops.translate(
        bm,
",0
"    for face in res[""faces""]:
        top_edge = max(
",0
"    """"""Cut a face(quad) vertically into multiple faces
    """"""
    res = bmesh.ops.subdivide_edges(
        bm, edges=filter_vertical_edges(face.edges, face.normal), cuts=segments
",0
"    return list({f for e in filter_geom(res, BMEdge) for f in e.link_faces})


",0
"def create_bar_from_face(bm, face, median, position, scale, depth, vertical=False):
    """"""Create bar geometry from a face
    """"""
    dup = duplicate_face_translate_scale(bm, face, position, scale, median).get(""geom"")
",0
"    FaceMap,
    sort_edges,
    edge_vector,
    filter_geom,
    map_new_faces,
",0
"    subdivide_edges,
    calc_edge_median,
    filter_vertical_edges,
    add_facemap_for_groups,
)
",0
"def create_railing(bm, faces, prop, normal):
    vertical_edges = list({e for f in faces for e in filter_vertical_edges(f.edges, f.normal)})
    add_facemap_for_groups(FaceMap.RAILING_POSTS)
",0
"    dup_face = filter_geom(ret[""geom""], BMFace)[0]
    vertical = filter_vertical_edges(dup_face.edges, dup_face.normal)
    non_vertical = [e for e in dup_face.edges if e not in vertical]
",0
"    # create fill
",0
"    elif prop.fill == ""WALL"":
        add_facemap_for_groups(FaceMap.RAILING_WALLS)
        create_fill_walls(bm, dup_face, prop)
",0
"
",0
"    if n_posts != 0:
        inner_edges = subdivide_edges(bm, [top_edge, bottom_edge], dir, widths=[1.]*(n_posts+1))
        for edge in inner_edges:
            ret = bmesh.ops.duplicate(bm, geom=[edge])
            dup_edge = filter_geom(ret[""geom""], BMEdge)[0]
",0
"            up = face.normal
",0
"    vertical_edges = filter_vertical_edges(face.edges, face.normal)
    n_rails = math.floor(vertical_edges[0].calc_length()*prop.rail_fill.density/rail_size)
    if n_rails != 0:
",0
"        bmesh.ops.holes_fill(bm, edges=top_edges)
        bmesh.ops.holes_fill(bm, edges=bottom_edges)


def scale_railing_edge(bm, edge, amount):
",0
"    WallFillProperty,
    RailProperty,
)

",0
")


",0
"
    def draw(self, context, layout):
        row = layout.row(align=True)
",0
"        min=0.0,
        max=1.0,
        default=0.3,
        description=""Number of rails over each edge"",
",0
"        min=0.01,
        max=100.0,
        default=0.1,
",0
"        description=""Width of each corner post"",
    )

    corner_post_height: FloatProperty(
        name=""Height"",
",0
"
",0
"    create_arch,
    add_arch_depth,
)
from ..door.door_types import (
",0
"    add_door_depth,
    create_door_fill,
)
",0
"    FaceMap,
    local_xyz,
    valid_ngon,
    get_top_faces,
",0
"
def create_multigroup(bm, faces, prop):
    """""" Create multigroup from face selection
",0
"                fill_window_face(bm, window, prop)
            if prop.add_arch:
                fill_arch(bm, arch, prop)
    return True
",0
"    """""" Use properties from SizeOffset to subdivide face into regular quads
",0
"    arch_face = None

    # create arch
",0
"        arch_face, arch_frame_faces = create_arch(bm, top_edges, frame_faces, prop.arch, prop.frame_thickness, local_xyz(face))
        frame_faces += arch_frame_faces

    bmesh.ops.recalc_face_normals(bm, faces=list(bm.faces))

",0
"        door_faces, window_faces, _, frame_faces = add_frame_depth(bm, door_faces, window_faces, [], frame_faces, prop.frame_depth, normal)

    door_faces, new_frame_faces = add_multi_door_depth(bm, door_faces, prop.dw_depth, normal)
    frame_faces += new_frame_faces
",0
"

def make_multigroup_insets(bm, face, size, frame_thickness, dws):
",0
"    clubbed_faces = subdivide_face_horizontally(bm, face, clubbed_widths)

    doors = []
    windows = []
",0
"        elif dw['type'] == 'window':
            ws, fs = make_window_insets(bm, f, dw['count'], window_height, dw_width, frame_thickness, i == 0, i == len(dws)-1)
            windows.extend(ws)
            frames.extend(fs)
",0
"    elif type == ""window"":
        if first and last:
            return (width * count) + (frame_thickness * (count+1))
        elif first or last:
            return (width * count) + (frame_thickness * count)
",0
"        else:
            return (width * count) + (frame_thickness * (count-1))
",0
"    return dws
import bpy
",0
"    )

    frame_depth: FloatProperty(
        name=""Frame Depth"",
        min=-1.0,
",0
"        max=1.0,
        default=0.0,
        step=1,
        description=""Depth of door/window Frame"",
    )
",0
"
    dw_depth: FloatProperty(
",0
"        name=""Door/Window Depth"",
        min=0.0,
        max=1.0,
        default=0.05,
        description=""Depth of door/window"",
",0
"        default=False,
        description=""Add arch over door/window"",
    )
",0
"        (""PANELS"", ""Panels"", """", 1),
        (""GLASS_PANES"", ""Glass_Panes"", """", 2),
        (""LOUVER"", ""Louver"", """", 3),
    ]

",0
"        name=""Fill Type"",
        items=fill_items,
        default=""NONE"",
        description=""Type of fill for door/window"",
    )
",0
"        self['wall_dimensions'] = wall_dimensions
        self.size_offset.init((self['wall_dimensions'][0]/self.count, self['wall_dimensions'][1]), default_size=(2.0, 1.0), default_offset=(0.0, 0.0))
",0
"        col.prop(self, ""count"")

        col = box.column(align=True)
        col.prop(self, ""double_door"")

",0
"    bl_idname = ""btools.add_multigroup""
    bl_label = ""Add Multigroup""
",0
"
    def execute(self, context):
        self.props.init(get_selected_face_dimensions(context))
        return Multigroup.build(context, self.props)

",0
"from .multigroup_props import MultigroupProperty

classes = (MultigroupProperty, BTOOLS_OT_add_multigroup)

",0
"        bm = bmesh.from_edit_mesh(me)
        faces = [face for face in bm.faces if face.select]
",0
"            bmesh.update_edit_mesh(me, True)
            return {""FINISHED""}
        return {""CANCELLED""}

    @classmethod
",0
"    def add_balcony_facemaps(cls):
        groups = FaceMap.BALCONY
        add_facemap_for_groups(groups)

    @classmethod
",0
"from .balcony_ops import BTOOLS_OT_add_balcony
from .balcony_props import BalconyProperty

",0
"        max=100.0,
",0
"
    size_offset: PointerProperty(type=SizeOffsetProperty)
",0
"
",0
"            self.rail.draw(context, box)
import bpy
",0
"
class BTOOLS_OT_add_balcony(bpy.types.Operator):
    """"""Create a balcony from selected faces""""""
",0
"
    bl_idname = ""btools.add_balcony""
    bl_label = ""Add Balcony""
    bl_options = {""REGISTER"", ""UNDO""}
",0
"
    def execute(self, context):
        self.props.init(get_selected_face_dimensions(context))
        return Balcony.build(context, self.props)

",0
"        if not valid_ngon(f):
            popup_message(""Balcony creation not supported for non-rectangular n-gon!"", ""Ngon Error"")
            return False

        f.select = False
",0
"        normal = f.normal.copy()
",0
"
def extrude_balcony(bm, face, depth, normal):
    front = filter_geom(bmesh.ops.extrude_face_region(bm, geom=[face])[""geom""], BMFace)[0]
",0
"    bmesh.ops.delete(bm, geom=ret[""faces""], context=""FACES"")

",0
"

def map_balcony_faces(bm, face):
    """""" Add balcony faces to their facemap """"""
",0
"        bm, verts=f.verts, vec=face.calc_center_bounds() - face.normal*prop.depth_offset
    )
",0
"class Door:
",0
"    @classmethod
",0
"
",0
"    @classmethod
    def validate(cls, faces):
        if faces:
",0
"        max=1.0,
        default=0.0,
        step=1,
        description=""Depth of door Frame"",
",0
"        min=0.0,
        max=1.0,
        default=0.05,
        description=""Depth of door"",
",0
"
    double_door: BoolProperty(
        name=""Double Door"",
",0
"        col.prop(self, ""count"")

",0
"        col.prop_menu_enum(self, ""fill_type"", text=prop_name)

",0
"        # -- draw fill types
        fill_map = {
",0
"    props: bpy.props.PointerProperty(type=DoorProperty)
",0
"    def poll(cls, context):
        return context.object is not None and context.mode == ""EDIT_MESH""

    def execute(self, context):
",0
"from ..frame import add_frame_depth
from ..fill import fill_panel, fill_glass_panes, fill_louver, FillUser

from ..arch import (
",0
"    get_bottom_faces,
    add_faces_to_map,
    extrude_face_region,
    calc_face_dimensions,
",0
"
def create_door(bm, faces, prop):
    """"""Create door from face selection
    """"""
    for face in faces:
",0
"                fill_arch(bm, arch, prop)
",0
"@map_new_faces(FaceMap.WALLS)
def create_door_split(bm, face, size, offset):
    """"""Use properties from SizeOffset to subdivide face into regular quads
    """"""

",0
"    wall_w, wall_h = calc_face_dimensions(face)
    # horizontal split
    h_widths = [wall_w/2 + offset.x - size.x/2, size.x, wall_w/2 - offset.x - size.x/2]
    h_faces = subdivide_face_horizontally(bm, face, h_widths)
",0
"    door_face, new_frame_faces = add_door_depth(bm, door_face, prop.door_depth, normal)
",0
"    frame_faces += new_frame_faces

    # add face maps
    add_faces_to_map(bm, [door_face], FaceMap.DOOR)
    add_faces_to_map(bm, frame_faces, FaceMap.FRAME)
",0
"    elif prop.fill_type == ""GLASS_PANES"":
",0
"        add_facemap_for_groups(FaceMap.DOOR_LOUVERS)
        fill_louver(bm, face, prop.louver_fill, user=FillUser.DOOR)


",0
"        ""setuptools>=38.5.1"",
",1
"        ""tensorboard>=1.14"",  # For pytorch>=1.1.0
",1
"        ""tensorboardX>=1.8"",  # For pytorch<1.1.0
        # Signal processing related
",1
"        ""espnet_tts_frontend"",
        # ASR frontend related
        ""museval>=0.2.1"",
        ""pystoi>=0.2.2"",
        ""nara_wpe>=0.0.5"",
",1
"        ""travis-sphinx>=2.0.1"",
        ""nbsphinx>=0.4.2"",
        ""sphinx-markdown-tables>=0.0.12"",
    ],
",1
"}
",1
"install_requires = requirements[""install""]
",1
"    author_email=""shinjiw@ieee.org"",
    description=""ESPnet: end-to-end speech processing toolkit"",
    long_description=open(os.path.join(dirname, ""README.md""), encoding=""utf-8"").read(),
",1
"    setup_requires=setup_requires,
    tests_require=tests_require,
",1
"    extras_require=extras_require,
    python_requires="">=3.6.0"",
    classifiers=[
        ""Programming Language :: Python"",
        ""Programming Language :: Python :: 3"",
",1
"        ""Programming Language :: Python :: 3.6"",
        ""Programming Language :: Python :: 3.7"",
        ""Programming Language :: Python :: 3.8"",
        ""Development Status :: 5 - Production/Stable"",
",1
"        help=""Type of microphones"",
    )
",1
"                location = x[""location""].upper()
            else:
                location = ""NOLOCATION""

            start_time = x[""start_time""][mictype]
",1
"            # convert to seconds, e.g., 1:10:05.55 -> 3600 + 600 + 5.55 = 4205.55
",1
"
def g2p(text, trans_type=""char""):
    text = jaconv.normalize(text)
    if trans_type == ""char"":
        text = pyopenjtalk.g2p(text, kana=True)
",1
"    parser = argparse.ArgumentParser()
    parser.add_argument(""in_text"", type=str, help=""text to be cleaned"")
    parser.add_argument(""out_text"", type=str, help=""text to be cleaned"")
    parser.add_argument(
        ""trans_type"",
",1
"        args.out_text, ""w"", ""utf-8""
    ) as f_out:
        for line in f_in.readlines():
            id = line.split("" "")[0]
",1
"            f_out.write(""%s %s\n"" % (id, clean_content))
#!/usr/bin/env python3
# Copyright 2012 Vassil Panayotov
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

from __future__ import print_function
",1
"from __future__ import unicode_literals

import argparse
import codecs
from io import open
",1
"import sys


",1
"""""""
Takes a ""PROMPTS"" file with lines like:
",1
"    print(msg, file=sys.stderr)

",1
"
for line in open(sys.argv[1], ""r"", encoding=""utf-8""):
",1
"# BBC to b._b._c.
",1
"# BBCs to b._b._c.s
# BBC's to b._b._c.'s

import argparse
",1
"fin_lex = open(args.input, ""r"")
fin_Letter = open(args.Letter, ""r"")
fout_lex = open(args.output1, ""w"")
fout_lex_ori = open(args.output2, ""w"")
fout_map = open(args.Map, ""w"")
",1
"    if pre_match:
",1
"                    acronym_mapped = acronym_mapped + w.lower() + ""._""
",1
"        elif word[-1] == ""s"" and (lexicon[-1] == ""s"" or lexicon[-1] == ""z""):
            actual_word = word[:-1]
            actual_lexicon = lexicon[:-2]
            acronym_lexicon = """"
            for w in actual_word:
",1
"                acronym_lexicon = acronym_lexicon + dict_letter[w.upper()] + "" ""
            if acronym_lexicon.strip() == actual_lexicon:
                acronym_mapped = """"
                for w in actual_word[:-1]:
",1
"        # find if words in the form of xxx (not ended with 's or s) is acronym
",1
"fin_map = open(args.Map, ""r"")
dict_acronym = {}
",1
"    items = pair.split(""\t"")
    dict_acronym[items[0]] = items[1].strip()
    dict_acronym_noi[items[0]] = items[1].strip()
fin_map.close()
",1
"
# Copyright 2018 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"        ""g2p_en is not installed. please run `. ./path.sh && pip install g2p_en`.""
",1
"    )
    args = parser.parse_args()
    with codecs.open(args.text, ""r"", ""utf-8"") as fid:
        for line in fid.readlines():
            id, _, content = line.split(""|"")
",1
"    parser.add_argument(""--verbose"", default=1, type=int, help=""verbose option"")
    args = parser.parse_args()

",1
"            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
        )
    else:
        logging.basicConfig(
            level=logging.WARN,
",1
"    dirname = os.path.dirname(args.feats_scp)
    feat_fid = open(f""{dirname}/feats_filtered.scp"", ""w"")
    dur_fid = open(f""{dirname}/durations_filtered.scp"", ""w"")

",1
"    # do filtering
    drop_count = 0
    for utt_id in fr_reader.keys():
        focus_rate = fr_reader[utt_id]
        if focus_rate >= args.threshold:
",1
"# Copyright 2018 Nagoya University (Tomoki Hayashi) and KÃ­nh Phan (@enamoria)
",1
"# Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
import codecs

",1
"
            clean_content = vietnamese_cleaner(content)
            lines[id] = clean_content

        for id in sorted(lines.keys()):
",1
"        in_dic[""name""] = ""input1""
        in_dic[""feat""] = dic[""feat""]

        out_list = []
",1
"                ensure_ascii=False,
                sort_keys=True,
                encoding=""utf-8"",
            )
    else:
",1
"            sort_keys=True,
            encoding=""utf-8"",
        )
",1
"import codecs
from io import open
import json
import logging
import sys
",1
"
from espnet.utils.cli_utils import get_commandline_args
",1
"

",1
"if __name__ == ""__main__"":
    description = """"""
""""""
",1
"    parser = argparse.ArgumentParser(
        description=""Given each file paths with such format as ""
",1
"        type=str,
        nargs=""*"",
        action=""append"",
        default=[],
",1
"    # logging info
",1
"                if len(sps) == 2:
",1
"                        raise RuntimeError(""Unknown type: {}"".format(type_func_str))

                    if not callable(type_func):
                        raise RuntimeError(""Unknown type: {}"".format(type_func_str))

",1
"                        )

                lis.append((key, scp, type_func, key_scp, type_func_str))
",1
"    ]
    output_fscps = [
",1
"    # The final goal is creating a JSON file such as.
    # {
    #     ""utts"": {
    #         ""sample_id1"": {(omitted)},
    #         ""sample_id2"": {(omitted)},
",1
"        lines = [[f.readline() for f in fl] for fl in fscps]

        # Get the first line
        concat = sum(input_lines + output_lines + lines, [])
        if len(concat) == 0:
",1
"                            concat = sum(input_infos + output_infos + infos, [])
                            raise RuntimeError(
",1
"                                'between: ""{}"" and ""{}""'.format(
                                    concat[0][1], concat[count][1]
                                )
",1
"                        raise RuntimeError(
                            ""The keys are mismatch at {}th line ""
                            'between ""{}"" and ""{}"":\n>>> {}\n>>> {}'.format(
                                nutt,
",1
"                                concat[0][1],
                                concat[count][1],
                                first.rstrip(),
                                line.rstrip(),
                            )
",1
"                # line_list: List[str]
                for line, info in zip(line_list, info_list):
                    sps = line.split(None, 1)
",1
"                        raise RuntimeError(
                            ""Format error {}th line in {}: ""
                            ' Expecting ""<key> <value>"":\n>>> {}'.format(
",1
"                    value = value.rstrip()

                    try:
                        # type_func: Callable[[str], Any]
                        value = type_func(value)
",1
"                    except Exception:
                        logging.error(
                            '""{}"" is an invalid function '
",1
"        entry = (""\n"" + indent).join(entry.split(""\n""))

",1
"IT SEEMED THE ORDAINED ORDER OF THINGS THAT DOGS SHOULD WORK

, an ID prefix and a list of audio file names (e.g. for above example the list
will contain ""a0405"").
It checks if the prompts file have transcription for all audio files in the list and
",1
"
if len(sys.argv) < 3:
    err(""Usage: %s <prompts-file> <id-prefix> <utt-id1> <utt-id2> ... "" % sys.argv[0])
    sys.exit(1)
",1
"unnorm_utt = set()
for line in open(sys.argv[1], encoding=""utf-8""):
",1
"    ):
",1
"        # Note(kamo): Changed from the original: isalpha() -> isalnum()
        # not trans.strip().replace(' ', '').replace(""'"", """").isalpha():
        err(
            ""The transcript for '%s'(user '%s') is not properly normalized - skipped!""
            % (u, id_prefix)
",1
"        )
        err(trans)
        unnorm_utt.add(u)
        continue
",1
"
if __name__ == ""__main__"":
",1
"    with open(args.filter_list, encoding=""utf-8"") as f:
        fil = [x.rstrip() for x in f]

    for x in sys.stdin:
        # extract text parts
",1
"        text = "" "".join(x.rstrip().split()[1:])
        if text in fil:
            print(x.split()[0], text)
#!/usr/bin/env python3
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"
from functools import reduce
import json
",1
"from operator import mul
import sys

from espnet.bin.asr_train import get_parser
from espnet.nets.pytorch_backend.nets_utils import get_subsample
",1
"        subsample = get_subsample(
            args, mode=args.mode_subsample, arch=args.arch_subsample
",1
"try:
    tmpFile = open(tmpFileLocation)
",1
"        speakers[comp[0]] = ""f""
    else:
        speakers[comp[0]] = comp[1]
",1
"# Note that if a speaker appears multiple times, it is categorized as female
",1
"
tmpFileLocation = ""data/local/tmp/spk2gendertmp""

tmpFile = None
",1
"
try:
    tmpFile = open(tmpFileLocation)
except IOError:
",1
"
for line in tmpFile:
    comp = line.split("" "")
    if comp[0] in speakers:
",1
"    )
",1
"
",1
"                segment_start, spk_start, start_t, _ = segments[
                    (session, start_id)
                ].split()
                segment_end, spk_end, _, end_t = segments[(session, end_id)].split()
",1
"                line_new = "" "".join(
                    [
",1
"                        + ""-""
",1
"        for line in f:
",1
"            session, ids = line.strip().split()
            if len(ids.split(""_"")) == 1:
                line_new = texts[(session, int(ids))]
",1
"                trans = "" "".join(texts[(session, start_id)].split()[1:])
                for i, id in enumerate(map(int, ids.split(""_"")[1:])):
                    segment_next = texts[(session, id)].split()[0]
                    trans_next = "" "".join(texts[(session, id)].split()[1:])
",1
"                            [
                                ""-"".join(segment.split(""-"")[:3])
                                + ""-""
",1
"                                + segment_next.split(""-"")[-1],
                                trans,
                            ]
",1
"#!/usr/bin/env python3
",1
"tmpFileLocation = ""data/local/tmp/spk2gendertmp""

tmpFile = None

try:
",1
"    tmpFile = open(tmpFileLocation)
except IOError:
    print(""The file spk2gendertmp does not exist. Run fsp_make_trans.pl first?"")
",1
"#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
",1
"    sys.exit(1)
an4_root = sys.argv[1]
sph2pipe = sys.argv[2]

",1
"    ) as transcript_f, open(os.path.join(""data"", x, ""text""), ""w"") as text_f, open(
",1
"        text_f.truncate()
",1
"        for line in lines:
            line = line.strip()
            if not line:
",1
"
",1
"    print(""Usage: python data_prep.py [an4_root] [sph2pipe]"")
    sys.exit(1)
an4_root = sys.argv[1]
",1
"sph2pipe = sys.argv[2]

sph_dir = {""train"": ""an4_clstk"", ""test"": ""an4test_clstk""}

",1
"                words = words[:-5]
            source = re.search(r""\((.*)\)"", line).group(1)
            pre, mid, last = source.split(""-"")
            utt_id = ""-"".join([mid, pre, last])

",1
"# MERCHANTABLITY OR NON-INFRINGEMENT.
# See the Apache 2 License for the specific language governing permissions and
# limitations under the License.
",1
"            pre, mid, last = source.split(""-"")
            utt_id = ""-"".join([mid, pre, last])

",1
"# Copyright  2014  Nickolay V. Shmyrev
#            2016  Johns Hopkins University (author: Daniel Povey)
",1
"# speech recognition.

prev_line = """"
for line in sys.stdin:
",1
"import pyopenjtalk


def g2p(text, trans_type=""char""):
",1
"    text = jaconv.normalize(text)
    if trans_type == ""char"":
",1
"        help=""Input transcription type"",
    )
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
import os
",1
"def get_parser():
",1
"    parser = argparse.ArgumentParser(
        description=""Prepare segments from HTS-style alignment files"",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""wav_scp"", type=str, help=""wav scp file"")
",1
"            assert os.path.exists(lab_path)
",1
"if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(""in_text"", type=str, help=""text to be cleaned"")
",1
"#!/usr/bin/env python3
# -*- encoding: utf-8 -*-
",1
"
# Copyright 2020 Nagoya University (Wen-Chin Huang)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
",1
"from tacotron_cleaner.cleaners import remove_unnecessary_symbols
from tacotron_cleaner.cleaners import uppercase

try:
",1
"    )
except LookupError:
    # NOTE: we need to download dict in initial running
",1
"    text = uppercase(text)
    text = collapse_whitespace(text)
    return text


",1
"    parser.add_argument(
        ""--lang_tag"",
        type=str,
        default=None,
",1
"        ""trans_type"", type=str, default=""char"", help=""transcription type (char or phn)""
    )
",1
"            for line in f.read().splitlines():
                path, _, content, _ = line.split(""|"")
                uid = args.spk_tag + ""_"" + os.path.basename(path).replace("".wav"", """")
                text = custom_finnish_cleaners(content.rstrip())
                if args.lang_tag is None:
",1
"    main()
#!/usr/bin/env python3
# -*- encoding: utf-8 -*-

",1
"import nltk
",1
"
    f_g2p = G2p()
",1
"        help=""language tag (can be used for multi lingual case)"",
    )
    parser.add_argument(""--spk_tag"", type=str, help=""speaker tag"")
    parser.add_argument(""jsons"", nargs=""+"", type=str, help=""*_mls.json filenames"")
    parser.add_argument(""out"", type=str, help=""output filename"")
",1
"                uid = args.spk_tag + ""_"" + key.replace("".wav"", """")

                content = js[key][""clean""]
                text = custom_english_cleaners(content.rstrip())
",1
"
if __name__ == ""__main__"":
",1
"    else:
        ssl._create_default_https_context = _create_unverified_https_context
    nltk.download(""punkt"")

",1
"def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--lang_tag"",
        type=str,
",1
"    parser.add_argument(
        ""trans_type"",
        type=str,
        default=""phn"",
        choices=[""char"", ""phn""],
",1
"                    line = ""%s <%s> %s\n"" % (uid, args.lang_tag, text)
                out.write(line)

",1
"if __name__ == ""__main__"":
",1
"
",1
"        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
",1
"    )
    parser.add_argument(
        ""--lowercase"", type=bool, default=False, help=""Lower case the result or not""
",1
"import codecs
import nltk

from tacotron_cleaner.cleaners import collapse_whitespace
from tacotron_cleaner.cleaners import custom_english_cleaners
",1
"from tacotron_cleaner.cleaners import expand_abbreviations
from tacotron_cleaner.cleaners import expand_numbers
from tacotron_cleaner.cleaners import expand_symbols
from tacotron_cleaner.cleaners import lowercase
",1
"from tacotron_cleaner.cleaners import remove_unnecessary_symbols
",1
"from tacotron_cleaner.cleaners import uppercase

E_lang_tag = ""en_US""
",1
"    f_g2p("""")
except ImportError:
",1
"def g2p(text):
    """"""Convert grapheme to phoneme.""""""
    tokens = filter(lambda s: s != "" "", f_g2p(text))
    return "" "".join(tokens)
",1
"if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""transcription_path"", type=str, help=""path for the transcription text file""
    )
",1
"            content = "" "".join(segments[1:])
            text = custom_finnish_cleaners(content.rstrip())
            if args.trans_type == ""phn"":
                # NOTE: we don't have phone for Finnish yet.
",1
"                    clean_content = g2p(text)

                transcription_dict[id] = ""<"" + E_lang_tag + ""> "" + clean_content

    # read the utt2spk file and actually write
",1
"import codecs
",1
"import nltk

from tacotron_cleaner.cleaners import custom_english_cleaners
",1
"    raise ImportError(
        ""g2p_en is not installed. please run `. ./path.sh && pip install g2p_en`.""
    )
except LookupError:
",1
"        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
",1
"def g2p(text):
    """"""Convert grapheme to phoneme.""""""
    tokens = filter(lambda s: s != "" "", f_g2p(text))
",1
"    transcription_dict = {}
    with codecs.open(args.transcription_path, ""r"", ""utf-8"") as fid:
",1
"                # NOTE: we don't have phone for German yet.
",1
"
    if args.transcription_path_en:
",1
"                clean_content = custom_english_cleaners(content.rstrip())
",1
"import codecs
import nltk

",1
"
",1
"    )
",1
"except LookupError:
    # NOTE: we need to download dict in initial running
    import ssl

",1
"    tokens = filter(lambda s: s != "" "", f_g2p(text))
",1
"        ""--lang_tag"",
        type=str,
        default="""",
",1
"                clean_content = g2p(text)

            if args.lowercase:
",1
"#!/usr/bin/env python3

",1
"my_pinyin = Pinyin(MyConverter())
pinyin = my_pinyin.pinyin

E_lang_tag = ""en_US""
",1
"    f_g2p("""")
except ImportError:
",1
"    else:
        ssl._create_default_https_context = _create_unverified_https_context
    nltk.download(""punkt"")
",1
"
",1
"    )
    parser.add_argument(""utt2spk"", type=str, help=""utt2spk file for the speaker"")
",1
"    parser.add_argument(
        ""trans_type"",
",1
"        help=""path for the English transcription text file"",
    )
    args = parser.parse_args()

    # clean every line in transcription file first
",1
"                    c = c.replace(""Ã¼"", ""v"")
                    c = c.replace(""ui"", ""uei"")
                    c = c.replace(""un"", ""uen"")
                    c = c.replace(""iu"", ""iou"")
",1
"            id = segments[0]  # ex. E10001
",1
"    return parser


if __name__ == ""__main__"":
    parser = get_parser()
",1
"
    for line in scps:
",1
"        number = line.split("" "")[0].split(""_"")[1]
        if number in utts:
            out.write(line)
",1
"
def g2p(text):
    """"""Convert grapheme to phoneme.""""""
    tokens = filter(lambda s: s != "" "", f_g2p(text))
",1
"    return "" "".join(tokens)
",1
"    )
",1
"

",1
"
",1
"if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        ""--skip-ncols"", ""-s"", default=0, type=int, help=""skip first n columns""
",1
"    )
    parser.add_argument(""text"", type=str, help=""input text"")
",1
"    args = parser.parse_args()

    if args.text:
        f = open(args.text, encoding=""utf-8"")
    else:
",1
"#!/usr/bin/env python3
",1
"import os
",1
"        return wav.split(""/"")[-4] + ""_"" + wav[-21:-4].replace(""/"", """")

",1
"
subsets = {""train"": {}, ""dev"": {}, ""test"": {}}

",1
"    ""buriy_audiobooks_2_val"",
    ""public_youtube700_val"",
    # next the training datasets
    # (it needs all validation transcripts)
",1
"            uttid = get_uttid(wav)
",1
"                subsets[subset][dataset].append([uttid, words, wav])

for dataset in subsets[""test""].keys():
",1
"    subsets[dataset] = {""all"": subsets[""test""][dataset][:]}

for subset in subsets.keys():
    if ""all"" not in subsets[subset]:
",1
"random.seed(1)
random.shuffle(subsets[""train""][""all""])

dev_size = min(int(len(subsets[""train""][""all""]) * 0.1), len(subsets[""test""][""all""]))
subsets[""dev""][""all""] = subsets[""train""][""all""][:dev_size]
",1
"from mmseg import seg_txt

",1
"            or blks[i] == ""[LAUGHTER]""
        ):
            out_line += "" "" + blks[i]
            continue
",1
"        for j in seg_txt(blks[i]):
            out_line += "" "" + j
    print(out_line)
#!/usr/bin/env python3
",1
"sys.stdin = codecs.getreader(""utf-8"")(sys.stdin if PY2 else sys.stdin.buffer)
sys.stdout = codecs.getwriter(""utf-8"")(sys.stdout if PY2 else sys.stdout.buffer)


if __name__ == ""__main__"":
",1
"        logging.basicConfig(
            level=logging.WARN,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"        )

    # make union set for utterance keys
    new_dic = dict()
    for x in args.jsons:  #
",1
"import argparse
import errno
import os
",1
"import soundfile as sf

from nara_wpe.utils import istft
from nara_wpe.utils import stft
from nara_wpe.wpe import wpe
",1
"
input_files = args.files[: len(args.files) // 2]
output_files = args.files[len(args.files) // 2 :]
out_dir = os.path.dirname(output_files[0])
try:
",1
"except OSError as e:
    if e.errno != errno.EEXIST:
",1
"    fading=True,
    pad=True,
",1
"        logging.basicConfig(
            level=logging.WARN,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
        )
",1
"    # make union set for utterance keys
    new_dic = dict()
    for x in args.jsons:  #
        with open(x, ""r"", encoding=""utf_8"") as f:
",1
"import argparse
",1
"from nara_wpe.wpe import wpe
import numpy as np

parser = argparse.ArgumentParser()
",1
"out_dir = os.path.dirname(output_files[0])
",1
"
stft_options = dict(
    size=512,
    shift=128,
",1
"sampling_rate = 16000
delay = 3
iterations = 5
taps = 10
",1
"parser = argparse.ArgumentParser(description=""format acronyms to a._b._c."")
parser.add_argument(""-i"", ""--input"", help=""Input lexicon"", required=True)
",1
"parser.add_argument(""-o"", ""--output"", help=""Output lexicon"", required=True)
parser.add_argument(
    ""-L"", ""--Letter"", help=""Input single letter pronunciation"", required=True
)
",1
"fin_Letter = open(args.Letter, ""r"")
fout_lex = open(args.output, ""w"")
",1
"fout_map = open(args.Map, ""w"")

# Initialise single letter dictionary
dict_letter = {}
",1
"# print dict_letter

for lex in fin_lex:
    items = lex.split()
    word = items[0]
",1
"        elif word[-1] == ""s"" and (lexicon[-1] == ""s"" or lexicon[-1] == ""z""):
            actual_word = word[:-1]
",1
"#!/usr/bin/env python3

# Copyright 2015  Minhua Wu
# Apache 2.0

",1
"
parser = argparse.ArgumentParser(description=""format acronyms to a._b._c."")
parser.add_argument(""-i"", ""--input"", help=""Input transcripts"", required=True)
parser.add_argument(""-o"", ""--output"", help=""Output transcripts"", required=True)
",1
"parser.add_argument(""-M"", ""--Map"", help=""Input acronyms mapping"", required=True)
args = parser.parse_args()

fin_map = open(args.Map, ""r"")
dict_acronym = {}
",1
"dict_acronym_noi = {}  # Mapping of acronyms without I, i
for pair in fin_map:
    items = pair.split(""\t"")
",1
"    dict_acronym[items[0]] = items[1]
    dict_acronym_noi[items[0]] = items[1]
fin_map.close()
",1
"fin_trans = open(args.input, ""r"")
",1
"        if items[i] == ""I"":
            x = 0
            while i - 1 - x >= 0 and re.match(r""^[A-Z]$"", items[i - 1 - x]):
                x += 1

",1
"                for bias in range(-x, y + 1):
                    items[i + bias] = dict_acronym[items[i + bias]]
",1
"
",1
"    utt_array = []  # uttrance array w/o '#'

    # get voice_part & utt_array
    with open(in_lab_file, ""r"") as f:
",1
"    tvn = sum(st_list)  # Number of Tmp Voice part
",1
"    # ignore short silence
    for i in range(avn):
        if st_list[i] == 1:
            voice_part_tmp[stn][0] = voice_part_ana[i][0]
            stn = stn + 1
",1
"    ovn = len(voice_part_old)  # Number of Old Voice part
    tvn = len(voice_part_tmp)  # Number of Tmp Voice part

    # initialize output
",1
"        for j in range(tvn):
            if (voice_part_old[i][0] <= voice_part_tmp[j][0]) and (
                voice_part_tmp[j][1] <= voice_part_old[i][1]
            ):
",1
"                f.write(
                    ""%.6f\t%.6f\t%s\n""
                    % (
",1
"        f.write(""%.6f\t%.6f\t%s\n"" % (np.float(voice_part_new[i][1]), dur, ""#""))


",1
"        dur_old = voice_part_old[i][1] - voice_part_old[i][0]
        dur_new = voice_part_new[i][1] - voice_part_new[i][0]
        diff_dur = dur_old - dur_new

        if 1.0 < diff_st:
",1
"            sys.stderr.write(
",1
"    in_wav_file = args[1]
    in_lab_file = args[2]
    out_lab_file = args[3]
",1
"
    # in_lab_file open & get voice_part_old from lab_file
    voice_part_old, utt_array = get_vp(in_lab_file)

",1
"    # connect voice_part_ana to ignore short silent
",1
"    voice_part_tmp = ignore_sil(voice_part_ana, sec=0.01)

    # separate voice_part based on lab
",1
"    # compare voice_part_old and voice_part_new (for debug)
    # compare_vp(voice_part_old, voice_part_new)

",1
"    logging.basicConfig(level=logging.INFO, format=log_format)

    logging.debug(""reading %s"", args.json)
",1
"    with open(args.json, ""rt"", encoding=""utf-8"") as f:
        j = json.load(f)
",1
"            else:
                location = ""NOLOCATION""

            start_time = x[""start_time""][mictype]
",1
"            end_time = x[""end_time""][mictype]

",1
"            # convert to seconds, e.g., 1:10:05.55 -> 3600 + 600 + 5.55 = 4205.55
            start_time = hms_to_seconds(start_time)
",1
"            end_time = hms_to_seconds(end_time)

            uttid = speaker_id + ""_"" + session_id
            if args.mictype not in [""worn"", ""ref""]:
                # Because ref is close-talk
",1
"                uttid += ""_"" + mictype
            uttid += ""_"" + location + ""-"" + start_time + ""-"" + end_time

",1
"import json
import os

",1
"
import argparse
import codecs
",1
"
",1
"        type=str,
        help=""text file which describes the order of audio files"",
",1
"            file_order.append(line.strip())

",1
"        dictionary = f.readlines()
    char_list = [entry.split("" "")[0] for entry in dictionary]
    char_list.insert(0, ""<blank>"")
",1
"    for x in j[""utts""]:
        talkid = x.split(""_"")[0]
        start_time = int(x.split(""_"")[1])
        if talkid not in hyps.keys():
            hyps[talkid] = {}
",1
"
import argparse
import codecs
from collections import OrderedDict
",1
"
def main():
    parser = argparse.ArgumentParser()
",1
"        lang = os.path.basename(args.xml).split(""."")[-2]
        talk_id = None

",1
"        # Parse a XML file
        trans_dict_all = OrderedDict()
        for e in elem.getiterator():
            if e.tag == ""doc"":
",1
"                trans_dict_all[talk_id][utt_id] = ref
",1
"    with codecs.open(args.output, ""w"", encoding=""utf-8"") as f:
        for talk_id, trans_dict in trans_dict_all.items():
            for utt_id, ref in trans_dict.items():
",1
"                )


",1
"# Copyright  2014  Nickolay V. Shmyrev
",1
"    parser.add_argument(""text"", type=str, help=""text"")
",1
"        level=logging.INFO,
        format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"        for ref in dic[talk_id]:
",1
"            # print(talk_id + ' ' + ref)
",1
"            print(ref)
#!/usr/bin/env python3
# encoding: utf-8

",1
"# Copyright 2018 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"            line = line.strip().lower()
",1
"            ref = "" "".join(line.split()[1:])
            refs += [(utt_id, ref)]

    ctms = []
    with codecs.open(args.ctm, encoding=""utf-8"") as f:
",1
"
",1
"    start_t = None
    end_t = None
    hyp = """"
    num_lines = len(ctms)
",1
"                start_t = None
                end_t = None
                utt_id += 1

",1
"
    for i, (utt_id, start_t, end_t, hyp) in enumerate(hyps):
        assert end_t - start_t > 0
        print(
            ""%s_%07d_%07d %s %.2f %.2f""
",1
"        ""--trg"",
        ""-t"",
",1
"        help=""path to target language data"",
    )
",1
"    parser.add_argument(
        ""--src-vocab"",
",1
"    source_dicts: List = [
        convert_line_to_dict(line, vocab=src_vocab, name=""target2"")
        for line in open(args.src)
    ]
",1
"def get_args():
    parser = argparse.ArgumentParser(description=""my script"")
    parser.add_argument(""--path"", ""-p"", required=True, help=""path to decode dir"")
    args = parser.parse_args()
    return args
",1
"    for json_file in json_files:
",1
"0: empty token for CTC algorithm
1: special UNK token
",1
"    args = parser.parse_args()
    with codecs.open(args.text, ""r"", ""utf-8"") as fid:
",1
"            id = line[0]
",1
"import argparse
import codecs
import json
import logging
",1
"    js = {}
    for i, x in enumerate(args.jsons):
",1
"
",1
"        num_keys += len(ks)
        if i > 0:
            for k in ks:
                js[k + ""."" + str(i)] = j[""utts""][k]
        else:
",1
"            js = j[""utts""]
        # js.update(j['utts'])

    # logging.info('new json has ' + str(len(js.keys())) + ' utterances')
",1
"    logging.info(""new json has "" + str(num_keys) + "" utterances"")

    # ensure ""ensure_ascii=False"", which is a bug
    jsonstring = json.dumps(
",1
"import argparse
import codecs
import json
import logging
import sys
",1
"        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
",1
"    args = get_parser().parse_args(args)
    convert(args.json, args.refs, args.hyps, args.num_spkrs)

",1
"        hyp_file = codecs.open(hyps[ns], ""w"", encoding=""utf-8"")
        ref_file = codecs.open(refs[ns], ""w"", encoding=""utf-8"")
",1
"            # recognition hypothesis
            if num_spkrs == 1:
                seq = j[""utts""][x][""output""][0][""rec_text""].replace(""<eos>"", """")
            else:
                seq = j[""utts""][x][""output""][ns][0][""rec_text""].replace(""<eos>"", """")
",1
"

if __name__ == ""__main__"":
    main(sys.argv[1:])
",1
"#!/usr/bin/env python3
# encoding: utf-8

# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
"import argparse
",1
"import codecs
import json
import logging

from espnet.utils.cli_utils import get_commandline_args
",1
"        description=""convert ASR recognized json to text"",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
",1
"    parser.add_argument(""json"", type=str, help=""json files"")
    parser.add_argument(""dict"", type=str, help=""dict"")
    parser.add_argument(""ref"", type=str, help=""ref"")
    parser.add_argument(""hyp"", type=str, help=""hyp"")
",1
"    return parser
",1
"
    # logging info
    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
",1
"    logging.info(""reading %s"", args.json)
    with codecs.open(args.json, ""r"", encoding=""utf-8"") as f:
        j = json.load(f)

",1
"from __future__ import unicode_literals
",1
"
import argparse
import codecs
import json
",1
"    parser.add_argument(
",1
"        nargs=""+"",
        action=""append"",
        default=[],
        help=""Json files for the outputs"",
",1
"    parser.add_argument(
        ""--jsons"",
",1
"        type=str,
",1
"        nargs=""+"",
        action=""append"",
",1
"    # logging info
    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
    if args.verbose > 0:
",1
"                        intersec_ks = intersec_ks.intersection(set(ks))
                        if len(intersec_ks) == 0:
                            logging.warning(""No intersection"")
",1
"                else:
                    _dic = {}

                    # FIXME(kamo): ad-hoc way to change str to List[int]
",1
"                        elif ""idim"" in dic:
                            _dic[""shape""] = (int(dic[""idim""]),)

",1
"                            _dic[k2] = v
                    new_dic[k][jtype].append(_dic)

    # ensure ""ensure_ascii=False"", which is a bug
",1
"    if args.output is not None:
        sys.stdout = codecs.open(args.output, ""w"", encoding=""utf-8"")
    else:
        sys.stdout = codecs.getwriter(""utf-8"")(
            sys.stdout if is_python2 else sys.stdout.buffer
",1
"import re
import sys

",1
"    sys.stdin = codecs.getreader(""utf-8"")(sys.stdin if is_python2 else sys.stdin.buffer)
    sys.stdout = codecs.getwriter(""utf-8"")(
",1
"#!/usr/bin/env python3

",1
"import logging
import os
",1
"import librosa
import numpy as np
",1
"    """"""Convert log Mel filterbank to linear spectrogram.

    Args:
        lmspc (ndarray): Log Mel filterbank (T, n_mels).
        fs (int): Sampling frequency.
",1
"        f_max (int, optional): Maximum frequency to analyze.
",1
"            win_length=win_length,
",1
"    else:
",1
"    return y


def get_parser():
    parser = argparse.ArgumentParser(
",1
"        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""--fs"", type=int, default=22050, help=""Sampling frequency"")
    parser.add_argument(
",1
"        help=""Type of window"",
",1
"            spc = logmelspc_to_linearspc(
",1
"# encoding: utf-8

",1
"
",1
"    )
    parser.add_argument(""--key"", ""-k"", type=str, help=""key"")
    return parser


",1
"import museval
import numpy as np
from pystoi.stoi import stoi
import soundfile

",1
"
    Note(kamo):
",1
"    :return: value, perm
    :rtype: Tuple[Tuple[float, ...], Tuple[int, ...]]
    """"""
    if ref.shape != y.shape:
",1
"    if compute_permutation:
",1
"    value, perm = best_pairs
    return tuple(value), tuple(perm)

",1
"
def eval_PESQ(ref, enh, fs, compute_permutation: bool = True, wideband: bool = True):
    """"""Evaluate PESQ
",1
"
    PESQ program can be downloaded from here:
",1
"        http://www.itu.int/rec/dologin_pub.asp?lang=e&id=T-REC-P.862-200511-I!Amd2!SOFT-ZST-E&type=items

    Reference:
        Perceptual evaluation of speech quality (PESQ)-a new method
            for speech quality assessment of telephone networks and codecs
",1
"    :param compute_permutation (bool):
    """"""
",1
"    if shutil.which(""PESQ"") is None:
        raise RuntimeError(""PESQ: command not found: Please install"")
    if fs not in (8000, 16000):
",1
"                wv = str(os.path.join(d, ""ref.{}.{}.wav"".format(isrc, imic)))
                soundfile.write(wv, ref[isrc, :, imic].astype(np.int16), fs)
                refs.append(wv)

",1
"            enh_files.append(enhs)

        if compute_permutation:
            index_list = list(itertools.permutations(range(n_src)))
",1
"                lis = []
                for imic in range(n_mic):
                    # PESQ +<8000|16000> <ref.wav> <enh.wav> [smos] [cond]
",1
"                    else:
                        commands = [
",1
"        ""--outdir outputdir"".format(c=sys.argv[0]),
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""--verbose"", ""-V"", default=0, type=int, help=""Verbose option"")
",1
"    parser.add_argument(
        ""--enh"",
        dest=""enhfiles"",
",1
"        d = OrderedDict()
        with open(enh, ""r"") as f:
            for line in f:
                key, path = line.split(None, 1)
                d[key] = path.rstrip()
",1
"    writers = {k: open(os.path.join(args.outdir, k), ""w"") for k in evaltypes}

    for key in keylist:
",1
"        # ref_signals, enh_signals: (Nsrc, Nframe, Nmic)
        ref_signals = np.stack(ref_signals, axis=0)
        enh_signals = np.stack(enh_signals, axis=0)

        # 4. Evaluates
",1
"                    enh_signals,
",1
"                )
                writers[""ISR""].write(
",1
"                writers[""STOI""].write(""{} {}\n"".format(key, "" "".join(map(str, stoi))))

            elif evaltype == ""ESTOI"":
                estoi, perm = eval_STOI(
                    ref_signals,
",1
"                )
                writers[""ESTOI""].write(""{} {}\n"".format(key, "" "".join(map(str, estoi))))

            elif evaltype == ""PESQ"":
",1
"                )
                writers[""PESQ""].write(""{} {}\n"".format(key, "" "".join(map(str, pesq))))
            else:
",1
"                # Cannot reach
                raise RuntimeError
",1
"
from __future__ import division
from __future__ import print_function
",1
"        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""json"", type=str, help=""json file"")
    parser.add_argument(
        ""--parts"", ""-p"", type=int, help=""Number of subparts to be prepared"", default=0
",1
"    dirname = os.path.dirname(args.json)
    dirname = ""{}/split{}utt"".format(dirname, args.parts)
",1
"    if not os.path.exists(dirname):
        os.makedirs(dirname)

    # load json and split keys
",1
"    j = json.load(codecs.open(args.json, ""r"", encoding=""utf-8""))
    utt_ids = sorted(list(j[""utts""].keys()))
    logging.info(""number of utterances = %d"" % len(utt_ids))
    if len(utt_ids) < args.parts:
",1
"        )
        fl = ""{}/{}.{}.json"".format(dirname, filename, i + 1)
",1
"    parser.add_argument(""dict"", type=str, help=""dict"")
",1
"    parser.add_argument(
        ""--bpe"", type=str, default=None, nargs=""?"", help=""BPE model if applicable""
    )
",1
"                    spm_args = [
",1
"                ""sed"",
",1
"                ""-e"",
                ""s/ //g"",
                ""-e"",
                ""s/(/ (/"",
                ""-e"",
",1
"        os.remove(hyps[0])
",1
"        os.remove(hyps[0] + "".bak2"")
        os.remove(wrd_name(hyps[0]))
",1
"    )
    parser.add_argument(""scp_file"", type=str, help=""scp file"")
",1
"    os.makedirs(args.out_dir, exist_ok=True)
    with ReadHelper(f""scp:{args.scp_file}"") as f:
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"        if fn != ""-"":
",1
"            fd.close()
",1
"    total_count = sum(counts.values())
    invocab_count = 0
    vocabulary = []
    for w, c in sorted(counts.items(), key=lambda x: -x[1]):
        if c <= args.cutoff:
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

from __future__ import print_function
",1
"    )
    parser.add_argument(""text"", type=str, default=False, nargs=""?"", help=""input text"")
    parser.add_argument(
        ""--trans_type"",
        ""-t"",
",1
"        type=str,
",1
"        default=""char"",
        choices=[""char"", ""phn""],
        help=""""""Transcript type. char/phn. e.g., for TIMIT FADG0_SI1279 -
                        If trans_type is char,
",1
"    return parser


def main():
    parser = get_parser()
",1
"            rs = [re.compile(re.escape(x)) for x in nls]

    if args.text:
",1
"    sys.stdout = codecs.getwriter(""utf-8"")(
        sys.stdout if is_python2 else sys.stdout.buffer
    )
    line = f.readline()
",1
"        match_pos = []
        for r in rs:
            i = 0
            while i >= 0:
                m = r.search(a, i)
",1
"                if m:
",1
"        if args.trans_type == ""phn"":
            a = a.split("" "")
        else:
            if len(match_pos) > 0:
                chars = []
",1
"                    if start_pos is not None:
                        chars.append(a[start_pos:end_pos])
",1
"                        i += 1
                a = chars

            a = [a[j : j + n] for j in range(0, len(a), n)]

",1
"
        a_chars = [z.replace("" "", args.space) for z in a_flat]
        if args.trans_type == ""phn"":
            a_chars = [z.replace(""sil"", args.space) for z in a_chars]
",1
"

",1
"# encoding: utf-8

from __future__ import print_function
",1
"import logging
import sys

from espnet.utils.cli_utils import get_commandline_args
",1
"
PY2 = sys.version_info[0] == 2
sys.stdin = codecs.getreader(""utf-8"")(sys.stdin if PY2 else sys.stdin.buffer)
sys.stdout = codecs.getwriter(""utf-8"")(sys.stdout if PY2 else sys.stdout.buffer)

",1
"        ""--output-scps text:data/text shape:data/utt2text_shape:shape ""
        ""--scps utt2spk:data/utt2spk"".format(sys.argv[0]),
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
",1
"        ""--input-scps"",
",1
"        type=str,
",1
"    )
    parser.add_argument(
        ""--out"",
",1
"                    if not callable(type_func):
",1
"    #     ""utts"": {
    #         ""sample_id1"": {(omitted)},
    #         ""sample_id2"": {(omitted)},
",1
"    #
    # To reduce memory usage, reading the input text files for each lines
    # and writing JSON elements per samples.
    if args.out is None:
        out = sys.stdout
",1
"                            )

",1
"                    elif line.split()[0] != first.split()[0]:
",1
"                        concat = sum(input_infos + output_infos + infos, [])
",1
"                        if not args.allow_one_column:
",1
"            else:
                # If key == 'other'. only has the first item
",1
"PY2 = sys.version_info[0] == 2

",1
"                )
            key, wav = sps
            keys.append(key)
            wavs.append(wav.strip())

",1
"            )
",1
"# encoding: utf-8

",1
"    args = parser.parse_args(args)
    convert(args.json, args.dict, args.refs, args.hyps, args.srcs, args.dict_src)
",1
"    if hyps:
",1
"        hyp_file = codecs.open(hyps[0], ""w"", encoding=""utf-8"")
",1
"    ref_file = codecs.open(refs[0], ""w"", encoding=""utf-8"")
    if srcs:
        src_file = codecs.open(srcs[0], ""w"", encoding=""utf-8"")

",1
"            char_list_tgt[int(i)] for i in j[""utts""][x][""output""][0][""tokenid""].split()
        ]
        ref_file.write("" "".join(seq).replace(""<eos>"", """")),
        ref_file.write(
",1
"            "" ("" + j[""utts""][x][""utt2spk""].replace(""-"", ""_"") + ""-"" + x + "")\n""
",1
"                ]
            src_file.write("" "".join(seq).replace(""<eos>"", """")),
            src_file.write(
                "" ("" + j[""utts""][x][""utt2spk""].replace(""-"", ""_"") + ""-"" + x + "")\n""
            )
",1
"
    if hyps:
",1
"        hyp_file.close()
    ref_file.close()
    if srcs:
        src_file.close()
",1
"is_python2 = sys.version_info[0] == 2


def get_parser():
",1
"        )
        if len(word_split) > 0:
            step_int = int(math.floor(float(diff_int) / len(word_split)))
",1
"
def get_parser():
    parser = argparse.ArgumentParser(description=""convert trn to stm"")
    parser.add_argument(
        ""--orig-stm"",
",1
"    )
    parser.add_argument(""trn"", type=str, default=None, nargs=""?"", help=""input trn"")
",1
"            split[0] = split[0].replace(""(("", ""("")
",1
"        col1 = segm_info[0] + ""_"" + segm_info[1]
        col2 = segm_info[2]
        col3 = segm_info[3] + ""_"" + segm_info[4] + ""_"" + segm_info[5]
        start_time = str(int(segm_info[6]))
",1
"def get_parser():
    parser = argparse.ArgumentParser(
",1
"        default=""mat"",
        choices=[""mat"", ""hdf5"", ""sound.hdf5"", ""sound""],
",1
"    parser.add_argument(
",1
"    )
",1
"        ""--compression-method"",
        type=int,
        default=2,
        help=""Specify the method(if mat) or "" ""gzip-level(if hdf5)"",
",1
"    )
",1
"
    with file_writer_helper(
        args.wspecifier,
        filetype=args.out_filetype,
",1
"
if __name__ == ""__main__"":
    main()
",1
"
def main(args):
",1
"    args = get_parser().parse_args(args)
    filter_file(args.infile, args.filt, args.exclude)


",1
"import sys

from espnet.utils.cli_utils import get_commandline_args
",1
"def main(args):
    args = get_parser().parse_args(args)
    convert(args.json, args.dict, args.refs, args.hyps, args.num_spkrs)

",1
"                ]
            # In the recognition hypothesis,
            # the <eos> symbol is usually attached in the last part of the sentence
            # and it is removed below.
",1
"            if num_spkrs == 1:
",1
"    #  [r1h2, r2h3, r3h2], [r1h3, r2h2, r3h1], [r1h3, r2h1, r3h2]]]
    # ...
    permutationDFS(np.array(src), 0, perms)
",1
"    new_dic = {}
",1
"        error_rate = [
            sum(s[1:4]) / float(sum(s[0:3])) for s in perm_score
        ]  # (s+d+i) / (c+s+d)
",1
"    return new_dic
",1
"    }
    re_id = re.compile(re_id)
    re_patterns = {}
    for p in re_strings.keys():
",1
"        re_patterns[p] = re.compile(re_strings[p])

    results = {}
    tmp_id = None
",1
"    if tmp_ret != {}:
        results[tmp_id] = {result_key: tmp_ret}

    return {""utts"": results}

",1
"    # make intersection set for utterance keys
    intersec_keys = []
    for x in results.keys():
        j = results[x]

",1
"        ks = j[""utts""].keys()
        logging.info(x + "": has "" + str(len(ks)) + "" utterances"")
",1
"
        if len(intersec_keys) > 0:
            intersec_keys = intersec_keys.intersection(set(ks))
",1
"    parser = argparse.ArgumentParser(description=""evaluate permutation-free error"")
    parser.add_argument(
        ""--num-spkrs"", type=int, default=2, help=""number of mixed speakers.""
    )
    parser.add_argument(
",1
"        ""in ascending order of references (1st) and hypotheses (2nd), ""
        ""e.g. [r1h1, r1h2, r2h1, r2h2] in 2-speaker-mix case."",
    )
",1
"
            result = get_results(args.results[idx], key)
",1
"            results[key] = result
",1
"    scores, new_results = main()
    score_sum = np.sum(scores, axis=0, dtype=int)

    # Print results
    print(sys.argv)
",1
"    print(""Total Scores: (#C #S #D #I) "" + "" "".join(map(str, list(score_sum))))
",1
"            100 * sum(score_sum[1:4]) / float(sum(score_sum[0:3]))
",1
"#!/usr/bin/env python3
# encoding: utf-8

# Copyright 2018 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"
",1
"
",1
"
    # make intersection set for utterance keys
    js = []
    intersec_ks = []
",1
"                logging.warning(""Empty intersection"")
                break
        else:
",1
"        intersec_add_dic[k] = v

",1
"            if ""idim"" in adddic and ""ilen"" in adddic:
                in_add_dic[""shape""] = [int(adddic[""ilen""]), int(adddic[""idim""])]
",1
"            new_dic[key_id] = {
",1
"                ""input"": input_list,
                ""output"": orgdic[""output""],
                ""utt2spk"": orgdic[""utt2spk""],
            }
",1
"                out_add_dic[""shape""] = [int(adddic[""olen""]), int(adddic[""odim""])]
            elif ""odim"" in adddic:
                out_add_dic[""shape""] = [int(adddic[""odim""])]
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
",1
"
import kaldiio
import numpy

from espnet.transform.spectrogram import spectrogram
",1
"        help=""Analisys window length in point"",
    )
    parser.add_argument(
        ""--window"",
        type=str,
",1
"        ""--filetype"",
",1
"    parser.add_argument(
        ""--compress"", type=strtobool, default=False, help=""Save in compressed format""
    )
    parser.add_argument(
",1
"    parser.add_argument(
        ""--segments"",
",1
"        type=str,
        help=""segments-file format: each line is either""
        ""<segment-id> <recording-id> <start-time> <end-time>""
",1
"        compress=args.compress,
",1
"            if args.normalize is not None and args.normalize != 1:
                array = array / (1 << (args.normalize - 1))
            spc = spectrogram(
                x=array,
",1
"
if __name__ == ""__main__"":
    main()
#!/usr/bin/env python3

",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
from distutils.util import strtobool
",1
"import kaldiio
import numpy

from espnet.transform.spectrogram import logmelspectrogram
from espnet.utils.cli_utils import get_commandline_args
",1
"    parser.add_argument(
        ""--window"",
        type=str,
        default=""hann"",
",1
"        ""--write-num-frames"", type=str, help=""Specify wspecifer for utt2num_frames""
    )
    parser.add_argument(
        ""--filetype"",
        type=str,
",1
"        logging.basicConfig(level=logging.INFO, format=logfmt)
    else:
        logging.basicConfig(level=logging.WARN, format=logfmt)
    logging.info(get_commandline_args())

",1
"        args.wspecifier,
        filetype=args.filetype,
        write_num_frames=args.write_num_frames,
        compress=args.compress,
",1
"from espnet.utils.cli_utils import get_commandline_args
from espnet.utils.cli_writers import file_writer_helper


",1
"        help=""Specify the file format for output. ""
        '""mat"" is the matrix format in kaldi',
    )
",1
"    parser.add_argument(
",1
"    )
    parser.add_argument(""--verbose"", ""-V"", default=0, type=int, help=""Verbose option"")
",1
"    parser.add_argument(
        ""--normalize"",
",1
"        type=str,
",1
"    )
    parser.add_argument(""rspecifier"", type=str, help=""WAV scp file"")
    parser.add_argument(
",1
"        ""--segments"",
",1
"    args = parser.parse_args()

    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
    if args.verbose > 0:
",1
"        logging.basicConfig(level=logging.WARN, format=logfmt)
    logging.info(get_commandline_args())

    if args.preprocess_conf is not None:
",1
"                for k in avg.keys():
                    avg[k] += states[k]

        # average
        for k in avg.keys():
",1
"            if avg[k] is not None:
                avg[k] /= args.num

        torch.save(avg, args.out)

",1
"        raise ValueError(""Incorrect type of backend"")


",1
"    parser.add_argument(""--backend"", default=""chainer"", type=str)
    parser.add_argument(""--log"", default=None, type=str, nargs=""?"")
",1
"import yaml


",1
"            if attr.isdigit():
                attr = int(attr)
            indict = indict[attr]
        print(indict)
",1
"

",1
"    parser.add_argument(
        ""-a"",
        ""--arg"",
",1
"        help='e.g -d a -> ""a"" is removed from the input yaml',
    )
    return parser
",1
"            value = arg.translate(table)
            eles.append(""del-"" + value)
        for arg in args.arg:
            if ""="" not in arg:
                raise RuntimeError(f'""{arg}"" does\'t include ""=""')
",1
"            key, value = arg.split(""="")
            key = key.translate(table)
            value = value.translate(table)
            eles.append(key + value)

",1
"            outyaml = p.parent / (p.stem + "".2"" + p.suffix)

        outyaml = Path(outyaml)
    else:
        outyaml = Path(args.outyaml)
",1
"
    for arg in args.delete + args.arg:
        if ""="" in arg:
            key, value = arg.split(""="")
",1
"                    k = int(k)
                    if k >= len(d):
",1
"                        d += type(d)(None for _ in range(k - len(d) + 1))
                elif isinstance(d, dict):
                    if k not in d:
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"
import argparse
import logging
import os
import time
",1
"from scipy.io.wavfile import write
from sklearn.preprocessing import StandardScaler

from espnet.nets.pytorch_backend.wavenet import decode_mu_law
",1
"
    This module is used to perform noise shaping described in
    `An investigation of noise shaping with perceptual
     weighting for WaveNet-based speech generation`_.
",1
"        alpha (float): All pass constant value.
        n_shift (int): Shift length in points.

",1
"    .. _`An investigation of noise shaping with perceptual
        weighting for WaveNet-based speech generation`:
        https://ieeexplore.ieee.org/abstract/document/8461332

    """"""
",1
"
",1
"        os.makedirs(args.outdir)

    # load model config
",1
"    model_dir = os.path.dirname(args.model)
    train_args = torch.load(os.path.join(model_dir, ""model.conf""))

    # load statistics
",1
"    scaler = StandardScaler()
    with h5py.File(os.path.join(model_dir, ""stats.h5"")) as f:
        scaler.mean_ = f[""/melspc/mean""][()]
",1
"        dilation_depth=train_args.dilation_depth,
        dilation_repeat=train_args.dilation_repeat,
        kernel_size=train_args.kernel_size,
        upsampling_factor=train_args.upsampling_factor,
",1
"    )
    model.load_state_dict(torch.load(args.model, map_location=""cpu"")[""model""])
    model.eval()
    model.to(device)
",1
"        logging.info(
            ""generation speed = %s (sec / sample)""
            % ((time.time() - start_time) / (len(y) - 1))
",1
"        y = decode_mu_law(y, mu=train_args.n_quantize)

        # apply mlsa filter for noise shaping
        y = mlsa_filter(y)

",1
"            os.path.join(args.outdir, ""%s.wav"" % utt_id),
            args.fs,
",1
"if __name__ == ""__main__"":
    main()
#!/usr/bin/env python3
# encoding: utf-8
",1
"
from __future__ import print_function
from __future__ import unicode_literals

",1
"
from espnet.utils.cli_utils import get_commandline_args
",1
"    parser.add_argument(""jsons"", type=str, nargs=""+"", help=""json files"")
    return parser
",1
"    logging.info(get_commandline_args())

    # make intersection set for utterance keys
    js = {}
",1
"        sys.stdout if is_python2 else sys.stdout.buffer
    )
    print(jsonstring)
#!/usr/bin/env python3
",1
"    parser.add_argument(""--verbose"", ""-V"", default=0, type=int, help=""Verbose option"")
    parser.add_argument(
",1
"        default=""mat"",
        choices=[""mat"", ""hdf5""],
        help=""Specify the file format for the wspecifier. ""
",1
"
    parser.add_argument(
        ""--norm-means"",
",1
"        '""ark:utt2spk"")',
    )
    parser.add_argument(
",1
"        type=int,
        default=2,
",1
"    )
    parser.add_argument(
        ""rspecifier"", type=str, help=""Read specifier id. e.g. ark:some.ark""
    )
",1
"    parser.add_argument(
        ""wspecifier"", type=str, help=""Write specifier id. e.g. ark:some.ark""
",1
"        logging.basicConfig(level=logging.INFO, format=logfmt)
    else:
        logging.basicConfig(level=logging.WARN, format=logfmt)
",1
"        norm_means=args.norm_means,
        norm_vars=args.norm_vars,
        utt2spk=args.utt2spk,
        spk2utt=args.spk2utt,
        reverse=args.reverse,
",1
"#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Copyright 2018 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"        description=""Trim slience with simple power thresholding ""
        ""and make segments file."",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(""--fs"", type=int, help=""Sampling frequency"")
",1
"    parser.add_argument(
        ""--win_length"", type=int, default=1024, help=""Analisys window length in point""
    )
",1
"        ""--normalize"",
        choices=[1, 16, 24, 32],
        type=int,
",1
"    args = parser.parse_args()

    # set logger
    logfmt = ""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s""
    if args.verbose > 0:
",1
"        logging.basicConfig(level=logging.INFO, format=logfmt)
",1
"    logging.info(get_commandline_args())
",1
"    main()
#!/usr/bin/env python3
import argparse
import logging

",1
"        description=""Compute cepstral mean and ""
        ""variance normalization statistics""
",1
"    parser.add_argument(
        ""--preprocess-conf"",
",1
"    ):
        if is_scipy_wav_style(matrix):
            # If data is sound file, then got as Tuple[int, ndarray]
            rate, matrix = matrix
",1
"
        spk = utt2spk(utt)

",1
"        _cmvn_stats = np.empty(cmvn_shape, dtype=np.float64)
        _cmvn_stats[0, :-1] = sum_feats[spk]
        _cmvn_stats[1, :-1] = square_sum_feats[spk]

        _cmvn_stats[0, -1] = counts[spk]
",1
"        _cmvn_stats[1, -1] = 0.0

        # You can get the mean and std as following,
        # >>> N = _cmvn_stats[0, -1]
",1
"    if is_wspecifier:
        with file_writer_helper(
            args.wspecifier_or_wxfilename, filetype=args.out_filetype
",1
"        ) as writer:
",1
"            # Kaldi supports only matrix or vector
",1
"    parser = argparse.ArgumentParser(
",1
"    parser.add_argument(""--verbose"", ""-V"", default=0, type=int, help=""Verbose option"")
    parser.add_argument(
        ""--filetype"",
",1
"
    # logging info
",1
"        logging.basicConfig(level=logging.INFO, format=logfmt)
    else:
        logging.basicConfig(level=logging.WARN, format=logfmt)
    logging.info(get_commandline_args())
",1
"
    if args.preprocess_conf is not None:
        preprocessing = Transformation(args.preprocess_conf)
        logging.info(""Apply preprocessing: {}"".format(preprocessing))
",1
"            shape_str = "","".join(map(str, mat.shape))
        else:
            if len(mat) == 2 and isinstance(mat[1], tuple):
                # If data is sound file, Tuple[int, Tuple[int, ...]]
                rate, mat = mat
",1
"def str2int_tuple(integers: str) -> Optional[Tuple[int, ...]]:
",1
"    """"""

    >>> str2int_tuple('3,4,5')
",1
"    parser.add_argument(""--segments"", default=None)
    parser.add_argument(
        ""--fs"",
        type=humanfriendly_or_none,
",1
"        default=None,
        help=""If the sampling rate specified, "" ""Change the sampling rate."",
    )
    parser.add_argument(""--audio-format"", default=""wav"")
",1
"    else:
",1
"        utt2ref_channels = None

",1
"        with SoundScpWriter(
            args.outdir,
            Path(args.outdir) / f""{args.name}.scp"",
",1
"        ) as writer, out_num_samples.open(""w"") as fnum_samples:
            for uttid, (rate, wave) in tqdm(loader):
                # wave: (Time,) or (Time, Nmic)
",1
"                if wave.ndim == 2 and utt2ref_channels is not None:
",1
"                fnum_samples.write(f""{uttid} {len(wave)}\n"")
    else:
",1
"                                wave.astype(np.float64), rate, args.fs, axis=0
",1
"                        args.fs is None or args.fs == rate
                    ):
                        save_asis = True

",1
"    parser.add_argument(
        ""--filetype"",
        type=str,
        default=""mat"",
",1
"        choices=[""mat"", ""hdf5"", ""sound.hdf5"", ""sound""],
",1
"        help=""Specify the file format for the rspecifier. ""
        '""mat"" is the matrix format in kaldi',
",1
"        help=""The configuration file for the pre-processing"",
    )
",1
"        nargs=""?"",
        type=argparse.FileType(""w""),
        default=sys.stdout,
        help=""The output filename. "" ""If omitted, then output to sys.stdout"",
    )
",1
"    parser = get_parser()
    args = parser.parse_args()

",1
"    for utt, mat in file_reader_helper(
        args.rspecifier, args.filetype, return_shape=preprocessing is None
    ):
        if preprocessing is not None:
",1
"            if is_scipy_wav_style(mat):
                # If data is sound file, then got as Tuple[int, ndarray]
",1
"            shape_str = "","".join(map(str, mat.shape))
        else:
            if len(mat) == 2 and isinstance(mat[1], tuple):
",1
"

if __name__ == ""__main__"":
",1
"
# err(str(sys.argv))
id_prefix = sys.argv[2]
utt_ids = sys.argv[3:]
utt2trans = dict()
",1
"    trans = trans.strip().replace(""-"", "" "").upper()
",1
"        # Note(kamo): Changed from the original: isalpha() -> isalnum()
        # not trans.strip().replace(' ', '').replace(""'"", """").isalpha():
        err(
            ""The transcript for '%s'(user '%s') is not properly normalized - skipped!""
            % (u, id_prefix)
",1
"    if uid in unnorm_utt:
        continue  # avoid double reporting the same problem
",1
"from __future__ import unicode_literals

import argparse
import codecs
from io import open
",1
"import sys

",1
"sys.stdout = codecs.getwriter(""utf-8"")(sys.stdout.buffer)


if __name__ == ""__main__"":
",1
"        fil = [x.rstrip() for x in f]

",1
"    for x in sys.stdin:
        # extract text parts
",1
"# Copyright 2016  Allen Guo

",1
"# KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
# WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
# MERCHANTABLITY OR NON-INFRINGEMENT.
",1
"for x in [""train"", ""test""]:
    with open(
        os.path.join(an4_root, ""etc"", ""an4_"" + x + "".transcription"")
",1
"        os.path.join(""data"", x, ""utt2spk""), ""w""
    ) as utt2spk_f:

        text_f.truncate()
",1
"        wav_scp_f.truncate()
",1
"                words = words[:-5]
            source = re.search(r""\((.*)\)"", line).group(1)
            pre, mid, last = source.split(""-"")
",1
"                + "" -f wav -p -c 1 ""
",1
"                + os.path.join(an4_root, ""wav"", sph_dir[x], mid, source + "".sph"")
                + "" |\n""
            )
",1
"    ) as transcript_f, open(os.path.join(""data"", x, ""text""), ""w"") as text_f, open(
",1
"            text_f.write(utt_id + "" "" + words + ""\n"")
            wav_scp_f.write(
                utt_id
",1
"from __future__ import print_function
from __future__ import unicode_literals

import argparse
import codecs
",1
"        x = line.split()
        print("" "".join(x[: args.skip_ncols]), end="" "")
        print("" "".join([st.split(""+"")[0] for st in x[args.skip_ncols :]]))
import argparse
",1
"        >>> _ = parser.add_argument('--conf', action=NestedDictAction,
        ...                         default={'a': 4})
        >>> parser.parse_args(['--conf', 'a=3', '--conf', 'c=4'])
        Namespace(conf={'a': 3, 'c': 4})
",1
"        Namespace(conf={'a': 4, 'c': {'d': 4}})
        >>> parser.parse_args(['--conf', 'c.d=4', '--conf', 'c=2'])
",1
"  {op} <yaml-string>
e.g.
  {op} a=4
",1
"""""""

    def __init__(
",1
"    def __call__(self, parser, namespace, values, option_strings=None):
        # --{option} a.b=3 -> {'a': {'b': 3}}
        if ""="" in values:
            indict = copy.deepcopy(getattr(namespace, self.dest, {}))
            key, value = values.split(""="", maxsplit=1)
",1
"        else:
            setattr(namespace, self.dest, values)
",1
"                if not isinstance(value, dict):
                    syntax = self._syntax.format(op=option_strings)
                    mes = f""must be interpreted as dict: but got {values}\n{syntax}""
                    raise argparse.ArgumentTypeError(self, mes)
            except Exception:
",1
"                    raise argparse.ArgumentError(self, mes)
",1
"    # params: An ordered mapping of inspect.Parameter
    params = inspect.signature(func).parameters
    data = {p.name: p.default for p in params.values()}
",1
"    # Remove not yaml-serializable object
    data = yaml_serializable(data)
    return data
import argparse
import dataclasses
",1
"
from typeguard import check_type


def build_dataclass(dataclass, args: argparse.Namespace):
",1
"                f""args doesn't have {field.name}. You need to set it to ArgumentsParser""
            )
",1
"    """"""Convert log Mel filterbank to linear spectrogram.

    Args:
        lmspc: Log Mel filterbank (T, n_mels).
        fs: Sampling frequency.
",1
"        n_fft: The number of FFT points.
",1
"
    """"""
    # assert the size of input linear spectrogram
",1
"            win_length=win_length,
            window=window,
",1
"            center=True if spc.shape[1] > 1 else False,
        )
    else:
        # use slower version of Grriffin-Lim algorithm
        logging.warning(
",1
"            ""librosa version is old. use slow version of Grriffin-Lim algorithm.""
            ""if you want to use fast Griffin-Lim, please update librosa via ""
            ""`source ./path.sh && pip install librosa==0.7.0`.""
",1
"        n_shift: int,
        fs: int = None,
",1
"        win_length: int = None,
        window: Optional[str] = ""hann"",
        fmin: int = None,
        fmax: int = None,
        griffin_lim_iters: Optional[int] = 32,
",1
"    ):
        """"""Initialize module.

",1
"            n_iter=griffin_lim_iters,
",1
"        if n_mels is not None:
            self.params.update(fs=fs, n_mels=n_mels, fmin=fmin, fmax=fmax)

    def __repr__(self):
",1
"        Args:
            spc: Log Mel filterbank (T, n_mels)
                or linear spectrogram (T, n_fft // 2 + 1).
",1
"
        Returns:
",1
"            Reconstructed waveform (N,).

        """"""
        if self.logmel2linear is not None:
",1
"        ...     subwriter = writer[""sub.txt""]
        ...     # Write ""uttidA some/where/a.wav""
",1
"        ...     subwriter[""uttidA""] = ""some/where/a.wav""
        ...     subwriter[""uttidB""] = ""some/where/b.wav""

    """"""
",1
"            w = DatadirWriter((self.path / key))
            self.chilidren[key] = w
            self.has_children = True

        retval = self.chilidren[key]
",1
"            self.fd = self.path.open(""w"", encoding=""utf-8"")

        self.keys.add(key)
        self.fd.write(f""{key} {value}\n"")

",1
"                if prev_child is not None and prev_child.keys != child.keys:
",1
"                prev_child = child

        elif self.fd is not None:
",1
"    """"""
    assert check_argument_types()

    data = {}
",1
"            k, v = sps
            if k in data:
                raise RuntimeError(f""{k} is duplicated ({path}:{linenum})"")
",1
"        delimiter = "" ""
        dtype = np.long
",1
"        raise ValueError(f""Not supported loader_type={loader_type}"")

",1
"    d = read_2column_text(path)
",1
"                StringIO(v), ndmin=1, dtype=dtype, delimiter=delimiter
            )
        except ValueError:
",1
"    assert check_return_type(retval)
    return retval

",1
"
class SoundScpReader(collections.abc.Mapping):
",1
"
    """"""

",1
"    def __init__(
        self, fname, dtype=np.int16, always_2d: bool = False, normalize: bool = False,
    ):
",1
"        self.dtype = dtype
        self.always_2d = always_2d
        self.normalize = normalize
        self.data = read_2column_text(fname)
",1
"
    def get_path(self, key):
        return self.data[key]
",1
"
    Examples:
        key1 /some/path/a.wav
        key2 /some/path/b.wav
        key3 /some/path/c.wav
",1
"
        self.data = {}
",1
"        rate, signal = value
        assert isinstance(rate, int), type(rate)
        assert isinstance(signal, np.ndarray), type(signal)
",1
"
        self.fscp.write(f""{key} {wav}\n"")

        # Store the file path
        self.data[key] = str(wav)
",1
"
        self.data = {}

    def get_path(self, key):
        return self.data[key]
",1
"        np.save(str(p), value)
",1
"
class NpyScpReader(collections.abc.Mapping):
    """"""Reader class for a scp file of numpy file.
",1
"
    Examples:
        key1 /some/path/a.npy
",1
"    """"""

    def __init__(self, fname: Union[Path, str]):
",1
"
def str2bool(value: str) -> bool:
    return bool(strtobool(value))

",1
"        value = value[1:-1]
    elif value.startswith(""'"") and value.endswith(""'""):
        value = value[1:-1]
    return value

",1
"        >>> parser.parse_args(['--foo', '4.5'])
        Namespace(foo=4.5)
",1
"        >>> parser = argparse.ArgumentParser()
        >>> _ = parser.add_argument('--foo', type=str_or_none)
",1
"

def str2pair_str(value: str) -> Tuple[str, str]:
    """"""str2pair_str.

",1
"    Examples:
        >>> import argparse
        >>> str2pair_str('abc,def ')
        ('abc', 'def')
",1
"    a, b = value.split("","")

",1
"    # If the list values are given from yaml file,
    # the value givent to type() is shaped as python-list,
    # e.g. ['a', 'b', 'c'],
    # so we need to remove double quotes from it.
",1
"    return remove_quotes(a), remove_quotes(b)


def str2triple_str(value: str) -> Tuple[str, str, str]:
",1
"    """"""str2triple_str.

    Examples:
",1
"    size = sys.getsizeof(obj)
    if seen is None:
        seen = set()

",1
"

class SizedDict(collections.abc.MutableMapping):
",1
"        if shared:
            # NOTE(kamo): Don't set manager as a field because Manager, which includes
            # weakref object, causes following error with method=""spawn"",
",1
"import numpy as np
from typeguard import check_argument_types

from espnet2.utils.fileio import load_num_sequence_text

",1
"        >>> array = dataset[""uttA""]
",1
"        >>> assert array.shape == (123, 83)
        >>> array = dataset[""uttB""]
        >>> assert array.shape == (34, 83)

    """"""
",1
"        loader_type: str = ""csv_int"",
    ):
        assert check_argument_types()
        shape_file = Path(shape_file)
",1
"        self.utt2shape = load_num_sequence_text(shape_file, loader_type)
        self.dtype = np.dtype(dtype)
        self.low = low
        self.high = high
",1
"
def default_tarinfo(name) -> tarfile.TarInfo:
    """"""Generate TarInfo using system information""""""
    tarinfo = tarfile.TarInfo(str(name))
",1
"        tarinfo.uid = os.getuid()
    tarinfo.mtime = datetime.now().timestamp()
",1
"        retval = defaultdict(list)
        for tarinfo in tar:
            outname = outpath / tarinfo.name
            outname.parent.mkdir(parents=True, exist_ok=True)
",1
"        retval = {k: v[0] if len(v) == 1 else v for k, v in retval.items()}
",1
"        files=list(files_map),
        yaml_files=list(yaml_files_map),
        timestamp=datetime.now().timestamp(),
        python=sys.version,
",1
"    try:
",1
"        for dst, dic in yaml_files_map.items():
            # Dump dict as yaml-bytes
",1
"            tarinfo = default_tarinfo(dst)
            tarinfo.size = fileobj.getbuffer().nbytes
            tar.addfile(tarinfo, fileobj=fileobj)
        for dst, src in files_map.items():
            # Resolve to avoid symbolic link
",1
"from typing import Tuple

import torch
from typeguard import check_argument_types
",1
"
class UtteranceMVN(AbsNormalize):
    def __init__(
",1
"
    def forward(
        self, x: torch.Tensor, ilens: torch.Tensor = None
",1
"def utterance_mvn(
    x: torch.Tensor,
    ilens: torch.Tensor = None,
",1
"    """"""Apply utterance mean and variance normalization

    Args:
        x: (B, T, D), assumed zero padded
        ilens: (B,)
",1
"    # Zero padding
    if x.requires_grad:
        x = x.masked_fill(make_pad_mask(ilens, x, 1), 0.0)
",1
"    if norm_means:
        x -= mean
",1
"
        if norm_vars:
            var = x.pow(2).sum(dim=1, keepdim=True) / ilens_
",1
"            std = torch.clamp(var.sqrt(), min=eps)
            x = x / std.sqrt()
        return x, ilens
    else:
",1
"from typing import Sequence
from typing import Union
",1
"        mask_width_range: Select the width randomly between this range
    """"""

    org_size = spec.size()
    if spec.dim() == 4:
",1
"    mask = mask.any(dim=1)
    if dim == 1:
        # mask: (Batch, Length, 1)
",1
"            if dim == ""time"":
                dim = 1
            elif dim == ""freq"":
                dim = 2
",1
"            else:
                raise ValueError(""dim must be int, 'time' or 'freq'"")
        if dim == 1:
            self.mask_axis = ""time""
",1
"    def extra_repr(self):
        return (
            f""mask_width_range={self.mask_width_range}, ""
            f""num_mask={self.num_mask}, axis={self.mask_axis}""
",1
"        )

    def forward(self, spec: torch.Tensor, spec_lengths: torch.Tensor = None):
        """"""Forward function.
",1
"            spec,
",1
"    """"""Apply global mean and variance normalization

    TODO(kamo): Make this class portable somehow

",1
"    """"""

",1
"        stats_file = Path(stats_file)

        self.stats_file = stats_file
",1
"        else:
",1
"            # New style: Npz file
            count = stats[""count""]
            sum_v = stats[""sum""]
            sum_square_v = stats[""sum_square""]
",1
"            mean = sum_v / count
            var = sum_square_v / count - mean * mean
",1
"        """"""Forward function

",1
"        norm_vars = self.norm_vars
        self.mean = self.mean.to(x.device, x.dtype)
        self.std = self.std.to(x.device, x.dtype)
",1
"import numpy as np
import torch
from typing import Tuple
",1
"        n_fft: int > 0 [scalar] number of FFT components
        n_mels: int > 0 [scalar] number of Mel bands to generate
",1
"        fmax: float >= 0 [scalar] highest frequency (in Hz).
            If `None`, use `fmax = fs / 2.0`
        htk: use HTK formula instead of Slaney
        norm: {None, 1, np.inf} [scalar]
",1
"            if 1, divide the triangular mel weights by the width of the mel band
            (area normalization).  Otherwise, leave all the triangles aiming for
            a peak value of 1.0
",1
"        n_fft: int = 512,
        n_mels: int = 80,
        fmin: float = None,
",1
"        self.mel_options = _mel_options

",1
"        self.register_buffer(""inv_melmat"", torch.from_numpy(inv_mel.T).float())

    def extra_repr(self):
        return "", "".join(f""{k}={v}"" for k, v in self.mel_options.items())

",1
"from espnet.nets.pytorch_backend.nets_utils import pad_list


if LooseVersion(torch.__version__) >= LooseVersion(""1.1""):
    DEFAULT_TIME_WARP_MODE = ""bicubic""
",1
"    def extra_repr(self):
        return f""window={self.window}, mode={self.mode}""

    def forward(self, x: torch.Tensor, x_lengths: torch.Tensor = None):
        """"""Forward function.
",1
"from typing import Optional
from typing import Tuple
from typing import Union

import torch
",1
"class Stft(torch.nn.Module, InversibleInterface):
    def __init__(
        self,
",1
"        onesided: bool = True,
    ):
",1
"        if win_length is None:
            self.win_length = n_fft
",1
"
",1
"            input,
            n_fft=self.n_fft,
",1
"            hop_length=self.hop_length,
",1
"    def inverse(
        self, input: torch.Tensor, ilens: torch.Tensor = None
    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        # TODO(kamo): torch audio?
",1
"        raise NotImplementedError
from abc import ABC
",1
"        normalize: Optional[AbsNormalize],
        encoder: AbsEncoder,
        decoder: AbsDecoder,
        ctc: CTC,
        rnnt_decoder: None,
",1
"        assert rnnt_decoder is None, ""Not implemented""

        super().__init__()
        # note that eos is the same as sos (equivalent ID)
        self.sos = vocab_size - 1
",1
"
        self.frontend = frontend
        self.specaug = specaug
        self.normalize = normalize
        self.encoder = encoder
",1
"        if report_cer or report_wer:
            self.error_calculator = ErrorCalculator(
                token_list, sym_space, sym_blank, report_cer, report_wer
            )
",1
"        Args:
            speech: (Batch, Length, ...)
            speech_lengths: (Batch, )
",1
"            text: (Batch, Length)
            text_lengths: (Batch,)
        """"""
        assert text_lengths.dim() == 1, text_lengths.shape
",1
"
        # 2b. CTC branch
",1
"        else:
            loss = self.ctc_weight * loss_ctc + (1 - self.ctc_weight) * loss_att

        stats = dict(
            loss=loss.detach(),
",1
"            cer_ctc=cer_ctc,
        )

        # force_gatherable: to-device and to-tensor if scalar for DataParallel
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)
",1
"    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """"""Frontend + Encoder. Note that this method is used by asr_inference.py

        Args:
            speech: (Batch, Length, ...)
",1
"        # 2. Data augmentation for spectrogram
        if self.specaug is not None and self.training:
            feats, feats_lengths = self.specaug(feats, feats_lengths)

",1
"            encoder_out.size(),
            speech.size(0),
        )
        assert encoder_out.size(1) <= encoder_out_lens.max(), (
            encoder_out.size(),
",1
"            #  e.g. STFT and Feature extract
",1
"        encoder_out_lens: torch.Tensor,
        ys_pad: torch.Tensor,
        ys_pad_lens: torch.Tensor,
    ):
        ys_in_pad, ys_out_pad = add_sos_eos(ys_pad, self.sos, self.eos, self.ignore_id)
",1
"        acc_att = th_accuracy(
",1
"        encoder_out_lens: torch.Tensor,
",1
"
    Args:
        odim: dimension of outputs
",1
"            import warpctc_pytorch as warp_ctc
",1
"            th_target = th_target.cpu().int()
            th_ilen = th_ilen.cpu().int()
            th_olen = th_olen.cpu().int()
",1
"        # (B, L) -> (BxL,)
        ys_true = torch.cat([ys_pad[i, :l] for i, l in enumerate(ys_lens)])

",1
"            Tensor hs_pad: 3d tensor (B, Tmax, eprojs)
",1
"
        Args:
            torch.Tensor hs_pad: 3d tensor (B, Tmax, eprojs)
        Returns:
            torch.Tensor: argmax applied 2d tensor (B, Tmax)
",1
"
from espnet.nets.pytorch_backend.frontends.frontend import Frontend
",1
"
class DefaultFrontend(AbsFrontend):
    """"""Conventional frontend structure for ASR

",1
"        # ""2"" refers to the real/imag parts of Complex
        assert input_stft.shape[-1] == 2, input_stft.shape

",1
"                input_stft = input_stft[:, :, ch, :]
            else:
                # Use the first channel
                input_stft = input_stft[:, :, 0, :]

",1
"

class AbsFrontend(torch.nn.Module, ABC):
",1
"    def forward(
        self, input: torch.Tensor, input_lengths: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        raise NotImplementedError
",1
"import torch

from espnet2.asr.specaug.abs_specaug import AbsSpecAug
from espnet2.layers.mask_along_axis import MaskAlongAxis
from espnet2.layers.time_warp import TimeWarp
",1
"    Reference:
        Daniel S. Park et al.
        ""SpecAugment: A Simple Data
         Augmentation Method for Automatic Speech Recognition""

",1
"    .. warning::
        When using cuda mode, time_warp doesn't have reproducibility
        due to `torch.nn.functional.interpolate`.

",1
"        apply_time_mask: bool = True,
        time_mask_width_range: Union[int, Sequence[int]] = (0, 100),
        num_time_mask: int = 2,
",1
"        super().__init__()
        self.apply_time_warp = apply_time_warp
        self.apply_freq_mask = apply_freq_mask
",1
"    """"""Abstract class for the augmentation of spectrogram

    The process-flow:
",1
"

class RNNEncoder(AbsEncoder):
",1
"        use_projection: Use projection layer or not
        num_layers: Number of recurrent layers
",1
"    """"""

    def __init__(
        self,
",1
"        input_size: int,
        rnn_type: str = ""lstm"",
",1
"        subsample: Optional[Sequence[int]] = (2, 2, 1, 1),
    ):
        assert check_argument_types()
        super().__init__()
",1
"        self._output_size = output_size
        self.rnn_type = rnn_type
        self.bidirectional = bidirectional
        self.use_projection = use_projection
",1
"        rnn_type = (""b"" if bidirectional else """") + rnn_type
        if use_projection:
            self.enc = torch.nn.ModuleList(
                [
",1
"                    RNNP(
",1
"                ]
",1
"        if prev_states is None:
            prev_states = [None] * len(self.enc)
",1
"from espnet2.asr.encoder.abs_encoder import AbsEncoder

",1
"        in_channel: int = 1,
    ):
        assert check_argument_types()
",1
"
        # Subsample is not used for VGGRNN
        subsample = np.ones(num_layers + 1, dtype=np.int)
",1
"                        typ=rnn_type,
",1
"                    ),
                ]
            )

    def output_size(self) -> int:
",1
"        return self._output_size
",1
"        return xs_pad, ilens, current_states
",1
"from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm
from espnet.nets.pytorch_backend.transformer.multi_layer_conv import Conv1dLinear
",1
"        attention_heads: the number of heads of multi head attention
        linear_units: the number of units of position-wise feed forward
        num_blocks: the number of decoder blocks
",1
"        normalize_before: whether to use layer_norm before the first block
        concat_after: whether to concat attention layer's input and output
",1
"            if False, no additional linear will be applied.
            i.e. x -> x + att(x)
        positionwise_layer_type: linear of conv1d
",1
"    """"""

    def __init__(
        self,
        input_size: int,
",1
"        assert check_argument_types()
        super().__init__()
",1
"                output_size,
                linear_units,
                positionwise_conv_kernel_size,
                dropout_rate,
",1
"            lambda: EncoderLayer(
",1
"                MultiHeadedAttention(
                    attention_heads, output_size, attention_dropout_rate
",1
"                ),
                positionwise_layer(*positionwise_layer_args),
                dropout_rate,
                normalize_before,
                concat_after,
",1
"            ),
        )
        if self.normalize_before:
            self.after_norm = LayerNorm(output_size)

",1
"        else:
            xs_pad = self.embed(xs_pad)
",1
"        olens = masks.squeeze(1).sum(1)
        return xs_pad, olens, None
from abc import ABC
from abc import abstractmethod
from typing import Optional
",1
"
    @abstractmethod
    def forward(
",1
"from typing import List
",1
"from espnet2.asr.decoder.abs_decoder import AbsDecoder


",1
"    Args:
        vocab_size: output dim
        encoder_output_size: dimension of attention
",1
"        num_blocks: the number of decoder blocks
",1
"    def __init__(
",1
"        self,
        vocab_size: int,
        encoder_output_size: int,
        attention_heads: int = 4,
",1
"        use_output_layer: bool = True,
        pos_enc_class=PositionalEncoding,
        normalize_before: bool = True,
",1
"            )
        else:
            raise ValueError(f""only 'embed' or 'linear' is supported: {input_layer}"")

",1
"        self.normalize_before = normalize_before
        self.decoders = repeat(
            num_blocks,
            lambda: DecoderLayer(
                attention_dim,
",1
"                MultiHeadedAttention(
                    attention_heads, attention_dim, self_attention_dropout_rate
",1
"            self.output_layer = torch.nn.Linear(attention_dim, vocab_size)
        else:
            self.output_layer = None

    def forward(
",1
"        self,
",1
"        ys_in_lens: torch.Tensor,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
",1
"        Returns:
            (tuple): tuple containing:
",1
"            cache: cached output list of (batch, max_time_out-1, size)
",1
"        if self.normalize_before:
",1
"    # beam search API (see ScorerInterface)
",1
"
    def score(self, ys, state, x):
        """"""Score.""""""
        ys_mask = subsequent_mask(len(ys), device=x.device).unsqueeze(0)
",1
"
",1
"from espnet.nets.pytorch_backend.nets_utils import to_device
",1
"from espnet.nets.pytorch_backend.rnn.attentions import initial_att
from espnet2.asr.decoder.abs_decoder import AbsDecoder
from espnet2.utils.get_default_kwargs import get_default_kwargs

",1
"    han_conv_chans: int = -1,
    han_conv_filts: int = 100,
    han_win: int = 5,
):
",1
"                han_win,
                han_conv_chans,
",1
"            for idx in range(num_encs):
                att = initial_att(
                    atype[idx],
                    eprojs,
",1
"                att_list.append(att)
",1
"
class RNNDecoder(AbsDecoder):
    def __init__(
",1
"        replace_sos: bool = False,
        num_encs: int = 1,
        att_conf: dict = get_default_kwargs(build_attention_list),
    ):
",1
"        att_idx = min(strm_idx, len(self.att_list) - 1)

        # hlens should be list of list of integer
        hlens = [list(map(int, hlens[idx])) for idx in range(self.num_encs)]

",1
"        z_all = []
        if self.num_encs == 1:
",1
"            att_w = None
            self.att_list[att_idx].reset()  # reset pre-computation of h
        else:
            att_w_list = [None] * (self.num_encs + 1)  # atts + han
",1
"        eys = self.dropout_emb(self.embed(ys_in_pad))  # utt x olen x zdim

        # loop for an output sequence
",1
"                for idx in range(self.num_encs):
                    att_c_list[idx], att_w_list[idx] = self.att_list[idx](
                        hs_pad[idx],
",1
"            if i > 0 and random.random() < self.sampling_probability:
                z_out = self.output(z_all[-1])
",1
"        z_all = self.output(z_all)
        z_all.masked_fill_(
            make_pad_mask(ys_in_lens, z_all, 1), 0,
",1
"        z_list = [self.zero_state(x[0].unsqueeze(0))]
        for _ in range(1, self.dlayers):
            c_list.append(self.zero_state(x[0].unsqueeze(0)))
",1
"            a = [None] * (self.num_encs + 1)  # atts + han
            for idx in range(self.num_encs + 1):
",1
"                # reset pre-computation of h in atts and han
",1
"
    def score(self, yseq, state, x):
        # to support mutiple encoder asr mode, in single encoder mode,
        # convert torch.Tensor to List of torch.Tensor
",1
"            logits = self.output(
",1
"                torch.cat((self.dropout_dec[-1](z_list[-1]), att_c), dim=-1)
            )
",1
"        return (
            logp,
",1
"            dict(
                c_prev=c_list[:],
                z_prev=z_list[:],
",1
"
if LooseVersion(torch.__version__) >= LooseVersion(""1.1.0""):
    from torch.utils.tensorboard import SummaryWriter
else:
    from tensorboardX import SummaryWriter
",1
"
",1
"def to_reported_value(v: Num, weight: Num = None) -> ""ReportedValue"":
    assert check_argument_types()
    if isinstance(v, (torch.Tensor, np.ndarray)):
        if np.prod(v.shape) != 1:
            raise ValueError(f""v must be 0 or 1 dimension: {len(v.shape)}"")
",1
"        v = v.item()

    if isinstance(weight, (torch.Tensor, np.ndarray)):
        if np.prod(weight.shape) != 1:
",1
"        retval = WeightedAverage(v, weight)
",1
"    else:
        retval = Average(v)
    assert check_return_type(retval)
    return retval
",1
"

def aggregate(values: Sequence[""ReportedValue""]) -> Num:
",1
"    assert check_argument_types()

    for v in values:
        if not isinstance(v, type(values[0])):
",1
"            retval = np.nan

    else:
        raise NotImplementedError(f""type={type(values[0])}"")
    assert check_return_type(retval)
",1
"

class SubReporter:
",1
"        return self.total_count

    def get_epoch(self) -> int:
",1
"        not_increment_count: bool = False,
    ) -> None:
        assert check_argument_types()
",1
"
        message = (
            f""{self.epoch}epoch:{self.key}:""
            f""{self.prev_count + 1}-{self.count}batch: ""
        )
",1
"                message += f""{key2}={v:.3e}""

        self.prev_count = self.count
",1
"                yield retval
            except StopIteration:
                break


",1
"        >>> reporter = Reporter()
        >>> with reporter.observe('train') as sub_reporter:
        ...     for batch in iterator:
        ...         stats = dict(loss=0.2)
",1
"        assert check_argument_types()
",1
"        self.epoch = epoch
        # stats: Dict[int, Dict[str, Dict[str, float]]]
        # e.g. self.stats[epoch]['train']['loss']
        self.stats = {}

",1
"        sub_reporter = self.start_epoch(key, epoch)
        yield sub_reporter
        # Receive the stats from sub_reporter
        self.finish_epoch(sub_reporter)
",1
"
        if self.epoch - 1 not in self.stats or key not in self.stats[self.epoch - 1]:
            # If the previous epoch doesn't exist for some reason,
            # maybe due to bug, this case also indicates 0-count.
            if self.epoch - 1 != 0:
",1
"
",1
"
    def sort_epochs(self, key: str, key2: str, mode: str) -> List[int]:
        return [e for e, v in self.sort_epochs_and_values(key, key2, mode)]

",1
"        return self.sort_epochs(key, key2, mode)[nbest]

    def check_early_stopping(
        self,
        patience: int,
",1
"    ) -> bool:
        if logger is None:
            logger = logging
        if epoch is None:
",1
"        best_epoch = self.get_best_epoch(key1, key2, mode)
        if epoch - best_epoch > patience:
            logger.info(
                f""[Early stopping] {key1}.{key2} has not been ""
",1
"        else:
            return False

    def has(self, key: str, key2: str, epoch: int = None) -> bool:
",1
"        if epoch is None:
",1
"                    if isinstance(v, float):
                        if abs(v) > 1.0e3:
",1
"                            _message += f""{key2}={v:.3f}""
",1
"                    message += f""{epoch}epoch results: ""
",1
"            raise TypeError(f""Input as [{keys}]"")

        import matplotlib

        matplotlib.use(""agg"")
",1
"        import matplotlib.pyplot as plt
        import matplotlib.ticker as ticker

",1
"        plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))
        plt.xlabel(""epoch"")
        plt.ylabel(key2)
        plt.grid()

",1
"        return plt

    def tensorboard_add_scalar(self, summary_writer: SummaryWriter, epoch: int = None):
",1
"                    k: self.stats[epoch][k][key2]
                    for k in self.get_keys(epoch)
",1
"class AbsPreprocessor(ABC):
    def __init__(self, train: bool):
        self.train = train
",1
"        self.train = train
        self.speech_name = speech_name
        self.text_name = text_name

",1
"                bpemodel=bpemodel,
                delimiter=delimiter,
                space_symbol=space_symbol,
",1
"    def __call__(
        self, uid: str, data: Dict[str, Union[str, np.ndarray]]
    ) -> Dict[str, np.ndarray]:
        assert check_argument_types()

",1
"from typing import Dict
from typing import Iterable
from typing import List
from typing import Optional
",1
"from typing import Sequence
",1
"
from espnet2.iterators.abs_iter_factory import AbsIterFactory
from espnet2.main_funcs.calculate_all_attentions import calculate_all_attentions
",1
"    and override the methods if necessary - at least ""train_one_epoch()""

    >>> class TwoOptimizerTrainer(Trainer):
    ...     num_optimizers: int = 1
    ...
",1
"    ...     @classmethod
    ...     def add_arguments(cls, parser):
    ...         ...
    ...
    ...     @classmethod
",1
"    ...     def train_one_epoch(cls, model, optimizers, ...):
    ...         loss1 = model.model1(...)
    ...         loss1.backward()
",1
"    ...         optimizers[1].step()

    """"""

",1
"        model: AbsESPnetModel,
        optimizers: Sequence[torch.optim.Optimizer],
",1
"        best_model_criterion: Sequence[Sequence[str]],
        val_scheduler_criterion: Sequence[str],
        trainer_options,
        distributed_option: DistributedOption,
    ) -> None:
",1
"
        # NOTE(kamo): trainer_options doesn't always have ""train_dtype""
",1
"            ""O2"",
            ""O3"",
        )
        if use_apex:
",1
"            try:
                from apex import amp
            except ImportError:
                logging.error(
                    ""You need to install apex. ""
",1
"                output_device=(
                    torch.cuda.current_device()
                    if distributed_option.ngpu == 1
                    else None
                ),
",1
"                    schedulers=schedulers,
                    iterator=train_iter_factory.build_iter(iepoch),
                    reporter=sub_reporter,
",1
"
            if not distributed_option.distributed or distributed_option.dist_rank == 0:
                # att_plot doesn't support distributed
                if plot_attention_iter_factory is not None:
",1
"            if not distributed_option.distributed or distributed_option.dist_rank == 0:
                # 3. Report the results
                logging.info(reporter.log_message())
",1
"                        ],
                        ""amp"": amp.state_dict() if use_apex else None,
                    },
",1
"                # 5. Save the model and update the link to the best model
                torch.save(model.state_dict(), output_dir / f""{iepoch}epoch.pth"")

                # Creates a sym link latest.pth -> {iepoch}epoch.pth
",1
"                    if reporter.has(_phase, k):
                        best_epoch = reporter.get_best_epoch(_phase, k, _mode)
                        # Creates sym links if it's the best result
                        if best_epoch == iepoch:
                            p = output_dir / f""{_phase}.{k}.best.pth""
",1
"                    break

",1
"        cls,
        model: torch.nn.Module,
        iterator: Iterable[Tuple[List[str], Dict[str, torch.Tensor]]],
",1
"        ngpu = options.ngpu
        distributed = isinstance(model, torch.nn.parallel.DistributedDataParallel)
        use_apex = options.train_dtype in (""O0"", ""O1"", ""O2"", ""O3"")
",1
"                stats, weight = recursive_average(stats, weight, distributed)

                # Now weight is summation over all workers
",1
"
",1
"                    loss.backward()

            if iiter % accum_grad == 0:
                # gradient noise injection
                if grad_noise:
",1
"                    add_gradient_noise(
                        model,
                        reporter.get_total_count(),
",1
"                        duration=100,
                        eta=1.0,
                        scale_factor=0.55,
                    )

",1
"                    model.parameters(), grad_clip
                )
                # PyTorch<=1.4, clip_grad_norm_ returns float value
",1
"                    with reporter.measure_time(""optim_step_time""):
                        optimizer.step()
                    if isinstance(scheduler, AbsBatchStepScheduler):
                        scheduler.step()
",1
"                # Register lr and train/load time[sec/step],
                # where step refers to accum_grad * mini-batch
",1
"
        else:
            if distributed:
                iterator_stop.fill_(1)
                torch.distributed.all_reduce(iterator_stop, ReduceOp.SUM)
",1
"        cls,
",1
"        model: torch.nn.Module,
        iterator: Iterable[Dict[str, torch.Tensor]],
        reporter: SubReporter,
        options: TrainerOptions,
    ) -> None:
",1
"                # if distributed, this method can also apply all_reduce()
",1
"                stats, weight = recursive_average(stats, weight, distributed)
",1
"
    @classmethod
    @torch.no_grad()
",1
"        reporter: SubReporter,
        options: TrainerOptions,
    ) -> None:
",1
"            batch = to_device(batch, ""cuda"" if ngpu > 0 else ""cpu"")
            if no_forward_run:
                continue

            # 1. Forwarding model and gathering all attentions
",1
"                    axes = fig.subplots(1, len(att_w))
                    if len(att_w) == 1:
                        axes = [axes]

                    for ax, aw in zip(axes, att_w):
",1
"                        ax.yaxis.set_major_locator(MaxNLocator(integer=True))

                    if output_dir is not None:
",1
"        self.rate = rate
        # Multichannel wave fie
        # array: (NSample, Channel) or (Nsample)
",1
"
    def __iter__(self):
",1
"    # NOTE(kamo): SoundScpReader doesn't support pipe-fashion
    # like Kaldi e.g. ""cat a.wav |"".
    # NOTE(kamo): The audio signal is normalized to [-1,1] range.
",1
"

",1
"def pipe_wav_loader(path, float_dtype):
    # The file is as follows:
",1
"    # NOTE(kamo): I don't think this case is practical
    # because subprocess takes much times due to fork().

    # NOTE(kamo): kaldiio doesn't normalize the signal.
",1
"def rand_int_loader(filepath, loader_type):
    # e.g. rand_int_3_10
    try:
        low, high = map(int, loader_type[len(""rand_int_"") :].split(""_""))
    except ValueError:
",1
"    # e.g. imagefolder_256x256
    # /
    #   |- horse/
    #   â    |- 8537.png
    #   â    |- ...
",1
"    #   |- butterfly/
    #   â    |- 2857.png
",1
"    # folder dataset
    return torchvision.datasets.ImageFolder(
",1
"        ""\n\n""
        ""   utterance_id_a a.wav\n""
        ""   utterance_id_b b.wav\n""
        ""   ..."",
    ),
",1
"        help=""Kaldi wav.scp file. If the file doesn't include a pipe, '|' ""
        ""for each line, use 'sound' instead.""
        "":\n\n""
",1
"    ""kaldi_ark"": dict(
        func=kaldiio.load_scp,
        kwargs=[],
        help=""Kaldi-ark file type.""
        ""\n\n""
",1
"        help=""A text file in which is written a sequence of interger numbers ""
        ""separated by space.""
",1
"    ),
    ""text_float"": dict(
        func=functools.partial(load_num_sequence_text, loader_type=""text_float""),
        kwargs=[],
        help=""A text file in which is written a sequence of float numbers ""
",1
"        ""separated by space.""
        ""\n\n""
        ""   utterance_id_A 12. 3.1 3.4 4.4\n""
        ""   utterance_id_B 3. 3.12 1.1\n""
",1
"        help=""A text file in which is written a sequence of float numbers ""
        ""separated by comma.""
",1
"        ""   ..."",
    ),
",1
"        float_dtype: str = ""float32"",
        int_dtype: str = ""long"",
        max_cache_size: Union[float, int, str] = 0.0,
    ):
        assert check_argument_types()
",1
"
        self.float_dtype = float_dtype
        self.int_dtype = int_dtype

        self.loader_dict = {}
",1
"        if max_cache_size > 0:
            self.cache = SizedDict(shared=True)
",1
"    ]:
",1
"        else:
            raise RuntimeError(f""Not supported: loader_type={loader_type}"")

    def has_name(self, name) -> bool:
        return name in self.loader_dict
",1
"    # Typically pytorch's Dataset.__getitem__ accepts an inger index,
    # however this Dataset handle a string, which represents a sample-id.
    def __getitem__(
",1
"        if self.cache is not None and uid in self.cache:
            data = self.cache[uid]
            return uid, data

",1
"        data = {}
        # 1. Load data from each loaders
        for name, loader in self.loader_dict.items():
",1
"                    )
",1
"
",1
"            if isinstance(value, (np.ndarray, torch.Tensor, str, numbers.Number)):
                # torch.Tensor is converted to ndarray
                if isinstance(value, torch.Tensor):
                    value = value.numpy()
",1
"                data[name] = value

            # The return value of ESPnet dataset must be a dict of ndarrays,
            # so we need to parse a container of ndarrays
            # if dict:
",1
"                        v = v.numpy()
",1
"                    elif isinstance(v, numbers.Number):
",1
"            if value.dtype.kind == ""f"":
                value = value.astype(self.float_dtype)
",1
"            elif value.dtype.kind == ""i"":
                value = value.astype(self.int_dtype)
            else:
                raise NotImplementedError(f""Not supported dtype: {value.dtype}"")
            data[name] = value
",1
"
        retval = uid, data
        assert check_return_type(retval)
        return retval
",1
"    our training system and the your task class are
",1
"    Example:
",1
"        ...         return loss, stats, weight
",1
"            raise ValueError('""none"", ""nil"", and ""null"" are reserved.')
        if type_check is not None:
",1
"            for v in self.classes.values():
                if not issubclass(v, type_check):
",1
"            self.optional = True

    def choices(self) -> Tuple[Optional[str], ...]:
",1
"        retval = tuple(self.classes)
        if self.optional:
            return retval + (None,)
        else:
",1
"            assert check_return_type(class_obj)
            retval = class_obj
        else:
            raise ValueError(
",1
"                f""--{self.name} must be one of {self.choices()}: ""
                f""--{self.name} {name.lower()}""
            )
",1
"            choices=self.choices(),
            help=f""The {self.name} type"",
        )
        parser.add_argument(
",1
"                        ""--dist_master_addr or MASTER_ADDR must be set ""
                        ""if --dist_init_method == 'env://'""
                    )
                if get_master_port(self.dist_master_port) is None:
",1
"            self.local_rank = get_local_rank(self.local_rank, self.dist_launcher)
",1
"                    if self.local_rank >= len(cvd.split("","")):
                        raise RuntimeError(
                            f""LOCAL_RANK={self.local_rank} is bigger ""
                            f""than the number of visible devices: {cvd}""
                        )
",1
"                    self.dist_init_method = (
                        f""tcp://{self.dist_master_addr}:{self.dist_master_port}""
                    )
",1
"
",1
"                rank=self.dist_rank,
            )

            # About distributed model:
",1
"

",1
"        #    e.g. torch.distributed.launch
        if get_world_size(args.dist_world_size, args.dist_launcher) > 1:
            args.distributed = True
        # e. single-process
",1
"

def _int_or_none(x: Optional[str]) -> Optional[int]:
    if x is None:
        return x
",1
"    return int(x)
",1
"
",1
"    if prior is not None:
",1
"        if launcher == ""slurm"":
            if not is_in_slurm_step():
                raise RuntimeError(""This process seems not to be launched by 'srun'"")

            prior = int(os.environ[""SLURM_LOCALID""])
",1
"            )
",1
"        # There are two possibility:
        # - ""CUDA_VISIBLE_DEVICES"" is set to multiple GPU ids. e.g. ""0.1,2""
        #   => This intends to specify multiple devices to to be used exactly
        #      and local_rank information is possibly insufficient.
",1
"        # - ""CUDA_VISIBLE_DEVICES"" is set to an id. e.g. ""1""
        #   => This could be used for LOCAL_RANK
        cvd = os.environ[""CUDA_VISIBLE_DEVICES""].split("","")
        if len(cvd) == 1 and ""LOCAL_RANK"" not in os.environ:
            # If CUDA_VISIBLE_DEVICES is set and LOCAL_RANK is not set,
",1
"            return int(os.environ.pop(""CUDA_VISIBLE_DEVICES""))
        else:
            return None
    else:
        return None
",1
"    """"""Get Node Rank.

",1
"
        # Assume ntasks_per_node == 1
",1
"        comm = MPI.COMM_WORLD
        # Assume ntasks_per_node == 1 (We can't check whether it is or not)
        return comm.Get_size()
    elif launcher is not None:
",1
"        raise RuntimeError(f""launcher='{launcher}' is not supported"")
    else:
",1
"        # prior is None -> NUM_NODES = 1
        return int(os.environ.get(""WORLD_SIZE"", 1))
from typing import Collection
from typing import Dict
",1
"from typing import Union

import numpy as np
import torch
",1
"

class CommonCollateFn:
",1
"        self, data: Collection[Tuple[str, Dict[str, np.ndarray]]]
    ) -> Tuple[List[str], Dict[str, torch.Tensor]]:
        return common_collate_fn(
",1
"    data = [d for _, d in data]

    assert all(set(data[0]) == set(d) for d in data), ""dict-keys mismatching""
    assert all(
",1
"        not k.endswith(""_lengths"") for k in data[0]
    ), f""*_lengths is reserved: {list(data[0])}""

    output = {}
    for key in data[0]:
",1
"        # Assume the first axis is length:
        # tensor_list: Batch x (Length, ...)
        tensor_list = [torch.from_numpy(a) for a in array_list]
        # tensor: (Batch, Length, ...)
        tensor = pad_list(tensor_list, pad_value)
",1
"        output[key] = tensor

        assert all(len(d[key]) != 0 for d in data), [len(d[key]) for d in data]

        # lens: (Batch,)
",1
"import torch.multiprocessing
",1
"from espnet2.train.distributed_utils import get_node_rank
from espnet2.train.distributed_utils import get_num_nodes
from espnet2.train.distributed_utils import resolve_distributed_mode
",1
"from espnet2.utils.yaml_no_alias_safe_dump import yaml_no_alias_safe_dump

if LooseVersion(torch.__version__) >= LooseVersion(""1.5.0""):
    from torch.multiprocessing.spawn import ProcessContext
",1
"    asgd=torch.optim.ASGD,
    lbfgs=torch.optim.LBFGS,
    rmsprop=torch.optim.RMSprop,
    rprop=torch.optim.Rprop,
",1
"    pass
try:
    import apex

    optim_classes.update(
",1
"        fusedlamb=apex.optimizers.FusedLAMB,
        fusednovograd=apex.optimizers.FusedNovoGrad,
",1
"    pass

scheduler_classes = dict(
    ReduceLROnPlateau=torch.optim.lr_scheduler.ReduceLROnPlateau,
",1
"    CosineAnnealingLR=torch.optim.lr_scheduler.CosineAnnealingLR,
)
if LooseVersion(torch.__version__) >= LooseVersion(""1.1.0""):
    scheduler_classes.update(
        noamlr=NoamLR, warmuplr=WarmupLR,
",1
"
    @classmethod
    @abstractmethod
    def build_preprocess_fn(
        cls, args: argparse.Namespace, train: bool
",1
"    @classmethod
",1
"
",1
"    def optional_data_names(cls, inference: bool = False) -> Tuple[str, ...]:
",1
"        class ArgumentDefaultsRawTextHelpFormatter(
            configargparse.RawTextHelpFormatter,
            configargparse.ArgumentDefaultsHelpFormatter,
",1
"            ""--log_level"",
            type=lambda x: x.upper(),
            default=""INFO"",
",1
"        )
        group.add_argument(
",1
"            help=""Specify iterator type"",
        )

        group.add_argument(""--output_dir"", type=str_or_none, default=None)
        group.add_argument(
",1
"            ""--ngpu"",
            type=int,
",1
"        group.add_argument(
",1
"            ""--dist_world_size"",
            default=None,
            type=int_or_none,
            help=""number of nodes for distributed training"",
",1
"            help=""node rank for distributed training"",
",1
"        group.add_argument(
            # Not starting with ""dist_"" for compatibility to launch.py
            ""--local_rank"",
",1
"        )
        group.add_argument(
            ""--dist_launcher"",
            default=None,
            type=str_or_none,
",1
"            ""--multiprocessing_distributed"",
            default=False,
            type=str2bool,
            help=""Use multi-processing distributed training to launch ""
            ""N processes per node, which has N GPUs. This is the ""
",1
"            ""fastest way to use PyTorch for either single node or ""
            ""multi node data parallel training"",
        )
",1
"        )

        group = parser.add_argument_group(""collect stats mode related"")
        group.add_argument(
            ""--collect_stats"",
",1
"            default=40,
",1
"            default=None,
            help=""Number of epochs to wait without improvement ""
            ""before stopping the training"",
        )
",1
"            nargs=""+"",
            default=[
",1
"            'Give a pair referring the phase, ""train"" or ""valid"",'
            'the criterion name, and the mode, ""min"" or ""max"", e.g. ""acc,max"".',
        )
        group.add_argument(
",1
"            ""--keep_nbest_models"",
",1
"        )
        group.add_argument(
",1
"            default=False,
            help=""The flag to switch to use noise injection to ""
            ""gradients during training"",
        )
        group.add_argument(
",1
"        )
        group.add_argument(
            ""--no_forward_run"",
            type=str2bool,
",1
"        group.add_argument(
            ""--resume"",
            type=str2bool,
            default=False,
            help=""Enable resuming if checkpoint is existing"",
",1
"            default=""float32"",
            choices=[""float16"", ""float32"", ""float64"", ""O0"", ""O1"", ""O2"", ""O3""],
            help=""Data type for training. O0,O1,.. flags require apex. ""
            ""See https://nvidia.github.io/apex/amp.html#opt-levels"",
        )
",1
"            default=None,
            help=""Show the logs every the number iterations in each epochs at the ""
            ""training phase. If None is given, it is decided according the number ""
            ""of training samples automatically ."",
",1
"        group.add_argument(
            ""--num_iters_per_epoch"",
            type=int_or_none,
            default=None,
            help=""Restrict the number of iterations for training per epoch"",
",1
"        )
        group.add_argument(
",1
"            type=int_or_none,
",1
"            ""--valid_batch_type"",
            type=str_or_none,
",1
"        group.add_argument(
            ""--sort_in_batch"",
            type=str,
            default=""descending"",
            choices=[""descending"", ""ascending""],
",1
"            ""the sample is discarded. "",
        )
        group.add_argument(
            ""--chunk_shift_ratio"",
",1
"            ""The first value, some/path/a.scp, indicates the file path, ""
            ""and the second, foo, is the key name used for the mini-batch data, ""
            ""and the last, sound, decides the file type. ""
            ""This option is repeatable, so you can input any number of features ""
",1
"            help=""Allow the arbitrary keys for mini-batch with ignoring ""
            ""the task requirements"",
",1
"        )
        group.add_argument(
",1
"                help=""The optimizer type"",
            )
            group.add_argument(
                f""--optim{suf}_conf"",
",1
"        return parser

    @classmethod
",1
"        if cls.num_optimizers != 1:
            raise RuntimeError(
                ""build_optimizers() must be overridden if num_optimizers != 1""
            )
",1
"
        optim_class = optim_classes.get(args.optim)
        if optim_class is None:
            raise ValueError(f""must be one of {list(optim_classes)}: {args.optim}"")
",1
"        optim = optim_class(model.parameters(), **args.optim_conf)
        optimizers = [optim]
",1
"        return optimizers

    @classmethod
    def exclude_opts(cls) -> Tuple[str, ...]:
        """"""The options not to be shown by --print_config""""""
",1
"        args, _ = parser.parse_known_args()
        config = vars(args)
        # Excludes the options not to be shown
",1
"                # and set it again
                config[f""scheduler{suf}_conf""] = conf
",1
"
        for class_choices in cls.class_choices_list:
            if getattr(args, class_choices.name) is not None:
",1
"    @classmethod
    def check_required_command_args(cls, args: argparse.Namespace):
        assert check_argument_types()
        for k in vars(args):
            if ""-"" in k:
",1
"            )
            sys.exit(2)

",1
"
        for k in cls.required_data_names(inference):
",1
"            )
",1
"            for k in dataset.names():
                if k not in task_keys:
",1
"                    raise RuntimeError(
                        f""The data-name must be one of {task_keys} ""
                        f'for {cls.__name__}: ""{k}"" is not allowed.\n{mes}'
                    )
",1
"            # https://github.com/pytorch/examples/blob/master/imagenet/main.py
            num_nodes = get_num_nodes(args.dist_world_size, args.dist_launcher)
            if num_nodes == 1:
",1
"                    args.dist_init_method == ""env://""
                    and get_master_port(args.dist_master_port) is None
                ):
                    # Get the unused port
",1
"            # The following block is copied from:
            # https://github.com/pytorch/pytorch/blob/master/torch/multiprocessing/spawn.py
            error_queues = []
            processes = []
",1
"                    f""{distributed_option.dist_world_size}""
                )

            # NOTE(kamo):
",1
"            # logging.basicConfig() is invoked in main_worker() instead of main()
            # because it can be invoked only once in a process.
            # FIXME(kamo): Should we use logging.getLogger()?
            logging.basicConfig(
                level=args.log_level,
",1
"            num_workers=args.num_workers,
            seed=args.seed,
            allow_variable_data_keys=args.allow_variable_data_keys,
            ngpu=args.ngpu,
",1
"            fold_length=args.fold_length,
            sort_in_batch=args.sort_in_batch,
            sort_batch=args.sort_batch,
",1
"            args.valid_batch_type = args.batch_type
        if args.valid_batch_size is None:
            args.valid_batch_size = args.batch_size
        if args.valid_batch_bins is None:
",1
"            distributed=distributed_option.distributed,
",1
"                train=False,
                preprocess_fn=cls.build_preprocess_fn(args, train=False),
                collate_fn=cls.build_collate_fn(args),
",1
"        model = cls.build_model(args=args)
        if not isinstance(model, AbsESPnetModel):
",1
"                raise
            model, optimizers = amp.initialize(
",1
"
",1
"            logging.info(f'Saving the configuration in {output_dir / ""config.yaml""}')
            yaml_no_alias_safe_dump(vars(args), f, indent=4, sort_keys=False)
",1
"                # NOTE(kamo): ""cuda"" for torch.load always indicates cuda:0
                #   in PyTorch<=1.4
",1
"            reporter.load_state_dict(states[""reporter""])
",1
"                    logging.error(
                        ""You need to install apex. ""
                        ""See https://github.com/NVIDIA/apex#linux""
                    )
",1
"                amp.load_state_dict(states[""amp""])
",1
"        # 9. Run
        if args.dry_run:
            pass
        elif args.collect_stats:
",1
"                valid_iter=valid_iter_factory.build_iter(1),
                output_dir=output_dir,
                ngpu=args.ngpu,
                log_interval=args.log_interval,
",1
"            # Don't give args to run() directly!!!
",1
"            cls.trainer.run(
                model=model,
                optimizers=optimizers,
",1
"                distributed_option=distributed_option,
            )

            if not distributed_option.distributed or distributed_option.dist_rank == 0:
                # Generated n-best averaged model
",1
"                average_nbest_models(
                    reporter=reporter,
                    output_dir=output_dir,
                    best_model_criterion=args.best_model_criterion,
                    nbest=args.keep_nbest_models,
",1
"        cls,
        iterator_type: str,
",1
"        batch_size: int,
        batch_bins: int,
        preprocess_fn,
        collate_fn,
",1
"        chunk_shift_ratio: float,
        num_cache_chunks: int,
        num_batches: int = None,
    ) -> Union[
        Tuple[AbsIterFactory, ESPnetDataset, List[Tuple[str, ...]]],
",1
"            seed=seed,
            allow_variable_data_keys=allow_variable_data_keys,
            ngpu=ngpu,
        )
",1
"                num_cache_chunks=num_cache_chunks,
            )
        elif iterator_type == ""none"":
            # This branch is used for --dry_run mode
",1
"        preprocess_fn,
        batch_size: int,
        batch_bins: int,
        collate_fn,
        train_dtype: str,
",1
"        seed: int,
        allow_variable_data_keys: bool,
",1
"            fold_lengths=fold_length,
            batch_size=batch_size,
            batch_bins=batch_bins,
            sort_in_batch=sort_in_batch,
            sort_batch=sort_batch,
",1
"            SequenceIterFactory(
                dataset=dataset,
                batches=batches,
                seed=seed,
",1
"        num_iters_per_epoch: Optional[int],
        max_cache_size: float,
",1
"            if batch_size < world_size:
                raise RuntimeError(""batch_size must be equal or more than world_size"")

            if rank < batch_size % world_size:
                batch_size = batch_size // world_size + 1
",1
"        )

    # ~~~~~~~~~ The methods below are mainly used for inference ~~~~~~~~~
    @classmethod
    def build_model_from_file(
",1
"        cls,
        config_file: Union[Path, str],
        model_file: Union[Path, str] = None,
",1
"            config_file: The yaml file saved when training.
            model_file: The model file saved when training.
",1
"        if not isinstance(model, AbsESPnetModel):
            raise RuntimeError(
                f""model must inherit {AbsESPnetModel.__name__}, but got {type(model)}""
            )
",1
"        cls,
        data_path_and_name_and_type,
",1
"        pin_memory: bool = False,
        preprocess_fn=None,
        collate_fn=None,
",1
"            data_path_and_name_and_type, float_dtype=dtype, preprocess=preprocess_fn,
",1
"from typing import Callable
from typing import Collection
from typing import Dict
",1
"from espnet2.train.class_choices import ClassChoices
from espnet2.train.collate_fn import CommonCollateFn
from espnet2.train.preprocessor import CommonPreprocessor
from espnet2.train.trainer import Trainer
",1
"
",1
"                ""kaiming_normal"",
",1
"        assert check_argument_types()
",1
"        assert check_return_type(retval)
        return retval

    @classmethod
    def required_data_names(cls, inference: bool = False) -> Tuple[str, ...]:
",1
"            token_list = args.token_list.copy()
",1
"
        # 2. Build ESPnetModel
        # Assume the last-id is sos_and_eos
        model = ESPnetLanguageModel(lm=lm, vocab_size=vocab_size, **args.model_conf)

",1
"import argparse
import logging
from typing import Callable
",1
"    ""normalize"",
    classes=dict(global_mvn=GlobalMVN, utterance_mvn=UtteranceMVN,),
    type_check=AbsNormalize,
    default=""utterance_mvn"",
    optional=True,
",1
"    ""encoder"",
    classes=dict(
",1
"    default=""rnn"",
)
decoder_choices = ClassChoices(
    ""decoder"",
",1
"class ASRTask(AbsTask):
    # If you need more than one optimizers, change this value
",1
"    num_optimizers: int = 1

    # Add variable objects configurations
    class_choices_list = [
        # --frontend and --frontend_conf
",1
"        normalize_choices,
        # --encoder and --encoder_conf
        encoder_choices,
        # --decoder and --decoder_conf
",1
"            type=int_or_none,
",1
"            default=False,
            help=""Apply preprocessing to data or not"",
        )
        group.add_argument(
            ""--token_type"",
",1
"        )

        for class_choices in cls.class_choices_list:
            # Append --<name> and --<name>_conf.
            # e.g. --encoder and --encoder_conf
",1
"        # NOTE(kamo): int value = 0 is reserved by CTC-blank symbol
",1
"            )
",1
"        else:
            retval = None
        assert check_return_type(retval)
",1
"        if isinstance(args.token_list, str):
            with open(args.token_list, encoding=""utf-8"") as f:
                token_list = [line.rstrip() for line in f]
",1
"        elif isinstance(args.token_list, (tuple, list)):
            token_list = list(args.token_list)
",1
"        else:
            raise RuntimeError(""token_list must be str or list"")
        vocab_size = len(token_list)
        logging.info(f""Vocabulary size: {vocab_size }"")

",1
"            specaug = None

        # 3. Normalization layer
        if args.normalize is not None:
            normalize_class = normalize_choices.get_class(args.normalize)
",1
"            encoder=encoder,
",1
"from typing import Callable
",1
"
",1
"from espnet2.layers.abs_normalize import AbsNormalize
from espnet2.layers.global_mvn import GlobalMVN
",1
"from espnet2.train.trainer import Trainer
",1
"    type_check=AbsNormalize,
    default=""global_mvn"",
    optional=True,
)
tts_choices = ClassChoices(
",1
"    # If you need more than one optimizers, change this value
    num_optimizers: int = 1

",1
"        # --tts and --tts_conf
        tts_choices,
    ]

    # If you need to modify train() or eval() procedures, change Trainer class here
",1
"            type=str_or_none,
            default=None,
            help=""A text mapping int-id to token"",
        )
        group.add_argument(
",1
"            help=""The keyword arguments for model class."",
        )

        group = parser.add_argument_group(description=""Preprocess related"")
        group.add_argument(
",1
"            ""--token_type"",
            type=str,
",1
"        group.add_argument(
            ""--bpemodel"",
            type=str_or_none,
            default=None,
",1
"            class_choices.add_arguments(group)
",1
"        assert check_argument_types()
        return CommonCollateFn(
            float_pad_value=0.0, int_pad_value=0, not_sequence=[""spembs""]
",1
"                non_linguistic_symbols=args.non_linguistic_symbols,
            )
        else:
            retval = None
",1
"    def required_data_names(cls, inference: bool = False) -> Tuple[str, ...]:
        if not inference:
            retval = (""text"", ""speech"")
",1
"        else:
            # Inference mode
",1
"            # Give features from data-loader
            args.feats_extract = None
            args.feats_extract_conf = None
",1
"        else:
            normalize = None

",1
"            **args.model_conf,
        )
        assert check_return_type(model)
        return model
",1
"
from espnet.utils.cli_utils import get_commandline_args
from espnet2.utils.types import str2bool
",1
"    parser.add_argument(
        ""--ngpu"", type=int, default=1, help=""The number of GPUs per node""
",1
"        ""Master is a host machine has RANK0 process."",
    )
    parser.add_argument(
        ""--master_addr"",
        type=str,
",1
"                init_method += [
                    ""--dist_master_addr"",
",1
"        hosts = []
        ids_list = []
",1
"            # e.g host = ""host1:0:2""
            sps = host.split("":"")
            host = sps[0]
",1
"        else:
            # Output to stdout/stderr
            f = None

        rank = 0
",1
"        for host, ids in zip(hosts, ids_list):
            ngpu = 1 if len(ids) > 0 else 0
            ids = ids if len(ids) > 0 else [""none""]
",1
"                        ""--dist_world_size"",
",1
"            else:
                # NOTE:
                #   If multiprocessing_distributed=false
                # -> ""DataParallel"" mode, which is single-process
                #    and Multi-GPUs with threading.
",1
"                # https://discuss.pytorch.org/t/why-torch-nn-parallel-distributeddataparallel-runs-faster-than-torch-nn-dataparallel-on-single-machine-with-multi-gpu/32977/2
                logging.info(f""single-node with {args.ngpu}gpu using DataParallel"")

        # Using cmd as it is simply
",1
"            + args.args
            + [
",1
"                ""--ngpu"",
                str(args.ngpu),
                ""--multiprocessing_distributed"",
                str(args.multiprocessing_distributed),
",1
"        raise RuntimeError(""run.pl doesn't support submitting to the other nodes."")

    elif Path(args.cmd[0]).name == ""ssh.pl"":
        raise RuntimeError(""Use --host option instead of ssh.pl"")

",1
"        logging.info(f""{args.num_nodes}nodes and {args.ngpu}gpu-per-node using srun"")
",1
"    else:
        # This pattern can also works with Slurm.

        logging.info(f""{args.num_nodes}nodes and {args.ngpu}gpu-per-node using mpirun"")
        cmd = (
",1
"                ""--num_threads"",
                str(max(args.ngpu, 1)),
                # Make sure scheduler setting, i.e. conf/queue.conf
",1
"                str(args.num_nodes),
                args.log,
                ""mpirun"",
                # -np option can be omitted with Torque/PBS
",1
"            + [
",1
"            cmd += [""--dist_backend"", ""gloo""]
        process = subprocess.Popen(cmd)
",1
"    for process in processes:
",1
"                    lines = list(f)
                raise RuntimeError(
                    f""\n################### The last 1000 lines of {args.log} ""
                    f""###################\n"" + """".join(lines[-1000:])
                )
",1
"from espnet.nets.scorers.ctc import CTCPrefixScorer
from espnet.nets.scorers.length_bonus import LengthBonus
from espnet.utils.cli_utils import get_commandline_args
from espnet2.tasks.asr import ASRTask
",1
"from espnet2.text.build_tokenizer import build_tokenizer
",1
"    output_dir: str,
    maxlenratio: float,
    minlenratio: float,
    batch_size: int,
",1
"    key_file: Optional[str],
    asr_train_config: str,
    asr_model_file: str,
",1
"    bpemodel: Optional[str],
    allow_variable_data_keys: bool,
",1
"        format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
    )

    if ngpu >= 1:
        device = ""cuda""
",1
"    else:
        device = ""cpu""
",1
"    scorers.update(
        decoder=decoder, ctc=ctc, length_bonus=LengthBonus(len(token_list)),
    )
",1
"    if lm_train_config is not None:
",1
"        scorers=scorers,
",1
"        sos=asr_model.sos,
        eos=asr_model.eos,
        vocab_size=len(token_list),
        token_list=token_list,
",1
"    for scorer in scorers.values():
        if isinstance(scorer, torch.nn.Module):
            scorer.to(device=device, dtype=getattr(torch, dtype)).eval()
    logging.info(f""Beam_search: {beam_search}"")
",1
"    logging.info(f""Decoding device={device}, dtype={dtype}"")

    # 5. Build data-iterator
    loader, _, _ = ASRTask.build_non_sorted_iterator(
",1
"        batch_size=batch_size,
        key_file=key_file,
        num_workers=num_workers,
",1
"    # 6. [Optional] Build Text converter: e.g. bpe-sym -> Text
    if token_type is None:
        token_type = asr_train_args.token_type
    if bpemodel is None:
",1
"        else:
            tokenizer = None
",1
"    with DatadirWriter(output_dir) as writer:
        for keys, batch in loader:
            assert isinstance(batch, dict), type(batch)
",1
"
            with torch.no_grad():
",1
"                    text = tokenizer.tokens2text(token)
",1
"    )

    # Note(kamo): Use '_' instead of '-' as separator.
    # '-' is confusing if written in yaml.
",1
"    parser.add_argument(""--config"", is_config_file=True, help=""config file path"")

    parser.add_argument(
        ""--log_level"",
        type=lambda x: x.upper(),
",1
"        ""--ngpu"", type=int, default=0, help=""The number of gpus. 0 indicates CPU mode"",
    )
",1
"        required=True,
        action=""append"",
    )
    group.add_argument(""--key_file"", type=str_or_none)
    group.add_argument(""--allow_variable_data_keys"", type=str2bool, default=False)
",1
"
",1
"        ""function ""
",1
"        help=""The token symbol represents CTC-blank"",
    )
",1
"
def main(cmd=None):
    print(get_commandline_args(), file=sys.stderr)
    parser = get_parser()
",1
"from espnet2.tasks.asr import ASRTask


",1
"    Example:

        % python asr_train.py asr --print_config --optim adadelta \
                > conf/train_asr.yaml
        % python asr_train.py --config conf/train_asr.yaml
",1
"    """"""
    ASRTask.main(cmd=cmd)

",1
"from pathlib import Path
import sys
from typing import List
from typing import Optional

",1
"    Examples:
        >>> field2slice(""1-"")
        slice(0, None, None)
        >>> field2slice(""1-3"")
",1
"        slice(0, 3, None)
        >>> field2slice(""-3"")
        slice(None, 3, None)

",1
"            if s2.strip() == """":
                s2 = None
            else:
                s2 = int(s2)
",1
"    except ValueError:
",1
"    non_linguistic_symbols: Optional[str],
",1
"    bpemodel: Optional[str],
    log_level: str,
",1
"    )

    counter = Counter()
    if field is not None:
        field = field2slice(field)
",1
"        if not write_vocabulary:
            fout.write("" "".join(tokens) + ""\n"")
        else:
",1
"    words_and_counts = list(sorted(counter.items(), key=lambda x: x[1]))

    for symbol_and_id in add_symbol:
",1
"        except ValueError:
            raise RuntimeError(f""Format error: e.g. '<blank>:0': {symbol_and_id}"")
        symbol = symbol.strip()

        # e.g. idx=0  -> append as the first symbol
",1
"    )
    parser.add_argument(
        ""--token_type"",
",1
"        help=""Token type"",
",1
"    group.add_argument(
        ""--cutoff"",
",1
"import logging
from pathlib import Path
",1
"from espnet2.torch_utils.set_all_random_seed import set_all_random_seed
from espnet2.utils.fileio import DatadirWriter
",1
"def calc_perplexity(
",1
"    seed: int,
    num_workers: int,
    log_level: Union[int, str],
",1
"        data_path_and_name_and_type,
        dtype=dtype,
        batch_size=batch_size,
",1
"        key_file=key_file,
        num_workers=num_workers,
        preprocess_fn=LMTask.build_preprocess_fn(train_args, False),
        collate_fn=LMTask.build_collate_fn(train_args),
        allow_variable_data_keys=allow_variable_data_keys,
",1
"                    # but for debuggability it's better to keep this block.
                    nll, lengths = wrapped_model(**batch)
",1
"            f.write(f""{ppl}\n"")
        with (Path(output_dir) / ""base"").open(""w"", encoding=""utf-8"") as f:
            if log_base is None:
",1
"            f.write(f""{_log_base}\n"")
        logging.info(f""PPL={ppl}"")

",1
"        formatter_class=configargparse.ArgumentDefaultsHelpFormatter,
    )

    # Note(kamo): Use '_' instead of '-' as separator.
",1
"    parser.add_argument(
",1
"    parser.add_argument(
        ""--batch_size"", type=int, default=1, help=""The batch size for inference"",
    )
",1
"        action=""append"",
    )
    group.add_argument(""--key_file"", type=str_or_none)
",1
"
",1
"    output_dir: str,
    batch_size: int,
    dtype: str,
",1
"    maxlenratio: float,
    use_att_constraint: bool,
    backward_window: int,
    forward_window: int,
",1
"):
",1
"    if ngpu > 1:
        raise NotImplementedError(""only single GPU decoding is supported"")
",1
"    logging.basicConfig(
        level=log_level,
        format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
    )
",1
"
",1
"    if ngpu >= 1:
        device = ""cuda""
",1
"    else:
        device = ""cpu""

    # 1. Set random-seed
    set_all_random_seed(seed)
",1
"    loader, _, batch_sampler = TTSTask.build_non_sorted_iterator(
",1
"        collate_fn=TTSTask.build_collate_fn(train_args),
        allow_variable_data_keys=allow_variable_data_keys,
    )

",1
"            )
            f[key] = outs.cpu().numpy()
            g[key] = outs_denorm.cpu().numpy()
",1
"
",1
"            # TODO(kamo): Write scp
            if spc2wav is not None:
",1
"def get_parser():
    """"""Get argument parser.""""""
    parser = configargparse.ArgumentParser(
",1
"
    # Note(kamo): Use ""_"" instead of ""-"" as separator.
    # ""-"" is confusing if written in yaml.
    parser.add_argument(""--config"", is_config_file=True, help=""config file path"")

",1
"        help=""The verbose level of logging"",
    )

    parser.add_argument(
",1
"        ""--dtype"",
        default=""float32"",
        choices=[""float16"", ""float32"", ""float64""],
",1
"        type=float,
        default=10.0,
        help=""Maximum length ratio in decoding"",
",1
"        ""--minlenratio"",
        type=float,
        default=0.0,
",1
"        ""--use_att_constraint"",
        type=str2bool,
",1
"    )

",1
"from espnet.utils.cli_utils import get_commandline_args
",1
"            stats_keys = [line.strip() for line in f if line.strip() != """"]
",1
"            if scp.exists():
                (output_dir / p).parent.mkdir(parents=True, exist_ok=True)
                with (output_dir / p).open(""w"", encoding=""utf-8"") as fout:
                    for idir in input_dirs:
",1
"
",1
"        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        ""--log_level"",
        type=lambda x: x.upper(),
",1
"    return parser
",1
"

",1
"    files = [""asr_model_file.pth"", ""lm_file.pth""]
    yaml_files = [""asr_train_config.yaml"", ""lm_train_config.yaml""]


class TTSPackedContents(PackedContents):
",1
"
    # Create subparser for ASR
    for name, contents in [(""asr"", ASRPackedContents), (""tts"", TTSPackedContents)]:
        parser_asr = subparsers.add_parser(
            name, formatter_class=argparse.ArgumentDefaultsHelpFormatter,
",1
"def main(cmd=None):
",1
"    if not hasattr(args, ""contents""):
",1
"    """"""LM training.

    Example:

",1
"        % python lm_train.py --config conf/train_asr.yaml
    """"""
    LMTask.main(cmd=cmd)


",1
"

class TokenIDConverter:
    def __init__(
        self, token_list: Union[Path, str, Iterable[str]], unk_symbol: str = ""<unk>"",
",1
"                    break
                self.token_list_repr += f""{t}, ""
            self.token_list_repr += f""... (NVocab={(len(self.token_list))})""

",1
"
    def get_num_vocabulary_size(self) -> int:
",1
"
    def tokens2ids(self, tokens: Iterable[str]) -> List[int]:
        return [self.token2id.get(i, self.unk_id) for i in tokens]
from pathlib import Path
from typing import Iterable
",1
"        else:
            self.non_linguistic_symbols = set(non_linguistic_symbols)
        self.remove_non_linguistic_symbols = remove_non_linguistic_symbols

",1
"            else:
                t = line[0]
                if t == "" "":
",1
"
import sentencepiece as spm
from typeguard import check_argument_types

",1
"class SentencepiecesTokenizer(AbsTokenizer):
    def __init__(self, model: Union[Path, str]):
",1
"
from espnet2.text.abs_tokenizer import AbsTokenizer
from espnet2.text.char_tokenizer import CharTokenizer
",1
"from espnet2.text.sentencepiece_tokenizer import SentencepiecesTokenizer
from espnet2.text.word_tokenizer import WordTokenizer


",1
"    elif token_type == ""word"":
        if remove_non_linguistic_symbols and non_linguistic_symbols is not None:
            return WordTokenizer(
",1
"                delimiter=delimiter,
                non_linguistic_symbols=non_linguistic_symbols,
                remove_non_linguistic_symbols=True,
",1
"        return CharTokenizer(
            non_linguistic_symbols=non_linguistic_symbols,
            space_symbol=space_symbol,
            remove_non_linguistic_symbols=remove_non_linguistic_symbols,
        )
",1
"        )
from pathlib import Path
from typing import Iterable
from typing import List
",1
"        return tokens

    def tokens2text(self, tokens: Iterable[str]) -> str:
",1
"
import torch
from typeguard import check_argument_types

from espnet2.layers.abs_normalize import AbsNormalize
",1
"        self,
        feats_extract: Optional[AbsFeatsExtract],
        normalize: Optional[AbsNormalize and InversibleInterface],
        tts: AbsTTS,
    ):
",1
"        feats, feats_lengths = self._extract_feats(speech, speech_lengths)

        if self.normalize is not None:
            feats, feats_lengths = self.normalize(feats, feats_lengths)
",1
"
",1
"            speech=feats,
            speech_lengths=feats_lengths,
",1
"        self,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
        speech: torch.Tensor,
",1
"    ) -> Tuple[torch.Tensor, torch.Tensor]:
",1
"from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import GuidedAttentionLoss
from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import Tacotron2Loss
from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
from espnet.nets.pytorch_backend.rnn.attentions import AttForward
from espnet.nets.pytorch_backend.rnn.attentions import AttForwardTA
",1
"from espnet.nets.pytorch_backend.tacotron2.cbhg import CBHGLoss
",1
"        embed_dim: int = 512,
        elayers: int = 1,
",1
"        dunits: int = 1024,
",1
"                f""there is no such an activation function. "" f""({output_activation})""
",1
"        )

        dec_idim = eunits if spk_embed_dim is None else eunits + spk_embed_dim
",1
"        if atype == ""location"":
",1
"            if self.cumulate_att_w:
",1
"                    ""in forward attention.""
                )
",1
"                logging.warning(
                    ""cumulation of attention weights is disabled ""
                    ""in forward attention.""
                )
                self.cumulate_att_w = False
",1
"            postnet_layers=postnet_layers,
            postnet_chans=postnet_chans,
            postnet_filts=postnet_filts,
            output_activation_fn=self.output_activation_fn,
",1
"            zoneout_rate=zoneout_rate,
",1
"                conv_proj_chans=cbhg_conv_proj_chans,
                highway_layers=cbhg_highway_layers,
                highway_units=cbhg_highway_units,
                gru_units=cbhg_gru_units,
",1
"            spcs: Batch of ground-truth spectrogram (B, Lmax, spc_dim).
            spcs_lengths:
        """"""
        text = text[:, : text_lengths.max()]  # for data-parallel
",1
"
        batch_size = text.size(0)
        # Add eos at the last of sequence
",1
"            xs[i, l] = self.eos
",1
"        if self.reduction_factor > 1:
            olens = olens.new([olen - olen % self.reduction_factor for olen in olens])
",1
"            max_out = max(olens)
            ys = ys[:, :max_out]
            labels = labels[:, :max_out]
            labels[:, -1] = 1.0  # make sure at least one frame has 1

",1
"                olens_in = olens.new([olen // self.reduction_factor for olen in olens])
            else:
                olens_in = olens
            attn_loss = self.attn_loss(att_ws, ilens, olens_in)
",1
"            # remove unnecessary padded part (for multi-gpus)
            if max_out != spcs.shape[1]:
                spcs = spcs[:, :max_out]

            # caluculate cbhg outputs & loss and report them
",1
"            cbhg_outs, _ = self.cbhg(after_outs, olens)
            cbhg_l1_loss, cbhg_mse_loss = self.cbhg_loss(cbhg_outs, spcs, olens)
            loss = loss + cbhg_l1_loss + cbhg_mse_loss
",1
"            Tensor: Attention weights (L, T).

        """"""
",1
"        x = text
        spemb = spembs
",1
"            cbhg_outs = self.cbhg.inference(outs)
            return cbhg_outs, probs, att_ws
        else:
            return outs, probs, att_ws
from abc import ABC
",1
"        raise NotImplementedError

    @abstractmethod
    def inference(
        self,
",1
"from espnet2.layers.log_mel import LogMel
",1
"        n_fft: int = 1024,
",1
"        self.hop_length = hop_length
        self.win_length = win_length
        self.fmin = fmin
",1
"            center=center,
            pad_mode=pad_mode,
            normalized=normalized,
",1
"            n_mels=self.n_mels,
",1
"            win_length=self.win_length,
            fmin=self.fmin,
            fmax=self.fmax,
        )
",1
"        input_stft, feats_lens = self.stft(input, input_lengths)

        assert input_stft.dim() >= 4, input_stft.shape
",1
"        # ""2"" refers to the real/imag parts of Complex
        assert input_stft.shape[-1] == 2, input_stft.shape

        # input_stft: (..., F, 2) -> (..., F)
        input_power = input_stft[..., 0] ** 2 + input_stft[..., 1] ** 2
",1
"            normalized=normalized,
            onesided=onesided,
",1
"        )
        self.n_fft = n_fft

    def output_size(self) -> int:
",1
"            n_fft=self.n_fft, n_shift=self.hop_length, win_length=self.win_length,
        )
",1
"    ) -> Tuple[torch.Tensor, torch.Tensor]:
        # 1. Stft: time -> time-freq
        input_stft, feats_lens = self.stft(input, input_lengths)
",1
"        # input_stft: (..., F, 2) -> (..., F)
        input_power = input_stft[..., 0] ** 2 + input_stft[..., 1] ** 2
        log_amp = 0.5 * torch.log(input_power + 1.0e-20)
        return log_amp, feats_lens
from abc import ABC
",1
"    def get_parameters(self) -> Dict[str, Any]:
        raise NotImplementedError
",1
"from typeguard import check_argument_types

from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
from espnet2.lm.abs_model import AbsLM
from espnet2.torch_utils.device_funcs import force_gatherable
",1
"    ) -> Tuple[torch.Tensor, torch.Tensor]:
        batch_size = text.size(0)
",1
"
        # 3. Calc negative log likelihood
        # nll: (BxL,)
        nll = F.cross_entropy(y.view(-1, y.shape[-1]), t.view(-1), reduction=""none"")
",1
"        ntokens = y_lengths.sum()
        loss = nll.sum() / ntokens
        stats = dict(loss=loss.detach())

        # force_gatherable: to-device and to-tensor if scalar for DataParallel
",1
"    >>> model = LanguageESPnetModel(lm=lm)
",1
"    def forward(
        self, input: torch.Tensor, hidden: torch.Tensor
",1
"from espnet2.lm.abs_model import AbsLM


class SequentialRNNLM(AbsLM):
",1
"            except KeyError:
",1
"        self.rnn_type = rnn_type
",1
"        """"""Score new token.

        Args:
",1
"    must have default value except for 'param'.

    I can't understand why only SGD.lr doesn't have the default value.
    """"""

",1
"            params,
            lr=lr,
            momentum=momentum,
            dampening=dampening,
            weight_decay=weight_decay,
",1
"    ignore_not_existing_keys: bool = True,
):
    """"""Load a model state and set it to the model.

    Examples:
",1
"        >>> load_pretrained_model(""somewhere/model.pth"", model)
        >>> load_pretrained_model(""somewhere/encoder.pth"", model, ""encoder"")
",1
"    """"""
    if pretrain_key is None:
        obj = model
",1
"import torch
",1
"    torch.nn.DataParallel parallelizes only ""forward()""
    and, maybe, the method having the other name can't be applied
    except for wrapping the module just like this class.

    Examples:
",1
"        >>> x = torch.randn(2, 10)
        >>> model(x)
",1
"    """"""

    def __init__(self, module: torch.nn.Module, name: str):
        assert check_argument_types()
        super().__init__()
",1
"
",1
"
        for mod in model.modules():
",1
"                        n = param.size(0)
                        param.data[n // 4 : n // 2].fill_(1.0)

",1
"                    torch.nn.init.kaiming_normal_(p.data, nonlinearity=""relu"")
                else:
",1
"
",1
"    else:
        from torch.distributed import reduce_op as ReduceOp
else:
    ReduceOp = None
",1
"        return type(obj)(recursive_sum(v, weight, distributed) for v in obj)
",1
"    elif obj is None:
",1
"        return None
    else:
        raise ValueError(type(obj))

",1
"        return None
    else:
        raise ValueError(type(a))
",1
"

",1
"    obj = recursive_divide(obj, weight)
    return obj, weight
",1
"import dataclasses
import warnings

import numpy as np
import torch
",1
"        return {
            k: to_device(v, device, dtype, non_blocking, copy) for k, v in data.items()
        }
    elif dataclasses.is_dataclass(data) and not isinstance(data, type):
",1
"    """"""
    if isinstance(data, dict):
        return {k: force_gatherable(v, device) for k, v in data.items()}
",1
"        return data.to(device)
    elif isinstance(data, float):
",1
"    Args:
        model: Model.
        iteration: Number of iterations.
",1
"            param.grad += noise
import random
",1
"import logging
from typing import Iterator
from typing import Tuple

",1
"    """"""BatchSampler with constant batch-size.

    Any sorting is not done in this class,
    so no length information is required,
    This class is convenient for decoding mode,
",1
"                keys[i * len(keys) // N : (i + 1) * len(keys) // N] for i in range(N)
            ]
        else:
",1
"            self.batch_list = [
                tuple(keys[i * batch_size : (i + 1) * batch_size]) for i in range(N)
            ]
",1
"            f""batch_size={self.batch_size}, ""
            f""key_file={self.key_file}, ""
        )

    def __len__(self):
",1
"
",1
"    def __iter__(self) -> Iterator[Tuple[str, ...]]:
        return iter(self.batch_list)
",1
"from typeguard import check_argument_types
",1
"            )
",1
"            raise RuntimeError(f""0 lines found: {shape_files[0]}"")

        # Decide batch-sizes
        start = 0
",1
"        while True:
            # shape: (Length, dim1, dim2, ...)
            if padding:
                max_lengths = [
",1
"                ]
",1
"            if bins > batch_bins and bs >= min_batch_size:
                batch_sizes.append(bs)
                start += bs
                bs = 1
",1
"            # Bug check
",1
"            minibatch_keys = keys[start : start + bs]
            start += bs
",1
"        elif sort_batch == ""descending"":
",1
"            self.batch_list.reverse()
",1
"        else:
            raise ValueError(
                f""sort_batch must be ascending or descending: {sort_batch}""
            )

",1
"    def __len__(self):
        return len(self.batch_list)

",1
"        if sort_batch != ""ascending"" and sort_batch != ""descending"":
",1
"                f""sort_in_batch must be ascending or descending: {sort_in_batch}""
            )

        self.batch_size = batch_size
",1
"            load_num_sequence_text(s, loader_type=""csv_int"") for s in shape_files
        ]
",1
"        # Decide batch-sizes
",1
"        if len(batch_sizes) > 1 and batch_sizes[-1] < min_batch_size:
            for i in range(batch_sizes.pop(-1)):
                batch_sizes[-(i % len(batch_sizes)) - 2] += 1

",1
"        # Set mini-batch
        self.batch_list = []
        start = 0
        for bs in batch_sizes:
",1
"            assert len(keys) >= start + bs, ""Bug""
",1
"            raise ValueError(
                f""sort_batch must be ascending or descending: {sort_batch}""
            )

    def __repr__(self):
",1
"    def __len__(self):
        return len(self.batch_list)

",1
"    ""    utterance_id_b\n""
    ""    utterance_id_c\n""
",1
"    ""The batch_size is decided by\n""
    ""    batch_size = base_batch_size // (L // fold_length)\n""
    ""L is referred to the largest length of samples in the mini-batch. ""
",1
"    ""\n\n""
    ""    utterance_id_a 1000\n""
    ""    utterance_id_b 1453\n""
",1
"
def build_batch_sampler(
    type: str,
    batch_size: int,
    batch_bins: int,
",1
"        drop_last:
        min_batch_size:  Used for ""numel"" or ""folded"" mode
        fold_lengths: Used for ""folded"" mode
        padding: Whether sequences are input as a padded tensor or not.
            used for ""numel"" mode
",1
"    elif type == ""numel"":
",1
"            padding=padding,
",1
"

class SortedBatchSampler(AbsSampler):
    """"""BatchSampler with sorted samples by length.
",1
"
    def __init__(
",1
"                f""sort_in_batch must be either one of ""
                f""ascending, descending, or None: {sort_in_batch}""
            )
        if len(keys) == 0:
            raise RuntimeError(f""0 lines found: {shape_file}"")
",1
"
        if sort_in_batch != sort_batch:
            if sort_batch not in (""ascending"", ""descending""):
                raise ValueError(
                    f""sort_batch must be ascending or descending: {sort_batch}""
",1
"    def __iter__(self) -> Iterator[Tuple[str, ...]]:
        return iter(self.batch_list)
from typing import Iterator
from typing import List
from typing import Tuple
",1
"class NumElementsBatchSampler(AbsSampler):
    def __init__(
        self,
",1
"        #    uttB 201,...
        utt2shapes = [
",1
"            load_num_sequence_text(s, loader_type=""csv_int"") for s in shape_files
        ]

",1
"        if len(keys) == 0:
            raise RuntimeError(f""0 lines found: {shape_files[0]}"")

        if padding:
            for d, s in zip(utt2shapes, shape_files):
",1
"                    )
",1
"
        # Decide batch-sizes
        start = 0
        batch_sizes = []
        bs = 1
",1
"                ]
                bins = sum(bs * lg * d for lg, d in zip(max_lengths, feat_dims))
            else:
                bins = sum(
                    np.prod(d[keys[i]])
",1
"        for bs in batch_sizes:
            assert len(keys) >= start + bs, ""Bug""
            minibatch_keys = keys[start : start + bs]
            start += bs
            if sort_in_batch == ""descending"":
",1
"        elif sort_batch == ""descending"":
            self.batch_list.reverse()
        else:
",1
"            f""N-batch={len(self)}, ""
            f""batch_bins={self.batch_bins}, ""
            f""sort_in_batch={self.sort_in_batch}, ""
",1
"    def __len__(self):
        return len(self.batch_list)
",1
"from typing import Sequence

import torch
from typeguard import check_argument_types
",1
"            for sym_op in [
                output_dir / f""{ph}.{cr}.ave.pth"",
                output_dir / f""{ph}.{cr}.ave_{len(epoch_and_values)}best.pth"",
",1
"                        output_dir / f""{e}epoch.pth"", map_location=""cpu"",
",1
"                    )
                states = _loaded[e]

                if avg is None:
",1
"                    avg = states
",1
"                else:
",1
"                    # Accumulated
                    for k in avg:
",1
"                        avg[k] += states[k]
            for k in avg:
                avg[k] /= len(epoch_and_values)
",1
"from collections import defaultdict
from typing import Dict
from typing import List
",1
"from espnet.nets.pytorch_backend.rnn.attentions import AttForward
from espnet.nets.pytorch_backend.rnn.attentions import AttForwardTA
from espnet.nets.pytorch_backend.rnn.attentions import AttLoc
from espnet.nets.pytorch_backend.rnn.attentions import AttLoc2D
",1
"    """"""Derive the outputs from the all attention layers

    Args:
        model:
        batch: same as forward
",1
"    Returns:
        return_dict: A dict of a list of tensor.
        key_names x batch x (D1, D2, ...)
",1
"        k: v.shape for k, v in batch.items()
    }
",1
"
",1
"    outputs = {}
    handles = {}
    for name, modu in model.named_modules():

        def hook(module, input, output, name=name):
",1
"            if isinstance(module, MultiHeadedAttention):
                # att_w: (B, Tout, Tin)
                att_w = output
                outputs[name] = att_w.detach().cpu()
            elif isinstance(module, AttLoc2D):
",1
"                c, w = output
",1
"                # w: previous concate attentions
                # w: (B, nprev, Tin)
                att_w = w[:, -1].detach().cpu()
                outputs.setdefault(name, []).append(att_w)
",1
"
    return_dict = defaultdict(list)
",1
"    for _, handle in handles.items():
        handle.remove()

",1
"    output_dir: Path,
",1
"    ngpu: Optional[int],
    log_interval: Optional[int],
    write_collected_feats: bool,
) -> None:
    """"""Perform on collect_stats mode.
",1
"    Running for deriving the shape information from data
",1
"                    if name.endswith(""_lengths""):
                        continue
                    for i, (key, data) in enumerate(zip(keys, batch[name])):
                        if f""{name}_lengths"" in batch:
",1
"        num_samples_per_epoch: int = None,
",1
"    ):
        assert check_argument_types()
        assert all(len(x) == 1 for x in batches), ""batch-size must be 1""
",1
"
            for key in sequence_keys:
                if len(batch[key]) != len(batch[sequence_keys[0]]):
                    raise RuntimeError(
",1
"        else:
",1
"        if shuffle:
            indices = np.arange(0, len(id_list))
            state.shuffle(indices)
",1
"            batches = {k: v[bs:] for k, v in batches.items()}
        return id_list, batches
from abc import ABC
from abc import abstractmethod

",1
"    @abstractmethod
    def build_iter(self, epoch: int, shuffle: bool = None):
        raise NotImplementedError
from typing import Any
",1
"from torch.utils.data import DataLoader
from typeguard import check_argument_types
",1
"        collate_fn=None,
        pin_memory: bool = False,
    ):
        assert check_argument_types()

",1
"        # https://discuss.pytorch.org/t/what-is-the-disadvantage-of-using-pin-memory/1702
        self.pin_memory = pin_memory
",1
"            if offset >= self.num_iters_per_epoch:
",1
"                    np.random.RandomState(real_epoch - 1 + self.seed).shuffle(
                        prev_batches
                    )
                    np.random.RandomState(real_epoch + self.seed).shuffle(
                        current_batches
",1
"                np.random.RandomState(epoch + self.seed).shuffle(batches)

        # For backward compatibility for pytorch DataLoader
        if self.collate_fn is not None:
",1
"            dataset=self.dataset,
            batch_sampler=batches,
            num_workers=self.num_workers,
            pin_memory=self.pin_memory,
",1
"from espnet2.schedulers.abs_scheduler import AbsBatchStepScheduler


",1
"import torch.optim.lr_scheduler as L

",1
"    def step(self, epoch: int = None):
        pass

    @abstractmethod
    def state_dict(self):
",1
"        pass

    @abstractmethod
    def load_state_dict(self, state):
",1
"        pass


",1
"# If you need to define custom scheduler, please inherit these classes
class AbsBatchStepScheduler(AbsScheduler):
",1
"    @abstractmethod
    def step(self, epoch: int = None):
        pass

    @abstractmethod
",1
"        pass

",1
"    def step(self, epoch: int = None):
        pass

",1
"class AbsValEpochStepScheduler(AbsEpochStepScheduler):
",1
"    @abstractmethod
    def step(self, val, epoch: int = None):
        pass

    @abstractmethod
",1
"# Create alias type to check the type
# Note(kamo): Currently PyTorch doesn't provide the base class
# to judge these classes.
AbsValEpochStepScheduler.register(L.ReduceLROnPlateau)
",1
"    L.LambdaLR,
    L.StepLR,
    L.MultiStepLR,
",1
"    L.ExponentialLR,
    L.CosineAnnealingLR,
]:
    AbsEpochStepScheduler.register(s)
if LooseVersion(torch.__version__) >= LooseVersion(""1.3.0""):
",1
"    Ref:
        ""Attention Is All You Need"", https://arxiv.org/pdf/1706.03762.pdf
",1
"    """"""

",1
"        return (
",1
"            * min(step_num ** -0.5, step_num * self.warmup_steps ** -1.5)
            for lr in self.base_lrs
        ]
""""""Initialize main package.""""""
",1
"except Exception:
    __version__ = ""(Not installed from setup.py)""
del pkg_resources
import io
",1
"import logging
import sys

import h5py
import kaldiio
",1
"import soundfile
",1
"
from espnet.utils.io_utils import SoundHDF5File
",1
"def file_reader_helper(
",1
"    """"""Read uttid and array in kaldi style

",1
"        ...     array

    """"""
",1
"        raise NotImplementedError(f""filetype={filetype}"")
",1
"                if self.return_shape:
                    array = array.shape
",1
"
",1
"
        self.return_shape = return_shape
",1
"
",1
"
                    if "":"" not in value:
                        raise RuntimeError(
",1
"                        except Exception:
                            logging.error(""Error when loading {}"".format(path))
                            raise
                        hdf5_dict[path] = hdf5_file
",1
"                    pass

",1
"        else:
",1
"            )
        self.ark_or_scp, self.filepath = rspecifier.split("":"", 1)
        if self.ark_or_scp not in [""ark"", ""scp""]:
",1
"                        raise RuntimeError(
",1
"                            hdf5_file = SoundHDF5File(path, ""r"")
                        except Exception:
                            logging.error(""Error when loading {}"".format(path))
                            raise
",1
"            # Closing all files
            for k in hdf5_dict:
                try:
                    hdf5_dict[k].close()
                except Exception:
",1
"                    pass
",1
"            else:
",1
"                filepath = self.filepath
            for key, (a, r) in SoundHDF5File(filepath, ""r"").items():
                if self.return_shape:
                    a = a.shape
                yield key, (r, a)
",1
"        self.return_shape = return_shape

    def __iter__(self):
",1
"#!/usr/bin/env python

# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
# Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"
""""""pytorch dataset and dataloader implementation for chainer training.""""""

import torch
",1
"
    def next(self):
        """"""Implement next function.""""""
        if self.iter is None:
            self.iter = iter(self.loader)
",1
"        return ret

    def __iter__(self):
        """"""Implement iter function.""""""
",1
"
    @property
    def epoch_detail(self):
        """"""Epoch_detail required by chainer.""""""
",1
"
    def serialize(self, serializer):
        """"""Serialize and deserialize function.""""""
",1
"        self.current_position = current_position

    def start_shuffle(self):
        """"""Shuffle function for sortagrad.""""""
        self.kwargs[""shuffle""] = True
",1
"in the Software without restriction, including without limitation the rights
",1
"LIABILITY, WHETjjHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
",1
"
import torch


",1
"
    This implementation modified from https://github.com/zcaceres/spec_augment

",1
"    :param torch.Tensor spec: input tensor with the shape (T, dim)
    :param int W: time warp parameter
    :param int F: maximum width of each freq mask
",1
"    :param int num_freq_masks: number of frequency masks
    :param int num_time_masks: number of time masks
    :param bool replace_with_zero: if True, masked parts will be filled with 0,
        if False, filled with mean
",1
"    """"""
    return time_mask(
        freq_mask(
",1
"            time_warp(spec, W=W),
",1
"
def time_warp(spec, W=5):
    """"""Time warping
",1
"    """"""
",1
"    src_pts, dest_pts = (
",1
"        torch.tensor([[[point_to_warp, y]]], device=device),
        torch.tensor([[[point_to_warp + dist_to_warp, y]]], device=device),
    )
    warped_spectro, dense_flows = sparse_image_warp(spec, src_pts, dest_pts)
",1
"def freq_mask(spec, F=30, num_masks=1, replace_with_zero=False):
    """"""Frequency masking

    :param torch.Tensor spec: input tensor with shape (T, dim)
    :param int F: maximum width of each mask
",1
"        t = random.randrange(0, T)
        t_zero = random.randrange(0, len_spectro - t)

        # avoids randrange error if values are equal and range is empty
",1
"def sparse_image_warp(
    img_tensor,
    source_control_point_locations,
",1
"    flattened_grid_locations = get_flat_grid_locations(
        image_height, image_width, device
    )

",1
"
",1
"def get_flat_grid_locations(image_height, image_width, device):
    y_range = torch.linspace(0, image_height - 1, image_height, device=device)
    x_range = torch.linspace(0, image_width - 1, image_width, device=device)
    y_grid, x_grid = torch.meshgrid(y_range, x_range)
    return torch.stack((y_grid, x_grid), -1).reshape([image_height * image_width, 2])
",1
"

def create_dense_flows(flattened_flows, batch_size, image_height, image_width):
",1
"    return query_values


",1
"
    c = train_points
",1
"    lhs_zeros = torch.randn((b, num_b_cols, num_b_cols), device=device) / 1e10
    right_block = torch.cat((matrix_b, lhs_zeros), 1)  # [b, n + d + 1, d + 1]
    lhs = torch.cat((left_block, right_block), 2)  # [b, n + d + 1, n + d + 1]

",1
"    return w, v


def cross_squared_distance_matrix(x, y):
    """"""Pairwise squared distance between two (batch) matrices' rows (2nd dim).
",1
"        x: [batch_size, n, d] float `Tensor`
        y: [batch_size, m, d] float `Tensor`
        Returns:
        squared_dists: [batch_size, n, m] float `Tensor`, where
        squared_dists[b,i,j] = ||x[b,i,:] - y[b,j,:]||^2
",1
"        return 0.5 * torch.square(r) * torch.log(torch.max(r, EPSILON))
    elif order % 2 == 0:
        r = torch.max(r, EPSILON)
        return 0.5 * torch.pow(r, 0.5 * order) * torch.log(r)
    else:
",1
"        query_points: `[b, m, d]` x values to evaluate the interpolation at
",1
"    # The flow is defined on the image grid. Turn the flow into a list of query
    # points in the grid space.
    grid_x, grid_y = torch.meshgrid(
        torch.arange(width, device=device), torch.arange(height, device=device)
",1
"
    query_points_on_grid = batched_grid - flow
    query_points_flattened = torch.reshape(
        query_points_on_grid, [batch_size, height * width, 2]
    )
",1
"
def interpolate_bilinear(
",1
"
        alpha = torch.tensor((queries - floor), dtype=grid_type, device=grid_device)
",1
"        alphas.append(alpha)

    flattened_grid = torch.reshape(grid, [batch_size * height * width, channels])
    batch_offsets = torch.reshape(
        torch.arange(batch_size, device=grid_device) * height * width, [batch_size, 1]
",1
"    interp = alphas[0] * (interp_bottom - interp_top) + interp_top
",1
"
    If kwargs are invalid, raise TypeError as same as python default
    :param function func: function to be validated
    :param dict kwargs: keyword arguments for func
",1
"    try:
        params = inspect.signature(func).parameters
    except ValueError:
        return
    if name is None:
",1
"        "")"",
        ""|"",
        ""^"",
",1
"        ""<"",
        "">"",
        ""?"",
        ""*"",
        ""["",
",1
"
    # Escape the extra characters for shell
    argv = [
",1
"        and len(value) == 2
",1
"    write_num_frames: str = None,
    compress: bool = False,
",1
"    >>>     f['uttid'] = array

    This ""scp"" has the following format:
",1
"    for some use-case. e.g. Concatenation, Splitting.

    """"""
    if filetype == ""mat"":
        return KaldiWriter(
",1
"            compress=compress,
            compression_method=compression_method,
",1
"        )
    elif filetype == ""sound.hdf5"":
        return SoundHDF5Writer(
            wspecifier, write_num_frames=write_num_frames, pcm_format=pcm_format
        )
",1
"        except Exception:
            pass

",1
"
        if self.writer_nframe is not None:
            try:
                self.writer_nframe.close()
",1
"            except Exception:
                pass
",1
"

def get_num_frames_writer(write_num_frames: str):
    """"""get_num_frames_writer

",1
"    Examples:
        >>> get_num_frames_writer('ark,t:num_frames.txt')
    """"""
",1
"
    def __setitem__(self, key, value):
",1
"    """"""Parse wspecifier to dict

    Examples:
        >>> parse_wspecifier('ark,scp:out.ark,out.scp')
",1
"
    Examples:
",1
"        if ""scp"" in spec_dict:
",1
"        value = (value[1], value[0])
",1
"        >>> fs = 16000
        >>> with SoundWriter('ark,scp:outdir,out.scp') as f:
        ...     f['key'] = fs, array
    """"""
",1
"        Path(self.dirname).mkdir(parents=True, exist_ok=True)
        self.writer = None

",1
"        else:
            self.writer_scp = None
        if write_num_frames is not None:
            self.writer_nframe = get_num_frames_writer(write_num_frames)
",1
"        if self.writer_nframe is not None:
            self.writer_nframe.write(f""{key} {len(signal)}\n"")
",1
"# -*- coding: utf-8 -*-

",1
"def fill_missing_args(args, add_arguments):
",1
"    """"""
    # check argument type
    assert isinstance(args, argparse.Namespace) or args is None
    assert callable(add_arguments)
",1
"
    # convert to dict
",1
"    for key, value in default_args.items():
        if key not in args:
            logging.info(
",1
"                'attribute ""%s"" does not exist. use default %s.' % (key, str(value))
            )
            args[key] = value
",1
"import io
import logging
import os

import h5py
",1
"class LoadInputsAndTargets(object):
",1
"    ...                output=[dict(tokenid='1 2 3 4',
    ...                             name='target1',
",1
"        mode=""asr"",
        preprocess_conf=None,
        load_input=True,
        load_output=True,
",1
"                '""use_second_target"" and ""use_speaker_embedding"" is '
                ""used only for tts mode""
            )

        self.mode = mode
",1
"            if self.load_input:
                # Note(kamo): This for-loop is for multiple inputs
                for idx, inp in enumerate(info[""input""]):
                    # {""input"":
                    #  [{""feat"": ""some/path.h5:F01_050C0101_PED_REAL"",
",1
"                        # {""input"":
                        #  [{""feat"": ""some/path.h5:F01_050C0101_PED_REAL"",
                        #    ""filetype"": ""hdf5"",
                        #    ""name"": ""target1"", ...}], ...}
",1
"        return tuple(return_batch.values())

",1
"        :return: batch, uttid_list
",1
"        else:
            # Note(kamo): Be careful not to make nonzero_idx to a generator
",1
"            nonzero_idx = list(range(len(xs[0])))

        if self.sort_in_input_length:
            # sort in input lengths based on the first input
            nonzero_sorted_idx = sorted(nonzero_idx, key=lambda i: -len(xs[0][i]))
",1
"            y_name = list(y_feats_dict.keys())[0]

",1
"        :param OrderedDict y_feats_dict:
        :return: batch, uttid_list
        :rtype: Tuple[OrderedDict, List[str]]
",1
"        """"""
",1
"
        # remove zero-length samples
",1
"        xs = [xs[i] for i in nonzero_sorted_idx]
        uttid_list = [uttid_list[i] for i in nonzero_sorted_idx]

",1
"        x_name = list(x_feats_dict.keys())[0]
        if self.load_output:
            ys = [ys[i] for i in nonzero_sorted_idx]
            y_name = list(y_feats_dict.keys())[0]
",1
"        :param OrderedDict y_feats_dict:
            e.g. {""target1"": [ndarray, ndarray, ...],
                  ""target2"": [ndarray, ndarray, ...]}
",1
"        :param int eos:
        :return: batch, uttid_list
        :rtype: Tuple[OrderedDict, List[str]]
        """"""
",1
"            # sort in input lengths
            nonzero_sorted_idx = sorted(nonzero_idx, key=lambda i: -len(xs[i]))
",1
"            spcs = None
            spembs_name = ""spembs_none""
            spcs_name = ""spcs_none""
",1
"            spembs_name = list(x_feats_dict.keys())[spembs_idx]

",1
"                loader = SoundHDF5File(filepath, ""r"", dtype=""int16"")
",1
"                self._loaders[filepath] = array
            return self._loaders[filepath]
        elif filetype == ""npz"":
            # e.g.
",1
"            loader = self._loaders.get(filepath)
            if loader is None:
                # To avoid disk access, create loader only for the first time
                loader = np.load(filepath)
",1
"                self._loaders[filepath] = loader
",1
"                self._loaders[filepath] = kaldiio.load_mat(filepath)
            return self._loaders[filepath]
        elif filetype == ""scp"":
            # e.g.
            #    {""input"": [{""feat"": ""some/path.scp:F01_050C0101_PED_REAL"",
",1
"                # To avoid disk access, create loader only for the first time
                loader = kaldiio.load_scp(filepath)
                self._loaders[filepath] = loader
            return loader[key]
",1
"

class SoundHDF5File(object):
",1
"            # filepath = a.flac.h5 -> format = flac
            second_ext = os.path.splitext(os.path.splitext(filepath)[0])[1]
            format = second_ext[1:]
",1
"        # This format affects only saving
        self.format = format

    def __repr__(self):
        return '<SoundHDF5 file ""{}"" (mode {}, format {}, type {})>'.format(
",1
"        return iter(self.file)

",1
"

def dynamic_import(import_path, alias=dict()):
    """"""dynamic import module and class

",1
"    return getattr(m, objname)
import chainer
",1
"import logging


def check_early_stop(trainer, epochs):
",1
"            ""Hit early stop at epoch ""
            + str(end_epoch)
",1
"def set_early_stop(trainer, args, is_lm=False):
    """"""Sets the early stop trigger given the program arguments

    :param trainer: The trainer used for training
    :param args: The program arguments
",1
"    :param is_lm: If the trainer is for a LM (epoch instead of epochs)
    """"""
",1
"class BaseEvaluator(Evaluator):
    """"""Base Evaluator in ESPnet""""""

    def __call__(self, trainer=None):
        ret = super().__call__(trainer)
",1
"                # force tensorboard to report evaluation log
                tb_logger = trainer.get_extension(TensorboardLogger.default_name)
",1
"
        :param trainer: The trainer
        """"""
",1
"

def batchfy_by_seq(
    sorted_data,
    batch_size,
",1
"    :param bool shortest_first: Sort from batch with shortest samples
        to longest if true, otherwise reverse
",1
"        (for ASR, TTS, MT oaxis=0, reserved for future research, -1 means all axis.)
    :return: List[List[Tuple[str, dict]]] list of batches
    """"""
",1
"        raise ValueError(f""Invalid batch_size={batch_size}"")

    # check #utts is more than min_batch_size
    if len(sorted_data) < min_batch_size:
",1
"
    # make list of minibatches
    minibatches = []
",1
"            else max(map(lambda x: int(x[""shape""][0]), info[okey]))
        )
",1
"        # change batchsize depending on the input and output length
        # if ilen = 1000 and max_length_in = 800
        # then b = batchsize / 2
        # and max(min_batches, .) avoids batchsize = 0
",1
"        end = min(len(sorted_data), start + bs)
",1
"        minibatch = sorted_data[start:end]
        if shortest_first:
",1
"            mod = min_batch_size - len(minibatch) % min_batch_size
",1
"            minibatch.extend(additional_minibatch)
        minibatches.append(minibatch)

        if end == len(sorted_data):
            break
",1
"
",1
"    shortest_first=False,
    ikey=""input"",
    okey=""output"",
",1
"):
    """"""Make variably sized batch set, which maximizes
",1
"
    the number of bins up to `batch_bins`.
",1
"        b = 0
",1
"        next_size = 0
        max_olen = 0
",1
"
    :param Dict[str, Dict[str, Any]] sorteddata: dictionary loaded from data.json
    :param int max_frames_in: Maximum input frames of a batch
    :param int max_frames_out: Maximum output frames of a batch
    :param int max_frames_inout: Maximum input+output frames of a batch
",1
"    :param int num_batches: # number of batches to use (for debug)
    :param int min_batch_size: minimum batch size (for multi-gpu)
",1
"        to longest if true, otherwise reverse
",1
"    """"""
    if max_frames_in <= 0 and max_frames_out <= 0 and max_frames_inout <= 0:
        raise ValueError(
",1
"                )
            max_olen = max(max_olen, olen)
            max_ilen = max(max_ilen, ilen)
            in_ok = max_ilen * (b + 1) <= max_frames_in or max_frames_in == 0
",1
"        if shortest_first:
            batch.reverse()
",1
"        minibatches.append(batch)
        # Check for min_batch_size and fixes the batches if needed
        i = -1
",1
"    sorted_data = random.sample(data.items(), len(data.items()))
    logging.info(""# utts: "" + str(len(sorted_data)))
",1
"    iaxis=0,
    oaxis=0,
",1
"):
    """"""Make batch set from json dictionary

",1
"        >>> data = {'utt1': {'category': 'A', 'input': ...},
        ...         'utt2': {'category': 'B', 'input': ...},
        ...         'utt3': {'category': 'B', 'input': ...},
        ...         'utt4': {'category': 'A', 'input': ...}}
",1
"    :param int batch_frames_out: maximum number of output frames in a minibatch.
",1
"    :param int min_batch_size: minimum batch size (for multi-gpu)
    :param bool shortest_first: Sort from batch with shortest samples
",1
"    :param str batch_sort_key: how to sort data before creating minibatches
        [""input"", ""output"", ""shuffle""]
    :param bool swap_io: if True, use ""input"" as output and ""output""
",1
"        as input in `data` dict
    :param bool mt: if True, use 0-axis of ""output"" as output and 1-axis of ""output""
        as input in `data` dict
    :param int iaxis: dimension to access input
",1
"        (for ASR, TTS iaxis=0, for MT iaxis=""1"".)
    :param int oaxis: dimension to access output (for ASR, TTS, MT oaxis=0,
        reserved for future research, -1 means all axis.)
",1
"        okey = ""input""
        if batch_sort_key == ""input"":
            batch_sort_key = ""output""
        elif batch_sort_key == ""output"":
            batch_sort_key = ""input""
",1
"        ikey = ""input""
        okey = ""output""

    if count == ""auto"":
        if batch_size != 0:
",1
"            count = ""seq""
        elif batch_bins != 0:
            count = ""bin""
",1
"        elif batch_frames_in != 0 or batch_frames_out != 0 or batch_frames_inout != 0:
            count = ""frame""
",1
"
    def __call__(self, trainer):
",1
"        if not self.set:
            for iterator in self.iterators:
                iterator.start_shuffle()
",1
"        """"""Starts shuffling (or reshuffles) the batches""""""
        self._shuffle = True
",1
"        dataset,
        batch_size,
        repeat=True,
        shuffle=True,
        n_processes=None,
",1
"        :param torch.nn.Tensor dataset: The dataset to take batches from
        :param int batch_size: The batch size
        :param bool repeat: Whether to repeat batches or not (enables multiple epochs)
",1
"    """"""Chainer optimizer scheduler.""""""

    def __init__(self, schedulers: List[SchedulerInterface], optimizer: Optimizer):
",1
"import argparse

from espnet.utils.dynamic_import import dynamic_import
",1
"        assert name.startswith(""--"")
        self.parser.add_argument(self.prefix + name[2:], **kwargs)


class SchedulerInterface:
",1
"            key (str): key of hyper parameter

        Returns:
            LMinterface: A new instance of LMInterface.

",1
"        args = argparse.Namespace(**kwargs)
",1
"
SCHEDULER_DICT = {}
",1
"def register_scheduler(cls):
    """"""Register scheduler.""""""
    SCHEDULER_DICT[cls.alias] = cls.__module__ + "":"" + cls.__name__
",1
"    Returns:
        type: Scheduler class

    """"""
",1
"    alias = ""noam""

",1
"        """"""Add scheduler args.""""""
",1
"        parser.add_argument(
            ""--total"",
            type=int,
            default=100000,
",1
"            help=""Number of total annealing iterations."",
",1
"        )

    def scale(self, n_iter):
",1
"        """"""Scale of lr.""""""
        import math
",1
"    def __init__(self, schedulers: List[SchedulerInterface], optimizer: Optimizer):
        """"""Initialize class.""""""
        self.schedulers = schedulers
        self.optimizer = optimizer
",1
"class SGDFactory(OptimizerFactoryInterface):
    """"""SGD factory.""""""
",1
"        """"""Register args.""""""
        return sgd(parser)

",1
"    @staticmethod
    def from_args(target, args: argparse.Namespace):
        """"""Initialize optimizer from argparse Namespace.

        Args:
",1
"
",1
"
",1
"
def adadelta(parser):
    """"""Add arguments.""""""
    parser.add_argument(""--rho"", type=float, default=0.95, help=""Rho"")
    parser.add_argument(""--eps"", type=float, default=1e-8, help=""Eps"")
",1
"
",1
"    @classmethod
    def build(cls, target, **kwargs):
        """"""Initialize optimizer with python-level args.

",1
"    elif backend == ""chainer"":
        from espnet.optimizer.chainer import OPTIMIZER_FACTORY_DICT

        return OPTIMIZER_FACTORY_DICT[name]
",1
"    def add_arguments(parser: argparse.ArgumentParser) -> argparse.ArgumentParser:
        """"""Register args.""""""
        return sgd(parser)

",1
"    @staticmethod
",1
"    def from_args(target, args: argparse.Namespace):
        """"""Initialize optimizer from argparse Namespace.
",1
"
        Args:
            target: for pytorch `model.parameters()`,
                for chainer `model`
            args (argparse.Namespace): parsed command-line args
",1
"            target: for pytorch `model.parameters()`,
                for chainer `model`
            args (argparse.Namespace): parsed command-line args
",1
"
        """"""
        return torch.optim.Adadelta(
",1
"    ""adam"": AdamFactory,
    ""sgd"": SGDFactory,
",1
"    :return: recognition tokenid string
    """"""
    # remove sos and get results
",1
"    tokenid_as_list = list(map(int, hyp[""yseq""][1:]))
",1
"    token = "" "".join(token_as_list)
    text = """".join(token_as_list).replace(""<space>"", "" "")

",1
"    new_js[""output""] = []
",1
"
        # add recognition results
        out_dic[""rec_text""] = rec_text
",1
"    return new_js
""""""Initialize sub package.""""""
""""""Initialize sub package.""""""
",1
"from espnet.asr.asr_utils import snapshot_object
from espnet.asr.asr_utils import torch_load
from espnet.asr.asr_utils import torch_resume
from espnet.asr.asr_utils import torch_snapshot
",1
"import espnet.lm.pytorch_backend.lm as lm_pytorch
from espnet.nets.mt_interface import MTInterface
from espnet.nets.pytorch_backend.e2e_asr import pad_list
",1
"from espnet.utils.training.train_utils import set_early_stop

from espnet.asr.pytorch_backend.asr import CustomEvaluator
from espnet.asr.pytorch_backend.asr import CustomUpdater
from espnet.asr.pytorch_backend.asr import load_trained_model
",1
"
import matplotlib
",1
"else:
    from itertools import zip_longest as zip_longest


",1
"        xs_pad = pad_list([torch.from_numpy(x).long() for x in xs], self.pad).to(device)
        ilens = torch.from_numpy(ilens).to(device)
        ys_pad = pad_list([torch.from_numpy(y).long() for y in ys], self.ignore_id).to(
            device
        )
",1
"    # check cuda availability
    if not torch.cuda.is_available():
        logging.warning(""cuda is not available"")
",1
"    # specify model architecture
    model_class = dynamic_import(args.model_module)
    model = model_class(idim, odim, args)
    assert isinstance(model, MTInterface)
",1
"        torch_load(args.rnnlm, rnnlm)
        model.rnnlm = rnnlm
",1
"    model_conf = args.outdir + ""/model.json""
    with open(model_conf, ""wb"") as f:
        logging.info(""writing a model config file to "" + model_conf)
",1
"            )
            args.batch_size *= args.ngpu

    # set torch device
    device = torch.device(""cuda"" if args.ngpu > 0 else ""cpu"")
",1
"    if args.train_dtype in (""float16"", ""float32"", ""float64""):
",1
"    # Setup an optimizer
    if args.opt == ""adadelta"":
",1
"    else:
        use_apex = False
",1
"    # Setup a converter
",1
"    with open(args.train_json, ""rb"") as f:
        train_json = json.load(f)[""utts""]
    with open(args.valid_json, ""rb"") as f:
        valid_json = json.load(f)[""utts""]

",1
"        min_batch_size=args.ngpu if args.ngpu > 1 else 1,
",1
"        ""main"": ChainerDataLoader(
",1
"            dataset=TransformDataset(train, lambda data: converter([load_tr(data)])),
            batch_size=1,
            num_workers=args.n_iter_processes,
",1
"        )
    )
    trainer.extend(
        extensions.PlotReport(
            [""main/acc"", ""validation/main/acc""], ""epoch"", file_name=""acc.png""
",1
"        )
    else:
        trainer.extend(torch_snapshot(), trigger=(1, ""epoch""))

",1
"                ),
            )
        elif args.criterion == ""loss"":
",1
"                    ""validation/main/loss"",
",1
"                    model, args.outdir + ""/model.acc.best"", load_fn=torch_load
                ),
                trigger=CompareValueTrigger(
                    ""validation/main/acc"",
                    lambda best_value, current_value: best_value > current_value,
",1
"                    lambda best_value, current_value: best_value > current_value,
                ),
",1
"        ""validation/main/acc"",
        ""main/ppl"",
        ""validation/main/ppl"",
",1
"            ),
            trigger=(args.report_interval_iters, ""iteration""),
        )
",1
"        trainer.extend(
",1
"        if getattr(rnnlm_args, ""model_module"", ""default"") != ""default"":
            raise ValueError(
                ""use '--api v2' option to decode with non-default language model""
            )
        rnnlm = lm_pytorch.ClassifierWithState(
",1
"            lm_pytorch.RNNLM(
                len(train_args.char_list), rnnlm_args.layer, rnnlm_args.unit
            )
        )
        torch_load(args.rnnlm, rnnlm)
",1
"        rnnlm.eval()
",1
"    else:
        rnnlm = None

    # gpu
",1
"    if args.ngpu == 1:
        gpu_id = list(range(args.ngpu))
        logging.info(""gpu id: "" + str(gpu_id))
",1
"    with open(args.trans_json, ""rb"") as f:
        js = json.load(f)[""utts""]
    new_js = {}

",1
"                )
",1
"
    else:
",1
"
        def grouper(n, iterable, fillvalue=None):
            kargs = [iter(iterable)] * n
            return zip_longest(*kargs, fillvalue=fillvalue)

",1
"        feat_lens = [js[key][""output""][1][""shape""][0] for key in keys]
        sorted_index = sorted(range(len(feat_lens)), key=lambda i: -feat_lens[i])
        keys = [keys[i] for i in sorted_index]

",1
"                    np.fromiter(
",1
"                        dtype=np.int64,
                    )
                    for name in names
                ]
                nbest_hyps = model.translate_batch(
",1
"from espnet.utils.dataset import ChainerDataLoader
from espnet.utils.dataset import TransformDataset
from espnet.utils.deterministic_utils import set_deterministic_pytorch
from espnet.utils.dynamic_import import dynamic_import
from espnet.utils.io_utils import LoadInputsAndTargets
",1
"from espnet.utils.training.batchfy import make_batchset
from espnet.utils.training.iterators import ShufflingEnabler
from espnet.utils.training.tensorboard_logger import TensorboardLogger
from espnet.utils.training.train_utils import check_early_stop
from espnet.utils.training.train_utils import set_early_stop
",1
"    from itertools import izip_longest as zip_longest
else:
",1
"
    """"""

    def __init__(self, subsampling_factor=1, dtype=torch.float32, asr_task=False):
",1
"
",1
"        args (namespace): The program arguments.

    """"""
    set_deterministic_pytorch(args)
",1
"    if not torch.cuda.is_available():
        logging.warning(""cuda is not available"")

    # get input and output dimension info
    with open(args.valid_json, ""rb"") as f:
",1
"    assert isinstance(model, STInterface)

    subsampling_factor = model.subsample[0]
",1
"            )
        )
        torch_load(args.rnnlm, rnnlm)
        model.rnnlm = rnnlm
",1
"    # check the use of multi-gpu
    if args.ngpu > 1:
        if args.batch_size != 0:
            logging.warning(
",1
"    # set torch device
",1
"        dtype = getattr(torch, args.train_dtype)
    else:
        dtype = torch.float32
    model = model.to(device=device, dtype=dtype)
",1
"        optimizer = torch.optim.Adam(
            model.parameters(), lr=args.lr, weight_decay=args.weight_decay
        )
",1
"        from espnet.nets.pytorch_backend.transformer.optimizer import get_std_opt

        optimizer = get_std_opt(
",1
"            model, optimizer = amp.initialize(
                model, optimizer, opt_level=args.train_dtype
            )
        use_apex = True
",1
"        args.maxlen_in,
        args.maxlen_out,
",1
"        batch_frames_out=args.batch_frames_out,
        batch_frames_inout=args.batch_frames_inout,
    )

    load_tr = LoadInputsAndTargets(
",1
"        mode=""asr"",
        load_output=True,
        preprocess_conf=args.preprocess_conf,
",1
"        preprocess_args={""train"": True},  # Switch the mode of preprocessing
    )
    load_cv = LoadInputsAndTargets(
",1
"        ""main"": ChainerDataLoader(
            dataset=TransformDataset(valid, lambda data: converter([load_cv(data)])),
",1
"        train_iter,
        optimizer,
",1
"        device,
        args.ngpu,
        args.grad_noise,
        args.accum_grad,
        use_apex=use_apex,
",1
"        )

    # Resume from a snapshot
    if args.resume:
",1
"    if args.num_save_attention > 0:
        data = sorted(
",1
"        trainer.extend(att_reporter, trigger=(1, ""epoch""))
    else:
        att_reporter = None

    # Make a plot for training and validation values
",1
"                ""main/loss"",
",1
"                ""validation/main/loss_st"",
            ],
            ""epoch"",
",1
"        extensions.PlotReport(
",1
"    # Save best models
    trainer.extend(
        snapshot_object(model, ""model.loss.best""),
        trigger=training.triggers.MinValueTrigger(""validation/main/loss""),
    )
",1
"    trainer.extend(
        snapshot_object(model, ""model.acc.best""),
        trigger=training.triggers.MaxValueTrigger(""validation/main/acc""),
    )

",1
"    # save snapshot which contains model and optimizer states
    if args.save_interval_iters > 0:
        trainer.extend(
            torch_snapshot(filename=""snapshot.iter.{.updater.iteration}""),
",1
"        trainer.extend(torch_snapshot(), trigger=(1, ""epoch""))

    # epsilon decay in the optimizer
",1
"                ),
            )
        elif args.criterion == ""loss"":
",1
"                    ""validation/main/loss"",
                    lambda best_value, current_value: best_value < current_value,
                ),
",1
"                    lambda best_value, current_value: best_value > current_value,
                ),
",1
"            trainer.extend(
",1
"                    model, args.outdir + ""/model.loss.best"", load_fn=torch_load
",1
"                ),
                trigger=CompareValueTrigger(
                    ""validation/main/loss"",
                    lambda best_value, current_value: best_value < current_value,
",1
"            extensions.observe_value(
                ""lr"",
                lambda trainer: trainer.updater.get_optimizer(""main"").param_groups[0][
                    ""lr""
                ],
",1
"            ),
            trigger=(args.report_interval_iters, ""iteration""),
        )
",1
"        report_keys.append(""lr"")
",1
"    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
",1
"        trainer.extend(
",1
"    set_deterministic_pytorch(args)
    model, train_args = load_trained_model(args.model)
",1
"
    # read rnnlm
",1
"        rnnlm = None

    # gpu
    if args.ngpu == 1:
        gpu_id = list(range(args.ngpu))
",1
"        else args.preprocess_conf,
        preprocess_args={""train"": False},
",1
"
                for i, nbest_hyp in enumerate(nbest_hyps):
                    name = names[i]
",1
"""""""Initialize sub package.""""""
#!/usr/bin/env python3

# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
"
from chainer.serializers.npz import DictionarySerializer
from chainer.serializers.npz import NpzDeserializer
",1
"
    """"""

    def __init__(self, key, compare_fn, trigger=(1, ""epoch"")):
",1
"        """"""Get value related to the key and compare with current value.""""""
        observation = trainer.observation
        summary = self._summary
        key = self._key
        if key in observation:
",1
"            return True
",1
"        outdir,
        converter,
        transform,
",1
"        if not os.path.exists(self.outdir):
",1
"            os.makedirs(self.outdir)

",1
"                    self._plot_and_save_attention(att_w, filename.format(trainer))
            # han
            for idx, att_w in enumerate(att_ws[num_encs]):
",1
"                filename = ""%s/%s.ep.{.updater.epoch}.han.png"" % (
                    self.outdir,
                    self.data[idx][0],
                )
                att_w = self.get_attention_weight(idx, att_w)
",1
"                self._plot_and_save_attention(att_w, filename.format(trainer))

    def log_attentions(self, logger, step):
        """"""Add image files of att_ws matrix to the tensorboard.""""""
",1
"                att_w = self.get_attention_weight(idx, att_w)
                plot = self.draw_attention_plot(att_w)
                logger.add_figure(""%s"" % (self.data[idx][0]), plot.gcf(), step)
                plot.clf()

",1
"
        """"""
        batch = self.converter([self.transform(self.data)], self.device)
        if isinstance(batch, tuple):
",1
"            att_w = att_w[:, :dec_len, :enc_len]
        else:
",1
"            att_w = att_w[:dec_len, :enc_len]
        return att_w

",1
"            for i in range(att_w.shape[1]):
                plt.plot(att_w[:, i])
                legends.append(""Att{}"".format(i))
            plt.ylim([0, 1.0])
",1
"            plt.xlim([0, att_w.shape[0]])
",1
"
    """"""

",1
"def _restore_snapshot(model, snapshot, load_fn=chainer.serializers.load_npz):
    load_fn(snapshot, model)
    logging.info(""restored from "" + str(snapshot))
",1
"        _adadelta_eps_decay(trainer, eps_decay)

    return adadelta_eps_decay


",1
"        setattr(optimizer, ""eps"", current_eps * eps_decay)
",1
"        An extension function.

    """"""

    @extension.make_extension(trigger=(1, ""epoch""), priority=-100)
",1
"
def _torch_snapshot_object(trainer, target, filename, savefun):
    # make snapshot_dict dictionary
    s = DictionarySerializer()
    s.save(trainer)
",1
"    else:
        # (for ASR)
        if hasattr(trainer.updater.model, ""module""):
            model_state_dict = trainer.updater.model.module.state_dict()
",1
"        else:
            model_state_dict = trainer.updater.model.state_dict()
    snapshot_dict = {
",1
"        if param.grad is not None:
            _shape = param.grad.size()
",1
"            noise = sigma * torch.randn(_shape).to(param.device)
            param.grad += noise


",1
"
    Args:
",1
"    if conf_path is None:
        model_conf = os.path.dirname(model_path) + ""/model.json""
    else:
",1
"        return idim, odim, argparse.Namespace(**args)


",1
"def chainer_load(path, model):
    """"""Load chainer model parameters.

    Args:
",1
"        path (str): Model path or snapshot file path to be loaded.
        model (chainer.Chain): Chainer model.
",1
"        filename (str): Name of the file into which the object is serialized.It can
            be a format string, where the trainer object is passed to
            the :meth: `str.format` method. For example,
            ``'snapshot_{.updater.iteration}'`` is converted to
            ``'snapshot_10000'`` at the 10,000th iteration.
",1
"    def snapshot_object(trainer):
        torch_save(os.path.join(trainer.out, filename.format(trainer)), target)

    return snapshot_object
",1
"
def torch_load(path, model):
",1
"    """"""Load torch model states.

",1
"    Args:
",1
"    if ""snapshot"" in os.path.basename(path):
",1
"            trainer.updater.model.load_state_dict(snapshot_dict[""model""])

    # retore optimizer states
",1
"    Args:
        hyp (list[dict[str, Any]]): Recognition hypothesis.
",1
"    Returns:
        tuple(str, str, str, float)

    """"""
    # remove sos and get results
",1
"
    # convert to string
    tokenid = "" "".join([str(idx) for idx in tokenid_as_list])
    token = "" "".join(token_as_list)
    text = """".join(token_as_list).replace(""<space>"", "" "")
",1
"
def add_results_to_json(js, nbest_hyps, char_list):
    """"""Add N-best results to json.

    Args:
",1
"        else:
",1
"            # for no reference case (e.g., speech translation)
            out_dic = {""name"": """"}

        # update name
",1
"    frame_shift=None,
    bottom=True,
    left=True,
    right=True,
",1
"    top=False,
    labelbottom=True,
    labelleft=True,
",1
"    labelright=True,
    labeltop=False,
    cmap=""inferno"",
):
    """"""Plot spectrogram using matplotlib.
",1
"        mode (str): db or linear.
        fs (int): Sample frequency. To convert y-axis to kHz unit.
        frame_shift (int): The frame shift of stft. To convert x-axis to second unit.
        bottom (bool):Whether to draw the respective ticks.
        left (bool):
",1
"        cmap (str): Colormap defined in matplotlib.
",1
"
    if labelbottom:
        plt.xlabel(""time [{}]"".format(xlabel))
    if labelleft:
",1
"
",1
"        ""aconv_filts"": 100,
    }
    for k in default_dict.keys():
",1
"                        k, vars(args)[k], vars(args)[k][: args.num_encs]
                    )
                )
            vars(args)[k] = vars(args)[k][: args.num_encs]
",1
"                logging.warning(
",1
"    CompareValueTrigger, restore_snapshot, adadelta_eps_decay, chainer_load,
    torch_snapshot, torch_save, torch_resume, AttributeDict, get_model_conf.
",1
"# * -------------------- chainer extension related -------------------- *
class PlotAttentionReport(extension.Extension):
    """"""Plot attention reporter.

",1
"    """"""

",1
"    def __init__(self, att_vis_fn, data, outdir, converter, device, reverse=False):
        """"""Initialize PlotAttentionReport.""""""
",1
"        """"""
        batch = self.converter([self.converter.transform(self.data)], self.device)
",1
"
    Args:
",1
"
            # add to list of N-best result dicts
            tmp_js.append(out_dic)

            # show 1-best result
",1
"                logging.info(""groundtruth: %s"" % out_dic[""text""])
                logging.info(""prediction : %s"" % out_dic[""rec_text""])

        new_js[""output""].append(tmp_js)
    return new_js
",1
"import six

# chainer related
import chainer

",1
"from chainer import training

from chainer.datasets import TransformDataset
",1
"from espnet.asr.asr_utils import add_results_to_json
",1
"from espnet.utils.training.train_utils import check_early_stop
",1
"import espnet.lm.chainer_backend.lm as lm_chainer

# numpy related
",1
"def train(args):
",1
"    """"""Train with the given args.

    Args:
        args (namespace): The program arguments.

",1
"    if args.mtlalpha == 1.0:
        mtl_mode = ""ctc""
        logging.info(""Pure CTC mode"")
    elif args.mtlalpha == 0.0:
",1
"        )
    for key in sorted(vars(args).keys()):
        logging.info(""ARGS: "" + key + "": "" + str(vars(args)[key]))

    # Set gpu
",1
"
    # Setup an optimizer
    if args.opt == ""adadelta"":
        optimizer = chainer.optimizers.AdaDelta(eps=args.eps)
",1
"    accum_grad = args.accum_grad
    if ngpu <= 1:
        # make minibatch list (variable length)
        train = make_batchset(
            train_json,
",1
"            min_batch_size=args.ngpu if args.ngpu > 1 else 1,
            shortest_first=use_sortagrad,
            count=args.batch_count,
            batch_bins=args.batch_bins,
            batch_frames_in=args.batch_frames_in,
",1
"            batch_frames_inout=args.batch_frames_inout,
            iaxis=0,
            oaxis=0,
        )
",1
"                    shuffle=not use_sortagrad,
                )
",1
"            ]
        else:
            train_iters = [
                ToggleableShufflingSerialIterator(
",1
"            accum_grad=accum_grad,
",1
"        train_subsets = []
",1
"                k: v for i, (k, v) in enumerate(train_json.items()) if i % ngpu == gid
            }
",1
"                )
            ]

        # each subset must have same length for MultiprocessParallelUpdater
        maxlen = max([len(train_subset) for train_subset in train_subsets])
",1
"        for train_subset in train_subsets:
            if maxlen != len(train_subset):
                for i in six.moves.xrange(maxlen - len(train_subset)):
",1
"                    n_prefetch=8,
                    maxtasksperchild=20,
                    shuffle=not use_sortagrad,
                )
",1
"            ]
        else:
",1
"            ShufflingEnabler(train_iters),
            trigger=(args.sortagrad if args.sortagrad != -1 else args.epochs, ""epoch""),
        )
",1
"    if args.opt == ""noam"":
        from espnet.nets.chainer_backend.transformer.training import VaswaniRule

",1
"            ),
            trigger=(1, ""iteration""),
        )
    # Resume from a snapshot
",1
"        batch_bins=args.batch_bins,
        batch_frames_in=args.batch_frames_in,
        batch_frames_out=args.batch_frames_out,
        batch_frames_inout=args.batch_frames_inout,
",1
"        oaxis=0,
    )

",1
"            n_processes=args.n_iter_processes,
            n_prefetch=8,
",1
"    # Save attention weight each epoch
    if args.num_save_attention > 0 and args.mtlalpha != 1.0:
        data = sorted(
            list(valid_json.items())[: args.num_save_attention],
",1
"            key=lambda x: int(x[1][""input""][0][""shape""][1]),
            reverse=True,
        )
        if hasattr(model, ""module""):
            att_vis_fn = model.module.calculate_all_attentions
",1
"            plot_class = model.attention_plot_class
        logging.info(""Using custom PlotAttentionReport"")
        att_reporter = plot_class(
            att_vis_fn,
",1
"            [
                ""main/loss"",
",1
"        )
    )

    # Save best models
",1
"            trigger=training.triggers.MaxValueTrigger(""validation/main/acc""),
        )
",1
"        ""validation/main/loss_att"",
        ""main/acc"",
        ""validation/main/acc"",
",1
"        ""elapsed_time"",
    ]
",1
"    if args.opt == ""adadelta"":
        trainer.extend(
            extensions.observe_value(
                ""eps"", lambda trainer: trainer.updater.get_optimizer(""main"").eps
",1
"        report_keys.append(""eps"")
    trainer.extend(
        extensions.PrintReport(report_keys),
        trigger=(args.report_interval_iters, ""iteration""),
",1
"    )
",1
"            trigger=(args.report_interval_iters, ""iteration""),
        )

",1
"    set_deterministic_chainer(args)

",1
"    if args.rnnlm:
",1
"                len(train_args.char_list), rnnlm_args.layer, rnnlm_args.unit
",1
"            )
        )
",1
"    else:
        rnnlm = None

    if args.word_rnnlm:
",1
"                    word_rnnlm.predictor, rnnlm.predictor, word_dict, char_dict
",1
"                extlm_chainer.LookAheadWordLM(
",1
"    new_js = {}
    with chainer.no_backprop_mode():
        for idx, name in enumerate(js.keys(), 1):
",1
"    with open(args.result_label, ""wb"") as f:
        f.write(
            json.dumps(
",1
"from espnet.nets.scorer_interface import BatchScorerInterface
from espnet.nets.scorers.length_bonus import LengthBonus
from espnet.utils.deterministic_utils import set_deterministic_pytorch
",1
"        sort_in_input_length=False,
        preprocess_conf=train_args.preprocess_conf
        if args.preprocess_conf is None
",1
"        token_list=train_args.char_list,
        pre_beam_score_key=None if args.ctc_weight == 1.0 else ""decoder"",
    )
    # TODO(karita): make all scorers batchfied
    if args.batchsize == 1:
",1
"        ]
        if len(non_batch) == 0:
            beam_search.__class__ = BatchBeamSearch
            logging.info(""BatchBeamSearch implementation is selected."")
",1
"        else:
            logging.warning(
                f""As non-batch scorers {non_batch} are found, ""
",1
"                f""fall back to non-batch implementation.""
",1
"    new_js = {}
    with torch.no_grad():
        for idx, name in enumerate(js.keys(), 1):
",1
"
",1
"from espnet.asr.asr_mix_utils import add_results_to_json
",1
"from espnet.asr.asr_utils import adadelta_eps_decay

from espnet.asr.asr_utils import CompareValueTrigger
from espnet.asr.asr_utils import get_model_conf
",1
"from espnet.asr.asr_utils import restore_snapshot
",1
"
",1
"        xs, ys = batch[0]
        # Convert zip object to list in python 3.x
",1
"
",1
"                [torch.from_numpy(x.real).float() for x in xs], 0
",1
"        else:
            xs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0).to(
                device, dtype=self.dtype
            )
",1
"    Args:
",1
"    # check cuda availability
    if not torch.cuda.is_available():
        logging.warning(""cuda is not available"")

    # get input and output dimension info
",1
"
",1
"    if not os.path.exists(args.outdir):
        os.makedirs(args.outdir)
",1
"        logging.info(""writing a model config file to "" + model_conf)
        f.write(
            json.dumps(
                (idim, odim, vars(args)), indent=4, ensure_ascii=False, sort_keys=True
",1
"        if args.batch_size != 0:
            logging.warning(
                ""batch size is automatically increased (%d -> %d)""
",1
"        dtype = torch.float32
    model = model.to(device=device, dtype=dtype)

    # Setup an optimizer
    if args.opt == ""adadelta"":
",1
"
",1
"    else:
        use_apex = False

    # FIXME: TOO DIRTY HACK
    setattr(optimizer, ""target"", reporter)
",1
"        args.maxlen_out,
        args.minibatches,
        min_batch_size=args.ngpu if args.ngpu > 1 else 1,
",1
"        preprocess_args={""train"": True},  # Switch the mode of preprocessing
    )
    load_cv = LoadInputsAndTargets(
        mode=""asr"",
",1
"        args.accum_grad,
        use_apex=use_apex,
",1
"    trainer.extend(CustomEvaluator(model, valid_iter, reporter, device, args.ngpu))

    # Save attention weight each epoch
",1
"        )
        if hasattr(model, ""module""):
            att_vis_fn = model.module.calculate_all_attentions
            plot_class = model.module.attention_plot_class
",1
"            data,
",1
"            transform=load_cv,
            device=device,
        )
        trainer.extend(att_reporter, trigger=(1, ""epoch""))
",1
"    trainer.extend(
",1
"        extensions.PlotReport(
            [
                ""main/loss"",
",1
"                ""validation/main/loss"",
                ""main/loss_ctc"",
                ""validation/main/loss_ctc"",
",1
"                ""main/loss_att"",
                ""validation/main/loss_att"",
",1
"                    lambda best_value, current_value: best_value > current_value,
                ),
",1
"            trainer.extend(
                adadelta_eps_decay(args.eps_decay),
                trigger=CompareValueTrigger(
",1
"    report_keys = [
        ""epoch"",
        ""iteration"",
        ""main/loss"",
",1
"        ""main/loss_ctc"",
        ""main/loss_att"",
        ""validation/main/loss"",
        ""validation/main/loss_ctc"",
",1
"        ""elapsed_time"",
    ]
    if args.opt == ""adadelta"":
        trainer.extend(
",1
"        report_keys.append(""validation/main/wer"")
    trainer.extend(
",1
"    set_early_stop(trainer, args)

    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
        trainer.extend(
",1
"            TensorboardLogger(SummaryWriter(args.tensorboard_dir), att_reporter),
            trigger=(args.report_interval_iters, ""iteration""),
        )
    # Run the training
",1
"    if args.rnnlm:
",1
"    else:
",1
"        rnnlm = None

    if args.word_rnnlm:
        rnnlm_args = get_model_conf(args.word_rnnlm, args.word_rnnlm_conf)
        word_dict = rnnlm_args.char_list_dict
",1
"        char_dict = {x: i for i, x in enumerate(train_args.char_list)}
        word_rnnlm = lm_pytorch.ClassifierWithState(
            lm_pytorch.RNNLM(len(word_dict), rnnlm_args.layer, rnnlm_args.unit)
        )
",1
"        logging.info(""gpu id: "" + str(gpu_id))
        model.cuda()
        if rnnlm:
            rnnlm.cuda()
",1
"        else args.preprocess_conf,
        preprocess_args={""train"": False},
    )
",1
"            for idx, name in enumerate(js.keys(), 1):
                logging.info(""(%d/%d) decoding "" + name, idx, len(js.keys()))
                batch = [(name, js[name])]
                feat = load_inputs_and_targets(batch)[0][0]
",1
"
    else:
",1
"            return zip_longest(*kargs, fillvalue=fillvalue)

",1
"                    )
",1
"
",1
"    for key_p, value_p in partial_state_dict.items():
        if any(key_p.startswith(m) for m in modules):
",1
"        partial_modules, key=lambda x: (x[0], x[1])
",1
"
    for key, value in model_state_dict.items():
        if any(key.startswith(m) for m in modules):
",1
"
    return new_state_dict
",1
"

def get_partial_lm_state_dict(model_state_dict, modules):
    """"""Create compatible ASR state_dict from model_state_dict (LM).
",1
"        modules (list): specified module list for transfer

    Return:
        new_state_dict (OrderedDict): the updated state_dict
",1
"    new_modules = []

    for key, value in list(model_state_dict.items()):
        if key == ""predictor.embed.weight"" and ""predictor.embed."" in modules:
",1
"        model_state_dict (OrderedDict): trained model state_dict
        modules (list): specified module list for transfer

    Return:
",1
"        new_mods (list): the update module list

    """"""
",1
"            ""available modules in model."",
            incorrect_mods,
        )
        logging.warning(""for information, the existing modules in model are:"")
",1
"        logging.warning(""%s"", mods_model)

",1
"    """"""Load the trained model for recognition.
",1
"        model_path, os.path.join(os.path.dirname(model_path), ""model.json"")
",1
"    if hasattr(train_args, ""model_module""):
        model_module = train_args.model_module
    else:
        model_module = ""espnet.nets.pytorch_backend.e2e_asr:E2E""
    model_class = dynamic_import(model_module)
",1
"
",1
"    )

    return model.state_dict(), False


",1
"    """"""Load model encoder or/and decoder modules with ESPNET pre-trained model(s).

    Args:
        idim (int): initial input dimension.
",1
"    """"""

    def print_new_keys(state_dict, modules, model_path):
        logging.warning(""loading %s from model: %s"", modules, model_path)

",1
"    dec_model_path = args.dec_init
    enc_modules = args.enc_init_mods
    dec_modules = args.dec_init_mods

",1
"                        ):
                            print_new_keys(partial_state_dict, modules, model_path)
                            main_state_dict.update(partial_state_dict)
",1
"from chainer import training
from chainer.training import extensions
from chainer.training.updater import StandardUpdater
",1
"import numpy as np
",1
"from espnet.asr.asr_utils import get_model_conf
from espnet.asr.asr_utils import plot_spectrogram
from espnet.asr.asr_utils import restore_snapshot
from espnet.asr.asr_utils import snapshot_object
",1
"from espnet.asr.asr_utils import torch_load
from espnet.asr.asr_utils import torch_resume
from espnet.asr.asr_utils import torch_snapshot
",1
"from espnet.transform.transformation import Transformation
",1
"from espnet.utils.cli_writers import file_writer_helper
from espnet.utils.dataset import ChainerDataLoader
from espnet.utils.dataset import TransformDataset
from espnet.utils.deterministic_utils import set_deterministic_pytorch
",1
"from espnet.utils.dynamic_import import dynamic_import
from espnet.utils.io_utils import LoadInputsAndTargets
from espnet.utils.training.batchfy import make_batchset
",1
"from espnet.utils.training.evaluator import BaseEvaluator
",1
"from espnet.utils.training.iterators import ShufflingEnabler
from espnet.utils.training.tensorboard_logger import TensorboardLogger
",1
"
    # The core part of the update routine can be customized by overriding
    def evaluate(self):
",1
"        if hasattr(iterator, ""reset""):
            iterator.reset()
",1
"            it = iterator
        else:
            it = copy.copy(iterator)
",1
"
        summary = reporter_module.DictSummary()
",1
"        device (torch.device): The device to use.
        ngpu (int): The number of gpus to use.
        use_apex (bool): The flag to use Apex in backprop.

",1
"        self.use_apex = use_apex

    # The core part of the update routine can be customized by overriding.
    def update_core(self):
        """"""Main update routine of the CustomUpdater.""""""
",1
"        batch = train_iter.next()
        # self.iteration += 1 # Increase may result in early report,
        # which is done in other place automatically.
        x = _recursive_to(batch, self.device)
",1
"        # gradient accumulation is turned off in order to evaluate the model
",1
"
        # Compute the loss at this time step and accumulate it
        if self.ngpu == 0:
",1
"            # NOTE: for a compatibility with noam optimizer
            opt = optimizer.optimizer if hasattr(optimizer, ""optimizer"") else optimizer
",1
"        # compute the gradient norm to check if it is normal or not
        grad_norm = torch.nn.utils.clip_grad_norm_(
            self.model.parameters(), self.grad_clip_threshold
        )
",1
"        else:
",1
"        dtype (torch.dtype): Data type to convert.

    """"""

    def __init__(self, subsampling_factor=1, dtype=torch.float32):
",1
"        self.subsampling_factor = subsampling_factor
        self.ignore_id = -1
",1
"            xs = [x[:: self.subsampling_factor, :] for x in xs]

        # get batch of lengths of input sequences
",1
"                    np.array(y[0][:]) if isinstance(y, tuple) else y
                ).long()
                for y in ys
            ],
",1
"    Args:
        subsampling_factors (list): List of subsampling factors for each encoder.
        dtype (torch.dtype): Data type to convert.
",1
"        ).to(device)

        return xs_list_pad, ilens_list, ys_pad
",1
"

",1
"
    Args:
        args (namespace): The program arguments.
",1
"        logging.info(""Pure attention mode"")
    else:
        mtl_mode = ""mtl""
        logging.info(""Multitask learning mode"")
",1
"        model = load_trained_modules(idim_list[0], odim, args)
    else:
        model_class = dynamic_import(args.model_module)
",1
"            idim_list[0] if args.num_encs == 1 else idim_list, odim, args
        )
",1
"        logging.info(""writing a model config file to "" + model_conf)
",1
"    else:
        dtype = torch.float32
    model = model.to(device=device, dtype=dtype)
",1
"            from apex import amp
",1
"        if args.opt == ""noam"":
",1
"            )
        use_apex = True

        from espnet.nets.pytorch_backend.ctc import CTC
",1
"
        amp.register_float_function(CTC, ""loss_fn"")
        amp.init()
        logging.warning(""register ctc as float function"")
",1
"    # read json data
    with open(args.train_json, ""rb"") as f:
",1
"
",1
"        train_json,
",1
"        args.batch_size,
        args.maxlen_in,
        args.maxlen_out,
",1
"        args.maxlen_out,
",1
"        load_output=True,
        preprocess_conf=args.preprocess_conf,
        preprocess_args={""train"": True},  # Switch the mode of preprocessing
    )
    load_cv = LoadInputsAndTargets(
",1
"    # hack to make batchsize argument as 1
    # actual bathsize is included in a list
",1
"        {""main"": train_iter},
        optimizer,
        device,
        args.ngpu,
",1
"        trainer.extend(
            ShufflingEnabler([train_iter]),
            trigger=(args.sortagrad if args.sortagrad != -1 else args.epochs, ""epoch""),
",1
"            list(valid_json.items())[: args.num_save_attention],
",1
"            key=lambda x: int(x[1][""input""][0][""shape""][1]),
            reverse=True,
        )
        if hasattr(model, ""module""):
            att_vis_fn = model.module.calculate_all_attentions
",1
"            device=device,
        )
        trainer.extend(att_reporter, trigger=(1, ""epoch""))
",1
"            [""main/acc"", ""validation/main/acc""], ""epoch"", file_name=""acc.png""
        )
    )
    trainer.extend(
",1
"        extensions.PlotReport(
            [""main/cer_ctc"", ""validation/main/cer_ctc""]
            + ([] if args.num_encs == 1 else report_keys_loss_ctc),
",1
"
    # Save best models
    trainer.extend(
        snapshot_object(model, ""model.loss.best""),
        trigger=training.triggers.MinValueTrigger(""validation/main/loss""),
",1
"                ),
",1
"        ""validation/main/loss"",
        ""validation/main/loss_ctc"",
        ""validation/main/loss_att"",
        ""main/acc"",
",1
"            ),
            trigger=(args.report_interval_iters, ""iteration""),
        )
        report_keys.append(""eps"")
    if args.report_cer:
",1
"        trigger=(args.report_interval_iters, ""iteration""),
    )

    trainer.extend(extensions.ProgressBar(update_interval=args.report_interval_iters))
    set_early_stop(trainer, args)
",1
"
",1
"
    """"""
",1
"    set_deterministic_pytorch(args)
    model, train_args = load_trained_model(args.model)
",1
"                ""use '--api v2' option to decode with non-default language model""
            )
        rnnlm = lm_pytorch.ClassifierWithState(
",1
"            lm_pytorch.RNNLM(
                len(train_args.char_list),
                rnnlm_args.layer,
",1
"                getattr(rnnlm_args, ""embed_unit"", None),  # for backward compatibility
            )
        )
",1
"        rnnlm = None

    if args.word_rnnlm:
        rnnlm_args = get_model_conf(args.word_rnnlm, args.word_rnnlm_conf)
",1
"                len(word_dict),
                rnnlm_args.layer,
",1
"        word_rnnlm.eval()

        if rnnlm is not None:
            rnnlm = lm_pytorch.ClassifierWithState(
                extlm_pytorch.MultiLevelLM(
",1
"                    word_rnnlm.predictor, rnnlm.predictor, word_dict, char_dict
",1
"            rnnlm.cuda()

    # read json data
    with open(args.recog_json, ""rb"") as f:
        js = json.load(f)[""utts""]
",1
"        load_output=False,
        sort_in_input_length=False,
        preprocess_conf=train_args.preprocess_conf
        if args.preprocess_conf is None
        else args.preprocess_conf,
",1
"                feat = (
                    feat[0][0]
                    if args.num_encs == 1
                    else [feat[idx][0] for idx in range(model.num_encs)]
                )
",1
"                        )
                        se2e.accept_input(feat[i : i + args.streaming_window])
",1
"                    logging.info(""Running offline attention decoder"")
                    se2e.decode_with_attention_offline()
                    logging.info(""Offline attention decoder finished"")
",1
"                elif args.streaming_mode == ""segment"" and args.num_encs == 1:
                    logging.info(
",1
"                            text = text.replace(model.blank, """")
                            logging.info(text)
                            for n in range(args.nbest):
",1
"        with torch.no_grad():
            for names in grouper(args.batchsize, keys, None):
                names = [name for name in names if name]
                batch = [(name, js[name]) for name in names]
                feats = (
",1
"                    raise NotImplementedError
                elif args.streaming_mode == ""segment"" and args.num_encs == 1:
",1
"                    if args.batchsize > 1:
                        raise NotImplementedError
",1
"                            ).strip()  # for SentencePiece
                            text = text.replace(model.space, "" "")
                            text = text.replace(model.blank, """")
                            logging.info(text)
                            for n in range(args.nbest):
",1
"            json.dumps(
                {""utts"": new_js}, indent=4, ensure_ascii=False, sort_keys=True
            ).encode(""utf_8"")
        )

",1
"
    # load trained model parameters
    logging.info(""reading model parameters from "" + args.model)
",1
"    model = model_class(idim, odim, train_args)
    assert isinstance(model, ASRInterface)
    torch_load(args.model, model)
",1
"    # read json data
    with open(args.recog_json, ""rb"") as f:
        js = json.load(f)[""utts""]
",1
"        transform = None

",1
"        if preprocess_conf is not None:
            # Read the conffile and find stft setting
            with open(preprocess_conf) as f:
                # Json format: e.g.
                #    {""process"": [{""type"": ""stft"",
",1
"                conf = json.load(f)
",1
"            istft = IStft(
                win_length=args.istft_win_length,
                n_shift=args.istft_n_shift,
                window=args.istft_window,
            )
",1
"            )

    # sort data
    keys = list(js.keys())
",1
"                num_images += 1
                ref_ch = 0

",1
"                    mas[:, ref_ch].T,
                    fs=args.fs,
                    mode=""linear"",
",1
"
                plt.subplot(4, 1, 2)
                plt.title(""Noisy speech [ref={}ch]"".format(ref_ch))
                plot_spectrogram(
",1
"                plt.subplot(4, 1, 3)
                plt.title(""Masked speech [ref={}ch]"".format(ref_ch))
                plot_spectrogram(
",1
"
            # Write enhanced wave files
            if enh_writer is not None:
                if istft is not None:
",1
"                        # Truncate the frames added by stft padding
                        enh = enh[: len(org_feats[idx])]
                    elif len(org_feats) > len(enh):
                        padwidth = [(0, (len(org_feats[idx]) - len(enh)))] + [
",1
"                            (0, 0)
                        ] * (enh.ndim - 1)
                        enh = np.pad(enh, padwidth, mode=""constant"")

                if args.enh_filetype in (""sound"", ""sound.hdf5""):
",1
"                    enh_writer[name] = (args.fs, enh)
                else:
                    # Hint: To dump stft_signal, mask or etc,
                    # enh_filetype='hdf5' might be convenient.
                    enh_writer[name] = enh
",1
"# Copyright 2019 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Neural machine translation model decoding script.""""""

",1
"
import numpy as np


# NOTE: you need this func to generate our sphinx doc
",1
"    parser.add_argument(
        ""--backend"",
        type=str,
        default=""chainer"",
        choices=[""chainer"", ""pytorch""],
",1
"        default=None,
        help=""The configuration file for the pre-processing"",
    )
    parser.add_argument(
",1
"        ""--api"",
        default=""v1"",
        choices=[""v1"", ""v2""],
",1
"    parser.add_argument(
        ""--model"", type=str, required=True, help=""Model file parameters to read""
    )
",1
"        ""--minlenratio"",
        type=float,
        default=0.0,
        help=""Input length ratio to obtain min output length"",
",1
"    # rnnlm related
    parser.add_argument(
        ""--rnnlm"", type=str, default=None, help=""RNNLM model file to read""
",1
"            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"    logging.info(""set random seed = %d"" % args.seed)

    # trans
",1
"        raise ValueError(""Only pytorch are supported."")


",1
"
""""""End-to-end speech translation model decoding script.""""""
",1
"    )
",1
"    parser.add(
",1
"        ""--config3"",
",1
"    )
",1
"        help=""Batch size for beam search (0: means no batch processing)"",
",1
"        choices=[""v1"", ""v2""],
        help=""Beam search APIs ""
        ""v1: Default API. ""
",1
"    # model (parameter) related
    parser.add_argument(
        ""--model"", type=str, required=True, help=""Model file parameters to read""
    )
",1
"    )
    parser.add_argument(
",1
"        ""--minlenratio"",
        type=float,
        default=0.0,
        help=""Input length ratio to obtain min output length"",
    )
",1
"    elif args.verbose == 2:
        logging.basicConfig(
",1
"            level=logging.DEBUG,
",1
"            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"            level=logging.WARN,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
        )
",1
"        logging.warning(""Skip DEBUG/INFO messages"")

    # check CUDA_VISIBLE_DEVICES
    if args.ngpu > 0:
        cvd = os.environ.get(""CUDA_VISIBLE_DEVICES"")
",1
"    # trans
    logging.info(""backend = "" + args.backend)
    if args.backend == ""pytorch"":
",1
"
import configargparse
import logging
import os
import platform
",1
"    )
    parser.add_argument(
",1
"    )
    parser.add_argument(
        ""--minlenratio"", type=float, default=0, help=""Minimum length ratio in decoding""
    )
    parser.add_argument(
",1
"        default=1,
        help=""Backward window size in the attention constraint"",
    )
    parser.add_argument(
        ""--forward-window"",
",1
"        type=strtobool,
",1
"        # python 3 case
        else:
            if ""clsp.jhu.edu"" in subprocess.check_output([""hostname"", ""-f""]).decode():
                cvd = (
",1
"                    )
                    .decode()
",1
"

if __name__ == ""__main__"":
    main(sys.argv[1:])
",1
"    parser.add(
",1
"    parser.add_argument(""--debugmode"", default=1, type=int, help=""Debugmode"")
    parser.add_argument(""--dict"", required=required, help=""Dictionary"")
    parser.add_argument(""--seed"", default=1, type=int, help=""Random seed"")
",1
"    parser.add_argument(
",1
"    )
",1
"    )
    parser.add_argument(
        ""--mtlalpha"",
        default=0.0,
        type=float,
",1
"        type=float,
        help=""Multitask learning coefficient for ASR task, weight: ""
",1
"    parser.add_argument(""--nbest"", type=int, default=1, help=""Output N-best hypotheses"")
    parser.add_argument(""--beam-size"", type=int, default=4, help=""Beam size"")
    parser.add_argument(""--penalty"", default=0.0, type=float, help=""Incertion penalty"")
",1
"    parser.add_argument(
        ""--rnnlm-conf"", type=str, default=None, help=""RNNLM model config file to read""
    )
    parser.add_argument(""--lm-weight"", default=0.0, type=float, help=""RNNLM weight."")
    parser.add_argument(""--sym-space"", default=""<space>"", type=str, help=""Space symbol"")
",1
"        default=0,
        type=int,
        nargs=""?"",
",1
"        help=""How many epochs to use sortagrad for. 0 = deactivated, -1 = all epochs"",
    )
",1
"        type=int,
        help=""Maximum output frames in a minibatch (0 to disable)"",
    )
",1
"        type=int,
        metavar=""ML"",
        help=""When --batch-count=seq, batch size is reduced ""
        ""if the input sequence length > ML."",
    )
",1
"        type=int,
",1
"        metavar=""ML"",
        help=""When --batch-count=seq, ""
        ""batch size is reduced if the output sequence length > ML"",
    )
",1
"    )
    parser.add_argument(
        ""--lr"", default=1e-3, type=float, help=""Learning rate for optimizer""
",1
"    )
",1
"    )
",1
"    parser.add_argument(
",1
"        ""--patience"",
        default=3,
        type=int,
",1
"        default=False,
        type=strtobool,
        nargs=""?"",
",1
"        help=""List of encoder modules to initialize, separated by a comma."",
    )
",1
"        default=None,
        type=str,
",1
"    )
    parser.add_argument(
        ""--n-mels"", type=int, default=80, help=""The number of mel-frequency bins.""
    )
    parser.add_argument(""--fbank-fmin"", type=float, default=0.0, help="""")
",1
"        model_module = args.model_module
    model_class = dynamic_import(model_module)
    model_class.add_arguments(parser)

",1
"
    # If --ngpu is not given,
    #   1. if CUDA_VISIBLE_DEVICES is set, all visible devices
",1
"                ngpu = len(p.stderr.decode().split(""\n"")) - 1
        args.ngpu = ngpu
",1
"        char_list.append(""<eos>"")
",1
"        args.char_list = None

    # train
    logging.info(""backend = "" + args.backend)
",1
"
",1
"import os
import random
import subprocess
import sys
",1
"            description=""Train an automatic speech recognition (ASR) model on one CPU, ""
            ""one or multiple GPUs"",
            config_file_parser_class=configargparse.YAMLConfigFileParser,
            formatter_class=configargparse.ArgumentDefaultsHelpFormatter,
",1
"    parser.add(
",1
"        default=""float32"",
        choices=[""float16"", ""float32"", ""float64"", ""O0"", ""O1"", ""O2"", ""O3""],
",1
"        help=""Data type for training (only pytorch backend). ""
        ""O0,O1,.. flags require apex. ""
",1
"        type=str,
",1
"        type=int,
        help=""Save snapshot interval iterations"",
",1
"    )
    parser.add_argument(""--nbest"", type=int, default=1, help=""Output N-best hypotheses"")
    parser.add_argument(""--beam-size"", type=int, default=4, help=""Beam size"")
",1
"    parser.add_argument(
",1
"    parser.add_argument(
",1
"        choices=BATCH_COUNT_CHOICES,
        help=""How to count batch_size. ""
        ""The default (auto) will find how to count by args."",
    )
    parser.add_argument(
",1
"        type=int,
        help=""Maximum bins in a minibatch (0 to disable)"",
    )
",1
"    )
    parser.add_argument(
        ""--early-stop-criterion"",
        default=""validation/main/acc"",
        type=str,
",1
"        ""--grad-clip"", default=5, type=float, help=""Gradient norm threshold to clip""
    )
    parser.add_argument(
        ""--num-save-attention"",
        default=3,
",1
"    parser.add_argument(
        ""--grad-noise"",
        type=strtobool,
        default=False,
        help=""The flag to switch to use noise injection to gradients during training"",
",1
"        help=""Apply Weighted Prediction Error"",
    )
    parser.add_argument(
        ""--wtype"",
",1
"            ""grup"",
            ""bgrup"",
",1
"    parser.add_argument(""--wunits"", type=int, default=300, help="""")
    parser.add_argument(""--wprojs"", type=int, default=300, help="""")
    parser.add_argument(""--wdropout-rate"", type=float, default=0.0, help="""")
",1
"    parser.add_argument(""--wpe-delay"", type=int, default=3, help="""")
",1
"        ],
        help=""Type of encoder network architecture ""
        ""of the mask estimator for Beamformer."",
    )
    parser.add_argument(""--blayers"", type=int, default=2, help="""")
",1
"    parser.add_argument(""--bunits"", type=int, default=300, help="""")
    parser.add_argument(""--bprojs"", type=int, default=300, help="""")
    parser.add_argument(""--badim"", type=int, default=320, help="""")
    parser.add_argument(
",1
"        help=""The stats file for the feature normalization"",
    )
    parser.add_argument(
        ""--apply-uttmvn"",
",1
"        type=strtobool,
        default=True,
",1
"    parser.add_argument(""--fbank-fmin"", type=float, default=0.0, help="""")
    parser.add_argument(""--fbank-fmax"", type=float, default=None, help="""")
",1
"        if is_torch_1_2_plus and args.ngpu != 1:
",1
"                ""There are some bugs with multi-GPU processing in PyTorch 1.2+""
                + "" (see https://github.com/pytorch/pytorch/issues/21108)""
            )
        ngpu = args.ngpu
    logging.info(f""ngpu: {ngpu}"")
",1
"
",1
"    else:
",1
"
if __name__ == ""__main__"":
",1
"        is_config_file=True,
",1
"        help=""third config file path that overwrites ""
",1
"        ""--ngpu"",
",1
"        default=None,
",1
"        default=None,
        type=str,
",1
"    parser.add_argument(
        ""--valid-json"", type=str, required=True, help=""Filename of validation json""
    )
    # network architecture
    parser.add_argument(
",1
"    parser.add_argument(
",1
"        ""--use-speaker-embedding"",
        default=False,
        type=strtobool,
        help=""Whether to use speaker embedding"",
",1
"    )
    parser.add_argument(
        ""--patience"",
        default=3,
        type=int,
",1
"        help=""Number of epochs to wait ""
        ""without improvement before stopping the training"",
",1
"        type=strtobool,
        help=""Whether to keep all data on memory"",
",1
"        default=None,
",1
"        type=str,
        help=""Pre-trained TTS model path to initialize encoder."",
    )
",1
"        default=None,
        type=str,
        help=""Pre-trained TTS model path to initialize decoder."",
    )
    parser.add_argument(
",1
"        help=""List of modules to freeze (not to train), separated by a comma."",
    )

    return parser
",1
"    parser = get_parser()
    args, _ = parser.parse_known_args(cmd_args)

",1
"    if args.backend == ""pytorch"":
        from espnet.tts.pytorch_backend.tts import train

        train(args)
    else:
",1
"

if __name__ == ""__main__"":
    main(sys.argv[1:])
#!/usr/bin/env python3
",1
"import configargparse
from distutils.util import strtobool
import logging
import os
import random
",1
"        ""--enh-wspecifier"",
        type=str,
        default=None,
        help=""Specify the output way for enhanced speech.""
",1
"        default=""hann"",
",1
"    )
    return parser
",1
"            logging.error(""#gpus is not matched with CUDA_VISIBLE_DEVICES."")
            sys.exit(1)
",1
"    parser.add(
",1
"        help=""Backend library"",
    )
    parser.add_argument(""--debugmode"", type=int, default=1, help=""Debugmode"")
    parser.add_argument(""--seed"", type=int, default=1, help=""Random seed"")
",1
"        ""--preprocess-conf"",
        type=str,
        default=None,
        help=""The configuration file for the pre-processing"",
    )
",1
"    parser.add_argument(
        ""--result-label"",
        type=str,
        required=True,
        help=""Filename of result label data (json)"",
",1
"    )
    # model (parameter) related
    parser.add_argument(
        ""--model"", type=str, required=True, help=""Model file parameters to read""
",1
"    parser.add_argument(
        ""--num-encs"", default=1, type=int, help=""Number of encoders in the model.""
    )
    # search related
",1
"        default=0.0,
        help=""""""Input length ratio to obtain max output length.
                        If maxlenratio=0.0 (default), it uses a end-detect function
",1
"                        to automatically find maximum hypothesis lengths"""""",
    )
",1
"        type=float,
",1
"        ""--ctc-weight"", type=float, default=0.0, help=""CTC weight in joint decoding""
    )
",1
"        action=""append"",
        help=""ctc weight assigned to each encoder during decoding.""
        ""[in multi-encoder mode only]"",
    )
",1
"        default=0,
        help=""""""Use CTC window with margin parameter to accelerate
                        CTC/attention decoding especially on GPU. Smaller magin
                        makes decoding faster, but may increase search errors.
",1
"        ""--rnnlm"", type=str, default=None, help=""RNNLM model file to read""
",1
"        ""--rnnlm-conf"", type=str, default=None, help=""RNNLM model config file to read""
    )
    parser.add_argument(
",1
"        ""--word-rnnlm"", type=str, default=None, help=""Word RNNLM model file to read""
    )
",1
"        default=None,
        help=""Word RNNLM model config file to read"",
    )
    parser.add_argument(""--word-dict"", type=str, default=None, help=""Word list to read"")
",1
"    parser.add_argument(
        ""--streaming-min-blank-dur"",
        type=int,
        default=10,
",1
"        logging.basicConfig(
            level=logging.DEBUG,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"        logging.warning(""Skip DEBUG/INFO messages"")

    # check CUDA_VISIBLE_DEVICES
    if args.ngpu > 0:
        cvd = os.environ.get(""CUDA_VISIBLE_DEVICES"")
",1
"        if args.ngpu > 1:
            logging.error(""The program only supports ngpu=1."")
            sys.exit(1)
",1
"                        raise NotImplementedError(
                            f""`--dtype {args.dtype}` is only available with `--api v2`""
                        )
                    recog(args)
            else:
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Neural machine translation model training script.""""""

",1
"
# NOTE: you need this func to generate our sphinx doc
",1
"        is_config_file=True,
",1
"    parser.add_argument(
        ""--backend"",
        default=""chainer"",
        type=str,
        choices=[""chainer"", ""pytorch""],
",1
"        help=""Backend library"",
",1
"    )
    parser.add_argument(
        ""--report-interval-iters"",
        default=100,
        type=int,
",1
"        type=int,
        help=""Save snapshot interval iterations"",
    )
    # task related
    parser.add_argument(
",1
"    )
    parser.add_argument(""--nbest"", type=int, default=1, help=""Output N-best hypotheses"")
    parser.add_argument(""--beam-size"", type=int, default=4, help=""Beam size"")
",1
"        nargs=""?"",
        help=""How many epochs to use sortagrad for. 0 = deactivated, -1 = all epochs"",
    )
    parser.add_argument(
",1
"    parser.add_argument(
        ""--batch-frames-out"",
        default=0,
        type=int,
        help=""Maximum output frames in a minibatch (0 to disable)"",
",1
"        type=int,
        help=""Number of processes of iterator"",
    )
",1
"    # optimization related
",1
"        help=""Optimizer"",
    )
    parser.add_argument(
        ""--accum-grad"", default=1, type=int, help=""Number of gradient accumuration""
    )
",1
"        default=""acc"",
        type=str,
",1
"        ""--threshold"", default=1e-4, type=float, help=""Threshold to stop iteration""
    )
    parser.add_argument(
",1
"        ""--epochs"", ""-e"", default=30, type=int, help=""Maximum number of epochs""
    )
    parser.add_argument(
",1
"    parser.add_argument(
        ""--patience"",
        default=3,
        type=int,
        nargs=""?"",
",1
"        help=""Number of epochs to wait ""
",1
"    )
    # finetuning related
    parser.add_argument(
        ""--enc-init"",
",1
"    parser.add_argument(
        ""--enc-init-mods"",
",1
"        help=""Pre-trained ASR, MT or LM model to initialize decoder."",
    )
",1
"        default=False,
        type=strtobool,
        help=""Prepend target language ID to the source sentence. ""
        ""Both source/target language IDs must be prepend in the pre-processing stage."",
    )
",1
"    parser.add_argument(
        ""--replace-sos"",
        default=False,
        type=strtobool,
        help=""Replace <sos> in the decoder with a target language ID ""
",1
"    parser = get_parser()
",1
"            f""--train-dtype {args.train_dtype} does not support the CPU backend.""
        )
",1
"
    from espnet.utils.dynamic_import import dynamic_import

    if args.model_module is None:
",1
"        raise ValueError(""Only pytorch are supported."")

",1
"from espnet.nets.lm_interface import dynamic_import_lm
",1
"from espnet.scheduler.scheduler import dynamic_import_scheduler


",1
"    )
    # training configuration
",1
"    parser.add_argument(""--opt"", default=""sgd"", type=str, help=""Optimizer"")
    parser.add_argument(
        ""--sortagrad"",
",1
"    )
    parser.add_argument(
        ""--maxlen"",
",1
"        type=int,
        default=40,
        help=""Batch size is reduced if the input sequence > ML"",
",1
"            scheduler_class.add_arguments(k, parser)

    opt_class = dynamic_import_optimizer(args.opt, args.backend)
    opt_class.add_arguments(parser)

",1
"    if args.verbose > 0:
        logging.basicConfig(
            level=logging.INFO,
            format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
",1
"            try:
",1
"        ngpu = args.ngpu
    logging.info(f""ngpu: {ngpu}"")
",1
"    # seed setting
",1
"        from espnet.lm.chainer_backend.lm import train

        train(args)
    elif args.backend == ""pytorch"":
        from espnet.lm.pytorch_backend.lm import train
",1
"# -*- coding: utf-8 -*-

# Copyright 2018 Nagoya University (Tomoki Hayashi)
",1
"import numpy as np
import torch

from chainer import training
from chainer.training import extensions
",1
"from espnet.asr.asr_utils import torch_snapshot
from espnet.asr.pytorch_backend.asr_init import load_trained_modules
from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"from espnet.utils.training.iterators import ShufflingEnabler

",1
"        with torch.no_grad():
            for batch in it:
                if isinstance(batch, tuple):
",1
"                        self.model(*x)
                    else:
                        self.model(**x)
                summary.add(observation)
",1
"        self.model.train()

        return summary.compute_mean()


",1
"
        Args:
            model (torch.nn.Module) model: Pytorch model instance.
            grad_clip (float) grad_clip : The gradient clipping value.
",1
"            iterator (chainer.dataset.Iterator): Iterator for training.
            optimizer (torch.optim.Optimizer) : Pytorch optimizer instance.
",1
"            device (torch.device): The device to be used in training.
",1
"        """"""
        super(CustomUpdater, self).__init__(iterator, optimizer)
        self.model = model
",1
"            x = batch
            for key in x.keys():
                x[key] = x[key].to(self.device)

",1
"            logging.warning(""grad norm is nan. Do not update model."")
        else:
            optimizer.step()
        optimizer.zero_grad()

",1
"
",1
"    """"""Custom converter.""""""

    def __init__(self):
        """"""Initilize module.""""""
        # NOTE: keep as class for future development
",1
"                          [np.random.randn(8, 2), np.random.randn(4, 2)],
                          None, None)]
",1
"                            [-1.2181, -0.5918],
",1
"        # get list of lengths (must be tensor for DataParallel)
",1
"
",1
"        if extras is not None:
            extras = pad_list([torch.from_numpy(extra).float() for extra in extras], 0)
            new_batch[""extras""] = extras.to(device)

        return new_batch
",1
"        args.spk_embed_dim = None
",1
"    # write model config
    if not os.path.exists(args.outdir):
        os.makedirs(args.outdir)
    model_conf = args.outdir + ""/model.json""
    with open(model_conf, ""wb"") as f:
",1
"        logging.info(""writing a model config file to"" + model_conf)
        f.write(
            json.dumps(
",1
"            ).encode(""utf_8"")
        )
    for key in sorted(vars(args).keys()):
",1
"
    # read json data
    with open(args.train_json, ""rb"") as f:
        train_json = json.load(f)[""utts""]
    with open(args.valid_json, ""rb"") as f:
",1
"        train_json,
        args.batch_size,
        args.maxlen_in,
",1
"        batch_frames_out=args.batch_frames_out,
",1
"                valid_batchset, lambda data: converter([load_cv(data)])
            ),
            batch_size=1,
",1
"    save_interval = (args.save_interval_epochs, ""epoch"")
    report_interval = (args.report_interval_iters, ""iteration"")
",1
"
    # Save attention figure for each epoch
    if args.num_save_attention > 0:
",1
"            reduction_factor = model.module.reduction_factor
        else:
            att_vis_fn = model.calculate_all_attentions
            plot_class = model.attention_plot_class
            reduction_factor = model.reduction_factor
",1
"            data,
",1
"            device=device,
            reverse=True,
        )
        trainer.extend(att_reporter, trigger=eval_interval)
    else:
",1
"        extensions.PlotReport(plot_keys, ""epoch"", file_name=""all_loss.png""),
        trigger=eval_interval,
",1
"    )

    # Write a log of evaluation statistics for each epoch
    trainer.extend(extensions.LogReport(trigger=report_interval))
    report_keys = [""epoch"", ""iteration"", ""elapsed_time""] + plot_keys
",1
"    trainer.extend(extensions.PrintReport(report_keys), trigger=report_interval)
    trainer.extend(extensions.ProgressBar(), trigger=report_interval)

    set_early_stop(trainer, args)
",1
"    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
        writer = SummaryWriter(args.tensorboard_dir)
",1
"    set_deterministic_pytorch(args)
    # read training config
    idim, odim, train_args = get_model_conf(args.model, args.model_conf)

",1
"    # show arguments
    for key in sorted(vars(args).keys()):
",1
"    # set torch device
",1
"        preprocess_conf=train_args.preprocess_conf
        if args.preprocess_conf is None
        else args.preprocess_conf,
        preprocess_args={""train"": False},  # Switch the mode of preprocessing
    )
",1
"            # whose shape is (#leyers, #heads, out_length, in_length)
            plt.figure(figsize=(figsize[0] * shape[0], figsize[1] * shape[1]), dpi=dpi)
            for idx1, xs in enumerate(array):
",1
"                    plt.subplot(shape[0], shape[1], idx1 * shape[1] + idx2)
                    plt.imshow(x, aspect=""auto"")
                    plt.xlabel(""Input"")
                    plt.ylabel(""Output"")
",1
"        if len(att_ws.shape) == 2:
            # tacotron 2 case -> (L, T)
            pass
        elif len(att_ws.shape) == 4:
            # transformer case -> (#layers, #heads, L, T)
",1
"            diagonal_scores = att_ws.max(dim=-1)[0].mean(dim=-1)  # (#heads * #layers,)
            diagonal_head_idx = diagonal_scores.argmax()
            att_ws = att_ws[diagonal_head_idx]  # (L, T)
        else:
",1
"        )
    if args.save_focus_rates:
        fr_writer = kaldiio.WriteHelper(
            ""ark,scp:{o}.ark,{o}.scp"".format(o=args.out.replace(""feats"", ""focus_rates""))
        )
",1
"        label_dict (dict[str, int]):
            dictionary that maps token label string to its ID number
        outdir (str): The path of an output dir

    Returns:
",1
"        logging.info(""skip dump/load HDF5 because the output dir is not specified"")
",1
"        with h5py.File(filename, ""w"") as f:
",1
"            # http://docs.h5py.org/en/stable/special.html#arbitrary-vlen-data
            data = f.create_dataset(
",1
"    n_tokens = 0
",1
"            n_oovs += np.count_nonzero(sentence == unk_id)
    return n_tokens, n_oovs

",1
"       Sentence batches are made in order of longer sentences, and then
       randomly shuffled.
",1
"        self.batch_size = batch_size  # batch size
        # Number of completed sweeps over the dataset. In this case, it is
",1
"        # incremented if every word is visited at least once after the last
        # increment.
        self.epoch = 0
        # True if the epoch is incremented at the last iteration.
        self.is_new_epoch = False
",1
"        if batch_size > 1:
            indices = sorted(range(len(dataset)), key=lambda i: -len(dataset[i]))
            bs = 0
            while bs < length:
",1
"                # is larger than max_length
                if max_length > 0:
                    sent_length = len(dataset[indices[bs]])
",1
"                    be = min(
",1
"            if shuffle:
                # shuffle batches
                random.shuffle(self.batch_indices)
        else:
",1
"            self._previous_epoch_detail = self.epoch + (
",1
"    """"""Extension that makes a symbolic link to the best model

",1
"            self.min_loss = serializer(""_min_loss"", 0.0)
            self.key = serializer(""_key"", """")
            self.prefix = serializer(""_prefix"", ""model"")
            self.suffix = serializer(""_suffix"", ""best"")
",1
"from chainer import training
",1
"from espnet.scheduler.chainer import ChainerScheduler
from espnet.scheduler.scheduler import dynamic_import_scheduler

",1
"    Args:
        n_vocab (int): The size of the vocabulary
",1
"
    :param link.Chain predictor : The RNNLM
    :param function lossfun: The loss function to use
",1
"                raise ValueError(msg)
",1
"            t = args[self.label_key]
",1
"        self.y = None
",1
"            return state, F.log_softmax(z).data

    def final(self, state):
        """"""Predict final log probabilities for given state using the predictor
",1
"
        """"""
        if hasattr(self.predictor, ""final""):
            return self.predictor.final(state)
        else:
",1
"
# Definition of a recurrent net for language modeling
class RNNLM(chainer.Chain):
    """"""A chainer RNNLM
",1
"    """"""
",1
"                else chainer.ChainList(
                    *[L.StatelessGRU(n_units, n_units) for _ in range(n_layers)]
",1
"class BPTTUpdater(training.updaters.StandardUpdater):
    """"""An updater for a chainer LM

    :param chainer.dataset.Iterator train_iter : The train iterator
",1
"            # self.converter does this job
            # (it is chainer.dataset.concat_examples by default)
            xp = chainer.backends.cuda.get_array_module(x)
            loss = 0
",1
"            state = None
",1
"        reporter.report({""loss"": sum_loss}, optimizer.target)
        reporter.report({""count"": count}, optimizer.target)
",1
"                non_zeros = xp.count_nonzero(x[:, i])
                loss += loss_batch.data * non_zeros
                count += int(non_zeros)
        # report validation loss
        observation = {}
",1
"    val = read_tokens(args.valid_label, args.char_list_dict)
    # count tokens
    n_train_tokens, n_train_oovs = count_tokens(train, unk)
",1
"    val_iter = ParallelSentenceIterator(
",1
"        logging.warning(""currently, multi-gpu is not supported. use single gpu."")
    if args.ngpu > 0:
        # Make the specified GPU current
",1
"
    # Save model conf to json
    model_conf = args.outdir + ""/model.json""
    with open(model_conf, ""wb"") as f:
        logging.info(""writing a model config file to "" + model_conf)
",1
"            postprocess=compute_perplexity,
            trigger=(args.report_interval_iters, ""iteration""),
        )
",1
"    )
    trainer.extend(
        extensions.PrintReport(
",1
"import chainer
import chainer.functions as F
from espnet.lm.lm_utils import make_lexical_tree

",1
"
# Definition of a multi-level (subword/word) language model
class MultiLevelLM(chainer.Chain):
    logzero = -10000000000.0
    zero = 1.0e-10
",1
"    ):
",1
"        super(MultiLevelLM, self).__init__()
",1
"                # update wordlm state and log-prob vector
                wlm_state, z_wlm = self.wordlm(wlm_state, w)
                wlm_logprobs = F.log_softmax(z_wlm).data
                new_node = self.lexroot  # move to the tree root
                clm_logprob = 0.0
",1
"        if xi != self.space:
            if new_node is not None and new_node[1] >= 0:  # if new node is word end
",1
"    def final(self, state):
        clm_state, wlm_state, wlm_logprobs, node, log_y, clm_logprob = state
        if node is not None and node[1] >= 0:  # check if the node is word end
",1
"            xi = self.space
        else:
            wlm_state, cumsum_probs, node = state
            xi = int(x)
",1
"                if wids is not None
",1
"            y = self.xp.full(
                (1, self.subword_dict_size), unk_prob * self.oov_penalty, ""f""
",1
"        else:  # this node is not a word end, which means <unk>
            w = self.xp_word_unk
        wlm_state, z_wlm = self.wordlm(wlm_state, w)
        return F.log_softmax(z_wlm).data[:, self.word_eos]
#!/usr/bin/env python3
",1
"
""""""LM training in pytorch.""""""

",1
"import numpy as np

import torch
",1
"from espnet.utils.training.tensorboard_logger import TensorboardLogger
from tensorboardX import SummaryWriter

",1
"
",1
"    # Routine to rewrite the result dictionary of LogReport to add perplexity values
    result[""perplexity""] = np.exp(result[""main/nll""] / result[""main/count""])
    if ""validation/main/nll"" in result:
        result[""val_perplexity""] = np.exp(
            result[""validation/main/nll""] / result[""validation/main/count""]
",1
"        self,
        train_iter,
        model,
        optimizer,
",1
"        Args:
            train_iter (chainer.dataset.Iterator): The train iterator
            model (LMInterface) : The model to update
            optimizer (torch.optim.Optimizer): The optimizer for training
            schedulers (espnet.scheduler.scheduler.SchedulerInterface):
",1
"                The schedulers of `optimizer`
            device (int): The device id
            gradclip (float): The gradient clipping value to use
            use_apex (bool): The flag to use Apex in backprop.
",1
"        self.device = device
",1
"            # backward
            loss = loss.mean() / self.accum_grad
            if self.use_apex:
                from apex import amp
",1
"        for k, v in accum.items():
            reporter.report({k: v}, optimizer.target)
        if self.gradclip is not None:
",1
"    """"""A custom evaluator for a pytorch LM.""""""

    def __init__(self, val_iter, eval_model, reporter, device):
        """"""Initialize class.

",1
"        # report validation loss
        observation = {}
        with reporter.report_scope(observation):
",1
"        return observation


def train(args):
",1
"    eos = args.char_list_dict[""<eos>""]
    # read tokens as a sequence of sentences
    val, n_val_tokens, n_val_oovs = load_dataset(
        args.valid_label, args.char_list_dict, args.dump_hdf5_path
    )
",1
"    logging.info(""#vocab = "" + str(args.n_vocab))
    logging.info(""#sentences in the training data = "" + str(len(train)))
    logging.info(""#tokens in the training data = "" + str(n_train_tokens))
    logging.info(
",1
"        ""oov rate in the training data = %.2f %%""
        % (n_train_oovs / n_train_tokens * 100)
    )
    logging.info(""#sentences in the validation data = "" + str(len(val)))
    logging.info(""#tokens in the validation data = "" + str(n_val_tokens))
",1
"
    # Set up an optimizer
    opt_class = dynamic_import_optimizer(args.opt, args.backend)
    optimizer = opt_class.from_args(model.parameters(), args)
    if args.schedulers is None:
",1
"    # setup apex.amp
    if args.train_dtype in (""O0"", ""O1"", ""O2"", ""O3""):
",1
"        use_apex = False

    # FIXME: TOO DIRTY HACK
    reporter = Reporter()
    setattr(model, ""reporter"", reporter)
",1
"
    updater = BPTTUpdater(
        train_iter,
",1
"            postprocess=compute_perplexity,
            trigger=(args.report_interval_iters, ""iteration""),
",1
"        trigger=(args.report_interval_iters, ""iteration""),
",1
"    )
    trainer.extend(extensions.ProgressBar(update_interval=args.report_interval_iters))
    # Save best models
    trainer.extend(torch_snapshot(filename=""snapshot.ep.{.updater.epoch}""))
",1
"    if args.tensorboard_dir is not None and args.tensorboard_dir != """":
",1
"        writer = SummaryWriter(args.tensorboard_dir)
        trainer.extend(
            TensorboardLogger(writer), trigger=(args.report_interval_iters, ""iteration"")
",1
"    trainer.run()
    check_early_stop(trainer, args.epoch)
",1
"        logging.info(""test the best model"")
",1
"        logging.info(""#sentences in the test data = "" + str(len(test)))
        logging.info(""#tokens in the test data = "" + str(n_test_tokens))
        logging.info(
            ""oov rate in the test data = %.2f %%"" % (n_test_oovs / n_test_tokens * 100)
",1
"        )
        test_iter = ParallelSentenceIterator(
            test, batch_size, max_length=args.maxlen, sos=eos, eos=eos, repeat=False
        )
        evaluator = LMEvaluator(test_iter, model, reporter, device=gpu_id)
",1
"
# Copyright 2018 Mitsubishi Electric Research Laboratories (Takaaki Hori)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

from __future__ import division
",1
"from __future__ import print_function
",1
"
import math

import torch
",1
"    zero = 1.0e-10

    def __init__(
        self,
        wordlm,
",1
"        self.eos = subword_dict[""<eos>""]
        self.lexroot = make_lexical_tree(word_dict, subword_dict, self.word_unk)
        self.log_oov_penalty = math.log(oov_penalty)
        self.open_vocab = open_vocab
",1
"        if state is None:  # make initial states and log-prob vectors
            self.var_word_eos = to_device(self, self.var_word_eos)
            self.var_word_unk = to_device(self, self.var_word_eos)
",1
"            wlm_state, z_wlm = self.wordlm(None, self.var_word_eos)
            wlm_logprobs = F.log_softmax(z_wlm, dim=1)
",1
"            log_y = F.log_softmax(z_clm, dim=1) * self.subwordlm_weight
            new_node = self.lexroot
            clm_logprob = 0.0
            xi = self.space
",1
"                # update wordlm state and log-prob vector
                wlm_state, z_wlm = self.wordlm(wlm_state, w)
                wlm_logprobs = F.log_softmax(z_wlm, dim=1)
",1
"
        # apply word-level probabilies for <space> and <eos> labels
",1
"        self.eos = subword_dict[""<eos>""]
        self.lexroot = make_lexical_tree(word_dict, subword_dict, self.word_unk)
",1
"        self.oov_penalty = oov_penalty
        self.open_vocab = open_vocab
",1
"            self.var_word_unk = to_device(self, self.var_word_eos)
            self.zero_tensor = to_device(self, self.zero_tensor)
",1
"            new_node = self.lexroot
            xi = self.space
        else:
",1
"            wlm_state, cumsum_probs, node = state
            xi = int(x)
            if xi == self.space:  # inter-word transition
                if node is not None and node[1] >= 0:  # check if the node is word end
",1
"                new_node = None
",1
"                    self, torch.full((1, self.subword_dict_size), self.logzero)
",1
"                (cumsum_probs[:, wids[1]] - cumsum_probs[:, wids[0]])
                if wids is not None
                else 1.0
",1
"                return (wlm_state, cumsum_probs, new_node), log_y
            # set <unk> probability as a default value
            unk_prob = (
                cumsum_probs[:, self.word_unk] - cumsum_probs[:, self.word_unk - 1]
            )
",1
"                y[:, self.space] = wlm_prob
                y[:, self.eos] = wlm_prob
            elif xi == self.space:
",1
"        return float(F.log_softmax(z_wlm, dim=1)[:, self.word_eos])
",1
"        """"""Return enhanced
",1
"
",1
"            psd_context=self.psd_context,
",1
"            statistics_mode=self.statistics_mode,
        )
",1
"        return xs.transpose(2, 1, 0)
import numpy

",1
"    def __repr__(self):
        return (
            ""{name}(train_channel={train_channel}, ""
            ""eval_channel={eval_channel}, axis={axis})"".format(
",1
"            )
",1
"    """"""Transform Interface""""""

",1
"class Identity(TransformInterface):
    """"""Identity Function""""""
",1
"                win_length=win_length,
",1
"                center=center,
            )
            for ch in range(x.shape[1])
        ],
",1
"
def stft2logmelspectrogram(x_stft, fs, n_mels, n_fft, fmin=None, fmax=None, eps=1e-10):
",1
"

def spectrogram(x, n_fft, n_shift, win_length=None, window=""hann""):
    # x: (Time, Channel) -> spc: (Time, Channel, Freq)
    spc = np.abs(stft(x, n_fft, n_shift, win_length, window=window))
",1
"    return spc


def logmelspectrogram(
    x,
",1
"    eps=1e-10,
    pad_mode=""reflect"",
):
    # stft: (Time, Channel, Freq) or (Time, Freq)
    x_stft = stft(
",1
"        pad_mode=pad_mode,
    )
",1
"        )

    def __call__(self, x):
        return spectrogram(
",1
"            ""n_shift={n_shift}, win_length={win_length}, window={window}, ""
            ""fmin={fmin}, fmax={fmax}, eps={eps}))"".format(
                name=self.__class__.__name__,
                fs=self.fs,
                n_mels=self.n_mels,
",1
"        self.fmin = fmin
        self.fmax = fmax
",1
"        self.win_length = win_length
        self.window = window
        self.center = center
        self.pad_mode = pad_mode
",1
"        return (
            ""{name}(n_fft={n_fft}, n_shift={n_shift}, ""
            ""win_length={win_length}, window={window},""
            ""center={center}, pad_mode={pad_mode})"".format(
",1
"                name=self.__class__.__name__,
                n_fft=self.n_fft,
                n_shift=self.n_shift,
                win_length=self.win_length,
",1
"            self.n_shift,
            win_length=self.win_length,
            window=self.window,
            center=self.center,
",1
"            pad_mode=self.pad_mode,
        )
",1
"
",1
"
class IStft(object):
    def __init__(self, n_shift, win_length=None, window=""hann"", center=True):
",1
"        self.center = center

    def __repr__(self):
        return (
",1
"                win_length=self.win_length,
",1
"            win_length=self.win_length,
            window=self.window,
            center=self.center,
        )
",1
"""""""Spec Augment module for preprocessing i.e., data augmentation""""""

import random
",1
"from espnet.transform.functional import FuncTrans


def time_warp(x, max_time_warp=80, inplace=False, mode=""PIL""):
    """"""time warp for spec augment
",1
"    if mode == ""PIL"":
        t = x.shape[0]
",1
"        if t - window <= window:
            return x
",1
"        return spec_augment.time_warp(torch.from_numpy(x), window).numpy()
    else:
        raise NotImplementedError(
",1
"    for f, mask_end in fs:
        f_zero = random.randrange(0, num_mel_channels - f)
        mask_end += f_zero
",1
"            continue

        if replace_with_zero:
",1
"        t_zero = random.randrange(0, len_spectro - t)
",1
"            cloned[t_zero:mask_end] = cloned.mean()
    return cloned
",1
"    _func = time_mask
    __doc__ = time_mask.__doc__

    def __call__(self, x, train):
        if not train:
",1
"    :param bool replace_with_zero: pad zero on mask if true else use mean
    """"""
    assert isinstance(x, numpy.ndarray)
    assert x.ndim == 2
    x = time_warp(x, max_time_warp, inplace=inplace, mode=resize_mode)
",1
"        n_freq_mask,
        inplace=inplace,
        replace_with_zero=replace_with_zero,
",1
"    )
    x = time_mask(
",1
"import io
import logging
",1
"else:
    # The ABCs from 'collections' will stop working in 3.8
",1
"    from inspect import signature


# TODO(karita): inherit TransformInterface
",1
"    fbank=""espnet.transform.spectrogram:LogMelSpectrogram"",
    spectrogram=""espnet.transform.spectrogram:Spectrogram"",
    stft=""espnet.transform.spectrogram:Stft"",
    istft=""espnet.transform.spectrogram:IStft"",
",1
"    Examples:
        >>> kwargs = {""process"": [{""type"": ""fbank"",
        ...                        ""n_mels"": 80,
",1
"        if conffile is not None:
",1
"            if isinstance(conffile, dict):
                self.conf = copy.deepcopy(conffile)
            else:
                with io.open(conffile, encoding=""utf-8"") as f:
",1
"                    self.functions[idx] = class_obj(**opts)
                except TypeError:
",1
"        rep = ""\n"" + ""\n"".join(
",1
"
",1
"            self.bias[spk] = -mean
            self.scale[spk] = 1 / std

",1
"                x = np.add(x, self.bias[spk])
            if self.norm_vars:
                x = np.multiply(x, self.scale[spk])

        else:
",1
"            if self.norm_vars:
                x = np.divide(x, self.scale[spk])
",1
"                x = np.subtract(x, self.bias[spk])
",1
"        return x
""""""Initialize main package.""""""
import librosa
import numpy
",1
"import scipy
import soundfile

",1
"        seed=None,
",1
"
        if utt2ratio is not None:
            self.utt2ratio = {}
            # Use the scheduled ratio for each utterances
",1
"        x = x.astype(numpy.float32)
        if self.accept_uttid:
            ratio = self.utt2ratio[uttid]
        else:
",1
"                # Truncate noise
",1
"                )
",1
"        ""randomly-selected frequency band was cut off under the constraint of
         leaving at least 1,000 Hz band within the range of less than 4,000Hz.""
        (The Hitachi/JHU CHiME-5 system: Advances in speech recognition for
         everyday home environments using multiple microphone arrays;
",1
"        if not train:
",1
"            return x_stft

",1
"        self.state = numpy.random.RandomState(seed)

        if utt2ratio is not None:
            # Use the scheduled ratio for each utterances
            self.utt2ratio = {}
",1
"            self.lower = None
            self.upper = None
",1
"            # The ratio is given on runtime randomly
            self.utt2ratio = None

    def __repr__(self):
        if self.utt2ratio is None:
",1
"            )
",1
"        utt2ratio=None,
        filetype=""list"",
        dbunit=True,
",1
"        else:
            # The ratio is given on runtime randomly
",1
"
",1
"                with open(utt2noise, ""r"") as f:
                    for line in f:
",1
"                        # Load all files in memory
                        self.utt2noise[utt] = (signal, rate)
",1
"    def __repr__(self):
        if self.utt2ratio is None:
            return ""{}(lower={}, upper={}, dbunit={})"".format(
                self.__class__.__name__, self.lower, self.upper, self.dbunit
            )
",1
"        else:
            return '{}(""{}"", dbunit={})'.format(
                self.__class__.__name__, self.utt2ratio_file, self.dbunit
            )

",1
"        if uttid is not None and self.utt2ratio is not None:
            ratio = self.utt2ratio[uttid]
        else:
            ratio = self.state.uniform(self.lower, self.upper)

",1
"        if self.dbunit:
            ratio = 10 ** (ratio / 20)
        scale = ratio * numpy.sqrt((x ** 2).mean())
",1
"            # Get noise from the external source
",1
"            return x

        x = x.astype(numpy.float32)

        if x.ndim != 1:
",1
"            # Must be single channel
            raise RuntimeError(
                ""Input x must be one dimensional array, but got {}"".format(x.shape)
            )

",1
"        rir, rate = self.utt2rir[uttid]
        if rir.ndim == 2:
            # FIXME(kamo): Use chainer.convolution_1d?
            # return [Time, Channel]
            return numpy.stack(
",1
"    assert window > 0
    delta_feat = np.zeros_like(feat)
",1
"    for i in range(1, window + 1):
        delta_feat[:-i] += i * feat[i:]
        delta_feat[i:] += -i * feat[:-i]
",1
"        )

    def __call__(self, x):
        return add_deltas(x, window=self.window, order=self.order)
",1
"from espnet.utils.check_kwargs import check_kwargs
",1
"
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        check_kwargs(self.func, kwargs)
",1
"            # TODO(karita): get help and choices from docstring?
            attr = k.replace(""_"", ""-"")
            group.add_argument(f""--{fname}-{attr}"", default=v, type=type(v))
",1
"
import chainer

from espnet.asr.asr_utils import torch_load
",1
"        for d in dicts:
            chainer.reporter.report(d, self)
",1
"        """"""Initilize TTS module.""""""
",1
"    def forward(self, *args, **kwargs):
        """"""Calculate TTS forward propagation.

        Returns:
",1
"        torch_load(model_path, self)

",1
"    @property
    def attention_plot_class(self):
        """"""Plot attention weights.""""""
        from espnet.asr.asr_utils import PlotAttentionReport

",1
"        return PlotAttentionReport

    @property
    def base_plot_keys(self):
        """"""Return base key names to plot during training.
",1
"        and `validation/main/loss` values.

        Returns:
            list[str]:  Base keys to plot during training.
",1
"
",1
"    count = 0
    best_hyp = sorted(ended_hyps, key=lambda x: x[""score""], reverse=True)[0]
    for m in six.moves.range(M):
",1
"                hyps_same_length, key=lambda x: x[""score""], reverse=True
            )[0]
            if best_hyp_same_length[""score""] - best_hyp[""score""] < D_end:
                count += 1

",1
"    :param lsm_type:
    :param blank:
",1
"    if lsm_type == ""unigram"":
        assert transcript is not None, (
            ""transcript is required for %s label smoothing"" % lsm_type
        )
        labelcount = np.zeros(odim)
",1
"    def __init__(
",1
"        self, char_list, sym_space, sym_blank, report_cer=False, report_wer=False
    ):
        """"""Construct an ErrorCalculator object.""""""
        super(ErrorCalculator, self).__init__()

",1
"            self.idx_space = None

    def __call__(self, ys_hat, ys_pad, is_ctc=False):
        """"""Calculate sentence-level WER/CER score.

",1
"
",1
"            char_ref_lens.append(len(ref_chars))
        return float(sum(char_eds)) / sum(char_ref_lens)

    def calculate_wer(self, seqs_hat, seqs_true):
",1
"class ErrorCalculatorTrans(object):
    """"""Calculate CER and WER for transducer models.

",1
"        report_wer (boolean): compute WER option
",1
"        self.char_list = args.char_list
        self.space = args.sym_space
        self.blank = args.sym_blank
",1
"
    def __call__(self, hs_pad, ys_pad):
",1
"
        for b in six.moves.range(batchsize):
            if self.recog_args.beam_size == 1:
                nbest_hyps = self.dec.recognize(hs_pad[b], self.recog_args)
",1
"
        if self.report_cer:
            cer = self.calculate_cer(seqs_hat, seqs_true)
",1
"
        if self.report_wer:
            wer = self.calculate_wer(seqs_hat, seqs_true)

",1
"    def convert_to_char(self, ys_hat, ys_pad):
        """"""Convert index to character.

        Args:
            ys_hat (torch.Tensor): prediction (batch, seqlen)
",1
"            ys_pad (torch.Tensor): reference (batch, seqlen)
",1
"
            seqs_hat.append(seq_hat_text)
            seqs_true.append(seq_true_text)

",1
"        return float(sum(char_eds)) / sum(char_ref_lens)

    def calculate_wer(self, seqs_hat, seqs_true):
        """"""Calculate sentence-level WER score for transducer model.

",1
"        Args:
            seqs_hat (torch.Tensor): prediction (batch, seqlen)
            seqs_true (torch.Tensor): reference (batch, seqlen)
",1
"
        Returns:
            (float): average sentence-level WER score

        """"""
",1
"        word_eds, word_ref_lens = [], []

        for i, seq_hat_text in enumerate(seqs_hat):
            seq_true_text = seqs_true[i]
",1
"            hyp_words = seq_hat_text.split()
",1
"from typing import Any
from typing import Dict
from typing import List
from typing import NamedTuple
from typing import Tuple
",1
"    states: Dict[str, Dict] = dict()

",1
"    def __len__(self) -> int:
        """"""Return a batch size.""""""
        return len(self.length)


",1
"    """"""Batch beam search implementation.""""""
",1
"
    def batchfy(self, hyps: List[Hypothesis]) -> BatchHypothesis:
        """"""Convert list to batch.""""""
        if len(hyps) == 0:
            return BatchHypothesis()
",1
"    def _batch_select(self, hyps: BatchHypothesis, ids: List[int]) -> BatchHypothesis:
",1
"            states={
                k: self.scorers[k].select_state(v, i) for k, v in hyps.states.items()
            },
        )
",1
"                scores={k: batch_hyps.scores[k][i] for k in self.scorers},
",1
"                },
            )
",1
"        Args:
            weighted_scores (torch.Tensor): The weighted sum scores for each tokens.
",1
"                Its shape is `(n_beam, self.vocab_size)`.
            ids (torch.Tensor): The partial token ids to compute topk.
                Its shape is `(n_beam, self.pre_beam_size)`.
",1
"            # where V is `self.n_vocab` and K is `self.beam_size`
            prev_hyp_ids = top_ids // self.n_vocab
            new_token_ids = top_ids % self.n_vocab
            return prev_hyp_ids, new_token_ids, prev_hyp_ids, new_token_ids

",1
"        raise NotImplementedError(
",1
"
        """"""
",1
"
    def score_full(
        self, hyp: BatchHypothesis, x: torch.Tensor
    ) -> Tuple[Dict[str, torch.Tensor], Dict[str, Any]]:
        """"""Score new hypothesis by `self.full_scorers`.
",1
"        n_batch = len(running_hyps)

        # batch scoring
        scores, states = self.score_full(running_hyps, x.expand(n_batch, *x.shape))
",1
"            part_ids = torch.arange(self.n_vocab, device=x.device).expand(
",1
"                n_batch, self.n_vocab
            )
        part_scores, part_states = self.score_partial(running_hyps, part_ids, x)

",1
"                        part_new_token_id,
                    ),
                )
            )
        return self.batchfy(best_hyps)
",1
"                )
            )
        # add eos in the final loop to avoid that there are no ended hyps
",1
"            running_hyps.yseq[torch.arange(n_batch), running_hyps.length - 1]
",1
"
",1
"        * Neural language models
            * :class:`espnet.nets.pytorch_backend.lm.transformer.TransformerLM`
            * :class:`espnet.nets.pytorch_backend.lm.default.DefaultRNNLM`
",1
"        Returns: initial state

        """"""
        return None

",1
"            i (int): Index to select a state in the main beam search
",1
"        self, y: torch.Tensor, state: Any, x: torch.Tensor
",1
"

class BatchScorerInterface(ScorerInterface):
    """"""Batch scorer interface.""""""
",1
"    all the tokens.

",1
"
class STInterface(ASRInterface):
    """"""ST Interface for ESPnet model implementation.

",1
"        :rtype: list
",1
"        """"""
        raise NotImplementedError(""translate method is not implemented"")

    def translate_batch(self, x, trans_args, char_list=None, rnnlm=None):
",1
"

predefined_st = {
    ""pytorch"": {
",1
"    # ""chainer"": {
    #     ""rnn"": ""espnet.nets.chainer_backend.e2e_st:E2E"",
    #     ""transformer"": ""espnet.nets.chainer_backend.e2e_st_transformer:E2E"",
    # }
",1
"        backend (str): NN backend. e.g., pytorch, chainer
",1
"    model_class = dynamic_import(module, predefined_st.get(backend, dict()))
    assert issubclass(
",1
"        model_class, STInterface
    ), f""{module} does not implement STInterface""
    return model_class
",1
"    """"""Batch processing of CTCPrefixScore

",1
"            torch.device(""cuda:%d"" % x.get_device())
            if x.is_cuda
",1
"        else:
            xn = x.transpose(0, 1)
",1
"        self.x = torch.stack([xn, xb])  # (2, T, B, O) or (2, T, BW, O)
",1
"        # Setup CTC windowing
        self.margin = margin
        if margin > 0:
            self.frame_ids = torch.arange(
                self.input_length, dtype=torch.float32, device=self.device
",1
"                r_prev = r_prev.view(-1, 2, self.n_bb)
            else:
",1
"                r_prev = torch.full(
",1
"                    (self.input_length, 2, self.n_bb),
                    self.logzero,
                    dtype=torch.float32,
                    device=self.device,
",1
"            r_prev, s_prev, f_min_prev, f_max_prev = state

        # select input dimensions for scoring
",1
"            ).view(2, -1, self.n_bb, snum)
",1
"        else:
            scoring_ids = None
            scoring_idmap = None
            snum = self.odim
            x_ = self.x
",1
"
        # new CTC forward probs are prepared as a (T x 2 x BW x S) tensor
        # that corresponds to r_t^n(h) and r_t^b(h) in a batch.
",1
"        # compute log prefix probabilites log(psi)
        log_phi_x = torch.cat((log_phi[0].unsqueeze(0), log_phi[:-1]), dim=0) + x_[0]
        if scoring_ids is not None:
            log_psi = torch.full(
                (self.n_bb, self.odim), self.logzero, device=self.device
",1
"            )
            log_psi_ = torch.logsumexp(
                torch.cat((log_phi_x[start:end], r[start - 1, 0].unsqueeze(0)), dim=0),
                dim=0,
            )
",1
"            log_psi = torch.logsumexp(
                torch.cat((log_phi_x[start:end], r[start - 1, 0].unsqueeze(0)), dim=0),
",1
"                dim=0,
            )

        for si in range(self.n_bb):
            log_psi[si, self.eos] = r_sum[self.end_frames[si], si]
",1
"
    def index_select_state(self, state, best_ids):
        """"""Select CTC states according to best ids

",1
"        :param state    : CTC state
",1
"
class CTCPrefixScore(object):
    """"""Compute CTC label sequence scores

    which is based on Algorithm 2 in WATANABE et al.
",1
"        # initialize CTC states
        output_length = len(y) - 1  # ignore sos
        # new CTC states are prepared as a frame x (n or b) x n_labels tensor
",1
"        else:
            r[output_length - 1] = self.logzero

",1
"        # prepare forward probabilities for the last label
        r_sum = self.xp.logaddexp(
",1
"            r_prev[:, 0], r_prev[:, 1]
",1
"        )  # log(r_t^n(g) + r_t^b(g))
        last = y[-1]
        if output_length > 0 and last in cs:
",1
"            r[t, 0] = self.xp.logaddexp(r[t - 1, 0], log_phi[t - 1]) + xs[t]
",1
"
        # get P(...eos|X) that ends with the prefix itself
        eos_pos = self.xp.where(cs == self.eos)[0]
        if len(eos_pos) > 0:
",1
"        # of the CTC states is moved to the first axis to slice it easily
        return log_psi, self.xp.rollaxis(r, 2)
#!/usr/bin/env python3

# Copyright 2019 Kyoto University (Hirofumi Inaguma)
",1
"
    :param y_hats: numpy array with predicted text
    :param y_pads: numpy array with true (target) text
    :param char_list: vocabulary list
",1
"
    def __call__(self, ys_hat, ys_pad):
",1
"        """"""Calculate sentence-level BLEU score.
",1
"        :param torch.Tensor seqs_hat: prediction (batch, seqlen)
        :param torch.Tensor seqs_true: reference (batch, seqlen)
        :return: token list of prediction
        :rtype list
        :return: token list of reference
",1
"            seqs_hat.append(seq_hat_text)
",1
"            seqs_true.append(seq_true_text)
        return seqs_hat, seqs_true

    def calculate_bleu(self, seqs_hat, seqs_true):
        """"""Calculate average sentence-level BLEU score.
",1
"from espnet.bin.asr_train import get_parser
from espnet.utils.fill_missing_args import fill_missing_args


",1
"
    @classmethod
",1
"
",1
"
    def forward(self, xs, ilens, ys):
        """"""Compute loss for training.

",1
"            For chainer, list of source sequences chainer.Variable
        :param ilens: batch of lengths of source sequences (B)
",1
"        :param ys:
            For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
",1
"        :return: N-best decoding results
        :rtype: list
",1
"from typing import List
from typing import NamedTuple
",1
"from espnet.nets.scorer_interface import PartialScorerInterface
from espnet.nets.scorer_interface import ScorerInterface
",1
"

class BeamSearch(torch.nn.Module):
",1
"        token_list: List[str] = None,
        pre_beam_ratio: float = 1.5,
        pre_beam_score_key: str = None,
    ):
        """"""Initialize beam search.
",1
"        # set scorers
",1
"        for k, v in scorers.items():
            w = weights.get(k, 0)
",1
"
        # set configurations
",1
"    def init_hyp(self, x: torch.Tensor) -> List[Hypothesis]:
",1
"        Args:
",1
"        self, hyp: Hypothesis, x: torch.Tensor
",1
"
",1
"
",1
"                and state dict that has string keys
                and state values of `self.part_scorers`

        """"""
        scores = dict()
",1
"        states = dict()
        for k, d in self.part_scorers.items():
            scores[k], states[k] = d.score_partial(hyp.yseq, ids, hyp.states[k], x)
",1
"        return scores, states
",1
"            Its shape is `(self.n_vocab,)`.
",1
"        if weighted_scores.size(0) == ids.size(0):
",1
"            top_ids = weighted_scores.topk(self.beam_size)[1]
",1
"        return new_scores
",1
"            states: states of `self.full_scorers`
            part_states: states of `self.part_scorers`
            part_idx (int): The new token id for `part_scores`

        Returns:
",1
"        """"""Search new tokens for running hypotheses and encoded speech x.

        Args:
            running_hyps (List[Hypothesis]): Running hypotheses on beam
",1
"                )[1]
            part_scores, part_states = self.score_partial(hyp, part_ids, x)

            # weighted sum scores
",1
"            ]
",1
"        Returns:
            list[Hypothesis]: N-best decoding results

",1
"        """"""
        # set length bounds
        if maxlenratio == 0:
",1
"        logging.info(""max output length: "" + str(maxlen))
        logging.info(""min output length: "" + str(minlen))

        # main loop of prefix search
        running_hyps = self.init_hyp(x)
",1
"                ""again with smaller minlenratio.""
            )
",1
"        logging.info(f""normalized log probability: {best.score / len(best.yseq)}"")
        return nbest_hyps

    def post_process(
        self,
",1
"                h._replace(yseq=self.append_token(h.yseq, self.eos))
                for h in running_hyps
            ]
",1
"    minlenratio: float = 0.0,
    pre_beam_ratio: float = 1.5,
",1
"        maxlenratio (float): Input length ratio to obtain max output length.
            If maxlenratio=0.0 (default), it uses a end-detect function
            to automatically find maximum hypothesis lengths
",1
"        eos=eos,
        token_list=token_list,
",1
"        """"""Add arguments to command line argument parser.""""""
",1
"
        Args:
            idim (int): The number of vocabulary.

        Returns:
",1
"
        """"""
        # local import to avoid cyclic import in lm_train
",1
"                loss to backward (scalar),
                negative log-likelihood of t: -log p(t) (scalar) and
",1
"
    @classmethod
    def build(cls, idim: int, odim: int, **kwargs):
        """"""Initialize this class with python-level args.
",1
"        Args:
            idim (int): The number of an input feature dim.
            odim (int): The number of output vocab.

        Returns:
",1
"            For chainer, list of source sequences chainer.Variable
        :param ilens: batch of lengths of source sequences (B)
",1
"        :return: N-best decoding results
        :rtype: list
        """"""
        raise NotImplementedError(""Batch decoding is not supported yet."")
",1
"        """"""Caluculate attention.

        :param list xs_pad: list of padded input sequences [(T1, idim), (T2, idim), ...]
",1
"
predefined_asr = {
    ""pytorch"": {
",1
"    assert issubclass(
        model_class, ASRInterface
",1
"
# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"
import chainer
",1
"from espnet.nets.chainer_backend.rnn.attentions import att_for
",1
"from espnet.nets.chainer_backend.rnn.decoders import decoder_for
from espnet.nets.chainer_backend.rnn.encoders import encoder_for
",1
"
    """"""

    @staticmethod
",1
"        self.subsample = get_subsample(args, mode=""asr"", arch=""rnn"")

",1
"        # label smoothing info
        if args.lsm_type:
",1
"            logging.info(""Use label smoothing with "" + args.lsm_type)
            labeldist = label_smoothing_dist(
",1
"        else:
",1
"            self.loss = loss_att
        elif alpha == 1:
",1
"            reporter.report({""acc"": acc}, self)

",1
"        with chainer.no_backprop_mode(), chainer.using_config(""train"", False):
            # 1. encoder
            # make a utt list (1) to use the same interface for encoder
",1
"        Returns:
            float np.ndarray: Attention weights. (B, Lmax, Tmax)

        """"""
        hs, ilens = self.enc(xs, ilens)
",1
"    @staticmethod
    def custom_converter(subsampling_factor=0):
        """"""Get customconverter of the model.""""""
        from espnet.nets.chainer_backend.rnn.training import CustomConverter

",1
"        """"""Get custom_updater of the model.""""""
",1
"    def custom_parallel_updater(iters, optimizer, converter, devices, accum_grad=1):
",1
"# encoding: utf-8
""""""Transformer-based model for End-to-end ASR.""""""
",1
"
from argparse import Namespace
from distutils.util import strtobool
",1
")
from espnet.nets.chainer_backend.transformer.plot import PlotAttentionReport
from espnet.nets.chainer_backend.transformer.training import CustomConverter
from espnet.nets.chainer_backend.transformer.training import CustomUpdater
from espnet.nets.chainer_backend.transformer.training import (
",1
"    CustomParallelUpdater,  # noqa: H301
",1
"            default=None,
            type=float,
",1
"            type=float,
            help=""Initial value of learning rate"",
        )
        group.add_argument(
",1
"            default=0.0,
            type=float,
            help=""Dropout rate for the encoder"",
        )
",1
"            ""--adim"",
",1
"        group.add_argument(
            ""--aheads"",
",1
"            default=4,
            type=int,
            help=""Number of heads for multi head attention"",
",1
"    def __init__(self, idim, odim, args, ignore_id=-1, flag_return=True):
        """"""Initialize the transformer.""""""
        chainer.Chain.__init__(self)
        self.mtlalpha = args.mtlalpha
        assert 0 <= self.mtlalpha <= 1, ""mtlalpha must be [0,1]""
",1
"                args.lsm_weight,
                len(args.char_list),
                args.transformer_length_normalized_loss,
",1
"            )
            if args.mtlalpha > 0.0:
                if args.ctc_type == ""builtin"":
                    logging.info(""Using chainer CTC implementation"")
                    self.ctc = ctc.CTC(odim, args.adim, args.dropout_rate)
",1
"        self.dims = args.adim
        self.odim = odim
        self.flag_return = flag_return
        if args.report_cer or args.report_wer:
",1
"            self.error_calculator = ErrorCalculator(
",1
"        else:
            self.error_calculator = None
        if ""Namespace"" in str(type(args)):
            self.verbose = 0 if ""verbose"" not in args else args.verbose
        else:
",1
"            self.verbose = 0 if args.verbose is None else args.verbose

    def reset_parameters(self, args):
        """"""Initialize the Weight according to the give initialize-type.
",1
"            logging.info(""Using GlorotNormal as Parameter initializer"")
",1
"            self.initialW = chainer.initializers.GlorotNormal
",1
"        alpha = self.mtlalpha
",1
"            loss_att = None
            acc = None
        else:
            # Make target
",1
"            reporter.report({""cer"": cer}, self)
            reporter.report({""wer"": wer}, self)
",1
"
",1
"    def calculate_attentions(self, xs, x_mask, ys_pad):
",1
"        Returns:
            List: N-best decoding results.

",1
"            h (ndarray): Encoder ouput features (B, T, D) or (T, D).
            lpz (ndarray): Log probabilities from CTC.
",1
"            hyp[""ctc_score_prev""] = 0.0
            if ctc_weight != 1.0:
",1
"                    local_best_ids = self.xp.argsort(local_scores, axis=1)[0, ::-1][
                        :beam
                    ]
                    local_best_scores = local_scores[:, local_best_ids]

",1
"                for hyp in hyps:
                    hyp[""yseq""].append(self.eos)

            # add ended hypothes to a final list, and removed them from current hypothes
            # (this will be a probmlem, number of hyps < beam)
",1
"            hyps = remained_hyps
            if len(hyps) > 0:
                logging.debug(""remained hypothes: "" + str(len(hyps)))
            else:
                logging.info(""no hypothesis. Finish decoding."")
",1
"                for hyp in hyps:
                    logging.debug(
",1
"                    )

            logging.debug(""number of ended hypothes: "" + str(len(ended_hyps)))
",1
"
        nbest_hyps = sorted(
            ended_hyps, key=lambda x: x[""score""], reverse=True
        )  # [:min(len(ended_hyps), recog_args.nbest)]
",1
"            )
            # should copy becasuse Namespace will be overwritten globally
            recog_args = Namespace(**vars(recog_args))
",1
"            recog_args.minlenratio = max(0.0, recog_args.minlenratio - 0.1)
            return self.recognize_beam(h, lpz, recog_args, char_list, rnnlm)

",1
"        Redirects to PlotAttentionReport

",1
"        Returns:
",1
"    def custom_updater(iters, optimizer, converter, device=-1, accum_grad=1):
        """"""Get custom_updater of the model.""""""
",1
"        with self.init_scope():
",1
"
        Returns:
            chainer.Variable: A variable holding a scalar value of the CTC loss.

",1
"
",1
"        # get length info
        input_length = chainer.Variable(self.xp.array(ilens, dtype=np.int32))
        label_length = chainer.Variable(self.xp.array(olens, dtype=np.int32))
",1
"        Returns:
            chainer.Variable: A n-dimension float array.

",1
"                Input variable of decoder.

        Returns:
           chainer.Variable: A variable holding a scalar value of the CTC loss.
",1
"
        """"""
",1
"
        Returns:
            chainer.Variable: A n-dimension float array.

",1
"        y_hat = self.ctc_lo(F.pad_sequence(hs), n_batch_axes=2)
        return F.log_softmax(y_hat.reshape(-1, y_hat.shape[-1])).reshape(y_hat.shape)

",1
"        :return: argmax applied 2d tensor (B, Tmax)
",1
"    Args:
",1
"    return ctc
import numpy
",1
"
class EmbedIDFunction(function_node.FunctionNode):
    def __init__(self, ignore_label=None):
        self.ignore_label = ignore_label
        self._w_shape = None
",1
"
",1
"        type_check.expect(w_type.dtype == numpy.float32, w_type.ndim == 2)

",1
"            for ix, igy in six.moves.zip(x.ravel(), gy.reshape(x.size, -1)):
                if ix == self.ignore_label:
                    continue
                gW[ix] += igy
",1
"        else:
            """"""
            # original code based on cuda elementwise method
",1
"            if self.ignore_label is None:
                cuda.elementwise(
",1
"                    'T gy, S x, S n_out', 'raw T gW',
                    'ptrdiff_t w_ind[] = {x, i % n_out};'
                    'atomicAdd(&gW[w_ind], gy)',
                    'embed_id_bwd')(
                        gy, xp.expand_dims(x, -1), gW.shape[1], gW)
",1
"                    'embed_id_bwd_ignore_label')(
                        gy, xp.expand_dims(x, -1), gW.shape[1],
                        self.ignore_label, gW)
            """"""
            # EmbedID gradient alternative without atomicAdd, which simply
",1
"            # creates a one-hot vector and applies dot product
            xi = xp.zeros((x.size, len(gW)), dtype=numpy.float32)
            idx = xp.arange(x.size, dtype=numpy.int32) * len(gW) + x.ravel()
",1
"                xi[:, self.ignore_label] = 0.0
            gW = xi.T.dot(gy.reshape(x.size, -1)).astype(gW.dtype, copy=False)

        return (gW,)
",1
"    def backward(self, indexes, grads):
        xp = cuda.get_array_module(*grads)
",1
"    Args:
        x (chainer.Variable | np.ndarray): Batch vectors of IDs. Each
            element must be signed integer.
        W (chainer.Variable | np.ndarray): Distributed representation
            of each ID (a.k.a. word embeddings).
",1
"        array([[ 2.,  2.,  2.],
               [ 1.,  1.,  1.]], dtype=float32)
        >>> F.embed_id(x, W, ignore_label=1).data
        array([[ 2.,  2.,  2.],
",1
"    """"""
    return EmbedIDFunction(ignore_label=ignore_label).apply((x, W))[0]


class EmbedID(link.Link):
",1
"        out_size (int): Output dimension.
        initialW (Initializer): Initializer to initialize the weight.
",1
"
    ignore_label = None

",1
"
    @staticmethod
",1
"import chainer.links as L

import numpy as np

MIN_VALUE = float(np.finfo(np.float32).min)
",1
"

class MultiHeadAttention(chainer.Chain):
    """"""Multi Head Attention Layer.

",1
"
",1
"class LabelSmoothingLoss(chainer.Chain):
    """"""Label Smoothing Loss.

    Args:
",1
"
    def __init__(self, smoothing, n_target_vocab, normalize_length=False, ignore_id=-1):
        """"""Initialize Loss.""""""
        super(LabelSmoothingLoss, self).__init__()
",1
"            self.use_label_smoothing = True
",1
"            self.n_target_vocab = n_target_vocab
        self.normalize_length = normalize_length
        self.ignore_id = ignore_id
        self.acc = None
",1
"
        Args:
",1
"        positional_dropout_rate=0.1,
        attention_dropout_rate=0.0,
        input_layer=""conv2d"",
        pos_enc_class=PositionalEncoding,
",1
"        initialW=None,
        initial_bias=None,
    ):
        """"""Initialize Encoder.

",1
"                self.input_layer = LinearSampling(
                    idim, attention_dim, initialW=initialW, initial_bias=initial_bias
                )
",1
"            elif input_layer == ""embed"":
                self.input_layer = chainer.Sequential(
",1
"    def forward(self, e, ilens):
        """"""Compute Encoder layer.

        Args:
",1
"            e = self[""encoders."" + str(i)](e, xx_mask, batch)
        return self.norm(e).reshape(batch, length, -1), x_mask, ilens
# encoding: utf-8
""""""Class Declaration of Transformer's Decoder.""""""

",1
"    """"""Decoder layer.

    Args:
        odim (int): The output dimension.
        n_layers (int): Number of ecoder layers.
",1
"                odim,
                args.adim,
",1
"            target_block (ndarray): Target block with dimensions: (B x T).
        Returns:
            ndarray: Mask with dimensions (B, S, T).
",1
"from espnet.asr import asr_utils
",1
"        axes = [axes]
    for ax, aw in zip(axes, att_w):
",1
"    """"""Plot multi head attentions.

",1
"    """"""
",1
"    """"""Plot an attention reporter.

    Args:
",1
"        plot_multi_head_attention(self.data, attn_dict, self.outdir, suffix, savefig)
",1
"        batch = self.converter([self.transform(self.data)], self.device)
        return self.att_vis_fn(*batch)
",1
"    def log_attentions(self, logger, step):
        """"""Add image files of att_ws matrix to the tensorboard.""""""

        def log_fig(plot, filename):
",1
"        """"""Initialize LayerNorm.""""""
",1
"        super(LayerNorm, self).__init__(size=dims, eps=eps)
",1
"                initial_bias=initial_bias(scale=stvd),
            )
",1
"            self.act = F.relu
        self.dropout = dropout
",1
"        Return:
            chainer.Variable: Output variable.

        """"""
        e = F.dropout(self.act(self.w_1(e)), self.dropout)
",1
"        return self.w_2(e)
# encoding: utf-8
""""""Class Declaration of Transformer's Positional Encoding.""""""

",1
"    """"""Positional encoding module.

    :param int n_units: embedding dim
",1
"    Returns:
        ndarray, np.ndarray: History mask with dimensions (B, S, S).

    """"""
    batch, length = block.shape
",1
"        n_units (int): Number of input/output dimension of a FeedForward layer.
        d_units (int): Number of units of hidden layer in a FeedForward layer.
",1
"            self.norm2 = LayerNorm(n_units)
        self.dropout = dropout
        self.n_units = n_units

    def forward(self, e, xx_mask, batch):
",1
"        return e
# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
""""""Class Declaration of Transformer's Training Subprocess.""""""
import collections
",1
"from chainer.training.updaters.multiprocess_parallel_updater import scatter_grads
import numpy as np
",1
"        with cuda.get_device_from_array(x) as dev:
            if x is not None:
",1
"                x = x.ravel()
",1
"            i.e. actual batchsize will be doubled.

    """"""

    def __init__(self, train_iter, optimizer, converter, device, accum_grad=1):
",1
"            loss = self._master(*x) / self.accum_grad
            loss.backward()
",1
"
",1
"            # check gradient value
            grad_norm = np.sqrt(
                sum_sqnorm([p.grad for p in optimizer.target.params(False)])
            )
",1
"            logging.info(""grad norm={}"".format(grad_norm))

",1
"                    gp.data.ptr, gp.size, self.nccl.NCCL_FLOAT, 0, null_stream.ptr
                )

    def update(self):
",1
"        scale=1.0,
    ):
        """"""Initialize Vaswani rule extension.""""""
",1
"        if self._init is None:
            self._init = self._d_inv05 * (1.0 * self._warmup_steps_inv15)
",1
"
class CustomConverter(object):
    """"""Custom Converter.
",1
"        Returns:
",1
"        xs, ys = batch[0]
        xs = F.pad_sequence(xs, padding=-1).data
        # get batch of lengths of input sequences
        ilens = np.array([x.shape[0] for x in xs], dtype=np.int32)
        return xs, ilens, ys
",1
"
    :param int idim: input dim
    :param int odim: output dim
    :param flaot dropout_rate: dropout rate
",1
"    def __init__(
        self, channels, idim, dims, dropout=0.1, initialW=None, initial_bias=None
    ):
        """"""Initialize Conv2dSubsampling.""""""
",1
"                3,
",1
"        xs = F.relu(self.conv1(xs))
        xs = F.relu(self.conv2(xs))
        batch, _, length, _ = xs.shape
",1
"                idim,
                dims,
",1
"        """"""Subsample x.

",1
"        logging.info(xs.shape)
        xs = self.linear(xs, n_batch_axes=2)
        logging.info(xs.shape)
        xs = self.pe(xs)
        return xs, ilens
",1
"        dropout_rate (float): Dropout rate.

",1
"        self.dropout_rate = dropout_rate
        self.loss = None
",1
"
        with self.init_scope():
",1
"            self.ctc_lo = L.Linear(eprojs, odim)

    def __call__(self, hs, ys):
        """"""CTC forward.

",1
"
        """"""
",1
"        y_true = F.pad_sequence(ys, padding=-1)  # batch x olen

",1
"
        # get ctc loss
        self.loss = F.connectionist_temporal_classification(
",1
"        logging.info(""ctc loss:"" + str(self.loss.data))

        return self.loss

",1
"
        Args:
            hs (list of chainer.Variable | N-dimension array):
",1
"                Input variable from encoder.

        Returns:
            chainer.Variable: A n-dimension float array.
",1
"        dropout_rate (float): Dropout rate.

    """"""

",1
"        self.ctc = warp_ctc
        self.dropout_rate = dropout_rate
        self.loss = None

",1
"        n_units (int): Number of input/output dimension of a FeedForward layer.
        d_units (int): Number of units of hidden layer in a FeedForward layer.
",1
"
    def forward(self, e, s, xy_mask, yy_mask, batch):
        """"""Compute Encoder layer.

",1
"        n_e = self.self_attn(n_e, mask=yy_mask, batch=batch)
        e = e + F.dropout(n_e, self.dropout)

",1
"        n_e = self.norm3(e)
        n_e = self.feed_forward(n_e)
        e = e + F.dropout(n_e, self.dropout)
        return e
",1
"import logging
import six
",1
"
from espnet.nets.chainer_backend.nets_utils import _subsamplex
from espnet.nets.e2e_asr_common import get_vgg2l_odim
",1
"

# TODO(watanabe) explanation of BLSTMP
",1
"        idim (int): Dimension of inputs.
",1
"        elayers (int): Number of encoder layers.
        cdim (int): Number of rnn units. (resulted in cdim * 2 if bidirectional)
",1
"        hdim (int): Number of projection units.
",1
"        else:
",1
"            rnn = L.NStepLSTM if ""lstm"" in typ else L.NStepGRU
        rnn_label = ""birnn"" if bidir else ""rnn""
        with self.init_scope():
",1
"            # TODO(watanabe) replace subsample and FC layer with CNN
            ys, ilens = _subsamplex(ys, self.subsample[layer + 1])
            # (sum _utt frame_utt) x dim
",1
"
        Args:
            xs (chainer.Variable): Batch of padded charactor ids. (B, Tmax)
",1
"        return xs, ilens  # x: utt list of frame x dim


# TODO(watanabe) explanation of VGG2L, VGG2B (Block) might be better
class VGG2L(chainer.Chain):
",1
"
        self.in_channel = in_channel

    def __call__(self, xs, ilens):
        """"""VGG2L forward propagation.
",1
"        # x: utt x frame x dim
        xs = F.pad_sequence(xs)
",1
"
        return xs, ilens


",1
"class Encoder(chainer.Chain):
    """"""Encoder network class.
",1
"                            typ=typ,
                        ),
                    )
",1
"            else:
                if etype[-1] == ""p"":
",1
"                    logging.info(
                        typ.upper() + "" with every-layer projection for encoder""
",1
"

def encoder_for(args, idim, subsample):
    """"""Return the Encoder module.

",1
"    )
import chainer
import chainer.functions as F
",1
"        self.dunits = dunits
        self.eprojs = eprojs
        self.att_dim = att_dim
        self.h_length = None
        self.enc_h = None
",1
"        self.pre_compute_enc_h = None
",1
"            dec_z (chainer.Variable | N-dimensional array): Input variable of decoder.
            scaling (float): Scaling weight to make attention sharp.

        Returns:
            chainer.Variable: Weighted sum over flames.
",1
"            chainer.Variable: Attention weight.
",1
"        )
",1
"    """"""

",1
"        self.h_length = None
        self.enc_h = None
        self.pre_compute_enc_h = None
",1
"        self.aconv_chans = aconv_chans

    def reset(self):
",1
"        """"""Reset states.""""""
        self.h_length = None
",1
"        self.enc_h = None
        self.pre_compute_enc_h = None

",1
"        """"""Compute AttLoc forward layer.
",1
"
        Args:
            enc_hs (chainer.Variable | N-dimensional array):
",1
"                Input variable from encoders.
            dec_z (chainer.Variable | N-dimensional array): Input variable of decoder.
            att_prev (chainer.Variable | None): Attention weight.
",1
"            scaling (float): Scaling weight to make attention sharp.

        Returns:
",1
"            chainer.Variable: Weighted sum over flames.
            chainer.Variable: Attention weight.

        """"""
",1
"        if att_prev is None:
",1
"        self.h_length = None
",1
"        """"""Reset states.""""""
        self.h_length = None
        self.enc_h = None
        self.pre_compute_enc_h = None
",1
"
        Args:
            enc_hs (chainer.Variable | N-dimensional array):
                Input variable from encoders.
            dec_z: Dummy.
",1
"            att_prev (chainer.Variable | None): Attention weight.
",1
"
",1
"        return self.c, att_prev

",1
"    """"""Returns an attention layer given the program arguments.

    Args:
",1
"import random
import six

import chainer
",1
"from argparse import Namespace

from espnet.nets.ctc_prefix_score import CTCPrefixScore
from espnet.nets.e2e_asr_common import end_detect
",1
"        dtype,
        dlayers,
        dunits,
        sos,
",1
"        self.verbose = verbose
        self.char_list = char_list
",1
"        self.labeldist = labeldist
",1
"                c_list[i], z_list[i] = self[""rnn%d"" % i](
                    c_prev[i], z_prev[i], z_list[i - 1]
                )
        else:
            if z_prev[0] is None:
",1
"                        z_prev[i] = chainer.Variable(
                            xp.zeros(
                                (z_list[i - 1].shape[0], self.dunits),
                                dtype=z_list[i - 1].dtype,
",1
"
        Args:
            hs (list of chainer.Variable | N-dimension array):
                Input variable from encoder.
",1
"            ys (list of chainer.Variable | N-dimension array):
                Input variable of decoder.
",1
"        # prepare input and output word sequences with sos/eos IDs
",1
"
",1
"        # padding for ys with -1
        # pys: utt x olen
        pad_ys_in = F.pad_sequence(ys_in, padding=self.eos)
",1
"            + str(self.xp.array([h.shape[0] for h in hs]))
        )
",1
"        logging.info(
            self.__class__.__name__
",1
"
        # initialization
        c_list = [None]  # list of cell state of each layer
        z_list = [None]  # list of hidden state of each layer
",1
"        for i in six.moves.range(olength):
            att_c, att_w = self.att(hs, z_list[0], att_w)
            if i > 0 and random.random() < self.sampling_probability:
                logging.info("" scheduled sampling "")
",1
"                z_out = self.output(z_all[-1])
                z_out = F.argmax(F.log_softmax(z_out), axis=1)
",1
"        self.loss *= np.mean([len(x) for x in ys_in]) - 1
        acc = F.accuracy(y_all, F.flatten(pad_ys_out), ignore_label=-1)
        logging.info(""att loss:"" + str(self.loss.data))
",1
"                seq_hat = [self.char_list[int(idx)] for idx in idx_hat]
                seq_true = [self.char_list[int(idx)] for idx in idx_true]
                seq_hat = """".join(seq_hat).replace(""<space>"", "" "")
",1
"                logging.info(""groundtruth[%d]: "" % i + seq_true)
                logging.info(""prediction [%d]: "" % i + seq_hat)

        if self.labeldist is not None:
",1
"            self.loss = (1.0 - self.lsm_weight) * self.loss + self.lsm_weight * loss_reg

        return self.loss, acc

    def recognize_beam(self, h, lpz, recog_args, char_list, rnnlm=None):
",1
"        """"""Beam search implementation.

",1
"        for _ in six.moves.range(1, self.dlayers):
            c_list.append(None)
            z_list.append(None)
",1
"            }
        else:
            hyp = {
",1
"        ended_hyps = []
",1
"
                z_list, c_list = self.rnn_forward(
                    ey, z_list, c_list, hyp[""z_prev""], hyp[""c_prev""]
                )
",1
"
                # get nbest local scores and their ids
",1
"                    local_scores = (
",1
"                        local_att_scores + recog_args.lm_weight * local_lm_scores
                    )
",1
"                    hyps_best_kept, key=lambda x: x[""score""], reverse=True
                )[:beam]
",1
"            remained_hyps = []
            for hyp in hyps:
",1
"                                hyp[""rnnlm_prev""]
                            )
                        ended_hyps.append(hyp)
                else:
                    remained_hyps.append(hyp)
",1
"            else:
                logging.info(""no hypothesis. Finish decoding."")
",1
"            recog_args = Namespace(**vars(recog_args))
            recog_args.minlenratio = max(0.0, recog_args.minlenratio - 0.1)
            return self.recognize_beam(h, lpz, recog_args, char_list, rnnlm)

",1
"        logging.info(""total log probability: "" + str(nbest_hyps[0][""score""]))
        logging.info(
",1
"
",1
"    def calculate_all_attentions(self, hs, ys):
        """"""Calculate all of attentions.

        Args:
",1
"            hs (list of chainer.Variable | N-dimensional array):
                Input variable from encoder.
            ys (list of chainer.Variable | N-dimensional array):
                Input variable of decoder.
",1
"        Returns:
            chainer.Variable: List of attention weights.

        """"""
",1
"        z_list = [None]  # list of hidden state of each layer
        for _ in six.moves.range(1, self.dlayers):
",1
"            att_c, att_w = self.att(hs, z_list[0], att_w)
            ey = F.hstack((eys[i], att_c))  # utt x (zdim + hdim)
            z_list, c_list = self.rnn_forward(ey, z_list, c_list, z_list, c_list)
            att_ws.append(att_w)  # for debugging

",1
"
",1
"    Returns:
        chainer.Chain: The decoder module.

    """"""
",1
"        args.lsm_weight,
        args.sampling_probability,
    )
",1
"
# chainer related
from chainer import cuda
",1
"from chainer import training
from chainer import Variable
",1
"import numpy as np


# copied from https://github.com/chainer/chainer/blob/master/chainer/optimizer.py
def sum_sqnorm(arr):
",1
"
    Returns:
",1
"        Float: Sum of the norm calculated from the given array.

",1
"        train_iter (iterator | dict[str, iterator]): Dataset iterator for the
            training dataset. It can also be a dictionary that maps strings to
            iterators. If this is just an iterator, then the iterator is
            registered by the name ``'main'``.
        optimizer (optimizer | dict[str, optimizer]): Optimizer to update
",1
"        converter (espnet.asr.chainer_backend.asr.CustomConverter): Converter
            function to build input arrays. Each batch extracted by the main
",1
"            In the case of multi-gpu, `device={""main"":0, ""sub_1"": 1, ...}`.
        accum_grad (int):The number of gradient accumulation. if set to 2, the network
            parameters will be updated once in twice,
            i.e. actual batchsize will be doubled.

",1
"        loss.unchain_backward()  # Truncate the graph

        # update parameters
        self.forward_count += 1
        if self.forward_count != self.accum_grad:
",1
"            return
",1
"        self.forward_count = 0
        # compute the gradient norm to check if it is normal or not
",1
"        grad_norm = np.sqrt(
            sum_sqnorm([p.grad for p in optimizer.target.params(False)])
        )
        logging.info(""grad norm={}"".format(grad_norm))
        if math.isnan(grad_norm):
",1
"            logging.warning(""grad norm is nan. Do not update model."")
        else:
",1
"            optimizer.update()
        optimizer.target.cleargrads()  # Clear the parameter gradients

    def update(self):
        self.update_core()
",1
"
    Args:
        train_iter (iterator | dict[str, iterator]): Dataset iterator for the
            training dataset. It can also be a dictionary that maps strings to
",1
"            batch = self.get_iterator(""main"").next()
            x = self.converter(batch, self._devices[0])
",1
"                return
            self.forward_count = 0
            # check gradient value
            grad_norm = np.sqrt(
                sum_sqnorm([p.grad for p in optimizer.target.params(False)])
",1
"    def update(self):
",1
"        # batch should be located in list
        assert len(batch) == 1
        xs, ys = batch[0]

",1
"        return xs, ilens, ys
",1
"# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""RNN sequence-to-sequence speech recognition model (pytorch).""""""
",1
"
",1
"import numpy as np
import six
",1
"from espnet.nets.pytorch_backend.frontends.frontend import frontend_for
from espnet.nets.pytorch_backend.initialization import lecun_normal_init_parameters
",1
"from espnet.nets.pytorch_backend.rnn.decoders import decoder_for
",1
"from espnet.nets.pytorch_backend.rnn.encoders import encoder_for
from espnet.nets.scorers.ctc import CTCPrefixScorer

",1
"
    def report(self, loss_ctc, loss_att, acc, cer_ctc, cer, wer, mtl_loss):
        """"""Report at every step.""""""
        reporter.report({""loss_ctc"": loss_ctc}, self)
",1
"        reporter.report({""loss_att"": loss_att}, self)
        reporter.report({""acc"": acc}, self)
        reporter.report({""cer_ctc"": cer_ctc}, self)
        reporter.report({""cer"": cer}, self)
",1
"
class E2E(ASRInterface, torch.nn.Module):
    """"""E2E module.

",1
"                ""lstmp"",
                ""blstmp"",
                ""vgglstmp"",
",1
"                ""vggbgru"",
            ],
            help=""Type of encoder network architecture"",
        )
        group.add_argument(
",1
"            ""--elayers"",
            default=4,
            type=int,
            help=""Number of encoder layers ""
            ""(for shared recognition part in multi-speaker asr mode)"",
",1
"        )
        group.add_argument(
            ""--eunits"",
            ""-u"",
",1
"            type=str,
            choices=[
                ""noatt"",
                ""dot"",
",1
"                ""coverage"",
                ""coverage_location"",
                ""location2d"",
",1
"        )
        group.add_argument(
            ""--adim"",
            default=320,
",1
"            ""--dtype"",
            default=""lstm"",
            type=str,
            choices=[""lstm"", ""gru""],
",1
"            type=float,
            help=""Dropout rate for the decoder"",
        )
        group.add_argument(
            ""--sampling-probability"",
",1
"            default=0.0,
            type=float,
",1
"        super(E2E, self).__init__()
        torch.nn.Module.__init__(self)
        self.mtlalpha = args.mtlalpha
",1
"        - LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)
        """"""
        lecun_normal_init_parameters(self)
        # exceptions
",1
"            set_forget_bias_to_one(self.dec.decoder[i].bias_ih)

",1
"            hs_pad, hlens, mask = self.frontend(to_torch_tensor(xs_pad), ilens)
            hs_pad, hlens = self.feature_transform(hs_pad, hlens)
        else:
            hs_pad, hlens = xs_pad, ilens

",1
"
        # 3. attention loss
        if self.mtlalpha == 1:
            self.loss_att, acc = None, None
",1
"        else:
",1
"                ref_chars = seq_true_text.replace("" "", """")
                if len(ref_chars) > 0:
                    cers.append(
                        editdistance.eval(hyp_chars, ref_chars) / len(ref_chars)
",1
"                    )

",1
"        # 5. compute cer/wer
",1
"            cer, wer = 0.0, 0.0
            # oracle_cer, oracle_wer = 0.0, 0.0
        else:
            if self.recog_args.ctc_weight > 0.0:
",1
"                ref_words = seq_true_text.split()
                word_eds.append(editdistance.eval(hyp_words, ref_words))
                word_ref_lens.append(len(ref_words))
                hyp_chars = seq_hat_text.replace("" "", """")
                ref_chars = seq_true_text.replace("" "", """")
",1
"                0.0
                if not self.report_wer
",1
"        :param Namespace recog_args: argument Namespace containing options
        :param list char_list: list of characters
        :param torch.nn.Module rnnlm: language model module
        :return: N-best decoding results
        :rtype: list
",1
"        """"""
        hs = self.encode(x).unsqueeze(0)
        # calculate log P(z_t|X) for CTC scores
        if recog_args.ctc_weight > 0.0:
",1
"
        # 1. Encoder
        hs_pad, hlens, _ = self.enc(hs_pad, hlens)

        # calculate log P(z_t|X) for CTC scores
",1
"        else:
            lpz = None
            normalize_score = True

",1
"        prev = self.training
",1
"        enhanced, hlensm, mask = self.frontend(xs_pad, ilens)
        if prev:
            self.train()
        return enhanced.cpu().numpy(), mask.cpu().numpy(), ilens

",1
"
        return att_ws

    def subsample_frames(self, x):
        """"""Subsample speeh frames in the encoder.""""""
",1
"        self.masks = None
",1
"            olens (LongTensor): Batch of output lenghts (B,).

        Returns:
",1
"            self.masks = self._make_masks(ilens, olens).to(att_ws.device)
        losses = self.guided_attn_masks * att_ws
        loss = torch.mean(losses.masked_select(self.masks))
        if self.reset_always:
",1
"            )
",1
"        return guided_attn_masks

    @staticmethod
",1
"
        """"""
        in_masks = make_non_pad_mask(ilens)  # (B, T_in)
        out_masks = make_non_pad_mask(olens)  # (B, T_out)
        return out_masks.unsqueeze(-1) & in_masks.unsqueeze(-2)  # (B, T_out, T_in)
",1
"        """"""
        super(Tacotron2Loss, self).__init__()
        assert (use_masking != use_weighted_masking) or not use_masking
        self.use_masking = use_masking
",1
"
        Returns:
",1
"            before_outs, ys
        )
        bce_loss = self.bce_criterion(logits, labels)
",1
"                .sum()
            )

",1
"    ):
        """"""Apply pre hook fucntion before loading state dict.

        From v.0.6.1 `bce_criterion.pos_weight` param is registered as a parameter but
        old models do not include it and as a result, it causes missing key error when
",1
"        loading old model parameter. This function solve the issue by adding param in
        state dict before loading as a pre hook function
        of the `load_state_dict` method.

",1
"            state_dict[key] = self.bce_criterion.pos_weight


",1
"    """"""

",1
"            ""--econv-layers"",
            default=3,
            type=int,
            help=""Number of encoder convolution layers"",
        )
",1
"            help=""Number of encoder convolution channels"",
",1
"        group.add_argument(
            ""--atype"",
",1
"            choices=[""forward_ta"", ""forward"", ""location""],
            help=""Type of attention mechanism"",
        )
        group.add_argument(
            ""--adim"",
",1
"            type=int,
            help=""Number of attention convolution channels"",
        )
",1
"            ""--cbhg-conv-bank-layers"",
            default=8,
            type=int,
",1
"            type=int,
",1
"            type=strtobool,
            help=""Whether to use residual connection in conv layer"",
        )
",1
"        )
        group.add_argument(
            ""--reduction-factor"", default=1, type=int, help=""Reduction factor""
        )
",1
"            default=None,
            type=int,
",1
"            help=""Whether to use masking in calculation of loss"",
        )
        group.add_argument(
            ""--use-weighted-masking"",
            default=False,
",1
"            type=float,
            help=""Positive sample weight in BCE calculation ""
            ""(only for use-masking=True)"",
",1
"        )
        return parser

",1
"        """"""Initialize Tacotron2 module.

        Args:
            idim (int): Dimension of the inputs.
            odim (int): Dimension of the outputs.
",1
"                - elayers (int): The number of encoder blstm layers.
                - eunits (int): The number of encoder blstm units.
                - econv_layers (int): The number of encoder conv layers.
                - econv_filts (int): The number of encoder conv filter size.
",1
"                - cumulate_att_w (bool): Whether to cumulate previous attention weight.
",1
"                    with decoder lstm outputs.
                - dropout_rate (float): Dropout rate.
                - zoneout_rate (float): Zoneout rate.
",1
"                - cbhg_highway_units (int):
                    The number of units of highway network in CBHG.
                - cbhg_gru_units (int): The number of units of GRU in CBHG.
",1
"                - use_masking (bool):
                    Whether to apply masking for padded part in loss calculation.
",1
"        torch.nn.Module.__init__(self)
",1
"                ""there is no such an activation function. (%s)"" % args.output_activation
            )

        # set padding idx
",1
"        dec_idim = (
            args.eunits
            if args.spk_embed_dim is None
            else args.eunits + args.spk_embed_dim
        )
",1
"        if args.atype == ""location"":
            att = AttLoc(
                dec_idim, args.dunits, args.adim, args.aconv_chans, args.aconv_filts
",1
"            )
        elif args.atype == ""forward"":
            att = AttForward(
                dec_idim, args.dunits, args.adim, args.aconv_chans, args.aconv_filts
",1
"            )
            if self.cumulate_att_w:
                logging.warning(
                    ""cumulation of attention weights is disabled in forward attention.""
                )
",1
"            odim=odim,
            att=att,
            dlayers=args.dlayers,
",1
"            dunits=args.dunits,
            prenet_layers=args.prenet_layers,
",1
"            )
        if self.use_cbhg:
",1
"
        # load pretrained model
        if args.pretrained_model is not None:
            self.load_pretrained_model(args.pretrained_model)
",1
"
",1
"    def forward(
        self, xs, ilens, ys, labels, olens, spembs=None, extras=None, *args, **kwargs
    ):
        """"""Calculate forward propagation.

",1
"            {""bce_loss"": bce_loss.item()},
        ]

",1
"                olens_in = olens
            attn_loss = self.attn_loss(att_ws, ilens, olens_in)
            loss = loss + attn_loss
",1
"
    def inference(self, x, inference_args, spemb=None, *args, **kwargs):
        """"""Generate the sequence of features given the sequences of characters.

",1
"            x (Tensor): Input sequence of characters (T,).
            inference_args (Namespace):
                - threshold (float): Threshold in inference.
                - minlenratio (float): Minimum length ratio in inference.
",1
"        )  # keep compatibility
        backward_window = inference_args.backward_window if use_att_constraint else 0
        forward_window = inference_args.forward_window if use_att_constraint else 0

        # inference
",1
"        h = self.enc.inference(x)
        if self.spk_embed_dim is not None:
            spemb = F.normalize(spemb, dim=0).unsqueeze(0).expand(h.size(0), -1)
            h = torch.cat([h, spemb], dim=-1)
        outs, probs, att_ws = self.dec.inference(
",1
"            return outs, probs, att_ws

    def calculate_all_attentions(
        self, xs, ilens, ys, spembs=None, keep_tensor=False, *args, **kwargs
",1
"
        """"""
",1
"        # check ilens type (should be list of int)
        if isinstance(ilens, torch.Tensor) or isinstance(ilens, np.ndarray):
            ilens = list(map(int, ilens))

        self.eval()
",1
"
",1
"
        Returns:
            list: List of strings which are base keys to plot during training.

        """"""
",1
"        plot_keys = [""loss"", ""l1_loss"", ""mse_loss"", ""bce_loss""]
        if self.use_guided_attn_loss:
            plot_keys += [""attn_loss""]
        if self.use_cbhg:
",1
"
""""""Transformer text translation model (pytorch).""""""

from argparse import Namespace
from distutils.util import strtobool
",1
"import logging
import math
",1
"
import numpy as np
import torch

",1
"
    """"""

",1
"            type=str,
            default=""xavier_uniform"",
",1
"                ""kaiming_normal"",
            ],
",1
"        )
        group.add_argument(
            ""--transformer-attn-dropout-rate"",
            default=None,
            type=float,
",1
"            help=""dropout in transformer attention. use --dropout-rate if None is set"",
        )
        group.add_argument(
",1
"            help=""normalize loss by length"",
        )

",1
"        # Attention
        group.add_argument(
",1
"            ""--dunits"", default=2048, type=int, help=""Number of decoder hidden units""
        )
        return parser
",1
"        return PlotAttentionReport

    def __init__(self, idim, odim, args, ignore_id=-1):
",1
"        """"""Construct an E2E object.

",1
"            positional_dropout_rate=args.dropout_rate,
",1
"            src_attention_dropout_rate=args.transformer_attn_dropout_rate,
",1
"        self.ignore_id = ignore_id
",1
"        self.criterion = LabelSmoothingLoss(
            self.odim,
            self.ignore_id,
            args.lsm_weight,
",1
"            )
        else:
            self.error_calculator = None
        self.rnnlm = None

",1
"
",1
"    def reset_parameters(self, args):
        """"""Initialize parameters.""""""
        # initialize parameters
        initialize(self, args.transformer_init)
        torch.nn.init.normal_(
",1
"        xs_pad = xs_pad[:, : max(ilens)]  # for data parallel
        src_mask = (~make_pad_mask(ilens.tolist())).to(xs_pad.device).unsqueeze(-2)
        xs_pad, ys_pad = self.target_forcing(xs_pad, ys_pad)
",1
"        if self.training or self.error_calculator is None:
            bleu = 0.0
        else:
",1
"            logging.warning(""loss (=%f) is not correct"", loss_data)
",1
"        return self.loss
",1
"        xs = torch.as_tensor(xs).unsqueeze(0)
",1
"        enc_output, _ = self.encoder(xs, None)
        return enc_output.squeeze(0)
",1
"        """"""Prepend target language IDs to source sentences for multilingual NMT.
",1
"            # prepend target language ID to source sentences
            xs_pad = torch.cat([lang_ids, xs_pad], dim=1)
        return xs_pad, ys_pad
",1
"
        # make a utt list (1) to use the same interface for encoder
        if self.multilingual:
",1
"            )
",1
"        if rnnlm:
            hyp = {""score"": 0.0, ""yseq"": [y], ""rnnlm_prev"": None}
        else:
",1
"                    local_att_scores = traced_decoder(ys, ys_mask, enc_output)[0]
",1
"                        ys, ys_mask, enc_output
                    )[0]
",1
"                )[:beam]

",1
"            logging.debug(""number of pruned hypothes: "" + str(len(hyps)))
            if char_list is not None:
                logging.debug(
                    ""best hypo: ""
                    + """".join([char_list[int(x)] for x in hyps[0][""yseq""][1:]])
",1
"                logging.info(""adding <eos> in the last postion in the loop"")
                for hyp in hyps:
                    hyp[""yseq""].append(self.eos)

            # add ended hypothes to a final list, and removed them from current hypothes
",1
"                        ended_hyps.append(hyp)
                else:
                    remained_hyps.append(hyp)

            # end detection
",1
"            from espnet.nets.e2e_asr_common import end_detect

            if end_detect(ended_hyps, i) and trans_args.maxlenratio == 0.0:
",1
"                for hyp in hyps:
                    logging.debug(
",1
"        ret = dict()
",1
"
",1
"""""""Initialization functions for RNN sequence-to-sequence models.""""""

import math
",1
"            # bias
            data.zero_()
        elif data.dim() == 2:
            # linear weight
",1
"    start, end = n // 4, n // 2
    bias.data[start:end].fill_(1.0)
# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"from espnet.nets.pytorch_backend.e2e_asr import CTC_LOSS_THRESHOLD
from espnet.nets.pytorch_backend.e2e_asr import Reporter
from espnet.nets.pytorch_backend.nets_utils import get_subsample
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask
from espnet.nets.pytorch_backend.nets_utils import th_accuracy
",1
"                ""xavier_uniform"",
",1
"                ""xavier_normal"",
                ""kaiming_uniform"",
                ""kaiming_normal"",
            ],
",1
"            default=0.0,
            type=float,
            help=""Dropout rate for the encoder"",
        )
        # Encoder
",1
"            type=int,
            help=""Number of attention transformation dimensions"",
",1
"        )
        group.add_argument(
            ""--dunits"", default=320, type=int, help=""Number of decoder hidden units""
        )
",1
"
        :param int idim: dimension of inputs
        :param int odim: dimension of outputs
",1
"        if args.transformer_attn_dropout_rate is None:
            args.transformer_attn_dropout_rate = args.dropout_rate
        self.encoder = Encoder(
",1
"            idim=idim,
",1
"            attention_dim=args.adim,
            attention_heads=args.aheads,
",1
"            num_blocks=args.dlayers,
            dropout_rate=args.dropout_rate,
",1
"        self.eos = odim - 1
        self.odim = odim
",1
"        self.mtlalpha = args.mtlalpha
        if args.mtlalpha > 0.0:
            self.ctc = CTC(
",1
"                args.sym_space,
",1
"        self.hs_pad = hs_pad

        # 2. forward decoder
        ys_in_pad, ys_out_pad = add_sos_eos(ys_pad, self.sos, self.eos, self.ignore_id)
        ys_mask = target_mask(ys_in_pad, self.ignore_id)
",1
"            loss_att_data = float(loss_att)
            loss_ctc_data = float(loss_ctc)

",1
"        else:
            logging.warning(""loss (=%f) is not correct"", loss_data)
        return self.loss

    def scorers(self):
",1
"
    def recognize(self, x, recog_args, char_list=None, rnnlm=None, use_jit=False):
        """"""Recognize input speech.
",1
"
        :param ndnarray x: input acoustic feature (B, T, D) or (T, D)
        :param Namespace recog_args: argment Namespace contraining options
        :param list char_list: list of characters
        :param torch.nn.Module rnnlm: language model module
",1
"        penalty = recog_args.penalty
        ctc_weight = recog_args.ctc_weight

",1
"        if lpz is not None:
            ctc_prefix_score = CTCPrefixScore(lpz.detach().numpy(), 0, self.eos, numpy)
            hyp[""ctc_state_prev""] = ctc_prefix_score.initial_state()
            hyp[""ctc_score_prev""] = 0.0
            if ctc_weight != 1.0:
",1
"                ctc_beam = min(lpz.shape[-1], int(beam * CTC_SCORING_RATIO))
            else:
",1
"                ctc_beam = lpz.shape[-1]
        hyps = [hyp]
        ended_hyps = []
",1
"            logging.debug(""position "" + str(i))

",1
"                if rnnlm:
                    rnnlm_state, local_lm_scores = rnnlm.predict(hyp[""rnnlm_prev""], vy)
                    local_scores = (
                        local_att_scores + recog_args.lm_weight * local_lm_scores
                    )
",1
"                        hyp[""yseq""], local_best_ids[0], hyp[""ctc_state_prev""]
                    )
                    local_scores = (1.0 - ctc_weight) * local_att_scores[
                        :, local_best_ids[0]
",1
"                        )
                    local_best_scores, joint_best_ids = torch.topk(
",1
"                        local_scores, beam, dim=1
                    )
                    local_best_ids = local_best_ids[:, joint_best_ids[0]]
",1
"            # sort and get nbest
            hyps = hyps_best_kept
            logging.debug(""number of pruned hypothes: "" + str(len(hyps)))
",1
"                for hyp in hyps:
                    hyp[""yseq""].append(self.eos)

",1
"                    if len(hyp[""yseq""]) > minlen:
                        hyp[""score""] += (i + 1) * penalty
                        if rnnlm:  # Word LM needs to add final <eos> score
                            hyp[""score""] += recog_args.lm_weight * rnnlm.final(
                                hyp[""rnnlm_prev""]
",1
"                        ended_hyps.append(hyp)
                else:
                    remained_hyps.append(hyp)

",1
"        nbest_hyps = sorted(ended_hyps, key=lambda x: x[""score""], reverse=True)[
            : min(len(ended_hyps), recog_args.nbest)
        ]

",1
"            ""normalized log probability: ""
            + str(nbest_hyps[0][""score""] / len(nbest_hyps[0][""yseq""]))
        )
        return nbest_hyps

",1
"
",1
"from espnet.nets.pytorch_backend.e2e_tts_tacotron2 import (
    Tacotron2Loss as TransformerLoss,  # noqa: H301
)
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask
",1
"            self.guided_attn_masks = (
                self._make_guided_attention_masks(ilens, olens)
                .to(att_ws.device)
",1
"            self.masks = self._make_masks(ilens, olens).to(att_ws.device).unsqueeze(1)
        losses = self.guided_attn_masks * att_ws
        loss = torch.mean(losses.masked_select(self.masks))
        if self.reset_always:
            self._reset_masks()
",1
"
    def plotfn(self, data, attn_dict, outdir, suffix=""png"", savefn=None):
        """"""Plot multi head attentions.

        Args:
",1
"                    ax.set_xlabel(""frames"")
                    ax.set_ylabel(""fbank coeff"")
                    fig.tight_layout()
                else:
                    fig = _plot_and_save_attention(att_w, filename)
",1
"            type=int,
            help=""Dimension of character embedding in encoder prenet"",
        )
        group.add_argument(
",1
"        group.add_argument(
",1
"        group.add_argument(
            ""--adim"",
            default=384,
",1
"            choices=[""linear"", ""conv1d"", ""conv1d-linear""],
",1
"            ""--postnet-chans"", default=256, type=int, help=""Number of postnet channels""
        )
",1
"            help=""Use trainable scaled positional encoding ""
",1
"            ""instead of the fixed scale one."",
        )
        group.add_argument(
            ""--use-batch-norm"",
",1
"        )
        group.add_argument(
",1
"        )
        group.add_argument(
",1
"            type=int,
            help=""Number of speaker embedding dimensions"",
        )
        group.add_argument(
",1
"            ""--spk-embed-integration-type"",
            type=str,
            default=""add"",
            choices=[""add"", ""concat""],
",1
"            help=""How to integrate speaker embedding"",
        )
        # training related
        group.add_argument(
",1
"            help=""How to initialize transformer parameters"",
        )
        group.add_argument(
            ""--initial-encoder-alpha"",
            type=float,
",1
"            default=1.0,
            help=""Initial alpha value in decoder's ScaledPositionalEncoding"",
",1
"            type=int,
            help=""Optimizer warmup steps"",
        )
        group.add_argument(
            ""--transformer-enc-dropout-rate"",
",1
"            default=0.1,
            type=float,
            help=""Dropout rate for transformer encoder except for attention"",
        )
",1
"        )
        group.add_argument(
            ""--transformer-dec-attn-dropout-rate"",
            default=0.1,
            type=float,
",1
"            ""--dprenet-dropout-rate"",
            default=0.5,
            type=float,
",1
"            help=""Whether to use weighted masking in calculation of loss"",
        )
        group.add_argument(
            ""--loss-type"",
",1
"            help=""Positive sample weight in BCE calculation ""
            ""(only for use-masking=True)"",
        )
        group.add_argument(
            ""--use-guided-attn-loss"",
",1
"            default=False,
            type=strtobool,
            help=""Whether to use guided attention loss"",
",1
"            help=""Number of layers to be applied guided attention loss""
",1
"        return TTSPlot

",1
"                - embed_dim (int): Dimension of character embedding.
                - eprenet_conv_layers (int):
",1
"                - eunits (int): Number of encoder hidden units.
                - adim (int): Number of attention transformation dimensions.
",1
"                - aheads (int): Number of heads for multi head attention.
                - dlayers (int): Number of decoder layers.
                - dunits (int): Number of decoder hidden units.
                - postnet_layers (int): Number of postnet layers.
                - postnet_chans (int): Number of postnet channels.
",1
"                - use_scaled_pos_enc (bool):
",1
"                - spk_embed_dim (int): Number of speaker embedding dimenstions.
                - spk_embed_integration_type: How to integrate speaker embedding.
                - transformer_init (float): How to initialize transformer parameters.
                - transformer_lr (float): Initial value of learning rate.
                - transformer_warmup_steps (int): Optimizer warmup steps.
",1
"                    Dropout rate in encoder self-attention module.
",1
"                - postnet_dropout_rate (float): Dropout rate in postnet.
                - use_masking (bool):
                    Whether to apply masking for padded part in loss calculation.
",1
"                    Whether to apply weighted masking in loss calculation.
                - bce_pos_weight (float): Positive sample weight in bce calculation
",1
"                    (only for use_masking=true).
                - loss_type (str): How to calculate loss.
                - use_guided_attn_loss (bool): Whether to use guided attention loss.
                - num_heads_applied_guided_attn (int):
",1
"                    Number of heads in each layer to apply guided attention loss.
                - num_layers_applied_guided_attn (int):
                    Number of layers to apply guided attention loss.
",1
"                - modules_applied_guided_attn (list):
",1
"                    List of module names to apply guided attention loss.
                - guided-attn-loss-sigma (float) Sigma in guided attention loss.
",1
"        if self.spk_embed_dim is not None:
",1
"        if self.use_guided_attn_loss:
            if args.num_layers_applied_guided_attn == -1:
                self.num_layers_applied_guided_attn = args.elayers
            else:
                self.num_layers_applied_guided_attn = (
",1
"                    econv_layers=args.eprenet_conv_layers,
                    econv_chans=args.eprenet_conv_chans,
                    econv_filts=args.eprenet_conv_filts,
                    use_batch_norm=args.use_batch_norm,
",1
"            attention_heads=args.aheads,
            linear_units=args.eunits,
            num_blocks=args.elayers,
",1
"            pos_enc_class=pos_enc_class,
",1
"            )
        else:
            decoder_input_layer = ""linear""
        self.decoder = Decoder(
            odim=-1,
",1
"            concat_after=args.decoder_concat_after,
",1
"        # initialize parameters
",1
"        self._reset_parameters(
",1
"
    def _reset_parameters(self, init_type, init_enc_alpha=1.0, init_dec_alpha=1.0):
        # initialize parameters
        initialize(self, init_type)

",1
"    def _add_first_frame_and_remove_last_frame(self, ys):
        ys_in = torch.cat(
            [ys.new_zeros((ys.shape[0], 1, ys.shape[2])), ys[:, :-1]], dim=1
        )
        return ys_in
",1
"        Args:
            xs (Tensor): Batch of padded character ids (B, Tmax).
            ilens (LongTensor): Batch of lengths of each input batch (B,).
",1
"        # remove unnecessary padded part (for multi-gpus)
        max_ilen = max(ilens)
        max_olen = max(olens)
        if max_ilen != xs.shape[1]:
",1
"        # integrate speaker embedding
        if self.spk_embed_dim is not None:
            hs = self._integrate_with_spk_embed(hs, spembs)

        # thin out frames for reduction factor (B, Lmax, odim) ->  (B, Lmax//r, odim)
",1
"        if self.reduction_factor > 1:
            ys_in = ys[:, self.reduction_factor - 1 :: self.reduction_factor]
            olens_in = olens.new([olen // self.reduction_factor for olen in olens])
        else:
",1
"            after_outs = before_outs
        else:
",1
"            after_outs = before_outs + self.postnet(
                before_outs.transpose(1, 2)
            ).transpose(1, 2)

        # modifiy mod part of groundtruth
",1
"            olens = olens.new([olen - olen % self.reduction_factor for olen in olens])
",1
"                att_ws = []
",1
"                            :, : self.num_heads_applied_guided_attn
",1
"                    ]
                    if idx + 1 == self.num_layers_applied_guided_attn:
                        break
                att_ws = torch.cat(att_ws, dim=1)  # (B, H*L, T_out, T_in)
                enc_dec_attn_loss = self.attn_criterion(att_ws, ilens, olens_in)
",1
"        # forward encoder
        xs = x.unsqueeze(0)
        hs, _ = self.encoder(xs, None)
",1
"
            # update next inputs
            ys = torch.cat(
                (ys, outs[-1][-1].view(1, 1, self.odim)), dim=1
            )  # (1, idx + 1, odim)
",1
"
        Returns:
            dict: Dict of attention weights and outputs.
",1
"
        """"""
        with torch.no_grad():
            # forward encoder
            x_masks = self._source_mask(ilens)
",1
"            # forward decoder
",1
"                    after_outs = before_outs + self.postnet(
                        before_outs.transpose(1, 2)
",1
"                att_ws_dict[""before_postnet_fbank""] = before_outs
",1
"                    m[:l].T for m, l in zip(after_outs, olens.tolist())
",1
"        Returns:
",1
"            # apply projection and then add to hidden states
",1
"            hs = self.projection(torch.cat([hs, spembs], dim=-1))
        else:
            raise NotImplementedError(""support only add or concat."")

",1
"
        Returns:
",1
"                     [1, 1, 1, 0, 0],
                     [1, 1, 1, 0, 0]]], dtype=torch.uint8)

        """"""
",1
"        also `loss.png` will be created as a figure visulizing `main/loss`
        and `validation/main/loss` values.

",1
"        Returns:
",1
"            if ""encoder"" in self.modules_applied_guided_attn:
                plot_keys += [""enc_attn_loss""]
            if ""decoder"" in self.modules_applied_guided_attn:
",1
"
""""""RNN sequence-to-sequence speech translation model (pytorch).""""""
",1
"
from __future__ import division

import argparse
import copy
",1
"import logging
",1
"import editdistance
import nltk

import chainer
import numpy as np
",1
"        cer_ctc,
        cer,
        wer,
        bleu,
        mtl_loss,
",1
"class E2E(STInterface, torch.nn.Module):
    """"""E2E module.
",1
"    def encoder_add_arguments(parser):
        """"""Add arguments for the encoder.""""""
        group = parser.add_argument_group(""E2E encoder setting"")
",1
"        # encoder
        group.add_argument(
            ""--etype"",
            default=""blstmp"",
            type=str,
",1
"            choices=[
                ""lstm"",
                ""blstm"",
                ""lstmp"",
",1
"        )
        group.add_argument(
            ""--subsample"",
",1
"    def attention_add_arguments(parser):
        """"""Add arguments for the attention.""""""
        group = parser.add_argument_group(""E2E attention setting"")
",1
"                ""noatt"",
",1
"                           (negative value indicates no location-aware attention)"",
        )
        group.add_argument(
            ""--dropout-rate"",
            default=0.0,
",1
"            type=float,
            help=""Dropout rate for the encoder"",
        )
        return parser

",1
"            default=0.0,
            type=float,
            help=""Ratio of predicted labels fed back to decoder"",
        )
        group.add_argument(
",1
"
        # label smoothing info
        if args.lsm_type and os.path.isfile(args.train_json):
",1
"        self.att = att_for(args)
        # decoder (ST)
        self.dec = decoder_for(args, odim, self.sos, self.eos, self.att, labeldist)

        # submodule for ASR task
",1
"            self.report_wer = False
        if args.report_bleu:
            trans_args = {
",1
"            self.report_bleu = args.report_bleu
        else:
            self.report_bleu = False
",1
"        chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
        pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)
        however, there are two exceptions as far as I know.
        - EmbedID.W ~ Normal(0, 1)
        - LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)
",1
"        """"""
        lecun_normal_init_parameters(self)
        # exceptions
",1
"        # embed weight ~ Normal(0, 1)
        self.dec.embed.weight.data.normal_(0, 1)
        # forget-bias = 1.0
        # https://discuss.pytorch.org/t/set-forget-gate-bias-of-lstm/1745
        for i in six.moves.range(len(self.dec.decoder)):
",1
"
",1
"            self.loss_asr, acc_asr, _ = self.dec_asr(hs_pad, hlens, ys_pad_src)
            self.acc_asr = acc_asr

        # 3. MT attention loss
",1
"        if self.mt_weight == 0:
",1
"            self.loss_mt = 0.0
            self.acc_mt = 0.0
        else:
",1
"            cers = []

            y_hats = self.ctc.argmax(hs_pad).data
            for i, y in enumerate(y_hats):
                y_hat = [x[0] for x in groupby(y)]
",1
"                if len(ref_chars) > 0:
",1
"            cer_ctc = sum(cers) / len(cers) if cers else None

        # 5. compute cer/wer
",1
"                self.asr_weight > 0 and self.mtlalpha > 0
            ) and self.recog_args.ctc_weight > 0.0:
                lpz = self.ctc.log_softmax(hs_pad).data
            else:
",1
"            word_eds, word_ref_lens, char_eds, char_ref_lens = [], [], [], []
",1
"            for i, y_hat in enumerate(y_hats):
                y_true = ys_pad[i]

                seq_hat = [self.char_list[int(idx)] for idx in y_hat if int(idx) != -1]
",1
"            cer = (
                0.0
                if not self.report_cer
",1
"            bleu = 0.0
",1
"            nbest_hyps = self.dec.recognize_beam_batch(
                hs_pad,
                torch.tensor(hlens),
",1
"                self.trans_args,
                self.char_list,
                self.rnnlm,
",1
"                bleus.append(bleu)

            bleu = 0.0 if not self.report_bleu else sum(bleus) / len(bleus)
",1
"        """"""Encode acoustic features.

",1
"        # subsample frame
",1
"        lpz = None

        # 2. Decoder
        hlens = torch.tensor(list(map(int, hlens)))  # make sure hlens is tensor
        y = self.dec.recognize_beam_batch(
",1
"    def calculate_all_attentions(self, xs_pad, ilens, ys_pad, ys_pad_src):
        """"""E2E attention calculation.

",1
"            1) multi-head case => attention weights (B, H, Lmax, Tmax),
            2) other case => attention weights (B, Lmax, Tmax).
",1
"        return h, ilen
#!/usr/bin/env python3

""""""Define e2e module for multi-encoder network. https://arxiv.org/pdf/1811.04903.pdf.""""""
# Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
"import os
",1
"from espnet.nets.pytorch_backend.nets_utils import to_torch_tensor
from espnet.nets.pytorch_backend.rnn.attentions import att_for
from espnet.nets.pytorch_backend.rnn.decoders import decoder_for
",1
"

class Reporter(chainer.Chain):
    """"""Define a chainer reporter wrapper.""""""
",1
"        reporter.report({""loss"": mtl_loss}, self)

",1
"
class E2E(ASRInterface, torch.nn.Module):
    """"""E2E module.

    :param List idims: List of dimensions of inputs
",1
"            type=str,
            choices=[
                ""lstm"",
                ""blstm"",
",1
"                ""lstmp"",
",1
"                ""blstmp"",
                ""vgglstmp"",
                ""vggblstmp"",
",1
"                ""bgrup"",
                ""vgggrup"",
                ""vggbgrup"",
                ""vgggru"",
                ""vggbgru"",
",1
"            ],
            help=""Type of encoder network architecture"",
        )
        group.add_argument(
            ""--elayers"",
",1
"            help=""Number of encoder layers ""
            ""(for shared recognition part in multi-speaker asr mode)"",
        )
        group.add_argument(
            ""--eunits"",
",1
"            ""--awin"",
",1
"        group.add_argument(
            ""--han-type"",
",1
"            default=""dot"",
            type=str,
",1
"            choices=[
                ""noatt"",
                ""dot"",
                ""add"",
                ""location"",
",1
"                ""coverage"",
                ""coverage_location"",
",1
"                ""location2d"",
                ""location_recurrent"",
                ""multi_head_dot"",
                ""multi_head_add"",
                ""multi_head_loc"",
",1
"                ""multi_head_multi_res_loc"",
            ],
            help=""Type of attention architecture (multi-encoder asr mode only)"",
",1
"            ""--han-win"",
            default=5,
            type=int,
            help=""Window size for location2d attention in HAN"",
",1
"        )
",1
"            type=str,
",1
"        )
        group.add_argument(
            ""--dropout-rate-decoder"",
            default=0.0,
",1
"            help=""Ratio of predicted labels fed back to decoder"",
        )
        group.add_argument(
            ""--lsm-type"",
            const="""",
",1
"            type=float,
            action=""append"",
            help=""ctc weight assigned to each encoder during training."",
        )
",1
"
    def __init__(self, idims, odim, args):
",1
"        """"""Initialize this class with python-level args.

        Args:
            idims (list): list of the number of an input feature dim.
            odim (int): The number of output vocab.
",1
"        self.mtlalpha = args.mtlalpha
        assert 0.0 <= self.mtlalpha <= 1.0, ""mtlalpha should be [0.0, 1.0]""
        self.verbose = args.verbose
",1
"            args, ""replace_sos"", False
        )  # use getattr to keep compatibility

",1
"            self.weights_ctc_dec = [1.0]
            self.weights_ctc_train = [1.0]
",1
"
        # weight initialization
        self.init_like_chainer()
",1
"
    def init_like_chainer(self):
        """"""Initialize weight like chainer.
",1
"            tgt_lang_ids = ys_pad[:, 0:1]
",1
"                ctc_idx = 0 if self.share_ctc else idx
                loss_ctc = self.ctc[ctc_idx](hs_pad, hlens, ys_pad)
                self.loss_ctc_list.append(loss_ctc)
",1
"            for ind in range(self.num_encs):
                cers = []
                ctc_idx = 0 if self.share_ctc else ind
                y_hats = self.ctc[ctc_idx].argmax(hs_pad_list[ind]).data
",1
"                    y_true = ys_pad[i]

                    seq_hat = [
                        self.char_list[int(idx)] for idx in y_hat if int(idx) != -1
",1
"                    ]
",1
"                    seq_true = [
                        self.char_list[int(idx)] for idx in y_true if int(idx) != -1
                    ]
",1
"                        cers.append(
                            editdistance.eval(hyp_chars, ref_chars) / len(ref_chars)
                        )

                cer_ctc = sum(cers) / len(cers) if cers else None
",1
"                cer_ctc_list.append(cer_ctc)
",1
"            ]

        # 5. compute cer/wer
        if self.training or not (self.report_cer or self.report_wer):
            cer, wer = 0.0, 0.0
",1
"                lpz_list = None

            word_eds, word_ref_lens, char_eds, char_ref_lens = [], [], [], []
",1
"            wer = (
",1
"                else float(sum(char_eds)) / sum(char_ref_lens)
            )

        alpha = self.mtlalpha
        if alpha == 0:
",1
"                    ]
                )
            )
            loss_att_data = None
            loss_ctc_data_list = [float(self.loss)] + [
",1
"                        (item * self.weights_ctc_train[i]).unsqueeze(0)
",1
"        loss_data = float(self.loss)
        if loss_data < CTC_LOSS_THRESHOLD and not math.isnan(loss_data):
            self.reporter.report(
",1
"                loss_att_data,
                acc,
                cer_ctc_list,
",1
"                loss_data,
            )
        else:
            logging.warning(""loss (=%f) is not correct"", loss_data)
",1
"            dict[str, ScorerInterface]: dict of `ScorerInterface` objects
",1
"
        Args:
            x_list (list): input feature [(T1, D), (T2, D), ... ]
        Returns:
            list
",1
"                encoded feature [(T1, D), (T2, D), ... ]

        """"""
        self.eval()
        ilens_list = [[x_list[idx].shape[0]] for idx in range(self.num_encs)]
",1
"
        # subsample frame
",1
"            x_list[idx][:: self.subsample_list[idx][0], :]
            for idx in range(self.num_encs)
        ]
",1
"        # make a utt list (1) to use the same interface for encoder
        xs_list = [
            x_list[idx].contiguous().unsqueeze(0) for idx in range(self.num_encs)
        ]
",1
"            hs, _, _ = self.enc[idx](xs_list[idx], ilens_list[idx])
            hs_list.append(hs[0])
        return hs_list
",1
"        :return: N-best decoding results
",1
"                    self.ctc[idx].log_softmax(hs_list[idx].unsqueeze(0))[0]
                    for idx in range(self.num_encs)
                ]
        else:
            lpz_list = None
",1
"        :param torch.nn.Module rnnlm: language model module
        :return: N-best decoding results
        :rtype: list
        """"""
",1
"        else:
",1
"
        if prev:
            self.train()
        return y

",1
"        :param List xs_pad_list: list of batch (torch.Tensor) of padded input sequences
                                [(B, Tmax_1, idim), (B, Tmax_2, idim),..]
        :param List ilens_list:
",1
"
            # 2. Decoder
            att_ws = self.dec.calculate_all_attentions(
",1
"import logging
",1
"import math

import torch

",1
"from espnet.nets.pytorch_backend.ctc import CTC
",1
"from espnet.nets.pytorch_backend.transformer.label_smoothing_loss import (
    LabelSmoothingLoss,  # noqa: H301
)
",1
"
    :param int idim: dimension of inputs
    :param int odim: dimension of outputs
    :param Namespace args: argument Namespace containing options

",1
"        # Encoder
",1
"            type=int,
            help=""Number of heads for multi head attention"",
        )
",1
"        )
        return parser

    @property
    def attention_plot_class(self):
",1
"        :param Namespace args: argument Namespace containing options
        """"""
        torch.nn.Module.__init__(self)
        if args.transformer_attn_dropout_rate is None:
            args.transformer_attn_dropout_rate = args.dropout_rate
",1
"        )
        self.decoder = Decoder(
            odim=odim,
",1
"            positional_dropout_rate=args.dropout_rate,
            self_attention_dropout_rate=args.transformer_attn_dropout_rate,
            src_attention_dropout_rate=args.transformer_attn_dropout_rate,
",1
"            assert self.replace_sos

",1
"        tgt_lang_ids = None
        if self.multilingual:
",1
"
        # 1. forward encoder
",1
"        # replace <sos> with target language ID
",1
"        if self.replace_sos:
            ys_in_pad = torch.cat([tgt_lang_ids, ys_in_pad[:, 1:]], dim=1)
        ys_mask = target_mask(ys_in_pad, self.ignore_id)
        pred_pad, pred_mask = self.decoder(ys_in_pad, ys_mask, hs_pad, hs_mask)
        self.pred_pad = pred_pad
",1
"            ys_zero_pad_src = ys_zero_pad_src[:, : max(ilens_mt)]  # for data parallel
",1
"            # ys_zero_pad_src, ys_pad = self.target_forcing(ys_zero_pad_src, ys_pad)
            hs_pad_mt, hs_mask_mt = self.encoder_mt(ys_zero_pad_src, src_mask_mt)
            # forward MT decoder
            pred_pad_mt, _ = self.decoder(ys_in_pad, ys_mask, hs_pad_mt, hs_mask_mt)
",1
"            # compute loss
            loss_mt = self.criterion(pred_pad_mt, ys_out_pad)

        self.acc = th_accuracy(
            pred_pad.view(-1, self.odim), ys_out_pad, ignore_label=self.ignore_id
",1
"            )
        else:
            self.acc_asr = 0.0
        if pred_pad_mt is not None:
",1
"            y = self.sos
",1
"        logging.info(""<sos> index: "" + str(y))
",1
"        logging.info(""<sos> mark: "" + char_list[y])

        enc_output = self.encode(x).unsqueeze(0)
        h = enc_output.squeeze(0)
",1
"        logging.info(""max output length: "" + str(maxlen))
        logging.info(""min output length: "" + str(minlen))

        # initialize hypothesis
",1
"        if rnnlm:
            hyp = {""score"": 0.0, ""yseq"": [y], ""rnnlm_prev"": None}
        else:
",1
"
                if rnnlm:
                    rnnlm_state, local_lm_scores = rnnlm.predict(hyp[""rnnlm_prev""], vy)
                    local_scores = (
",1
"            # add eos in the final loop to avoid that there are no ended hyps
",1
"                    if len(hyp[""yseq""]) > minlen:
                        hyp[""score""] += (i + 1) * penalty
                        if rnnlm:  # Word LM needs to add final <eos> score
",1
"            ""normalized log probability: ""
            + str(nbest_hyps[0][""score""] / len(nbest_hyps[0][""yseq""]))
        )
        return nbest_hyps
",1
"        :return: attention weights with the following shape,
            1) multi-head case => attention weights (B, H, Lmax, Tmax),
            2) other case => attention weights (B, Lmax, Tmax).
        :rtype: float ndarray
        """"""
",1
"# -*- coding: utf-8 -*-

""""""Network related utility tools.""""""
",1
"    """"""Send tensor into the device of the module.

    Args:
        m (torch.nn.Module): Torch module.
",1
"        x (Tensor): Torch tensor.
",1
"        lengths (LongTensor or List): Batch of lengths (B,).
        xs (Tensor, optional): The reference tensor.
            If set, masks will be the same shape as this tensor.
",1
"        >>> make_non_pad_mask(lengths)
        masks = [[0, 0, 0, 0 ,0],
",1
"                 [0, 0, 0, 0]],
                [[0, 0, 0, 1],
                 [0, 0, 0, 1]],
                [[0, 0, 1, 1],
                 [0, 0, 1, 1]]], dtype=torch.uint8)
",1
"        >>> xs = torch.zeros((3, 2, 6))
        >>> make_pad_mask(lengths, xs)
        tensor([[[0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1]],
                [[0, 0, 0, 1, 1, 1],
",1
"                 [1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)
        >>> make_pad_mask(lengths, xs, 2)
        tensor([[[0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1],
",1
"                 [0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1],
                 [0, 0, 0, 0, 0, 1]],
                [[0, 0, 0, 1, 1, 1],
                 [0, 0, 0, 1, 1, 1],
",1
"                 [0, 0, 1, 1, 1, 1],
",1
"                 [0, 0, 1, 1, 1, 1],
                 [0, 0, 1, 1, 1, 1],
                 [0, 0, 1, 1, 1, 1]]], dtype=torch.uint8)

",1
"        # ind = (:, None, ..., None, :, , None, ..., None)
        ind = tuple(
            slice(None) if i in (0, length_dim) else None for i in range(xs.dim())
        )
        mask = mask[ind].expand_as(xs).to(xs.device)
",1
"
    Args:
        lengths (LongTensor or List): Batch of lengths (B,).
",1
"            See the example.

    Returns:
        ByteTensor: mask tensor containing indices of padded part.
                    dtype=torch.uint8 in PyTorch 1.2-
",1
"
        With the reference tensor.

",1
"
        With the reference tensor and dimension indicator.

        >>> xs = torch.zeros((3, 6, 6))
        >>> make_non_pad_mask(lengths, xs, 1)
",1
"                 [1, 1, 1, 1, 1, 1],
                 [1, 1, 1, 1, 1, 1],
                 [0, 0, 0, 0, 0, 0],
",1
"    """"""
",1
"
    Returns:
        Tensor: Batch of masked input tensor (B, `*`).

",1
"        >>> x = torch.arange(5).repeat(3, 1) + 1
        >>> x
        tensor([[1, 2, 3, 4, 5],
                [1, 2, 3, 4, 5],
                [1, 2, 3, 4, 5]])
",1
"        pad_outputs (Tensor): Prediction tensors (B * Lmax, D).
",1
"
    Returns:
        Tensor or ComplexTensor: Type converted inputs.

",1
"        >>> to_torch_tensor(xs)
        ComplexTensor(
        Real:
        tensor([1., 1., 1.])
        Imag;
",1
"
    # If {'real': ..., 'imag': ...}, convert to ComplexTensor
    elif isinstance(x, dict):
        # Dynamically importing because torch_complex requires python3
        from torch_complex.tensor import ComplexTensor
",1
"            # If PY2
            raise ValueError(error)
        else:
            # If PY3
            if isinstance(x, ComplexTensor):
",1
"        logging.info(""subsample: "" + "" "".join([str(x) for x in subsample]))
        return subsample

",1
"            )
        logging.info(""subsample: "" + "" "".join([str(x) for x in subsample]))
        return subsample

",1
"    elif mode == ""asr"" and arch == ""rnn_mulenc"":
        subsample_list = []
        for idx in range(train_args.num_encs):
            subsample = np.ones(train_args.elayers[idx] + 1, dtype=np.int)
",1
"                idx
            ].startswith(""vgg""):
                ss = train_args.subsample[idx].split(""_"")
                for j in range(min(train_args.elayers[idx] + 1, len(ss))):
",1
"                    subsample[j] = int(ss[j])
            else:
                logging.warning(
                    ""Encoder %d: Subsampling is not performed for vgg*. ""
                    ""It is performed in max pooling layers at CNN."",
",1
"
# Copyright 2019 Kyoto University (Hirofumi Inaguma)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"import torch

from espnet.nets.e2e_asr_common import label_smoothing_dist
",1
"    def report(self, loss, acc, ppl, bleu):
        """"""Report at every step.""""""
        reporter.report({""loss"": loss}, self)
        reporter.report({""acc"": acc}, self)
",1
"    @staticmethod
    def add_arguments(parser):
        """"""Add arguments.""""""
        E2E.encoder_add_arguments(parser)
        E2E.attention_add_arguments(parser)
",1
"        return parser

    @staticmethod
    def encoder_add_arguments(parser):
",1
"                ""vggblstm"",
                ""gru"",
                ""bgru"",
",1
"        group.add_argument(
            ""--eunits"",
            ""-u"",
",1
"            ""--eprojs"", default=320, type=int, help=""Number of encoder projection units""
",1
"        return parser

    @staticmethod
    def attention_add_arguments(parser):
",1
"        """"""Add arguments for the attention.""""""
",1
"                ""multi_head_dot"",
                ""multi_head_add"",
                ""multi_head_loc"",
                ""multi_head_multi_res_loc"",
            ],
",1
"            help=""Type of attention architecture"",
        )
        group.add_argument(
",1
"        )
",1
"
    @staticmethod
    def decoder_add_arguments(parser):
        """"""Add arguments for the decoder.""""""
        group = parser.add_argument_group(""E2E encoder setting"")
",1
"            ""--dlayers"", default=1, type=int, help=""Number of decoder layers""
",1
"            default=0.0,
",1
"        )
        return parser

",1
"        :param Namespace args: argument Namespace containing options

",1
"        """"""
        super(E2E, self).__init__()
        torch.nn.Module.__init__(self)
",1
"        # below means the last number becomes eos/sos ID
        # note that sos/eos IDs are identical
        self.sos = odim - 1
        self.eos = odim - 1
        self.pad = 0
",1
"            if idim != odim:
                raise ValueError(
                    ""When using tie_src_tgt_embedding, idim and odim must be equal.""
                )
",1
"            if args.eunits != args.dunits:
                raise ValueError(
                    ""When using tie_src_tgt_embedding, eunits and dunits must be equal.""
                )
            self.embed.weight = self.dec.embed.weight
",1
"            if args.context_residual:
",1
"        if args.report_bleu:
            trans_args = {
                ""beam_size"": args.beam_size,
",1
"
",1
"        """"""
        uniform_init_parameters(self)
        # exceptions
        # embed weight ~ Normal(-0.1, 0.1)
",1
"        torch.nn.init.constant_(self.dec.embed.weight[self.pad], 0)

    def forward(self, xs_pad, ilens, ys_pad):
        """"""E2E forward.

",1
"        :param torch.Tensor ys_pad:
            batch of padded character id sequence tensor (B, Lmax)
        :return: loss value
        :rtype: torch.Tensor
        """"""
",1
"        # 1. Encoder
        xs_pad, ys_pad = self.target_language_biasing(xs_pad, ilens, ys_pad)
        hs_pad, hlens, _ = self.enc(self.dropout(self.embed(xs_pad)), ilens)
",1
"                hs_pad,
",1
"                y_true = ys_pad[i]

                seq_hat = [self.char_list[int(idx)] for idx in y_hat if int(idx) != -1]
",1
"                bleus.append(bleu)

            bleu = 0.0 if not self.report_bleu else sum(bleus) / len(bleus)

        self.loss = loss
",1
"
        loss_data = float(self.loss)
        if not math.isnan(loss_data):
            self.reporter.report(loss_data, acc, ppl, bleu)
        else:
",1
"        """"""Prepend target language IDs to source sentences for multilingual NMT.

        These tags are prepended in source/target sentences as pre-processing.
",1
"            tgt_lang_ids = ys_pad[:, 0].unsqueeze(1)
            xs_pad = xs_pad[:, 1:]  # remove source language IDs here
            ys_pad = ys_pad[:, 1:]

            # prepend target language ID to source sentences
",1
"        :return: N-best decoding results
        :rtype: list
        """"""
        prev = self.training
        self.eval()
",1
"
        # 1. encoder
",1
"        # make a utt list (1) to use the same interface for encoder
        if self.multilingual:
            ilen = [len(x[0][1:])]
            h = to_device(
",1
"                self, torch.from_numpy(np.fromiter(map(int, x[0][1:]), dtype=np.int64))
            )
",1
"        self.eval()

        # 1. Encoder
",1
"        hs_pad, hlens, _ = self.enc(self.dropout(self.embed(xpad)), ilens)
",1
"
        # 2. Decoder
        hlens = torch.tensor(list(map(int, hlens)))  # make sure hlens is tensor
",1
"        :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
        :param torch.Tensor ilens: batch of lengths of input sequences (B)
        :param torch.Tensor ys_pad:
            batch of padded character id sequence tensor (B, Lmax)
",1
"import torch

",1
"from espnet.nets.asr_interface import ASRInterface
from espnet.nets.pytorch_backend.nets_utils import get_subsample
",1
"from espnet.nets.pytorch_backend.transducer.utils import prepare_loss_inputs
from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention
from espnet.nets.pytorch_backend.transformer.encoder import Encoder
from espnet.nets.pytorch_backend.transformer.mask import target_mask

",1
"        group = parser.add_argument_group(""transformer model setting"")

        # Encoder - general
        group.add_argument(
            ""--etype"",
",1
"                ""blstm"",
",1
"                ""vgglstm"",
                ""vggblstm"",
                ""gru"",
",1
"            help=""Number of encoder layers (for shared recognition part ""
            ""in multi-speaker asr mode)"",
        )
        group.add_argument(
            ""--eunits"",
",1
"            ""--subsample"",
            default=""1"",
",1
"            ""at 1st layer, every y frame at 2nd layer etc."",
        )
        # Attention - general
",1
"                ""multi_head_loc"",
                ""multi_head_multi_res_loc"",
            ],
            help=""Type of attention architecture"",
        )
",1
"            ""--awin"", default=5, type=int, help=""Window size for location2d attention""
        )
        group.add_argument(
",1
"        )
        group.add_argument(
            ""--dropout-rate-decoder"",
            default=0.0,
            type=float,
",1
"        )
        group.add_argument(
",1
"            default=""pytorch"",
            choices=[
                ""pytorch"",
                ""xavier_uniform"",
                ""xavier_normal"",
",1
"            type=str,
            default=""embed"",
            choices=[""linear"", ""embed""],
            help=""transformer decoder input layer type"",
",1
"        )
        group.add_argument(
",1
"            type=str,
",1
"        )
",1
"        self.etype = args.etype
        self.dtype = args.dtype
        self.rnnt_mode = args.rnnt_mode

",1
"        self.criterion = TransLoss(args.trans_type, self.blank_id)
",1
"
            if self.dtype == ""transformer"":
",1
"        else:
            self.error_calculator = None

",1
"
",1
"            loss (torch.Tensor): transducer loss value

        """"""
        # 1. encoder
",1
"        if self.etype == ""transformer"":
            xs_pad = xs_pad[:, : max(ilens)]
            src_mask = make_non_pad_mask(ilens.tolist()).to(xs_pad.device).unsqueeze(-2)
",1
"
        # 1.5. transducer preparation related
        ys_in_pad, target, pred_len, target_len = prepare_loss_inputs(ys_pad, hs_mask)

",1
"        loss_data = float(self.loss)
",1
"
        Args:
            x (ndarray): input acoustic feature (T, D)
",1
"        x = x[:: self.subsample[0], :]
        h = to_device(self, to_torch_tensor(x).float())
        hs = h.contiguous().unsqueeze(0)

        h, _, _ = self.enc(hs, ilens)
",1
"        return h[0]

    def recognize(self, x, recog_args, char_list=None, rnnlm=None):
        """"""Recognize input features.

",1
"                nbest_hyps = self.dec.recognize(*params)
        else:
            params.append(rnnlm)
            if self.dtype == ""transformer"":
",1
"                nbest_hyps = self.decoder.recognize_beam(*params)
            else:
                nbest_hyps = self.dec.recognize_beam(*params)

        return nbest_hyps
",1
"                return []
            else:
",1
"            with torch.no_grad():
",1
"import logging

",1
"import numpy as np
",1
"import torch.nn.functional as F

from espnet.nets.pytorch_backend.nets_utils import to_device
",1
"        super().__init__()
        self.dropout_rate = dropout_rate
        self.loss = None
        self.ctc_lo = torch.nn.Linear(eprojs, odim)

",1
"        self.ctc_type = (
            ctc_type
",1
"            self.ctc_loss = warp_ctc.CTCLoss(size_average=True, reduce=reduce)
        else:
            raise ValueError(
",1
"        self.reduce = reduce

    def loss_fn(self, th_pred, th_target, th_ilen, th_olen):
        if self.ctc_type == ""builtin"":
            th_pred = th_pred.log_softmax(2)
",1
"        else:
            raise NotImplementedError
",1
"        """"""
        # TODO(kan-bayashi): need to make more smart way
        ys = [y[y != self.ignore_id] for y in ys_pad]  # parse padded ys

",1
"        logging.info(
            self.__class__.__name__
            + "" output lengths: ""
",1
"        )
        if self.reduce:
            # NOTE: sum() is needed to keep consistency
            # since warpctc return as tensor w/ shape (1,)
            # but builtin return as tensor w/o shape (scalar).
",1
"        return self.loss

    def log_softmax(self, hs_pad):
",1
"            ctc = CTC(
                odim,
                args.eprojs,
",1
"                ctc = CTC(
",1
"                    ctc_type=args.ctc_type,
                    reduce=reduce,
                )
                ctcs_list.append(ctc)
",1
"
Copyright 2017 Johns Hopkins University (Shinji Watanabe)
",1
" Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
""""""

",1
"
",1
"import chainer
from chainer import reporter
import editdistance
import numpy as np
",1
"    feature_transform_for,  # noqa: H301
)
",1
"            raise ValueError

",1
"
        loss_perm = torch.stack([r[0] for r in ret], dim=0).to(losses.device)  # (B)
",1
"        group.add_argument(
            ""--elayers-sd"",
",1
"            type=int,
            help=""Number of speaker differentiate encoder layers""
            ""for multi-speaker speech recognition task."",
        )
        return parser
",1
"        self.spa = args.spa
        self.pit = PIT(self.num_spkrs)

        # below means the last number becomes eos/sos ID
",1
"        else:
            labeldist = None
",1
"        # encoder
        self.enc = encoder_for(args, idim, self.subsample)
",1
"                ""maxlenratio"": args.maxlenratio,
                ""minlenratio"": args.minlenratio,
                ""lm_weight"": args.lm_weight,
                ""rnnlm"": args.rnnlm,
                ""nbest"": args.nbest,
",1
"        - EmbedID.W ~ Normal(0, 1)
        - LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)
        """"""

",1
"        :param torch.Tensor ilens: batch of lengths of input sequences (B)
        :param torch.Tensor ys_pad:
",1
"            else:  # multi-speaker input xs_pad
                ys_pad = ys_pad.transpose(0, 1)  # (num_spkrs, B, Lmax)
                loss_ctc_perm = torch.stack(
                    [
",1
"                )  # (B, num_spkrs^2)
                loss_ctc, min_perm = self.pit.pit_process(loss_ctc_perm)
                logging.info(""ctc loss:"" + str(float(loss_ctc)))

        # 3. attention loss
",1
"        else:
            if not isinstance(hs_pad, list):  # single-speaker input xs_pad
                loss_att, acc, _ = self.dec(hs_pad, hlens, ys_pad)
",1
"                    self.recog_args,
",1
"                for i in range(self.num_spkrs)
            ]
            for i in range(len(y_hats[0])):
                hyp_words = []
                hyp_chars = []
",1
"                char_ref_lens.append(len("""".join(ref_chars)))

",1
"        if loss_data < CTC_LOSS_THRESHOLD and not math.isnan(loss_data):
            self.reporter.report(loss_ctc_data, loss_att_data, acc, cer, wer, loss_data)
        else:
            logging.warning(""loss (=%f) is not correct"", loss_data)
",1
"        """"""
        prev = self.training
        self.eval()
        ilens = [x.shape[0]]
",1
"            hs, hlens, mask = self.frontend(hs, ilens)
            hlens_n = [None] * self.num_spkrs
            for i in range(self.num_spkrs):
                hs[i], hlens_n[i] = self.feature_transform(hs[i], hlens)
            hlens = hlens_n
",1
"        else:
",1
"            hs, hlens = hs, ilens

        # 1. Encoder
        if not isinstance(hs, list):  # single-channel multi-speaker input x
",1
"            hs, hlens, _ = self.enc(hs, hlens)
        else:  # multi-channel multi-speaker input x
            for i in range(self.num_spkrs):
                hs[i], hlens[i], _ = self.enc(hs[i], hlens[i])

",1
"        # 2. decoder
        # decode the first utterance
        y = [
            self.dec.recognize_beam(
",1
"    def recognize_batch(self, xs, recog_args, char_list, rnnlm=None):
        """"""E2E beam search.

",1
"                hs_pad[i],
                hlens[i],
                lpz[i],
                recog_args,
",1
"        return y

    def enhance(self, xs):
        """"""Forward only the frontend stage.
",1
"        ilens = np.fromiter((xx.shape[0] for xx in xs), dtype=np.int64)

",1
"            enhanced = list(enhanced)
            mask = list(mask)
            for idx in range(len(enhanced)):  # number of speakers
                enhanced[idx] = enhanced[idx].cpu().numpy()
",1
"                            ys_pad[i % self.num_spkrs],
                        )
",1
"    :param int in_channel: number of input channels
",1
"        elayers_sd,
",1
"        in_channel=1,
    ):
        """"""Initialize the encoder of single-channel multi-speaker ASR.""""""
",1
"                    [
                        torch.nn.ModuleList(
                            [
                                RNNP(
",1
"                        for i in range(num_spkrs)
",1
"                            dropout,
                            typ=typ,
                        )
                    ]
",1
"                    f""Illegal name {etype}""
                )
",1
"
        # SD and Rec encoder
        xs_pad_sd = [xs_pad for i in range(self.num_spkrs)]
        ilens_sd = [ilens for i in range(self.num_spkrs)]
        for ns in range(self.num_spkrs):
",1
"            idim,
            args.elayers_sd,
            args.elayers,
            args.eunits,
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""FastSpeech related modules.""""""

import logging
",1
"
import torch
",1
"import torch.nn.functional as F

",1
"from espnet.asr.asr_utils import torch_load
from espnet.nets.pytorch_backend.e2e_tts_transformer import TTSPlot
",1
"    DurationCalculator,  # noqa: H301
)
",1
"from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask
from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
from espnet.nets.pytorch_backend.tacotron2.decoder import Postnet
from espnet.nets.pytorch_backend.transformer.attention import MultiHeadedAttention
",1
"from espnet.nets.pytorch_backend.transformer.initializer import initialize
from espnet.nets.tts_interface import TTSInterface
from espnet.utils.cli_utils import strtobool
from espnet.utils.fill_missing_args import fill_missing_args

",1
"    """"""Loss function module for feed-forward Transformer.""""""

    def __init__(self, use_masking=True, use_weighted_masking=False):
",1
"        super(FeedForwardTransformerLoss, self).__init__()
        assert (use_masking != use_weighted_masking) or not use_masking
",1
"            )
            ys = ys.masked_select(out_masks)

",1
"        # calculate loss
        l1_loss = self.l1_criterion(before_outs, ys)
        if after_outs is not None:
            l1_loss += self.l1_criterion(after_outs, ys)
        duration_loss = self.duration_criterion(d_outs, ds)
",1
"            out_weights = out_masks.float() / out_masks.sum(dim=1, keepdim=True).float()
",1
"                duration_masks.float() / duration_masks.sum(dim=1, keepdim=True).float()
            )
",1
"    """"""Feed Forward Transformer for TTS a.k.a. FastSpeech.

    This is a module of FastSpeech,
    feed-forward Transformer with duration predictor described in
",1
"            ""--adim"",
            default=384,
            type=int,
            help=""Number of attention transformation dimensions"",
        )
",1
"        group.add_argument(
",1
"        group.add_argument(
            ""--elayers"", default=6, type=int, help=""Number of encoder layers""
        )
        group.add_argument(
",1
"        group.add_argument(
            ""--dunits"", default=1536, type=int, help=""Number of decoder hidden units""
        )
        group.add_argument(
",1
"            ""--positionwise-layer-type"",
            default=""linear"",
            type=str,
",1
"            choices=[""linear"", ""conv1d"", ""conv1d-linear""],
",1
"            ""instead of the fixed scale one"",
        )
",1
"            type=strtobool,
            help=""Whether to apply layer norm before encoder block"",
        )
",1
"            ""--decoder-normalize-before"",
            default=False,
",1
"            type=strtobool,
            help=""Whether to apply layer norm before decoder block"",
        )
        group.add_argument(
",1
"        group.add_argument(
            ""--duration-predictor-chans"",
            default=384,
            type=int,
            help=""Number of channels in duration predictor"",
",1
"            default=3,
",1
"        group.add_argument(
",1
"            type=str,
            default=""add"",
            choices=[""add"", ""concat""],
",1
"            default=1.0,
            type=float,
            help=""Initial value of learning rate"",
        )
        group.add_argument(
",1
"        group.add_argument(
            ""--transformer-enc-dropout-rate"",
            default=0.1,
            type=float,
            help=""Dropout rate for transformer encoder except for attention"",
",1
"        )
        group.add_argument(
            ""--transformer-enc-positional-dropout-rate"",
",1
"            default=0.1,
            type=float,
            help=""Dropout rate for transformer encoder-decoder attention"",
        )
",1
"        group.add_argument(
            ""--transferred-encoder-module"",
",1
"                    Whether to perform layer normalization before decoder block.
                - encoder_concat_after (bool): Whether to concatenate attention
",1
"                - spk_embed_dim (int): Number of speaker embedding dimensions.
                - spk_embed_integration_type: How to integrate speaker embedding.
                - teacher_model (str): Teacher auto-regressive transformer model path.
                - reduction_factor (int): Reduction factor.
                - transformer_init (float): How to initialize transformer parameters.
",1
"                - transformer_lr (float): Initial value of learning rate.
                - transformer_warmup_steps (int): Optimizer warmup steps.
                - transformer_enc_dropout_rate (float):
                    Dropout rate in encoder except attention & positional encoding.
",1
"                    Dropout rate in encoder self-attention module.
                - transformer_dec_dropout_rate (float):
                    Dropout rate in decoder except attention & positional encoding.
                - transformer_dec_positional_dropout_rate (float):
                    Dropout rate after decoder positional encoding.
",1
"
        """"""
        # initialize base classes
        TTSInterface.__init__(self)
",1
"
        # get positional encoding class
        pos_enc_class = (
",1
"        # define encoder
        encoder_input_layer = torch.nn.Embedding(
            num_embeddings=idim, embedding_dim=args.adim, padding_idx=padding_idx
",1
"            normalize_before=args.encoder_normalize_before,
            concat_after=args.encoder_concat_after,
            positionwise_layer_type=args.positionwise_layer_type,
",1
"        self.decoder = Encoder(
",1
"            num_blocks=args.dlayers,
            input_layer=None,
            dropout_rate=args.transformer_dec_dropout_rate,
            positional_dropout_rate=args.transformer_dec_positional_dropout_rate,
            attention_dropout_rate=args.transformer_dec_attn_dropout_rate,
",1
"                dropout_rate=args.postnet_dropout_rate,
            )
        )

        # initialize parameters
",1
"
        # define duration calculator
        if self.teacher is not None:
            self.duration_calculator = DurationCalculator(self.teacher)
        else:
",1
"
    def _forward(
        self,
        xs,
",1
"        spembs=None,
        ds=None,
        is_inference=False,
        alpha=1.0,
",1
"            hs = self._integrate_with_spk_embed(hs, spembs)

        # forward duration predictor and length regulator
        d_masks = make_pad_mask(ilens).to(xs.device)
",1
"            hs = self.length_regulator(hs, ds, ilens)  # (B, Lmax, adim)

        # forward decoder
        if olens is not None:
            if self.reduction_factor > 1:
",1
"            ).transpose(1, 2)

        if is_inference:
            return before_outs, after_outs, d_outs
        else:
",1
"        xs = xs[:, : max(ilens)]
        ys = ys[:, : max(olens)]
        if extras is not None:
            extras = extras[:, : max(ilens)].squeeze(-1)
",1
"        # forward propagation
",1
"        before_outs, after_outs, ds, d_outs = self._forward(
            xs, ilens, ys, olens, spembs=spembs, ds=extras, is_inference=False
",1
"        if self.reduction_factor > 1:
",1
"            ys = ys[:, :max_olen]

        # calculate loss
",1
"        ]

        # report extra information
        if self.use_scaled_pos_enc:
",1
"        self.reporter.report(report_keys)

",1
"        """"""
        with torch.no_grad():
            # remove unnecessary padded part (for multi-gpus)
            xs = xs[:, : max(ilens)]
            ys = ys[:, : max(olens)]
",1
"            x (Tensor): Input sequence of characters (T,).
            inference_args (Namespace): Dummy for compatibility.
            spemb (Tensor, optional): Speaker embedding vector (spk_embed_dim).

        Returns:
",1
"        Args:
            hs (Tensor): Batch of hidden state sequences (B, Tmax, adim).
            spembs (Tensor): Batch of speaker embeddings (B, spk_embed_dim).

        Returns:
",1
"            spembs = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)
            hs = self.projection(torch.cat([hs, spembs], dim=-1))
        else:
",1
"        return hs

    def _source_mask(self, ilens):
",1
"        idim, odim, args = get_model_conf(model_path)
",1
"        model_class = dynamic_import(args.model_module)
        model = model_class(idim, odim, args)
        torch_load(model_path, model)
",1
"
        # freeze teacher model parameters
        for p in model.parameters():
            p.requires_grad = False

",1
"
",1
"            self.decoder.embed[-1].alpha.data = torch.tensor(init_dec_alpha)

    def _transfer_from_teacher(self, transferred_encoder_module):
",1
"            )
",1
"        if self.use_scaled_pos_enc:
",1
"    return x
",1
"
    """"""
    if isinstance(m, nn.Conv1d):
",1
"        nn.init.xavier_uniform_(m.weight)
        nn.init.constant_(m.bias, 0.0)

",1
"        Returns:
            Tensor: float tensor variable with the shape (B, depth, T)

        """"""
",1
"        x = x % self.depth
        x = torch.unsqueeze(x, 2)
        x_onehot = x.new_zeros(x.size(0), x.size(1), self.depth).float()

        return x_onehot.scatter_(2, x, 1)
",1
"
",1
"class CausalConv1d(nn.Module):
    """"""1D dilated causal convolution.""""""

",1
"        """"""
        x = self.conv(x)
        if self.padding != 0:
            x = x[:, :, : -self.padding]
",1
"        self.upsampling_factor = upsampling_factor
        self.bias = bias
        self.conv = nn.ConvTranspose2d(
            1,
",1
"            bias=self.bias,
        )

    def forward(self, x):
",1
"        x = x.unsqueeze(1)  # B x 1 x C x T
        x = self.conv(x)  # B x 1 x C x T'
        return x.squeeze(1)

",1
"        n_aux (int): Number of aux feature dimension.
",1
"        n_resch (int): Number of filter channels for residual block.
        n_skipch (int): Number of filter channels for skip connection.
        dilation_depth (int): Number of dilation depth
            (e.g. if set 10, max dilation = 2^(10-1)).
",1
"        upsampling_factor=0,
    ):
        super(WaveNet, self).__init__()
",1
"        ] * self.dilation_repeat
        self.receptive_field = (self.kernel_size - 1) * sum(self.dilations) + 1

        # for preprocessing
",1
"        self.onehot = OneHot(self.n_quantize)
        self.causal = CausalConv1d(self.n_quantize, self.n_resch, self.kernel_size)
",1
"            Tensor: Logits with the shape (B, T, n_quantize).
",1
"            h = self.upsampling(h)
",1
"        Args:
            x (LongTensor): Initial waveform tensor with the shape  (T,).
            h (Tensor): Auxiliary feature tensor with the shape  (n_samples + T, n_aux).
",1
"                self.skip_1x1[i],
                self.res_1x1[i],
            )
            if d == 2 ** (self.dilation_depth - 1):
                buffer_size.append(self.kernel_size - 1)
",1
"        samples = x[0]
        start_time = time.time()
        for i in range(n_samples):
",1
"            for j, d in enumerate(self.dilations):
",1
"                dist = torch.distributions.Categorical(posterior)
                sample = dist.sample().unsqueeze(0)
            elif mode == ""argmax"":
                sample = output.argmax(-1)
            else:
",1
"            # show progress
            if interval is not None and (i + 1) % interval == 0:
                elapsed_time_per_sample = (time.time() - start_time) / interval
                logging.info(
",1
"                    % (
                        i + 1,
                        n_samples,
                        (n_samples - i - 1) * elapsed_time_per_sample,
",1
"        output_sigmoid = dil_sigmoid(x)
        output_tanh = dil_tanh(x)
        aux_output_sigmoid = aux_1x1_sigmoid(h)
        aux_output_tanh = aux_1x1_tanh(h)
",1
"        skip = skip_1x1(output)
",1
"        res_1x1,
    ):
        output_sigmoid = dil_sigmoid(x)[:, :, -1:]
",1
"        output = res_1x1(output)
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"    """"""Initialize encoder parameters.""""""
    if isinstance(m, torch.nn.Conv1d):
        torch.nn.init.xavier_uniform_(m.weight, torch.nn.init.calculate_gain(""relu""))
",1
"
    This is a module of encoder of Spectrogram prediction network in Tacotron2,
    which described in `Natural TTS
    Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions`_.
    This is the encoder which converts the
",1
"
    .. _`Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions`:
",1
"       https://arxiv.org/abs/1712.05884

    """"""
",1
"        use_residual=False,
        dropout_rate=0.5,
",1
"    ):
",1
"        """"""Initialize Tacotron2 encoder module.

        Args:
            idim (int) Dimension of the inputs.
            embed_dim (int, optional) Dimension of character embedding.
",1
"            dropout_rate (float, optional) Dropout rate.

        """"""
",1
"                                padding=(econv_filts - 1) // 2,
                                bias=False,
                            ),
                            torch.nn.BatchNorm1d(econv_chans),
",1
"                                econv_filts,
",1
"                                stride=1,
                                padding=(econv_filts - 1) // 2,
                                bias=False,
",1
"        if elayers > 0:
",1
"        else:
            self.blstm = None
",1
"        """"""Calculate forward propagation.

",1
"            ilens (LongTensor): Batch of lengths of each input batch (B,).
",1
"
        Returns:
",1
"
",1
"        assert len(x.size()) == 1
        xs = x.unsqueeze(0)
        ilens = [x.size(0)]

        return self.forward(xs, ilens)[0][0]
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Tacotron2 decoder related modules.""""""
",1
"

def decoder_init(m):
",1
"
        Args:
",1
"            cell (torch.nn.Module): Pytorch recurrent cell module
",1
"        super(ZoneOutCell, self).__init__()
        self.cell = cell
        self.hidden_size = cell.hidden_size
        self.zoneout_rate = zoneout_rate
",1
"        next_hidden = self._zoneout(hidden, next_hidden, self.zoneout_rate)
        return next_hidden

    def _zoneout(self, h, next_h, prob):
        # apply recursively
",1
"            x = F.dropout(self.prenet[i](x), self.dropout_rate)
",1
"
class Postnet(torch.nn.Module):
",1
"    """"""Postnet module for Spectrogram prediction network.

    This is a module of Postnet in Spectrogram prediction network,
    which described in `Natural TTS Synthesis by
",1
"    The Postnet predicts refines the predicted
    Mel-filterbank of the decoder,
    which helps to compensate the detail sturcture of spectrogram.

",1
"        self,
        idim,
",1
"        odim,
        n_layers=5,
",1
"            idim (int): Dimension of the inputs.
",1
"                    torch.nn.Sequential(
                        torch.nn.Conv1d(
                            ichans,
                            ochans,
                            n_filts,
",1
"                            padding=(n_filts - 1) // 2,
                            bias=False,
                        ),
",1
"                            stride=1,
                            padding=(n_filts - 1) // 2,
                            bias=False,
",1
"                    torch.nn.BatchNorm1d(odim),
                    torch.nn.Dropout(dropout_rate),
                )
            ]
",1
"                    ),
                    torch.nn.Dropout(dropout_rate),
",1
"
",1
"
class Decoder(torch.nn.Module):
    """"""Decoder module of Spectrogram prediction network.

    This is a module of decoder of Spectrogram prediction network in Tacotron2,
",1
"        postnet_chans=512,
        postnet_filts=5,
        output_activation_fn=None,
        cumulate_att_w=True,
        use_batch_norm=True,
",1
"            dunits (int, optional): The number of decoder lstm units.
            prenet_layers (int, optional): The number of prenet layers.
            prenet_units (int, optional): The number of prenet units.
",1
"            postnet_layers (int, optional): The number of postnet layers.
",1
"        self.use_concate = use_concate
        self.reduction_factor = reduction_factor
",1
"        else:
",1
"            self.use_att_extra_inputs = False

",1
"        self.lstm = torch.nn.ModuleList()
        for layer in six.moves.range(dlayers):
",1
"            if zoneout_rate > 0.0:
",1
"
        # define postnet
        if postnet_layers > 0:
            self.postnet = Postnet(
                idim=idim,
",1
"        prev_out = hs.new_zeros(hs.size(0), self.odim)

        # initialize attention
",1
"        prev_att_w = None
        self.att.reset()

        # loop for an output sequence
        outs, logits, att_ws = [], [], []
",1
"                    z_list[i - 1], (z_list[i], c_list[i])
                )
            zcs = (
",1
"            logits += [self.prob_out(zcs)]
",1
"            att_ws += [att_w]
            prev_out = y  # teacher forcing
",1
"        self,
",1
"            minlenratio (float, optional): Minimum length ratio.
                If set to 1.0 and the length of input is 10,
                the minimum length of outputs will be 10 * 1 = 10.
",1
"                If set to 10 and the length of input is 10,
                the maximum length of outputs will be 10 * 10 = 100.
            use_att_constraint (bool):
",1
"        .. _`Deep Voice 3`: https://arxiv.org/abs/1710.07654

        """"""
        # setup
        assert len(h.size()) == 2
",1
"        hs = h.unsqueeze(0)
        ilens = [h.size(0)]
",1
"
        # loop for an output sequence
        idx = 0
        outs, att_ws, probs = [], [], []
",1
"        while True:
            # updated index
",1
"            # decoder calculation
            if self.use_att_extra_inputs:
                att_c, att_w = self.att(
                    hs,
                    ilens,
",1
"                    z_list[0],
",1
"                    forward_window=forward_window,
                )
            else:
",1
"                    backward_window=backward_window,
                    forward_window=forward_window,
                )

",1
"                torch.cat([z_list[-1], att_c], dim=1)
                if self.use_concate
                else z_list[-1]
",1
"            )
            outs += [self.feat_out(zcs).view(1, self.odim, -1)]  # [(1, odim, r), ...]
            probs += [torch.sigmoid(self.prob_out(zcs))[0]]  # [(r), ...]
            if self.output_activation_fn is not None:
",1
"                prev_out = self.output_activation_fn(outs[-1][:, :, -1])  # (1, odim)
            else:
                prev_out = outs[-1][:, :, -1]  # (1, odim)
            if self.cumulate_att_w and prev_att_w is not None:
                prev_att_w = prev_att_w + att_w  # Note: error when use +=
",1
"
",1
"        # initialize attention
        prev_att_w = None
        self.att.reset()

        # loop for an output sequence
",1
"        for y in ys.transpose(0, 1):
",1
"            for i in six.moves.range(1, len(self.lstm)):
",1
"            prev_out = y  # teacher forcing
            if self.cumulate_att_w and prev_att_w is not None:
                prev_att_w = prev_att_w + att_w  # Note: error when use +=
            else:
                prev_att_w = att_w
",1
"# Copyright 2019 Nagoya University (Tomoki Hayashi)
",1
"import torch.nn.functional as F

from torch.nn.utils.rnn import pack_padded_sequence
",1
"
from espnet.nets.pytorch_backend.nets_utils import make_non_pad_mask


",1
"        return cbhg_l1_loss, cbhg_mse_loss


class CBHG(torch.nn.Module):
    """"""CBHG module to convert log Mel-filterbanks to linear spectrogram.
",1
"
    """"""

    def __init__(
",1
"            else:
",1
"                self.conv_proj_chans,
",1
"            torch.nn.Conv1d(
                self.conv_proj_chans,
",1
"        # define final projection
        self.output = torch.nn.Linear(gru_units, odim, bias=True)

    def forward(self, xs, ilens):
        """"""Calculate forward propagation.
",1
"        return xs, ilens

",1
"        """"""
",1
"        assert len(x.size()) == 2
",1
"        """"""
        super(HighwayNet, self).__init__()
",1
"
",1
"""""""Initialize sub package.""""""
",1
"        eps (float):
",1
"    return beamform_vector


",1
"
",1
"        n_mels: int = 80,
        fmin: float = 0.0,
        fmax: float = None,
        # Normalization
        stats_file: str = None,
",1
"        else:
            self.global_mvn = None
",1
"
        if self.apply_uttmvn is not None:
",1
"            if self.training:
                # Select 1ch randomly
                ch = np.random.randint(x.size(2))
                h = x[:, :, ch, :]
",1
"        htk: use HTK formula instead of Slaney
        norm: {None, 1, np.inf} [scalar]
",1
"        melmat = librosa.filters.mel(**_mel_options)
        # melmat: (D2, D1) -> (D1, D2)
        self.register_buffer(""melmat"", torch.from_numpy(melmat.T).float())
",1
"    def extra_repr(self):
",1
"        return "", "".join(f""{k}={v}"" for k, v in self.mel_options.items())

    def forward(
        self, feat: torch.Tensor, ilens: torch.LongTensor
    ) -> Tuple[torch.Tensor, torch.LongTensor]:
",1
"            From the _first element to
            the {(len(array) - 1) / 2}th element are treated as
            the sum of features,
",1
"            f""stats_file={self.stats_file}, ""
            f""norm_means={self.norm_means}, norm_vars={self.norm_vars}""
        )

",1
"    ) -> Tuple[torch.Tensor, torch.LongTensor]:
",1
"
",1
"class UtteranceMVN(torch.nn.Module):
",1
"    def __init__(
        self, norm_means: bool = True, norm_vars: bool = False, eps: float = 1.0e-20
    ):
        super().__init__()
        self.norm_means = norm_means
",1
"    """"""Apply utterance mean and variance normalization

    Args:
        x: (B, T, D), assumed zero padded
        ilens: (B, T, D)
",1
"    """"""
",1
"def feature_transform_for(args, n_fft):
    return FeatureTransform(
        # Mel options,
",1
"        fs=args.fbank_fs,
",1
"        stats_file=args.stats_file,
        apply_uttmvn=args.apply_uttmvn,
",1
"from typing import List
from typing import Optional
",1
"from typing import Tuple
from typing import Union
",1
"        super().__init__()

        self.use_beamformer = use_beamformer
        self.use_wpe = use_wpe
",1
"            if self.use_dnn_mask_for_wpe:
                # Use DNN for power estimation
                # (Not observed significant gains)
                iterations = 1
            else:
",1
"                iterations=iterations,
                use_dnn_mask=use_dnn_mask_for_wpe,
",1
"
    def forward(
        self, x: ComplexTensor, ilens: Union[torch.LongTensor, numpy.ndarray, List[int]]
    ) -> Tuple[ComplexTensor, torch.LongTensor, Optional[ComplexTensor]]:
",1
"        assert len(x) == len(ilens), (len(x), len(ilens))
        # (B, T, F) or (B, T, C, F)
        if x.dim() not in (3, 4):
            raise ValueError(f""Input dim must be 3 or 4: {x.dim()}"")
",1
"        mask = None
        h = x
",1
"                if self.use_wpe:
                    choices.append((True, False))

",1
"                if self.use_beamformer:
",1
"                    choices.append((False, True))

                use_wpe, use_beamformer = choices[numpy.random.randint(len(choices))]
",1
"                h, ilens, mask = self.wpe(h, ilens)

            # 2. Beamformer
            if use_beamformer:
                # h: (B, T, C, F) -> h: (B, T, F)
",1
"                h, ilens, mask = self.beamformer(h, ilens)

        return h, ilens, mask
",1
"def frontend_for(args, idim):
    return Frontend(
        idim=idim,
",1
"        blayers=args.blayers,
        bunits=args.bunits,
        bprojs=args.bprojs,
        bnmask=args.bnmask,
        badim=args.badim,
",1
"from torch_complex.tensor import ComplexTensor

from espnet.nets.pytorch_backend.frontends.mask_estimator import MaskEstimator
",1
"
class DNN_WPE(torch.nn.Module):
    def __init__(
",1
"        self,
        wtype: str = ""blstmp"",
        widim: int = 257,
        wlayers: int = 3,
",1
"
        self.inverse_power = True

        if self.use_dnn_mask:
            self.mask_est = MaskEstimator(
",1
"    def forward(
        self, data: ComplexTensor, ilens: torch.LongTensor
",1
"                # (..., C, T) * (..., C, T) -> (..., C, T)
                power = power * mask
",1
"            power = power.mean(dim=-2)

            # enhanced: (..., C, T) -> (..., C, T)
",1
"
",1
"import numpy as np
import torch
from torch.nn import functional as F
",1
"from torch_complex.tensor import ComplexTensor

from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
from espnet.nets.pytorch_backend.rnn.encoders import RNN
from espnet.nets.pytorch_backend.rnn.encoders import RNNP
",1
"        if type[-1] == ""p"":
            self.brnn = RNNP(idim, layers, units, projs, subsample, dropout, typ=typ)
        else:
",1
"        Returns:
",1
"            hs (torch.Tensor): The hidden vector (B, F, C, T)
            masks: A tuple of the masks. (B, F, C, T)
            ilens: (B,)
",1
"        xs = xs.contiguous().view(-1, xs.size(-2), xs.size(-1))
        # ilens: (B,) -> ilens_: (B * C)
        ilens_ = ilens[:, None].expand(-1, C).contiguous().view(-1)
",1
"            # Zero padding
",1
"            if mask.size(-1) < input_length:
                mask = F.pad(mask, [0, input_length - mask.size(-1)], value=0)
            masks.append(mask)

        return tuple(masks), ilens
",1
"    get_power_spectral_density_matrix,  # noqa: H301
)
from espnet.nets.pytorch_backend.frontends.mask_estimator import MaskEstimator
",1
"from torch_complex.tensor import ComplexTensor

is_torch_1_2_plus = LooseVersion(torch.__version__) >= LooseVersion(""1.2.0"")
is_torch_1_3_plus = LooseVersion(torch.__version__) >= LooseVersion(""1.3.0"")
",1
"    Citation:
",1
"            btype, bidim, blayers, bunits, bprojs, dropout_rate, nmask=bnmask
        )
",1
"
        if beamformer_type != ""mvdr"":
",1
"            ilens (torch.Tensor): (B,)
        Returns:
            enhanced (ComplexTensor): (B, T, F)
            ilens (torch.Tensor): (B,)
",1
"
",1
"        if self.nmask == 2:  # (mask_speech, mask_noise)
            mask_speech, mask_noise = masks

            psd_speech = get_power_spectral_density_matrix(data, mask_speech)
",1
"                get_power_spectral_density_matrix(data, mask) for mask in mask_speech
            ]
",1
"            psd_noise = get_power_spectral_density_matrix(data, mask_noise)

            enhanced = []
            ws = []
",1
"                enh = enh.transpose(-1, -2)
                mask_speech[i] = mask_speech[i].transpose(-1, -3)

",1
"        Returns:
",1
"            u (torch.Tensor): (B, C)
            ilens (torch.Tensor): (B,)
        """"""
        B, _, C = psd_in.size()[:3]
        assert psd_in.size(2) == psd_in.size(3), psd_in.size()
",1
"        psd_feat = (psd.real ** 2 + psd.imag ** 2) ** 0.5

        # (B, C, F) -> (B, C, F2)
",1
"            p.data.zero_()

    # reset some modules with default init
    for m in model.modules():
        if isinstance(m, (torch.nn.Embedding, LayerNorm)):
",1
"        :param torch.Tensor key: (batch, time2, size)
        :param torch.Tensor value: (batch, time2, size)
        :param torch.Tensor mask: (batch, time1, time2)
",1
"
",1
"
",1
"        padding_idx,
        smoothing,
",1
"        normalize_length=False,
        criterion=nn.KLDivLoss(reduction=""none""),
    ):
        """"""Construct an LabelSmoothingLoss object.""""""
        super(LabelSmoothingLoss, self).__init__()
",1
"            true_dist.fill_(self.smoothing / (self.size - 1))
",1
"            ignore = target == self.padding_idx  # (B,)
            total = len(target) - ignore.sum().item()
",1
"""""""Encoder definition.""""""
",1
"
import torch
",1
"
class Encoder(torch.nn.Module):
    """"""Transformer encoder module.

",1
"    :param float dropout_rate: dropout rate
    :param float attention_dropout_rate: dropout rate in attention
    :param float positional_dropout_rate: dropout rate after adding positional encoding
    :param str or torch.nn.Module input_layer: input layer type
    :param class pos_enc_class: PositionalEncoding or ScaledPositionalEncoding
",1
"    :param bool normalize_before: whether to use layer_norm before the first block
    :param bool concat_after: whether to concat attention layer's input and output
        if True, additional linear will be applied.
",1
"        linear_units=2048,
        num_blocks=6,
",1
"        pos_enc_class=PositionalEncoding,
        normalize_before=True,
        concat_after=False,
        positionwise_layer_type=""linear"",
",1
"        positionwise_conv_kernel_size=1,
        padding_idx=-1,
    ):
        """"""Construct an Encoder object.""""""
        super(Encoder, self).__init__()
",1
"        self.normalize_before = normalize_before
        if positionwise_layer_type == ""linear"":
            positionwise_layer = PositionwiseFeedForward
",1
"            raise NotImplementedError(""Support only linear or conv1d."")
        self.encoders = repeat(
            num_blocks,
",1
"        :return: position embedded tensor, mask and new cache
",1
"from typing import List
from typing import Tuple
",1
"class Decoder(BatchScorerInterface, torch.nn.Module):
    """"""Transfomer decoder module.

",1
"        attention_dim=256,
",1
"        positional_dropout_rate=0.1,
        self_attention_dropout_rate=0.0,
        src_attention_dropout_rate=0.0,
        input_layer=""embed"",
",1
"    ):
        """"""Construct an Decoder object.""""""
        torch.nn.Module.__init__(self)
        self._register_load_state_dict_pre_hook(_pre_hook)
",1
"        self.decoders = repeat(
            num_blocks,
            lambda: DecoderLayer(
                attention_dim,
                MultiHeadedAttention(
",1
"                normalize_before,
",1
"        :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                                      dtype=torch.uint8 in PyTorch 1.2-
                                      dtype=torch.bool in PyTorch 1.2+ (include 1.2)
        :param torch.Tensor memory: encoded memory, float32  (batch, maxlen_in, feat)
",1
"
        :param torch.Tensor tgt: input token ids, int64 (batch, maxlen_out)
        :param torch.Tensor tgt_mask: input token mask,  (batch, maxlen_out)
                                      dtype=torch.uint8 in PyTorch 1.2-
                                      dtype=torch.bool in PyTorch 1.2+ (include 1.2)
",1
"            cached output list of (batch, max_time_out-1, size)
",1
"
    # batch beam search API (see BatchScorerInterface)
    def batch_score(
        self, ys: torch.Tensor, states: List[Any], xs: torch.Tensor
    ) -> Tuple[torch.Tensor, List[Any]]:
",1
"        return logp, state_list
",1
"
import torch


",1
"
# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import logging
",1
"    from matplotlib.ticker import MaxNLocator
    import os

",1
"
def savefig(plot, filename):
    plot.savefig(filename)
    plt.clf()
",1
"

def plot_multi_head_attention(
    data,
    attn_dict,
",1
"                        xtokens = data[idx][1][ikey][iaxis][""token""].split()
                # for ASR/ST/MT
",1
"

class PlotAttentionReport(asr_utils.PlotAttentionReport):
",1
"        def log_fig(plot, filename):
            from os.path import basename

",1
"            logger.add_figure(basename(filename), plot, step)
            plt.clf()
",1
"
        attn_dict = self.get_attention_weights()
        self.plotfn(self.data, attn_dict, self.outdir, """", log_fig)
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
",1
"
",1
"    """"""Layer normalization module.

    :param int nout: output dim size
",1
"    :param int dim: dimension to be normalized
    """"""

    def __init__(self, nout, dim=-1):
        """"""Construct an LayerNorm object.""""""
",1
"
    @property
",1
"        if step is None:
            step = self._step
        return (
",1
"        )

    def zero_grad(self):
        """"""Reset gradient.""""""
        self.optimizer.zero_grad()
",1
"        for key, value in state_dict.items():
",1
"def get_std_opt(model, d_model, warmup, factor):
    """"""Get standard NoamOpt.""""""
",1
"
",1
"import torch
",1
"
",1
"
        :param int d_model: embedding dim
        :param float dropout_rate: dropout rate
        :param int max_len: maximum input length
",1
"        Args:
            x (torch.Tensor): Input. Its shape is (batch, time, ...)

",1
"            torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)

        """"""
",1
"
# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"
""""""Mask module.""""""

from distutils.version import LooseVersion
",1
"
import torch

",1
"datatype = torch.bool if is_torch_1_2_plus else torch.uint8


def subsequent_mask(size, device=""cpu"", dtype=datatype):
",1
"    """"""Create mask for subsequent steps (1, size, size).

",1
"    :param int size: size of mask
    :param str device: ""cpu"" or ""cuda"" or torch.Tensor.device
    :param torch.dtype dtype: result dtype
    :rtype: torch.Tensor
",1
"    """"""
    ys_mask = ys_in_pad != ignore_id
    m = subsequent_mask(ys_mask.size(-1), device=ys_mask.device).unsqueeze(0)
    return ys_mask.unsqueeze(-2) & m
",1
"
# Copyright 2019 Shigeki Karita
",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

""""""Encoder self-attention layer definition.""""""

",1
"    """"""Encoder layer module.

",1
"    :param espnet.nets.pytorch_backend.transformer.positionwise_feed_forward.
        PositionwiseFeedForward feed_forward:
        feed forward module
    :param float dropout_rate: dropout rate
",1
"        i.e. x -> x + linear(concat(x, att(x)))
",1
"        normalize_before=True,
        concat_after=False,
    ):
        """"""Construct an EncoderLayer object.""""""
        super(EncoderLayer, self).__init__()
",1
"        """"""Compute encoded features.
",1
"            mask = None if mask is None else mask[:, -1:, :]

        if self.concat_after:
",1
"            x = self.norm2(x)

",1
"# -*- coding: utf-8 -*-
",1
"
# Copyright 2019 Tomoki Hayashi
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"    `FastSpeech: Fast, Robust and Controllable Text to Speech`_.

",1
"    def __init__(self, in_chans, hidden_chans, kernel_size, dropout_rate):
",1
"        Args:
            in_chans (int): Number of input channels.
",1
"            stride=1,
            padding=(kernel_size - 1) // 2,
        )
        self.w_2 = torch.nn.Conv1d(
            hidden_chans,
",1
"
        Returns:
            Tensor: Batch of output tensors (B, ..., hidden_chans).
",1
"
    """"""
",1
"            kernel_size (int): Kernel size of conv1d.
",1
"            x (Tensor): Batch of input tensors (B, ..., in_chans).

        Returns:
            Tensor: Batch of output tensors (B, ..., hidden_chans).

",1
"
from espnet.nets.pytorch_backend.transformer.embedding import PositionalEncoding
",1
"        self.out = torch.nn.Sequential(
            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 2), odim),
            PositionalEncoding(odim, dropout_rate),
        )
",1
"
",1
"        :return: subsampled x and mask
        :rtype Tuple[torch.Tensor, torch.Tensor]
",1
"# Copyright 2019 Shigeki Karita
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"        if False, no additional linear will be applied. i.e. x -> x + att(x)

    """"""

",1
"        feed_forward,
",1
"        self.norm2 = LayerNorm(size)
        self.norm3 = LayerNorm(size)
",1
"            tgt_q_mask = None
            if tgt_mask is not None:
                tgt_q_mask = tgt_mask[:, -1:, :]
",1
"
",1
"        if self.normalize_before:
            x = self.norm3(x)
        x = residual + self.dropout(self.feed_forward(x))
        if not self.normalize_before:
",1
"#!/usr/bin/env python3
",1
"
""""""Repeat the same layer definition.""""""
",1
"
from espnet.nets.pytorch_backend.nets_utils import pad_list


class LengthRegulator(torch.nn.Module):
",1
"        xs = [self._repeat_one_sequence(x, d) for x, d in zip(xs, ds)]

",1
"                    [3],
                    [3]])

",1
"
    This is a module of duration predictor described
    in `FastSpeech: Fast, Robust and Controllable Text to Speech`_.
    The duration predictor predicts a duration of each frame in log domain
    from the hidden embeddings of encoder.
",1
"        between in `forward` and in `inference`. In `forward`,
",1
"
        Args:
            idim (int): Input dimension.
            n_layers (int, optional): Number of convolutional layers.
            n_chans (int, optional): Number of channels of convolutional layers.
",1
"            in_chans = idim if idx == 0 else n_chans
            self.conv += [
                torch.nn.Sequential(
                    torch.nn.Conv1d(
                        in_chans,
",1
"                        n_chans,
                        kernel_size,
",1
"                        padding=(kernel_size - 1) // 2,
                    ),
                    torch.nn.ReLU(),
",1
"        # NOTE: calculate in log domain
        xs = self.linear(xs.transpose(1, -1)).squeeze(-1)  # (B, Tmax)

        if is_inference:
            # NOTE: calculate in linear domain
",1
"        if x_masks is not None:
            xs = xs.masked_fill(x_masks, 0.0)

        return xs
",1
"        """"""Calculate forward propagation.

        Args:
            xs (Tensor): Batch of input sequences (B, Tmax, idim).
",1
"
    The loss value is Calculated in log domain to make it Gaussian.

",1
"class DurationCalculator(torch.nn.Module):
    """"""Duration calculator module for FastSpeech.

    Todo:
        * Fix the duplicated calculation of diagonal head decision
",1
"            pass
        else:
            raise ValueError(
",1
"                Batch of speaker embedding vectors (B, spk_embed_dim).

        Returns:
            Tensor: Batch of durations (B, Tmax).

",1
"        """"""
        if isinstance(self.teacher_model, Transformer):
            att_ws = self._calculate_encoder_decoder_attentions(
                xs, ilens, ys, olens, spembs=spembs
            )
",1
"        durations = [
",1
"        self.register_buffer(""diag_head_idx"", diagonal_scores.argmax())

",1
"    def add_arguments(parser):
        """"""Add arguments to command line argument parser.""""""
",1
"            ""--embed-unit"",
            default=None,
            help=""Number of hidden units in embedding layer, ""
            ""if it is not specified, it keeps the same number with hidden units."",
        )
",1
"        parser.add_argument(
            ""--dropout-rate"", type=float, default=0.5, help=""dropout probability""
        )
",1
"
",1
"    def __init__(self, n_vocab, args):
        """"""Initialize class.

",1
"        nn.Module.__init__(self)
        # NOTE: for a compatibility with less than 0.5.0 version models
        dropout_rate = getattr(args, ""dropout_rate"", 0.0)
        # NOTE: for a compatibility with less than 0.6.1 version models
        embed_unit = getattr(args, ""embed_unit"", None)
",1
"        self.model = ClassifierWithState(
            RNNLM(n_vocab, args.layer, args.unit, embed_unit, args.type, dropout_rate)
",1
"        )
",1
"                the number of elements in x (scalar)

        Notes:
            The last two return values are used
",1
"            loss += loss_batch.mean() * non_zeros
",1
"            logp += torch.sum(loss_batch * non_zeros)
            count += int(non_zeros)
",1
"        return loss / batch_size, loss, count.to(loss.device)

    def score(self, y, state, x):
        """"""Score new token.

",1
"            state: Scorer state for prefix tokens
            x (torch.Tensor): 2D encoder feature that generates ys.
",1
"
        """"""
        new_state, scores = self.model.predict(state, y[-1].unsqueeze(0))
        return scores.squeeze(0), new_state

",1
"        if states[0] is None:
            states = None
        else:
",1
"            # transpose state of [batch, key, layer] into [key, layer, batch]
            states = {
                k: [
",1
"                {k: [states[k][i][b] for i in range(n_layers)] for k in keys}
",1
"    """"""A wrapper for pytorch RNNLM.""""""

",1
"        if not (isinstance(label_key, (int, str))):
            raise TypeError(""label_key must be int or str, but is %s"" % type(label_key))
        super(ClassifierWithState, self).__init__()
        self.lossfun = lossfun
",1
"            if index is not None:
                return self.predictor.final(state[index])
            else:
                return self.predictor.final(state)
",1
"        else:
            return 0.0


",1
"class RNNLM(nn.Module):
",1
"            )
",1
"                for n in range(self.n_layers)
            ]
            state = {""h"": h}
",1
"                    for n in range(self.n_layers)
",1
"            for n in range(1, self.n_layers):
                h[n], c[n] = self.rnn[n](
                    self.dropout[n](h[n - 1]), (state[""h""][n], state[""c""][n])
                )
",1
"            n_vocab (int): The size of the vocabulary
",1
"    ):
        self.drop = nn.Dropout(dropout)
        self.encoder = nn.Embedding(ntoken, ninp)
",1
"        if rnn_type in [""LSTM"", ""GRU""]:
",1
"            except KeyError:
                raise ValueError(
                    ""An invalid option for `--model` was supplied, ""
                    ""options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']""
",1
"        # Optionally tie weights as in:
        # ""Using the Output Embedding to Improve Language Models"" (Press & Wolf 2016)
        # https://arxiv.org/abs/1608.05859
",1
"        # and
        # ""Tying Word Vectors and Word Classifiers:
",1
"        #  A Loss Framework for Language Modeling"" (Inan et al. 2016)
",1
"
    def _init_weights(self):
        # NOTE: original init in pytorch/examples
",1
"        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden

",1
"        """"""
",1
"        bsz = 1
        weight = next(self.parameters())
",1
"                weight.new_zeros(self.nlayers, bsz, self.nhid),
            )
        else:
            return weight.new_zeros(self.nlayers, bsz, self.nhid)
",1
"
    def score(self, y, state, x):
",1
"                and next state for ys

        """"""
        y, new_state = self._before_loss(y[-1].view(1, 1), state)
        logp = y.log_softmax(dim=-1).view(-1)
",1
"import torch.nn as nn
",1
"
    @staticmethod
    def add_arguments(parser):
",1
"        )
        parser.add_argument(
",1
"            ""--embed-unit"",
            type=int,
            default=128,
            help=""Number of hidden units in embedding layer"",
",1
"            ""--dropout-rate"", type=float, default=0.5, help=""dropout probability""
        )
        parser.add_argument(
",1
"        Args:
            n_vocab (int): The size of the vocabulary
            args (argparse.Namespace): configurations. see py:method:`add_arguments`
",1
"
        """"""
        nn.Module.__init__(self)
        if args.pos_enc == ""sinusoidal"":
",1
"    def forward(
        self, x: torch.Tensor, t: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """"""Compute LM loss value from buffer sequences.
",1
"
        Args:
",1
"            tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Tuple of
                loss to backward (scalar),
",1
"
",1
"            x (torch.Tensor): encoder feature that generates ys.

        Returns:
            tuple[torch.Tensor, Any]: Tuple of
                torch.float32 scores for next token (n_vocab)
",1
"            ys (torch.Tensor): torch.int64 prefix tokens (n_batch, ylen).
            states (List[Any]): Scorer states for prefix tokens.
            xs (torch.Tensor):
                The encoder feature that generates ys (n_batch, xlen, n_feat).
",1
"import six

import numpy as np
",1
"            if bidir:
                setattr(self, ""bt%d"" % i, torch.nn.Linear(2 * cdim, hdim))
            else:
                setattr(self, ""bt%d"" % i, torch.nn.Linear(cdim, hdim))
",1
"        """"""RNNP forward

",1
"        :param torch.Tensor xs_pad: batch of padded input sequences (B, Tmax, idim)
",1
"            xs_pad = projected.view(ys_pad.size(0), ys_pad.size(1), -1)
            if layer < self.elayers - 1:
                xs_pad = torch.tanh(F.dropout(xs_pad, p=self.dropout))

        return xs_pad, ilens, elayer_states  # x: utt list of frame x dim
",1
"            )
            if ""lstm"" in typ
            else torch.nn.GRU(
                idim,
",1
"        if torch.is_tensor(ilens):
            ilens = ilens.cpu().numpy()
",1
"    :param int eunits: number of lstm units of encoder network
",1
"    :param int eprojs: number of projection units of encoder network
",1
"                self.enc = torch.nn.ModuleList(
                    [
                        VGG2L(in_channel),
                        RNNP(
                            get_vgg2l_odim(idim, in_channel=in_channel),
",1
"            else:
                self.enc = torch.nn.ModuleList(
                    [
                        VGG2L(in_channel),
",1
"                        RNN(
                            get_vgg2l_odim(idim, in_channel=in_channel),
                            elayers,
                            eunits,
                            eprojs,
",1
"                logging.info(typ.upper() + "" with every-layer projection for encoder"")
            else:
",1
"            prev_states = [None] * len(self.enc)
",1
"
        # make mask to remove bias value in padded part
        mask = to_device(self, make_pad_mask(ilens).unsqueeze(-1))
",1
"

",1
"def encoder_for(args, idim, subsample):
    """"""Instantiates an encoder module given the program arguments

    :param Namespace args: The arguments
    :param int or List of integer idim: dimension of input, e.g. 83, or
",1
"                subsample[idx],
                args.dropout_rate[idx],
            )
",1
"        raise ValueError(
            ""Number of encoders needs to be more than one. {}"".format(num_encs)
        )
""""""Attention modules for RNN.""""""

",1
"import math
import six

import torch
",1
"
    def __init__(self):
",1
"        """"""reset states""""""
",1
"        :return: attention weighted encoder state (B, D_enc)
        :rtype: torch.Tensor
        :return: previous attention weights
        :rtype: torch.Tensor
        """"""
",1
"            mask = 1.0 - make_pad_mask(enc_hs_len).float()
            att_prev = mask / mask.new(enc_hs_len).unsqueeze(-1)
            att_prev = att_prev.to(self.enc_h)
            self.c = torch.sum(
",1
"    """"""Dot product attention
",1
"    def __init__(self, eprojs, dunits, att_dim, han_mode=False):
        super(AttDot, self).__init__()
        self.mlp_enc = torch.nn.Linear(eprojs, att_dim)
        self.mlp_dec = torch.nn.Linear(dunits, att_dim)
",1
"        self.att_dim = att_dim
",1
"        self.pre_compute_enc_h = None
        self.mask = None
        self.han_mode = han_mode
",1
"        """"""reset states""""""
        self.h_length = None
        self.enc_h = None
",1
"        if self.pre_compute_enc_h is None or self.han_mode:
            self.enc_h = enc_hs_pad  # utt x frame x hdim
",1
"            dec_z = dec_z.view(batch, self.dunits)

        e = torch.sum(
            self.pre_compute_enc_h
            * torch.tanh(self.mlp_dec(dec_z)).view(batch, 1, self.att_dim),
",1
"
        # weighted sum over flames
        # utt x hdim
        # NOTE use bmm instead of sum(*)
        c = torch.sum(self.enc_h * w.view(batch, self.h_length, 1), dim=1)
",1
"        return c, w


class AttAdd(torch.nn.Module):
",1
"        self.dunits = dunits
        self.eprojs = eprojs
",1
"        :param list enc_hs_len: padded encoder hidden state length (B)
",1
"            self.enc_h = enc_hs_pad  # utt x frame x hdim
            self.h_length = self.enc_h.size(1)
",1
"        # NOTE consider zero padding when compute w.
        if self.mask is None:
            self.mask = to_device(self, make_pad_mask(enc_hs_len))
",1
"        e.masked_fill_(self.mask, -float(""inf""))
        w = F.softmax(scaling * e, dim=1)

        # weighted sum over flames
",1
"
",1
"    :param int att_dim: attention dimension
    :param int aconv_chans: # channels of attention convolution
    :param int aconv_filts: filter size of attention convolution
    :param bool han_mode: flag to swith on mode of hierarchical attention
        and not store pre_compute_enc_h
",1
"        self.mlp_att = torch.nn.Linear(aconv_chans, att_dim, bias=False)
",1
"        self.loc_conv = torch.nn.Conv2d(
            1,
",1
"            aconv_chans,
            (1, 2 * aconv_filts + 1),
            padding=(0, aconv_filts),
",1
"        self.pre_compute_enc_h = None
        self.mask = None

    def forward(
        self,
",1
"            forward window size when constraining attention
        :param int last_attended_idx: index of the inputs of the last attended
",1
"        :rtype: torch.Tensor
",1
"            # if no bias, 0 0-pad goes 0
",1
"        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"        c = torch.sum(self.enc_h * w.view(batch, self.h_length, 1), dim=1)
",1
"
        return c, w


",1
"        self.pre_compute_enc_h = None
        self.mask = None
",1
"            dec_z = enc_hs_pad.new_zeros(batch, self.dunits)
        else:
            dec_z = dec_z.view(batch, self.dunits)

        # initialize attention weight with uniform dist.
",1
"

class AttLoc2D(torch.nn.Module):
    """"""2D location-aware attention

",1
"    :param int eprojs: # projection-units of encoder
",1
"    :param bool han_mode:
        flag to swith on mode of hierarchical attention and not store pre_compute_enc_h
    """"""
",1
"        self.att_win = att_win
        self.mask = None
        self.han_mode = han_mode

    def reset(self):
",1
"
    def forward(self, enc_hs_pad, enc_hs_len, dec_z, att_prev, scaling=2.0):
        """"""AttLoc2D forward

        :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
",1
"        :return: attention weighted encoder state (B, D_enc)
        :rtype: torch.Tensor
        :return: previous attention weights (B x att_win x T_max)
",1
"            dec_z = enc_hs_pad.new_zeros(batch, self.dunits)
        else:
",1
"            # if no bias, 0 0-pad goes 0
            att_prev = to_device(self, (1.0 - make_pad_mask(enc_hs_len).float()))
            att_prev = att_prev / att_prev.new(enc_hs_len).unsqueeze(-1)
            att_prev = att_prev.unsqueeze(1).expand(-1, self.att_win, -1)
",1
"
        # update att_prev: B x att_win x Tmax -> B x att_win+1 x Tmax
        # -> B x att_win x Tmax
        att_prev = torch.cat([att_prev, w.unsqueeze(1)], dim=1)
        att_prev = att_prev[:, 1:]
",1
"
",1
"class AttLocRec(torch.nn.Module):
",1
"
    :param int eprojs: # projection-units of encoder
    :param int dunits: # units of decoder
",1
"        self.mlp_enc = torch.nn.Linear(eprojs, att_dim)
",1
"
    def forward(self, enc_hs_pad, enc_hs_len, dec_z, att_prev_states, scaling=2.0):
        """"""AttLocRec forward

        :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
",1
"        :param list enc_hs_len: padded encoder hidden state length (B)
        :param torch.Tensor dec_z: decoder hidden state (B x D_dec)
        :param tuple att_prev_states: previous attention weight and lstm states
                                      ((B, T_max), ((B, att_dim), (B, att_dim)))
",1
"            att_states = (att_h, att_c)
        else:
            att_prev = att_prev_states[0]
            att_states = att_prev_states[1]
",1
"        w = F.softmax(scaling * e, dim=1)

",1
"        # weighted sum over flames
",1
"        return c, (w, (att_h, att_c))
",1
"    :param int aconv_filts: filter size of attention convolution
",1
"    :param bool han_mode:
        flag to swith on mode of hierarchical attention and not store pre_compute_enc_h
    """"""

    def __init__(
",1
"        self.mlp_enc = torch.nn.Linear(eprojs, att_dim)
",1
"            padding=(0, aconv_filts),
",1
"
    def reset(self):
        """"""reset states""""""
",1
"        # pre-compute all h outside the decoder loop
        if self.pre_compute_enc_h is None or self.han_mode:
",1
"            self.mask = to_device(self, make_pad_mask(enc_hs_len))
        e.masked_fill_(self.mask, -float(""inf""))
",1
"        c = torch.sum(self.enc_h * w.view(batch, self.h_length, 1), dim=1)

        return c, att_prev_list

",1
"        self.pre_compute_k = None
        self.pre_compute_v = None
",1
"
        :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
        :param list enc_hs_len: padded encoder hidden state length (B)
",1
"        batch = enc_hs_pad.size(0)
        # pre-compute all k and v outside the decoder loop
",1
"        if self.pre_compute_k is None or self.han_mode:
",1
"        if dec_z is None:
            dec_z = enc_hs_pad.new_zeros(batch, self.dunits)
        else:
            dec_z = dec_z.view(batch, self.dunits)
",1
"        for h in six.moves.range(self.aheads):
            e = torch.sum(
                self.pre_compute_k[h]
                * torch.tanh(self.mlp_q[h](dec_z)).view(batch, 1, self.att_dim_k),
",1
"            # weighted sum over flames
",1
"                    self.pre_compute_v[h] * w[h].view(batch, self.h_length, 1), dim=1
                )
",1
"            ]
",1
"class AttMultiHeadAdd(torch.nn.Module):
    """"""Multi head additive attention
",1
"    :param int att_dim_k: dimension k in multi head attention
    :param int att_dim_v: dimension v in multi head attention
    :param bool han_mode: flag to swith on mode of hierarchical attention
        and not store pre_compute_k and pre_compute_v
",1
"        self.gvec = torch.nn.ModuleList()
        for _ in six.moves.range(aheads):
",1
"        self.dunits = dunits
",1
"        self.att_dim_v = att_dim_v
        self.scaling = 1.0 / math.sqrt(att_dim_k)
        self.h_length = None
        self.enc_h = None
",1
"                self.mlp_k[h](self.enc_h) for h in six.moves.range(self.aheads)
            ]

        if self.pre_compute_v is None or self.han_mode:
",1
"
class AttMultiHeadLoc(torch.nn.Module):
",1
"    :param int att_dim_k: dimension k in multi head attention
    :param int att_dim_v: dimension v in multi head attention
    :param int aconv_chans: # channels of attention convolution
",1
"        eprojs,
        dunits,
",1
"        self.loc_conv = torch.nn.ModuleList()
        self.mlp_att = torch.nn.ModuleList()
        for _ in six.moves.range(aheads):
            self.mlp_q += [torch.nn.Linear(dunits, att_dim_k)]
",1
"            self.mlp_k += [torch.nn.Linear(eprojs, att_dim_k, bias=False)]
            self.mlp_v += [torch.nn.Linear(eprojs, att_dim_v, bias=False)]
            self.gvec += [torch.nn.Linear(att_dim_k, 1)]
            self.loc_conv += [
                torch.nn.Conv2d(
",1
"                    padding=(0, aconv_filts),
                    bias=False,
",1
"        self.scaling = 1.0 / math.sqrt(att_dim_k)
        self.h_length = None
        self.enc_h = None
",1
"        self.mask = None
        self.han_mode = han_mode

    def reset(self):
",1
"        """"""reset states""""""
        self.h_length = None
        self.enc_h = None
",1
"        self.pre_compute_v = None
        self.mask = None

    def forward(self, enc_hs_pad, enc_hs_len, dec_z, att_prev, scaling=2.0):
",1
"        :param torch.Tensor att_prev:
            list of previous attention weight (B x T_max) * aheads
        :param float scaling: scaling parameter before applying softmax
",1
"        """"""

        batch = enc_hs_pad.size(0)
",1
"        # pre-compute all k and v outside the decoder loop
        if self.pre_compute_k is None or self.han_mode:
            self.enc_h = enc_hs_pad  # utt x frame x hdim
            self.h_length = self.enc_h.size(1)
",1
"        if att_prev is None:
",1
"            att_prev = []
            for _ in six.moves.range(self.aheads):
                # if no bias, 0 0-pad goes 0
",1
"                mask = 1.0 - make_pad_mask(enc_hs_len).float()
                att_prev += [to_device(self, mask / mask.new(enc_hs_len).unsqueeze(-1))]
",1
"        self,
",1
"        att_dim_v,
        aconv_chans,
        aconv_filts,
",1
"        self.mlp_q = torch.nn.ModuleList()
        self.mlp_k = torch.nn.ModuleList()
",1
"        self.enc_h = None
        self.pre_compute_k = None
        self.pre_compute_v = None
        self.mask = None
",1
"
    def reset(self):
",1
"    def forward(self, enc_hs_pad, enc_hs_len, dec_z, att_prev):
        """"""AttMultiHeadMultiResLoc forward

",1
"        :return: attention weighted encoder state (B x D_enc)
        :rtype: torch.Tensor
        :return: list of previous attention weight (B x T_max) * aheads
",1
"            self.pre_compute_k = [
                self.mlp_k[h](self.enc_h) for h in six.moves.range(self.aheads)
",1
"            ]

        if dec_z is None:
            dec_z = enc_hs_pad.new_zeros(batch, self.dunits)
        else:
",1
"        w = []
        for h in six.moves.range(self.aheads):
",1
"                    + att_conv
                    + self.mlp_q[h](dec_z).view(batch, 1, self.att_dim_k)
",1
"    Forward attention in sequence-to-sequence acoustic modeling for speech synthesis
        (https://arxiv.org/pdf/1807.06736.pdf)

    :param int eprojs: # projection-units of encoder
",1
"    :param int dunits: # units of decoder
    :param int att_dim: attention dimension
    :param int aconv_chans: # channels of attention convolution
    :param int aconv_filts: filter size of attention convolution
    """"""
",1
"
    def __init__(self, eprojs, dunits, att_dim, aconv_chans, aconv_filts):
        super(AttForward, self).__init__()
        self.mlp_enc = torch.nn.Linear(eprojs, att_dim)
        self.mlp_dec = torch.nn.Linear(dunits, att_dim, bias=False)
",1
"        dec_z,
        att_prev,
        scaling=1.0,
",1
"    ):
        """"""Calculate AttForward forward propagation.

        :param torch.Tensor enc_hs_pad: padded encoder hidden state (B x T_max x D_enc)
        :param list enc_hs_len: padded encoder hidden state length (B)
",1
"        """"""
        batch = len(enc_hs_pad)
",1
"        att_conv = self.loc_conv(att_prev.view(batch, 1, 1, self.h_length))
        # att_conv: utt x att_conv_chans x 1 x frame -> utt x frame x att_conv_chans
        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"            self.mask = to_device(self, make_pad_mask(enc_hs_len))
",1
"        w = F.normalize(torch.clamp(w, 1e-6), p=1, dim=1)

        # weighted sum over flames
",1
"        # utt x hdim
        # NOTE use bmm instead of sum(*)
        c = torch.sum(self.enc_h * w.unsqueeze(-1), dim=1)

        return c, w
",1
"

class AttForwardTA(torch.nn.Module):
    """"""Forward attention with transition agent module.

",1
"    :param int dunits: # units of decoder
    :param int att_dim: attention dimension
    :param int aconv_chans: # channels of attention convolution
",1
"            1,
            aconv_chans,
            (1, 2 * aconv_filts + 1),
            padding=(0, aconv_filts),
",1
"            bias=False,
        )
        self.gvec = torch.nn.Linear(att_dim, 1)
        self.dunits = dunits
        self.eunits = eunits
",1
"        self.enc_h = None
        self.pre_compute_enc_h = None
",1
"        :param torch.Tensor att_prev: attention weights of previous step
        :param torch.Tensor out_prev: decoder outputs of previous step (B, odim)
        :param float scaling: scaling parameter before applying softmax
",1
"        :param int backward_window: backward window size in attention constraint
        :param int forward_window: forward window size in attetion constraint
        :return: attention weighted encoder state (B, dunits)
",1
"        :rtype: torch.Tensor
        :return: previous attention weights (B, Tmax)
",1
"            self.pre_compute_enc_h = self.mlp_enc(self.enc_h)

        if dec_z is None:
",1
"
",1
"        # att_prev: utt x frame -> utt x 1 x 1 x frame
        # -> utt x att_conv_chans x 1 x frame
        att_conv = self.loc_conv(att_prev.view(batch, 1, 1, self.h_length))
",1
"        # att_conv: utt x att_conv_chans x 1 x frame -> utt x frame x att_conv_chans
        att_conv = att_conv.squeeze(2).transpose(1, 2)
        # att_conv: utt x frame x att_conv_chans -> utt x frame x att_dim
        att_conv = self.mlp_att(att_conv)
",1
"
        # dot with gvec
        # utt x frame x att_dim -> utt x frame
        e = self.gvec(
            torch.tanh(att_conv + self.pre_compute_enc_h + dec_z_tiled)
",1
"        ).squeeze(2)

        # NOTE consider zero padding when compute w.
",1
"        if self.mask is None:
            self.mask = to_device(self, make_pad_mask(enc_hs_len))
        e.masked_fill_(self.mask, -float(""inf""))
",1
"
        # update transition agent prob
        self.trans_agent_prob = torch.sigmoid(
",1
"    aconv_filts = getattr(args, ""aconv_filts"", None)
",1
"        if han_mode:
",1
"                args.eprojs,
",1
"                    args.adim[idx],
                    awin[idx],
                    aconv_chans[idx],
                    aconv_filts[idx],
                )
",1
"        )
",1
"    :param int aconv_filts: filter size of attention convolution
    :param bool han_mode: flag to swith on mode of hierarchical attention
    :return: The attention module
",1
"        att = AttCovLoc(eprojs, dunits, adim, aconv_chans, aconv_filts, han_mode)
    elif atype == ""multi_head_dot"":
        att = AttMultiHeadDot(eprojs, dunits, aheads, adim, adim, han_mode)
    elif atype == ""multi_head_add"":
",1
"    return att


def att_to_numpy(att_ws, att):
",1
"    """"""Converts attention weights to a numpy array given the attention

    :param list att_ws: The attention weights
    :param torch.nn.Module att: The attention
",1
"    :rtype: np.ndarray
    :return: The numpy array of the attention weights
    """"""
    # convert to numpy array with the shape (B, Lmax, Tmax)
",1
"    ):
        # att_ws => list of list of each head attention
        n_heads = len(att_ws[0])
        att_ws_sorted_by_head = []
",1
"            att_ws_sorted_by_head += [att_ws_head]
        att_ws = torch.stack(att_ws_sorted_by_head, dim=1).cpu().numpy()
    else:
        # att_ws => list of attentions
",1
"import math
import random
import six

",1
"
",1
"    :param int dlayers: decoder layers
    :param int dunits: decoder units
    :param int sos: start of sequence symbol id
",1
"    :param int eos: end of sequence symbol id
    :param torch.nn.Module att: attention module
    :param int verbose: verbose level
    :param list char_list: list of character strings
    :param ndarray labeldist: distribution of label smoothing
",1
"        dropout=0.0,
        context_residual=False,
        replace_sos=False,
        num_encs=1,
",1
"            ]
            self.dropout_dec += [torch.nn.Dropout(p=dropout)]
            # NOTE: dropout is applied only for the vertical connections
            # see https://arxiv.org/pdf/1409.2329.pdf
",1
"        self.sampling_probability = sampling_probability
        self.dropout = dropout
        self.num_encs = num_encs

",1
"        # for multilingual E2E-ST
        self.replace_sos = replace_sos

        self.logzero = -10000000000.0

",1
"        return z_list, c_list

    def forward(self, hs_pad, hlens, ys_pad, strm_idx=0, lang_ids=None):
        """"""Decoder forward

",1
"                                    (B, Lmax)
        :param int strm_idx: stream index indicates the index of decoding stream.
        :param torch.Tensor lang_ids: batch of target language id tensor (B, 1)
        :return: attention loss value
",1
"
",1
"        # loop for an output sequence
        for i in six.moves.range(olength):
            if self.num_encs == 1:
                att_c, att_w = self.att[att_idx](
                    hs_pad[0], hlens[0], self.dropout_dec[0](z_list[0]), att_w
",1
"            if i > 0 and random.random() < self.sampling_probability:
                logging.info("" scheduled sampling "")
                z_out = self.output(z_all[-1])
",1
"            reduction_str = ""mean""
        self.loss = F.cross_entropy(
            y_all,
",1
"        )
        # compute perplexity
        ppl = math.exp(self.loss.item())
        # -1: eos, which is removed in the loss computation
        self.loss *= np.mean([len(x) for x in ys_in]) - 1
",1
"        logging.info(""att loss:"" + """".join(str(self.loss.item()).split(""\n"")))

        # show predicted character sequence for debug
        if self.verbose > 0 and self.char_list is not None:
",1
"            ys_hat = y_all.view(batch, olength, -1)
            ys_true = ys_out_pad
",1
"        :param torch.Tensor lpz: ctc log softmax output (T, odim)
                                [in multi-encoder case, list of torch.Tensor,
                                [(T1, odim), (T2, odim), ...] ]
        :param Namespace recog_args: argument Namespace containing options
",1
"        for idx in range(self.num_encs):
            logging.info(
",1
"            weights_ctc_dec = recog_args.weights_ctc_dec / np.sum(
                recog_args.weights_ctc_dec
            )  # normalize
            logging.info(
                ""ctc weights (decoding): "" + "" "".join([str(x) for x in weights_ctc_dec])
",1
"            )
        else:
            weights_ctc_dec = [1.0]
",1
"
        maxlen = np.amin([h[idx].size(0) for idx in range(self.num_encs)])
",1
"        minlen = int(recog_args.minlenratio * maxlen)
        logging.info(""max output length: "" + str(maxlen))
",1
"        if lpz[0] is not None:
",1
"                for idx in range(self.num_encs)
",1
"        ended_hyps = []

        for i in six.moves.range(maxlen):
            logging.debug(""position "" + str(i))

",1
"                        att_c_list[idx], att_w_list[idx] = self.att[idx](
                            h[idx].unsqueeze(0),
",1
"                    )
",1
"                        )
",1
"                        )
                    else:
                        for idx in range(self.num_encs):
",1
"                                * torch.from_numpy(
",1
"                    new_hyp[""yseq""][len(hyp[""yseq""])] = int(local_best_ids[0, j])
",1
"                            for idx in range(self.num_encs)
                        ]
                    # will be (2 x beam) hyps at most
                    hyps_best_kept.append(new_hyp)

",1
"                ""best hypo: ""
",1
"            # and removed them from current hypotheses
            # (this will be a problem, number of hyps < beam)
",1
"                                hyp[""rnnlm_prev""]
                            )
                        ended_hyps.append(hyp)
                else:
                    remained_hyps.append(hyp)
",1
"            if len(hyps) > 0:
                logging.debug(""remaining hypotheses: "" + str(len(hyps)))
            else:
",1
"                logging.debug(
                    ""hypo: "" + """".join([char_list[int(x)] for x in hyp[""yseq""][1:]])
",1
"            ""normalized log probability: ""
            + str(nbest_hyps[0][""score""] / len(nbest_hyps[0][""yseq""]))
        )
",1
"        lang_ids=None,
    ):
",1
"            lpz = [lpz]
        if self.num_encs > 1 and lpz is None:
            lpz = [lpz] * self.num_encs

",1
"        att_idx = min(strm_idx, len(self.att) - 1)
        for idx in range(self.num_encs):
",1
"                )
            )
",1
"        # weights-ctc,
",1
"        if lpz[0] is not None and self.num_encs > 1:
",1
"        else:
            weights_ctc_dec = [1.0]

",1
"            att_w_list, ctc_scorer, ctc_state = [None], [None], [None]
            self.att[att_idx].reset()  # reset pre-computation of h
        else:
            a_prev = [None] * (self.num_encs + 1)  # atts + han
",1
"            att_w_list = [None] * (self.num_encs + 1)  # atts + han
            att_c_list = [None] * (self.num_encs)  # atts
            ctc_scorer, ctc_state = [None] * (self.num_encs), [None] * (self.num_encs)
            for idx in range(self.num_encs + 1):
                self.att[idx].reset()  # reset pre-computation of h in atts and han
",1
"            logging.info(""<sos> index: "" + str(char_list.index(recog_args.tgt_lang)))
            logging.info(""<sos> mark: "" + recog_args.tgt_lang)
            yseq = [
                [char_list.index(recog_args.tgt_lang)] for _ in six.moves.range(n_bb)
",1
"                CTC_SCORING_RATIO if att_weight > 0.0 and not lpz[0].is_cuda else 0
            )
            ctc_scorer = [
                CTCPrefixScoreTH(
",1
"                    lpz[idx],
                    hlens[idx],
",1
"        for i in six.moves.range(maxlen):
",1
"                    )
                exp_h_han = torch.stack(att_c_list, dim=1)
                att_c, att_w_list[self.num_encs] = self.att[self.num_encs](
                    exp_h_han,
",1
"                )
            ey = torch.cat((ey, att_c), dim=1)
",1
"                )
            else:
                logits = self.output(self.dropout_dec[-1](z_list[-1]))
",1
"
",1
"                    _a_prev = (_a_prev_, (_h_prev_, _c_prev_))
",1
"                thr = accum_best_scores[:, -1]
                for samp_i in six.moves.range(batch):
",1
"                            yk = yseq[k][:]
                            _vscore = vscores[samp_i][beam_j] + penalty_i
                        if _vscore:
",1
"                                {""yseq"": yk, ""vscore"": _vscore, ""score"": _score}
                            )
                        k = k + 1
",1
"            if len(stop_search_summary) == 1 and stop_search_summary[0]:
                break

",1
"            if ctc_scorer[0]:
",1
"                        ctc_state[idx], accum_best_ids
",1
"        dummy_hyps = [
",1
"                for x in ended_hyps[samp_i]:
",1
"            :param torch.Tensor hlen: batch of lengths of hidden state sequences (B)
                                        [in multi-encoder case, list of torch.Tensor,
                                        [(B), (B), ..., ]
",1
"                1) multi-head case => attention weights (B, H, Lmax, Tmax),
                2) multi-encoder case =>
                    [(B, Lmax, Tmax1), (B, Lmax, Tmax2), ..., (B, Lmax, NumEncs)]
                3) other case => attention weights (B, Lmax, Tmax).
",1
"            hs_pad = [hs_pad]
            hlen = [hlen]

",1
"        ys = [y[y != self.ignore_id] for y in ys_pad]  # parse padded ys
",1
"        # pys: utt x olen
        ys_in_pad = pad_list(ys_in, self.eos)
",1
"        if self.num_encs == 1:
            att_w = None
            self.att[att_idx].reset()  # reset pre-computation of h
        else:
            att_w_list = [None] * (self.num_encs + 1)  # atts + han
",1
"        eys = self.dropout_emb(self.embed(ys_in_pad))  # utt x olen x zdim
",1
"    def _get_last_yseq(exp_yseq):
        last = []
        for y_seq in exp_yseq:
            last.append(y_seq[-1])
        return last
",1
"    def _append_ids(yseq, ids):
        if isinstance(ids, list):
            for i, j in enumerate(ids):
                yseq[i].append(j)
",1
"                new_state[k] = [torch.index_select(vi, dim, vidx) for vi in v]
        elif isinstance(rnnlm_state, list):
            new_state = []
",1
"            for i in vidx:
                new_state.append(rnnlm_state[int(i)][:])
        return new_state

    # scorer interface methods
",1
"            ),
        )
",1
"    :param recog_args: arguments for ""recognize"" method of E2E
    """"""

",1
"        self._e2e = e2e
        self._recog_args = recog_args
        self._char_list = e2e.char_list
        self._rnnlm = rnnlm
",1
"        ), ""SegmentStreamingE2E works only with uni-directional encoders""
",1
"                            -1, self._ctc_posteriors[0].size(0)
                        )
                        if self._recog_args.batchsize > 0:
                            lpz = lpz.unsqueeze(0)
                        normalize_score = False
",1
"
",1
"                        hlens = torch.tensor([h.shape[0]])
                        hyp = self._e2e.dec.recognize_beam_batch(
",1
"                    self._blank_dur = 0
",1
"
                    tail_len = (
                        self._subsampling_factor
                        * self._recog_args.streaming_onset_margin
",1
"        self._offset = 0
        self._previous_encoder_recurrent_state = None
        self._encoder_states = []
        self._ctc_posteriors = []
",1
"        ), ""WindowStreamingE2E works only with combined CTC and attention decoders.""

    def accept_input(self, x):
        """"""Call this method each time a new batch of input is available.""""""
",1
"
        h, ilen = self._e2e.subsample_frames(x)

",1
"            select_unprocessed_windows(self._encoder_states),
",1
"
    """"""

    def __init__(self, trans_type, blank_id):
        """"""Construct an TransLoss object.""""""
",1
"        else:
            raise NotImplementedError

        self.blank_id = blank_id

",1
"        model (torch.nn.Module): transducer instance
        args (Namespace): argument Namespace containing options
",1
"
    """"""
    if args.dtype != ""transformer"":
        if args.etype == ""transformer"":
            initialize(model.encoder, args.transformer_init)
",1
"class VGG2L(torch.nn.Module):
    """"""VGG2L module for transformer-transducer encoder.""""""

    def __init__(self, idim, odim):
        """"""Construct a VGG2L object.
",1
"
        Args:
            idim (int): dimension of inputs
",1
"            odim (int): dimension of outputs

",1
"    def create_new_mask(self, x_mask, x):
        """"""Create a subsampled version of x_mask.

        Args:
            x_mask (torch.Tensor): (B, 1, T)
",1
"        dlayers,
        dunits,
        blank,
        embed_dim,
",1
"        """"""Transducer initializer.""""""
        super(DecoderRNNT, self).__init__()

        self.embed = torch.nn.Embedding(odim, embed_dim, padding_idx=blank)
        self.dropout_embed = torch.nn.Dropout(p=dropout_embed)
",1
"            self.dropout_dec += [torch.nn.Dropout(p=dropout)]
",1
"            (list): list of L zero-init hidden and cell state (B, Hdec)

        """"""
        z_list = [ey.new_zeros(ey.size(0), self.dunits)]
        c_list = [ey.new_zeros(ey.size(0), self.dunits)]
",1
"            ey (torch.Tensor): batch of input features (B, Emb_dim)
            dstate (list): list of L input hidden and cell state (B, Hdec)

        Returns:
",1
"            output (torch.Tensor): batch of output features (B, Hdec)
            dstate (list): list of L output hidden and cell state (B, Hdec)
",1
"
        """"""
        if dstate is None:
            z_prev, c_prev = self.zero_state(ey)
        else:
",1
"            z_prev, c_prev = dstate

",1
"
        Returns:
            z (torch.Tensor): output (B, T, U, odim)

",1
"        z = self.lin_out(z)

        return z

    def forward(self, hs_pad, ys_in_pad, hlens=None):
",1
"
        z_all = []
",1
"        return z
",1
"
        for hi in h:
            ytu = F.log_softmax(self.joint(hi, y[0]), dim=0)
            logp, pred = torch.max(ytu, dim=0)

",1
"                    self, torch.full((1, 1), hyp[""yseq""][-1], dtype=torch.long)
",1
"                y, (z_list, c_list) = self.rnn_forward(ey[0], (z_list, c_list))

        return [hyp]
",1
"
        Args:
            h (torch.Tensor): encoder hidden state sequences (Tmax, Henc)
            recog_args (Namespace): argument Namespace containing options
            rnnlm (torch.nn.Module): language module
",1
"                    ""c_prev"": c_list,
                    ""lm_state"": None,
                }
            ]
        else:
",1
"            hyps = kept_hyps
",1
"                        ""score"": new_hyp[""score""] + float(ytu[k]),
                        ""yseq"": new_hyp[""yseq""][:],
                        ""z_prev"": new_hyp[""z_prev""],
                        ""c_prev"": new_hyp[""c_prev""],
",1
"                    if k == self.blank:
                        kept_hyps.append(beam_hyp)
                    else:
                        beam_hyp[""z_prev""] = z_list[:]
                        beam_hyp[""c_prev""] = c_list[:]
",1
"                        beam_hyp[""yseq""].append(int(k))

                        if rnnlm:
                            beam_hyp[""lm_state""] = rnnlm_state
",1
"                            beam_hyp[""score""] += (
                                recog_args.lm_weight * rnnlm_scores[0][k]
",1
"                            )

                        hyps.append(beam_hyp)

",1
"    """"""RNNT-Att Decoder module.

    Args:
        eprojs (int): # encoder projection units
        odim (int): dimension of outputs
",1
"    """"""

    def __init__(
        self,
",1
"    ):
",1
"        self.dlayers = dlayers
        self.dunits = dunits
        self.embed_dim = embed_dim
",1
"
    def zero_state(self, ey):
        """"""Initialize decoder states.

        Args:
",1
"        """"""
        z_list = [ey.new_zeros(ey.size(0), self.dunits)]
        c_list = [ey.new_zeros(ey.size(0), self.dunits)]

        for _ in six.moves.range(1, self.dlayers):
",1
"                    self.dropout_dec[i - 1](z_list[i - 1]), (z_prev[i], c_prev[i])
                )
        else:
            z_list[0] = self.decoder[0](ey, z_prev[0])
",1
"                )
",1
"        return y, (z_list, c_list)

    def joint(self, h_enc, h_dec):
",1
"            h_dec (torch.Tensor): batch of expanded hidden state (B, 1, U, Hdec)

        Returns:
            z (torch.Tensor): output (B, T, U, odim)

",1
"        """"""
        z = torch.tanh(self.lin_enc(h_enc) + self.lin_dec(h_dec))
        z = self.lin_out(z)

",1
"
",1
"            ey = torch.cat((eys[:, i, :], att_c), dim=1)
",1
"        )

",1
"            nbest_hyps (list of dicts): n-best decoding results

        """"""
        beam = recog_args.beam_size
",1
"                    ""a_prev"": None,
                }
",1
"
                for k in six.moves.range(self.odim):
                    beam_hyp = {
                        ""score"": new_hyp[""score""] + float(ytu[k]),
",1
"                        ""a_prev"": new_hyp[""a_prev""],
                    }
                    if rnnlm:
",1
"            args.dec_embed_dim,
            args.joint_dim,
            args.dropout_rate_decoder,
",1
"            args.dropout_rate_embed_decoder,
        )
",1
"            args.dlayers,
            args.dunits,
            blank,
",1
"import torch
",1
"        target (torch.Tensor): batch of padded target sequences (B, Lmax)
        pred_len (torch.Tensor): batch of hidden sequence lengths (B)
",1
"    return ys_in_pad, target, pred_len, target_len
",1
"import torch
from torch import nn

from espnet.nets.pytorch_backend.transformer.layer_norm import LayerNorm
",1
"
class DecoderLayer(nn.Module):
    """"""Single decoder layer module for transformer-transducer models.

    Args:
",1
"        self_attn (MultiHeadedAttention): self attention module
        feed_forward (PositionwiseFeedForward): feed forward layer module
        dropout_rate (float): dropout rate
        normalize_before (bool): whether to use layer_norm before the first block
",1
"        concat_after (bool): whether to concat attention layer's input and output

    """"""
",1
"        self.norm2 = LayerNorm(size)

        self.dropout = nn.Dropout(dropout_rate)

",1
"        self.size = size

        self.normalize_before = normalize_before
",1
"
import six
import torch

",1
"

class Decoder(torch.nn.Module):
",1
"    """"""Decoder module for transformer-transducer models.

",1
"        odim (int): dimension of outputs
        jdim (int): dimension of joint-space
",1
"        attention_dim (int): dimension of attention
",1
"        pos_enc_class=PositionalEncoding,
        blank=0,
",1
"        if input_layer == ""embed"":
            self.embed = torch.nn.Sequential(
",1
"                torch.nn.Dropout(dropout_rate),
                torch.nn.ReLU(),
                pos_enc_class(attention_dim, positional_dropout_rate),
",1
"
    def forward(self, tgt, tgt_mask, memory):
        """"""Forward transformer-transducer decoder.

",1
"                                input tensor
                                (batch, maxlen_out, #mels) in the other cases
            tgt_mask (torch.Tensor): input token mask,  (batch, maxlen_out)
                                     dtype=torch.uint8 in PyTorch 1.2-
",1
"        return z, tgt_mask

    def joint(self, h_enc, h_dec):
        """"""Joint computation of z.
",1
"                                input tensor (batch, maxlen_out, #mels)
                                in the other cases
            tgt_mask (torch.Tensor): input token mask,  (batch, Tmax)
                                     dtype=torch.uint8 in PyTorch 1.2-
",1
"
        if cache is None:
",1
"
",1
"
        Returns:
",1
"        """"""Beam search implementation for transformer-transducer.

        Args:
",1
"            while True:
                new_hyp = max(hyps, key=lambda x: x[""score""])
                hyps.remove(new_hyp)

",1
"
                ytu = torch.log_softmax(self.joint(hi, y[0]), dim=0)

",1
"                for k in six.moves.range(self.odim):
                    beam_hyp = {
                        ""score"": new_hyp[""score""] + float(ytu[k]),
                        ""yseq"": new_hyp[""yseq""][:],
",1
"            nbest_hyps = sorted(
                kept_hyps, key=lambda x: x[""score""] / len(x[""yseq""]), reverse=True
            )[:nbest]
        else:
            nbest_hyps = sorted(kept_hyps, key=lambda x: x[""score""], reverse=True)[
",1
"                :nbest
            ]
",1
"import torch
",1
"class CTCPrefixScorer(PartialScorerInterface):
    """"""Decoder interface wrapper for CTCPrefixScore.""""""

    def __init__(self, ctc: torch.nn.Module, eos: int):
",1
"        )
        return tscore, (presub_score, new_st)
""""""Length bonus module.""""""
from typing import Any
",1
"from typing import Tuple

import torch
",1
"
",1
"
        """"""
        self.n = n_vocab

",1
"    def batch_score(
",1
"from espnet.scheduler import scheduler
",1
"import pytest
",1
"import torch
",1
"
@pytest.mark.parametrize(""name"", scheduler.SCHEDULER_DICT.keys())
def test_scheduler(name):
    s = scheduler.dynamic_import_scheduler(name).build(""lr"")
",1
"
def test_pytorch_scheduler():
    warmup = 30000
",1
"    s = scheduler.NoamScheduler.build(""lr"", warmup=warmup)
    net = torch.nn.Linear(2, 1)
    o = torch.optim.SGD(net.parameters(), lr=1.0)
    so = PyTorchScheduler([s], o)
",1
"    so.step(0)
    for g in o.param_groups:
        assert g[""lr""] == s.scale(0)
",1
"
@pytest.mark.parametrize(
    ""name, backend"",
",1
")
def test_asr_build(name, backend):
    model = dynamic_import_asr(name, backend).build(
        10, 10, mtlalpha=0.123, adim=4, eunits=3, dunits=3, elayers=2, dlayers=2
    )
",1
"def make_inference_args(**kwargs):
    defaults = dict(
        threshold=0.5,
",1
"    maxout_len,
    spk_embed_dim=None,
    spc_dim=None,
",1
"    device=torch.device(""cpu""),
):
    ilens = np.sort(np.random.randint(1, maxin_len, bs))[::-1].tolist()
    olens = np.sort(np.random.randint(3, maxout_len, bs))[::-1].tolist()
    xs = [np.random.randint(0, idim, lg) for lg in ilens]
",1
"    ys = [np.random.randn(lg, odim) for lg in olens]
    ilens = torch.LongTensor(ilens).to(device)
    olens = torch.LongTensor(olens).to(device)
",1
"
    batch = {
",1
"        ""xs"": xs,
        ""ilens"": ilens,
        ""ys"": ys,
        ""labels"": labels,
",1
"
",1
"        ({""use_batch_norm"": False}, {}),
",1
"        ({""atype"": ""forward""}, {""use_att_constraint"": True}),
        ({""atype"": ""forward_ta""}, {""use_att_constraint"": True}),
    ],
)
",1
"    maxin_len = 10
    maxout_len = 10
    idim = 5
",1
"    if model_args[""use_cbhg""]:
        model_args[""spc_dim""] = 129
    if model_args[""use_speaker_embedding""]:
        model_args[""spk_embed_dim""] = 128
",1
"
    # trainable
",1
"    loss = model(**batch).mean()
",1
"            batch[""xs""][0][: batch[""ilens""][0]], Namespace(**inference_args), spemb
",1
"
@pytest.mark.skipif(not torch.cuda.is_available(), reason=""gpu required"")
@pytest.mark.parametrize(
",1
"    [
        ({}, {}),
        ({""atype"": ""forward""}, {}),
        ({""atype"": ""forward_ta""}, {}),
",1
"    maxin_len = 10
    maxout_len = 10
",1
"        odim,
        maxin_len,
",1
"        device=device,
    )
",1
"    model = Tacotron2(idim, odim, Namespace(**model_args))
    optimizer = torch.optim.Adam(model.parameters())
    model.to(device)

",1
"        model.calculate_all_attentions(**batch)


@pytest.mark.skipif(torch.cuda.device_count() < 2, reason=""multi gpu required"")
@pytest.mark.parametrize(
",1
"    ""model_dict"",
",1
"import torch

from espnet.asr.asr_utils import chainer_load
from espnet.asr.asr_utils import get_model_conf
from espnet.asr.asr_utils import torch_load
",1
"

def download_zip_from_google_drive(download_dir, file_id):
    # directory check
    os.makedirs(download_dir, exist_ok=True)
",1
"        ""wget"",
        ""https://drive.google.com/uc?export=download&id=%s"" % file_id,
",1
"        ""-O"",
        tmpzip,
    ]
    subprocess.run(cmd, check=True)

",1
"        # to avoid it, we need to do some tricky processings
        # see
",1
"        # https://stackoverflow.com/questions/20665881/direct-download-from-google-drive-using-google-drive-api
",1
"        out = subprocess.check_output(
            ""curl -c /tmp/cookies ""
",1
"            (""v.0.3.0 egs/an4/asr1 pytorch"", ""1zF88bRNbJhw9hNBq3NrDg8vnGGibREmg""),
        ),
        (
",1
"        shutil.rmtree(tmpdir)
# coding: utf-8

",1
"#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)
",1
"    def __init__(self):
        super(ChModel, self).__init__()
        with self.init_scope():
            self.a = chainer.links.Linear(3, 1)

",1
"        self.a = torch.nn.Linear(3, 1)
",1
"
",1
"

@pytest.mark.parametrize(""name"", OPTIMIZER_FACTORY_DICT.keys())
def test_optimizer_backend_compatible(name):
    torch.set_grad_enabled(True)
",1
"    # model construction
    ch_model = ChModel()
    th_model = ThModel()

",1
"    # copy params
    th_model.a.weight.data = torch.from_numpy(numpy.copy(ch_model.a.W.data))
    th_model.a.bias.data = torch.from_numpy(numpy.copy(ch_model.a.b.data))
",1
"

def test_pytorch_optimizer_factory():
",1
"        assert g[""rho""] == 0.9
",1
"

def test_chainer_optimizer_factory():
    model = chainer.links.Linear(2, 1)
    opt_class = dynamic_import_optimizer(""adam"", ""chainer"")
",1
"    optimizer = opt_class.build(model, lr=0.9)
    assert optimizer.lr == 0.9
",1
"    opt_class = dynamic_import_optimizer(""adadelta"", ""chainer"")
    optimizer = opt_class.build(model, rho=0.9)
",1
"        eunits=16,
        eprojs=8,
        dtype=""lstm"",
",1
"        awin=5,
        aconv_chans=4,
",1
"        adim=16,
        dropout_rate=0.0,
        dropout_rate_decoder=0.0,
",1
"        nbest=5,
        beam_size=2,
        penalty=0.5,
        maxlenratio=1.0,
        minlenratio=0.0,
",1
"        outdir=None,
        ctc_type=""warpctc"",
",1
"        report_cer=False,
        report_wer=False,
        sym_space=""<space>"",
        sym_blank=""<blank>"",
        replace_sos=False,
",1
"    return idim, odim, ilens, olens


",1
"    ilens = np.array([x.shape[0] for x in xs], dtype=np.int32)

",1
"    ],
)
",1
"):
    idim, odim, ilens, olens = get_default_scope_inputs()
    args = make_arg()

    module = importlib.import_module(""espnet.nets.pytorch_backend.e2e_asr"")
",1
"    model = module.E2E(idim, odim, args)
",1
"    utils = importlib.import_module(""espnet.asr.asr_utils"")

    tmppath = tempfile.mktemp()
",1
"        f.write(
            json.dumps(
",1
"        dec_init_mods=dec_mods,
        mtlalpha=mtlalpha,
",1
"
    with torch.no_grad():
        in_data = np.random.randn(20, idim)
        model.recognize(in_data, args, args.char_list)
",1
"from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"from espnet.utils.training.batchfy import make_batchset
from test.utils_test import make_dummy_json_st

",1
"        etype=""vggblstm"",
        eunits=16,
",1
"        lsm_type="""",
        lsm_weight=0.0,
",1
"        maxlenratio=1.0,
        minlenratio=0.0,
",1
"        ctc_weight=0.0,
        ctc_window_margin=0,  # dummy
        lm_weight=0.0,
        rnnlm=None,
",1
"        tgt_lang=False,
        asr_weight=0.0,
        mt_weight=0.0,
    )
    defaults.update(kwargs)
",1
"
def prepare_inputs(
    mode, ilens=[20, 15], olens_tgt=[4, 3], olens_src=[3, 2], is_cuda=False
):
",1
"
    if mode == ""chainer"":
        raise NotImplementedError

",1
"        ys_tgt = pad_list([torch.from_numpy(y).long() for y in ys_tgt], -1)
        ys_src = pad_list([torch.from_numpy(y).long() for y in ys_src], -1)
",1
"
    return xs, ilens, ys_tgt, ys_src


@pytest.mark.parametrize(
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_st"",
",1
"            ""espnet.nets.pytorch_backend.e2e_st"",
            {""etype"": ""vggblstmp"", ""atype"": ""location2d""},
        ),
        (
",1
"            ""espnet.nets.pytorch_backend.e2e_st"",
",1
"            ""espnet.nets.pytorch_backend.e2e_st"",
",1
"            {""report_cer"": True, ""report_wer"": True, ""asr_weight"": 0.0},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_st"",
            {
",1
"        raise NotImplementedError
",1
"        loss.backward()  # trainable

",1
"            batch_in_data = [np.random.randn(10, 40), np.random.randn(5, 40)]
",1
"def test_sortagrad_trainable(module):
    args = make_arg(sortagrad=1)
    dummy_json = make_dummy_json_st(4, [10, 20], [10, 20], [10, 20], idim=20, odim=5)
    if module == ""pytorch"":
",1
"    batchset = make_batchset(dummy_json, 2, 2 ** 10, 2 ** 10, shortest_first=True)
",1
"        else:
            loss.backward()  # trainable
    with torch.no_grad(), chainer.no_backprop_mode():
        in_data = np.random.randn(50, 20)
",1
"        4, [10, 20], [10, 20], [10, 20], idim=idim, odim=odim
    )
    if module == ""pytorch"":
        import espnet.nets.pytorch_backend.e2e_st as m
",1
"
def init_chainer_weight_const(m, val):
    for p in m.params():
",1
"        if p.data.ndim > 1:
            p.data[:] = val

",1
"
    const = 1e-4
    init_torch_weight_const(th_model, const)

    th_batch = prepare_inputs(""pytorch"")
",1
"@pytest.mark.parametrize(""etype"", [""blstmp"", ""vggblstmp""])
",1
"def test_zero_length_target(etype):
    th = importlib.import_module(""espnet.nets.pytorch_backend.e2e_st"")
",1
"    #     (""aaa"", dict(feat=np.random.randn(200, 40).astype(np.float32), tokenid="""")),
    #     (""bbb"", dict(feat=np.random.randn(100, 40).astype(np.float32), tokenid="""")),
    #     (""cc"", dict(feat=np.random.randn(100, 40).astype(np.float32), tokenid=""""))
",1
"    [
",1
"        (""espnet.nets.pytorch_backend.e2e_st"", ""noatt""),
        (""espnet.nets.pytorch_backend.e2e_st"", ""dot""),
        (""espnet.nets.pytorch_backend.e2e_st"", ""add""),
        (""espnet.nets.pytorch_backend.e2e_st"", ""location""),
",1
"        (""espnet.nets.pytorch_backend.e2e_st"", ""multi_head_add""),
        (""espnet.nets.pytorch_backend.e2e_st"", ""multi_head_loc""),
        (""espnet.nets.pytorch_backend.e2e_st"", ""multi_head_multi_res_loc""),
    ],
",1
"    args = make_arg(atype=atype)
    if ""pytorch"" in module:
        batch = prepare_inputs(""pytorch"")
",1
"    m = importlib.import_module(""espnet.nets.pytorch_backend.e2e_st"")
",1
"    utils = importlib.import_module(""espnet.asr.asr_utils"")
    args = make_arg()
    model = m.E2E(40, 5, args)
    # initialize randomly
",1
"    utils.torch_load(tmppath, model)
    for p1, p2 in zip(p_saved, model.parameters()):
        np.testing.assert_array_equal(p1, p2.data.numpy())
    if os.path.exists(tmppath):
        os.remove(tmppath)
",1
"    if ""pytorch"" in module:
",1
"@pytest.mark.parametrize(""module"", [""espnet.nets.pytorch_backend.e2e_st""])
",1
"        model.cuda()
        loss = 1.0 / ngpu * model(*batch)
        loss.backward(loss.new_ones(ngpu))  # trainable
    else:
",1
"import importlib
import os
",1
"import tempfile

import chainer
",1
"        streaming_offset_margin=2,
        verbose=2,
        char_list=[u""ã"", u""ã"", u""ã"", u""ã"", u""ã""],
        outdir=None,
",1
"        grad_noise=False,
",1
"    return argparse.Namespace(**defaults)


",1
"            pad_list([torch.from_numpy(x).float() for x in xs], 0) for xs in xs_list
        ]
",1
"def convert_batch(
    batch, backend=""pytorch"", is_cuda=False, idim=40, odim=5, num_inputs=2
):
    ilens_list = [
",1
"    xs_list = [
        [np.random.randn(ilen, idim).astype(np.float32) for ilen in ilens_list[idx]]
        for idx in range(num_inputs)
    ]
",1
"

@pytest.mark.parametrize(
",1
"        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 2, {""etype"": [""bgru"", ""bgru""]}),
        (
",1
"            {""etype"": [""vgglstm"", ""vgglstm""]},
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
",1
"            2,
",1
"            2,
            {""atype"": [""multi_head_loc"", ""multi_head_loc""]},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
            {""han_type"": ""coverage_location""},
        ),
",1
"            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
",1
"            2,
",1
"        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 2, {""mtlalpha"": 1.0}),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            2,
",1
"            {""report_cer"": True, ""report_wer"": True, ""mtlalpha"": 0.0},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"            {""elayers"": [2, 3, 4], ""dlayers"": 2},
        ),
        (
",1
"            {""etype"": [""vgglstm"", ""vgglstm"", ""vgglstm""]},
        ),
",1
"            {""etype"": [""vggbgrup"", ""vggbgrup"", ""vggbgrup""]},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            3,
",1
"        ),
",1
"            {
                ""atype"": [
                    ""location_recurrent"",
",1
"                    ""location_recurrent"",
                ]
            },
        ),
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            3,
",1
"            {""atype"": [""multi_head_dot"", ""multi_head_dot"", ""multi_head_dot""]},
        ),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"                ]
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
",1
"            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            3,
            {""sampling_probability"": 0.5},
        ),
",1
"        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 3, {""report_cer"": True}),
        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 3, {""report_wer"": True}),
        (
            ""espnet.nets.pytorch_backend.e2e_asr_mulenc"",
            3,
",1
"        ),
",1
"    m = importlib.import_module(module)
    model = m.E2E([40 for _ in range(num_encs)], 5, args)
    loss = model(*batch)
",1
"
",1
"    tmpdir = tempfile.mkdtemp()
    plot = PlotAttentionReport(
        model.calculate_all_attentions, batchset[0], tmpdir, None, None, None
    )
    for i in range(num_encs):
",1
"    dummy_json = make_dummy_json(
        num_encs, [10, 20], [10, 20], idim=20, odim=5, num_inputs=num_encs
",1
"        6, [10, 20], [10, 20], idim=20, odim=5, num_inputs=num_encs
    )
    import espnet.nets.pytorch_backend.e2e_asr_mulenc as m

    batchset = make_batchset(dummy_json, 2, 2 ** 10, 2 ** 10, shortest_first=True)
",1
"        model.recognize(in_data, args, args.char_list)
",1
"    odim = 5
    dummy_json = make_dummy_json(
        4, [10, 20], [10, 20], idim=idim, odim=odim, num_inputs=num_encs
    )
    import espnet.nets.pytorch_backend.e2e_asr_mulenc as m
",1
"        n = 0
",1
"        for uttid, info in batch:
",1
"            ilen = int(info[""input""][0][""shape""][0])  # based on the first input
            olen = int(info[""output""][0][""shape""][0])
            n += ilen * idim + olen * odim
",1
"        assert olen < batch_elems

    model = m.E2E([20 for _ in range(num_encs)], 5, args)
    for batch in batchset:
",1
"        i = 0
",1
"    ""module, num_encs, atype"",
    [
",1
"
@pytest.mark.parametrize(""num_encs"", [2, 3])
def test_torch_save_and_load(num_encs):
    m = importlib.import_module(""espnet.nets.pytorch_backend.e2e_asr_mulenc"")
",1
"    for p in model.parameters():
",1
"        os.makedirs("".pytest_cache"")
    tmppath = tempfile.mktemp()
    utils.torch_save(tmppath, model)
    p_saved = [p.data.numpy() for p in model.parameters()]
",1
"    not torch.cuda.is_available() and not chainer.cuda.available, reason=""gpu required""
)
@pytest.mark.parametrize(
    ""module, num_encs"",
    [
",1
"        (""espnet.nets.pytorch_backend.e2e_asr_mulenc"", 3),
    ],
",1
"    assert xpad.data.tolist() == es


def test_bmm_attention():
    b, t, h = 3, 2, 5
",1
"# Copyright 2019 Tomoki Hayashi
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

",1
"        dprenet_units=32,
        adim=32,
",1
"        eprenet_dropout_rate=0.1,
",1
"        transformer_enc_dec_attn_dropout_rate=0.0,
        spk_embed_integration_type=""add"",
",1
"        decoder_concat_after=False,
",1
"        ({""use_guided_attn_loss"": True, ""reduction_factor"": 3}),
        (
",1
"                ""modules_applied_guided_attn"": [""encoder-decoder""],
            }
        ),
",1
"
    # check gradient of ScaledPositionalEncoding
",1
"        ({""spk_embed_dim"": 16, ""spk_embed_integration_type"": ""concat""}),
        ({""spk_embed_dim"": 16, ""spk_embed_integration_type"": ""add""}),
        ({""use_masking"": False}),
        ({""use_scaled_pos_enc"": False}),
        ({""bce_pos_weight"": 10.0}),
",1
"        assert model.encoder.embed[1].alpha.grad is not None
        assert model.decoder.embed[1].alpha.grad is not None
",1
"
",1
"        ({}),
",1
"        ({""spk_embed_dim"": 16, ""spk_embed_integration_type"": ""concat""}),
",1
"    odim = 10
    ilens = [10, 5]
",1
"    model.to(device)
    optimizer = torch.optim.Adam(model.parameters())

    # trainable
",1
"
    # setup batch
    idim = 5
    odim = 10
",1
"    ilens = [10, 5]
    olens = [20, 15]
    batch = prepare_inputs(idim, odim, ilens, olens)
",1
"    # define model
    model = Transformer(idim, odim, Namespace(**model_args))

    # test encoder self-attention
",1
"    for aw, ilen in zip(aws, batch[""ilens""]):
        assert not np.isnan(aw[:, :ilen, :ilen]).any()
",1
"
    # test encoder-decoder attention
",1
"    ys = model.decoder.embed(batch[""ys""])
    ys[1, olens[1] :] = float(""nan"")
",1
"        np.testing.assert_almost_equal(
",1
"    # define model
    model = Transformer(idim, odim, Namespace(**model_args))
    model.eval()

",1
"            1, 2
        )
        # --------- forward calculation ---------
",1
"        maxlen = ys_in.shape[1]
",1
"        minlen = ys_in.shape[1]
        idx = 0
        # this is the inferene calculation but we use groundtruth to check the behavior
        ys_in_ = ys_in[0, idx].view(1, 1, model.odim)
",1
"        np.testing.assert_array_equal(
",1
"            )  # (1, idx + 1, odim)
        # --------- inference calculation ---------

",1
"        # check both are equal
        np.testing.assert_array_almost_equal(
            hs_fp.detach().cpu().numpy(), hs_ir.detach().cpu().numpy(),
        )
        np.testing.assert_array_almost_equal(
",1
"
import numpy
import pytest
",1
"
",1
"    dtype=""lstm"",
    dlayers=1,
    dunits=16,
    atype=""location"",
",1
"    minlenratio=0.0,
    ctc_weight=0.2,
    lm_weight=0.0,
    rnnlm=None,
",1
"    ctc_type=""warpctc"",
    report_cer=False,
    report_wer=False,
",1
"    ctc_type=""warpctc"",
",1
"    lsm_weight=0.001,
",1
"    n_token = odim - 1
    # avoid 0 for eps in ctc
    y = (torch.rand(batchsize, 10) * n_token % (n_token - 1)).long() + 1
",1
"        )
    return model, x, torch.tensor(ilens), y, data, args
",1
"    ""model_class, args, ctc_weight, lm_weight, bonus, device, dtype"",
    [
        (nn, args, ctc, lm, bonus, device, dtype)
",1
"    model_class, args, ctc_weight, lm_weight, bonus, device, dtype
",1
"    if device == ""cuda"" and not torch.cuda.is_available():
        pytest.skip(""no cuda device is available"")
    if device == ""cpu"" and dtype == ""float16"":
",1
"    # test previous beam search
    args = Namespace(
        beam_size=3,
        penalty=bonus,
",1
"    scorers[""length_bonus""] = LengthBonus(len(char_list))
    weights = dict(
        decoder=1.0 - ctc_weight,
        ctc=ctc_weight,
",1
"        lm=args.lm_weight,
",1
"        beam_size=args.beam_size,
        vocab_size=len(char_list),
        weights=weights,
",1
"        scorers=scorers,
        token_list=train_args.char_list,
",1
"
from espnet.utils.io_utils import LoadInputsAndTargets
from espnet.utils.io_utils import SoundHDF5File
",1
"    print([len(batch) for batch in batchset])
",1
"        dummy_json, 24, 256, 64, min_batch_size=10, swap_io=swap_io
    )
",1
"            swap_io=True,
        )
        key = ""output""
    else:
",1
"    ark = str(tmpdir.join(""test.ark""))
    scp = str(tmpdir.join(""test.scp""))
",1
"            batch.append(
                (
                    uttid,
                    {
                        ""input"": [{""feat"": path, ""name"": ""input1""}],
",1
"            )

    load_inputs_and_targets = LoadInputsAndTargets()
",1
"    #                      ""name"": ""input1""}
    #                     {""feat"": ""some/path2.ark:123""
",1
"
    for line_1, line_2 in zip(lines_1, lines_2):
        uttid, path_1 = line_1.strip().split()
        uttid, path_2 = line_2.strip().split()
        batch.append(
",1
"                {
",1
"    xs_1, xs_2, ys = load_inputs_and_targets(batch)
    for x, xd in zip(xs_1, desire_xs_1):
",1
"    desire_ys = []
    batch = []
",1
"                        ""input"": [
                            {
                                ""feat"": str(p) + "":"" + uttid,
                                ""filetype"": ""hdf5"",
",1
"                    },
                )
            )
            desire_xs.append(x)
",1
"            desire_ys.append(np.array([1, 2, 3, 4]))

    load_inputs_and_targets = LoadInputsAndTargets()
",1
"    xs, ys = load_inputs_and_targets(batch)
    for x, xd in zip(xs, desire_xs):
        np.testing.assert_array_equal(x, xd)
    for y, yd in zip(ys, desire_ys):
",1
"
    space = ""<space>""
    blank = ""<blank>""
",1
"        assert cer_ctc_val is not None
        assert _cer is None
",1
"    cer_ctc_val = ec(ys_pad, ys_hat, is_ctc=True)
    _cer, _wer = ec(ys_pad, ys_hat)
    assert cer_ctc_val is not None
    assert _cer is not None
    assert _wer is not None
",1
"    kwargs = {
        ""process"": [
            {""type"": ""fbank"", ""n_mels"": 80, ""fs"": 16000, ""n_fft"": 1024, ""n_shift"": 512},
",1
"    # Creates cmvn_ark
    samples = np.random.randn(100, 80)
",1
"    xs = [np.random.randn(1000).astype(np.float32) for _ in range(bs)]
    preprocessing = Transformation(kwargs)
",1
"    processed_xs = preprocessing(xs)
",1
"        return x + a - b

    class FooBar(FuncTrans):
        _func = foo_bar
",1
"    format=""%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s"",
)


",1
"    ""Mask out subsequent positions.""
    attn_shape = (1, size, size)
    subsequent_mask = numpy.triu(numpy.ones(attn_shape), k=1).astype(""uint8"")
",1
"
@pytest.mark.parametrize(""module"", [""pytorch""])
def test_mask(module):
",1
"    T = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_asr_transformer"".format(module)
    )
    m = T.subsequent_mask(3)
    print(m)
",1
"

def make_arg(**kwargs):
    defaults = dict(
",1
"        adim=16,
",1
"    )
",1
"    olens = [3, 9, 10, 2, 3]
    for i in range(batchsize):
",1
"        y[i, olens[i] :] = model.ignore_id

",1
"                {
                    ""input"": [{""shape"": [ilens[i], idim]}],
                    ""output"": [{""shape"": [olens[i]]}],
                },
            )
",1
"        )
    if backend == ""pytorch"":
        return model, x, torch.tensor(ilens), y, data
    else:
        return model, x, ilens, y, data
",1
"

@pytest.mark.parametrize(""module"", [""pytorch""])
def test_transformer_mask(module):
",1
"    args = make_arg()
    model, x, ilens, y, data = prepare(module, args)
",1
"@pytest.mark.parametrize(
",1
"    ""module, model_dict"",
    [
        (""pytorch"", {}),
",1
"        (""pytorch"", {""report_cer"": True}),
        (""pytorch"", {""report_wer"": True}),
        (""pytorch"", {""report_cer"": True, ""report_wer"": True}),
",1
"        (""pytorch"", {""report_cer"": True, ""report_wer"": True, ""mtlalpha"": 0.0}),
        (""pytorch"", {""report_cer"": True, ""report_wer"": True, ""mtlalpha"": 1.0}),
        (""chainer"", {}),
    ],
)
",1
"        # test decodable
        with chainer.no_backprop_mode():
",1
"    idim = 11
    odim = idim
",1
"        model = T.E2E(idim, odim, args)
    else:
        model = None
",1
"            (
",1
"        )
",1
"            nbest = model.recognize(x[i, : ilens[i]].numpy(), recog_args)
",1
"    # test acc is almost 100%
    optim = torch.optim.Adam(model.parameters(), 0.02)
",1
"        #    data, attn_dict, ""/tmp/espnet-test"", ""iter%d.png"" % i
",1
"

# https://github.com/espnet/espnet/issues/1750
def test_v0_3_transformer_input_compatibility():
    args = make_arg()
",1
"if __name__ == ""__main__"":
    run_transformer_copy()
",1
"import numpy as np

",1
"
def make_dummy_json(
    n_utts=10,
    ilen_range=(100, 300),
    olen_range=(10, 300),
",1
"    idim=83,
    odim=52,
    num_inputs=1,
):
",1
"    ilens = np.random.randint(ilen_range[0], ilen_range[1], n_utts)
    olens = np.random.randint(olen_range[0], olen_range[1], n_utts)
",1
"    for idx in range(n_utts):
        input = []
        for input_idx in range(num_inputs):
",1
"    olens_asr = np.random.randint(olen_asr_range[0], olen_asr_range[1], n_utts)
",1
"        output = [{""shape"": [olens[idx], odim]}, {""shape"": [olens_asr[idx], odim]}]
        dummy_json[""utt_%d"" % idx] = {""input"": input, ""output"": output}
    return dummy_json


",1
"import espnet.nets.pytorch_backend.lm.default as lm_pytorch
from espnet.nets.scorers.length_bonus import LengthBonus

from test.test_beam_search import prepare
",1
"        for n in range(ch_rnnlm.n_layers):
",1
"            transfer_lstm(ch_rnnlm.rnn[n], th_rnnlm.rnn[n])
    else:
",1
"        assert False
    th_rnnlm.lo.weight.data = torch.from_numpy(ch_rnnlm.lo.W.data)
",1
"

def test_lm():
    n_vocab = 3
    n_layers = 2
",1
"        x = torch.from_numpy(numpy.random.randint(n_vocab, size=batchsize)).long()
        with torch.no_grad(), chainer.no_backprop_mode(), chainer.using_config(
            ""train"", False
        ):
",1
"                    print(state_th[k][n].data.numpy())
                    print(state_ch[k][n].data)
                    numpy.testing.assert_allclose(
                        state_th[k][n].data.numpy(), state_ch[k][n].data, 1e-5
",1
"

@pytest.mark.parametrize(
    ""lm_name, lm_args, device, dtype"",
",1
"    [
        (nn, args, device, dtype)
        for nn, args in (
",1
"            (""default"", dict(type=""lstm"", layer=2, unit=2, dropout_rate=0.5)),
            (""default"", dict(type=""gru"", layer=2, unit=2, dropout_rate=0.5)),
            (""seq_rnn"", dict(type=""lstm"", layer=2, unit=2, dropout_rate=0.5)),
            (""seq_rnn"", dict(type=""gru"", layer=2, unit=2, dropout_rate=0.5)),
",1
"            ),
            (
                ""transformer"",
                dict(
                    layer=2,
",1
"                    unit=2,
                    att_unit=2,
                    head=2,
                    dropout_rate=0.5,
",1
"    dtype = getattr(torch, dtype)
    model, x, ilens, y, data, train_args = prepare(""rnn"", rnn_args)
    char_list = train_args.char_list
    n_vocab = len(char_list)
",1
"    scorers[""length_bonus""] = LengthBonus(len(char_list))
    weights = dict(decoder=1.0, lm=1.0, length_bonus=1.0)
    with torch.no_grad():
        feat = x[0, : ilens[0]].to(device=device, dtype=dtype)
        enc = model.encode(feat)
",1
"            weights=weights,
            scorers=scorers,
            token_list=train_args.char_list,
        )
",1
"    assert len(result) >= beam_size
# coding: utf-8

",1
"# Copyright 2018 Hiroshi Seki
#  Apache 2.0  (http://www.apache.org/licenses/LICENSE-2.0)

import argparse
",1
"        batch_count=""auto"",
        batch_frames_in=0,
        batch_frames_inout=0,
",1
"        eunits=100,
        fbank_fmax=None,
        fbank_fmin=0.0,
",1
"    for p in m.parameters():
        p.data.fill_(val)


def init_chainer_weight_const(m, val):
",1
"                ),
            )
        ]

        in_data = data[0][1][""feat""]
",1
"    losses_2 = torch.ones([bs, 4], dtype=torch.float32)
    for i in range(bs):
        losses_2[i][i % 4] = 0
    true_losses_2 = torch.ones(bs, dtype=torch.float32) / 2
    perm_choices_2 = [[0, 1], [1, 0], [1, 0], [0, 1]]
",1
"    for i in range(bs):
        true_perm_2.append(perm_choices_2[i % 4])
    true_perm_2 = torch.tensor(true_perm_2).long()

",1
"    feat_real = torch.from_numpy(numpy.random.uniform(size=(bs, 100, 2, 257))).float()
    feat_imag = torch.from_numpy(numpy.random.uniform(size=(bs, 100, 2, 257))).float()
",1
"    assert torch.equal(enhanced2.real, enhanced[1].real)
",1
"import argparse
import importlib
",1
"import torch
",1
"        report_cer=False,
",1
"        report_wer=False,
",1
"        nbest=1,
        verbose=2,
",1
"    )
",1
"    )
    recog_defaults.update(kwargs)

    return argparse.Namespace(**recog_defaults)

",1
"    xs = [np.random.randn(ilen, idim).astype(np.float32) for ilen in ilens]
    ys = [np.random.randint(1, odim, olen).astype(np.int32) for olen in olens]
    ilens = np.array([x.shape[0] for x in xs], dtype=np.int32)

",1
"    if backend == ""pytorch"":
        xs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0)
        ys_pad = pad_list([torch.from_numpy(y).long() for y in ys], -1)
        ilens = torch.from_numpy(ilens).long()
",1
"        ({""rnnt_mode"": ""rnnt-att""}, {}),
        ({""etype"": ""gru""}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""etype"": ""gru""}, {}),
",1
"        ({""etype"": ""blstm""}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""etype"": ""blstm""}, {}),
        ({""etype"": ""vgggru""}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""etype"": ""vgggru""}, {}),
",1
"        ({""etype"": ""vggbru""}, {}),
",1
"        ({""etype"": ""blstm"", ""eprojs"": 16}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""etype"": ""blstm"", ""eprojs"": 16}, {}),
",1
"        ({""dtype"": ""gru"", ""dlayers"": 2}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""dtype"": ""gru"", ""dlayers"": 2}, {}),
        ({""dtype"": ""lstm"", ""dlayers"": 3}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""dtype"": ""lstm"", ""dlayers"": 3}, {}),
",1
"                ""joint-dim"": 4,
            },
",1
"            {},
        ),
        ({""dec-embed-dim"": 16}, {}),
        ({""dec-embed-dim"": 16, ""dropout-rate-embed-decoder"": 0.1}, {}),
        ({""dunits"": 16}, {""beam_size"": 1}),
",1
"        ({""rnnt_mode"": ""rnnt-att"", ""dunits"": 2}, {""beam_size"": 1}),
        ({""dropout-rate-decoder"": 0.2}, {}),
",1
"        ({""rnnt_mode"": ""rnnt-att"", ""atype"": ""multi_head_loc""}, {}),
        ({""rnnt_mode"": ""rnnt-att"", ""atype"": ""multi_head_multi_res_loc""}, {}),
",1
"        (
            {
                ""rnnt_mode"": ""rnnt-att"",
                ""beam_size"": 1,
",1
"        ({""beam_size"": 1, ""report_cer"": False, ""report_wer"": True}, {}),
        (
            {
                ""rnnt_mode"": ""rnnt-att"",
                ""beam_size"": 1,
",1
"            },
            {},
        ),
    ],
",1
"        model.recognize(in_data, recog_args, train_args.char_list)

",1
"    module = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_asr_transducer"".format(backend)
    )
",1
"    model = module.E2E(idim, odim, train_args)
    model.cuda()

    batch = prepare_inputs(backend, idim, odim, ilens, olens, is_cuda=True)
",1
"

@pytest.mark.skipif(torch.cuda.device_count() < 2, reason=""multi gpu required"")
",1
"
    ngpu = 2
",1
"    )
    model = module.E2E(idim, odim, train_args)
    model = torch.nn.DataParallel(model, device_ids)
",1
"        ""add"",
",1
"    idim, odim, ilens, olens = get_default_scope_inputs()
    train_args = get_default_train_args(rnnt_mode=""rnnt-att"", atype=atype)

    module = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_asr_transducer"".format(backend)
",1
"
def make_train_args(**kwargs):
    train_defaults = dict(
        transformer_init=""pytorch"",
        transformer_input_layer=""conv2d"",
",1
"        rnnlm=None,
    )
    train_defaults.update(kwargs)

",1
"    return bs, idim, odim, ilens, olens
",1
"    from espnet.nets.pytorch_backend.transformer.repeat import MultiSequential

    class Masked(torch.nn.Module):
        def forward(self, x, m):
",1
"    x = torch.randn(2, 3)
    m = torch.randn(2, 3) > 0
    assert len(f(x, m)) == 2

    if torch.cuda.is_available():
",1
"                    ""output"": [{""shape"": [olens[i]]}],
                },
            )
        )
",1
"@pytest.mark.parametrize(""module"", [""pytorch""])
def test_sa_transducer_mask(module):
    from espnet.nets.pytorch_backend.nets_utils import make_pad_mask
    from espnet.nets.pytorch_backend.transducer.utils import prepare_loss_inputs
",1
"            {
                ""transformer_attn_dropout_rate_encoder"": 0.2,
                ""transformer_attn_dropout_rate_decoder"": 0.3,
            },
            {},
",1
"                ""eunits"": 8,
                ""adim"": 4,
",1
"        ),
        ({""report_cer"": True, ""beam_size"": 1}, {}),
        ({""report_wer"": True, ""beam_size"": 1}, {}),
        ({""report_cer"": True, ""beam_size"": 2}, {}),
",1
"
    with torch.no_grad():
        nbest = model.recognize(x[0, : ilens[0]].numpy(), recog_args)

        print(y[0])
",1
"        print(nbest[0][""yseq""][1:-1])


def test_sa_transducer_parallel():
",1
"
    optim = torch.optim.Adam(model.parameters(), 0.02)

    for i in range(10):
",1
"        loss.mean().backward()
",1
"import torch

from test.test_e2e_asr_transformer import run_transformer_copy
from test.test_e2e_asr_transformer import subsequent_mask
",1
"        aheads=2,
",1
"        dropout_rate=0.0,
        transformer_attn_dropout_rate=None,
        elayers=2,
        eunits=16,
        dlayers=2,
",1
"        asr_weight=0.0,
        mt_weight=0.0,
    )
    defaults.update(kwargs)
",1
"        x = numpy.random.randn(batchsize, 40, idim).astype(numpy.float32)
    ilens = [40, 30, 20, 15, 10]
    n_token = odim - 1
    if backend == ""pytorch"":
",1
"        y_tgt = (torch.rand(batchsize, 11) * n_token % n_token).long()
    else:
",1
"    for i in range(batchsize):
        data.append(
            (
                ""utt%d"" % i,
                {
",1
"
    yi, yo = add_sos_eos(y_tgt, model.sos, model.eos, model.ignore_id)
",1
"    a(y_tgt, y_tgt, y_tgt, y_mask)
    assert not numpy.isnan(a.attn[0, :, :3, :3].detach().numpy()).any()
",1
"        (""pytorch"", {""asr_weight"": 0.1, ""mtlalpha"": 1.0, ""report_cer"": True}),
",1
"                ""report_wer"": True,
",1
"            },
",1
"        ),  # MTL w/ CTC ASR + MT
        (
            ""pytorch"",
            {""asr_weight"": 0.1, ""mtlalpha"": 0.5, ""mt_weight"": 0.0},
        ),  # MTL w/ attention ASR + CTC ASR
",1
")
def test_transformer_trainable_and_decodable(module, model_dict):
    args = make_arg(**model_dict)
    model, x, ilens, y_tgt, y_src, data = prepare(module, args)

",1
"        optim = torch.optim.Adam(model.parameters(), 0.01)
        loss = model(x, ilens, y_tgt, y_src)
        optim.zero_grad()
        loss.backward()
        optim.step()
",1
"
        # test attention plot
",1
"
        plot.plot_multi_head_attention(data, attn_dict, ""/tmp/espnet-test"")

        # test decodable
",1
"    run_transformer_copy()
from collections import defaultdict

",1
"    # setup model
    model = chainer.links.Classifier(chainer.links.Linear(3, 2))
    optimizer = chainer.optimizers.Adam()
    optimizer.setup(model)

",1
"    # setup data
    data_size = 6
",1
"    # test runnable with tensorboard logger
    for log_interval in [1, 3]:
",1
"import numpy
import pytest
",1
"@pytest.mark.parametrize(
    ""in_length,out_length"", [([11, 17, 15], [4, 2, 3]), ([4], [1])]
)
def test_ctc_loss(in_length, out_length, use_warpctc):
    pytest.importorskip(""torch"")
",1
"            # Batch-size average
            loss = loss / th_pred.size(1)
            return loss

    n_out = 7
",1
"    # NOTE: this index 0 is only for CTC not attn. so it can be ignored
    # unfortunately, torch cross_entropy does not accept out-of-bound ids
    th_ignore = 0
    th_pred = torch.from_numpy(y_all.data)
    th_target = pad_list([torch.from_numpy(t.data).long() for t in ys_out], th_ignore)
",1
"    else:
        reduction_str = ""mean""
    th_loss = torch.nn.functional.cross_entropy(
        th_pred, th_target.view(-1), ignore_index=th_ignore, reduction=reduction_str
",1
"    # while chainer's default setting does
    loss_data = float(th_loss)
",1
"    )
    # NOTE: 0 is only used for CTC, never appeared in attn target
    np_target = [
",1
"        numpy.random.randint(1, n_out - 1, size=ol, dtype=numpy.int32)
        for ol in label_length
    ]
",1
"    # unfortunately, torch cross_entropy does not accept out-of-bound ids
    th_ignore = 0
    th_pred = torch.from_numpy(y_all.data)
    th_ys = [torch.from_numpy(numpy.append(t, eos)).long() for t in np_target]
    th_target = pad_list(th_ys, th_ignore)
",1
"
from espnet.utils.cli_readers import file_reader_helper
from espnet.utils.cli_utils import assert_scipy_wav_style
from espnet.utils.cli_writers import file_writer_helper

",1
"
    # 1. Test ark read
    if filetype != ""sound"":
",1
"            np.testing.assert_array_equal(value, valid[key].shape)
    # 4. Test scp shape read
    for key, value in file_reader_helper(
",1
"        np.testing.assert_array_equal(value, valid[key].shape)
# coding: utf-8

# Copyright 2019 Hirofumi Inaguma
",1
"        sampling_probability=0.0,
        adim=16,
",1
"        dropout_rate=0.0,
        dropout_rate_decoder=0.0,
        nbest=5,
        beam_size=3,
        penalty=0.5,
",1
"        verbose=2,
        char_list=[u""ã"", u""ã"", u""ã"", u""ã"", u""ã""],
        outdir=None,
        report_bleu=False,
",1
"
def convert_batch(batch, backend=""pytorch"", is_cuda=False, idim=5, odim=5):
",1
"        ys = pad_list([torch.from_numpy(y).long() for y in ys], -1)

        if is_cuda:
            xs = xs.cuda()
            ilens = ilens.cuda()
",1
"def test_model_trainable_and_decodable(module, model_dict):
    args = make_arg(**model_dict)
    if ""pytorch"" in module:
        batch = prepare_inputs(""pytorch"")
    else:
",1
"    if isinstance(loss, tuple):
        # chainer return several values as tuple
",1
"        model.translate(in_data, args, args.char_list)  # decodable
        if ""pytorch"" in module:
            batch_in_data = np.random.randint(0, 5, (2, 10))
            model.translate_batch(
                batch_in_data, args, args.char_list
",1
"        loss = model(*convert_batch(batch, module, idim=6, odim=5))
        if isinstance(loss, tuple):
",1
"@pytest.mark.parametrize(""module"", [""pytorch""])
def test_sortagrad_trainable_with_batch_bins(module):
    args = make_arg(sortagrad=1)
    idim = 6
",1
"
    th_model.zero_grad()

",1
"    args = make_arg(etype=etype)
",1
"    th_model = th.E2E(6, 5, args)
",1
"    # out_data = """"
    # data = [
    #     (""aaa"",
",1
"        (""espnet.nets.pytorch_backend.e2e_mt"", ""dot""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""add""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""coverage""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""multi_head_dot""),
        (""espnet.nets.pytorch_backend.e2e_mt"", ""multi_head_add""),
",1
"    ],
)
",1
"def test_calculate_all_attentions(module, atype):
",1
"
",1
"    m = importlib.import_module(""espnet.nets.pytorch_backend.e2e_mt"")
    utils = importlib.import_module(""espnet.asr.asr_utils"")
    args = make_arg()
    model = m.E2E(6, 5, args)
    # initialize randomly
",1
"    if not os.path.exists("".pytest_cache""):
        os.makedirs("".pytest_cache"")
    tmppath = tempfile.mktemp()
",1
"        os.remove(tmppath)

",1
"    model = m.E2E(6, 5, args)
    if ""pytorch"" in module:
",1
"    ngpu = 2
    device_ids = list(range(ngpu))
    args = make_arg()
",1
"    model = m.E2E(6, 5, args)
    if ""pytorch"" in module:
        model = torch.nn.DataParallel(model, device_ids)
",1
"    import kaldi_io

    train_scp = ""scp:egs/voxforge/asr1/data/tr_it/feats.scp""
",1
"        pytest.skip(""voxforge scp has not been created"")

    r1 = kaldiio.load_scp(train_scp).items()
    r2 = kaldi_io.RandomAccessBaseFloatMatrixReader(train_scp)

",1
"import numpy
import pytest
import torch

",1
"from espnet.nets.batch_beam_search import BatchBeamSearch
",1
"from espnet.nets.batch_beam_search import BeamSearch
",1
"from test.test_beam_search import prepare
from test.test_beam_search import transformer_args


",1
"        Hypothesis(
            yseq=torch.tensor([0, 1]),
            score=torch.tensor(0.1),
",1
"        assert us[i].score == hs[i].score
        assert us[i].scores == hs[i].scores
        assert us[i].states == hs[i].states
",1
"lstm_lm = Namespace(type=""lstm"", layer=1, unit=2, dropout_rate=0.0)
",1
"        pytest.skip(""no cuda device is available"")
    if device == ""cpu"" and dtype == ""float16"":
        pytest.skip(""cpu float16 implementation is not available in pytorch yet"")

",1
"    lm.eval()

    # test previous beam search
    args = Namespace(
",1
"        minlenratio=0,
",1
"        nbest=5,
    )
",1
"        lm=args.lm_weight,
",1
"        sos=model.sos,
        eos=model.eos,
        pre_beam_score_key=None if ctc_weight == 1.0 else ""decoder"",
",1
"    )
    legacy_beam.to(device, dtype=dtype)
    legacy_beam.eval()
",1
"        eos=model.eos,
",1
"    y = pe(x)
    init_cache = pe.pe

    # test not extended from init
    x = torch.rand(2, 3, dim, dtype=dtype, device=device)
",1
"    if device == ""cuda"" and not torch.cuda.is_available():
",1
"    init_cache = pe.pe

    # test not extended from init
",1
"        self.register_buffer(""pe"", pe)
",1
"
",1
"

",1
"    legacy_net = torch.nn.Sequential(
",1
"        LegacyPositionalEncoding(4, 0.0), torch.nn.Linear(4, 2)
",1
"    legacy = legacy_net(x)
    latest = latest_net(x)
",1
"        eunits=100,
        eprojs=100,
        dtype=""lstm"",
        dlayers=1,
",1
"        word_list=[""<blank>"", ""<unk>"", ""ai"", ""iu"", ""ue"", ""eo"", ""oa"", ""<eos>""],
        outdir=None,
        ctc_type=""warpctc"",
        report_cer=False,
        report_wer=False,
",1
"        sym_space=""<space>"",
        sym_blank=""<blank>"",
",1
"        if ""wordlm.lo.bias"" in name or ""dec.output.bias"" in name:
            p.data[0] = -10.0

",1
"        (""blstmp"", ""lstm"", ""espnet.nets.pytorch_backend.e2e_asr"", 1),
",1
"        [""o"", ""iuiuiuiuiuiuiuo"", ""ieieieieieieieieo""],
        [""o"", ""iuiuiuiuiuiuiuiuo"", ""iuiuiuiuiuiuiuiuo""],
",1
"
        args = make_arg(etype=etype, ctc_weight=ctc_weight)
",1
"            )
        ]
",1
"
        in_data = data[0][1][""feat""]
        nbest_hyps = model.recognize(in_data, args, args.char_list)
        y_hat = nbest_hyps[0][""yseq""][1:]
        seq_hat = [args.char_list[int(idx)] for idx in y_hat]
",1
"@pytest.mark.parametrize(
",1
"    (""etype"", ""dtype"", ""m_str"", ""text_idx1""),
    [
",1
"        (""vggbgrup"", ""gru"", ""espnet.nets.chainer_backend.e2e_asr"", 6),
",1
")
def test_recognition_results_with_lm(etype, dtype, m_str, text_idx1):
    const = 1e-4
",1
"        [""o"", ""o"", ""ieieieieieieieieo""],
        [""o"", ""iuiuiuiuiuiuiuiuo"", ""iuiuiuiuiuiuiuiuo""],
        [""o"", ""o"", ""ieieieieieieieieo""],
",1
"        [""o"", ""iuiuiuiuiuiuiuiuo"", ""iuiuiuiuiuiuiuiuo""],
        [""o"", ""o"", ""ieieieieieieieieo""],
    ]

    # ctc_weight: 0.0 (attention), 0.5 (hybrid CTC/attention), 1.0 (CTC)
",1
"            init_torch_weight_const(model, const)
",1
"            init_torch_weight_const(rnnlm, const)
        else:
            rnnlm = lm_chainer.ClassifierWithState(
                lm_chainer.RNNLM(len(args.char_list), 2, 10)
            )
",1
"            init_chainer_weight_const(model, const)
            init_chainer_weight_const(rnnlm, const)

",1
"                )
            )
            init_torch_weight_random(model, rand_range)
            init_torch_weight_random(rnnlm, rand_range)
            model.eval()
",1
"@pytest.mark.parametrize(""module"", [""pytorch""])
",1
"    print(subsequent_mask(3))
    assert (m.unsqueeze(0) == subsequent_mask(3)).all()


",1
"    idim = 5
    odim = 5
    T = importlib.import_module(
        ""espnet.nets.{}_backend.e2e_mt_transformer"".format(backend)
    )
",1
"        y_src = (torch.randn(batchsize, 10) * n_token % n_token).long() + 1
        y_tgt = (torch.randn(batchsize, 11) * n_token % n_token).long() + 1
        # NOTE: + 1 to avoid to assign idx:0
    else:
",1
"        y_tgt[i, olens[i] :] = model.ignore_id

",1
"                ""utt%d"" % i,
                {""input"": [{""shape"": [ilens[i]]}], ""output"": [{""shape"": [olens[i]]}]},
            )
",1
"        (""pytorch"", {}),
        (""pytorch"", {""report_bleu"": True}),
        (""pytorch"", {""tie_src_tgt_embedding"": True}),
",1
"    # test beam search
    trans_args = argparse.Namespace(
",1
"        lm_weight=0,
",1
"
import numpy as np
",1
"
def make_taco2_args(**kwargs):
    defaults = dict(
        model_module=""espnet.nets.pytorch_backend.e2e_tts_tacotron2:Tacotron2"",
        use_speaker_embedding=False,
",1
"        eunits=32,
",1
"        use_concate=True,
        use_residual=False,
        dropout_rate=0.5,
",1
"        zoneout_rate=0.1,
",1
"        eprenet_conv_layers=0,
        eprenet_conv_filts=0,
        eprenet_conv_chans=0,
        dprenet_layers=2,
",1
"        eunits=32,
",1
"        eprenet_dropout_rate=0.1,
        dprenet_dropout_rate=0.5,
        postnet_dropout_rate=0.1,
",1
"        use_batch_norm=True,
        use_scaled_pos_enc=True,
",1
"    defaults.update(kwargs)
",1
"    defaults = dict(
        spk_embed_dim=None,
        adim=32,
",1
"        duration_predictor_kernel_size=3,
        duration_predictor_dropout_rate=0.1,
        positionwise_layer_type=""linear"",
        positionwise_conv_kernel_size=1,
        postnet_layers=0,
",1
"        use_masking=True,
        use_weighted_masking=False,
        use_scaled_pos_enc=True,
        encoder_normalize_before=True,
",1
"        (""transformer"", {""decoder_normalize_before"": False}),
",1
"        ),
        (""transformer"", {""encoder_concat_after"": True}),
        (""transformer"", {""decoder_concat_after"": True}),
        (""transformer"", {""encoder_concat_after"": True, ""decoder_concat_after"": True}),
        (""transformer"", {""transfer_encoder_from_teacher"": True}),
",1
"            {
                ""transfer_encoder_from_teacher"": True,
                ""transferred_encoder_module"": ""embed"",
",1
"        (""transformer"", {""reduction_factor"": 3}),
        (""transformer"", {""reduction_factor"": 4}),
        (""transformer"", {""reduction_factor"": 5}),
        (""tacotron2"", {}),
        (""tacotron2"", {""spk_embed_dim"": 16}),
",1
"        (""tacotron2"", {""reduction_factor"": 3}),
        (""tacotron2"", {""reduction_factor"": 4}),
        (""tacotron2"", {""reduction_factor"": 5}),
    ],
)
",1
"
    # setup batch
    ilens = [10, 5]
    olens = [20, 15]
",1
"    batch = prepare_inputs(idim, odim, ilens, olens, model_args[""spk_embed_dim""])

    # define teacher model and save it
    if teacher_type == ""transformer"":
",1
"
    # define model
    model_args[""teacher_model""] = tmpdir + ""/model.dummy.best""
    model = FeedForwardTransformer(idim, odim, Namespace(**model_args))
",1
"    if os.path.exists(tmpdir):
        shutil.rmtree(tmpdir)
",1
")
def test_fastspeech_gpu_trainable_and_decodable(teacher_type, model_dict):
    # make args
    idim, odim = 10, 25
    model_args = make_feedforward_transformer_args(**model_dict)
",1
"
",1
"        if model_args[""spk_embed_dim""] is None:
            spemb = None
        else:
            spemb = batch[""spembs""][0]
",1
"        (""tacotron2"", {}),
        (""tacotron2"", {""spk_embed_dim"": 16}),
    ],
)
def test_fastspeech_multi_gpu_trainable(teacher_type, model_dict):
",1
"    ilens = [10, 5]
    olens = [20, 15]
    device = torch.device(""cuda"")
    batch = prepare_inputs(
        idim, odim, ilens, olens, model_args[""spk_embed_dim""], device=device
",1
"    )
",1
"
    # define teacher model and save it
    if teacher_type == ""transformer"":
        teacher_model_args = make_transformer_args(**model_dict)
        teacher_model = Transformer(idim, odim, Namespace(**teacher_model_args))
",1
"    if os.path.exists(tmpdir):
        shutil.rmtree(tmpdir)


@pytest.mark.parametrize(
",1
"        ),
",1
"        ),
        ({""transfer_encoder_from_teacher"": True, ""encoder_concat_after"": True}),
        ({""transfer_encoder_from_teacher"": True, ""decoder_concat_after"": True}),
        (
",1
"    teacher_model = Transformer(idim, odim, Namespace(**teacher_model_args))
    tmpdir = tempfile.mkdtemp(prefix=""tmp_"", dir=""/tmp"")
    torch.save(teacher_model.state_dict(), tmpdir + ""/model.dummy.best"")
    with open(tmpdir + ""/model.json"", ""wb"") as f:
        f.write(
",1
"                indent=4,
                ensure_ascii=False,
                sort_keys=True,
            ).encode(""utf_8"")
",1
"        shutil.rmtree(tmpdir)

",1
"
",1
"    batch = prepare_inputs(idim, odim, ilens, olens, model_args[""spk_embed_dim""])
",1
"
",1
"    # define model
    model = FeedForwardTransformer(idim, odim, Namespace(**model_args))

    # test inference
    inference_args = Namespace(**{""fastspeech_alpha"": alpha})
",1
"    model.eval()
    with torch.no_grad():
        if model_args[""spk_embed_dim""] is None:
            spemb = None
",1
"        for nn, conf in [
            (
",1
"                    elayers=2,
                    dlayers=2,
                    mtlalpha=0.5,
",1
"        ]
        for dtype in (""float16"", ""float32"", ""float64"")
        for device in (""cpu"", ""cuda"")
",1
"    if device == ""cuda"" and not torch.cuda.is_available():
        pytest.skip(""no cuda device is available"")
",1
"    assert any(p.grad is not None for p in model.parameters())
    opt.step()
# coding: utf-8

# Copyright 2017 Shigeki Karita
",1
"import random

args = argparse.Namespace(
    elayers=4,
",1
"    dlayers=2,
    dunits=300,
",1
"    atype=""location"",
    aconv_chans=10,
",1
"    aconv_filts=100,
    mtlalpha=0.5,
    lsm_type="""",
",1
"    use_frontend=False,
    replace_sos=False,
",1
"
",1
"
    model = m.E2E(40, 5, args)
",1
"        elif ""dec.decoder.1.bias_ih"" in name:
            assert data.sum() == data.size // 4
        elif data.ndim == 1:
",1
"    random.seed(nseed)
    numpy.random.seed(nseed)
    os.environ[""CHAINER_SEED""] = str(nseed)
    import espnet.nets.chainer_backend.e2e_asr as m
",1
"import pytest
",1
"            x[:, :-1], prev_mask, memory, cache=decoder.init_state(None)
        )
",1
"@pytest.mark.parametrize(""normalize_before"", [True, False])
def test_encoder_cache(normalize_before):
",1
"        y_fast = elayer(x, mask, cache=cache)[0]
        numpy.testing.assert_allclose(y.numpy(), y_fast.numpy(), rtol=RTOL)
",1
"            idim=odim,
            attention_dim=adim,
            linear_units=3,
",1
"    result = {""cached"": [], ""baseline"": []}
",1
"    for key, value in result.items():
        cache = None
        print(key)
        for i in range(xlen):
            x = xs[:, : i + 1]
",1
"    plt.legend()
    plt.savefig(f""benchmark_{model}.png"")
# coding: utf-8
",1
"
",1
"import importlib
",1
"
import chainer
",1
"import numpy as np
import pytest
import torch

from espnet.nets.pytorch_backend.nets_utils import pad_list
",1
"        dunits=16,
        atype=""location"",
",1
"        streaming_offset_margin=2,
        verbose=2,
        char_list=[u""ã"", u""ã"", u""ã"", u""ã"", u""ã""],
        outdir=None,
",1
"    elif mode == ""pytorch"":
        ilens = torch.from_numpy(ilens).long()
",1
"

def convert_batch(batch, backend=""pytorch"", is_cuda=False, idim=40, odim=5):
    ilens = np.array([x[1][""input""][0][""shape""][0] for x in batch])
",1
"        ys = pad_list([torch.from_numpy(y).long() for y in ys], -1)

        if is_cuda:
",1
"            xp = importlib.import_module(""cupy"")
            xs = [chainer.Variable(xp.array(x)) for x in xs]
            ys = [chainer.Variable(xp.array(y)) for y in ys]
",1
"@pytest.mark.parametrize(
    ""module, model_dict"",
    [
        (""espnet.nets.chainer_backend.e2e_asr"", {}),
",1
"        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vggbgrup""}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vgglstm""}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""etype"": ""vgglstmp""}),
",1
"        (""espnet.nets.chainer_backend.e2e_asr"", {""mtlalpha"": 1.0}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""sampling_probability"": 0.5}),
",1
"        (""espnet.nets.chainer_backend.e2e_asr"", {""ctc_type"": ""builtin""}),
        (""espnet.nets.chainer_backend.e2e_asr"", {""ctc_weight"": 0.0}),
",1
"            {""report_cer"": True, ""report_wer"": True, ""mtlalpha"": 0.0},
        ),
        (
",1
"        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgggrup""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgglstm""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vgglstmp""}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vggbgru""}),
",1
"            ""espnet.nets.pytorch_backend.e2e_asr"",
            {""etype"": ""vggblstmp"", ""atype"": ""noatt""},
        ),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""etype"": ""vggblstmp"", ""atype"": ""add""}),
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr"",
            {""etype"": ""vggblstmp"", ""atype"": ""coverage""},
        ),
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr"",
            {""etype"": ""vggblstmp"", ""atype"": ""coverage_location""},
",1
"        (
            ""espnet.nets.pytorch_backend.e2e_asr"",
            {""etype"": ""vggblstmp"", ""atype"": ""multi_head_loc""},
",1
"        ),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""mtlalpha"": 0.0}),
        (""espnet.nets.pytorch_backend.e2e_asr"", {""mtlalpha"": 1.0}),
",1
"    args = make_arg(**model_dict)
    if ""pytorch"" in module:
        batch = prepare_inputs(""pytorch"")
",1
"    in_data = np.random.randn(100, 40)
    for i in range(10):
        asr.accept_input(in_data)

    asr.decode_with_attention_offline()
",1
"        assert grad[0] != grad_org[0]

",1
"        import espnet.nets.chainer_backend.e2e_asr as m
    batchset = make_batchset(dummy_json, 2, 2 ** 10, 2 ** 10, shortest_first=True)
",1
"    model = m.E2E(20, 5, args)
    for batch in batchset:
        loss = model(*convert_batch(batch, module, idim=20, odim=5))
",1
"        if isinstance(loss, tuple):
            # chainer return several values as tuple
            loss[0].backward()  # trainable
",1
"        else:
            loss.backward()  # trainable
    with torch.no_grad(), chainer.no_backprop_mode():
",1
"@pytest.mark.parametrize(""module"", [""pytorch"", ""chainer""])
def test_sortagrad_trainable_with_batch_bins(module):
    args = make_arg(sortagrad=1)
",1
"    for batch in batchset:
        loss = model(*convert_batch(batch, module, idim=20, odim=5))
        if isinstance(loss, tuple):
",1
"    batch_frames_out = 50
",1
"        for uttid, info in batch:
            i += int(info[""input""][0][""shape""][0])
            o += int(info[""output""][0][""shape""][0])
        assert i <= batch_frames_in
        assert o <= batch_frames_out
",1
"        else:
            loss.backward()  # trainable
",1
"        return ch_ctc.data, W_grad, b_grad

    ref_loss, ref_W_grad, ref_b_grad = _propagate(""builtin"")
    loss, W_grad, b_grad = _propagate(""warpctc"")
",1
"    np.testing.assert_allclose(ref_loss, loss, rtol=1e-5)
    np.testing.assert_allclose(ref_W_grad, W_grad)
    np.testing.assert_allclose(ref_b_grad, b_grad)

",1
"        1e-5,
        1e-6,
    )
",1
"
    # test cross-entropy grads
    ch_model.cleargrads()
    th_model.zero_grad()
",1
"    th_att.backward()
    np.testing.assert_allclose(
        ch_model.dec.output.W.grad,
        th_model.dec.output.weight.grad.data.numpy(),
",1
"    _, ch_ctc, ch_att, ch_acc = ch_model(*ch_batch)
    th_model(*th_batch)
    th_ctc, th_att = th_model.loss_ctc, th_model.loss_att
",1
"    # test loss with constant weights (1.0) and bias (0.0) except for foget-bias (1.0)
    np.testing.assert_allclose(ch_ctc.data, th_ctc.detach().numpy())
    np.testing.assert_allclose(ch_att.data, th_att.detach().numpy())

    # test grads in mtl mode
",1
"        ch_model.ctc.ctc_lo.b.grad,
        th_model.ctc.ctc_lo.bias.grad.data.numpy(),
        1e-5,
        1e-6,
    )
",1
"    np.testing.assert_allclose(
        ch_model.dec.output.W.grad,
        th_model.dec.output.weight.grad.data.numpy(),
        1e-7,
        1e-8,
",1
"        (""espnet.nets.chainer_backend.e2e_asr"", ""location""),
        (""espnet.nets.pytorch_backend.e2e_asr"", ""noatt""),
        (""espnet.nets.pytorch_backend.e2e_asr"", ""dot""),
        (""espnet.nets.pytorch_backend.e2e_asr"", ""add""),
        (""espnet.nets.pytorch_backend.e2e_asr"", ""location""),
",1
"        (""espnet.nets.pytorch_backend.e2e_asr"", ""multi_head_add""),
",1
"    args = make_arg(atype=atype)
    if ""pytorch"" in module:
",1
"        batch = prepare_inputs(""pytorch"")
    else:
",1
"        batch = prepare_inputs(""chainer"")
    model = m.E2E(40, 5, args)
    with chainer.no_backprop_mode():
        if ""pytorch"" in module:
",1
"            att_ws = model.calculate_all_attentions(*batch)
        print(att_ws.shape)

",1
"
def test_chainer_save_and_load():
    m = importlib.import_module(""espnet.nets.chainer_backend.e2e_asr"")
",1
"

def test_torch_save_and_load():
",1
"        p.data.uniform_()
    if not os.path.exists("".pytest_cache""):
        os.makedirs("".pytest_cache"")
",1
"        loss.backward()  # trainable

",1
"            with cupy.cuda.Device(device):
                batch = prepare_inputs(""chainer"", is_cuda=True)
",1
"                _model = copy.deepcopy(
                    model
",1
"    bpemodel = ""test_spm""

    # test train
    spm.SentencePieceTrainer.Train(
        f""--input={testfile} --vocab_size={nbpe} --model_type={bpemode} \
",1
"    ) as fb:
",1
"from typing import Any

import pytest

from espnet2.utils.get_default_kwargs import get_default_kwargs
",1
"

class Dummy:
    pass
",1
"def func2(b=[{1, 2, 3}]):
    pass
",1
"
def func5(b={3: 5}):
",1
"    [
",1
"import yaml

",1
"def test_find_path_and_change_it_recursive():
    target = {""a"": [""foo/path.npy""], ""b"": 3}
    target = find_path_and_change_it_recursive(target, ""foo/path.npy"", ""bar/path.npy"")
    assert target == {""a"": [""bar/path.npy""], ""b"": 3}

",1
"    files = {""abc.pth"": str(tmp_path / ""foo.pth"")}
",1
"        yaml_files={""def.yaml"": str(tmp_path / ""bar.yaml"")},
        option=[tmp_path / ""a"", tmp_path / ""b"" / ""a""],
        outpath=str(tmp_path / ""out.tgz""),
",1
"
    retval = unpack(str(tmp_path / ""out.tgz""), str(tmp_path))
    assert retval == {
        ""abc"": str(tmp_path / ""packed"" / ""abc.pth""),
        ""def"": str(tmp_path / ""packed"" / ""def.yaml""),
",1
"def test_pack_not_exist_file():
    with pytest.raises(FileNotFoundError):
        pack(files={""a"": ""aaa""}, yaml_files={}, outpath=""out"")

",1
"        unpack(str(tmp_path / ""a.tgz""), ""out"")
import argparse
from argparse import Namespace

",1
"    )
    assert parser.parse_args(
        [""--conf"", '{""d"": 5, ""e"": 9}', ""--conf"", ""d.e=3""]
",1
"from espnet2.utils.types import str2pair_str
from espnet2.utils.types import str2triple_str
from espnet2.utils.types import str_or_int
from espnet2.utils.types import str_or_none
",1
"        (""false"", False),
        (""True"", True),
        (""False"", False),
        (""aa"", ValueError),
    ],
",1
"

",1
"    with pytest_raise_or_nothing(desired):
        assert float_or_none(value) == desired


",1
"@pytest.mark.parametrize(
    ""value, desired"", [(""3k"", 3000), (""2m "", 2000000), (""none"", None)],
",1
"def test_str_or_none(value: str, desired: Any):
    with pytest_raise_or_nothing(desired):
        assert str_or_none(value) == desired

",1
"        (""a, b"", (""a"", ""b"")),
        (""a,b,c"", ValueError),
        (""a"", ValueError),
        (""['a', 'b']"", (""a"", ""b"")),
",1
"    ],
",1
"        assert str2pair_str(value) == desired


",1
"    [
        (""a,b, c"", (""a"", ""b"", ""c"")),
",1
"
import numpy as np
import pytest
",1
"import soundfile

from espnet2.utils.fileio import DatadirWriter
from espnet2.utils.fileio import load_num_sequence_text
",1
"    d = read_2column_text(p)
    assert d == {""abc"": ""/some/path/a.wav"", ""def"": ""/some/path/b.wav""}


",1
"@pytest.mark.parametrize(
    ""loader_type"", [""text_int"", ""text_float"", ""csv_int"", ""csv_float"", ""dummy""]
)
",1
"
def test_DatadirWriter(tmp_path: Path):
",1
"
",1
"
    for k in desired:
        rate1, t = target[k]
        rate2, d = desired[k]
        assert rate1 == rate2
",1
"        # Unsupported dimension
        with pytest.raises(RuntimeError):
            y = np.random.randint(-100, 100, [16, 1, 1], dtype=np.int16)
            writer[""ghi""] = 16, y
    target = SoundScpReader(tmp_path / ""wav.scp"", normalize=False, dtype=np.int16)
",1
"        assert rate1 == rate2
",1
"            y = np.random.randint(-100, 100, [16, 1, 1], dtype=np.int16)
            writer[""ghi""] = 16, y
    target = SoundScpReader(tmp_path / ""wav.scp"", normalize=True, dtype=np.float64)
",1
"
def test_NpyScpReader(tmp_path: Path):
",1
"    npy_path1 = tmp_path / ""a1.npy""
    array1 = np.random.randn(1)
    npy_path2 = tmp_path / ""a2.npy""
    array2 = np.random.randn(1, 1, 10)
    np.save(npy_path1, array1)
",1
"    np.save(npy_path2, array2)

    p = tmp_path / ""dummy.scp""
    with p.open(""w"") as f:
",1
"    assert ""abc"" in target
",1
"        writer[""def""] = array2
    target = NpyScpReader(tmp_path / ""feats.scp"")
    desired = {""abc"": array1, ""def"": array2}

",1
"import yaml

from espnet2.utils.yaml_no_alias_safe_dump import yaml_no_alias_safe_dump

d = {""a"": (1, 2, 3)}
",1
"

@pytest.mark.parametrize(
    ""data, desired"",
    [(d, {""a"": [1, 2, 3]}), ((d, d[""a""]), [{""a"": [1, 2, 3]}, [1, 2, 3]])],
",1
")
",1
"    assert d.size == get_size(x) + get_size(y) + sys.getsizeof(""a"") + sys.getsizeof(""b"")

",1
"    # Overwrite
    z = np.random.randn(10)
    d[""b""] = z
",1
"def test_SizedDict_iter():
    d = SizedDict(data={""a"": 2, ""b"": 5, ""c"": 10})
    assert list(iter(d)) == [""a"", ""b"", ""c""]
",1
"@pytest.mark.parametrize(""requires_grad"", [False, True])
@pytest.mark.parametrize(""replace_with_zero"", [False, True])
@pytest.mark.parametrize(""dim"", [""freq"", ""time""])
def test_MaskAlongAxis(dim, replace_with_zero, requires_grad):
",1
"
def test_TimeWarp_repr():
",1
"    time_warp = TimeWarp(window=10)
    print(time_warp)
",1
"
",1
"
@pytest.fixture()
",1
"    s2 = np.pad(s2, [0, 1], mode=""constant"", constant_values=0.0)

",1
"    s = x.sum(0)
    s2 = (x ** 2).sum(0)

",1
")
def test_backward_leaf_in(stats_file, norm_vars, norm_means):
    layer = GlobalMVN(stats_file, norm_means=norm_means, norm_vars=norm_vars)
    x = torch.randn(1, 2, 80, requires_grad=True)
    y, _ = layer(x)
",1
"
@pytest.mark.parametrize(
    ""norm_vars, norm_means"",
",1
"def test_backward_not_leaf_in(stats_file, norm_vars, norm_means):
",1
"@pytest.mark.parametrize(
    ""norm_vars, norm_means"",
    [(True, True), (False, False), (True, False), (False, True)],
)
def test_inverse_backwar_not_leaf_in(stats_file, norm_vars, norm_means):
",1
"    [(True, True), (False, False), (True, False), (False, True)],
)
def test_inverse_identity(stats_file, norm_vars, norm_means):
    layer = GlobalMVN(stats_file, norm_means=norm_means, norm_vars=norm_vars)
",1
"    layer = GlobalMVN(stats_file, norm_means=norm_means, norm_vars=norm_vars)
    layer2 = GlobalMVN(stats_file2, norm_means=norm_means, norm_vars=norm_vars)
    x = torch.randn(2, 3, 80)
",1
"    y, _ = layer(x)
",1
"def test_repr():
    print(Stft())
",1
"    x = torch.randn(2, 400, requires_grad=True)
    y, _ = layer(x)
",1
"    y.sum().backward()

",1
"    x = x + 2
",1
"import torch

",1
"from espnet2.layers.utterance_mvn import UtteranceMVN

",1
"@pytest.mark.parametrize(
    ""norm_vars, norm_means"",
    [(True, True), (False, False), (True, False), (False, True)],
",1
")
",1
"@pytest.mark.parametrize(
",1
"    x = torch.randn(2, 1000, requires_grad=True)
",1
"    x = x + 2
",1
"
from espnet2.asr.ctc import CTC
",1
"

",1
"
",1
"    y, y_lengths = frontend(x, x_lengths)
",1
"    )
    if train:
",1
"            specaug = SpecAug(
                apply_time_warp=apply_time_warp,
                apply_freq_mask=apply_freq_mask,
                apply_time_mask=apply_time_mask,
            )
",1
"
@pytest.mark.parametrize(""apply_time_warp"", [False, True])
@pytest.mark.parametrize(""apply_freq_mask"", [False, True])
",1
"@pytest.mark.parametrize(""apply_time_mask"", [False, True])
def test_SpecAuc_repr(apply_time_warp, apply_freq_mask, apply_time_mask):
    if not apply_time_warp and not apply_time_mask and not apply_freq_mask:
",1
"def test_Encoder_forward_backward(input_layer, positionwise_layer_type):
    encoder = TransformerEncoder(
",1
"def test_Encoder_output_size():
    encoder = TransformerEncoder(20, output_size=256)
",1
"        TransformerEncoder(20, input_layer=""fff"")
",1
"
@pytest.mark.parametrize(""rnn_type"", [""lstm"", ""gru""])
@pytest.mark.parametrize(""bidirectional"", [True, False])
@pytest.mark.parametrize(""use_projection"", [True, False])
@pytest.mark.parametrize(""subsample"", [None, (2, 2, 1, 1)])
",1
"def test_Encoder_forward_backward(rnn_type, bidirectional, use_projection, subsample):
    encoder = RNNEncoder(
        5,
        rnn_type=rnn_type,
",1
"        bidirectional=bidirectional,
        use_projection=use_projection,
        subsample=subsample,
",1
"        RNNEncoder(5, rnn_type=""fff"")
import pytest
",1
"
",1
"    x_lens = torch.tensor([9, 7], dtype=torch.long)
",1
"    state = decoder.init_state(x)
    t = torch.randint(0, 10, [4], dtype=torch.long)
    decoder.score(t, state, x)

",1
"
def test_RNNDecoder_invalid_type():
    with pytest.raises(ValueError):
        RNNDecoder(10, 12, rnn_type=""foo"")
import pytest
",1
"

def test_TransformerDecoder_init_state():
",1
"        TransformerDecoder(10, 12, input_layer=""foo"")
import h5py
",1
"        if isinstance(v, str):
            if v == ""hello world"":
                new_data[k] = np.array([0])
            elif v == ""foo bar"":
                new_data[k] = np.array([1])
",1
"    p = tmp_path / ""wav.scp""
    w = SoundScpWriter(tmp_path / ""data"", p)
    w[""a""] = 16000, np.random.randint(-100, 100, (160000,), dtype=np.int16)
    w[""b""] = 16000, np.random.randint(-100, 100, (80000,), dtype=np.int16)
    return str(p)
",1
"    _, data = dataset[""a""]
    assert data[""data1""].shape == (160000,)

",1
"@pytest.fixture
def pipe_wav(tmp_path):
    p = tmp_path / ""wav.scp""
    soundfile.write(
",1
"        tmp_path / ""b.wav"",
        np.random.randint(-100, 100, (80000,), dtype=np.int16),
        16000,
",1
"
@pytest.fixture
def feats_scp(tmp_path):
    p = tmp_path / ""feats.scp""
    p2 = tmp_path / ""feats.ark""
",1
"    with kaldiio.WriteHelper(f""ark,scp:{p2},{p}"") as w:
        w[""a""] = np.random.randn(100, 80)
        w[""b""] = np.random.randn(150, 80)
    return str(p)
",1
"def test_ESPnetDataset_npy_scp(npy_scp):
    dataset = ESPnetDataset(
",1
"    p = tmp_path / ""file.h5""
    with h5py.File(p, ""w"") as w:
        w[""a/input""] = np.random.randn(100, 80)
        w[""a/target""] = np.random.randint(0, 10, (10,))
",1
"

def test_ESPnetDataset_h5file_1(h5file_1):
    dataset = ESPnetDataset(
",1
"    _, data = dataset[""b""]
    assert data[""data4""].shape == (150, 80,)
",1
"

def test_ESPnetDataset_h5file_2(h5file_2):
    dataset = ESPnetDataset(
",1
"        f.write(""b 150,80\n"")
    return str(p)


",1
"
def test_ESPnetDataset_rand_int(shape_file):
    dataset = ESPnetDataset(
        path_name_type_list=[(shape_file, ""data6"", ""rand_int_0_10"")],
",1
"        preprocess=preprocess,
    )

    _, data = dataset[""a""]
    assert data[""data6""].shape == (100, 80,)
",1
"
    _, data = dataset[""b""]
    assert data[""data6""].shape == (150, 80,)


",1
"
def test_ESPnetDataset_text(text):
    dataset = ESPnetDataset(
",1
"    p = tmp_path / ""shape.txt""
    with p.open(""w"") as f:
        f.write(""a 1.4 3.4\n"")
",1
"

def test_ESPnetDataset_text_float(text_float):
    dataset = ESPnetDataset(
        path_name_type_list=[(text_float, ""data8"", ""text_float"")],
",1
"    _, data = dataset[""a""]
    assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))

    _, data = dataset[""b""]
",1
"        f.write(""a 0 1 2\n"")
",1
"    )

    _, data = dataset[""a""]
",1
"
@pytest.fixture
def csv_float(tmp_path):
",1
"    p = tmp_path / ""shape.txt""
    with p.open(""w"") as f:
        f.write(""a 1.4,3.4\n"")
",1
"    _, data = dataset[""a""]
    assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))

    _, data = dataset[""b""]
    assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))
",1
"
",1
"@pytest.fixture
def csv_int(tmp_path):
    p = tmp_path / ""shape.txt""
",1
"    with p.open(""w"") as f:
        f.write(""a 0,1,2\n"")
        f.write(""b 2,3,4\n"")
",1
"    return str(p)
",1
"        preprocess=preprocess,
    )

    _, data = dataset[0]
    assert data[""data1_0""].shape == (3, 32, 32)
",1
"from espnet2.train.collate_fn import CommonCollateFn


@pytest.mark.parametrize(
",1
"    ]
    t = common_collate_fn(
        data,
",1
"            [
",1
"def test_(float_pad_value, int_pad_value, not_sequence):
    _common_collate_fn = CommonCollateFn(
        float_pad_value=float_pad_value,
        int_pad_value=int_pad_value,
        not_sequence=not_sequence,
",1
"    )
    data = [
        (""id"", dict(a=np.random.randn(3, 5), b=np.random.randn(4).astype(np.long))),
",1
"            [
",1
"                data[0][1][""a""],
                np.pad(
                    data[1][1][""a""],
                    [(0, 1), (0, 0)],
                    mode=""constant"",
",1
"    ""float_pad_value, int_pad_value, not_sequence"",
    [(0.0, -1, ()), (3.0, 2, (""a"",)), (np.inf, 100, (""a"", ""b""))],
)
def test_CommonCollateFn_repr(float_pad_value, int_pad_value, not_sequence):
",1
"    print(
        CommonCollateFn(
            float_pad_value=float_pad_value,
",1
"    option.init()

",1
"        dist_backend=""nccl"",
        dist_init_method=dist_init_method,
        dist_master_addr=None,
        dist_master_port=None,
",1
"
def test_resolve_distributed_mode2(dist_init_method):
    args = argparse.Namespace(
",1
"        dist_master_addr=None,
        dist_master_port=None,
    )
    with pytest.raises(RuntimeError):
",1
"        dist_master_port=None,
    )
",1
"    resolve_distributed_mode(args)


def test_resolve_distributed_mode4(dist_init_method):
",1
"        local_rank=1,
        dist_launcher=None,
        dist_backend=""nccl"",
        dist_init_method=dist_init_method,
        dist_master_addr=None,
",1
"def test_resolve_distributed_mode5(dist_init_method):
    args = argparse.Namespace(
        multiprocessing_distributed=False,
        dist_world_size=2,
",1
"        local_rank=None,
",1
"        dist_launcher=None,
        dist_backend=""nccl"",
        dist_init_method=dist_init_method,
        dist_master_addr=None,
        dist_master_port=None,
",1
"        multiprocessing_distributed=True,
        dist_world_size=1,
        dist_rank=None,
",1
"        ngpu=2,
        local_rank=None,
        dist_launcher=None,
        dist_backend=""nccl"",
",1
"        dist_init_method=dist_init_method,
",1
"
",1
"        dist_master_addr=None,
        dist_master_port=None,
    )
",1
"        dist_rank=None,
        ngpu=0,
",1
"        fn.result()
",1
"        multiprocessing_distributed=True,
        dist_world_size=2,
",1
"        dist_world_size=2,
        dist_rank=None,
        ngpu=0,
        local_rank=None,
",1
"    args.dist_rank = 0
    option = build_dataclass(DistributedOption, args)
    args.dist_rank = 1
    option2 = build_dataclass(DistributedOption, args)
    with ThreadPoolExecutor(max_workers=2) as e:
",1
"        fn = e.submit(option.init)
        fn2 = e.submit(option2.init)
",1
"
def test_init_cpu4():
",1
"        multiprocessing_distributed=True,
",1
"        ngpu=2,
",1
"            SLURM_STEP_NUM_NODES=""2"",
            SLURM_STEP_NODELIST=""host1"",
            SLURM_NODEID=""0"",
            SLURM_LOCALID=""0"",
",1
"        dist_backend=""nccl"",
        dist_init_method=dist_init_method,
",1
"            resolve_distributed_mode(args)


def test_resolve_distributed_mode_slurm3():
    args = argparse.Namespace(
",1
"        option2 = build_dataclass(DistributedOption, args)
        fn2 = e.submit(option2.init)
",1
"import uuid
",1
"        }
        sub.register(stats1, weight1)
        stats2 = {
",1
"
",1
"        np.testing.assert_allclose(reporter.get_value(k1, k2), desired[k2])


@pytest.mark.parametrize(""mode"", [""min"", ""max"", ""foo""])
",1
"            sub.register(stats_list[e])
    if mode not in (""min"", ""max""):
        with pytest.raises(ValueError):
            reporter.sort_epochs_and_values(key1, ""aa"", mode)
",1
"
    for e in range(len(stats_list)):
        assert sort_values[e] == desired[e]


",1
"

",1
"    for e in range(len(stats_list)):
        reporter.set_epoch(e + 1)
        with reporter.observe(key1) as sub:
            sub.register(stats_list[e])
",1
"    reporter = Reporter()
    key1 = uuid.uuid4().hex
",1
"    stats_list = [{""aa"": 0.3}, {""aa"": 0.5}, {""aa"": 0.2}]
    for e in range(len(stats_list)):
",1
"    key1 = uuid.uuid4().hex
    stats_list = [{""aa"": 0.3}, {""aa"": 0.2}, {""aa"": 0.4}, {""aa"": 0.3}]
    patience = 1

    results = []
",1
"    reporter = Reporter()
    reporter.set_epoch(1)
    key1 = uuid.uuid4().hex
    with reporter.observe(key1) as sub:
",1
"        stats1 = {""aa"": 0.6}
",1
"        sub.register(stats1)

    reporter.set_epoch(1)
    with reporter.observe(key1) as sub:
",1
"    reporter.set_epoch(3)
    with reporter.observe(key1) as sub:
",1
"    reporter.matplotlib_plot(tmp_path)
    assert (tmp_path / ""aa.png"").exists()


",1
"        # Skip epoch=2
",1
"        stats1 = {""bb"": 0.6}
",1
"    reporter2 = Reporter()
    reporter2.load_state_dict(state)
",1
"    reporter = Reporter(2)
    assert reporter.get_epoch() == 2

",1
"def test_total_count():
    reporter = Reporter(2)
    assert reporter.get_epoch() == 2
    with reporter.observe(""train"", 1) as sub:
        sub.register({})
",1
"        assert sub.get_total_count() == 3


",1
"        with reporter.observe(""train"", 1):
            reporter.set_epoch(2)


",1
"        Reporter(-1)

",1
"
def test_minus_epoch2():
    reporter = Reporter()
    with pytest.raises(ValueError):
        reporter.set_epoch(-1)
",1
"

",1
"def test_zero_weight():
    reporter = Reporter()
    with reporter.observe(""train"", 1) as sub:
        sub.register({""a"": 1}, weight=0)
",1
"
def test_no_register():
    reporter = Reporter()
    with reporter.observe(""train"", 1):
        pass
",1
"        sub.register({""a"": 2})
",1
"            sub.register({""a"": 2}, weight=1)
            sub.register({""a"": 3})
",1
"
def test__plot_stats_input_str():
    reporter = Reporter()
",1
"        reporter._plot_stats(""aaa"", ""a"")


",1
"import pytest

",1
"    with pytest.raises(SystemExit):
        ASRTask.main(cmd=[])


",1
"def test_print_config_and_load_it(tmp_path):
    config_file = tmp_path / ""config.yaml""
    with config_file.open(""w"") as f:
        ASRTask.print_config(f)
    parser = ASRTask.get_parser()
",1
"

def test_main_print_config():
",1
"    with pytest.raises(SystemExit):
        LMTask.main(cmd=[""--print_config""])


def test_main_with_no_args():
",1
"    AbsTask.get_parser()


def test_add_arguments_help():
    parser = AbsTask.get_parser()
",1
"
def test_print_config_and_load_it(tmp_path):
    config_file = tmp_path / ""config.yaml""
    with config_file.open(""w"") as f:
",1
"

def test_add_arguments_help():
    parser = TTSTask.get_parser()
",1
"    parser = TTSTask.get_parser()
    parser.parse_args([""--config"", str(config_file)])
",1
"from argparse import ArgumentParser
",1
"

def test_main():
    with pytest.raises(SystemExit):
        main()
",1
"from espnet2.bin.tokenize_text import main


",1
"from argparse import ArgumentParser

import pytest

",1
"from espnet2.bin.lm_train import get_parser
from espnet2.bin.lm_train import main

",1
"import pytest

from espnet2.bin.pack import get_parser
from espnet2.bin.pack import main
",1
"        main()
",1
"
def test_get_parser():
    assert isinstance(get_parser(), ArgumentParser)
",1
"

",1
"
",1
"

@pytest.fixture
def char_converter():
    return CharTokenizer([""[foo]""])
",1
"
    with input_text.open(""w"") as f:
",1
"    sp.load(model)
",1
"            f.write(f""{v}\n"")
    return SentencepiecesTokenizer(model=model)
",1
"
from espnet2.text.token_id_converter import TokenIDConverter

",1
"    converter = TokenIDConverter([""a"", ""b"", ""c"", ""<unk>""])
    assert converter.tokens2ids(""abc"") == [0, 1, 2]
",1
"def test_duplicated():
",1
"    with pytest.raises(RuntimeError):
        TokenIDConverter([""a"", ""a"", ""c""])

",1
"
def test_backward_not_leaf_in():
",1
"    y, _ = layer(x, torch.LongTensor([4, 3]))
    y.sum().backward()


",1
"    print(layer.output_size())


",1
"def test_SGD():
",1
"def test_ForwardAdaptor_no_func():
",1
"    model = Model()
    with pytest.raises(ValueError):
        ForwardAdaptor(model, ""aa"")
from espnet2.torch_utils.pytorch_version import pytorch_cudnn_version

",1
"    print(pytorch_cudnn_version())
from espnet2.torch_utils.set_all_random_seed import set_all_random_seed


",1
"
from espnet2.torch_utils.initialize import initialize

",1
"
class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()
",1
"

",1
"@pytest.mark.parametrize(
",1
"        ""xavier_normal"",
",1
"import dataclasses
from typing import NamedTuple
",1
"from espnet2.torch_utils.device_funcs import force_gatherable
from espnet2.torch_utils.device_funcs import to_device

",1
"class Named(NamedTuple):
    x: torch.Tensor


@pytest.mark.parametrize(
",1
"    obj2 = to_device(obj, ""cuda"")
    assert obj2[""a""][0].device == torch.device(""cuda:0"")


@pytest.mark.parametrize(
",1
"
",1
"
@pytest.mark.skipif(not torch.cuda.is_available(), reason=""Require cuda"")
def test_force_gatherable_cuda():
    obj = {""a"": [torch.tensor([0, 1])]}
    obj2 = force_gatherable(obj, ""cuda"")
",1
"
def test_add_gradient_noise():
    linear = torch.nn.Linear(1, 1)
    linear(torch.rand(1, 1)).sum().backward()
",1
"import pytest
",1
"            build_batch_sampler(
                batch_bins=60000,
                batch_size=2,
",1
"
def test_build_batch_sampler_invalid_fold_lengths(shape_files):
    with pytest.raises(ValueError):
",1
"import pytest

from espnet2.samplers.folded_batch_sampler import FoldedBatchSampler
",1
"@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
",1
"        shape_files=shape_files,
        fold_lengths=[500, 80],
        sort_in_batch=sort_in_batch,
        sort_batch=sort_batch,
",1
"        drop_last=drop_last,
    )
",1
"    list(sampler)
",1
"        f.write(""f 999,80\n"")

",1
"        f.write(""c 39,30\n"")
        f.write(""d 49,30\n"")
        f.write(""e 44,30\n"")
        f.write(""f 99,30\n"")
",1
"def test_SortedBatchSampler(shape_files, sort_in_batch, sort_batch, drop_last):
    sampler = SortedBatchSampler(
        2,
        shape_file=shape_files[0],
        sort_in_batch=sort_in_batch,
",1
"@pytest.mark.parametrize(""sort_in_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""drop_last"", [True, False])
",1
"        shape_file=shape_files[0],
        sort_in_batch=sort_in_batch,
",1
"        sort_batch=sort_batch,
",1
"@pytest.mark.parametrize(""sort_in_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""drop_last"", [True, False])
",1
"        shape_file=shape_files[0],
        sort_in_batch=sort_in_batch,
",1
"from espnet2.samplers.num_elements_batch_sampler import NumElementsBatchSampler


@pytest.fixture()
def shape_files(tmp_path):
",1
"    with p1.open(""w"") as f:
        f.write(""a 1000,80\n"")
        f.write(""b 400,80\n"")
",1
"    sampler = NumElementsBatchSampler(
        60000,
        shape_files=shape_files,
        sort_in_batch=sort_in_batch,
        sort_batch=sort_batch,
",1
"@pytest.mark.parametrize(""sort_in_batch"", [""descending"", ""ascending""])
@pytest.mark.parametrize(""sort_batch"", [""descending"", ""ascending""])
",1
"        60000,
        shape_files=shape_files,
",1
"def test_NumElementsBatchSampler_len(
    shape_files, sort_in_batch, sort_batch, drop_last, padding
):
",1
"    sampler = LengthBatchSampler(
",1
"        padding=padding,
    )
",1
"    sampler = LengthBatchSampler(
        6000,
",1
"    )
    print(sampler)


",1
"    shape_files, sort_in_batch, sort_batch, drop_last, padding
",1
"from espnet2.asr.decoder.rnn_decoder import RNNDecoder
",1
"from espnet2.main_funcs.calculate_all_attentions import calculate_all_attentions
from espnet2.train.abs_espnet_model import AbsESPnetModel

",1
"        super().__init__()
        self.att1 = MultiHeadedAttention(2, 10, 0.0)
",1
"        self.att2 = AttAdd(10, 20, 15)
        self.desired = defaultdict(list)

",1
"class Dummy2(AbsESPnetModel):
    def __init__(self, atype):
        super().__init__()
",1
"def test_calculate_all_attentions_MultiHeadedAttention():
    model = Dummy()
",1
"        for i, att in enumerate(o):
            print(att.shape)
            if att.dim() == 2:
                att = att[None]
",1
"def test_SequenceIterFactory(collate):
",1
"
@pytest.mark.parametrize(""collate"", [None, collate_func])
def test_SequenceIterFactory_without_num_iters_per_epoch_deterministic(collate):
    dataset = Dataset()
    batches = [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]
",1
"

class Dataset:
",1
"from espnet2.schedulers.noam_lr import NoamLR
",1
"def test_WarumupLR():
",1
"    lr = 10
    model_size = 320
",1
"import pathlib
import re

import configargparse
",1
"    return parser


# parser
",1
"parser.add_argument('root', type=str,
                    help='root module to generate docs recursively')
parser.add_argument('dst', type=str,
",1
"

def gen_rst(module_path, f):
",1
"    dst = f""{gendir}/{fname}""
    modules_rst += f""   ./_gen/{fname}\n""
",1
"    print(f""[INFO] generating {dst}"")
    with open(dst, ""w"") as f:
        gen_rst(p, f)
",1
"#
# All configuration values have a default; values that are commented out
# serve to show the default.

# If extensions (or modules to document with autodoc) are in another directory,
",1
"# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#
import os
",1
"import sys

sys.path.insert(0, os.path.abspath('../espnet/nets'))
sys.path.insert(0, os.path.abspath('../utils'))
",1
"
# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
",1
"    'sphinx.ext.viewcode',
    ""sphinx.ext.mathjax"",
    ""sphinx.ext.todo"",
    ""sphinxarg.ext"",
",1
"    ""sphinx_markdown_tables"",
]

",1
"master_doc = 'index'

# General information about the project.
project = u'ESPnet'
copyright = u'2017, Shinji Watanabe'
",1
"# built documents.
#
# The short X.Y version.
",1
"import espnet
version = espnet.__version__
",1
"# html_theme_options = {}

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
",1
"#
# This is required for the alabaster theme
",1
"    ]
}

# -- Options for HTMLHelp output ------------------------------------------

",1
"# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #
",1
"# Grouping the document tree into Texinfo files. List of tuples
",1
"from distutils.version import LooseVersion
",1
"                        help='Disable CUPY tests')
    parser.add_argument('--torch-version', default='0.4.1', type=str,
",1
"                        help='Disable CUPY tests')
    args = parser.parse_args(args)
",1
"        ('torch', (""0.4.1"",
                   ""1.0.0"", 
                   ""1.0.1"", 
",1
"                   ""1.3.0"", 
                   ""1.3.1"",
                   ""1.4.0"")),
        ('chainer', (""6.0.0"")),
        ('chainer_ctc', None),
",1
"    if len(library_list) != sum(is_correct_installed_list):
        logging.info(""please try to setup again and then re-run this script."")
",1
"        sys.exit(1)
",1
"            if vers != None:
                is_correct = vers in version
",1
"                    logging.warning(""--> %s version is not matched (%s is not in %s)."" % (
                        name, vers, str(version)))
",1
"                is_correct_version_list.append(False)
    logging.info(""library version check done."")
    logging.info(""%d / %d libraries are correct version."" % (
",1
"        sum(is_correct_version_list), num_version_specified))

    if sum(is_correct_version_list) != num_version_specified:
",1
"    try:
        assert torch.backends.cudnn.is_available()
        logging.info(""--> cudnn is available in torch."")
",1
"    except AssertionError:
        logging.warning(""--> it seems that cudnn is not available in torch."")
",1
"    except ImportError:
        logging.warning(""--> it seems that nccl is not installed. multi-gpu is not enabled."")
        logging.warning(""--> if you want to use multi-gpu, please install it and then re-setup."")
    try:
        assert torch.cuda.device_count() > 1
",1
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",2
"import re
import shlex
import subprocess
import sys
import textwrap
",2
"class CMakeExtension(Extension):
    def __init__(self, name, cmake_lists_dir='.', sources=[], **kwa):
        Extension.__init__(self, name, sources=sources, **kwa)
        self.cmake_lists_dir = os.path.abspath(cmake_lists_dir)

",2
"
",2
"                'Your TensorFlow version %s is outdated.  '
                'Horovod requires tensorflow>=1.1.0' % tf.__version__)
",2
"    try:
        import mxnet as mx
        if mx.__version__ < '1.4.0':
            raise DistutilsPlatformError(
",2
"                'Your MXNet version %s is outdated.  '
                'Horovod requires mxnet>=1.4.0' % mx.__version__)
    except ImportError:
        raise DistutilsPlatformError(
            'import mxnet failed, is it installed?\n\n%s' % traceback.format_exc())
",2
"            'Your MXNet version is outdated.  Horovod requires mxnet>1.3.0')


",2
"                    }
                    '''))

            return cpp_flags
        except (CompileError, LinkError):
",2
"    import tensorflow as tf
    tf_lib = tf.sysconfig.get_lib()
",2
"    return [tf_lib]


def get_tf_libs(build_ext, lib_dirs, cpp_flags):
    last_err = None
",2
"            link_flags.append('-L%s' % lib_dir)
        for lib in tf_libs:
            link_flags.append('-l%s' % lib)

        return compile_flags, link_flags
",2
"

def get_mx_include_dirs():
    import mxnet as mx
",2
"    raise DistutilsPlatformError(last_err)

",2
"        if has_mkldnn:
            mkldnn_include = os.path.join(include_dir, 'mkldnn')
            compile_flags.append('-I%s' % mkldnn_include)

    link_flags = []
",2
"            mpi_show_args = mpi_show_args[1:]
        # strip off compiler call portion and always escape each arg
",2
"        raise DistutilsPlatformError(
            '%s failed (see error below), is MPI in $PATH?\n'
            'Note: If your version of MPI has a custom command to show compilation flags, '
            'please specify it with the HOROVOD_MPICXX_SHOW environment variable.\n\n'
            '%s' % (show_command, traceback.format_exc()))
",2
"
",2
"        # default to /usr/local/cuda
        cuda_include_dirs += ['/usr/local/cuda/include']
        cuda_lib_dirs += ['/usr/local/cuda/lib', '/usr/local/cuda/lib64']

    try:
",2
"            '''))
    except (CompileError, LinkError):
",2
"    return cuda_include_dirs, cuda_lib_dirs


def get_rocm_dirs(build_ext, cpp_flags):
    rocm_include_dirs = []
",2
"    rocm_lib_dirs = []
    rocm_libs = ['hip_hcc']
    rocm_macros = [('__HIP_PLATFORM_HCC__',1)]

",2
"            '%s/hcc/include' % rocm_path,
            '%s/hip/include' % rocm_path,
            '%s/hsa/include' % rocm_path,
",2
"    nccl_libs = []
",2
"
",2
"                     code=textwrap.dedent('''\
            #include <%s>
            #if NCCL_MAJOR < 2
            #error Horovod requires NCCL 2.0 or later version, please upgrade.
",2
"            void test() {
                ncclUniqueId nccl_id;
                ncclGetUniqueId(&nccl_id);
            }
",2
"            '''%('rccl.h' if have_rocm else 'nccl.h')))
    except (CompileError, LinkError):
        raise DistutilsPlatformError(
            'NCCL 2.0 library or its later version was not found (see error above).\n'
            'Please specify correct NCCL location with the HOROVOD_NCCL_HOME '
",2
"            'environment variable or combination of HOROVOD_NCCL_INCLUDE and '
            'HOROVOD_NCCL_LIB environment variables.\n\n'
            'HOROVOD_NCCL_HOME - path where NCCL include and lib directories can be found\n'
",2
"            'HOROVOD_NCCL_INCLUDE - path to NCCL include directory\n'
",2
"def get_ddl_dirs(build_ext, cuda_include_dirs, cuda_lib_dirs, cpp_flags):
    ddl_include_dirs = []
",2
"    ddl_lib_dirs = []

    ddl_home = os.environ.get('HOROVOD_DDL_HOME')
",2
"            'Please specify correct DDL location with the HOROVOD_DDL_HOME '
            'environment variable or combination of HOROVOD_DDL_INCLUDE and '
            'HOROVOD_DDL_LIB environment variables.\n\n'
            'HOROVOD_DDL_HOME - path where DDL include and lib directories can be found\n'
",2
"            'HOROVOD_DDL_INCLUDE - path to DDL include directory\n'
            'HOROVOD_DDL_LIB - path to DDL lib directory')
",2
"        try:
            cmake_bin = get_cmake_bin()
            subprocess.check_output([cmake_bin, '--version'])
            have_cmake = True
",2
"        except Exception:
            if compile_with_gloo:
                # Require Gloo to succeed, otherwise fail the install.
                raise RuntimeError('Cannot find CMake. CMake is required to build Horovod with Gloo.')

",2
"            print('INFO: Cannot find CMake, will skip compiling Horovod with Gloo.')
            have_cmake = False

",2
"        # TODO: remove system check if gloo support MacOX in the future
        #  https://github.com/facebookincubator/gloo/issues/182
",2
"            print('INFO: Cannot find MPI compilation flags, will skip compiling with MPI.')
            have_mpi = False
",2
"        raise RuntimeError('One of Gloo or MPI are required for Horovod to run. Check the logs above for more info.')

    gpu_operations = os.environ.get('HOROVOD_GPU_OPERATIONS')
    if gpu_operations and gpu_operations not in {'NCCL', 'MPI'}:
        raise DistutilsError(f'HOROVOD_GPU_OPERATIONS={gpu_operations} is invalid, '
",2
"            'You should not mix NCCL and MPI GPU due to a possible deadlock.\n'
            'If you\'re sure you want to mix them, set the '
",2
"                'third_party/eigen',
                'third_party/flatbuffers/include',
",2
"                'third_party/lbfgs/include']
    SOURCES = ['horovod/common/common.cc',
               'horovod/common/controller.cc',
               'horovod/common/fusion_buffer_manager.cc',
               'horovod/common/logging.cc',
",2
"                raise RuntimeError('MPI is not installed, try changing HOROVOD_CPU_OPERATIONS.')
",2
"            MACROS += [('HOROVOD_CPU_OPERATIONS_DEFAULT', ""'M'"")]
        elif cpu_operation.upper() == 'MLSL':
",2
"            if is_mac:
                raise RuntimeError('Cannot compile Gloo on MacOS, try changing HOROVOD_CPU_OPERATIONS.')
",2
"
    if have_mpi:
        MACROS += [('HAVE_MPI', '1')]
",2
"                    'horovod/common/gloo/gloo_controller.cc',
                    'horovod/common/gloo/http_store.cc',
                    'horovod/common/gloo/memory_store.cc',
                    'horovod/common/ops/gloo_operations.cc']
",2
"        INCLUDES += ddl_include_dirs
",2
"    if gpu_allreduce:
",2
"        if os.path.isdir(path_dir):
            for bin_file in sorted(os.listdir(path_dir)):
",2
"                yield path_dir, bin_file


def determine_gcc_version(compiler):
    try:
",2
"    return None
",2
"
    tensorflow_mpi_lib.define_macros = options['MACROS']
    tensorflow_mpi_lib.include_dirs = options['INCLUDES']
    tensorflow_mpi_lib.sources = options['SOURCES'] + \
",2
"            tf_compiler_version = LooseVersion(tf.version.COMPILER_VERSION)
",2
"        else:
",2
"        cflags, cppflags, ldshared = remove_offensive_gcc_compiler_options(compiler_version)
",2
"    try:
        with env(CC=cc_compiler, CXX=cxx_compiler, CFLAGS=cflags, CPPFLAGS=cppflags,
                 LDSHARED=ldshared):
",2
"            if options['BUILD_GLOO']:
                build_cmake(build_ext, gloo_lib, 'tf', gloo_compile_macros, options, tensorflow_mpi_lib)
",2
"    if ""dev"" in version_str:
",2
"    if m.group(2) is not None:
        version += int(m.group(2)) * 10 ** 6
    if m.group(3) is not None:
        version += int(m.group(3)) * 10 ** 3
",2
"def is_mx_mkldnn():
    try:
        from mxnet import runtime
        features = runtime.Features()
        return features.is_enabled('MKLDNN')
",2
"                import mxnet as mx
                mx_libs = mx.libinfo.find_lib_path()
                for mx_lib in mx_libs:
                    output = subprocess.check_output(['readelf', '-d', mx_lib])
",2
"                return os.environ.get('MXNET_USE_MKLDNN', '0') == '1'

",2
"                for mx_lib in mx_libs:
                    output = subprocess.check_output(['readelf', '-d', mx_lib])
                    if 'cuda' in str(output):
",2
"                        return True
                return False
",2
"    macro_have_cuda = check_macro(options['MACROS'], 'HAVE_CUDA')
",2
"        mxnet_mpi_lib.define_macros += [('MSHADOW_USE_CUDA', '1')]
    else:
        mxnet_mpi_lib.define_macros += [('MSHADOW_USE_CUDA', '0')]
    if is_mx_mkldnn():
",2
"    mxnet_mpi_lib.include_dirs = options['INCLUDES']
",2
"    # parse version
    version = parse_version(torch.__version__)
    if version is None:
",2
"        raise DistutilsPlatformError(
            'Unable to determine PyTorch version from the version string \'%s\'' % torch.__version__)
",2
"        cuda_test_ext = create_extension(
            name='horovod.torch.test_cuda',
            headers=['horovod/torch/dummy.h'],
            sources=[],
",2
"        cuda_test_ext.build()
",2
"            #include <THH/THH.h>
            void test() {
",2
"
def check_macro(macros, key):
    return any(k == key and v for k, v in macros)


",2
"        return macros + [(key, new_value)]
",2
"

",2
"        return [('{}={}'.format(flag, value) if f.split('=')[0] == flag else f) for f in flags]
    else:
",2
"        return flags + ['{}={}'.format(flag, value)]
",2
"    # Backup the options, preventing other plugins access libs that
    # compiled with compiler of this plugin
    options = deepcopy(global_options)
",2
"    have_cuda_macro = check_macro(options['MACROS'], 'HAVE_CUDA')
    if not have_cuda and have_cuda_macro:
        raise DistutilsPlatformError(
            'Horovod build with GPU support was requested, but this PyTorch '
",2
"
    have_rocm = is_torch_rocm_v2(build_ext, include_dirs=options['INCLUDES'],
                                 extra_compile_args=compile_flags)
    have_rocm_macro = check_macro(updated_macros, 'HAVE_ROCM')
    if not have_rocm and have_rocm_macro:
",2
"            'Horovod build with GPU support was requested, but this PyTorch '
            'installation does not support ROCm.')
    elif have_rocm and not have_rocm_macro:
        # ROCm PyTorch requires extensions to be hipified with the provided utility.
",2
"        for (k,v) in get_torch_rocm_macros():
            updated_macros = set_macro(updated_macros, k, v)

    # Export TORCH_VERSION equal to our representation of torch.__version__. Internally it's
    # used for backwards compatibility checks.
",2
"    updated_macros = set_macro(updated_macros, 'TORCH_VERSION', str(torch_version))
",2
"    for k, v in ext.__dict__.items():
        torch_mpi_lib_v2.__dict__[k] = v

    cc_compiler = cxx_compiler = cflags = cppflags = ldshared = None
    if sys.platform.startswith('linux') and not os.getenv('CC') and not os.getenv('CXX'):
",2
"                candidate_cc_compiler = \
                    find_matching_gcc_compiler_path(candidate_compiler_version)
                if candidate_cc_compiler and candidate_compiler_version > compiler_version:
                    cc_compiler = candidate_cc_compiler
                    cxx_compiler = candidate_cxx_compiler
",2
"
        if cc_compiler:
            print('INFO: Compilers %s and %s (version %s) selected for PyTorch plugin build.'
",2
"                'Please check the Horovod website for recommended compiler versions.\n'
                'To force a specific compiler version, set CC and CXX environment variables.')

",2
"
    extdir = os.path.abspath(
        os.path.dirname(build_ext.get_ext_fullpath(ext.name)))
    config = 'Debug' if build_ext.debug else 'Release'
",2
"                  ]

    cmake_build_args = [
        '--config', config,
",2
"        # If PyTorch is installed, it must be imported before TensorFlow, otherwise
        # we may get an error: dlopen: cannot load any more object with static TLS
        if not os.environ.get('HOROVOD_WITHOUT_PYTORCH'):
            dummy_import_torch()
        if not os.environ.get('HOROVOD_WITHOUT_TENSORFLOW'):
",2
"require_list = ['cloudpickle', 'psutil', 'pyyaml']
test_require_list = ['mock', 'pytest', 'pytest-forked']

# framework dependencies
",2
"      # which is undesirable.  Luckily, `install` action will install cffi before executing build,
      # so it's only necessary for `build*` or `bdist*` actions.
      setup_requires=require_list if is_build_action() else [],
",2
"# you may not use this file except in compliance with the License.
",2
"#
# Unless required by applicable law or agreed to in writing, software
",2
"
class KerasTests(tf.test.TestCase):
",2
"        with self.test_session(config=self.config) as sess:
",2
"                new_model = hvd.load_model(fname, custom_optimizers=custom_optimizers)
                new_opt = new_model.optimizer

            self.assertEqual(type(new_opt).__module__, 'horovod._keras')
",2
"                          metrics=[keras.metrics.categorical_accuracy],
",2
"                          sample_weight_mode='temporal')

            x = np.random.random((1, 3))
            y = np.random.random((1, 3, 3))
",2
"            self.assertEqual(type(new_opt).__name__, 'TestOptimizer')
",2
"
                if hvd.rank() == 0:
                    model.save(fname)

",2
"
    def _check_optimizer_weights(self, opt, new_opt):
        self.assertEqual(len(opt.get_weights()), len(new_opt.get_weights()))
        for weights, new_weights in zip(opt.get_weights(),
                                        new_opt.get_weights()):
",2
"                self.assertEqual(weights, new_weights)
            else:
",2
"            hopt_copy1 = hopt.from_config(cfg)
            self.assertEqual(cfg, hopt_copy1.get_config())

            hopt_copy2 = hopt.__class__.from_config(cfg)
            self.assertEqual(cfg, hopt_copy2.get_config())
",2
"            model2.build((2, 2))
            model2.set_weights(
                [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),
                 np.array([0.0, 0.0], dtype=np.float32)])
",2
"
            # Partially modify then restore
",2
"
",2
"import unittest
",2
"class TorchAdasumTests(unittest.TestCase):
  """"""
  Tests for Adasum reduction logic in horovod.torch.
  """"""
",2
"
  def are_close(self, data_type, true_vec, comp_vec):
    return self.diff_ratio(true_vec, comp_vec) < np.finfo(data_type).eps
",2
"    rank = hvd.rank()

    for data_type in self.data_types:
      denominator = local_size if hvd.nccl_built() else 1
",2
"  def test_parallel(self):
    hvd.init()
    # TODO support non-MPI Adasum operation
    # Only do this test if there are GPUs available.
",2
"        q = np.dot(a,r.T)
",2
"      expected = [np.sum(q,axis=1) / size for q in all_qs]
      all_comp = [self.are_close(data_type, e, rt.cpu().numpy()) for e,rt in zip(expected,reduced_tensors)]
      if np.alltrue(all_comp):
",2
"    hvd.init()
    # TODO support non-MPI Adasum operation
    if not hvd.mpi_enabled():
      self.skipTest(""MPI not enabled"")

",2
"      tensor = np.zeros(N,dtype=data_type)
      tensor[:] = q[:,hvd.rank()]

      tensor = torch.from_numpy(tensor).to(device)

",2
"      if comp:
        print('Stability test passed')
      else:
        print('computed: ', tensor)
        print('expected: ', expected)
",2
"    device = torch.device('cuda:{}'.format(hvd.local_rank())) if torch.cuda.is_available() else torch.device('cpu')
    np.random.seed(2)
",2
"    torch.manual_seed(2)
    size = hvd.size()
    local_size = hvd.local_size()
",2
"      comp = self.are_close(data_type, expected, tensor.cpu().numpy()) 
      if comp:
        print('Stability 2 test passed')
",2
"        print('off by: ', self.diff_ratio(expected,tensor.cpu().numpy()))
",2
"      assert comp

if __name__ == ""__main__"":
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"import unittest
import warnings

import mock
",2
"        time.sleep(0.01)

",2
"        yield v
    while True:
        yield lst[-1]
",2
"    """"""

    def __init__(self, *args, **kwargs):
        super(ElasticDriverTests, self).__init__(*args, **kwargs)
",2
"
        def exec_command(slot_info, events):
            driver.record_ready(slot_info.hostname, slot_info.local_rank)
            updated_slot_info = driver.get_slot_info(slot_info.hostname, slot_info.local_rank)
",2
"            rank_results[slot_info.rank] = (slot_info, updated_slot_info)
",2
"        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)
        driver.wait_for_available_slots(min_np=2)

        rank_results = {}

",2
"
        assert len(res) == 2
        for name, (exit_code, timestamp) in res.items():
            assert exit_code == 0, name

",2
"        assert len(rank_results) == 2
        for rank, (slot_info, updated_slot_info) in rank_results.items():
            assert updated_slot_info.size == 2, rank
            assert updated_slot_info.rank == slot_info.rank % 2, rank
",2
"            assert updated_slot_info.cross_size == 1, rank
            assert updated_slot_info.cross_rank == 0, rank

    @mock.patch('horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)
",2
"
        driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)
        driver.wait_for_available_slots(min_np=2)
",2
"
        rank_results = {}

        def exec_command(slot_info, events):
            driver.record_ready(slot_info.hostname, slot_info.local_rank)
",2
"        driver.start(np=2, create_worker_fn=exec_command)
        res = driver.get_results()
        driver.stop()

",2
"            assert updated_slot_info.local_size == slot_info.local_size, rank
            assert updated_slot_info.local_rank == slot_info.local_rank, rank
            assert updated_slot_info.cross_size == 2, rank
",2
"    def test_wait_for_min_hosts(self):
        """"""Tests that driver blocks until the min number of hosts and slots are available.""""""
        slots = [{'host-1': 4},
",2
"
        driver.start(np=2, create_worker_fn=exec_command)
        res = driver.get_results()
        driver.stop()

",2
"        assert len(res) == 4

        exit_code_sum = 0
",2
"        def exec_command(slot_info, events):
            if slot_info.hostname == 'host-1':
                if slot_info.local_rank == 0:
                    return 1, time.time()
",2
"
",2
"        port = rendezvous.start_server(handler)
        nic = list(common_intfs)[0]

",2
"
        def add_host():
",2
"            notification_receiver = NotificationReceiver()
            manager.register_listener(notification_receiver)

            driver.record_ready(slot_info.hostname, slot_info.local_rank)
",2
"
",2
"                time.sleep(0.01)

",2
"
        # On the second call, we should see the number of slots dip below the minimum, but we still want to ensure
        # we notify workers every time there is a change, so in total we should observe 3 calls.
",2
"        assert mock_get_worker_client.call_count == 3
        assert mock_get_coordinator_info.call_count == 3

    def test_order_available_hosts(self):
",2
"        ordered_hosts = HostManager.order_available_hosts(available_hosts, ordered_hosts)
",2
"        ordered_hosts = HostManager.order_available_hosts(available_hosts, ordered_hosts)
        assert ordered_hosts == ['b', 'c', 'd']

    def test_update_available_hosts(self):
        """"""Tests that the current hosts object is immutable, while fetching the latest is correctly updated.""""""
",2
"        current_hosts = host_manager.current_hosts
        assert current_hosts.available_hosts == set()
",2
"        host_manager.update_available_hosts()

        # First, check that nothing changed with our existing object, which is immutable
        assert current_hosts.available_hosts == set()
",2
"        current_hosts = host_manager.current_hosts
        assert current_hosts.available_hosts == {'a', 'b'}
        assert current_hosts.count_available_slots() == 4

",2
"        assert current_hosts.count_available_slots() == 4

        # Check the new object, make sure we've blacklisted the host
",2
"        current_hosts = host_manager.current_hosts
",2
"            ElasticDriver._discover_hosts = wrapped_discover_hosts
            driver = ElasticDriver(mock.Mock(), discovery, min_np=2, max_np=4)
            with pytest.raises(RuntimeError):
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"from common import temppath
",2
"    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(8, input_dim=2))
    model.add(tf.keras.layers.Activation('tanh'))
",2
"    model.add(tf.keras.layers.Dense(1))
    model.add(tf.keras.layers.Activation('sigmoid'))
    return model


",2
"def create_mnist_model():
    model = tf.keras.models.Sequential()
",2
"    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),
                                     activation='relu',
                                     input_shape=(8, 8, 1)))
    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
    model.add(tf.keras.layers.Dropout(0.25))
",2
"
                keras_model = keras_estimator.fit(df)

                trained_model = keras_model.getModel()
",2
"                        metrics=['accuracy'],
                        feature_cols=['features'],
",2
"                assert not store.exists(ckpt_path)
                keras_estimator._load_model_from_checkpoint.assert_not_called()
                keras_model = keras_estimator.fit(df)

",2
"                assert len(pred) == 1

",2
"                with util.prepare_data(backend.num_processes(),
                                       store,
",2
"                                       feature_columns=['features'],
",2
"                        feature_cols=['features'],
                        label_cols=['y'],
                        batch_size=1,
                        epochs=3,
                        verbose=2)
",2
"
",2
"        with spark_session('test_model_serialization') as spark:
            df = create_xor_data(spark)

            keras_estimator = hvd.KerasEstimator(
",2
"                    keras_estimator.save(saved_path)
",2
"                    keras_estimator_loaded.backend: backend,
                    keras_estimator_loaded.store: store
",2
"                assert len(pred) == 1
                assert pred.dtype == np.float32

    def test_serialize_param_value(self):
        serialized_backend = _serialize_param_value(EstimatorParams.backend.name, 'dummy_value', None, None)
",2
"        serialized_store = _serialize_param_value(EstimatorParams.store.name, 'dummy_value', None, None)
        assert serialized_store is None

",2
"    def test_calculate_shuffle_buffer_size_small_row_size(self):
        hvd_size = 4
        local_size = 2
",2
"        hvd_mock.allgather.return_value = [local_size for _ in range(hvd_size)]

        avg_row_size = 100
        train_row_count_per_worker = 100
",2
"        dense_shape = 10
        custom_sparse_to_dense = _custom_sparse_to_dense_fn()
",2
"        assert len(sparse_vector_values) == dense_shape

    def test_convert_custom_sparse_to_dense_bare_keras_fn(self):
",2
"        convert_custom_sparse_to_dense_bare_keras = BareKerasUtil._convert_custom_sparse_to_dense_fn()
        custom_sparse_row = np.array([2, 1, 2, 0.1, 0.2])
",2
"            }
",2
"        assert np.array_equal(col1_prepared, np.array([[1., 2., 3.]]))

        col3 = [np.array([3., 0., 2., 5., 0., 0.2, 0.5, 0, 0]),
                np.array([4., 0., 2., 5., 6., 0.2, 0.5, 0.6, 0])]
",2
"        shuffle_buffer_size = 10
        rows_in_row_group = 100
",2
"        batch_size = 32

        def _create_numpy_array(n_rows, shape):
            return np.array([[i for i in range(j, j + shape)] for j in range(n_rows)])
",2
"
        def dummy_reader():
            Row = collections.namedtuple('row', ['col1', 'col2', 'sample_weight', 'label'])

",2
"                    'shape': 1
                },
",2
"                # sample weight has to be a singel np array with shape (batch_size,)
                assert batch[2][0].shape == (batch_size,)

    def test_reshape(self):
",2
"        metadata = \
            {
",2
"                    'dtype': float,
",2
"                    'intermediate_format': constants.NOCHANGE,
                    'max_size': 1,
                    'shape': 1
                },
            }
",2
"
        reshape_fn = TFKerasUtil._reshape_fn(
            sample_weight_col, feature_columns, label_columns, metadata)

        reshaped_row = reshape_fn(row1)
",2
"        assert np.allclose(reshaped_row_value['col1'], np.array([3.]))
        assert np.allclose(reshaped_row_value['col2'],
                           np.array([[0., 10., 0., 30., 0., 0., 60., 0., 0., 0.]]))
",2
"
        feature_columns = ['col1', 'col2']
        label_columns = ['label1', 'label2']
        sample_weight_col = 'sample_weight'

",2
"
    def test_prep_data_tf_keras_fn_without_sparse_col(self):
        has_sparse_col = False
",2
"
        feature_columns = ['col1', 'col2']
        label_columns = ['label1', 'label2']
",2
"        input_shapes = [[-1, 1], [-1, 2, 5]]
        output_shapes = [[-1, 4], [-1, 2, 2]]
        output_names = ['label1', 'label2']
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"
import horovod.mxnet as hvd
",2
"
has_gpu = mx.context.num_gpus() > 0
",2
"            elif size < 10:
",2
"                print(""summed"", hvd.rank(), summed)
                print(""multiplied"", hvd.rank(), multiplied)
",2
"    def test_horovod_allreduce_average(self):
        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""
",2
"            # Threshold for floating point equality depends on number of
            # ranks, since we're comparing against precise multiplication.
            if size <= 3 or dtype in ['int32', 'int64']:
",2
"                threshold = 1e-4
            elif size < 15:
",2
"            mx.random.seed(1234, ctx=ctx)
            tensor = mx.nd.random.uniform(-100, 100, shape=shapes[dim],
",2
"            count += 1

            # Threshold for floating point equality depends on number of
            # ranks, since we're comparing against precise multiplication.
",2
"                print(""self"", count, dtype, dim, max_difference, threshold)
                print(""tensor"", hvd.rank(), tensor)
                print(""multiplied"", hvd.rank(), multiplied)
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
",2
"            self.skipTest(""Only one worker available"")

        # Same rank, different dimension
        ctx = self._current_context()

",2
"        shape = (17 + rank, 3)
        tensor = mx.nd.ones(shape=shape, ctx=ctx)
        try:
            output = hvd.allreduce(tensor)
            output.wait_to_read()
",2
"            assert False, 'hvd.allreduce did not throw error'
",2
"
        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")
",2
"            tensor = tensor.astype('float32')

        try:
",2
"            output.wait_to_read()
            assert False, 'hvd.allreduce did not throw error'
        except (MXNetError, RuntimeError):
            pass
",2
"        if os.environ.get('HOROVOD_MIXED_INSTALL'):
            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.
",2
"
        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")
",2
"        try:
            output = hvd.allreduce(tensor)
            output.wait_to_read()
            assert False, 'hvd.allreduce did not throw cpu-gpu error'
",2
"            expected = tensor * (i + 1) * size
            assert same(sum.asnumpy(), expected.asnumpy())

    def test_horovod_broadcast(self):
        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""
",2
"                  'float32', 'float64'] 
        dims = [1, 2, 3]
        ctx = self._current_context()
        count = 0
        shapes = [(), (17), (17, 17), (17, 17, 17)]
",2
"            if rank != root_rank:
                if same(tensor.asnumpy(), root_tensor.asnumpy()):
                    print(""broadcast"", count, dtype, dim,
",2
"            root_dict[count] = root_dict[count].astype(dtype)

            # Only do broadcasting using and on broadcast_tensor
            count += 1
",2
"
        hvd.broadcast_parameters(tensor_dict, root_rank=root_rank)
        for i in range(count):
",2
"            if not same(tensor_dict[i].asnumpy(), root_dict[i].asnumpy()):
                print(""broadcast"", count, dtype, dim)
                print(""broadcast_tensor"", hvd.rank(), tensor_dict[i])
                print(""root_tensor"", hvd.rank(), root_dict[i])
                print(""comparison"", hvd.rank(), tensor_dict[i] == root_dict[i])
",2
"            assert same(tensor_dict[i].asnumpy(), root_dict[i].asnumpy()), \
",2
"                'hvd.broadcast produces incorrect broadcasted tensor'
",2
"            output = hvd.broadcast(tensor, 0)
            output.wait_to_read()
            assert False, 'hvd.broadcast did not throw error'
        except (MXNetError, RuntimeError):
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")

        ctx = self._current_context()
",2
"            assert False, 'hvd.broadcast did not throw rank error'
        except (MXNetError, RuntimeError):
",2
"        """"""Test that the deferred initialized parameters are broadcasted.""""""
",2
"            assert same(tensor.asnumpy(), root_tensor.asnumpy()), \
                'horovod did not broadcast deferred initialized parameter correctly'

",2
"        from mxnet import gluon
",2
"                    self.dense_l = nn.HybridSequential()
                    for i in range(layer_num):
",2
"
                Parameters
",2
"                -------
                out :
                    Shape (batch_size, seq_len, fea_dim)
",2
"                """"""
                for i in range(self._layer_num):
                   data = self.ln_l[i](data)
                   data = self.dense_l[i](data)
                return data
",2
"            if cnt >= 10:
                for key, param in params.items():
                    hvd.allreduce_(param.list_data()[0])
",2
"import numpy as np

from pyspark.ml.linalg import VectorUDT
",2
"        super(SparkTorchTests, self).__init__(*args, **kwargs)
        warnings.simplefilter('module')

    def test_fit_model(self):
",2
"        model = create_xor_model()
        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
        loss = F.binary_cross_entropy

        with spark_session('test_fit_model') as spark:
",2
"            df = create_xor_data(spark)

            with local_store() as store:
                torch_estimator = hvd.TorchEstimator(
                    num_proc=2,
",2
"
                trained_model = torch_model.getModel()
                pred = trained_model(torch.ones([1, 2], dtype=torch.int32))
                assert len(pred) == 1
                assert pred.dtype == torch.float32
",2
"                    store=store,
                    model=model,
                    optimizer=optimizer,
                    loss=loss,
",2
"                    batch_size=1,
                    epochs=1,
                    verbose=2,
                    run_id=run_id)

",2
"        current_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)
        optimizer_cls = current_optimizer.__class__
",2
"    def test_calculate_shuffle_buffer_size_small_row_size(self):
        hvd_size = 4
        local_size = 2
        hvd_mock = mock.MagicMock()
        hvd_mock.local_size = lambda: local_size
",2
"
    def test_calculate_shuffle_buffer_size(self):
",2
"        assert int(shuffle_size) == \
",2
"                count += 1
",2
"        construct_metric_value_holders = remote._construct_metric_value_holders_fn()
        metric_values = construct_metric_value_holders(metric_class, metric_fn_groups, label_columns,
                                                       hvd_mock)

        assert metric_values[0][0].name == 'group_0_l1'
",2
"            to_petastorm = util.to_petastorm_fn(schema_cols, metadata)
            modified_df = df.rdd.map(to_petastorm).toDF()
",2
"        metric12 = _generate_mock_metric('12', 12)
        metric21 = _generate_mock_metric('21', 21)
        metric22 = _generate_mock_metric('22', 22)

",2
"        metric_value_groups = [[metric11, metric12], [metric21, metric22]]
        all_metric_groups_values = get_metric_avgs(metric_value_groups)

        assert all_metric_groups_values[0]['11'] == 11
        assert all_metric_groups_values[0]['12'] == 12
",2
"            return output + label

        def dummy_metric_sub(output, label):
",2
"        assert serialized_store is None

        serialized_dummy_param = _torch_param_serialize('dummy_param_name', None)
",2
"    def test_torch_direct_parquet_train(self):
        with spark_session('test_torch_direct_parquet_train') as spark:
            df = create_xor_data(spark)
",2
"                                       feature_columns=['features'],
                                       label_columns=['y']):
                    model = create_xor_model()
",2
"                        model=model,
                        optimizer=optimizer,
                        input_shapes=[[2]],
                        feature_cols=['features'],
                        label_cols=['y'],
",2
"    def test_calculate_loss_with_sample_weight(self):
        calculate_loss = remote._calculate_loss_fn()

        labels = torch.tensor([[1.0, 2.0, 3.0]])
        outputs = torch.tensor([[1.0, 0.0, 2.0]])
",2
"
        def fn_add(output, label, reduction=None):
            losses = label+output
            if reduction == 'none':
",2
"        assert loss == 5.0

",2
"    def test_calculate_loss_without_sample_weight(self):
        calculate_loss = remote._calculate_loss_fn()

",2
"            if reduction == 'none':
                return losses
            else:
",2
"#
",2
"
    def convert_cpu_fp16_to_fp32(self, *values):
        # PyTorch doesn't support any CPU ops on FP16 tensors.
",2
"        # In case we need to do ops, we will convert tensor to FP32 here.
        result = []
        for value in values:
            if value.dtype in [torch.float16, torch.HalfTensor]:
",2
"
    def filter_supported_types(self, types):
        if 'CCL_ROOT' in os.environ:
           types = [t for t in types if t in ccl_supported_types]
",2
"        """"""Test that the allreduce correctly sums 1D, 2D, 3D tensors.""""""
        hvd.init()
        size = hvd.size()
        dtypes = self.filter_supported_types([torch.IntTensor, torch.LongTensor,
",2
"        """"""Test that the allreduce correctly averages 1D, 2D, 3D tensors.""""""
        hvd.init()
",2
"            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,
",2
"                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"
            # Threshold for floating point equality depends on number of
            # ranks, since we're comparing against precise multiplication.
            if size <= 3 or dtype in [torch.IntTensor, torch.LongTensor,
                                      torch.cuda.IntTensor, torch.cuda.LongTensor]:
",2
"                break

            assert max_difference <= threshold, 'hvd.allreduce produces incorrect results'

",2
"    def test_horovod_allreduce_inplace(self):
",2
"        if _fp16_supported:
            dtypes += self.filter_supported_types([torch.HalfTensor])
        if torch.cuda.is_available():
            dtypes += [torch.cuda.IntTensor, torch.cuda.LongTensor,
                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"                threshold = 5e-4
            else:
                break
",2
"
            assert max_difference <= threshold, 'hvd.allreduce produces incorrect results'

    def test_horovod_allreduce_async_fused(self):
",2
"        is_hvd_poll_false_once = False
        for dtype, dim in itertools.product(dtypes, dims):
",2
"            torch.manual_seed(1234)
            tensor = torch.FloatTensor(*([17] * dim)).random_(-100, 100)
            tensor = self.cast_and_place(tensor, dtype)
            handle = hvd.allreduce_async(tensor, average=False)
",2
"            multiplied = tensor * size
            tests.append((dtype, multiplied, handle))

",2
"        # Make sure it's an asynchronous operation.
        assert is_hvd_poll_false_once, 'hvd.poll() always returns True, not an async op?'

        for dtype, multiplied, handle in tests:
            summed = hvd.synchronize(handle)
",2
"            summed, = self.convert_cpu_fp16_to_fp32(summed)
",2
"            max_difference = summed.sub(multiplied).max()

            # Threshold for floating point equality depends on number of
            # ranks, since we're comparing against precise multiplication.
",2
"                threshold = 5e-4
            else:
",2
"        if torch.cuda.device_count() < hvd.local_size() * 2:
            self.skipTest(""Not enough GPUs available"")
",2
"            iter += 1
            torch.manual_seed(1234)
",2
"                threshold = 0
",2
"        rank = hvd.rank()
        size = hvd.size()

        # This test does not apply if there is only one worker.
        if size == 1:
",2
"            tensor = torch.FloatTensor(*dims)

        try:
            hvd.allreduce(tensor)
            assert False, 'hvd.allreduce did not throw error'
",2
"        # Only do this test if there are GPUs available.
        if not torch.cuda.is_available():
            self.skipTest(""No GPUs available"")
",2
"        dims = [17] * 3
        tensor = torch.FloatTensor(*dims)
",2
"        try:
            for i in range(10):
                hvd.allreduce_async(tensor, name='duplicate_name')
            assert False, 'hvd.allreduce_async did not throw error'
        except (torch.FatalError, ValueError):
",2
"            pass
",2
"
    def test_horovod_allreduce_grad_average(self):
        """"""Test the correctness of the allreduce averaged gradient.""""""
        hvd.init()
",2
"                dtypes += [torch.cuda.HalfTensor]
        dims = [1, 2, 3]
",2
"                       torch.cuda.IntTensor, torch.cuda.LongTensor,
                       torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"
    def test_horovod_allgather_variable_size(self):
        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors,
        even if those tensors have different sizes along the first dim.""""""
        hvd.init()
",2
"            if _fp16_supported:
                dtypes += [torch.cuda.HalfTensor]
        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
            # Support tests up to MPI Size of 35
",2
"            for i in range(size):
                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)
                rank_tensor = gathered[sum(
",2
"            tensor = torch.FloatTensor(*(rank_shape)).fill_(1).mul_(rank)
            tensor = self.cast_and_place(tensor, dtype)
            handle = hvd.allgather_async(tensor)
            if not hvd.poll(handle):
                is_hvd_poll_false_once = True
",2
"        except (torch.FatalError, RuntimeError):
            pass

",2
"
        try:
            hvd.allgather(tensor)
            assert False, 'hvd.allgather did not throw error'
",2
"        size = hvd.size()
",2
"        tensor = torch.FloatTensor(*dims)
",2
"            for i in range(10):
                hvd.allgather_async(tensor, name='duplicate_name')
",2
"
            tensor_sizes = [3, 2, 7, 4, 6, 8, 10] * 5
            tensor_sizes = tensor_sizes[:size]

            tensor = torch.FloatTensor(
",2
"    def test_horovod_broadcast(self):
        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors.""""""
        hvd.init()
        rank = hvd.rank()
        size = hvd.size()
",2
"            self.skipTest(""Only one worker available"")

        dtypes = [torch.ByteTensor, torch.CharTensor, torch.ShortTensor,
",2
"            dtypes += [torch.cuda.ByteTensor, torch.cuda.CharTensor, torch.cuda.ShortTensor,
                       torch.cuda.IntTensor, torch.cuda.LongTensor,
",2
"                'hvd.broadcast produces incorrect broadcasted tensor'
",2
"    def test_horovod_broadcast_error(self):
        """"""Test that the broadcast returns an error if any dimension besides
        the first is different among the tensors being broadcasted.""""""
",2
"
",2
"            self.skipTest(""Only one worker available"")

",2
"        tensor_size = [17] * 3
        tensor_size[1] = 10 * (rank + 1)
        tensor = torch.FloatTensor(*tensor_size).fill_(1).mul_(rank)
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")

",2
"
        try:
",2
"            hvd.broadcast(tensor, 0)
            assert False, 'hvd.broadcast did not throw error'
        except (torch.FatalError, RuntimeError):
            pass

",2
"
        tensor = torch.FloatTensor(*([17] * 3)).fill_(1)
",2
"        rank = hvd.rank()
        size = hvd.size()

        # This test does not apply if there is only one worker.
        if size == 1:
",2
"            dtypes += [torch.cuda.FloatTensor, torch.cuda.DoubleTensor]
",2
"            tensor.requires_grad_()

            broadcasted_tensor = hvd.broadcast(tensor, root_rank)
",2
"    def test_broadcast_state(self):
        hvd.init()

        N, D_in, H, D_out = 64, 100, 10, 10
",2
"        def new_optimizer(cls, opt_params, model):
            p = {
                k: v for k, v in opt_params.items()
",2
"                for param_id in group['params']:
                    if param_id not in state_dict['state']:
                        continue
                    params = sorted(state_dict['state'][param_id].items())
",2
"               subclass != torch.optim.LBFGS and
               subclass != torch.optim.SparseAdam
        ]
        optimizers.sort()

",2
"            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

",2
"            with temppath() as fname:
                if hvd.rank() == 0:
                    state = {
",2
"                    (model_param_value == model_param_value_after).all())

            hvd.broadcast_optimizer_state(optimizer, root_rank=0)

            expected_tensors = 4
",2
"                self.assertEqual(name, name_after)
",2
"    @unittest.skip
    def test_broadcast_state_gpu(self):
        # Only do this test if there are GPUs available.
",2
"            self.test_broadcast_state()
",2
"        finally:
",2
"            )

            params = params_0 if hvd.rank() == 0 else params_1
            p = {
                k: v for k, v in params.items()
",2
"
",2
"            model, optimizer = create_model(opt_class)
            y_pred = model(x)
            loss = F.mse_loss(y_pred, y, size_average=False)
",2
"            optimizer.step()

    @pytest.mark.skipif(LooseVersion(torch.__version__) < LooseVersion('0.4.1'),
                        reason='Cannot optimize parameters that do not require gradients before PyTorch 0.4.1')
",2
"
",2
"        grad = optimizer.param_groups[0]['params'][1].grad
        bgrad = hvd.broadcast(grad, root_rank=0)

        assert optimizer.param_groups[0]['params'][0].grad is None
        assert torch.all(torch.eq(grad, bgrad)).item()
",2
"        valid_dtypes = [torch.float32, torch.float64]
        invalid_dtypes = [torch.uint8, torch.int8, torch.int16,
                          torch.int32, torch.int64]

        tensor_size = [5] * 3
",2
"        for dtype in valid_dtypes:
",2
"            tensor = torch.ones(tensor_size, dtype=dtype)

",2
"
    def test_force_allreduce(self):
",2
"            p = {
",2
"        class Net(torch.nn.Module):
",2
"                self.fc2 = torch.nn.Linear(H, D_out)
                self.fc3 = torch.nn.Linear(D_out, D_out)

",2
"
        def create_model(opt_class, opt_params):
            model = Net()
",2
"            dict(lr=0.2)
",2
"            if rank == 0:
                loss = F.mse_loss(y_pred1, y, size_average=False)
            else:
                loss = F.mse_loss(y_pred2, y, size_average=False)
",2
"        size = hvd.size()
",2
"                self.conv2 = torch.nn.Conv2d(100, 1, 1).cuda(second_device)
",2
"                x = x.cuda(second_device)
                x = self.conv2(x)
                return x

",2
"        loss.backward()
        opt.step()

    def test_delta_optimizer(self):
",2
"        """"""Test that delta optimizer.""""""
",2
"        hvd.init()
        # TODO support non-MPI Adasum operation
        # Only do this test if there are GPUs available.
        if not hvd.mpi_enabled() or not torch.cuda.is_available():
",2
"
            def forward(self, x):
                x = x.cuda(local_rank)
                x = self.conv1(x)
                x = x.cuda(local_rank)
",2
"        model = Net()
        inp = torch.rand([1, 1, 1000, 1000])

        opt = torch.optim.SGD(model.parameters(), lr=0.1)

",2
"        opt = hvd.DistributedOptimizer(opt, named_parameters=model.named_parameters(), op=hvd.Adasum)
        loss = model(inp).sum()
        opt.zero_grad()
",2
"        loss.backward()
        opt.step()

    def test_duplicate_names(self):
        """"""Test that passing duplicate names to optimizer will fail.""""""
",2
"        # This will have duplicate names, since both net1 and net2 have 'weight' and 'bias'
",2
"        """"""Test that makes sure that gradients can be turned off/on dynamically.""""""
        hvd.init()
        size = hvd.size()
",2
"        gen_opt = hvd.DistributedOptimizer(gen_opt, named_parameters=gen.named_parameters())

        disc_opt = torch.optim.SGD(disc.parameters(), lr=0.1)
        disc_opt = hvd.DistributedOptimizer(disc_opt, named_parameters=disc.named_parameters())
",2
"            train_step(train_generator=True)

            # Step 2: train discriminator.
            train_step(train_discriminator=True)
",2
"        model.weight = torch.nn.Parameter(torch.zeros(1, 1) + 0.5)
        model.bias = torch.nn.Parameter(torch.zeros(1))
        hvd.broadcast_parameters(model.state_dict(), root_rank=0)
        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
        optimizer = hvd.DistributedOptimizer(
",2
"            optimizer, named_parameters=model.named_parameters())

",2
"        y = torch.ones(1, 1).requires_grad_()
",2
"
        model = torch.nn.Linear(1, 1)
        hvd.broadcast_parameters(model.state_dict(), root_rank=0)
        optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
        optimizer = hvd.DistributedOptimizer(
",2
"            optimizer, named_parameters=model.named_parameters())

",2
"        y_pred = model(x)
        loss = F.mse_loss(y_pred, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.synchronize()
",2
"            assert len(ws) == 1
            assert 'optimizer.step() called without optimizer.skip_synchronize()' \
",2
"
",2
"        loss.backward()
        opt.step()

    def test_missing_named_parameters(self):
",2
"            tensor_b = self.cast_and_place(tensor_b, dtype)

",2
"                averaged_b = hvd.synchronize(handle_b)
                if dtype.is_cuda:
                    ret = hvd.join(hvd.local_rank())
                else:
                    ret = hvd.join()
",2
"                    break
                assert max_difference_a <= threshold, 'hvd.join with hvd.allreduce produces incorrect results'
                assert max_difference_b <= threshold, 'hvd.join with hvd.allreduce produces incorrect results'
",2
"        dims = [17] * 3
        tensor = torch.FloatTensor(*dims)
",2
"        if rank == 0:
",2
"            if torch.cuda.is_available():
                ret = hvd.join(hvd.local_rank())
            else:
                ret = hvd.join()
        else:
",2
"                pass

",2
"    
",2
"            self.skipTest(""No GPUs available"")

        hvd.init()
",2
"
",2
"        ts_list = [
            torch.stack([
",2
"                torch.tensor([
                    [r, r + 1],
                    [r * 2, r * 2 + 1],
                    [r * 3, r * 3 + 1],
",2
"                    [r * 4, r * 4 + 1]
                ])
                for r in range(hvd.size())
            ]),
            torch.stack([
",2
"            bn_out.mean(dim=0).sum().backward()
            assert (hvd.allreduce(sync_bn.weight.grad, name='sync_bn.weight.grad') - bn.weight.grad).abs().sum() < 1e-6
            assert (hvd.allreduce(sync_bn.bias.grad, name='sync_bn.bias.grad') - bn.bias.grad).abs().sum() < 1e-6
            assert (hvd.allreduce(ts1.grad, name='ts1.grad') - ts2.grad).abs().sum() < 1e-6
",2
"                        reason='Synchronizing state requires PyTorch 1.0 or above')
    def test_elastic_state(self):
        hvd.init()
",2
"            '0.bias': torch.tensor([v, v])
        })

        model2 = torch.nn.Sequential(torch.nn.Linear(2, 2))
",2
"        model1_weights = model1.state_dict().values()
        model2_weights = model2.state_dict().values()
",2
"            np.testing.assert_allclose(w, np.ones_like(w))
        assert state.batch == 20
        assert state.epoch == 10

",2
"            np.testing.assert_allclose(w1, w2)
        assert state.batch == 20
        assert state.epoch == 10

",2
"        # Partially modify then commit
        model1.load_state_dict(model2.state_dict())
        state.batch = 21
",2
"import numpy as np
import pytest
import tensorflow as tf
import warnings

",2
"
        self.config = tf.ConfigProto()
        self.config.gpu_options.allow_growth = True
        self.config.gpu_options.visible_device_list = str(hvd.local_rank())

",2
"            model.add(keras.layers.ThresholdedReLU(0.5))
",2
"
            x = np.random.random((1, 3))
            y = np.random.random((1, 3, 3))
",2
"                                steps_per_epoch=10,
                                callbacks=callbacks,
                                epochs=0,
                                verbose=0,
",2
"
    @pytest.mark.skipif(LooseVersion(tf.__version__) < LooseVersion('1.12.0'), reason='TensorFlow version too low')
    def test_load_model(self):
",2
"        with self.test_session(config=self.config) as sess:
            K.set_session(sess)

            opt = keras.optimizers.RMSprop(lr=0.0001)
",2
"            opt = hvd.DistributedOptimizer(opt)

",2
"
",2
"            self.assertEqual(type(new_opt).__module__, 'horovod._keras')
            self.assertEqual(type(new_opt).__name__, 'RMSprop')
            self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))
            self._check_optimizer_weights(opt, new_opt)

",2
"            model.add(keras.layers.RepeatVector(3))
            model.add(keras.layers.TimeDistributed(keras.layers.Dense(3)))
            model.compile(loss=keras.losses.MSE,
                          optimizer=opt,
",2
"                model.save(fname)

",2
"            y = np.random.random((1, 3, 3))
            model.train_on_batch(x, y)

            with temppath() as fname:
",2
"                          optimizer=opt,
                          metrics=[keras.metrics.categorical_accuracy],
                          sample_weight_mode='temporal')
",2
"
            return model
",2
"                K.set_session(sess)

                model = create_model()

                x = np.random.random((1, 3))
",2
"                K.set_session(sess)

",2
"                def generator():
                    while 1:
",2
"                else:
                    self.assertEqual(len(model.optimizer.weights), 0)

",2
"            if np.isscalar(weights):
",2
"            model1 = tf.keras.Sequential([
                tf.keras.layers.Dense(2, activation='softmax')
",2
"            state.restore()

            for w1, w2 in zip(model1.get_weights(), model1_weights):
",2
"            model1.set_weights(model2_weights)
            state.batch = 21
            state.epoch = 11
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"import unittest
import warnings
",2
"from horovod.common.util import env

from common import temppath


",2
"                hvd.init()

                # Perform a simple allreduce operation
                hvd.allreduce(torch.tensor([1, 2, 3], dtype=torch.float32), name='test_allreduce')

",2
"
import copy
import io
import itertools
",2
"import pytest
import mock

from mock import MagicMock
",2
"
import horovod
from horovod.run.common.util import codec, config_parser, safe_shell_exec, secret, \
",2
"
",2
"
class RunTests(unittest.TestCase):
    """"""
    Tests for horovod.run.
    """"""
",2
"                           '--hierarchical-allreduce',
                           '--hierarchical-allgather'):
            args = parse_args()
            env = {}
",2
"            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_WARMUP_SAMPLES), '1')
            self.assertEqual(env.get(config_parser.HOROVOD_AUTOTUNE_STEPS_PER_SAMPLE), '5')
",2
"                           '--autotune',
                           '--cache-capacity', '1024',
                           '--no-hierarchical-allgather'):
            args = parse_args()
",2
"            self.assertEqual(env.get(config_parser.HOROVOD_HIERARCHICAL_ALLGATHER), '0')

    def test_timeline_args(self):
        with override_args('horovodrun', '-np', '2',
                           '--timeline-filename', '/tmp/timeline.json',
",2
"
    def test_stall_check_args(self):
        with override_args('horovodrun', '-np', '2',
",2
"                           '--no-stall-check'):
            args = parse_args()
",2
"            env = {}
            config_parser.set_env_from_args(env, args)

",2
"                           '--stall-check-shutdown-time-seconds', '20'):
            args = parse_args()
            env = {}
            config_parser.set_env_from_args(env, args)

",2
"    def test_library_args(self):
        with override_args('horovodrun', '-np', '2',
",2
"            self.assertEqual(args.num_nccl_streams, 2)
            self.assertEqual(args.ccl_bgt_affinity, 1)
            self.assertEqual(args.gloo_timeout_seconds, 60)
",2
"
    # test_on_event tests in_thread as well, but it does not test args
",2
"        self.assertFalse(thread.is_alive())
",2
"        # a happy run without args and stop event
        event = threading.Event()
        fn = mock.Mock()
        thread = on_event(event, fn)
        fn.assert_not_called()
",2
"        fn.assert_called_once()

        # a happy run with args but without stop event
        event = threading.Event()
",2
"        fn = mock.Mock()
        thread = on_event(event, fn, ('a', 1))
        fn.assert_not_called()
        event.set()
",2
"        stop = threading.Event()
        fn = mock.Mock()
        thread = on_event(event, fn, stop=stop, check_interval_seconds=0.01)
        fn.assert_not_called()
        stop.set()
",2
"        event.set()
        thread.join(1.0)
",2
"        fn = mock.Mock()
        with pytest.raises(ValueError, match=""^args must be a tuple, not <(class|type) 'int'>, ""
                                             ""for a single argument use \\(arg,\\)$""):
",2
"            on_event(event, fn, args=1)
",2
"
    def test_safe_shell_exec_captures_stderr(self):
        self.do_test_safe_shell_exec('echo hello >&2', 0, '', 'hello\n')
",2
"        self.do_test_safe_shell_exec(cmd, 0, 'hello\nstdout', 'hello\nstderr')

    def test_safe_shell_exec_returns_exit_code(self):
",2
"        self.do_test_safe_shell_exec('false', 1, '', '')

    def test_safe_shell_exec_interrupts_on_event(self):
        # interrupt execute in one second
",2
"            # It's important that this executes in an entirely different interpreter with as little shared
            # state as possible, to avoid issues with the semaphore tracker.
",2
"        hash = host_hash()
        # host_hash should consider CONTAINER_ID environment variable
        with override_env({'CONTAINER_ID': 'a container id'}):
",2
"            self.assertNotEqual(host_hash(), hash)
        self.assertEqual(host_hash(), hash)

    def test_get_mpi_implementation(self):
",2
"
        test(""output"", exit_code=1, expected=_MISSING_IMPL)

        test(None, _MISSING_IMPL)

",2
"                mpi_run.assert_called_once()
",2
"        for use_gloo, use_mpi, use_js, \
            gloo_is_built, mpi_is_built, \
",2
"                if mpi_is_built:
                    expected = 'mpi'
                else:
                    exception = r'^MPI support has not been built\.  If this is not expected, ensure MPI is installed ' \
",2
"            test(use_gloo, use_mpi, use_js,
                 gloo_is_built, mpi_is_built,
                 lsf_exists, jsrun_installed,
                 expected, exception)
",2
"    """"""
    Tests mpi_run with full settings.
    """"""
    def test_mpi_run_full(self):
",2
"        )

",2
"
        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):
            with mock.patch(""horovod.run.mpi_run.safe_shell_exec.execute"", return_value=0) as execute:
                mpi_run(settings, nics, env, cmd, stdout=stdout, stderr=stderr)

",2
"                                    '>mpi-extra args go here< '
                                    'cmd arg1 arg2').format(mpi_flags=' '.join(mpi_flags))
                expected_env = {'env1': 'val1', 'env2': 'val2', 'PATH': os.environ.get('PATH')}
                execute.assert_called_once_with(expected_command, env=expected_env, stdout=stdout, stderr=stderr)

",2
"    def test_mpi_run_with_non_zero_exit(self):
        if not mpi_available():
            self.skipTest(""MPI is not available"")

",2
"                fp.write('172.31.33.9 slots=8\n')

            hosts = parse_host_files(host_filename)
            self.assertEqual(hosts, '172.31.32.7:8,172.31.33.9:8')
",2
"        def mpi_impl_flags(tcp):
            return [""--mock-mpi-impl-flags""], []
",2
"
rank: 4: { hostname: host2; cpu: {0-3} ; gpu: * ; mem: * }
",2
"    @mock.patch('horovod.run.util.lsf.LSFUtils.get_num_gpus', MagicMock(return_value=2))
    @mock.patch('horovod.run.util.network.filter_local_addresses', MagicMock(return_value=['host1', 'host2']))
    @mock.patch('horovod.run.runner._check_all_hosts_ssh_successful', MagicMock())
",2
"            time.sleep(10 * hvd.rank());
        try:
",2
"# limitations under the License.
",2
"        super(Tf2KerasTests, self).__init__(*args, **kwargs)
        warnings.simplefilter('module')
        hvd.init()

        gpus = tf.config.experimental.list_physical_devices('GPU')
",2
"        opt = hvd.DistributedOptimizer(opt)
",2
"        model.compile(loss=keras.losses.mean_squared_error,
                      optimizer=opt,
                      experimental_run_tf_function=False)

        x = np.random.randint(1000, size=(32, 10))
",2
"            tf.keras.layers.Dense(2, activation='softmax')
        ])
        model2.build((2, 2))
",2
"        model2.set_weights(
            [np.array([[1.0,  2.0], [3.0, 4.0]], dtype=np.float32),
             np.array([0.0, 0.0], dtype=np.float32)])

",2
"        # After sync, all values should match the root rank
        for w in state.model.get_weights():
",2
"        # Partially modify then restore
        model1.set_weights(model2_weights)
",2
"
        for w1, w2 in zip(model1.get_weights(), model1_weights):
            self.assertAllClose(w1, w2)
        assert state.batch == 20
",2
"
        state.commit()
",2
"        state.restore()

        for w1, w2 in zip(model1.get_weights(), model2_weights):
            self.assertAllClose(w1, w2)
        assert state.batch == 21
",2
"# =============================================================================

""""""Tests for horovod.tensorflow.mpi_ops.""""""

from distutils.version import LooseVersion
",2
"from horovod.tensorflow.util import _executing_eagerly, _has_eager
from tensorflow.python.framework import ops
",2
"
ccl_supported_types = set([tf.uint8, tf.int32, tf.int64, tf.float32, tf.float64])

_IS_TF2 = LooseVersion(tf.__version__) >= LooseVersion('2.0.0')
",2
"    """"""
    Tests for ops in horovod.tensorflow.
    """"""

    def __init__(self, *args, **kwargs):
",2
"        else:
            return sess.run(tensors)

    def assign(self, variables, values):
",2
"                var.assign(val)
        else:
",2
"           types = [t for t in types if t in ccl_supported_types]
        return types

    def test_horovod_rank(self):
",2
"
        if is_mpi:
            assert mpi_rank == rank
        else:
            assert gloo_rank == rank
",2
"
        # The mpi size does not match gloo size, we need to figure which one
        # we are using to run the test.
        is_mpi = gloo_size == -1
",2
"        hvd.init()
",2
"        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
            with tf.device(""/cpu:0""):
                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"                summed = hvd.allreduce(tensor, average=False)
            multiplied = tensor * size
            max_difference = tf.reduce_max(tf.abs(summed - multiplied))
",2
"            self.assertTrue(diff <= threshold, ""hvd.allreduce produces incorrect results"")

",2
"        for dtype, dim in itertools.product(dtypes, dims):
",2
"            with tf.device(""/cpu:0""):
                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")

        hvd.init()
        local_rank = hvd.local_rank()
        size = hvd.size()
",2
"                threshold = 1e-4
            elif size < 15:
                threshold = 5e-4
            else:
",2
"            diff = self.evaluate(max_difference)
",2
"        # Only do this test if there are GPUs available.
        if not tf.test.is_gpu_available(cuda_only=True):
            self.skipTest((""No GPUs available""))

        if os.environ.get('HOROVOD_MIXED_INSTALL'):
",2
"            # Threshold for floating point equality depends on number of
            # ranks, since we're comparing against precise multiplication.
            if size <= 3 or dtype in [tf.int32, tf.int64]:
                threshold = 0
            elif size < 10:
",2
"                threshold = 1e-4
            elif size < 15:
                threshold = 5e-4
",2
"
            test = max_difference <= threshold
",2
"        local_rank = hvd.local_rank()
",2
"        dtypes = [tf.int32, tf.int64, tf.float16, tf.float32, tf.float64]
        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
            iter += 1
            with tf.device(""/gpu:%d"" % gpu_ids[(iter + local_rank) % 2]):
",2
"                tensor = self.random_uniform(
                    [17] * dim, -100, 100, dtype=dtype)
",2
"                threshold = 1e-4
",2
"            self.skipTest((""No GPUs available""))

        if os.environ.get('HOROVOD_MIXED_INSTALL'):
            # Skip if compiled with CUDA but without HOROVOD_GPU_OPERATIONS.
",2
"                    grad_out = self.evaluate(grad)

            expected = np.ones([5] * dim) * size
            err = np.linalg.norm(expected - grad_out)
",2
"                            ""error: %s"" % (grad_out, expected, str(err)))

    def test_horovod_allgather_cpu(self):
",2
"        for dtype, dim in itertools.product(dtypes, dims):
            with tf.device(""/cpu:0""):
",2
"                rank_tensor = tf.slice(gathered_tensor,
                                       [i * 17] + [0] * (dim - 1),
                                       [17] + [-1] * (dim - 1))
                self.assertEqual(list(rank_tensor.shape), [17] * dim)
                # tf.equal() does not support tf.uint16 as of TensorFlow 1.2,
",2
"                # so need to cast rank_tensor to tf.int32.
                if dtype != tf.bool:
                    value = i
                else:
                    value = i % 2
",2
"            self.skipTest(""Not compiled with HOROVOD_GPU_OPERATIONS"")
",2
"
        hvd.init()
        rank = hvd.rank()
",2
"            with tf.device(""/gpu:%d"" % local_rank):
                tensor = tf.ones([17] * dim) * rank
                if dtype == tf.bool:
                    tensor = tensor % 2
                tensor = tf.cast(tensor, dtype=dtype)
",2
"                    value = i
",2
"                else:
                    value = i % 2
                self.assertTrue(
",2
"                    self.evaluate(tf.reduce_all(
                        tf.equal(tf.cast(rank_tensor, tf.int32), value))),
",2
"        """"""Test that the allgather correctly gathers 1D, 2D, 3D tensors
        with Tensor Fusion.""""""
        hvd.init()
        rank = hvd.rank()
        size = hvd.size()
",2
"                tensor = tf.ones([17] * dim) * rank
                if dtype == tf.bool:
                    tensor = tensor % 2
                tensor = tf.cast(tensor, dtype=dtype)
                gathered = hvd.allgather(tensor)
",2
"
",2
"                rank_tensor = tf.slice(gathered,
                                       [i * 17] + [0] * (dim - 1),
",2
"        # Only do this test if there are GPUs available.
        if not tf.test.is_gpu_available(cuda_only=True):
            self.skipTest((""No GPUs available""))
",2
"            for i in range(size):
                rank_tensor = tf.slice(gathered,
                                       [i * 17] + [0] * (dim - 1),
                                       [17] + [-1] * (dim - 1))
                if dtype != tf.bool:
",2
"            self.assertTrue(shape_tests_passed,
                            ""hvd.allgather produces incorrect gathered tensor"")
",2
"
            tensor_sizes = [17, 32, 81, 12, 15, 23, 22] * 5
",2
"                tensor = tensor % 2
",2
"                             [sum(tensor_sizes)] + [17] * (dim - 1))))

            for i in range(size):
                rank_size = [tensor_sizes[i]] + [17] * (dim - 1)
                rank_tensor = tf.slice(
",2
"                tests.append(tf.reduce_all(
                    tf.equal(tf.cast(rank_tensor, tf.int32), value)))

            shape_tests_passed, value_tests_passed = \
",2
"            self.assertTrue(shape_tests_passed,
                            ""hvd.allgather produces incorrect gathered tensor"")

",2
"                  tf.float64, tf.bool]
        dims = [1, 2, 3]
        for dtype, dim in itertools.product(dtypes, dims):
",2
"            if dtype == tf.bool:
                tensor = tensor % 2
            tensor = tf.cast(tensor, dtype=dtype)
            gathered = hvd.allgather(tensor)

",2
"                        tf.equal(tf.cast(rank_tensor, tf.int32), value))),
                    ""hvd.allgather produces incorrect gathered tensor"")

    def test_horovod_allgather_error(self):
        """"""Test that the allgather returns an error if any dimension besides
",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")

",2
"
    def test_horovod_allgather_type_error(self):
        """"""Test that the allgather returns an error if the types being gathered
        differ among the processes""""""
",2
"        hvd.init()
        rank = hvd.rank()
        size = hvd.size()

        # As of TensorFlow v1.9, gradients are not supported on
",2
"                        tf.ones([tensor_sizes[rank]] + [17] * (dim - 1)) * rank)
                    if dtype == tf.bool:
                        tensor = tensor % 2
                    tensor = tf.cast(tensor, dtype=dtype)
",2
"                if dtype == tf.bool:
                    tensor = tensor % 2
",2
"        # As of TensorFlow v1.9, gradients are not supported on
        # integer tensors
        dtypes = [tf.float32, tf.float64]
        dims = [1, 2, 3]
",2
"
    def test_horovod_broadcast_cpu(self):
        """"""Test that the broadcast correctly broadcasts 1D, 2D, 3D tensors on CPU.""""""
        hvd.init()
",2
"        dims = [1, 2, 3]
",2
"            with tf.device(""/gpu:%d"" % local_rank):
                tensor = tf.ones([17] * dim) * rank
",2
"                    tf.cast(root_tensor, tf.int32), tf.cast(broadcasted_tensor, tf.int32)))),
                ""hvd.broadcast produces incorrect broadcasted tensor"")

    def test_horovod_broadcast_error(self):
",2
"        specify different root rank.""""""
        hvd.init()
        rank = hvd.rank()
        size = hvd.size()

",2
"        # This test does not apply if there is only one worker.
        if size == 1:
            self.skipTest(""Only one worker available"")
",2
"    def test_horovod_broadcast_grad_cpu(self):
        """"""Test the correctness of the broadcast gradient on CPU.""""""
",2
"                else:
                    tensor = tf.ones([5] * dim) * rank
                if dtype == tf.bool:
                    tensor = tensor % 2
                if _executing_eagerly():
",2
"                    broadcasted_tensor = hvd.broadcast(tensor, root_rank)
",2
"
        # This test does not apply if there is only one worker.
        if size == 1:
",2
"                    tensor = self.tfe.Variable(tf.ones([5] * dim) * rank)
                else:
                    tensor = tf.ones([5] * dim) * rank
                if dtype == tf.bool:
                    tensor = tensor % 2
",2
"                    with tf.GradientTape() as tape:
                        tensor = tf.cast(tensor, dtype=dtype)
                        broadcasted_tensor = hvd.broadcast(tensor, root_rank)
                    grad_out = tape.gradient(broadcasted_tensor, tensor)
                else:
",2
"        """"""Test that tries to broadcast tensorflow global variables
        in eager execution mode. This call should raise a RuntimeError.""""""

        if not hvd.util._executing_eagerly():
            self.skipTest(""Only in eager execution mode"")
",2
"
        with self.assertRaises(RuntimeError):
            hvd.broadcast_global_variables(root_rank=0)
",2
"
    def test_compression_fp16(self):
        valid_dtypes = [tf.float16, tf.float32, tf.float64]
        invalid_dtypes = [tf.uint8, tf.int8, tf.uint16, tf.int16,
                          tf.int32, tf.int64, tf.bool]
",2
"            tensor_compressed, ctx = compression.compress(tensor)
            self.assertEqual(tensor_compressed.dtype, tf.float16)

            tensor_decompressed = compression.decompress(tensor_compressed, ctx)
            self.assertEqual(tensor_decompressed.dtype, dtype)
",2
"
            actual = self.evaluate(tensor_decompressed)
            expected = np.ones(tensor_size)
",2
"        with tf.device(""/cpu:0""):
            expected_obj = {
                'hello': 123,
                0: [1, 2]
",2
"            obj = hvd.broadcast_object(obj, root_rank=0)
",2
"
",2
"                np.array([[v, v], [v, v]]),
                np.array([v, v])
",2
"            ]
",2
"                init = tf.global_variables_initializer()
",2
"                self.evaluate(init)

            state = hvd.elastic.TensorFlowState(vars1, batch=20 + hvd.rank(), epoch=10 + hvd.rank())
            state.sync()

",2
"
            state.restore()

            for w1, w2 in zip(self.evaluate(vars1), weights1):
",2
"                self.assertAllClose(w1, w2)
            assert state.batch == 20
            assert state.epoch == 10

",2
"            # Partially modify then commit
            self.assign(vars1, weights2)
            state.batch = 21
",2
"            state.epoch = 11
",2
"
if _has_eager:
    from tensorflow.python.framework.test_util import run_all_in_graph_and_eager_modes
    run_all_in_graph_and_eager_modes(TensorFlowTests)

",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",2
"# ==============================================================================

import unittest
import warnings

",2
"from horovod.run import run


",2
"    def __init__(self, *args, **kwargs):
        super(InteractiveRunTests, self).__init__(*args, **kwargs)
        warnings.simplefilter('module')

",2
"                run(fn, np=2, use_gloo=True)

        if mpi_built():
            with pytest.raises(RuntimeError, match='mpirun failed'):
",2
"    variables that contain the rank and size of the MPI_COMM_WORLD
    communicator. We can read those environment variables from Python in order
    to ensure that `hvd.rank()` and `hvd.size()` return the expected values.

",2
"    to support several different implementation, but really it only needs to
    support whatever implementation we want to use for the TensorFlow test
",2
"    application not started with mpirun, it will create a new independent
    communicator with only one process in it.)
    """"""
    rank_env = 'PMI_RANK OMPI_COMM_WORLD_RANK'.split()
    size_env = 'PMI_SIZE OMPI_COMM_WORLD_SIZE'.split()
",2
"

",2
"
    t = in_thread(target=fn)


def wait(func, timeout=None):
",2
"    """"""Wait for func to return True until timeout.""""""
",2
"    try:
        yield path
    finally:
        if os.path.exists(path):
",2
"        sys.argv[1:] = args
        yield
    finally:
",2
"    controller to use. Patching these methods allows to test horovod.spark.run without an MPI
    implementation to be installed.

    :param gloo_is_built: boolean returned by gloo_built
",2
"    """"""
    with mock.patch(""horovod.run.runner.gloo_built"", return_value=gloo_is_built) as g:
",2
"    Patches the _get_mpi_implementation_flags method used by horovod.run.mpi_run to retrieve
",2
"
@contextlib.contextmanager
def lsf_and_jsrun(lsf_exists, jsrun_installed):
    """"""
",2
"    Patches the lsf.LSFUtils.using_lsf and is_jsrun_installed methods called from
    horovod.run.run.run_controller to return the given booleans.
    :param lsf_exists: boolean returned by lsf.LSFUtils.using_lsf
",2
"# Unless required by applicable law or agreed to in writing, software
",2
"
import pyspark

from pyspark.ml.linalg import DenseVector, SparseVector, VectorUDT
from pyspark.sql.types import ArrayType, BooleanType, DoubleType, FloatType, IntegerType, \
",2
"    NullType, StructField, StructType

import horovod.spark
",2
"
",2
"

# Spark will fail to initialize correctly locally on Mac OS without this
",2
"    """"""
    def test_spark_run_with_gloo(self):
        self.do_test_spark_run(use_mpi=False, use_gloo=True)

    """"""
",2
"        expected_env = '-x env1 -x env2'
        extra_mpi_args = '<extra args go here>'
        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):
            self._do_test_spark_run(num_proc=2, use_mpi=use_mpi, use_gloo=use_gloo,
                                    extra_mpi_args=extra_mpi_args,
",2
"    """"""
    Test that horovod.spark.run does not default to spark parallelism given num_proc using MPI.
",2
"        self._do_test_spark_run(num_proc=1, cores=2, expected_np=1,
",2
"                                    extra_mpi_args=extra_mpi_args,
                                    env=env, stdout='<stdout>', stderr='<stderr>',
                                    cores=4, expected_np=2, expected_env=expected_env)

",2
"    """"""
",2
"
",2
"    """"""
    def do_test_spark_run_does_not_default_env_to_os_env(self, use_mpi, use_gloo):
        env = {'env1': 'val1', 'env2': 'val2'}
        expected_env = ''

",2
"    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using MPI.
    """"""
    def test_spark_run_with_non_zero_exit_with_mpi(self):
        expected = '^mpirun failed with exit code 1$'
        with mpi_implementation_flags():
",2
"    Test that horovod.spark.run raises an exception on non-zero exit code of mpi_run using Gloo.
",2
"                return 1, alloc_info.rank
            return _exec_command

",2
"                        with is_built(gloo_is_built=use_gloo, mpi_is_built=use_mpi):
                            with pytest.raises(Exception, match=expected):
",2
"                                horovod.spark.run(fn, start_timeout=10, use_mpi=use_mpi, use_gloo=use_gloo, verbose=2)

    """"""
    Performs an actual horovod.spark.run test using MPI or Gloo.
    """"""
",2
"            self._do_test_spark_run_with_gloo(args, kwargs, num_proc, extra_mpi_args, env,
                                              stdout, stderr, verbose, cores,
                                              expected_np)

",2
"            raise Exception('Test Exception')

        with mock.patch(""horovod.run.mpi_run._get_mpi_implementation_flags"", side_effect=mpi_impl_flags):
",2
"                            horovod.spark.run(fn, args=args, kwargs=kwargs,
                                              num_proc=num_proc, start_timeout=10,
                                              use_mpi=True, use_gloo=False,
                                              extra_mpi_args=extra_mpi_args, env=env,
                                              stdout=stdout, stderr=stderr, verbose=verbose)
",2
"                expected_command = ('mpirun '
                                    '--allow-run-as-root --tag-output '
                                    '-np {expected_np} -H [^ ]+ '
",2
"                                    '{binding_args} '
                                    '{mpi_flags}  '
                                    '-mca btl_tcp_if_include [^ ]+ -x NCCL_SOCKET_IFNAME=[^ ]+  '
                                    '{expected_env} '
                                    '{extra_mpi_args} '
",2
"        actual_rsh_settings = codec.loads_base64(serialized_rsh_settings)
        self.assertIsNone(actual_rsh_settings.key)

        # for better comparison replace sections in actual_command that change across runs / hosts
",2
"    """"""
    def _do_test_spark_run_with_gloo(self, args=(), kwargs={}, num_proc=1, extra_mpi_args=None,
                                     env=None, stdout=None, stderr=None, verbose=2,
                                     cores=2, expected_np=1):
",2
"        with mock.patch(""horovod.spark.gloo_run._exec_command_fn"", side_effect=gloo_exec_command_fn):
            with spark_session('test_spark_run', cores=cores):
                with is_built(gloo_is_built=True, mpi_is_built=False):
                    # we make the run fail just after we caught our mocked method calls
",2
"                         'Spark timed out before mpi_run was called, test setup is broken.')
",2
"            self.assertEqual(num_proc, alloc_info.local_size)
            self.assertEqual(alloc_info.local_rank, alloc_info.rank)
",2
"
            # command fully derived from alloc_info
",2
"                                'NCCL_SOCKET_IFNAME=[^ ]+ '
                                '[^ ]+python[0-9.]* -m horovod.spark.task.gloo_exec_fn '
                                '[^ ]+ [^ ]+$'.format(rank=alloc_info.rank,
                                                      size=alloc_info.size,
                                                      local_rank=alloc_info.local_rank,
",2
"                                                      local_size=alloc_info.local_size,
                                                      np=num_proc))

            actual_command = call_args[0][0]
",2
"
    def test_rsh_events(self):
        self.do_test_rsh_events(3)

",2
"            start = time.time()
",2
"
                def reset():
",2
"                    # ingest tmp_path into workers PYTHONPATH
                    test_horovod_python_path = ['horovod', 'horovod/python']
                    test_env['HOROVOD_SPARK_PYTHONPATH'] = os.pathsep.join(test_horovod_python_path)

                with override_env(test_env):
",2
"                        with mock.patch('horovod.spark.task.mpirun_exec_fn.task_exec') as task_exec:
                            msg = 'work_dir_env_set={} python_path_is_set={} hvd_python_path_is_set={}'\
                                .format(work_dir_env_set, python_path_is_set, hvd_python_path_is_set)
",2
"                            print('testing with {}'.format(msg))
",2
"                            if hvd_python_path_is_set:
                                expected_python_path = test_horovod_python_path
                            if python_path_is_set:
                                expected_python_path = expected_python_path + test_python_path
                            if 'PYTHONPATH' in os.environ:
",2
"                                                    test_horovod_python_path + \
                                                    expected_sys_path[1:]
                            self.assertEqual(expected_sys_path, sys.path, msg)

                            task_exec.assert_called_once()
",2
"        settings.verbose = 2
",2
"            task_exec_args, task_exec_kwargs = task_exec.call_args
",2
"        util._training_cache.get_dataset = mock.Mock(side_effect=util._training_cache.get_dataset)

",2
"        with spark_session('test_df_cache') as spark:
            with local_store() as store:
",2
"                # All keys are distinct
                assert key != key2
                assert key != key3
                assert key2 != key3

",2
"                assert not util._training_cache.is_cached(key3, store)

",2
"                    assert train_rows == train_rows1
",2
"
",2
"                0,
                0.0,
                None,
                [1, 1],
",2
"            all_col_types, col_shapes, col_max_sizes = util._get_col_info(df)
",2
"
            # Only check validation ratio, as we can't rely on random splitting to produce an exact
            # result of 4 training and 1 validation samples.
",2
"            ]
            schema = StructType([StructField('data', FloatType()), StructField('val', IntegerType())])
",2
"            df = create_test_data_from_schema(spark, data, schema)

            validation = 'val'
",2
"            data = [
                [1.0, False], [1.0, False], [1.0, False], [1.0, False], [1.0, True]
            ]
",2
"            {
                'float': {
                    'spark_data_type': FloatType,
                    'is_sparse_vector_only': False,
",2
"                    'intermediate_format': constants.ARRAY,
                    'max_size': 2,
                    'shape': 2
                },
                'sparse': {
",2
"                'mixed': {
                    'spark_data_type': DenseVector,
                    'is_sparse_vector_only': False,
                    'intermediate_format': constants.ARRAY,
",2
"                    'shape': 2
",2
"                },
            }

",2
"            ])
            df = create_test_data_from_schema(spark, data, schema)
",2
"                'sparse': {
                    'spark_data_type': DenseVector,
",2
"            with spark_session('test_prepare_data') as spark:
                data = [[
                    0.0,
",2
"                    SparseVector(2, {1: 1.0}),
                    SparseVector(2, {1: 1.0})
",2
"                'sparse': {
                    'spark_data_type': SparseVector,
",2
"                    'shape': 2
                },
                'mixed': {
",2
"                    SparseVector(2, {1: 1.0}),
                    DenseVector([1.0, 1.0])
                ], [
                    1.0,
",2
"                    SparseVector(2, {1: 1.0}),
                    SparseVector(2, {1: 1.0})
                ]]
",2
"                    StructField('dense', VectorUDT()),
                    StructField('sparse', VectorUDT()),
",2
"                with local_store() as store:
                    with util.prepare_data(num_processes=2,
                                           store=store,
",2
"                                           label_columns=['float'],
                                           compress_sparse=True) as dataset_idx:
                        mock_get_metadata.assert_called()
                        assert dataset_idx == 0

",2
"        label_columns = ['y1', 'y_embedding']

        schema = StructType([StructField('x1', DoubleType()),
                             StructField('x2', IntegerType()),
                             StructField('features', VectorUDT()),
",2
"                             StructField('y1', FloatType()),
                             StructField('y_embedding', VectorUDT())])
        data = [[1.0, 1, DenseVector([1.0] * 12), 1.0, DenseVector([1.0] * 12)]] * 10
",2
"                util.check_shape_compatibility(metadata, feature_columns, label_columns,
",2
"                                               input_shapes, output_shapes)

                bad_input_shapes = [[1], [1], [-1, 3, 5]]
                with pytest.raises(ValueError):
",2
"
    @mock.patch('horovod.spark.common.store.HDFSStore._get_filesystem_fn')
    def test_hdfs_store_parse_url(self, mock_get_filesystem_fn):
        # Case 1: full path
        hdfs_root = 'hdfs://namenode01:8020/user/test/output'
",2
"        assert store._hdfs_kwargs['host'] == 'namenode01', hdfs_root
        assert store._hdfs_kwargs['port'] == 8020, hdfs_root

",2
"        # Case 2: no host and port
",2
"        hdfs_root = 'hdfs:///user/test/output'
        store = HDFSStore(hdfs_root)
        assert store.path_prefix() == 'hdfs://', hdfs_root
",2
"
        # Case 6: override paths, no prefix
        hdfs_root = '/user/prefix'
        store = HDFSStore(hdfs_root,
",2
"        assert store.get_test_data_path() == 'hdfs:///user/test_path', hdfs_root

    def test_spark_task_service_env(self):
        key = secret.make_secret_key()
",2
"            'HADOOP_TOKEN_FILE_LOCATION': 'path',
",2
"                    ]
                    self.assertEqual(expected, env)

    @pytest.mark.skipif(LooseVersion(pyspark.__version__) < LooseVersion('3.0.0'),
                        reason='get_available_devices only supported in Spark 3.0 and above')
",2
"    def test_get_available_devices(self):
",2
"        def fn():
",2
"            return devices, hvd.local_rank()

",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",2
"import warnings

import pytest
",2
"
from horovod.run.common.service.task_service import BasicTaskClient, BasicTaskService
from horovod.run.common.util import network, secret
from horovod.run.util.threads import in_thread

",2
"                                              service_addresses,
                                              key,
                                              verbose=2,
",2
"        time.sleep(sleep / 2.0)
        service.shutdown()
        duration = time.time() - start
",2
"        key = secret.make_secret_key()
        service_name = 'test-service'
        service = BasicTaskService(service_name, key, nics=None, verbose=2)
",2
"        warnings.simplefilter('module')

    def test_gloo_built(self):
        """"""Test that Gloo has been built if env is set.""""""
        gloo_rank = int(os.getenv('HOROVOD_RANK', -1))
",2
"            self.assertTrue(gloo_built())
",2
"        try:
            self.assertTrue(available)
        except:
",2
"
    def test_mxnet_available(self):
        """"""Test that MXNet support has been built.""""""
        available = extension_available('mxnet')
",2
"#
",2
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",2
"# ==============================================================================

",2
"import platform
import stat

from pyspark.ml import Pipeline
from pyspark.ml.feature import VectorAssembler
",2
"from common import tempdir, temppath

# Spark will fail to initialize correctly locally on Mac OS without this
if platform.system() == 'Darwin':
    os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'
",2
"    conf = SparkConf().setAppName(app).setMaster(master)

    with temppath() as temp_filename:
        if gpus > 0:
",2
"            .config(conf=conf) \
            .getOrCreate()

",2
"                         StructField('label_vec', VectorUDT()),
                         StructField('label', FloatType())])
    df = create_test_data_from_schema(spark, data, schema)
    return df

",2
"
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"        bcoeff = 1.0 - dotProduct / bnormsq * 0.5
    answer = acoeff * a + bcoeff * b
    return answer

",2
"def reference_tree_reduction(tensors, hvd_size):
",2
"class MPITests(tf.test.TestCase):
    """"""
    Tests for ops in horovod.tensorflow.
",2
"    """"""
    def __init__(self, *args, **kwargs):
        super(MPITests, self).__init__(*args, **kwargs)
",2
"        warnings.simplefilter('module')
        if _has_eager:
",2
"        hvd.init()
        # TODO support non-MPI Adasum operation
        if not hvd.mpi_enabled():
",2
"            self.skipTest(""MPI not enabled"")

        size = hvd.size()
        # TODO support testing with non-power 2 ranks
        if not is_power2(size):
",2
"                tensors = map(tf.constant, rank_tensors[rank])
                # cast to the corresponding dtype
                tensors = map(lambda tensor: tf.cast(tensor, dtype), tensors)
                # and away we go: do reduction
                reduced_tensors = [
",2
"                    self.evaluate(hvd.allreduce(tensor, op=hvd.Adasum))
                    for tensor in tensors
                ]
",2
"            self.skipTest(""MPI rank is not power of 2"")

        local_size = hvd.local_size()
",2
"
        # Only run on homogeneous cluster
        if not hvd.is_homogeneous():
            self.skipTest(""Horovod cluster is not homogeneous"")
",2
"        for dtype in [tf.float16, tf.float32, tf.float64]:
            with tf.device(""/gpu:{}"".format(hvd.local_rank())):
                tensors = map(tf.constant, rank_tensors[rank])
                # cast to the corresponding dtype
                tensors = map(lambda tensor: tf.cast(tensor, dtype), tensors)
",2
"                # and away we go: do reduction
",2
"# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.
",2
"    Tests for .buildkite directory
    """"""

    def __init__(self, *args, **kwargs):
",2
"    
    Then run `git diff` to see the changes in the generated pipeline YAML.
    Commit `test/data/expected_buildkite_pipeline.yaml` to get those changes into your PR.
    """"""
    def test_gen_pipeline(self):
",2
"#
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"
from horovod.run.common.util import config_parser
from horovod.run.runner import parse_args, _run_elastic
",2
"    elif not start and not end:
        return 'elif [ ""$epoch"" == ""{}"" ]; then'.format(epoch) + os.linesep + hosts_str + os.linesep
",2
"

",2
"            f.write(DISCOVERY_SCRIPT_TEMPLATE.format(logfile=logfile) + os.linesep)
            for i, schedule_step in enumerate(discovery_schedule):
                f.write(_get_discovery_lines(schedule_step,
                                             start=i == 0,
",2
"
class BaseElasticTests(object):
    def __init__(self, training_script, *args, **kwargs):
        self._training_script = training_script
        super(BaseElasticTests, self).__init__(*args, **kwargs)
",2
"                    config_parser.set_env_from_args(env, args)
                    _run_elastic(args)

                    with open(logfile, 'r') as f:
                        lines = f.readlines()
",2
"
                    return [json.loads(line) for line in lines]

    @mock.patch('horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)
",2
"            discovery_schedule = [
",2
"            results = self._run(discovery_schedule, np=np, min_np=min_np, max_np=max_np)
            for result in results:
                print(result)

",2
"            assert results[1]['size'] == 2
            assert results[1]['rendezvous'] == 2

            assert results[2]['start_rank'] == 2
",2
"    @mock.patch('horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)
    @mock.patch('horovod.run.gloo_run._get_min_start_hosts', return_value=1)
    def test_fault_tolerance_without_scaling(self, mock_get_min_start_hosts):
        for exit_mode in ['exception', 'kill']:
",2
"
            exit_schedule = {
",2
"
            assert results[1]['start_rank'] == 2
            assert results[1]['size'] == 2
            assert results[1]['rendezvous'] == 2

",2
"            assert results[2]['rendezvous'] == 2

    @mock.patch('horovod.run.elastic.driver.DISCOVER_HOSTS_FREQUENCY_SECS', 0.01)
    @mock.patch('horovod.run.gloo_run._get_min_start_hosts', return_value=1)
",2
"    def test_all_ranks_failure(self, mock_get_min_start_hosts):
        discovery_schedule = [
            (None, ['localhost:2', '127.0.0.1:2']),
        ]
",2
"    @mock.patch('horovod.run.gloo_run._get_min_start_hosts', return_value=1)
    def test_min_hosts_timeout(self, mock_get_min_start_hosts):
",2
"        }
",2
"        with pytest.raises(RuntimeError, match=message):
",2
"# You may obtain a copy of the License at
",2
"
from elastic_common import BaseElasticTests


",2
"        warnings.simplefilter('module')
# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.
",2
"import os
import unittest
",2
"import os
import unittest
import warnings

from elastic_common import BaseElasticTests
",2
"import psutil
",2
"
parser.add_argument('--batches-per-epoch', type=int, default=10,
",2
"                    help='number of batches per epoch')
parser.add_argument('--batches-per-commit', type=int, default=1,
",2
"parser.add_argument('--logfile', default='/tmp/logfile.txt',
                    help='log file to record results (one line per epoch)')
parser.add_argument('--discovery-schedule', default='[]',
",2
"                    help='means used to cause a worker to exit [exception | kill]')

args = parser.parse_args()
",2
"lr = 0.001
model = torch.nn.Sequential(torch.nn.Linear(2, 2))
",2
"exit_schedule = json.loads(args.exit_schedule) if args.exit_schedule else {}
",2
"
def check_exit(epoch, batch):
",2
"    key = str((epoch, batch))
    if key in exit_schedule:
        ranks_to_exit = exit_schedule[key]
        if start_rank in ranks_to_exit:
            if args.exit_mode == 'exception':
",2
"        'epoch': state.epoch,
        'batch': state.batch,
        'commits': state.commits,
        'hostname': hostname,
        'start_rank': start_rank,
",2
"        'rank': hvd.rank(),
",2
"
@hvd.elastic.run
def train(state):
",2
"                start = int(time.time())
                while state._host_messages.empty():
                    if int(time.time()) - start > 3:
                        raise TimeoutError('Timed out waiting for notifications from driver.')
",2
"        state.batch = 0
        state.commits += 1
        state.commit()

",2
"
def on_state_reset():
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr * hvd.size()
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"import time

import tensorflow as tf

",2
"
parser.add_argument('--batches-per-epoch', type=int, default=10,
                    help='number of batches per epoch')
parser.add_argument('--batches-per-commit', type=int, default=1,
                    help='number of batches per commit of the elastic state object')
",2
"indices = tf.random.uniform([batch_size], minval=0, maxval=2, dtype=tf.int64)
target = tf.one_hot(indices, 2)

",2
"
discovery_schedule = json.loads(args.discovery_schedule)
epoch_to_hosts = {epoch: hosts for epoch, hosts in discovery_schedule if epoch is not None}
",2
"        probs = model(data, training=True)
        loss = tf.losses.categorical_crossentropy(target, probs)
",2
"state.register_reset_callbacks([on_state_reset])
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"import os
import psutil
import time

",2
"
hostname = os.environ.get('HOROVOD_HOSTNAME')
",2
"
    train_opt = optimizer.minimize(loss)
    train(state, lambda: session.run(train_opt))
""""""
",2
"import time

from horovod.run.common.util import safe_shell_exec

",2
"
class FakeEvent(object):
    def wait(self):
",2
"        time.sleep(999)


def write(filename, value):
    filename_tmp = filename + '.tmp'
",2
"        f.write(str(value))
",2
"    os.rename(filename_tmp, filename)

",2
"
# The data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

",2
"                 activation='relu',
",2
"model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
",2
"
# Horovod: add Horovod Distributed Optimizer.
opt = hvd.DistributedOptimizer(opt)

model.compile(loss=keras.losses.categorical_crossentropy,
",2
"    hvd.callbacks.BroadcastGlobalVariablesCallback(0),
",2
"    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))

model.fit(x_train, y_train,
",2
"# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the ""Software""), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
",2
"parser.add_argument('--data-nthreads', type=int, default=2,
                    help='number of threads for data decoding (default: 2)')
parser.add_argument('--rec-train', type=str, default='',
                    help='the training data')
",2
"                    help='the index of training data')
parser.add_argument('--rec-val', type=str, default='',
                    help='the validation data')
parser.add_argument('--rec-val-idx', type=str, default='',
                    help='the index of validation data')
",2
"                    help='data type for training (default: float32)')
",2
"parser.add_argument('--eval-epoch', action='store_true', default=False,
                    help='evaluate validation accuracy after each epoch \
                    when training in module mode (default: False)')
",2
"hvd.init()
num_workers = hvd.size()
",2
"        warmup_begin_lr=args.warmup_lr
    )
elif args.lr_mode == 'cosine':
",2
"# https://mxnet.incubator.apache.org/tutorials/basic/data.html?highlight=imagerecorditer
def get_data_rec(rec_train, rec_train_idx, rec_val, rec_val_idx, batch_size,
                 data_nthreads):
    rec_train = os.path.expanduser(rec_train)
    rec_train_idx = os.path.expanduser(rec_train_idx)
",2
"        rand_crop=False,
        random_resized_crop=True,
",2
"        max_aspect_ratio=4. / 3.,
        min_aspect_ratio=3. / 4.,
",2
"        shuffle=False,
        batch_size=batch_size,
        resize=256,
        label_width=1,
",2
"        data_shape=(3, 224, 224),
        mean_r=mean_rgb[0],
",2
"# Create data iterator for synthetic data
class SyntheticDataIter(DataIter):
",2
"    def __init__(self, num_classes, data_shape, max_iter, dtype, ctx):
        self.batch_size = data_shape[0]
        self.cur_iter = 0
        self.max_iter = max_iter
        self.dtype = dtype
",2
"                                 ctx=ctx)

",2
"        return [mx.io.DataDesc('data', self.data.shape, self.dtype)]
",2
"
if args.use_rec:
    # Fetch training and validation data if present
    train_data, val_data = get_data_rec(args.rec_train,
                                        args.rec_train_idx,
",2
"kwargs = {'ctx': context,
          'pretrained': args.use_pretrained,
",2
"          'classes': num_classes}
if args.last_gamma:
    kwargs['last_gamma'] = True
net = get_model(args.model, **kwargs)
net.cast(args.dtype)
",2
"                             magnitude=2)


",2
"    if params is not None:
",2
"            data, label = get_data_label(batch, context)
",2
"
        # Report metrics
        elapsed = time.time() - tic
        _, acc = metric.get()
",2
"
        # Evaluate performance
",2
"        if args.eval_frequency and (epoch + 1) % args.eval_frequency == 0:
",2
"            arg_params[x.name] = x.data()
    else:
        arg_params = None
    aux_params = None
    mod.bind(data_shapes=train_data.provide_data,
",2
"        epoch_callback = mx.callback.do_checkpoint(
            '%s-%d' % (args.model, rank),
            period=args.save_frequency)

",2
"            eval_data=eval_data,
            num_epoch=args.num_epochs,
",2
"                         args.num_epochs - 1, rank, name, val)

",2
"import os
import errno
import numpy as np
",2
"

def cnn_model_fn(features, labels, mode):
    """"""Model function for CNN.""""""
",2
"    # Input Layer
    # Reshape X to 4-D tensor: [batch_size, width, height, channels]
    # MNIST images are 28x28 pixels, and have one color channel
",2
"    input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])

",2
"    # Convolutional Layer #1
    # Computes 32 features using a 5x5 filter with ReLU activation.
    # Padding is added to preserve width and height.
    # Input Tensor Shape: [batch_size, 28, 28, 1]
    # Output Tensor Shape: [batch_size, 28, 28, 32]
",2
"    # Input Tensor Shape: [batch_size, 28, 28, 32]
    # Output Tensor Shape: [batch_size, 14, 14, 32]
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

    # Convolutional Layer #2
",2
"    # Padding is added to preserve width and height.
    # Input Tensor Shape: [batch_size, 14, 14, 32]
",2
"        padding=""same"",
",2
"
    # Dense Layer
    # Densely connected layer with 1024 neurons
    # Input Tensor Shape: [batch_size, 7 * 7 * 64]
    # Output Tensor Shape: [batch_size, 1024]
",2
"        # Horovod: scale learning rate by the number of workers.
        optimizer = tf.train.MomentumOptimizer(
            learning_rate=0.001 * hvd.size(), momentum=0.9)
",2
"        optimizer = hvd.DistributedOptimizer(optimizer)

",2
"        train_op = optimizer.minimize(
            loss=loss,
",2
"
    # Keras automatically creates a cache directory in ~/.keras/datasets for
    # storing the downloaded MNIST data. This creates a race
",2
"        try:
            os.mkdir(cache_dir)
        except OSError as e:
",2
"            else:
                raise

",2
"    # Download and load MNIST dataset.
    (train_data, train_labels), (eval_data, eval_labels) = \
        keras.datasets.mnist.load_data('MNIST-data-%d' % hvd.rank())
",2
"    config.gpu_options.allow_growth = True
    config.gpu_options.visible_device_list = str(hvd.local_rank())
",2
"
    # Horovod: save checkpoints only on worker 0 to prevent other workers from
",2
"
",2
"    # Create the Estimator
    mnist_classifier = tf.estimator.Estimator(
",2
"    # Set up logging for predictions
    # Log the values in the ""Softmax"" tensor with label ""probabilities""
    tensors_to_log = {""probabilities"": ""softmax_tensor""}
",2
"    bcast_hook = hvd.BroadcastGlobalVariablesHook(0)

    # Train the model
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": train_data},
",2
"        y=train_labels,
        batch_size=100,
",2
"import torch.nn as nn
",2
"parser.add_argument('--momentum', type=float, default=0.5, metavar='M',
",2
"                    help='random seed (default: 42)')
",2
"        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
",2
"    # Horovod: print output only on first rank.
    if hvd.rank() == 0:
",2
"            test_loss, 100. * test_accuracy))


",2
"    # When supported, use 'forkserver' to spawn dataloader workers instead of 'fork' to prevent
    # issues with Infiniband implementations that are not fork-safe
",2
"    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,
                                              sampler=test_sampler, **kwargs)

    model = Net()
",2
"    lr_scaler = hvd.size() if not args.use_adasum else 1

    if args.cuda:
        # Move model to GPU.
",2
"        train(epoch)
        test()
import torch
import argparse
import torch.backends.cudnn as cudnn
",2
"from torchvision import datasets, transforms, models
import horovod.torch as hvd
import os
",2
"# Default settings from https://arxiv.org/abs/1706.02677.
parser.add_argument('--batch-size', type=int, default=32,
                    help='input batch size for training')
parser.add_argument('--val-batch-size', type=int, default=32,
",2
"                    help='learning rate for a single GPU')
parser.add_argument('--warmup-epochs', type=float, default=5,
",2
"
",2
"parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
",2
"    model.train()
    train_sampler.set_epoch(epoch)
    train_loss = Metric('train_loss')
    train_accuracy = Metric('train_accuracy')
",2
"            # Split data into sub-batches of size batch_size
            for i in range(0, len(data), args.batch_size):
                data_batch = data[i:i + args.batch_size]
                target_batch = target[i:i + args.batch_size]
",2
"                output = model(data_batch)
                train_accuracy.update(accuracy(output, target_batch))
                loss = F.cross_entropy(output, target_batch)
",2
"                train_loss.update(loss)
",2
"def validate(epoch):
",2
"        with torch.no_grad():
            for data, target in val_loader:
",2
"# accuracy. Scale the learning rate `lr = base_lr` ---> `lr = base_lr * hvd.size()` during
# the first five epochs. See https://arxiv.org/abs/1706.02677 for details.
# After the warmup reduce learning rate by 10 on the 30th, 60th and 80th epochs.
def adjust_learning_rate(epoch, batch_idx):
",2
"    if epoch < args.warmup_epochs:
        epoch += float(batch_idx + 1) / len(train_loader)
",2
"        }
        torch.save(state, filepath)


",2
"        self.n = torch.tensor(0.)

    def update(self, val):
        self.sum += hvd.allreduce(val.detach().cpu(), name=self.name)
        self.n += 1
",2
"
    @property
    def avg(self):
        return self.sum / self.n

",2
"                                      name='resume_from_epoch').item()

    # Horovod: print logs on the first worker.
",2
"                                 transforms.RandomResizedCrop(224),
                                 transforms.RandomHorizontalFlip(),
",2
"        sampler=train_sampler, **kwargs)
",2
"    # By default, Adasum doesn't need scaling up learning rate.
    # For sum/average with gradient Accumulation: scale learning rate by batches_per_allreduce
",2
"    if args.cuda:
        # Move model to GPU.
        model.cuda()
        # If using GPU Adasum allreduce, scale learning rate by local_size.
        if args.use_adasum and hvd.nccl_built():
",2
"            lr_scaler = args.batches_per_allreduce * hvd.local_size()

    # Horovod: scale learning rate by the number of GPUs.
    optimizer = optim.SGD(model.parameters(),
",2
"                          lr=(args.base_lr *
                              lr_scaler),
                          momentum=args.momentum, weight_decay=args.wd)
",2
"    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none

    # Horovod: wrap optimizer with DistributedOptimizer.
",2
"        backward_passes_per_step=args.batches_per_allreduce,
        op=hvd.Adasum if args.use_adasum else hvd.Average)

",2
"import numpy as np
import timeit

import tensorflow as tf
",2
"
parser.add_argument('--model', type=str, default='ResNet50',
                    help='model to benchmark')
parser.add_argument('--batch-size', type=int, default=32,
",2
"                    help='input batch size')

parser.add_argument('--num-warmup-batches', type=int, default=10,
",2
"                    help='number of warm-up batches that don\'t count towards benchmark')
parser.add_argument('--num-batches-per-iter', type=int, default=10,
                    help='number of batches per benchmark iteration')
",2
"    gpus = tf.config.experimental.list_physical_devices('GPU')
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
    if gpus:
",2
"        tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')
else:
    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""

# Set up standard model.
",2
"
    gradients = tape.gradient(loss, model.trainable_variables)
    opt.apply_gradients(zip(gradients, model.trainable_variables))
",2
"    log('Running warmup...')
    benchmark_step(first_batch=True)
",2
"parser.add_argument('--batch-size', type=int, default=128,
                    help='input batch size for training')
parser.add_argument('--epochs', type=int, default=12,
",2
"    elif args.num_proc:
        conf.setMaster('local[{}]'.format(args.num_proc))
    spark = SparkSession.builder.config(conf=conf).getOrCreate()

    # Setup our store for intermediate data
",2
"            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
            self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
",2
"    model = Net()
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
    loss = nn.NLLLoss()

",2
"
import tensorflow as tf
import horovod.tensorflow.keras as hvd

",2
"# Horovod: initialize Horovod.
hvd.init()

# Horovod: pin GPU to be used to process local rank (one GPU per process)
",2
"opt = hvd.DistributedOptimizer(opt)
",2
"callbacks = [
    # Horovod: broadcast initial variable states from rank 0 to all other processes.
    # This is necessary to ensure consistent initialization of all workers when
    # training is started with random weights or restored from a checkpoint.
    hvd.callbacks.BroadcastGlobalVariablesCallback(0),
",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"    h_fc1 = layers.dropout(
        layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu),
        rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)
",2
"

",2
"            index += batch_size


def main(_):
",2
"            os.mkdir(cache_dir)
        except OSError as e:
            if e.errno == errno.EEXIST and os.path.isdir(cache_dir):
",2
"                pass
            else:
                raise

    # Download and load MNIST dataset.
",2
"    x_test = np.reshape(x_test, (-1, 784)) / 255.0

    # Build model...
    with tf.name_scope('input'):
",2
"
    lr_scaler = hvd.size()
    # By default, Adasum doesn't need scaling when increasing batch size. If used with NCCL,
    # scale lr by local_size
    if args.use_adasum:
",2
"    # Horovod: add Horovod Distributed Optimizer.
    opt = hvd.DistributedOptimizer(opt, op=hvd.Adasum if args.use_adasum else hvd.Average)
",2
"    hooks = [
        # Horovod: BroadcastGlobalVariablesHook broadcasts initial variable states
        # from rank 0 to all other processes. This is necessary to ensure consistent
",2
"
        tf.train.LoggingTensorHook(tensors={'step': global_step, 'loss': loss},
                                   every_n_iter=10),
    ]

",2
"    # Horovod: pin GPU to be used to process local rank (one GPU per process)
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    config.gpu_options.visible_device_list = str(hvd.local_rank())
",2
"import horovod.tensorflow as hvd
from tensorflow.keras import applications

# Benchmark settings
",2
"
parser.add_argument('--model', type=str, default='ResNet50',
                    help='model to benchmark')
parser.add_argument('--batch-size', type=int, default=32,
",2
"parser.add_argument('--use-adasum', action='store_true', default=False,
                    help='use adasum algorithm to do reduction')

args = parser.parse_args()
",2
"else:
    os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
    config.gpu_options.allow_growth = False
",2
"    config.gpu_options.visible_device_list = ''

",2
"opt = hvd.DistributedOptimizer(opt, compression=compression, op=hvd.Adasum if args.use_adasum else hvd.Average)

init = tf.global_variables_initializer()
",2
"log('Batch size: %d' % args.batch_size)
device = 'GPU' if args.cuda else 'CPU'
",2
"        run(lambda: session.run(train_opt))
import argparse
import os
import subprocess
from distutils.version import LooseVersion
",2
"parser.add_argument('--work-dir', default='/tmp',
                    help='temporary working directory to write intermediate files (prefix with hdfs:// to use HDFS)')
",2
"        conf.setMaster(args.master)
    elif args.num_proc:
        conf.setMaster('local[{}]'.format(args.num_proc))
    spark = SparkSession.builder.config(conf=conf).getOrCreate()

",2
"    encoder = OneHotEncoderEstimator(inputCols=['label'],
                                     outputCols=['label_vec'],
                                     dropLast=False)
    model = encoder.fit(df)
",2
"    model.add(Conv2D(32, kernel_size=(3, 3),
",2
"    optimizer = keras.optimizers.Adadelta(1.0)
    loss = keras.losses.categorical_crossentropy

    # Train a Horovod Spark Estimator on the DataFrame
    keras_estimator = hvd.KerasEstimator(num_proc=args.num_proc,
",2
"    np.random.seed(1 + hvd.rank())
    torch.manual_seed(1234)

    prev_zero = False

",2
"    train(args)# Copyright 2017 onwards, fast.ai, Inc.
# Modifications copyright (C) 2019 Uber Technologies, Inc.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"import pyspark.sql.types as T
import pyspark.sql.functions as F
from pyspark import SparkConf, Row
from pyspark.sql import SparkSession
",2
"import tensorflow as tf
import tensorflow.keras.backend as K
",2
"
",2
"            .withColumn('State', F.when(google_trend_all.State == 'NI', 'HB,NI').otherwise(google_trend_all.State))

        # Expand dates.
        return expand_date(google_trend_all)
",2
"
",2
"
    def add_elapsed(df, cols):
        def add_elapsed_column(col, asc):
            def fn(rows):
                last_store, last_date = None, None
",2
"        # Merge in Google Trend information.
        google_trend_all = prepare_google_trend()
        df = df.join(google_trend_all, ['State', 'Year', 'Week']).select(df['*'], google_trend_all.trend)

        # Merge in Google Trend for whole Germany.
",2
"        google_trend_de = google_trend_all[google_trend_all.file == 'Rossmann_DE']
        google_trend_de = google_trend_de.withColumnRenamed('trend', 'trend_de')
",2
"        df = df.withColumn('CompetitionDaysOpen',
                           F.when(df.CompetitionOpenSinceYear > 1900,
                                  F.greatest(F.lit(0), F.least(F.lit(360 * 2), F.datediff(df.Date, df.CompetitionOpenSince))))
",2
"                           .otherwise(0))
        df = df.withColumn('CompetitionMonthsOpen', (df.CompetitionDaysOpen / 30).cast(T.IntegerType()))
",2
"                           F.when(df.Promo2SinceYear > 1900,
",2
"        df = df.withColumn('Promo2Weeks', (df.Promo2Days / 7).cast(T.IntegerType()))

        # Check that we did not lose any rows through inner joins.
        assert num_rows == df.count(), 'lost rows in joins'
",2
"        vocab = {}
        for col in cols:
            values = [r[0] for r in df.select(col).distinct().collect()]
",2
"            col_type = type([x for x in values if x is not None][0])
            default_value = col_type()
            vocab[col] = sorted(values, key=lambda x: x or default_value)
",2
"
    if args.sample_rate:
        train_csv = train_csv.sample(withReplacement=False, fraction=args.sample_rate)
        test_csv = test_csv.sample(withReplacement=False, fraction=args.sample_rate)

",2
"    elapsed = add_elapsed(train_df.select('Date', 'Store', *elapsed_cols)
                          .unionAll(test_df.select('Date', 'Store', *elapsed_cols)),
                          elapsed_cols)

",2
"    print('Prepared data frame')
    print('===================')
    train_df.show()

    categorical_cols = [
",2
"        'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'Events', 'Promo',
        'StateHoliday', 'SchoolHoliday'
    ]
",2
"
",2
"    # Select features.
    train_df = train_df.select(*(all_cols + ['Sales', 'Date'])).cache()
    test_df = test_df.select(*(all_cols + ['Id', 'Date'])).cache()

    # Build vocabulary of categorical columns.
",2
"    # Determine max Sales number.
    max_sales = train_df.agg(F.max(train_df.Sales)).collect()[0][0]
",2
"    CUSTOM_OBJECTS = {'exp_rmspe': exp_rmspe,
                      'act_sigmoid_scaled': act_sigmoid_scaled}

    # Disable GPUs when building the model to prevent memory leaks
    if LooseVersion(tf.__version__) >= LooseVersion('2.0.0'):
",2
"        # See https://github.com/tensorflow/tensorflow/issues/33168
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
    else:
",2
"    continuous_bn = BatchNormalization()(continuous_bn)
",2
"    store = Store.create(args.work_dir)
    keras_estimator = hvd.KerasEstimator(num_proc=args.num_proc,
                                         store=store,
",2
"
",2
"    print('Best RMSPE: %f' % best_val_rmspe)

    # Save the trained model.
    keras_model.save(args.local_checkpoint_file)
",2
"    # FINAL PREDICTION #
    # ================ #

",2
"
",2
"import argparse
",2
"                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--train-dir', default=os.path.expanduser('~/imagenet/train'),
                    help='path to training data')
parser.add_argument('--val-dir', default=os.path.expanduser('~/imagenet/validation'),
                    help='path to validation data')
",2
"parser.add_argument('--checkpoint-format', default='./checkpoint-{epoch}.h5',
",2
"                    help='input batch size for training')
parser.add_argument('--val-batch-size', type=int, default=32,
                    help='input batch size for validation')
",2
"verbose = 1 if hvd.rank() == 0 else 0

# Training data iterator.
train_gen = image.ImageDataGenerator(
    width_shift_range=0.33, height_shift_range=0.33, zoom_range=0.5, horizontal_flip=True,
",2
"
# Horovod: adjust learning rate based on number of GPUs.
",2
"# Horovod: restore on the first worker which will broadcast both model and optimizer weights
",2
"        if type(layer) == keras.layers.BatchNormalization:
            layer_config['config']['momentum'] = 0.9
            layer_config['config']['epsilon'] = 1e-5

",2
"
callbacks = [
    # Horovod: broadcast initial variable states from rank 0 to all other processes.
    # This is necessary to ensure consistent initialization of all workers when
    # training is started with random weights or restored from a checkpoint.
",2
"    hvd.callbacks.MetricAverageCallback(),

    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final
    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during
",2
"
",2
"
# Horovod: save checkpoints only on the first worker to prevent other workers from corrupting them.
if hvd.rank() == 0:
    callbacks.append(keras.callbacks.ModelCheckpoint(args.checkpoint_format))
    callbacks.append(keras.callbacks.TensorBoard(args.log_dir))
",2
"
# Train the model. The training will randomly sample 1 / N batches of training data and
",2
"    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"for gpu in gpus:
",2
"])
",2
"import time
",2
"parser.add_argument('--lr', type=float, default=0.01,
                    help='learning rate (default: 0.01)')
",2
"    if not mx.test_utils.list_gpus():
        args.no_cuda = True

logging.basicConfig(level=logging.INFO)
",2
"    zip_file_path = download('http://data.mxnet.io/mxnet/data/mnist.zip',
",2
"    net = gluon.nn.HybridSequential()
    with net.name_scope():
        net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))
",2
"        net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))
        net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))
        net.add(gluon.nn.Flatten())
        net.add(gluon.nn.Dense(512, activation=""relu""))
",2
"        net.add(gluon.nn.Dense(10))
",2
"    return net


# Function to evaluate accuracy for a model
def evaluate(model, data_iter, context):
",2
"    data_iter.reset()
    metric = mx.metric.Accuracy()
    for _, batch in enumerate(data_iter):
",2
"optimizer_params = {'momentum': args.momentum,
                    'learning_rate': args.lr * hvd.size()}
opt = mx.optimizer.create('sgd', **optimizer_params)

",2
"loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()
metric = mx.metric.Accuracy()

",2
"    train_data.reset()
    metric.reset()
",2
"                         (epoch, nbatch, name, acc))

    if hvd.rank() == 0:
",2
"import torch.backends.cudnn as cudnn
",2
"                    help='input batch size')

parser.add_argument('--num-warmup-batches', type=int, default=10,
",2
"                    help='number of warm-up batches that don\'t count towards benchmark')
parser.add_argument('--num-batches-per-iter', type=int, default=10,
                    help='number of batches per benchmark iteration')
",2
"parser.add_argument('--num-iters', type=int, default=10,
",2
"                    help='disables CUDA training')

parser.add_argument('--use-adasum', action='store_true', default=False,
",2
"                    help='use adasum algorithm to do reduction')

args = parser.parse_args()
args.cuda = not args.no_cuda and torch.cuda.is_available()

",2
"if args.cuda:
    # Horovod: pin GPU to local rank.
    torch.cuda.set_device(hvd.local_rank())
",2
"device = 'GPU' if args.cuda else 'CPU'
log('Number of %ss: %d' % (device, hvd.size()))

",2
"    log('Iter #%d: %.1f img/sec per %s' % (x, img_sec, device))
    img_secs.append(img_sec)

# Results
",2
"# Copyright 2017 onwards, fast.ai, Inc.
# Modifications copyright (C) 2018 Uber Technologies, Inc.
#
",2
"import argparse
import datetime
",2
"from pyspark import SparkConf, Row
from pyspark.sql import SparkSession
",2
"parser.add_argument('--batch-size', type=int, default=100,
                    help='batch size')
parser.add_argument('--epochs', type=int, default=100,
                    help='number of epochs to train')
",2
"parser.add_argument('--data-dir', default='file://' + os.getcwd(),
                    help='location of data on local filesystem (prefixed with file://) or on HDFS')
parser.add_argument('--local-submission-csv', default='submission.csv',
                    help='output submission predictions CSV on local filesystem (without file:// prefix)')
",2
"parser.add_argument('--local-checkpoint-file', default='checkpoint.h5',
                    help='model checkpoint on local filesystem (without file:// prefix)')

",2
"            .withColumn('Week', F.weekofyear(df.Date)) \
            .withColumn('Day', F.dayofmonth(df.Date))


",2
"            def fn(rows):
                last_store, last_date = None, None
",2
"                for r in rows:
                    if last_store != r.Store:
                        last_store = r.Store
                        last_date = r.Date
",2
"                    fields[('After' if asc else 'Before') + col] = (r.Date - last_date).days
                    yield Row(**fields)
            return fn
",2
"
",2
"
        df = df \
            .withColumn('Open', df.Open != '0') \
            .withColumn('Promo', df.Promo != '0') \
",2
"            .withColumn('StateHoliday', df.StateHoliday != '0') \
            .withColumn('SchoolHoliday', df.SchoolHoliday != '0')

",2
"        google_trend_de = google_trend_all[google_trend_all.file == 'Rossmann_DE']
        df = df.join(google_trend_de, ['Year', 'Week']).select(df['*'], google_trend_all.trend.alias('trend_de'))

        # Merge in weather.
",2
"            .withColumn('CompetitionOpenSinceYear', F.coalesce(df.CompetitionOpenSinceYear, F.lit(1900))) \
",2
"            .withColumn('CompetitionOpenSinceMonth', F.coalesce(df.CompetitionOpenSinceMonth, F.lit(1))) \
            .withColumn('Promo2SinceYear', F.coalesce(df.Promo2SinceYear, F.lit(1900))) \
            .withColumn('Promo2SinceWeek', F.coalesce(df.Promo2SinceWeek, F.lit(1)))

",2
"        # Days & months competition was open, cap to 2 years.
        df = df.withColumn('CompetitionOpenSince',
                           F.to_date(F.format_string('%s-%s-15', df.CompetitionOpenSinceYear,
                                                     df.CompetitionOpenSinceMonth)))
",2
"                           F.when(df.Promo2SinceYear > 1900,
                                  F.greatest(F.lit(0), F.least(F.lit(25 * 7), F.datediff(df.Date, df.Promo2Since))))
                           .otherwise(0))
",2
"    train_df = train_df \
        .join(elapsed, ['Date', 'Store']) \
        .select(train_df['*'], *[prefix + col for prefix in ['Before', 'After'] for col in elapsed_cols])
",2
"        .join(elapsed, ['Date', 'Store']) \
        .select(test_df['*'], *[prefix + col for prefix in ['Before', 'After'] for col in elapsed_cols])

",2
"        'CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity',
        'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',
        'BeforePromo', 'AfterPromo', 'AfterStateHoliday', 'BeforeStateHoliday', 'BeforeSchoolHoliday', 'AfterSchoolHoliday'
",2
"                                     .unionAll(test_df.select(*categorical_cols)).cache(),
                             categorical_cols)

    # Cast continuous columns to float & lookup categorical columns.
",2
"    val_df = train_df.filter((test_min_date - a_year <= train_df.Date) & (train_df.Date < test_max_date - a_year))
    train_df = train_df.filter((train_df.Date < test_min_date - a_year) | (train_df.Date >= test_max_date - a_year))

",2
"    test_df.write.parquet('%s/test_df.parquet' % args.data_dir, mode='overwrite')

",2
"    print('Model training')
    print('==============')

",2
"    import horovod.tensorflow.keras as hvd

",2
"            model.save(f)
",2
"        bio = io.BytesIO(model_bytes)
        with h5py.File(bio) as f:
",2
"            return load_model_fn(f, custom_objects=CUSTOM_OBJECTS)


",2
"
        # Horovod: pin GPU to be used to process local rank (one GPU per process), if GPUs are available.
",2
"        K.set_value(model.optimizer.lr, scaled_lr)

        # Horovod: print summary logs on the first worker.
        verbose = 2 if hvd.rank() == 0 else 0
",2
"
            # Horovod: average metrics among workers at the end of every epoch.
",2
"            #
            # Note: This callback must be in the list before the ReduceLROnPlateau,
            # TensorBoard, or other metrics-based callbacks.
",2
"            hvd.callbacks.MetricAverageCallback(),

            # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final
            # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during
",2
"                # Convert readers to tf.data.Dataset.
                train_ds = make_petastorm_dataset(train_reader) \
                    .apply(tf.data.experimental.unbatch()) \
",2
"                    .apply(tf.data.experimental.unbatch()) \
                    .batch(args.batch_size) \
                    .map(lambda x: (tuple(getattr(x, col) for col in all_cols), tf.log(x.Sales)))

",2
"                                    verbose=verbose,
                                    epochs=args.epochs)

        # Dataset API usage currently displays a wall of errors upon termination.
        # This global model registration ensures clean termination.
",2
"    with open(args.local_checkpoint_file, 'wb') as f:
",2
"    # ================ #
    # FINAL PREDICTION #
    # ================ #

",2
"    spark = SparkSession.builder.config(conf=conf).getOrCreate()


    def predict_fn(model_bytes):
",2
"            import math
            import tensorflow as tf
            import tensorflow.keras.backend as K

",2
"        .rdd.mapPartitions(predict_fn(best_model_bytes)).toDF()
    submission_df = pred_df.select(pred_df.Id.cast(T.IntegerType()), pred_df.Sales).toPandas()
    submission_df.sort_values(by=['Id']).to_csv(args.local_submission_csv, index=False)
    print('Saved predictions to %s' % args.local_submission_csv)

",2
"    spark.stop()
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"    mnist_model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(16, [3, 3], activation='relu'),
        tf.keras.layers.Conv2D(16, [3, 3], activation='relu'),
        tf.keras.layers.GlobalAveragePooling2D(),
",2
"            dataset.take(20000 // hvd.size())):
        with tf.GradientTape() as tape:
            logits = mnist_model(images, training=True)
",2
"        # This is necessary to ensure consistent initialization of all workers when
        # training is started with random weights or restored from a checkpoint.
        if batch == 0:
            hvd.broadcast_variables(mnist_model.variables, root_rank=0)
            hvd.broadcast_variables(opt.variables(), root_rank=0)
",2
"    if hvd.rank() == 0:
        checkpoint.save(checkpoint_dir)


",2
"parser.add_argument('--batch-size', type=int, default=128, metavar='N',
",2
"hvd.init()
",2
"
batch_size = args.batch_size
num_classes = 10

# Enough epochs to demonstrate learning rate warmup and the reduction of
",2
"
if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
",2
"y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
",2
"model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=opt,
              metrics=['accuracy'])
",2
"    # This is necessary to ensure consistent initialization of all workers when
    # training is started with random weights or restored from a checkpoint.
    hvd.callbacks.BroadcastGlobalVariablesCallback(0),
",2
"
    # Horovod: average metrics among workers at the end of every epoch.
",2
"# Evaluate the model on the full data set.
score = model.evaluate(x_test, y_test, verbose=0)
",2
"print('Test loss:', score[0])
print('Test accuracy:', score[1])
import math
",2
"from tensorflow import keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
",2
"
# Horovod: pin GPU to be used to process local rank (one GPU per process)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list = str(hvd.local_rank())
",2
"
# Input image dimensions
img_rows, img_cols = 28, 28

",2
"(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
",2
"x_train /= 255
x_test /= 255
",2
"print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
",2
"model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
",2
"opt = hvd.DistributedOptimizer(opt)

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=opt,
              metrics=['accuracy'])
",2
"    # Horovod: broadcast initial variable states from rank 0 to all other processes.
    # This is necessary to ensure consistent initialization of all workers when
    # training is started with random weights or restored from a checkpoint.
    hvd.callbacks.BroadcastGlobalVariablesCallback(0),
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
# ==============================================================================

",2
"                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--processing-master',
                    help='spark cluster to use for light processing (data preparation & prediction).'
",2
"                         'supplying `-c <NUM_GPUS>` in Spark Standalone mode. Example: spark://hostname:7077')
parser.add_argument('--num-proc', type=int, default=4,
",2
"                    help='initial learning rate')
parser.add_argument('--batch-size', type=int, default=100,
                    help='batch size')
",2
"    GPU_INFERENCE_CLUSTER = 'local-cluster[2,1,1024]'  # or 'spark://hostname:7077'

    # ================ #
",2
"        conf.setMaster(args.processing_master)
    spark = SparkSession.builder.config(conf=conf).getOrCreate()

    train_csv = spark.read.csv('%s/train.csv' % args.data_dir, header=True)
    test_csv = spark.read.csv('%s/test.csv' % args.data_dir, header=True)
",2
"

    def prepare_google_trend():
        # Extract week start date and state.
",2
"

    def add_elapsed(df, cols):
",2
"                for r in rows:
                    if last_store != r.Store:
                        last_store = r.Store
",2
"                    if r[col]:
                        last_date = r.Date
",2
"        df = df.repartition(df.Store)
        for asc in [False, True]:
            sort_col = df.Date.asc() if asc else df.Date.desc()
            rdd = df.sortWithinPartitions(df.Store.asc(), sort_col).rdd
",2
"
        df = df \
            .withColumn('Open', df.Open != '0') \
            .withColumn('Promo', df.Promo != '0') \
            .withColumn('StateHoliday', df.StateHoliday != '0') \
",2
"        google_trend_all = prepare_google_trend()
",2
"                                                     df.CompetitionOpenSinceMonth)))
        df = df.withColumn('CompetitionDaysOpen',
",2
"    # Prepare data frames from CSV files.
    train_df = prepare_df(train_csv).cache()
    test_df = prepare_df(test_csv).cache()
",2
"    elapsed = add_elapsed(train_df.select('Date', 'Store', *elapsed_cols)
                                  .unionAll(test_df.select('Date', 'Store', *elapsed_cols)),
",2
"        'Store', 'State', 'DayOfWeek', 'Year', 'Month', 'Day', 'Week', 'CompetitionMonthsOpen', 'Promo2Weeks', 'StoreType',
        'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'Events', 'Promo',
",2
"        'CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity',
        'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',
",2
"        'BeforePromo', 'AfterPromo', 'AfterStateHoliday', 'BeforeStateHoliday', 'BeforeSchoolHoliday', 'AfterSchoolHoliday'
    ]

    all_cols = categorical_cols + continuous_cols
",2
"    test_df = lookup_columns(test_df, vocab)
",2
"
    # Split into training & validation.
",2
"    def exp_rmspe(y_true, y_pred):
        """"""Competition evaluation metric, expects logarithic inputs.""""""
",2
"    config = tf.ConfigProto(device_count={'GPU': 0})
    K.set_session(tf.Session(config=config))

",2
"    opt = hvd.DistributedOptimizer(opt)
    model.compile(opt, 'mae', metrics=[exp_rmspe])
",2
"        scaled_lr = K.get_value(model.optimizer.lr) * hvd.size()
        K.set_value(model.optimizer.lr, scaled_lr)

",2
"            # Horovod: average metrics among workers at the end of every epoch.
",2
"            #
            # Note: This callback must be in the list before the ReduceLROnPlateau,
            # TensorBoard, or other metrics-based callbacks.
",2
"        # Model checkpoint location.
        ckpt_dir = tempfile.mkdtemp()
        ckpt_file = os.path.join(ckpt_dir, 'checkpoint.h5')
        atexit.register(lambda: shutil.rmtree(ckpt_dir))

",2
"        if hvd.rank() == 0:
            callbacks.append(tf.keras.callbacks.ModelCheckpoint(ckpt_file, monitor='val_exp_rmspe', mode='min',
                                                                save_best_only=True))

",2
"                               cur_shard=hvd.rank(), shard_count=hvd.size(),
                               hdfs_driver=PETASTORM_HDFS_DRIVER) as train_reader:
            with make_batch_reader('%s/val_df.parquet' % args.data_dir, num_epochs=None,
",2
"
",2
"    best_val_rmspe = min(history['val_exp_rmspe'])
    print('Best RMSPE: %f' % best_val_rmspe)

",2
"
    # Create Spark session for prediction.
    conf = SparkConf().setAppName('prediction') \
",2
"    if GPU_INFERENCE_ENABLED:
        if GPU_INFERENCE_CLUSTER:
            conf.setMaster(GPU_INFERENCE_CLUSTER)
        conf = set_gpu_conf(conf)
    else:
",2
"            import tensorflow as tf
            import tensorflow.keras.backend as K
",2
"
",2
"            if GPU_INFERENCE_ENABLED:
                from pyspark import TaskContext
",2
"            # Restore from checkpoint.
            model = deserialize_model(model_bytes, tf.keras.models.load_model)
",2
"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
# Modifications copyright (C) 2017 Uber Technologies, Inc.
#
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"import zipfile

import numpy as np
",2
"

# Step 1: Download the data.
",2
"
def maybe_download(filename, expected_bytes):
",2
"        print(statinfo.st_size)
        raise Exception(
            'Failed to verify ' + url + '. Can you get to it with a browser?')
    return filename

",2
"    for word, _ in count:
        dictionary[word] = len(dictionary)
",2
"    data = list()
    unk_count = 0
    for word in words:
        if word in dictionary:
",2
"
data, count, dictionary, reverse_dictionary = build_dataset(vocabulary,
                                                            vocabulary_size)
",2
"del vocabulary  # Hint to reduce memory.
print('Most common words (+UNK)', count[:5])
print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])

",2
"# validation samples to the words that have a low numeric ID, which by
# construction are also the most frequent.
valid_size = 16     # Random set of words to evaluate similarity on.
valid_window = 100  # Only pick dev samples in the head of the distribution.
",2
"    # Compute the average NCE loss for the batch.
    # tf.nce_loss automatically draws a new sample of the negative labels each
    # time we evaluate the loss.
",2
"    # Compute the cosine similarity between minibatch examples and all embeddings.
",2
"    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))
",2
"num_steps = 100000 // hvd.size() + 1

",2
"    print('Initialized')

",2
"        # We perform one update step by evaluating the optimizer op (including it
        # in the list of returned values for session.run()
        _, loss_val = session.run([train_op, loss], feed_dict=feed_dict)
        average_loss += loss_val
",2
"        for i in range(valid_size):
",2
"            valid_word = reverse_dictionary[valid_examples[i]]
            top_k = 8  # number of nearest neighbors
            nearest = (-sim[i, :]).argsort()[1:top_k + 1]
            log_str = 'Nearest to %s:' % valid_word
",2
"epochs = 24
",2
"    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))

",2
"                    steps_per_epoch=500 // hvd.size(),
                    callbacks=callbacks,
",2
"
# Benchmark settings
",2
"                    help='model to benchmark')
",2
"parser.add_argument('--num-batches-per-iter', type=int, default=10,
                    help='number of batches per benchmark iteration')
",2
"                    help='number of batches per commit of the elastic state object')

parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')
",2
"if args.cuda:
    # Horovod: pin GPU to local rank.
    torch.cuda.set_device(hvd.local_rank())
",2
"        lr_scaler = hvd.local_size()

lr = 0.01
optimizer = optim.SGD(model.parameters(), lr=lr * lr_scaler())
",2
"# Horovod: (optional) compression algorithm.
compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none

# Horovod: wrap optimizer with DistributedOptimizer.
optimizer = hvd.DistributedOptimizer(optimizer,
",2
"hvd.broadcast_optimizer_state(optimizer, root_rank=0)

# Set up fixed fake data
data = torch.randn(args.batch_size, 3, 224, 224)
target = torch.LongTensor(args.batch_size).random_() % 1000
",2
"    data, target = data.cuda(), target.cuda()

",2
"def benchmark_step(state):
    optimizer.zero_grad()
    output = model(data)
    loss = F.cross_entropy(output, target)
    loss.backward()
",2
"        state.batch = 0
        state.commit()


def log(s, nl=True):
",2
"log('Model: %s' % args.model)
log('Batch size: %d' % args.batch_size)
device = 'GPU' if args.cuda else 'CPU'
",2
"def run_benchmark(state):
",2
"img_sec_mean = np.mean(state.img_secs)
img_sec_conf = 1.96 * np.std(state.img_secs)
log('Img/sec per %s: %.1f +-%.1f' % (device, img_sec_mean, img_sec_conf))
log('Total img/sec on %d %s(s): %.1f +-%.1f' %
",2
"# See the License for the specific language governing permissions and
",2
"# Horovod: initialize Horovod.
hvd.init()
",2
"if gpus:
    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')

(mnist_images, mnist_labels), _ = \
    tf.keras.datasets.mnist.load_data(path='mnist-%d.npz' % hvd.rank())
",2
"
",2
"dataset = tf.data.Dataset.from_tensor_slices(
",2
"
",2
"
state = hvd.elastic.TensorFlowKerasState(mnist_model, opt, batch=0)
state.register_reset_callbacks([on_state_reset])
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",2
"import os
import numpy as np
import timeit

",2
"                    help='input batch size')

parser.add_argument('--num-warmup-batches', type=int, default=10,
",2
"
parser.add_argument('--no-cuda', action='store_true', default=False,
                    help='disables CUDA training')

args = parser.parse_args()
",2
"
# Horovod: initialize Horovod.
hvd.init()

# Horovod: pin GPU to be used to process local rank (one GPU per process)
",2
"    # Horovod: (optional) compression algorithm.
",2
"        probs = model(data, training=True)
        loss = tf.losses.categorical_crossentropy(target, probs)

    # Horovod: add Horovod Distributed GradientTape.
    tape = hvd.DistributedGradientTape(tape, compression=compression)
",2
"
def log(s, nl=True):
",2
"log('Model: %s' % args.model)
",2
"        if not state.warm:
",2
"state.register_reset_callbacks([on_state_reset])
run_benchmark(state)

# Results
",2
"                    help='number of epochs to train (default: 10)')
",2
"                    help='use adasum algorithm to do reduction')

args = parser.parse_args()
args.cuda = not args.no_cuda and torch.cuda.is_available()
",2
"    torch.cuda.manual_seed(args.seed)

",2
"
class Net(nn.Module):
",2
"    def __init__(self):
",2
"    model.cuda()
    # If using GPU Adasum allreduce, scale learning rate by local_size.
    if args.use_adasum and hvd.nccl_built():
        lr_scaler = hvd.local_size()

",2
"

def check_rank(epoch):
    if epoch == 2 and int(os.environ.get('HOROVOD_RANK')) == 0:
",2
"def train(state):
",2
"    # post synchronization event (worker added, worker removed) init ...
    for state.epoch in range(state.epoch, args.epochs + 1):
        state.model.train()

",2
"            check_rank(state.epoch)
            if args.cuda:
                data, target = data.cuda(), target.cuda()
",2
"        if args.cuda:
            data, target = data.cuda(), target.cuda()
        output = model(data)
        # sum up batch loss
        test_loss += F.nll_loss(output, target, size_average=False).item()
",2
"    test_loss = metric_average(test_loss, 'avg_loss')
    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')

    # Horovod: print output only on first rank.
",2
"    if hvd.rank() == 0:
        print('\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\n'.format(
            test_loss, 100. * test_accuracy))

",2
"
# adjust learning rate on reset
def on_state_reset():
    for param_group in optimizer.param_groups:
",2
"        param_group['lr'] = args.lr * hvd.size()


state = hvd.elastic.TorchState(model, optimizer, epoch=1, batch=0)
state.register_reset_callbacks([on_state_reset])
",2
"        verbose = settings.verbose
        result = rsh(driver_addresses, key, host, command, env, local_rank, verbose, False, events)
        return result, time.time()
    return _exec_command

",2
"
def gloo_run(settings, nics, driver, env):
    """"""
    Run distributed gloo jobs.

",2
"                     Note: settings.num_proc and settings.hosts must not be None.
    :param nics: Interfaces to use by gloo.
    :param driver: The Spark driver service that tasks are connected to.
",2
"    # error occurs in one thread, entire process will be terminated. Otherwise,
",2
"    server_ip = driver.addresses()[iface][0][0]
    command = (sys.executable,
               '-m', 'horovod.spark.task.gloo_exec_fn',
               codec.dumps_base64(driver.addresses()),
               codec.dumps_base64(settings))
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"from horovod.spark.mpi_run import mpi_run
from horovod.run.runner import is_gloo_used, run_controller
from horovod.run.common.util import timeout, host_hash, secret
",2
"    os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'


def _task_fn(index, driver_addresses, key, settings, use_gloo):
    # deserialized on Spark workers, settings do not contain the key, so it is given here explicitly
",2
"
    task = task_service.SparkTaskService(index, settings.key, settings.nics, settings.verbose)
    try:
        driver_client = driver_service.SparkDriverClient(driver_addresses, settings.key, settings.verbose)
",2
"        driver_client.register_task(index, task.addresses(), host_hash.host_hash())
        task.wait_for_initial_registration(settings.start_timeout)
        task_indices_on_this_host = driver_client.task_host_hash_indices(host_hash.host_hash())

        # With Gloo all tasks wait for the command
",2
"        # With MPI task with first index executes orted which will run mpirun_exec_fn for all tasks.
",2
"            first_task_addresses = driver_client.all_task_addresses(task_indices_on_this_host[0])
            first_task_client = \
                task_service.SparkTaskClient(task_indices_on_this_host[0],
                                             first_task_addresses, settings.key,
                                             settings.verbose)
",2
"        # command terminated, make sure this task service does not shutdown too quickly after
",2
"        return task.fn_result()
    finally:
",2
"            # thus ensuring that key that is passed here remains secret.
            result = procs.mapPartitionsWithIndex(_make_mapper(driver.addresses(), settings, use_gloo)).collect()
",2
"            result_queue.put(result)
",2
"        except:
            driver.notify_spark_job_failed()
            raise

",2
"    spark_thread = in_thread(target=run_spark, daemon=False)
",2
"def run(fn, args=(), kwargs={}, num_proc=None, start_timeout=None,
        use_mpi=None, use_gloo=None, extra_mpi_args=None,
        env=None, stdout=None, stderr=None, verbose=1, nics=None):
",2
"    """"""
    Runs Horovod in Spark.  Runs `num_proc` processes executing `fn` using the same amount of Spark tasks.
",2
"        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.
        start_timeout: Timeout for Spark tasks to spawn, register and start running the code, in seconds.
                       If not set, falls back to `HOROVOD_SPARK_START_TIMEOUT` environment variable value.
                       If it is not set as well, defaults to 600 seconds.
",2
"                                    'process runs in a Spark task. You may need to increase the '
                                    'start_timeout parameter to a larger value if your Spark resources '
                                    'are allocated on-demand.')
    settings = hvd_settings.Settings(verbose=verbose,
                                     extra_mpi_args=extra_mpi_args,
",2
"        raise Exception('Could not find an active SparkContext, are you '
",2
"    if num_proc is None:
        num_proc = spark_context.defaultParallelism
        if settings.verbose >= 1:
            print('Running %d processes (inferred from spark.default.parallelism)...' % num_proc)
    else:
",2
"
",2
"        task_client.notify_initial_registration_complete()
        next_task_index = (index + 1) % settings.num_proc
        next_task_addresses = driver.all_task_addresses(next_task_index)
        task_to_task_addresses = task_client.get_task_addresses_for_task(next_task_index, next_task_addresses)
        driver.register_task_to_task_addresses(next_task_index, task_to_task_addresses)
",2
"                     Note: settings.num_proc and settings.hosts must not be None.
    :param nics: Interfaces to include by MPI.
    :param driver: The Spark driver service that tasks are connected to.
",2
"    :param env: Environment dictionary to use for running MPI.  Can be None.
    :param stdout: Stdout of the mpi process.
                   Only used when settings.run_func_mode is True.
",2
"    rsh_agent = (sys.executable,
                 '-m', 'horovod.spark.driver.mpirun_rsh',
",2
"import horovod.spark.common._namedtuple_fix

from .runner import run
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"# Unless required by applicable law or agreed to in writing, software
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
",2
"
import numbers
",2
"import time
",2
"from horovod.spark.common.estimator import HorovodEstimator, HorovodModel
from horovod.spark.common.params import EstimatorParams
",2
"        return KerasEstimatorParamsWriter(self)


",2
"                def load_model_fn(x):
                    with keras_utils.keras().utils.custom_object_scope(custom_objects):
                        return keras_utils.keras().models.load_model(x, compile=True)
",2
"                opt_base64_encoded = codec.loads_base64(param_val)
                return keras_utils.deserialize_optimizer(opt_base64_encoded)
            else:
",2
"                keras_utils = BareKerasUtil
            elif keras_pkg_type == TF_KERAS:
                keras_utils = TFKerasUtil

        custom_objects = {}
",2
"        for key, val in dict.items():
",2
"

class KerasEstimatorParamsReadable(MLReadable):
    @classmethod
    def read(cls):
",2
"    Supports standalone `keras` and `tf.keras`, and TensorFlow 1.X and 2.X.
",2
"
    Args:
        num_proc: Number of Horovod processes.  Defaults to `spark.default.parallelism`.
        model: Keras model to train.
        backend: Optional Backend object for running distributed training function. Defaults to SparkBackend with
",2
"                               transformations to it. Increasing this number
                               will generally increase the reading rate but will also
                               increase the memory footprint. More processes are
                               particularly useful if the bandwidth to the data store is not
                               high enough, or users need to apply transformation such as
",2
"        val_reader_num_workers: Similar to the train_reader_num_workers.
    """"""

",2
"                 shuffle_buffer_size=None,
                 partitions_per_process=None,
",2
"
        super(KerasEstimator, self).__init__()

        self._setDefault(optimizer=None,
",2
"
        optimizer_type = None
        optimizer = self.getOptimizer()
        if optimizer:
            if isinstance(optimizer, str):
",2
"
        if len(types) > 1:
            raise ValueError('mixed keras and tf.keras values for optimizers and model')
        elif len(types) == 1:
",2
"    def get_model_shapes(self):
",2
"                        for input in model.inputs]
",2
"        output_shapes = [[dim if dim else -1 for dim in output.shape.as_list()]
                         for output in model.outputs]
        return input_shapes, output_shapes

",2
"        loss = self.getLoss()
        loss_weights = self.getLossWeights()

",2
"        if not loss:
            raise ValueError('Loss parameter is required for the model to compile')

        optimizer = self.getOptimizer()
        if not optimizer:
",2
"            optimizer = model.optimizer

        if not optimizer:
",2
"            model.optimizer.set_weights(optimizer_weight_values)

        return keras_utils.serialize_model(model)

",2
"            with keras_module.utils.custom_object_scope(custom_objects):
                return keras_module.models.load_model(x)

        model = keras_utils.deserialize_model(serialized_model, load_model_fn=load_model_fn)

",2
"    # deserializing the transformer
",2
"
",2
"            super(KerasModel, self)._set(_keras_pkg_type=pkg_type)

",2
"        metadata = self._get_metadata()
",2
"
        pin_cpu = remote._pin_cpu_fn()

        def predict(rows):
",2
"                for label_col, output_col, pred, in zip(label_cols, output_cols, preds):
",2
"                    if col_type == DenseVector:
                        shape = np.prod(pred.shape)
                        flattened_pred = pred.reshape(shape, )
",2
"                        field = DenseVector(flattened_pred)
                    elif col_type == SparseVector:
                        shape = meta['shape']
",2
"                        # If the column is scalar type, int, float, etc.
                        value = pred[0]
                        python_type = util.spark_scalar_to_python_type(col_type)
                        if issubclass(python_type, numbers.Integral):
",2
"
        return df.rdd.mapPartitions(predict).toDF()
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"
from horovod.run.common.util import codec

",2
"def serialize_bare_keras_optimizer(x):
    import keras
",2
"        with h5py.File(bio, 'w') as f:
            save_optimizer_fn(opt, f)
        return codec.dumps_base64(bio.getvalue())
    else:
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"
import numpy as np
",2
"from keras import backend as K
from keras import optimizers


def save_bare_keras_optimizer(optimizer, h5py_file):
",2
"
",2
"        if hasattr(obj, 'get_config'):
            return {'class_name': obj.__class__.__name__,
                    'config': obj.get_config()}

",2
"            return obj.item()

        # misc functions (e.g. loss function)
        if callable(obj):
            return obj.__name__
",2
"
        # if obj is a python 'type'
        if type(obj).__name__ == type.__name__:
            return obj.__name__
",2
"    if isinstance(optimizer, optimizers.TFOptimizer):
",2
"            },
",2
"                    unique_name = name + '_1'
                    while unique_name in weight_names:
                        unique_name = name + '_' + str(idx)
                        idx += 1
                    name = unique_name
",2
"            for value in obj:
",2
"                deserialized[key] = convert_custom_objects(value)
            return deserialized
",2
"    optimizer, optimizer_weight_values = None, None

    # instantiate optimizer
    training_config = h5py_file.get('training_config')
",2
"    training_config = json.loads(training_config[()].decode('utf-8'))
    optimizer_config = training_config['optimizer_config']
    optimizer = optimizers.deserialize(optimizer_config, custom_objects=custom_objects)
",2
"
    if 'optimizer_weights' in h5py_file:
",2
"            'as part of the model save file.'
",2
"            'Prefer using a Keras optimizer instead '
            '(see keras.io/optimizers).')
    else:
        h5py_file.attrs['training_config'] = json.dumps(
            {
",2
"            The same structure, where occurrences
",2
"            deserialized = []
            for value in obj:
                deserialized.append(convert_custom_objects(value))
            return deserialized
        if isinstance(obj, dict):
",2
"            deserialized = {}
",2
"    training_config = h5py_file.attrs.get('training_config')
",2
"        optimizer_weight_names = [
            n.decode('utf8')
            for n in optimizer_weights_group.attrs['weight_names']
",2
"#
# Unless required by applicable law or agreed to in writing, software
",2
"#
",2
"                        input_shapes, output_shapes, output_names, batch_size):
        # Check if any of the columns are only SparseVector
",2
"        return TFKerasUtil.horovod_fn()()

    @staticmethod
    def horovod_fn():
        def fn():
",2
"            import horovod.tensorflow.keras as hvd
            return hvd
",2
"    def serialize_model(*args, **kwargs):
        def serialize_keras_model(x):
",2
"
        return _serialize_param(*args, **kwargs)
",2
"            new_row = {}
",2
"            if sample_weight_col:
                new_row[sample_weight_col] = getattr(row, sample_weight_col)
",2
"                      input_shapes, output_shapes, output_names):
        def _get_from_dict(row, col):
            return row[col]

",2
"        def as_tuple(v):
            return tuple(v) if len(v) > 1 else v[0]

        def prep(row):
            if sample_weight_col:
",2
"                )

        return prep


",2
"                verbose=verbose,
                epochs=epochs)

",2
"    def deserialize_optimizer(*args, **kwargs):
        return optimizer.deserialize_bare_keras_optimizer(*args, **kwargs)
",2
"    @staticmethod
    def deserialize_model(*args, **kwargs):
",2
"        return _deserialize_keras_model(*args, **kwargs)

    @staticmethod
    def serialize_param_value(*args, **kwargs):
",2
"        prepare_data_bare_keras = BareKerasUtil._prepare_data_fn(metadata)

        cols = feature_columns + label_columns
        if sample_weight_col:
            cols.append(sample_weight_col)
",2
"            return np.array(dense_rows).reshape(shape)
        return prepare_data

    @staticmethod
    def _convert_custom_sparse_to_dense_fn():
",2
"            size = int(row[0])
            dense_row = np.zeros(shape)
            dense_row[row[1:size + 1].astype(int)] = row[size + 1:2 * size + 1]
            return dense_row
        return convert_custom_sparse_to_dense
",2
"
def _serialize_keras_model(model, save_model_fn):
    """"""Serialize model into byte array encoded into base 64.""""""
    bio = io.BytesIO()
",2
"        # We do not serialize backend and store. These params have to be regenerated for each
        # run of the pipeline
        return None
",2
"    else:
        return codec.dumps_base64(param_val)


",2
"        # Get the first element from custom_sparse_vec. This element is the size of
",2
"        # non-zero elements in the original sparse vector.
        sparse_vector_size = tf.cast(tf.gather(custom_sparse_vec, 0, axis=0), tf.int32)
",2
"        sparse_vector_size = tf.reshape(sparse_vector_size, [1])

        # get the first sparse_vector_size elements of the custom_sparse_vec which are the
        # indices
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"

def RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):
    # Estimator parameters
",2
"    sample_weight_col = estimator.getSampleWeightCol()
    custom_objects = estimator.getCustomObjects()
    should_validate = estimator.getValidation()
",2
"    input_shapes, output_shapes = estimator.get_model_shapes()
",2
"    # Utility functions
    deserialize_keras_model = _deserialize_keras_model_fn()
    calculate_shuffle_buffer_size = _calculate_shuffle_buffer_size_fn()
    pin_gpu = _pin_gpu_fn()

",2
"    # Storage
    store = estimator.getStore()
",2
"        k.backend.set_floatx(floatx)

        hvd = get_horovod()
        hvd.init()
",2
"                serialized_model, lambda x: hvd.load_model(x))

        # Horovod: adjust learning rate based on number of processes.
",2
"            transform_spec = TransformSpec(transformation)

",2
"                # Horovod: broadcast initial variable states from rank 0 to all other processes.
                # This is necessary to ensure consistent initialization of all workers when
                # training is started with random weights or restored from a checkpoint.
                hvd.callbacks.BroadcastGlobalVariablesCallback(root_rank=0),

",2
"                # Horovod: average metrics among workers at the end of every epoch.
                #
                # Note: This callback must be in the list before the ReduceLROnPlateau,
                # TensorBoard, or other metrics-based callbacks.
                hvd.callbacks.MetricAverageCallback(),
",2
"                if remote_store.saving_runs:
                    callbacks.append(k.callbacks.TensorBoard(logs_dir))
                    callbacks.append(SyncCallback(run_output_dir, remote_store.sync, k))
",2
"                steps_per_epoch = train_steps_per_epoch

",2
"                    if should_validate else None
            else:
                validation_steps = validation_steps_per_epoch
",2
"
            # In general, make_batch_reader is faster than make_reader for reading the dataset.
            # However, we found out that make_reader performs data transformations much faster than
",2
"            with reader_factory(remote_store.train_data_path,
                                num_epochs=None,
                                cur_shard=hvd.rank(),
                                reader_pool_type='process',
                                workers_count=train_reader_worker_count,
",2
"

",2
"        memory_cap_gb GB are allocated for shuffling buffer. Also, it ensures that the buffer size
",2
"def _pin_gpu_fn():
    # Horovod: pin GPU to be used to process local rank (one GPU per process)
    return _pin_gpu_tensorflow2_fn() if LooseVersion(tf.__version__) >= LooseVersion('2.0.0') \
",2
"
",2
"        tf.config.threading.set_intra_op_parallelism_threads(1)
    return fn
",2
"        config.inter_op_parallelism_threads = 1
        config.intra_op_parallelism_threads = 1
",2
"        keras.backend.set_session(tf.Session(config=config))
    return fn
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"        backend = self._get_or_create_backend()
        store = self.getStore()
        label_columns = self.getLabelCols()
",2
"                                              sample_weight_col=sample_weight_col)

",2
"        return self._fit_on_prepared_data(backend, train_rows, val_rows, metadata, avg_row_size)

    def _fit(self, df):
        backend = self._get_or_create_backend()
        with util.prepare_data(backend.num_processes(),
",2
"

class HorovodModel(Model, ModelParams):
    def transform(self, df, params=None):
",2
"        """"""
        Transforms the input dataset with prediction columns representing model predictions.

        Prediction column names default to <label_column>__output. Override column names
",2
"# You may obtain a copy of the License at
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

",2
"import shutil
import tempfile

import pyarrow as pa
import pyarrow.parquet as pq
",2
"    basic semantics for reading and writing objects, and how to access objects with certain definitions.

",2
"    The store exposes a generic interface that is not coupled to a specific DataFrame, model, or runtime. Every run
    of an Estimator should result in a separate run directory containing checkpoints and logs, and every variation
    in dataset should produce a separate intermediate data path.

",2
"    def saving_runs(self):
        """"""Returns True if run output should be saved during training.""""""
        raise NotImplementedError()

    def get_runs_path(self):
",2
"    def get_run_path(self, run_id):
        """"""Returns the path to the run with the given ID.""""""
        raise NotImplementedError()

",2
"
    def get_logs_subdir(self):
        """"""Returns the subdirectory name for the logs directory.""""""
",2
"
    def get_local_output_dir_fn(self, run_id):
        raise NotImplementedError()

    def sync_fn(self, run_id):
",2
"                    setattr(self, name, attr)

        return RemoteStore()

    def _remote_attrs(self, run_id, dataset_idx):
",2
"            'saving_runs': self.saving_runs(),
            'runs_path': self.get_runs_path(),
            'run_path': self.get_run_path(run_id),
            'checkpoint_path': self.get_checkpoint_path(run_id),
            'logs_path': self.get_logs_path(run_id),
",2
"    """"""Abstract class for stores that use a filesystem for underlying storage.""""""

    def __init__(self, prefix_path, train_path=None, val_path=None, test_path=None, runs_path=None, save_runs=True):
        self.prefix_path = self.get_full_path(prefix_path)
",2
"            return False

    def get_parquet_dataset(self, path):
        return pq.ParquetDataset(self.get_localized_path(path), filesystem=self.get_filesystem())

",2
"
    def get_runs_path(self):
        return self._runs_path

",2
"    def get_run_path(self, run_id):
        return os.path.join(self.get_runs_path(), run_id)

    def get_checkpoint_path(self, run_id):
",2
"
    def get_full_path_fn(self):
        prefix = self.path_prefix()
",2
"
    FS_PREFIX = 'file://'

",2
"        super(LocalStore, self).__init__(prefix_path, *args, **kwargs)

    def path_prefix(self):
        return self.FS_PREFIX

",2
"    def get_filesystem(self):
",2
"
        return local_run_path
",2
"            # No-op for LocalStore since the `local_run_path` will be the same as the run path
            assert run_path == local_run_path
        return fn

",2
"    @classmethod
    def filesystem_prefix(cls):
",2
"
    def __init__(self, prefix_path,
                 host=None, port=None, user=None, kerb_ticket=None,
                 driver='libhdfs', extra_conf=None, temp_dir=None, *args, **kwargs):
        self._temp_dir = temp_dir
",2
"        host = host or url_host or 'default'
        port = port or url_port or 0
        self._hdfs_kwargs = dict(host=host,
                                 port=port,
                                 user=user,
",2
"                                 kerb_ticket=kerb_ticket,
                                 driver=driver,
                                 extra_conf=extra_conf)
        self._hdfs = self._get_filesystem_fn()()

",2
"
    def get_local_output_dir_fn(self, run_id):
",2
"            finally:
                shutil.rmtree(dirpath)

        return local_run_path

",2
"    def sync_fn(self, run_id):
        class SyncState(object):
            def __init__(self):
                self.fs = None
",2
"
            hdfs = state.fs
            uploaded = state.uploaded

            # We need to swap this prefix from the local path with the absolute path, +1 due to
",2
"                    local_path = os.path.join(local_dir, file)
                    modified_ts = int(os.path.getmtime(local_path))
",2
"        hdfs_kwargs = self._hdfs_kwargs

        def fn():
",2
"            raise ValueError('Failed to parse path from URL: {}'.format(url))
",2
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"# limitations under the License.
# ==============================================================================

import horovod.spark.common._namedtuple_fix

",2
"

class EstimatorParams(Params):
",2
"    optimizer = Param(Params._dummy(), 'optimizer', 'optimizer')
    model = Param(Params._dummy(), 'model', 'model')
",2
"                                typeConverter=TypeConverters.toInt)

    verbose = Param(Params._dummy(), 'verbose', 'verbose flag (0=silent, 1=enabled, other values used by frameworks)',
                    typeConverter=TypeConverters.toInt)

",2
"    partitions_per_process = Param(Params._dummy(), 'partitions_per_process',
                                   'partitions for parquet form of the DataFrame per process',
",2
"            feature_cols=None,
            label_cols=None,
",2
"            train_reader_num_workers=2,
            val_reader_num_workers=2)
",2
"
    def _check_params(self, metadata):
        model = self.getModel()
",2
"        if missing_labels:
            raise ValueError('Label columns {} not found in training DataFrame metadata'
",2
"                             .format(missing_labels))

    @keyword_only
    def setParams(self, **kwargs):
        return self._set(**kwargs)
",2
"
",2
"
",2
"    def setSampleWeightCol(self, value):
        return self._set(sample_weight_col=value)

",2
"    def getSampleWeightCol(self):
        return self.getOrDefault(self.sample_weight_col)

",2
"
    def getBatchSize(self):
        return self.getOrDefault(self.batch_size)

    def setEpochs(self, value):
",2
"
    def getEpochs(self):
        return self.getOrDefault(self.epochs)

    def setTrainStepsPerEpoch(self, value):
",2
"    def setVerbose(self, value):
        return self._set(verbose=value)

    def getVerbose(self):
        return self.getOrDefault(self.verbose)
",2
"    def getGradientCompression(self):
        return self.getOrDefault(self.gradient_compression)

    def setCompressSparseCols(self, value):
        return self._set(compress_sparse_cols=value)
",2
"    def setOptimizer(self, value):
        return self._set(optimizer=value)

    def getOptimizer(self):
",2
"    def setPartitionsPerProcess(self, value):
        return self._set(partitions_per_process=value)
",2
"class ModelParams(HasOutputCols):
    history = Param(Params._dummy(), 'history', 'history')
",2
"
    def setFeatureColumns(self, value):
        return self._set(feature_columns=value)

",2
"    def getFeatureColumns(self):
",2
"        return self.getOrDefault(self.feature_columns)

    def setLabelColoumns(self, value):
",2
"    # Only for internal use
    def _get_metadata(self):
        return self.getOrDefault(self._metadata)
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"# limitations under the License.
",2
"from pyspark.ml.util import DefaultParamsWriter, DefaultParamsReader

",2
"        else:
",2
"            for p, param_val in params.items():
                # If param is not json serializable, convert it into serializable object
                json_params[p.name] = param_serializer_fn(p.name, param_val)

",2
"        basic_metadata = {""class"": cls, ""timestamp"": int(round(time.time() * 1000)),
                          ""sparkVersion"": sc.version, ""uid"": uid, ""paramMap"": json_params,
                          ""defaultParamMap"": json_default_params}
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"
",2
"PETASTORM_HDFS_DRIVER = 'libhdfs'
",2
"
TOTAL_BUFFER_MEMORY_CAP_GIB = 4
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"# limitations under the License.
# ==============================================================================

import horovod.spark.common._namedtuple_fix

",2
"import os

import pyspark

import horovod.spark
",2
"    spark_context = pyspark.SparkContext._active_spark_context
    return spark_context.defaultParallelism
",2
"        raise NotImplementedError()


class SparkBackend(Backend):
    """"""Uses `horovod.spark.run` to execute the distributed training `fn`.""""""
",2
"
",2
"        if 'CUDA_VISIBLE_DEVICES' in full_env:
            # In TensorFlow 2.0, we set this before calling `run` in order to prevent TensorFlow
            # from allocating memory on the GPU outside the training process.  Once we submit the
            # function for execution, we want to ensure that TensorFLow has visibility into GPUs on
            # the device so we can use them for training, which is why we need to unset this.
",2
"import horovod.spark.common._namedtuple_fix

import contextlib

",2
"import pyarrow as pa
import numpy as np
import pyspark.sql.functions as f
from pyspark.ml.linalg import DenseVector, SparseVector, Vector, VectorUDT
from pyspark.sql.types import ArrayType, BinaryType, BooleanType, FloatType, DoubleType, \
",2
"    from pyspark.sql.types import from_arrow_type

from horovod.run.common.util import codec
",2
"def data_type_to_str(dtype):
    if dtype == VectorUDT or dtype == SparseVector or dtype == DenseVector:
",2
"    elif dtype == BinaryType:
        return 'Binary'
",2
"    if dtype == np.int32:
        return 'Int'
    elif dtype == np.float32:
        return 'Float'
",2
"def spark_scalar_to_python_type(dtype):
    if dtype == IntegerType:
        return int
",2
"        return np.float64
",2
"        return np.uint8
    elif dtype == FloatType:
        return np.float32
",2
"        return np.bool
",2
"def check_shape_compatibility(metadata, feature_columns, label_columns,
                              input_shapes=None, output_shapes=None):
    # Check for model and input type incompatibility. Columns must have the same size
    # (total number of elements) of the corresponding inputs.
",2
"                             'model inputs count {inputs}'
                             .format(features=feature_count, inputs=len(input_shapes)))

        for idx, col, input_shape in zip(range(feature_count), feature_columns, input_shapes):
",2
"
    if output_shapes is not None:
        label_count = len(label_columns)
",2
"
        for idx, col, output_shape in zip(range(label_count), label_columns, output_shapes):
            col_size = metadata[col]['shape']
            if col_size is None:
                # When training directly on Parquet, we do not compute shape metadata
",2
"                size = data_col.indices.shape[0]
            elif isinstance(data_col, list):
                shape = size = len(data_col)
            else:
",2
"        y_dtypes, y_shapes, y_sizes = y
        dtypes = x_dtypes | y_dtypes
        shapes = x_shapes | y_shapes
        sizes = x_sizes | y_sizes
",2
"
    for col_info in raw_col_info_list:
        col_name, col_meta = col_info
        dtypes, shapes, sizes = col_meta

",2
"        'shape': 1
        },
     'col2': {
        'dtype': <type 'float'>,
",2
"            # If a col has DenseVector type (whether it is mixed sparse and dense vector or just
            # DenseVector), convert all of the values to dense vector
",2
"            is_sparse_vector_only = False
            spark_data_type = type(field.dataType)
            convert_to_target = constants.NOCHANGE

",2
"        #     dtype:
        #
        #     spark_data_type:
        #         The spark data type from dataframe schema: type(field.dataType). If column has
",2
"        metadata[col] = {'spark_data_type': spark_data_type,
                         'is_sparse_vector_only': is_sparse_vector_only,
",2
"        for col in schema_cols:
            col_data = row[col]
            if isinstance(col_data, Vector):
                intermediate_format = metadata[col]['intermediate_format'] if metadata else ARRAY
",2
"                if intermediate_format == ARRAY:
                    converted[col] = col_data.toArray().tolist()
                elif intermediate_format == CUSTOM_SPARSE:
                    # Currently petastorm does not support reading pyspark sparse vector. We put
                    # the indices and values into one array. when consuming the data, we re-create
",2
"            row_group = metadata.row_group(row_group_index)
",2
"    return total_rows, total_byte_size
",2
"

def _save_meta_to_fs(fs, path, schema, rows, total_byte_size):
",2
"    validation_data_path = store.get_val_data_path(dataset_idx)

    if not store.exists(train_data_path):
        raise ValueError(""{} path does not exist in the store"".format(train_data_path))
",2
"                _load_metadata_from_fs(fs, train_data_meta_path)
            metadata, avg_row_size = make_metadata_dictionary(train_data_schema)
",2
"
            return train_rows, val_rows, metadata, avg_row_size
    except Exception as ex:
        print(ex)

",2
"    train_rows, train_data_total_byte_size = _get_dataset_info(train_data, 'training',
",2
"        val_data_schema = val_data.schema.to_arrow_schema()
        val_rows, val_data_total_byte_size = _get_dataset_info(val_data, 'validation',
",2
"    train_df = df
    val_df = None
",2
"    validation_ratio = 0.0
",2
"        train_df = train_df.filter(
            ~f.col(validation) if bool_dtype else f.col(validation) == 0).drop(validation)
",2
"def _get_or_create_dataset(key, store, df, feature_columns, label_columns,
                           validation, sample_weight_col, compress_sparse,
                           num_partitions, num_processes, verbose):
    with _training_cache.lock:
        if _training_cache.is_cached(key, store):
",2
"                print('using cached dataframes for key: {}'.format(key))
                print('train_data_path={}'.format(train_data_path))
                print('train_rows={}'.format(train_rows))
",2
"                schema_cols.append(validation)
            df = df[schema_cols]

            metadata = None
",2
"                print('train_partitions={}'.format(train_partitions))

            train_df \
",2
"                    .coalesce(val_partitions) \
                    .write \
                    .mode('overwrite') \
                    .parquet(val_data_path)

",2
"        else:
            raise ValueError('Param validation must be of type ""float"" or ""str"", found: {}'
",2
"                             .format(type(validation)))
",2
"
    for col in label_columns:
        if col not in df.columns:
            raise ValueError('Label column {} does not exist in the DataFrame'.format(col))

",2
"    if feature_columns is None:
        feature_columns = [col for col in df.columns if col not in set(label_columns)]
",2
"    key = _training_cache.create_key(df, store, validation)
",2
"def clear_training_cache():
    _training_cache.clear()

",2
"                             ""label_cols"")

    return var
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"# See the License for the specific language governing permissions and
# limitations under the License.
",2
"
        NOTE: this method is not thread-safe. You must wrap usage with `cache.lock` if using
        in a multi-threaded setting (see `prepare_data`).
        """"""
",2
"    def get_dataset(self, key):
        return self._key_to_dataset[key]

",2
"        """"""Returns true if the key is in the cache and its paths exist in the store already.""""""
        if key not in self._key_to_dataset:
            return False
",2
"
        dataset_idx = self._key_to_dataset[key]
        _, _, _, validation = key
        train_data_path = store.get_train_data_path(dataset_idx)
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

import threading
",2
"        return JOB_ID
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"import sys

",2
"        print('Usage: %s <service addresses> <settings> <host hash> '
              '<command...>' % sys.argv[0])
",2
"    settings = codec.loads_base64(sys.argv[2])
",2
"    host_hash = sys.argv[3]
    command = "" "".join(sys.argv[4:])
    env = {}  # orted does not need any env vars, the target training code gets env from mpirun

",2
"    # Since tasks with the same host hash have shared memory,
    # we will run only one orted process on the first task.
    rsh(addresses, key, host_hash, command, env, 0, settings.verbose)
# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.
#
",2
"
    :param driver_addresses: driver's addresses
    :param key: used for encryption of parameters passed across the hosts
    :param host_hash: host hash to connect to
",2
"        stop = None
        events = events or []
",2
"    def __init__(self, host_hash):
        self.host_hash = host_hash

",2
"
class TaskIndexByRankRequest(object):
    """"""Request task index by Horovod rank.""""""
    def __init__(self, rank):
        self.rank = rank
",2
"

",2
"

class CodeRequest(object):
    """"""Request Python function to execute.""""""
",2
"        self._args = args
        self._kwargs = kwargs
        self._ranks_to_indices = None
",2
"            return TaskHostHashIndicesResponse(self._task_host_hash_indices[req.host_hash])

        if isinstance(req, TaskIndexByRankRequest):
",2
"
    def notify_spark_job_failed(self):
",2
"        self._wait_cond.acquire()
        try:
            self._spark_job_failed = True
        finally:
",2
"            self._wait_cond.notify_all()
            self._wait_cond.release()

    def check_for_spark_job_failure(self):
        if self._spark_job_failed:
",2
"            while len(self._all_task_addresses) < self._num_proc:
                self.check_for_spark_job_failure()
                self._wait_cond.wait(timeout.remaining())
                timeout.check_time_out_for('Spark tasks to start')
",2
"        os.chdir(work_dir)

",2
"#
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# ==============================================================================

import os
import time
",2
"

",2
"                os._exit(1)
",2
"                                                     verbose=settings.verbose)
",2
"
",2
"        """"""Map of interface to list of (ip, port) pairs.""""""


class SparkTaskService(task_service.BasicTaskService):
    NAME_FORMAT = 'task service #%d'
",2
"
    @staticmethod
",2
"            next_task_addresses = req.all_task_addresses
            # We request interface matching to weed out all the NAT'ed interfaces.
",2
"            from pyspark import TaskContext
            return TaskContext.get().resources()
        return dict()

",2
"
from horovod.spark.task import task_exec
from horovod.run.common.util import codec


",2
"def main(driver_addresses, settings):
    task_exec(driver_addresses, settings, 'HOROVOD_RANK')

",2
"
if __name__ == '__main__':
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",2
"# limitations under the License.
# ==============================================================================


class TaskInfo(object):
",2
"        train_minibatch_fn: Optional custom function to execute within the training loop. Defaults to standard
                            gradient descent process.
        train_steps_per_epoch: Number of steps to train each epoch. Useful for testing that model trains successfully.
                               Defaults to training the entire dataset each epoch.
        validation_steps_per_epoch: Number of validation steps to perform each epoch.
",2
"        val_reader_num_workers: Similar to the train_reader_num_workers.
    """"""
",2
"                 input_shapes=None,
",2
"        if EstimatorParams.loss.name in kwargs and TorchEstimator.loss_constructors.name in kwargs:
            raise ValueError(""only one of loss_constructors and loss parameters can be specified."")

        self.setParams(**kwargs)
",2
"
    def getInputShapes(self):
        return self.getOrDefault(self.input_shapes)

",2
"
    def _fit_on_prepared_data(self, backend, train_rows, val_rows, metadata, avg_row_size, dataset_idx=None):
        self._check_params(metadata)

        run_id = self.getRunId()
",2
"        # Combine model and optimizer state
        model_opt_state = {'model': model_state, 'optimizer': optimizer_state} \
            if last_checkpoint_state is None else last_checkpoint_state
        model_opt_state_serialized = save_into_bio(model_opt_state, torch.save)
",2
"                             env={})
        return self._create_model(handle, run_id, metadata)

    def _load_checkpoint(self, run_id):
        store = self.getStore()
",2
"        if self.getVerbose():
            print('Resuming training from last checkpoint: {}'.format(last_ckpt_path))
",2
"        ckpt_file = io.BytesIO(store.read(last_ckpt_path))
        return torch.load(ckpt_file)

    def _create_model(self, run_results, run_id, metadata):
",2
"        optimizer.load_state_dict(best_checkpoint['optimizer'])

        return self.get_model_class()(**self._get_model_kwargs(
            model, history, optimizer, run_id, metadata))
",2
"                    loss=self.getLoss(),
                    loss_constructors=self.getLossConstructors())


class TorchModel(HorovodModel, TorchEstimatorParamsWritable, TorchEstimatorParamsReadable):
",2
"        label_columns: List of label column names.
        optimizer: PyTorch optimizer used during training, containing updated state.
        run_id: ID of the run used to train the model.
        loss: PyTorch loss(es).
",2
"    def __init__(self,
                 history=None,
                 model=None,
                 feature_columns=None,
                 input_shapes=None,
",2
"        if label_columns:
",2
"                         loss=None,
                         loss_constructors=None,
                         input_shapes=None)
",2
"        return self._set(loss_constructors=value)

",2
"        return self.getOrDefault(self.loss_constructors)
",2
"
    def setInputShapes(self, value):
",2
"        return self._set(input_shapes=value)

    def getInputShapes(self):
        return self.getOrDefault(self.input_shapes)
",2
"
                for label_col, output_col, pred in zip(label_cols, output_cols, preds):
                    meta = metadata[label_col]
                    col_type = meta['spark_data_type']
",2
"                                             flattened_pred[nonzero_indices])
                    elif pred.shape.numel() == 1:
                        # If the column is scalar type, int, float, etc.
                        value = pred.item()
                        python_type = util.spark_scalar_to_python_type(col_type)
",2
"
                    fields[output_col] = field

                yield Row(**fields)
",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"#
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"        elif sys.version_info >= (3, 4):
            # python 3.4 and above
            import importlib
",2
"            torch_loader = importlib.util.find_spec(module_name)
        else:
            raise RuntimeError('Unsupported version of Python: {}'.format(platform.python_version()))

",2
"def serialize_fn():
    is_module_available = is_module_available_fn()

",2
"    def _serialize(model):
        """"""Serialize model into byte array encoded into base 64.""""""
        if is_module_available('torch'):
            import torch
            sys.modules[""torch._C._nn""] = torch.nn.functional
",2
"    epochs = estimator.getEpochs()
",2
"            shuffle_buffer_size = user_shuffle_buffer_size

        cuda_available = torch.cuda.is_available()
",2
"        if last_checkpoint_state is not None:
            model.load_state_dict(last_checkpoint_state['model'])
",2
"
            optimizer.load_state_dict(optimizer_state)

",2
"        if gradient_compression:
            # Pass the compression arg only if it is specified by the user.
            dist_optimizer_args['compression'] = gradient_compression
        # Horovod: wrap optimizer with DistributedOptimizer.
        optimizer = hvd.DistributedOptimizer(**dist_optimizer_args)
",2
"
",2
"            # setting num_epochs=None will cause an infinite iterator
            # and enables ranks to perform training and validation with
            # unequal number of samples
            with reader_factory(remote_store.train_data_path,
                                num_epochs=None,
",2
"                                cur_shard=hvd.rank(),
                                reader_pool_type='process',
                                workers_count=train_reader_worker_count,
                                shard_count=hvd.size(),
",2
"                                    num_epochs=None,
                                    cur_shard=hvd.rank(),
                                    reader_pool_type='process',
                                    workers_count=val_reader_worker_count,
                                    shard_count=hvd.size(),
",2
"                            labels = [label.cuda() for label in labels]
                            if sample_weights:
                                sample_weights = sample_weights.cuda()
                        return inputs, labels, sample_weights
",2
"                                  format(epoch=epoch,
                                         batch_idx=batch_idx,
",2
"                            metric_value_groups = construct_metric_value_holders(
                                metric_cls, metric_fn_groups, label_columns, hvd)

",2
"                                inputs, labels, sample_weights = prepare_batch(row)
",2
"                                    outputs, labels, loss_weights, loss_fns, sample_weights)
                                val_loss.update(loss)
                                update_metrics(metric_value_groups, outputs, labels)
                                print_metrics(batch_idx, val_loss, metric_value_groups, 'val')
                            return aggregate_metrics('val', epoch, val_loss, metric_value_groups)
",2
"                            # Save model after every epoch
",2
"
    return train

",2
"
",2
"        optimizer_state = current_optimizer.state_dict()
        # scale down the learning rate with the number of horovod workers
",2
"        for i in range(len(optimizer_state['param_groups'])):
            optimizer_state['param_groups'][i]['lr'] = \
                optimizer_state['param_groups'][i]['lr'] / hvd.size()
        optimizer = optimizer_cls(model.parameters(), lr=1)
        optimizer.load_state_dict(optimizer_state)
",2
"        Determines the shuffling buffer size such that each worker gets at most 1GB for shuffling
",2
"        memory_cap_gb = 4
        machine1: 8 workers
        machine2: 3 workers
        shuffle_buffer_size = 0.5 GB
",2
"
        example 2:
        memory_cap_gb = 4
            machine1: 2 workers
            machine2: 3 workers
",2
"
        if max_local_size > TOTAL_BUFFER_MEMORY_CAP_GIB:
            shuffle_buffer_size = TOTAL_BUFFER_MEMORY_CAP_GIB * BYTES_PER_GIB / avg_row_size / max_local_size
",2
"

",2
"            metric_group_val = []
            for label_col in label_columns:
",2
"    return construct_metric_value_holders


def _metric_cls():
    # Horovod: average metrics from distributed training.
",2
"    class Metric(object):
",2
"
def _prepare_np_data_fn():
    def prepare_np_data(rows, col_name, metadata):
",2
"        num_rows = rows.shape[0]
        dense_rows = torch.zeros([num_rows, shape])
        for r in range(num_rows):
            size = rows[r][0].long()
            dense_rows[r][rows[r][1:size + 1].long()] = \
",2
"        all_metric_groups_values = []
        for metric_value_group in metric_value_groups:
            metric_avgs = {}
            for metric in metric_value_group:
",2
"        """"""
        metric_value_groups is a list of metric functions. For example, for a model with 3
        outputs, we can define these two metric groups
        [
",2
"        ]

        In this example, first metric group provides only one metric function. This
        function will be used to calculate the metric on all of the model outputs. Second
",2
"        for metric_fn_group, metric_value_group in zip(metric_fn_groups, metric_value_groups):
            if len(metric_fn_group) == 1:
                _metric_fn_group = [metric_fn_group[0] for _ in range(num_outputs)]
            else:
",2
"            # samples with identical weights but in different batches will not be equal on
            # the calculated gradients.
            losses = []
            for output, label, loss_fn, loss_weight in zip(outputs, labels,
",2
"                                                           loss_fns, loss_weights):
                weight_adjusted_sample_losses = \
                    loss_fn(output, label, reduction='none').flatten() * sample_weights
",2
"            losses = [loss_fn(output, label) * loss_weight for
                      output, label, loss_fn, loss_weight in
                      zip(outputs, labels, loss_fns, loss_weights)]

        loss = sum(losses)
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
",2
"
",2
"    task = task_service.HorovodRunTaskService(index, settings.key, settings.nics)
",2
"                             task.addresses(),
                             host_hash.host_hash())
        task.wait_for_initial_registration(settings.start_timeout)
        # Tasks ping each other in a circular fashion to determine interfaces
",2
"        # reachable within the cluster.
        next_task_index = (index + 1) % num_hosts
        next_task_addresses = driver.all_task_addresses(next_task_index)
",2
"    if len(sys.argv) != 5:
        print('Usage: {} <index> <num_hosts> <driver_addresses> <settings>'.format(sys.argv[0]))
        sys.exit(1)

",2
"    index = codec.loads_base64(sys.argv[1])
    num_hosts = codec.loads_base64(sys.argv[2])
",2
"    driver_addresses = codec.loads_base64(sys.argv[3])
    settings = codec.loads_base64(sys.argv[4])
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
",2
"    def write(self, text):
",2
"            'HOROVOD_CROSS_SIZE={cross_size} '
                .format(hostname=host_name,
",2
"    return slot_info_to_command


def _create_elastic_worker_fn(exec_command, run_command, env, event):
",2
"    return create_worker

",2
"            'Size':2, 'Local_size':1, 'Cross_size':2},
",2
"        {'Hostname':'worker-1', 'Rank': 1, 'Local_rank': 0, 'Cross_rank':1,
            'Size':2, 'Local_size':1, 'Cross_size':2}
",2
"    :type remote_host_names: set
    :param _run_command: command to execute
    :type _run_command: string
    :return:
",2
"        local_addresses = network.get_local_host_addresses()
        if host_address not in local_addresses:
            command = 'ssh -o StrictHostKeyChecking=no {host} {ssh_port_arg} ' \
                      '{local_command}'\
",2
"                .format(host=host_name,
                        ssh_port_arg=ssh_port_arg,
",2
"            print(command)

        # Redirect output if requested
        stdout = stderr = None
        stdout_file = stderr_file = None
",2
"            stdout = MultiFile([sys.stdout, stdout_file])
            stderr = MultiFile([sys.stderr, stderr_file])

        try:
",2
"                elastic='HOROVOD_ELASTIC=1 ' if elastic else '',
",2
"    if settings.output_filename:
        _mkdir_p(settings.output_filename)

    # start global rendezvous server and get port that it is listening on
    rendezvous = RendezvousServer(settings.verbose)
",2
"    # This function exists for the purpose of mocking in tests
    return 2 if settings.elastic and not settings.nics else 1

",2
"    res = driver.get_results()
    driver.stop()
    rendezvous.stop_server()

",2
"                               .format(name=name, code=exit_code))
# Copyright IBM Corp. 2020. All Rights Reserved.
#
",2
"# Unless required by applicable law or agreed to in writing, software
",2
"    Args:
        settings: Settings for running jsrun.
",2
"    """"""
    mpi_impl_flags, _ = _get_mpi_implementation_flags(settings.tcp_flag)
    if mpi_impl_flags is None:
        raise Exception(_MPI_NOT_FOUND_ERROR_MSG)
",2
"            'Please, make sure you are running on a cluster with jsrun installed or '
            'use one of the other launchers.')

    if nics and 'NCCL_SOCKET_IFNAME' not in env:
",2
"    if settings.run_func_mode:
        exit_code = safe_shell_exec.execute(jsrun_command, env=env, stdout=stdout, stderr=stderr)
        if exit_code != 0:
",2
"    host_list = (x.split(':') for x in settings.hosts.split(','))
",2
"        slots = int(slots)
        if slots > lsf.LSFUtils.get_num_gpus():
",2
"        validated_list.append((host, needed_slots))
        remaining_slots -= needed_slots
",2
"                tmp.write('rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\n'.format(
",2
"                    rank=rank,
                    host=host,
                    scpu=cpu_val,
                    ecpu=cpu_val + cpu_per_gpu - 1
                ))
",2
"                rank += 1
",2
"
",2
"

# Cached information of horovod functions be stored in this directory
CACHE_FOLDER = os.path.join(os.path.expanduser('~'), '.horovod')
",2
"
",2
"def _check_all_hosts_ssh_successful(host_addresses, ssh_port=None):
    """"""
    checks if ssh can successfully be performed to all the hosts.
",2
"    :param host_addresses: list of addresses to ssh into. for example,
",2
"        ['worker-0','worker-1']
        ['10.11.11.11', '10.11.11.12']
    :type host_addresses: list(strings)
",2
"            try:
                exit_code = safe_shell_exec.execute(command,
",2
"                output.close()
",2
"    ssh_port_arg = '-p {ssh_port}'.format(
",2
"        ssh_port=ssh_port) if ssh_port else ''

",2
"            ssh_successful_to_all_hosts = False
",2
"    if not ssh_successful_to_all_hosts:
        exit(1)
    return True


",2
"def check_build(verbose):
    def get_check(value):
",2
"        [{mpi_ops}] MPI
        [{gloo_ops}] Gloo\
",2
"               ddl_ops=get_check(ddl_built(verbose=verbose)),
",2
"               mpi_ops=get_check(mpi_built(verbose=verbose)),
",2
"                default=default,
                type=type,
                choices=choices,
                required=required,
                help=help)
",2
"                     help=None):
            super(StoreOverrideBoolAction, self).__init__(
                option_strings=option_strings,
                dest=dest,
",2
"
    parser.add_argument('-p', '--ssh-port', action='store', dest='ssh_port',
",2
"                             'horovodrun is called.')

    parser.add_argument('--start-timeout', action='store',
",2
"                        dest='start_timeout', type=int,
                        help='Horovodrun has to perform all the checks and '
                             'start the processes before the specified '
                             'timeout. The default value is 30 seconds. '
",2
"    parser.add_argument('--network-interface', action='store', dest='nics',
                        help='Network interfaces that can be used for communication separated by '
                             'comma. If not specified, Horovod will find the common NICs among all '
                             'the workers and use it; example, --network-interface ""eth0,eth1"".')

",2
"                                   '(default: 5')
    group_params.add_argument('--cache-capacity', action=make_override_action(override_args), type=int,
",2
"                                                   'between equal local ranks across workers, and finally a '
                                                   'local gather.')
    group_hierarchical_allreduce.add_argument('--no-hierarchical-allreduce', dest='hierarchical_allreduce',
                                              action=make_override_false_action(override_args),
                                              help='Explicitly disable hierarchical allreduce to prevent autotuning '
",2
"                                              action=make_override_false_action(override_args),
                                              help='Explicitly disable hierarchical allgather to prevent autotuning '
                                                   'from adjusting it.')
",2
"    group_autotune.add_argument('--autotune-steps-per-sample', action=make_override_action(override_args),
                                type=int, default=10,
                                help='Number of steps (approximate) to record before observing a sample. The sample '
                                     'score is defined to be the median score over all batches within the sample. The '
                                     'more batches per sample, the less variance in sample scores, but the longer '
",2
"                                     'autotuning will take. (default: %(default)s)')
    group_autotune.add_argument('--autotune-bayes-opt-max-samples', action=make_override_action(override_args),
                                type=int, default=20,
",2
"                                    'more instances to become available. Defaults to --num-proc.')
    group_elastic.add_argument('--max-np', action='store', dest='max_np', type=int,
                               help='Maximum number of training processes, beyond which no additional '
                                    'processes will be created. If not specified, then will be unbounded.')
",2
"    group_elastic.add_argument('--slots-per-host', action='store', dest='slots', type=int,
                               help='Number of slots for processes per host. Normally 1 slot per GPU per host. '
                                    'If slots are provided by the output of the host discovery script, then '
                                    'that value will override this parameter.')
    group_elastic.add_argument('--elastic-timeout', action='store', dest='elastic_timeout', type=int,
",2
"                                    'The default value is 600 seconds. Alternatively, '
",2
"    group_stall_check.add_argument('--stall-check-shutdown-time-seconds', action=make_override_action(override_args),
",2
"                                       'They need to be passed with the equal sign to avoid parsing issues. '
                                       'e.g. --mpi-args=""--map-by ppr:6:node""')
",2
"                                       type=int, default=30,
",2
"                                         help='Hide the timestamp from Horovod log messages.')
    group_logging_timestamp.add_argument('--no-log-hide-timestamp', dest='log_hide_timestamp',
                                         action=make_override_false_action(override_args), help=argparse.SUPPRESS)

",2
"                             help='List of host names and the number of available slots '
                                  'for running processes on each, of the form: <hostname>:<slots> '
                                  '(e.g.: host1:2,host2:4,host3:1 indicating 2 processes can run on host1, '
                                  '4 on host2, and 1 on host3). If not specified, defaults to using '
                                  'localhost:<np>')
",2
"class HorovodArgs(object):
    def __init__(self):
        self.np = 1
        self.check_build = None
",2
"        self.nic = None
        self.output_filename = None
        self.verbose = None
",2
"        self.config_file = None
        self.nics = None
",2
"                                     ssh_port=args.ssh_port,
                                     extra_mpi_args=args.mpi_args,
                                     tcp_flag=args.tcp_flag,
                                     binding_args=args.binding_args,
                                     key=secret.make_secret_key(),
",2
"                                     start_timeout=tmout,
                                     num_proc=args.np,
",2
"
    # This cache stores the results of checks performed by horovod
    # during the initialization step. It can be disabled by setting
",2
"    # --disable-cache flag.
    fn_cache = None
    if not args.disable_cache:
",2
"        command = [sys.executable, '-m', 'horovod.run.run_task', str(driver_ip), str(run_func_server_port)]

",2
"    if args.host_discovery_script:
        discover_hosts = discovery.HostDiscoveryScript(args.host_discovery_script, args.slots)
    elif args.hosts:
        _, available_host_slots = parse_hosts_and_slots(args.hosts)
",2
"        # Lookup default timeout from the environment variable.
        start_timeout = int(os.getenv('HOROVOD_START_TIMEOUT', '30'))
",2
"                                                start_timeout=tmout,
                                                elastic_timeout=args.elastic_timeout,
",2
"        raise ValueError('Gloo support is required to use elastic training, but has not been built.  Ensure CMake is '
                         'installed and reinstall Horovod with HOROVOD_WITH_GLOO=1 to debug the build error.')

",2
"def is_gloo_used(use_gloo=None, use_mpi=None, use_jsrun=None):
    # determines whether run_controller will run gloo
    # for the given (use_gloo, _, use_mpi, _, use_jsrun, _, _)
",2
"        elif gloo_built(verbose=verbose):
            gloo_run()
        else:
            raise ValueError('Neither MPI nor Gloo support has been built. Try reinstalling Horovod ensuring that '
",2
"    def gloo_run_fn():
        driver_ip = network.get_driver_ip(nics)
        gloo_run(settings, nics, env, driver_ip, command)

    def mpi_run_fn():
",2
"        mpi_run(settings, nics, env, command)

    def js_run_fn():
        js_run(settings, nics, env, command)
",2
"
    run_controller(args.use_gloo, gloo_run_fn,
                   args.use_mpi, mpi_run_fn,
                   args.use_jsrun, js_run_fn,
",2
"            args.hosts = 'localhost:{np}'.format(np=args.np)

",2
"
",2
"def run(
        func,
",2
"        args=(),
        kwargs=None,
        np=1,
        min_np=None,
",2
"
    :param func: The function to be run in Horovod job processes. The function return value will
",2
"    :param args: Arguments to pass to `func`.
    :param kwargs: Keyword arguments to pass to `func`.
    :param np: Number of Horovod processes.
",2
"    :param hostfile: Path to a host file containing the list of host names and the number of
                     available slots. Each line of the file must be of the form:
",2
"                          timeout. The default value is 30 seconds.
                          Alternatively, The environment variable
",2
"                          Otherwise, all the checks will run every time
                          horovodrun is called.'
    :param output_filename: For Gloo, writes stdout / stderr of all processes to a filename of the form
                            <output_filename>/rank.<rank>/<stdout | stderr>. The <rank> will be padded with 0
                            characters to ensure lexicographical order.
",2
"                    be the default if Horovod was built with MPI support.
    :param mpi_args: Extra arguments for the MPI controller. This is only used when use_mpi is True.
    :param network_interface: Network interfaces to use for communication separated by comma. If
                             not specified, Horovod will find the common NICs among all the
",2
"                             workers and use those; example, eth0,eth1.
    :return: Return a list which contains values return by all Horovod processes.
",2
"             The index of the list corresponds to the rank of each Horovod process.
",2
"    def wrapped_func():
        return func(*args, **kwargs)

",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"                           ' MPI distribution (usually mpirun, srun, or jsrun).\n'
                           '3. Use built-in gloo option (horovodrun --gloo ...).')

",2
"def mpi_available():
",2
"    command as the only argument and returns (output, exit code). Output
    represents the stdout and stderr as a string.
",2
"    (output, exit_code) = res

    if exit_code == 0:
        if 'Open MPI' in output or 'OpenRTE' in output:
            return _OMPI_IMPL
",2
"        return list(_MPICH_FLAGS), list(_NO_BINDING_ARGS)
    else:
        return None, None
",2
"        '{nccl_socket_intf_arg} '
        '{output_filename_arg} '
        '{env} {extra_mpi_args} {command}'  # expect a lot of environment variables
        .format(num_proc=settings.num_proc,
                hosts_arg=hosts_arg,
",2
"                output_filename_arg='--output-filename ' + settings.output_filename
",2
"                extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else '',
                command=' '.join(quote(par) for par in command))
    )

",2
"    except BaseException as e:
        sys.stderr.write(""User function raise error: {error}"".format(error=str(e)))
        raise e
",2
"    put_data_into_kvstore(addr, port, 'runfunc_result', str(rank), ret_val)
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"        return ""LSB_JOBID"" in os.environ

",2
"    @staticmethod
",2
"            if exit_code != 0:
                raise RuntimeError(
",2
"            exit_code = safe_shell_exec.execute(""{cmd} -n {node}"".format(
                cmd=LSFUtils._CSM_NODE_QUERY,
                node=LSFUtils._csm_allocation_info[""compute_nodes""][0]),
                stdout=output, stderr=output)
            if exit_code != 0:
",2
"    def get_num_gpus():
        """"""Returns the number of gpus per node.""""""
",2
"        return len(LSFUtils.get_compute_hosts()) * LSFUtils.get_num_gpus()

    @staticmethod
    @_cache
",2
"        exit_code = safe_shell_exec.execute(lscpu_cmd, stdout=output, stderr=output)
        if exit_code != 0:
",2
"        return int(yaml.safe_load(output.getvalue())[LSFUtils._THREAD_KEY])
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"    args_list.
    :param fn: function to be executed
    :type fn:
",2
"                if t.is_alive():
                    have_alive_child = True

        results = {}
        while not result_queue.empty():
",2
"    return results


def in_thread(target, args=(), name=None, daemon=True, silent=False):
",2
"            except:
                pass
    else:
",2
"    That threat can be stopped by setting the optional stop event.
",2
"    Exceptions will silently be swallowed when silent is True.

    :param event: event that triggers func
    :type event: threading.Event
    :param func: function to trigger
",2
"    :param args: function arguments
    :param stop: event to stop thread
    :type stop: threading.Event
    :param check_interval_seconds: interval in seconds to check the stop event
    :type check_interval_seconds: float
",2
"                event.wait(timeout=check_interval_seconds)
            if not stop.is_set():
                func(*args)

    return in_thread(fn, silent=silent)
",2
"# ==============================================================================

import psutil
",2
"import socket

from socket import AF_INET
",2
"            continue
        for addr in addrs:
            if addr.family == AF_INET and addr.address == '127.0.0.1':
                common_intfs.add(iface)
                break
",2
"    except socket.gaierror:
        return None


",2
"
    args_list = [[host] for host in all_host_names]
    host_addresses = threads.execute_function_multithreaded(
",2
"        resolve_host_address, args_list)

    # host_addresses is a map
    remote_host_names = []
    for i in range(len(all_host_names)):
",2
"        host_address = host_addresses[i]
        host_name = all_host_names[i]
",2
"        try:
",2
"    """"""
    :param nics: object return by `_driver_fn`
    :return: driver ip. We make sure all workers can connect to this ip.
",2
"    iface = list(nics)[0]
    driver_ip = None
    for addr in net_if_addrs()[iface]:
",2
"    if not driver_ip:
        raise RuntimeError(
            'Cannot find an IPv4 address of the common interface.')
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"# ==============================================================================

import datetime
import errno
import os
",2
"
    def __init__(self, cache_folder, cache_staleness_threshold_in_minutes,
                 parameters_hash):
        # Protocol version 0 is the original ""human-readable"" protocol and is
",2
"        # compatible with earlier python 2 and 3.
        self._pickle_protocol = 0
        self._cache_file = os.path.join(cache_folder, 'cache.bin')
        try:
            # If folder exists, does not do anything.
",2
"                print(
                    'There is an error with reading cache file. You '
                    'can delete the corrupt file: {cache_file}.'.format(
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# Unless required by applicable law or agreed to in writing, software
",2
"

",2
"            raise Exception(self._message.format(activity=activity))
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"
def terminate_executor_shell_and_children(pid):
",2
"        try:
",2
"    # Wait for graceful termination.
",2
"            pass


def forward_stream(src_stream, dst_stream, prefix, index):
",2
"            time=localtime,
            rank=str(rank),
            prefix=prefix,
",2
"
",2
"
        if not isinstance(text, str):
",2
"            text = text.decode('utf-8')

",2
"                line_buffer = ''
",2
"    # Make a pipe for the subprocess stdout/stderr.
    (stdout_r, stdout_w) = ctx.Pipe()
    (stderr_r, stderr_w) = ctx.Pipe()

",2
"        while True:
            try:
",2
"    finally:
        stop.set()

    stdout_fwd.join()
    stderr_fwd.join()
",2
"

def loads_base64(encoded):
    decoded = base64.b64decode(encoded)
",2
"# You may obtain a copy of the License at
#
",2
"
import psutil
import queue
import socket
import socketserver
",2
"
",2
"        self.service_name = service_name
        """"""Service name that responded to this ping.""""""
        self.source_address = source_address
        """"""Source IP address that was visible to the service.""""""
",2
"

class AckResponse(object):
    """"""Used for situations when the response does not carry any data.""""""
    pass
",2
"
    The objects are serialized using cloudpickle. Serialized objects become
    the body of the message.

    Structure of the message is as follows:
",2
"    - HMAC digest of the body (32 bytes)
    - length of the body (4 bytes)
",2
"    def write(self, obj, wfile):
",2
"        wfile.write(message)
        wfile.flush()

",2
"    def read(self, rfile):
        digest = rfile.read(secret.DIGEST_LENGTH)
",2
"class BasicService(object):
    def __init__(self, service_name, key, nics):
        self._service_name = service_name
",2
"        self._wire = Wire(key)
",2
"            def handle(self):
                try:
                    req = server._wire.read(self.rfile)
                    resp = server._handle(req, self.client_address)
                    if not resp:
",2
"                except EOFError:
                    # Happens when client is abruptly terminated, don't want to pollute the logs.
                    pass
",2
"
    def _handle(self, req, client_address):
        if isinstance(req, PingRequest):
            return PingResponse(self._service_name, client_address[0])
",2
"        result = {}
        for intf, intf_addresses in psutil.net_if_addrs().items():
            if self._nics and intf not in self._nics:
",2
"        self._wire = Wire(key)
",2
"            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(self._probe_timeout)
            try:
                sock.connect(addr)
                rfile = sock.makefile('rb')
",2
"                                resp_intf = ''
                                for key in psutil.net_if_addrs().keys():
                                    key_intf_addrs = [x.address
                                                      for x in psutil.net_if_addrs().get(key, [])]
",2
"
    def _send_one(self, addr, req):
        for iter in range(self._attempts):
",2
"            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            try:
                sock.connect(addr)
",2
"                    raise
            finally:
                sock.close()

    def _send(self, req):
",2
"        # Since all the addresses were vetted, use the first one.
        addr = list(self._addresses.values())[0][0]
        return self._send_one(addr, req)
",2
"
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"        hostname, slots = host_string.strip().split(':')
        return HostInfo(hostname, int(slots))


",2
"    :param hosts_string: list of addresses and number of processes on each host.
        For example:
            - 'worker-0:2,worker-1:2'
",2
"            - '10.11.11.11:4,10.11.11.12:4'
",2
"    """"""
    rank = 0
    alloc_list = []

    # key: local_rank; value: cross_size for this local_rank
",2
"                    rank,
                    local_rank,
",2
"
    if rank < min_np:
        raise ValueError('Requested more processes ({}) than there are available slots ({})'
                         .format(min_np, rank))
",2
"    for alloc_item in alloc_list:
",2
"HOROVOD_STALL_SHUTDOWN_TIME_SECONDS = 'HOROVOD_STALL_SHUTDOWN_TIME_SECONDS'

# Library options knobs
HOROVOD_MPI_THREADS_DISABLE = 'HOROVOD_MPI_THREADS_DISABLE'
HOROVOD_NUM_NCCL_STREAMS = 'HOROVOD_NUM_NCCL_STREAMS'
",2
"NCCL_IB_DISABLE = 'NCCL_IB_DISABLE'
",2
"
",2
"

def set_args_from_config(args, config, override_args):
",2
"        _set_arg_from_config(args, 'hierarchical_allgather', override_args, params)

",2
"
",2
"
    # Stall Check
",2
"        _set_arg_from_config(args, 'ccl_bgt_affinity', override_args, library_options)
        _set_arg_from_config(args, 'gloo_timeout_seconds', override_args, library_options)

    # Logging
    logging = config.get('logging')
",2
"
    _validate_arg_nonnegative(args, 'stall_check_warning_time_seconds')
    _validate_arg_nonnegative(args, 'stall_check_shutdown_time_seconds')
    _validate_arg_nonnegative(args, 'num_nccl_streams')
",2
"

",2
"def set_env_from_args(env, args):
    def identity(value):
        return 1 if value else 0

",2
"    _add_arg_to_env(env, HOROVOD_HIERARCHICAL_ALLREDUCE, args.hierarchical_allreduce, identity)
    _add_arg_to_env(env, HOROVOD_HIERARCHICAL_ALLGATHER, args.hierarchical_allgather, identity)

",2
"
",2
"    _add_arg_to_env(env, HOROVOD_CCL_BGT_AFFINITY, args.ccl_bgt_affinity)
    _add_arg_to_env(env, HOROVOD_GLOO_TIMEOUT_SECONDS, args.gloo_timeout_seconds)

    # Logging
    _add_arg_to_env(env, HOROVOD_LOG_LEVEL, args.log_level)
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
# ==============================================================================

import hashlib
import os
",2
"    Computes a hash that represents this host, a unit of processing power that shares memory.

    The hash contains the part of the hostname, e.g. `host` for hostname `host.example.com`,
    plus a hash derived from the full hostname and further information about this machine.

",2
"    container = os.environ.get(""CONTAINER_ID"")
    if container is not None:
        host_info = '{host_info}-{container}'.format(host_info=host_info, container=container)

    return '{host}-{hash}'.format(host=host, hash=_hash(host_info))
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
# ==============================================================================

",2
"    def __init__(self, delay):
",2
"
class WaitForCommandExitCodeResponse(object):
    def __init__(self, exit_code):
",2
"    pass


",2
"
    def __init__(self, result):
",2
"            if value is None:
                if key in env:
                    del env[key]
            else:
",2
"                self._wait_cond.release()
            return network.AckResponse()
",2
"            try:
                terminated = (self._command_thread is not None and
                              not self._command_thread.is_alive())
                return CommandExitCodeResponse(terminated,
                                               self._command_exit_code if terminated else None)
",2
"                while self._command_thread is None or self._command_thread.is_alive():
                    self._wait_cond.wait(req.delay if req.delay >= 1.0 else 1.0)
                return WaitForCommandExitCodeResponse(self._command_exit_code)
            finally:
                self._wait_cond.release()
",2
"        return super(BasicTaskService, self)._handle(req, client_address)

",2
"        self._wait_cond.acquire()
        try:
",2
"        super(BasicTaskClient, self).__init__(service_name,
",2
"        :type delay: float
",2
"        """"""
        self.wait_for_command_exit_code(delay)

    def wait_for_command_exit_code(self, delay=1.0):
        """"""
",2
"
        :param delay: delay in seconds
        :type delay: float
        """"""
        try:
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"

class RegisterTaskToTaskAddressesRequest(object):
",2
"                                    source=client_address[0]))
                # Make host hash -> indices map.
                if req.host_hash not in self._task_host_hash_indices:
",2
"
        if isinstance(req, AllTaskAddressesRequest):
",2
"        for intf, intf_addresses in addresses.items():
            for ip, port in intf_addresses:
                if ip == target_ip:
",2
"        try:
",2
"        finally:
",2
"    def wait_for_task_to_task_address_updates(self, timeout):
        self._wait_cond.acquire()
        try:
",2
"        """"""Task index.""""""

        self.task_addresses = task_addresses
        """"""Map of interface to list of (ip, port) pairs.""""""

",2
"
    def register_task(self, index, task_addresses, host_hash):
        self._send(RegisterTaskRequest(index, task_addresses, host_hash))

    def all_task_addresses(self, index):
",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
# ==============================================================================

import os
import threading
",2
"    def __init__(self, timestamp):
        self.timestamp = timestamp


",2
"class WorkerNotificationManager(object):
    def __init__(self):
        self._lock = threading.Lock()
        self._service = None
        self._listeners = set()
",2
"             nic=None, hostname=None, local_rank=None):
        with self._lock:
            if self._service:
                return
",2
"        self._listeners.add(listener)

    def remove_listener(self, listener):
        self._listeners.remove(listener)

",2
"    def __init__(self, addresses, key, verbose, match_intf=False):
        super(WorkerNotificationClient, self).__init__(WorkerNotificationService.NAME,
                                                       addresses,
",2
"        self._results = {}
        self._worker_threads = queue.Queue()

    def expect(self, worker_thread):
",2
"        if key in self._results:
            return
        self._results[key] = value
",2
"
    def get_results(self):
",2
"        return self._results


class ElasticDriver(object):
",2
"    def __init__(self, rendezvous, discovery, min_np, max_np, timeout=None, verbose=0):
        self._rendezvous = rendezvous
",2
"        self._activate_workers(np)

",2
"        self._shutdown.set()
",2
"            addresses, secret_key, self._verbose)

",2
"
    def world_size(self):
        return self._world_size

    def local_size(self, host):
",2
"
    def get_slot_info(self, host, slot):
        return self._host_assignments[host][slot] if self.has_rank_assignment(host, slot) \
            else hosts.INVALID_SLOT_INFO

",2
"    def host_assignments(self):
",2
"        try:
            while True:
",2
"                    raise RuntimeError('Job has been shutdown, see above error messages for details.')
",2
"        first_update = True
        while not self._shutdown.is_set():
            self._wait_hosts_cond.acquire()
            try:
",2
"
        coordinator_client = self.get_worker_client(coordinator_slot_info)
        if not coordinator_client:
",2
"            logging.debug('no coordinator client, skipping notifications')
            return

        timestamp = _epoch_time_s()
",2
"            if self._verbose >= 2:
",2
"            self._start_worker_process(slot_info)

    def _start_worker_process(self, slot_info):
        create_worker_fn = self._create_worker_fn
",2
"            rendezvous_id = self._worker_registry.record_failure(slot_info.hostname, slot_info.local_rank)

",2
"    @property
",2
"        # TODO(travis): also check for hosts removed from the blacklist in the future
        prev_host_slots = self._current_hosts.host_slots
        prev_host_assignment_order = self._current_hosts.host_assignment_order
        host_slots = self._discovery.find_available_hosts_and_slots()
        if prev_host_slots != host_slots:
",2
"                                                  host_assignment_order=host_assignment_order)
            return True
        return False
",2
"        known_hosts = set(host_assignment_order)
        for host in available_hosts:
            if host not in known_hosts:
                host_assignment_order.append(host)
        return host_assignment_order
",2
"        self._host_slots = host_slots
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

",2
"        super(ElasticSettings, self).__init__(elastic=True, **kwargs)
        self.discovery = discovery
        self.min_np = min_np
",2
"        self._barrier = None
",2
"        self._rendezvous_id = 0
        self._verbose = verbose
        self._size = 0

",2
"        return len(self._workers[state])

",2
"        return self._size

    def last_rendezvous(self):
        return self._rendezvous_id

",2
"
    def record_failure(self, host, slot):
        return self._record_state(host, slot, FAILURE)

    def _record_state(self, host, slot, state):
",2
"
        key = (host, slot)
        with self._lock:
            if key in self._states:
                if state == FAILURE:
",2
"                    if saved_state != state:
                        # This worker changed its state, so do not attempt to wait again to avoid double-counting
                        raise RuntimeError('State {} overridden by {}'.format(state, saved_state))

    def _action(self):
",2
"    def _on_workers_recorded(self):
        logging.info('all {} workers recorded'.format(self.size()))

        # Check for success state, if any process succeeded, shutdown all other processes
        if self.count(SUCCESS) > 0:
",2
"        if all([self._host_manager.is_blacklisted(host) for host, slot in self.get_recorded_slots()]):
            logging.error('blacklisted slots count == {} -> stop running'.format(self._size))
            self._driver.stop()
            return

",2
"        try:
            self._driver.resume()
        except Exception:
            logging.exception('failed to activate new hosts -> stop running')
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"# GET methods
GET_RANK_AND_SIZE = 'rank_and_size'

# PUT methods
",2
"                host, local_rank = key.split(':')
                addresses, secret_key = codec.loads_base64(value)
                self._put_worker_addresses(host, int(local_rank), addresses, secret_key)

",2
"    def __init__(self, driver_addresses, key, verbose, match_intf=False):
        super(HorovodRunDriverClient, self).__init__(
            HorovodRunDriverService.NAME,
",2
"        ['10.11.11.11', '10.11.11.12']
",2
"            'eth0': [('11.111.33.73', 34588)]
        }
",2
"    :rtype:
    """"""

",2
"            host_output.close()
        return exit_code
",2
"        else:
            command = \
                'ssh -o StrictHostKeyChecking=no {host} {ssh_port_arg} ' \
                '\'{python} -m horovod.run.task_fn {index} {driver_addresses}' \
",2
"    # the ssh sessions and all the task servers will die as well.
    threads.execute_function_multithreaded(_exec_command,
                                           args_list,
",2
"        ['10.11.11.11', '10.11.11.12']
    :type all_host_names: list(string)
    :param local_host_names: host names that resolve into a local addresses.
    :type local_host_names: set
",2
"    :param settings: the object that contains the setting for running horovod
    :type settings: Horovod.run.common.util.settings.Settings
    :return: example: ['eth0', 'eth1']
    :rtype: list[string]
",2
"    """"""
    # Launch a TCP server called service service on the host running horovod
    driver = HorovodRunDriverService(
",2
"    # Have all the workers register themselves with the service service.
    _launch_task_servers(all_host_names, local_host_names,
                         driver.addresses(), settings)
    if settings.verbose >= 2:
        print('Attempted to launch horovod task servers.')
",2
"                settings.verbose) for index in range(
                settings.num_hosts)]
",2
"        # interfaces that are not really connected to any external networks
        # such as lo0 with address 127.0.0.1.
        if settings.verbose >= 2:
            print('Waiting for hosts to perform host-to-host interface checking.')
",2
"        # Determine a set of common interfaces for task-to-task communication.
        nics = set(driver.task_addresses_for_tasks(0).keys())
        for index in range(1, settings.num_hosts):
            nics.intersection_update(
                driver.task_addresses_for_tasks(index).keys())
",2
"    :param settings: the object that contains the setting for running horovod
",2
"    :type fn_cache: Horovod.run.util.cache.Cache
    :return: List of common interfaces
",2
"    '''
    # Skipping interface discovery for LSF cluster as it slows down considerably the job start
    if lsf.LSFUtils.using_lsf():
",2
"
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"            key, nics)
        self.index = index
        self._task_to_task_address_check_completed = False
",2
"
    def _handle(self, req, client_address):

",2
"
            return TaskToTaskAddressCheckFinishedSignalResponse(self.index)

        return super(HorovodRunTaskService, self)._handle(req, client_address)

",2
"            attempts=attempts)
        self.index = index

",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# =============================================================================
",2
"def read_data_from_kvstore(addr, port, scope, key):
    try:
        url = ""http://{addr}:{port}/{scope}/{key}"".format(
            addr=addr, port=str(port), scope=scope, key=key
        )
",2
"        resp = urlopen(req)
        # TODO: remove base64 encoding because base64 is not efficient
        return codec.loads_base64(resp.read())
",2
"    except (HTTPError, URLError) as e:
",2
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"import threading

from http.server import HTTPServer, SimpleHTTPRequestHandler

",2
"            self.send_status_code(TIMEOUT)
            return

",2
"        self._put_value(scope, key, value)
        self.send_status_code(OK)

",2
"
    def _get_value(self, scope, key):
        with self.server.cache_lock:
",2
"    def do_DELETE(self):
        paths = self.path.split('/')
        if len(paths) < 3:
",2
"            logging.error(
",2
"        # Cache that provides the store
",2
"
        with self.finished_list_lock:
            self.finished_list.clear()
",2
"class RendezvousServer:
    def __init__(self, verbose=0):
        self.httpd = None
        self.listen_thread = None
",2
"        self.verbose = verbose

    # Rendezvous function finds a available port, create http socket,
",2
"    def stop_server(self):
        self.httpd.shutdown()
        self.listen_thread.join()
",2
"class UpdateEpochStateCallback(_impl.UpdateEpochStateCallbackImpl, keras.callbacks.Callback):
",2
"    Keras Callback that will update the value of `state.epoch` with the current epoch number at
    the end of each epoch.
",2
"        super(MetricAverageCallback, self).__init__(K, device)

",2
"    """"""
    Implements gradual learning rate warmup:

",2
"# Copyright 2017 Uber Technologies, Inc. All Rights Reserved.
#
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"from horovod.tensorflow import size
from horovod.tensorflow import local_size
from horovod.tensorflow import rank
",2
"                         sparse_as_dense=False):
    """"""
    An optimizer that wraps another keras.optimizers.Optimizer, using an allreduce to
",2
"    Perform an allreduce on a tensor-compatible value.
",2
"    Perform a broadcast on a tensor-compatible value.
",2
"    """"""
    Loads a saved Keras model with a Horovod DistributedOptimizer.

",2
"    By default, all optimizers in the module `keras.optimizers` will be loaded
    and wrapped without needing to specify any `custom_optimizers` or
",2
"    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)
",2
"# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
",2
"    @staticmethod
",2
"    def decompress(tensor, ctx):
        """"""Decompress the tensor with the given context.""""""
        pass


",2
"    @staticmethod
    def compress(tensor):
        """"""Downcasts the tensor to 16-bit.""""""
",2
"    none = NoneCompressor

    """"""Compress all floating point gradients to 16-bit.""""""
    fp16 = FP16Compressor
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"# limitations under the License.
# ==============================================================================

",2
"from distutils.version import LooseVersion

import tensorflow as tf

",2
"from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables
from horovod.tensorflow.mpi_ops import _executing_eagerly, init, rank, shutdown


",2
"
    When a worker is added or removed, other workers will raise an exception to bring them back to such a sync
    point before executing `func` again. This ensures that workers do not diverge when such reset events occur.

    It's important to note that collective operations (e.g., broadcast, allreduce) cannot be the call to
",2
"    """"""State representation of a TensorFlow Keras model and optimizer.

    Supports TensorFlow 2 models and optimizers, as well as `keras` and `tf.keras`.

",2
"    Args:
        model: TensorFlow Keras model.
        optimizer: Optional optimizer, can be compiled into model instead.
        backend: For TensorFlow v1, backend used by Keras for obtaining the session.
        kwargs: Additional properties to sync, will be exposed as attributes of the object.
",2
"            raise ValueError('Model must be built first. Run `model.build(input_shape)`.')

",2
"
        super(TensorFlowState, self).__init__(bcast_object=broadcast_object_with_session,
",2
"    def sync(self):
        if self.session is not None:
            self.session.run(self._bcast_op)
        self._save_model()
        super(TensorFlowState, self).sync()
",2
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"from tensorflow.python.framework import ops
",2
"local_size = _basics.local_size
rank = _basics.rank
local_rank = _basics.local_rank
mpi_threads_supported = _basics.mpi_threads_supported
mpi_enabled = _basics.mpi_enabled
",2
"
handle_average_backwards_compatibility = get_average_backwards_compatibility_fun(_basics)
",2
"# Please run this function in a subprocess
def _check_has_gpu():
    import tensorflow as tf
    return tf.test.is_gpu_available()

",2
"    """"""
    if name is None and not _executing_eagerly():
        name = 'HorovodAllreduce_%s' % _normalize_name(tensor.name)
    return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op)
",2
"

@ops.RegisterGradient('HorovodAllreduce')
def _allreduce_grad(op, grad):
    """"""Gradient for allreduce op.
",2
"    The concatenation is done on the first dimension, so the input tensors on the
    different processes must have the same rank and shape, except for the first
    dimension, which is allowed to be different.
",2
"    """"""
    if name is None and not _executing_eagerly():
",2
"

def broadcast(tensor, root_rank, name=None):
    """"""An op which broadcasts the input tensor on root rank to the same input tensor
",2
"    if name is None and not _executing_eagerly():
        name = 'HorovodBroadcast_%s' % _normalize_name(tensor.name)
",2
"    return MPI_LIB.horovod_broadcast(tensor, name=name, root_rank=root_rank)


@ops.RegisterGradient('HorovodBroadcast')
def _broadcast_grad(op, grad):
",2
"    """"""Gradient for broadcast op.

    Args:
      op: An operation.
",2
"    grad_reduced = _allreduce(grad)
    if rank() != root_rank:
        return grad_reduced * 0
    return grad_reduced
",2
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",2
"from horovod.tensorflow.mpi_ops import Average, Sum, Adasum
",2
"
    Arguments:
        tensor: tf.Tensor, tf.Variable, or tf.IndexedSlices to reduce.
                The shape of the input must be identical across all ranks.
",2
"        device_sparse: Device to be used for sparse tensors. Uses GPU by default
                       if Horovod was built with HOROVOD_GPU_OPERATIONS.
        compression: Compression algorithm used to reduce the amount of data
                     sent and received by each worker node.  Defaults to not
",2
"    """"""
    op = handle_average_backwards_compatibility(op, average)
    # Averaging happens in framework code, so translate that to Sum for the actual call
    true_op = Sum if op == Average else op

",2
"                    else:
                        warnings.warn('Adasum reduction does not currently support GPU reduction using MPI. Tensors '
                                      'are copied to CPU memory instead. To use Adasum for GPU reduction, please '
                                      'compile Horovod with HOROVOD_GPU_OPERATIONS=NCCL.')
",2
"
if _global_variables is not None:
    def broadcast_global_variables(root_rank):
        """"""Broadcasts all global variables from root rank to all other processes.
",2
"except AttributeError:
    try:
",2
"        _SessionRunHook = tf.train.SessionRunHook
    except AttributeError:
        _SessionRunHook = None
",2
"            self.bcast_op = None
            self.device = device

",2
"
    if _executing_eagerly():
        return _make_subgraph(allreduce_grads)
    else:
        return allreduce_grads
",2
"    try:
        # TensorFlow 1.x
        _LegacyOptimizer = tf.train.Optimizer
    except AttributeError:
        # Future TensorFlow versions
",2
"        """"""An optimizer that wraps another tf.Optimizer, using an allreduce to
        combine gradient values before applying gradients to model weights.""""""

",2
"            super(_DistributedOptimizer, self).__init__(name=name, use_locking=use_locking)

",2
"            gradients = self._optimizer.compute_gradients(*args, **kwargs)
            if size() > 1 or os.environ.get('HOROVOD_ELASTIC') == '1':
                grads, vars = zip(*gradients)
                avg_grads = self._allreduce_grads(grads)
",2
"
    class _DistributedAdasumOptimizer(_LegacyOptimizer):
        """"""An optimizer that wraps another tf.Optimizer, using an allreduce to
        combine model deltas after applying gradients to model weights.""""""

",2
"        def __init__(self, optimizer, name=None, use_locking=False, device_dense='',
",2
"            # initialize start on the first step
            assign_op = tf.cond(self._is_first_step, 
                lambda: start_slot.assign(var, use_locking=self.use_locking).op, 
                tf.no_op)
            
",2
"                    def update():
                        # delta = var - start
                        local_delta = var.assign_sub(start_slot, use_locking=self.use_locking) # reuse var's memory
                        # delta = allreduce (delta)
",2
"                                                 device_dense=self._device_dense,
",2
"                                                 device_sparse=self._device_sparse,
",2
"                        return var.assign(new_start, use_locking=self.use_locking).op
                    
                    # if its a communication step, then apply logic above
",2
"                    # if its not a communication step then just have the underlying
                    # optimizer update the model parameters according to its logic
",2
"
        def get_slot_names(self):
            """"""Appends local slot names to those of the underlying optimizer.""""""
            return super(_DistributedAdasumOptimizer, self).get_slot_names() +\
",2
"        Device to be used for dense tensors. Uses GPU by default
        if Horovod was built with HOROVOD_GPU_OPERATIONS.
      device_sparse:
        Device to be used for sparse tensors. Uses GPU by default
        if Horovod was built with HOROVOD_GPU_OPERATIONS.
",2
"        different ranks.
    """"""
    if isinstance(optimizer, _LegacyOptimizer):
",2
"                                          compression, sparse_as_dense)
    else:
        raise ValueError('Provided optimizer doesn\'t inherit from either legacy '
                         'TensorFlow or Keras optimizer: %s' % optimizer)

",2
"            if size() > 1 or os.environ.get('HOROVOD_ELASTIC') == '1':
                return self._allreduce_grads(gradients)
            else:
",2
"                       sparse_as_dense, op, gradtape._persistent,
",2
"                       gradtape._watch_accessed_variables)
        else:
            return cls(gradtape._tape, device_dense, device_sparse, compression,
                       sparse_as_dense, op, gradtape._persistent)
# Copyright 2020 Uber Technologies, Inc. All Rights Reserved.
",2
"
",2
"

",2
"@_cache
def _make_broadcast_group_fn():
    if _executing_eagerly():
        # Eager mode will parallelize independent control flow
        def broadcast_group(variables, root_rank):
",2
"              type.
    Returns:
        The object that was broadcast from the `root_rank`.
    """"""
",2
"            return v.numpy()

    if rank() == root_rank:
        b = io.BytesIO()
        cloudpickle.dump(obj, b)
",2
"        sz = to_numpy(broadcast(sz, root_rank, name + '.sz'))
",2
"    t = tf.placeholder(tf.uint8, [None], name='bcast_object_data')
    bcast_data = broadcast(t, root_rank, name + '.t')
",2
"            t_ = bytearray(b.getvalue())
            sz_ = [len(t_)]
",2
"    return _bcast
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"def _make_subgraph(f):
    if hasattr(tf, 'function'):
        # TensorFlow 1.14.0+
",2
"        if key in cache:
            return cache[key]
",2
"#if HAVE_GPU
#include ""tensorflow/stream_executor/stream.h""
#endif

",2
"#define OMPI_SKIP_MPICXX
#include ""../common/operations.h""
",2
"  }
}
",2
"  TFPersistentBuffer(OpKernelContext* context, int64_t size);
  virtual const void*
",2
"                                               tensor_.get(), &unused);
  if (!status.ok()) {
    throw status;
",2
"  }
#if HAVE_GPU
  // On GPU allocation is asynchronous, we need to wait for it to
  // complete.
  auto device_context = context->op_device_context();
",2
"const common::DataType TFTensor::dtype() const {
  switch (tensor_.dtype()) {
  case DT_UINT8:
    return common::HOROVOD_UINT8;
",2
"  common::TensorShape shape;
  for (auto dim : tensor_.shape()) {
    shape.AddDim(dim.size);
  }
",2
"int64_t TFTensor::size() const { return (int64_t)tensor_.tensor_data().size(); }
",2
"  }
  return device;
",2
"// On GPU this event will signal that data is ready, and tensors are
// allocated.
common::ReadyEvent* RecordReadyEvent(OpKernelContext* context) {
#if HAVE_GPU
  auto device_context = context->op_device_context();
",2
"  if (device_context != nullptr) {
    return new TFReadyEvent(device_context);
",2
"      : AsyncOpKernel(context) {
    OP_REQUIRES_OK(context, context->GetAttr(""reduce_op"", &reduce_op_));
  }

  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {
",2
"    // ReadyEvent makes sure input tensor is ready, and output is allocated.
    auto ready_event = std::shared_ptr<common::ReadyEvent>(RecordReadyEvent(context));
    auto hvd_context = std::make_shared<TFOpContext>(context);
    auto hvd_tensor = std::make_shared<TFTensor>(tensor);
    auto hvd_output = std::make_shared<TFTensor>(*output);
",2
"  void ComputeAsync(OpKernelContext* context, DoneCallback done) override {
    OP_REQUIRES_OK_ASYNC(context, ConvertStatus(common::CheckInitialized()),
                         done);

",2
"        [context, done](const common::Status& status) {
          context->SetStatus(ConvertStatus(status));
          done();
        });
",2
"    std::shared_ptr<TFTensor> hvd_output = nullptr;
",2
"REGISTER_OP(""HorovodBroadcast"")
    .Attr(
",2
"      c->set_output(0, c->input(0));
      return Status::OK();
    })
",2
"# You may obtain a copy of the License at
",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",2
"import tensorflow as tf
",2
"from horovod.tensorflow.elastic import TensorFlowKerasState

",2
"class CommitStateCallback(_impl.CommitStateCallbackImpl, tf.keras.callbacks.Callback):
    """"""
    Keras Callback that will commit the `state` object every `batches_per_commit`
    batches at the end of each batch.
",2
"    def __init__(self, state):
        """"""
        Constructs a new UpdateBatchStateCallback.
",2
"        super(UpdateBatchStateCallback, self).__init__(tf.keras.backend, state)
",2
"        Args:
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
",2
"
import tensorflow as tf

",2
"from distutils.version import LooseVersion
if LooseVersion(tf.__version__) >= LooseVersion(""1.4.0""):
    from tensorflow import keras
    from tensorflow.python.keras import backend as K
",2
"from horovod._keras import callbacks as _impl


",2
"class BroadcastGlobalVariablesCallback(_impl.BroadcastGlobalVariablesCallbackImpl, keras.callbacks.Callback):
    """"""
    Keras Callback that will broadcast all global variables from root rank
    to all other processes during initialization.
",2
"
    This is necessary to ensure consistent initialization of all workers when
    training is started with random weights or restored from a checkpoint.
",2
"
        Args:
            root_rank: Rank that will send data, other ranks will receive data.
            device: Device to be used for broadcasting. Uses GPU by default
                    if Horovod was build with HOROVOD_GPU_OPERATIONS.
",2
"        """"""
        super(BroadcastGlobalVariablesCallback, self).__init__(K, root_rank, device)


",2
"    def __init__(self, multiplier, start_epoch=0, end_epoch=None, staircase=True,
                 momentum_correction=True, steps_per_epoch=None, initial_lr=None):
        """"""
",2
"#
",2
"                         compression=Compression.none,
                         sparse_as_dense=False):
    """"""
    An optimizer that wraps another keras.optimizers.Optimizer, using an allreduce to
    average gradient values before applying gradients to model weights.
",2
"              gradients. Defaults to ""Distributed"" followed by the provided
              optimizer type.
        device_dense: Device to be used for dense tensors. Uses GPU by default
                      if Horovod was build with HOROVOD_GPU_OPERATIONS.
        device_sparse: Device to be used for sparse tensors. Uses GPU by default
",2
"    """"""Broadcasts all global variables from root rank to all other processes.
",2
"    """"""
    Loads a saved Keras model with a Horovod DistributedOptimizer.

    The DistributedOptimizer will wrap the underlying optimizer used to train
",2
"
",2
"    Raises:
        ImportError: If h5py is not available.
        ValueError: In case of an invalid savefile.
    """"""
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"#include <iostream>
#include <memory>
#include <unordered_map>
#include <vector>
",2
"// ParameterManager encapsulates the various tunable ""knobs"" in Horovod including the cycle time
// between iterations of the background thread, and the size of the fusion buffer.
//
// During the early training batches, the auto-tuning feature (if enabled) will try various
",2
"class ParameterManager {
public:
  ParameterManager();
  ParameterManager(const ParameterManager&) = delete;
",2
"
",2
"  // Do hierarchical allgather.
  bool HierarchicalAllgather() const;
",2
"  //  Whether the parameters need to be broadcasted to all ranks.
  bool Update(const std::vector<std::string>& tensor_names, int64_t bytes);
",2
"  };
",2
"  void Reset();

private:
",2
"  // Outputs parameter values and writes results to a log file (if provided).
  void LogParameters(double score);
  void LogBestParameters();

  // Interface used to represent a parameter (or group of parameters) being tuned.
",2
"    bool Tune(double score, double* best_score) override;
",2
"
  private:
    void CompleteTuning();
    virtual void OnTune(double score, T& value) = 0;
",2
"  struct BayesianVariableConfig {
    BayesianVariable variable;
",2
"  };

  // A set of numerical parameters optimized jointly using Bayesian Optimization.
",2
"    double BestValue(BayesianVariable variable) const;

",2
"    std::unique_ptr<BayesianOptimization> bayes_;
",2
"
  CategoricalParameter<bool> hierarchical_allreduce_;
  CategoricalParameter<bool> hierarchical_allgather_;
",2
"  bool active_;
",2
"
#endif //HOROVOD_PARAMETER_MANAGER_H
// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
// Modifications copyright Microsoft
",2
"#include ""tensor_queue.h""

",2
"#include <assert.h>

",2
"// Add a TensorTableEntry as well as its message to the queue.
Status TensorQueue::AddToTensorQueue(TensorTableEntry& e, Request& message) {
  std::lock_guard<std::mutex> guard(mutex_);
  if (tensor_table_.find(e.tensor_name) != tensor_table_.end()) {
    return DUPLICATE_NAME_ERROR;
",2
"  std::lock_guard<std::mutex> guard(mutex_);
  for (auto& e : tensor_table_) {
",2
"    for (auto& name : response.tensor_names()) {
",2
"        assert(join_iter != tensor_table_.end());
",2
"                                                 response.tensor_type(),
                                                 &(entry.tensor));

        entry.output = entry.tensor;
",2
"  }
}

// Get tensor entry given a tensor name
",2
"  // Lock on the tensor table.
  std::lock_guard<std::mutex> guard(mutex_);
  auto& iter = tensor_table_.at(tensor_name);

",2
"}
",2
"}

// Push messages to message queue
void TensorQueue::PushMessagesToQueue(
",2
"// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
",2
"  capacity_ = capacity;
",2
"
uint32_t ResponseCache::capacity() const { return capacity_; }
",2
"               : CacheState::INVALID;
  } else {
    return CacheState::MISS;
  }
",2
"}

ResponseCache::CacheState
",2
"    uint32_t cache_bit = it->second;
    auto& cache_params = std::get<1>(*cache_iters_[cache_bit]);
",2
"  // Disallow caching name-conflicted responses here. Invalid cache entries
  // must be removed prior to caching new entries.
",2
"  if (cache_state == CacheState::INVALID) {
    throw std::logic_error(
",2
"                 ""the cache capacity (HOROVOD_CACHE_CAPACITY>""
              << std::to_string(capacity_) << "")."";
      LOG(WARNING) << message.str();
      print_warning_ = false;
    }
",2
"  }

  cache_iters_[cache_bit] = cache_.begin();
  tensor_name_to_bit_[response.tensor_names()[0]] = cache_bit;
",2
"
",2
"
  std::vector<TensorTableEntry> entries_for_join;
  if (joined) {
    tensor_queue.GetTensorEntriesFromResponse(response, entries_for_join,
                                              joined);
",2
"      this->put_(new_response, params, joined);
      i++;
    }
  } else {
    TensorParams params;
",2
"        joined ? entries_for_join[0]
               : tensor_queue.GetTensorEntry(response.tensor_names()[0]);
",2
"  return tensor_name_to_bit_.at(tensor_name);
}

std::vector<uint32_t> ResponseCache::list_all_bits() const {
",2
"const std::set<uint32_t>& CacheCoordinator::timeline_bits() const {
",2
"  assert(synced_);
  return should_shut_down_;
}

bool CacheCoordinator::uncached_in_queue() const {
",2
"  int nbits = num_active_bits_ + NUM_STATUS_BITS;
  int count = (nbits + sizeof(long long) * CHAR_BIT - 1) /
              (sizeof(long long) * CHAR_BIT);

  // Allocate extended bit vector for timeline handling if required.
",2
"  std::memset(&bitvector_[0], 0, count * sizeof(long long));
  if (timeline_enabled) {
    std::memset(&bitvector_[count], -1, count * sizeof(long long));
  }

",2
"  if (!invalid_in_queue_) {
    bitvector_[0] |= (1ull << StatusBit::INVALID_IN_QUEUE);
  }

  // Before communication, remove any invalid bits from cache hit set.
",2
"  for (auto bit : invalid_bits_) {
    cache_hits_.erase(bit);
",2
"      ll &= ~(1ull << (idx - 1));
    }
  }

  // Set states from reserved status bits
",2
"    should_shut_down_ = true;
  }
  if (!cache_hits_.erase(StatusBit::UNCACHED_IN_QUEUE - NUM_STATUS_BITS)) {
    uncached_in_queue_ = true;
  }
",2
"        int idx = __builtin_ffsll(ll);
",2
"            invalid_bits_.end()) {
          timeline_bits_.insert(shifted_bit - NUM_STATUS_BITS);
",2
"// Modifications copyright Microsoft
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
" *
 * The primary logic of the allreduce, allgather and broadcast currently
 * support in MPI, NCCL, CUDA/ROCm, Gloo, oneCCL, DDL. The background thread
 * which facilitates controller operations is run in BackgroundThreadLoop().
 * The provided ops are:
",2
" */

namespace horovod {
",2
"HorovodGlobalState horovod_global;

",2
"#if HAVE_MPI
MPIContext mpi_context;
#endif

#if HAVE_GLOO
",2
"
    allreduce_ops.push_back(
",2
"        std::shared_ptr<BroadcastOp>(new GlooBroadcast(&gloo_context, &state)));
  }
#endif
",2
"
",2
"#if HAVE_CCL
  if (state.cpu_operation == LibType::CCL) {
",2
"    allreduce_ops.push_back(
",2
"
  std::shared_ptr<JoinOp> join_op(new JoinOp(&state));
  std::shared_ptr<ErrorOp> error_op(new ErrorOp(&state));

",2
"          it = waiting_tensors.erase(it);
        } else {
          ++it;
        }
",2
"      }
      std::this_thread::sleep_for(std::chrono::nanoseconds(100));
    }
    for (auto& e : entries) {
",2
"        e.callback(status);
      }
    }
  }
",2
"//      with other ongoing operations. This means that they cannot be blocking
//      ops, but rather must be async ops, the execution of which happens on a
//      separate thread.
//      4. We cannot guarantee that all the processes reduce their tensors
//      in the same order, so we cannot dispatch one thread per tensor,
",2
"#endif
    {
",2
"  // Open the timeline file on coordinator.
  auto horovod_timeline = std::getenv(HOROVOD_TIMELINE);
",2
"
  // Override response cache capacity, if it's set.
  state.parameter_manager.SetCacheEnabled(true);
  auto horovod_cache_capacity = std::getenv(HOROVOD_CACHE_CAPACITY);
  if (horovod_cache_capacity != nullptr) {
",2
"  auto horovod_hierarchical_allgather =
      std::getenv(HOROVOD_HIERARCHICAL_ALLGATHER);
  state.parameter_manager.SetHierarchicalAllgather(false);
  if (horovod_hierarchical_allgather != nullptr) {
",2
"  // single node.
  auto horovod_hierarchical_allreduce =
      std::getenv(HOROVOD_HIERARCHICAL_ALLREDUCE);
  state.parameter_manager.SetHierarchicalAllreduce(false);
",2
"      (state.parameter_manager.HierarchicalAllreduce() ||
       state.parameter_manager.HierarchicalAllgather()) &&
",2
"      !is_homogeneous) {
    std::cerr
        << ""WARNING: Using different number of ranks per node might cause ""
",2
"           ""performance loss in hierarchical allgather and ""
           ""hierarchical allreduce. Consider assigning the same ""
           ""number of ranks to each node, or disabling hierarchical ""
           ""allgather and hierarchical allreduce."";
",2
"  auto horovod_autotune = std::getenv(HOROVOD_AUTOTUNE);
  if (horovod_autotune != nullptr &&
",2
"
  op_manager.reset(CreateOperationManager(state));

  // Signal that initialization is completed.
",2
"  state.initialization_done = true;
  LOG(INFO, horovod_global.controller->GetRank()) << ""Horovod Initialized"";

  // Iterate until shutdown.
  try {
",2
"  nccl_context.ShutDown();
#endif

#if HAVE_GLOO
",2
"
  LOG(DEBUG, horovod_global.controller->GetRank()) << ""Shutting down background thread"";

",2
"  std::vector<StatusCallback> callbacks;
  horovod_global.tensor_queue.FinalizeTensorQueue(callbacks);
  for (auto& cb : callbacks) {
",2
"#endif

#if HAVE_MPI
  mpi_context.Finalize(mpi_ctx_manager);
",2
"    bool should_sync =
        state.parameter_manager.Update(tensor_names, total_tensor_size);

    if (should_sync) {
",2
"      horovod_global.controller->SetRanks(ranks, nranks);
    }
",2
"}

} // namespace

",2
"    return NOT_INITIALIZED_ERROR;
  }
  return Status::OK();
}
",2
"    return -1;
",2
"  }
  return horovod_global.controller->GetLocalRank();
}
",2
"int horovod_local_size() {
  if (!horovod_global.initialization_done) {
    return -1;
  }
",2
"}

",2
"  return mpi_context.IsEnabled();
#else
  return false;
",2
"#else
  return false;
#endif
",2
"  return false;
",2
"  return true;
",2
"#else
",2
"
// Contexts and controller must be initialized and the background thread
// must be running before this function is called.
Status EnqueueTensorAllreduce(std::shared_ptr<OpContext> context,
                              std::shared_ptr<Tensor> tensor,
",2
"  if (reduce_op == ReduceOp::AVERAGE) {
    LOG(ERROR, horovod_global.controller->GetRank()) << ""Enqueuing AVERAGE allreduce is not allowed."";
    return status.Aborted(""AVERAGE not allowed."");
  }
  Request message;
",2
"  message.set_request_rank(horovod_global.controller->GetRank());
  message.set_tensor_name(name);
  message.set_tensor_type(tensor->dtype());
  message.set_device(device);
  
",2
"  if (horovod_global.shut_down) {
    return SHUT_DOWN_ERROR;
  }
",2
"
  TensorTableEntry e;
  e.tensor_name = name;
  e.context = context;
  e.tensor = tensor;
",2
"  e.device = device;
  e.callback = callback;

",2
"// Contexts and controller must be initialized and the background thread
// must be running before this function is called.
Status EnqueueTensorBroadcast(std::shared_ptr<OpContext> context,
                              std::shared_ptr<Tensor> tensor,
                              std::shared_ptr<Tensor> output, int root_rank,
",2
"  message.set_tensor_name(name);
  message.set_tensor_type(tensor->dtype());
",2
"  if (status.ok()) {
    LOG(TRACE, horovod_global.controller->GetRank()) << ""Enqueued "" << name;
  }
  return status;
}
",2
"Status EnqueueJoin(std::shared_ptr<OpContext> context,
",2
"// =============================================================================

#ifndef HOROVOD_HASHES_H
",2
"
",2
"namespace {

template <typename T>
inline std::size_t hash_one(const T& element, std::size_t seed) {
",2
"  return seed ^
",2
"template <typename T> struct hash<std::vector<T>> {
  using argument_type = std::vector<T>;
  using result_type = std::size_t;

  result_type operator()(argument_type const& in) const {
",2
"    size_t size = in.size();
    result_type seed = 0;
    for (size_t i = 0; i < size; i++)
      seed = hash_one<T>(in[i], seed);
",2
"    return seed;
",2
"    seed = hash_one<W>(std::get<2>(in), seed);
    return seed;
",2
"  }
};

template <> struct hash<horovod::common::Framework> {
",2
"#include <utility>
#include <vector>
",2
"  ResponseCache(const ResponseCache&) = delete;

  enum CacheState { MISS = 0, HIT = 1, INVALID = 2 };
",2
"  uint32_t capacity() const;

  size_t num_active_bits() const;
",2
"  // Lookup table mapping tensor names to assigned cache bits.
  std::unordered_map<std::string, uint32_t> tensor_name_to_bit_;

",2
"
// Helper class to coordinate cache and state information
// across workers. Uses global controller operations on a bit vector
",2
"  void record_hit(uint32_t bit);
",2
"  const std::set<uint32_t>& cache_hits() const;

  const std::set<uint32_t>& invalid_bits() const;
",2
"
  bool should_shut_down() const;

",2
"  // Set of invalid bits. After sync(), contains only common
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
",2
"// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
",2
"// limitations under the License.
// =============================================================================

#include ""parameter_manager.h""

",2
"#include ""logging.h""
",2
"    warmup_remaining_(warmups_),
    sample_(0),
    rank_(-1),
    root_rank_(0),
    writing_(false) {
",2
"  root_rank_ = root_rank;
  if (rank_ == root_rank) {
    LOG(INFO) << ""Autotuner: Tunable params [hierarchical_allreduce,hierarchical_allgather,cache_enabled,cycle_time_ms,tensor_fusion_threshold] score"";
  }
",2
"  if (rank_ == root_rank && !file_name.empty()) {
    file_.open(file_name, std::ios::out | std::ios::trunc);
    if (file_.good()) {
      file_ << ""hierarchical_allreduce,hierarchical_allgather,cache_enabled,cycle_time_ms,tensor_fusion_threshold,score"" << std::endl;
",2
"  return active_ ? hierarchical_allgather_.Value() : hierarchical_allgather_.BestValue();
}

",2
"
void ParameterManager::SetCacheEnabled(bool enabled, bool fixed) {
  cache_enabled_.SetValue(enabled, fixed);
",2
"    double med_score = scores_[SAMPLES / 2];
    return Tune(med_score);
  }

  return false;
",2
"    if (rank_ == root_rank_) {
      LOG(INFO) << ""Autotuner: Warming up ("" << warmup_remaining_ << "" remaining)"";
",2
"          finished_tuning = false;
          break;
        }
",2
"}

void ParameterManager::SetParams(const Params& newParams) {
  hierarchical_allreduce_.SetValue(newParams.hierarchical_allreduce, true);
",2
"  hierarchical_allgather_.SetValue(newParams.hierarchical_allgather, true);
",2
"  cache_enabled_.SetValue(newParams.cache_enabled, true);
  joint_params_.SetValue(fusion_buffer_threshold_mb, newParams.tensor_fusion_threshold, true);
  joint_params_.SetValue(cycle_time_ms, newParams.cycle_time, true);
",2
"  total_bytes_ = 0;
  last_sample_start_ = std::chrono::steady_clock::now();
",2
"}

void ParameterManager::LogBestParameters() {
",2
"              << cache_enabled_.BestValue() << "", ""
              << joint_params_.BestValue(cycle_time_ms) << "" ms, ""
",2
"    return true;
  }

  OnTune(score, value_);
  if (IsDoneTuning()) {
",2
"
",2
"  return false;
",2
"  best_value_ = value;
  if (fixed) {
    value_ = value;
    tunable_ = false;
  }
",2
"}

template <class T>
",2
"// CategoricalParameter
template <class T>
ParameterManager::CategoricalParameter<T>::CategoricalParameter(std::vector<T> values) :
    TunableParameter<T>(values[0]),
",2
"    values_(values) {
  ResetState();
}

template <class T>
",2
"}

template <class T>
void ParameterManager::CategoricalParameter<T>::ResetState() {
",2
"    TunableParameter<Eigen::VectorXd>(test_points[0]),
",2
"    gaussian_process_noise_(gaussian_process_noise),
    iteration_(0) {
  ResetBayes();
  Reinitialize(FilterTestPoint(0));
",2
"}

void ParameterManager::BayesianParameter::OnTune(double score, Eigen::VectorXd& value) {
",2
"  int j = 0;
  for (auto var : variables_) {
    if (fixed_values_.find(var.variable) == fixed_values_.end()) {
      bounds.push_back(var.bounds);
      index_[var.variable] = j;
",2
"}

Eigen::VectorXd ParameterManager::BayesianParameter::FilterTestPoint(int i) {
  Eigen::VectorXd& test_point = test_points_[i];
  Eigen::VectorXd filtered_point(test_point.size() - fixed_values_.size());
",2
"
  int k = 0;
  for (int j = 0; j < test_point.size(); ++j) {
    BayesianVariable variable = variables_[j].variable;
",2
"
",2
"  }

  return filtered_point;
}
",2
"namespace common {

",2
"  char phase;
  std::string op_name;
  std::string args;
  std::string marker_name;
",2
"  long ts_micros;
};

",2
"  void Initialize(std::string file_name);
  inline bool IsHealthy() const { return healthy_; }
  void EnqueueWriteEvent(const std::string& tensor_name, char phase,
                         const std::string& op_name, const std::string& args,
                         long ts_micros);
",2
"
  // Timeline file.
  std::ofstream file_;
",2
"
  // Timeline record queue.
  boost::lockfree::spsc_queue<TimelineRecord,
",2
"
",2
"  void ActivityStartAll(const std::vector<TensorTableEntry>& entries,
                        const std::string& activity);
  void ActivityStart(const std::string& tensor_name,
",2
"  std::recursive_mutex mutex_;

  // Current state of each tensor in the timeline.
  std::unordered_map<std::string, TimelineState> tensor_states_;

",2
"} // namespace horovod

#endif // HOROVOD_TIMELINE_H
",2
"
#include ""logging.h""

namespace horovod {
namespace common {
",2
"
void TimelineWriter::Initialize(std::string file_name) {
",2
"                                       char phase, const std::string& op_name,
                                       const std::string& args,
                                       long ts_micros) {
  TimelineRecord r{};
",2
"  r.type = TimelineRecordType::EVENT;
  r.tensor_name = tensor_name;
  r.phase = phase;
",2
"
  while (healthy_ && !record_queue_.push(r))
    ;
}

",2
"  }
",2
"
",2
"        break;
      case TimelineRecordType::MARKER:
        DoWriteMarker(r);
        break;
      default:
",2
"}

void Timeline::Initialize(std::string file_name, unsigned int horovod_size) {
  if (initialized_) {
",2
"  rank_strings_ = std::vector<std::string>(horovod_size);
  for (unsigned int i = 0; i < horovod_size; i++) {
    rank_strings_[i] = std::to_string(i);
  }
",2
"void Timeline::WriteEvent(const std::string& tensor_name, const char phase,
                          const std::string& op_name, const std::string& args) {
  auto ts_micros = TimeSinceStartMicros();
  writer_.EnqueueWriteEvent(tensor_name, phase, op_name, args, ts_micros);
",2
"  if (!initialized_) {
    return;
  }

",2
"  // negotiation phase, either due to multiple cycles with cache misses on
  // some worker, or if the response is evicted from the cache before
  // completion and its handling proceeds to the default communication path.
",2
"  WriteEvent(tensor_name, 'X', rank_strings_[rank]);
}
",2
"  auto event_category = Response::ResponseType_Name(response_type);
",2
"
void Timeline::ActivityEndAll(const std::vector<TensorTableEntry>& entries) {
  for (auto& e : entries) {
    ActivityEnd(e.tensor_name);
",2
"  }
}

void Timeline::ActivityEnd(const std::string& tensor_name) {
",2
"  }

",2
"  // Pop out of current state, if applicable.
  if (tensor_states_[tensor_name] == TimelineState::ACTIVITY) {
    ActivityEnd(tensor_name);
",2
"    args << ""\""dtype\"": \"""" << DataType_Name(tensor->dtype()) << ""\"""";
    args << "", \""shape\"": \"""" << tensor->shape().DebugString() << ""\"""";
  }
  WriteEvent(tensor_name, 'E', """", args.str());
}
",2
"
  std::lock_guard<std::recursive_mutex> guard(mutex_);
  WriteMarker(""CYCLE_START"");
}
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

",2
"import functools
",2
"from horovod.common.exceptions import HorovodInternalError, HostsUpdatedInterrupt
from horovod.run.elastic.worker import WorkerNotificationManager
",2
"
notification_manager = WorkerNotificationManager()


class State(object):
",2
"    """"""
    def __init__(self, bcast_object, get_rank):
        self._bcast_object = bcast_object
",2
"    def register_reset_callbacks(self, callbacks):
        """"""Register callbacks that will be invoked following a reset event (worker added or removed).

        For example, a common use of a reset callback would be to update the learning rate scale with the
        new number of workers.
",2
"    def commit(self):
",2
"        """"""Commits all modifications to state tracked by this object to host memory.

        This call will also check for any changes to known hosts, and raise a `HostsUpdatedInterrupt`
        if any were detected.

",2
"        self.check_host_updates()
",2
"        # Iterate through the update messages sent from the server. If the update timestamp
        # is greater than the last update timestamp, then trigger a HostsUpdatedException.
        last_updated_timestamp = prev_timestamp = self._last_updated_timestamp
",2
"    """"""State for simple Python objects.

",2
"        kwargs: Properties to sync, will be exposed as attributes of the object.
    """"""
    def __init__(self, bcast_object, get_rank, **kwargs):
",2
"        new_state = {}
",2
"
",2
"
",2
"        notification_manager.register_listener(state)

",2
"
                reset()
                state.on_reset()
        finally:
",2
"// Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
// Modifications copyright (C) 2019 Intel Corporation
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"#include <memory>
",2
"#define ALLOCATE_SHARED_BUFFER ""ALLOCATE_SHARED_BUFFER""
#define CCL_ALLREDUCE ""CCL_ALLREDUCE""
",2
"#define HOROVOD_CYCLE_TIME ""HOROVOD_CYCLE_TIME""
#define HOROVOD_STALL_CHECK_DISABLE ""HOROVOD_STALL_CHECK_DISABLE""
#define HOROVOD_STALL_CHECK_TIME_SECONDS ""HOROVOD_STALL_CHECK_TIME_SECONDS""
",2
"#define JOIN_TENSOR_NAME ""join.noname""

",2
"    default:
      return ""<unknown>"";
  }
}
",2
"// Common error status
const Status NOT_INITIALIZED_ERROR = Status::PreconditionError(
",2
"    ""Horovod has not been initialized; use hvd.init()."");

",2
"  const std::string DebugString() const;
",2
"
class PersistentBuffer {
public:
",2
"class Tensor {
public:
",2
"  // Pre-allocated output tensor.
  std::shared_ptr<Tensor> output;
  // Root rank for broadcast operation.
",2
"// Set affinity function
void server_affinity_set(int affinity);
",2
"    if (__get_cpuid(1, &eax, &ebx, &ecx, &edx)) {
      result = (ecx & bit_AVX) && (ecx & bit_F16C);
",2
"  return result;
}
#endif
",2
"
// float16 custom data type summation operation.
void float16_sum(void* invec, void* inoutvec, int* len,
                 MPI_Datatype* datatype) {
  // cast invec and inoutvec to your float16 type
",2
"  auto* in = (unsigned short*)invec;
  auto* inout = (unsigned short*)inoutvec;

  int i = 0;
#if __AVX__ && __F16C__
",2
"    HalfBits2Float(inout + i, &inout_float);
    inout_float += in_float;
    Float2HalfBits(&inout_float, inout + i);
  }
}
",2
"// limitations under the License.
// =============================================================================

#include ""common.h""
#include ""logging.h""
",2
"
#include <sstream>
#include <cassert>

",2
"namespace horovod {
namespace common {
",2
"}

Status Status::OK() {
  return Status();
",2
"Status Status::UnknownError(std::string message) {
  return Status(StatusType::UNKNOWN_ERROR, message);
}
",2
"}

",2
"  return reason_;
}

",2
"
void TensorShape::AppendShape(TensorShape& other) {
  for (auto dim : other.shape_) {
",2
"}

const std::string TensorShape::DebugString() const {
  std::stringstream args;
  args << ""["";
",2
"  assert(idx >= 0);
  assert(idx < shape_.size());
  return shape_[idx];
",2
"}
",2
"
int64_t TensorShape::num_elements() const {
",2
"    LOG(ERROR) << ""setaffinity failed"";
  }

  // Check if we set the affinity correctly
  if (pthread_getaffinity_np(current_thread, sizeof(cpu_set_t), &cpuset) != 0) {
",2
"      LOG(INFO) << ""Background thread affinity "" << core_idx;
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"// limitations under the License.
",2
"// =============================================================================

#ifndef HOROVOD_MESSAGE_H
#define HOROVOD_MESSAGE_H

",2
"std::size_t DataType_Size(DataType value);

// A Request is a message sent from a rank greater than zero to the
// coordinator (rank zero), informing the coordinator of an operation that
",2
"  enum RequestType {
    ALLREDUCE = 0, ALLGATHER = 1, BROADCAST = 2, JOIN = 3, ADASUM = 4
  };

  static const std::string& RequestType_Name(RequestType value);
",2
"  int32_t request_rank() const;

  void set_request_rank(int32_t value);

  RequestType request_type() const;
",2
"
  void set_requests(const std::vector<Request>& value);

",2
"    ALLREDUCE = 0, ALLGATHER = 1, BROADCAST = 2, JOIN = 3, ADASUM = 4, ERROR = 5
  };

  static const std::string& ResponseType_Name(ResponseType value);

",2
"  // Empty if the type is DONE or SHUTDOWN.
  const std::vector<std::string>& tensor_names() const;

  DataType tensor_type() const;

",2
"private:
  ResponseType response_type_ = ResponseType::ALLREDUCE;
  std::vector<std::string> tensor_names_;
",2
"  DataType tensor_type_ = DataType::HOROVOD_UINT8;
  std::string error_message_;
",2
"class ResponseList {
public:
  const std::vector<Response>& responses() const;

  void set_responses(const std::vector<Response>& value);
",2
"
",2
"  static void ParseFromBytes(ResponseList& response_list,
                             const uint8_t* input);

  static void SerializeToString(const ResponseList& response_list,
",2
"                                std::string& output);

",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"
",2
"    on_end_init();

    return status;
",2
"  }

  return Status::OK();
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"// See the License for the specific language governing permissions and
",2
"
",2
"#include ""timeline.h""
",2
"using MessageTable = std::unordered_map<std::string, std::vector<Request>>;
",2
"
  virtual void CrossRankBitwiseOr(std::vector<long long>& bitvector,
",2
"                                  int count) = 0;

",2
"
  virtual void Bcast(void* buffer, size_t size, int root_rank, Communicator
",2
"
",2
"  // The coordinator follows a master-worker paradigm. Rank zero acts
  // as the master (the ""coordinator""), whereas all other ranks are simply
  // workers. Each worker maintains a cache of tensors that are previously
  // broadcasted as ready by other ranks. If the cache covers all incoming
",2
"  //      reduce, as well as their shape and type). They repeat this for every
  //      tensor that they would like to operate on.
  //
",2
"  //      as from its own TensorFlow ops, and stores them in a request table.
  //      The coordinator continues to receive Request messages until it has
",2
"  //      those, it sends a Response to all the workers. When no more
  //      Responses are available, it sends a ""DONE"" response to the workers.
  //      If the process is being shutdown, it instead sends a ""SHUTDOWN""
  //      response.
",2
"                                std::vector<RequestList>& ready_list) = 0;

  // For other ranks to send their ready tensors to rank 0
  virtual void SendReadyTensors(RequestList& message_list) = 0;
",2
"  virtual void SendFinalTensors(ResponseList& response_list) = 0;

  // For other ranks to receive to final ready tensors.
  virtual void RecvFinalTensors(ResponseList& response_list) = 0;
",2
"
  // Once a tensor is ready to be reduced, the coordinator sends a Response
",2
"
  // COMM_WORLD ranks of processes running on this node.
  std::vector<int> local_comm_ranks_;

  // Numbers of ranks running per node
",2
"  Timeline& timeline_;

  ResponseCache& response_cache_;

  ParameterManager& parameter_manager_;
",2
"ThreadPool::~ThreadPool() {
  reset();
}

void ThreadPool::execute(std::function<void(void)> f) {
",2
"  }
  cond_.notify_one();
}

",2
"    auto f = work_queue_.front();
    work_queue_.pop();
",2
"bool StallInspector::CheckForStalledTensors(int global_size) {
  bool should_shut_down = false;
  auto now = std::chrono::steady_clock::now();
",2
"                    ""HOROVOD_STALL_CHECK_TIME_SECONDS, will not shutdown."";
    stall_shutdown_time = std::chrono::seconds(0);
  }
",2
"
",2
"  for (auto& m : uncached_tensor_table) {
",2
"            should_shut_down = true;
          }
",2
"      message << "": ["";
      auto it = kv.second.begin();
      message << *it;
",2
"      int count = 0;
",2
"    // for global removal from cache to trigger stall messaging.
    if (now - entry.second > stall_warning_time) {
      uint32_t cache_bit = response_cache_.peek_cache_bit(entry.first);
",2
"      cache_coordinator.record_invalid_bit(cache_bit);
      cache_coordinator.set_uncached_in_queue(true);
    }
",2
"  } else {
    std::vector<int>& ranks = std::get<0>(table_iter->second);
    ranks.push_back(rank);
  }
}
",2
"}

void StallInspector::SetPerformStallCheck(bool value) {
  perform_stall_check = value;
}
",2
"
void StallInspector::SetStallWarningTimeSeconds(int value) {
  stall_warning_time_seconds = value;
",2
"}

void StallInspector::SetStallShutdownTimeSeconds(int value) {
",2
"// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================

",2
"#include ""message.h""

#include <iostream>
",2
"  switch (value) {
    case HOROVOD_UINT8:
      static const std::string uint8(""uint8"");
      return uint8;
",2
"    case HOROVOD_INT8:
      static const std::string int8(""int8"");
      return int8;
    case HOROVOD_UINT16:
      static const std::string uint16(""uint16"");
",2
"      return float32;
    case HOROVOD_FLOAT64:
      static const std::string float64(""float64"");
",2
"      static const std::string unknown(""<unknown>"");
      return unknown;
  }
}
",2
"    case HOROVOD_FLOAT32:
",2
"int32_t Request::root_rank() const { return root_rank_; }

void Request::set_root_rank(int32_t value) { root_rank_ = value; }
",2
"
namespace {

void Request_ParseFromWire(Request& request,
                           const wire::Request* obj) {
",2
"}

void Request_SerializeToWire(const Request& request,
",2
"  wire::RequestBuilder request_builder(builder);
",2
"}

} // namespace

void Request::ParseFromBytes(Request& request, const uint8_t* input) {
",2
"  auto obj = flatbuffers::GetRoot<wire::Request>(input);
  Request_ParseFromWire(request, obj);
}

",2
"  builder.Finish(obj);
",2
"
void RequestList::set_requests(const std::vector<Request>& value) {
  requests_ = value;
}

",2
"void RequestList::emplace_request(Request&& value) {
  requests_.emplace_back(value);
}

",2
"  for (const auto& req_obj : *obj->requests()) {
    Request request;
    Request_ParseFromWire(request, req_obj);
    request_list.emplace_request(std::move(request));
  }
",2
"  auto size = builder.GetSize();
  output = std::string((char*) buf, size);
",2
"}

const std::string& Response::ResponseType_Name(ResponseType value) {
",2
"      static const std::string allreduce(""ALLREDUCE"");
",2
"      return allreduce;
",2
"    case ResponseType::BROADCAST:
      static const std::string broadcast(""BROADCAST"");
      return broadcast;
",2
"
",2
"void Response::set_response_type(ResponseType value) {
  response_type_ = value;
}

",2
"const std::string& Response::error_message() const { return error_message_; }

void Response::set_error_message(const std::string& value) {
  error_message_ = value;
}
",2
"  tensor_sizes_ = value;
}
",2
"}

void Response_ParseFromWire(Response& response,
                            const wire::Response* obj) {
",2
"}
",2
"void Response_SerializeToWire(const Response& response,
                              flatbuffers::FlatBufferBuilder& builder,
                              flatbuffers::Offset<wire::Response>& obj) {
",2
"  Response_SerializeToWire(response, builder, obj);
  builder.Finish(obj);

  uint8_t* buf = builder.GetBufferPointer();
  auto size = builder.GetSize();
",2
"}

bool ResponseList::shutdown() const { return shutdown_; }
",2
"
void ResponseList::set_shutdown(bool value) { shutdown_ = value; }

void ResponseList::add_response(const Response& value) {
",2
"                                     std::string& output) {
  // FlatBuffers must be built bottom-up.
",2
"  }
  auto responses_wire = builder.CreateVector(responses);

  wire::ResponseListBuilder response_list_builder(builder);
",2
"  output = std::string((char*) buf, size);
}
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"#include ""fusion_buffer_manager.h""
#include ""parameter_manager.h""
",2
"struct HorovodGlobalState {
  // An atomic boolean which is set to true when background thread is started.
",2
"  // Pointer to shared buffer for allgather
  void* shared_buffer = nullptr;

  // Current shared buffer size
",2
"  int64_t shared_buffer_size = 0;

",2
"
  // A LibType indicating what framework we are using to perform controller
  // operations.
",2
"
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"  StallInspector() = default;
",2
"  // Record initial time cached tensor is encountered in queue.
  void RecordCachedTensorStart(const std::string& tensor_name);

  // Record initial time for an uncached tensor is encountered in queue.
  void RecordUncachedTensorStart(const std::string& tensor_name, int rank,
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"// you may not use this file except in compliance with the License.
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"#include ""common.h""
",2
"    ADASUM = 2
};

",2
"extern ""C"" {

// C interface to initialize Horovod.
void horovod_init(const int *ranks, int nranks);
",2
"
#if HAVE_MPI
// C interface to initialize Horovod with the given MPI communicator.
void horovod_init_comm(MPI_Comm comm);
",2
"
// C interface to get index of current Horovod process.
// Returns -1 if Horovod is not initialized.
int horovod_rank();
",2
"// Returns -1 if Horovod is not initialized.
int horovod_size();

// C interface to return number of Horovod processes in the node it is on.
// Returns -1 if Horovod is not initialized.
",2
"
// C interface to return flag indicating whether MPI is enabled.
",2
"bool horovod_mpi_enabled();

// C interface to return flag indicating whether Horovod was compiled with MPI support.
bool horovod_mpi_built();

",2
"// C interface to return value of the ReduceOp::SUM enum field.
int horovod_reduce_op_sum();

// C interface to return value of the ReduceOp::ADASUM enum field.
int horovod_reduce_op_adasum();
",2
"
",2
"                              std::shared_ptr<ReadyEvent> ready_event,
",2
"                              StatusCallback callback);

} // namespace common
",2
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"            'Extension %s has not been built.  If this is not expected, reinstall '
            'Horovod with %s=1 to debug the build error.' % (ext_name, ext_env_var))

",2
"        import sys
        import traceback

        if verbose:
            print('Checking whether extension {ext_base_name} was {fn_desc}.'.format(
",2
"            result = fn(ext)
",2
"            print('Extension {ext_base_name} {flag} {fn_desc}.'.format(
                ext_base_name=ext_base_name, flag=('was' if result else 'was NOT'),
                fn_desc=fn_desc))
",2
"    p.join()
",2
"        if key in cache:
            return cache[key]
        else:
",2
"
",2
"        result = _check_extension_lambda(
            ext_base_name, built_fn, 'built with MPI', verbose)
        if result is not None:
            return result
",2
"def gloo_built(verbose=False):
    for ext_base_name in EXTENSIONS:
        built_fn = lambda ext: ext.gloo_built()
        result = _check_extension_lambda(
",2
"def ddl_built(verbose=False):
    for ext_base_name in EXTENSIONS:
",2
"    raise RuntimeError('Failed to determine if DDL support has been built. '
",2
"
",2
"    for Adasum allreduce.
    TODO support non-power of 2 ranks.
    """"""
",2
"# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
# Modifications copyright Microsoft
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"# ==============================================================================


class HorovodInternalError(RuntimeError):
",2
"
#include ""common.h""
",2
"
namespace horovod {
",2
"  TensorQueue() = default;
  TensorQueue(const TensorQueue&) = delete;
  Status AddToTensorQueue(TensorTableEntry& e, Request& message);

",2
"  void PopMessagesFromQueue(std::deque<Request>& message_queue_buffer);

  void PushMessageToQueue(Request& message);

",2
"  std::unordered_map<std::string, TensorTableEntry> tensor_table_;

  // Queue of MPI requests waiting to be sent to the coordinator node.
  std::queue<Request> message_queue_;
",2
"  mutable std::mutex mutex_;
};

} // namespace common
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"
from horovod.common import util as util

",2
"        full_path = util.get_extension_full_path(pkg_path, *args)
        self.MPI_LIB_CTYPES = ctypes.CDLL(full_path, mode=ctypes.RTLD_GLOBAL)
",2
"
",2
"        """"""
        if comm is None:
            comm = []

        atexit.register(self.shutdown)
",2
"            mpi_built = self.MPI_LIB_CTYPES.horovod_mpi_built()
            if not bool(mpi_built):
                raise ValueError(
                    ""Horovod has not been built with MPI support. Ensure MPI is installed and ""
                    ""reinstall Horovod with HOROVOD_WITH_MPI=1 to debug the build error."")
",2
"            if MPI._sizeof(MPI.Comm) == ctypes.sizeof(ctypes.c_int):
                MPI_Comm = ctypes.c_int
            else:
                MPI_Comm = ctypes.c_void_p
",2
"            comm_size = len(comm)
            self.MPI_LIB_CTYPES.horovod_init(
",2
"                'Horovod has not been initialized; use hvd.init().')
        return local_size

",2
"    def rank(self):
        """"""A function that returns the Horovod rank of the calling process.
",2
"        return rank

    def local_rank(self):
        """"""A function that returns the local Horovod rank of the calling process, within the
        node that it is running on. For example, if there are seven processes running
",2
"        if not bool(mpi_enabled):
",2
"
        Returns:
          A boolean value indicating whether MPI is enabled.
",2
"        """"""
        mpi_enabled = self.MPI_LIB_CTYPES.horovod_mpi_enabled()
        return bool(mpi_enabled)

    def mpi_built(self):
",2
"
",2
"        Returns:
          A boolean value indicating whether Gloo support was compiled.
        """"""
        return bool(self.MPI_LIB_CTYPES.horovod_gloo_built())
",2
"
",2
"          A boolean value indicating whether NCCL support was compiled.
        """"""
        return bool(self.MPI_LIB_CTYPES.horovod_nccl_built())
",2
"
#include ""common.h""
",2
"// you may not use this file except in compliance with the License.
",2
"//
",2
"#include <vector>

namespace horovod {
",2
"
enum class LogLevel {
",2
"  LogMessage(__FILE__, __LINE__, LogLevel::DEBUG)
#define _HVD_LOG_INFO \
  LogMessage(__FILE__, __LINE__, LogLevel::INFO)
#define _HVD_LOG_WARNING \
",2
"#define _LOG(severity) _HVD_LOG_##severity

",2
"LogLevel MinLogLevelFromEnv();
bool LogTimeFromEnv();

}
}
",2
" *       provided with the distribution.
 *     * Neither the name of the NVIDIA CORPORATION nor the names of its contributors may be used
",2
" * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TOR (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
",2
" * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 **************************************************************************************************/
",2
"
",2
"  unsigned h = *src;
  int sign = ((h >> 15) & 1);
",2
"  int exp = ((h >> 10) & 0x1f);
  int mantissa = (h & 0x3ff);
  unsigned f = 0;
",2
"    } else {
",2
"  }

  *res = *reinterpret_cast<float const*>(&f);
}

",2
"  uint16_t sign = uint16_t((s >> 16) & 0x8000);
  int16_t exp = uint16_t(((s >> 23) & 0xff) - 127);
  int mantissa = s & 0x7fffff;
  uint16_t u = 0;
",2
"      u = sign | 0x7c00;
",2
"  if (exp >= -14) {
    // normal fp32 to normal fp16
",2
"    }
  }

  // round to nearest even
",2
"
void float16_sum(void* invec, void* inoutvec, int* len, MPI_Datatype* datatype);

} // namespace common
} // namespace horovod
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"
#include <atomic>
#include <map>
#include <queue>
",2
"  std::deque<Request> message_queue_tmp;
  tensor_queue_.PopMessagesFromQueue(message_queue_tmp);
  for (auto& message : message_queue_tmp) {
    if (message.request_type() == Request::JOIN) {
      state.joined = true;
",2
"      cache_coordinator.set_uncached_in_queue(true);
      continue;
    }

",2
"        stall_inspector_.RecordCachedTensorStart(message.tensor_name());
",2
"        // Remove timing entry if uncached or marked invalid.
",2
"
    if (response_cache_.capacity() > 0) {
      stall_inspector_.InvalidateStalledCachedTensors(cache_coordinator);
    }
",2
"    std::deque<Request> messages_to_replace;
    size_t num_messages = message_queue_tmp.size();
    for (size_t i = 0; i < num_messages; ++i) {
",2
"    tensor_queue_.PushMessagesToQueue(messages_to_replace);
  }

  if (!message_queue_tmp.empty()) {
    LOG(TRACE, rank_) << ""Sent "" << message_queue_tmp.size()
",2
"
  ResponseList response_list;
  response_list.set_shutdown(cache_coordinator.should_shut_down());

",2
"    std::deque<Response> responses;
    // Convert cache hits to responses. Populate so that least
    // recently used responses get priority. All workers call the code
    // here so we use the get method here to consistently update the cache
    // order.
",2
"    for (auto bit : cache_coordinator.cache_hits()) {
      responses.push_back(response_cache_.get_response(bit));
    }

",2
"    std::vector<std::string> ready_to_reduce;

    if (is_coordinator_) {
",2
"            state.joined_size++;
            continue;
          }

",2
"            ready_to_reduce.push_back(received_name);
          }
        }
        if (received_message_list.shutdown()) {
",2
"      if (state.joined_size > 0) {
        for (auto& table_iter : message_table_) {
          int count = (int)table_iter.second.size();
",2
"      // table and should know all the tensors that need to be reduced or
      // gathered, and everyone else should have sent all their information
      // to rank zero. We can now do reductions and gathers; rank zero will
      // choose which ones and in what order, and will notify the other ranks
      // before doing each reduction.
",2
"        }
      }

      for (auto& tensor_name : ready_to_reduce) {
",2
"      }
      response_list = FuseResponses(responses);
      response_list.set_shutdown(should_shut_down);
",2
"    std::string tensors_ready;
    for (const auto& r : response_list.responses()) {
      tensors_ready += r.tensor_names_string() + ""; "";
    }
    LOG(TRACE) << ""Sending ready responses as "" << tensors_ready;
",2
"    // All workers add supported responses to cache. This updates the cache
    // order consistently across workers.
    for (auto& response : response_list.responses()) {
      if ((response.response_type() == Response::ResponseType::ALLREDUCE ||
",2
"
    auto request_type = requests[i].request_type();
    if (message_type != request_type) {
",2
"      error = true;
      error_message_stream << ""Mismatched operations: One rank did an ""
                           << Request::RequestType_Name(message_type)
                           << "", but another rank did an ""
                           << Request::RequestType_Name(request_type) << ""."";
",2
"
      TensorShape request_shape;
      for (auto dim : requests[i].tensor_shape()) {
        request_shape.AddDim(dim);
      }
",2
"                           << ""Specify sparse_to_dense=True if using DistributedOptimizer"";
    }

    // If we are doing an allgather, make sure all but the first dimension are
    // the same. The first dimension may be different and the output tensor is
",2
"    }

    for (unsigned int i = 1; i < requests.size(); ++i) {
      if (error) {
",2
"          break;
        }
      }
      if (dim_mismatch) {
        break;
",2
"      }

",2
"  if (message_type == Request::BROADCAST) {
",2
"    if (joined_size > 0) {
      error = true;
      error_message_stream << ""Broadcast is not supported with Join at this time."";
    }
",2
"  for (unsigned int i = 1; i < requests.size(); ++i) {
",2
"          << (first_device_is_cpu ? ""CPU"" : ""GPU"")
          << "", but another rank specified device ""
          << (this_device_is_cpu ? ""CPU"" : ""GPU"") << ""."";
",2
"    std::string error_message = error_message_stream.str();
    response.set_response_type(Response::ERROR);
    response.set_error_message(error_message);
  } else if (message_type == Request::ALLGATHER) {
",2
"    for (auto dim : tensor_sizes) {
      response.add_tensor_size(dim);
    }
  } else if (message_type == Request::ALLREDUCE) {
    response.set_response_type(Response::ALLREDUCE);
",2
"    response.set_response_type(Response::ADASUM);
    for (auto dim : tensor_sizes) {
",2
"            tensor_size + new_tensor_size <= TensorFusionThresholdBytes()) {
          // These tensors will fuse together well.
          tensor_size += new_tensor_size;
",2
"          response.add_tensor_name(std::move(new_response.tensor_names()[0]));
          response.add_tensor_size(new_response.tensor_sizes()[0]);
          responses.pop_front();
        } else {
",2
"          // usually computed in order of requests and skipping tensors may
          // mean that the batch will have to wait longer while skipped
          // tensors could be reduced at that time. However, mixed-precision
          // training may yield requests of various dtype in a mixed-up
",2
"
      std::deque<Response> skipped_responses;
      int64_t skipped_size = 0;
      while (!responses.empty()) {

",2
"        const auto& new_entry =
            tensor_queue_.GetTensorEntry(new_response.tensor_names()[0]);

",2
"            // Skip response and look ahead for more to fuse.
            skipped_responses.push_back(std::move(new_response));
            responses.pop_front();
",2
"  return response_list;
",2
"}

int64_t Controller::TotalByteSizeOfAllgatherOutput(
    const std::vector<int64_t>& tensor_sizes, const TensorTableEntry& entry) {
",2
"  return local_sizes_for_cross_rank_[i];
}

bool Controller::IncrementTensorCount(const Request& msg, int joined_size) {
  auto& name = msg.tensor_name();
",2
"
  timeline_.NegotiateRankReady(name, msg.request_rank());

  std::vector<Request>& messages = table_iter->second;
  int count = (int)messages.size();
",2
"  return ready_to_reduce;
",2
"}

} // namespace common
} // namespace horovod
#include ""logging.h""
",2
"
namespace horovod {
",2
"namespace common {

LogMessage::LogMessage(const char* fname, int line, LogLevel severity)
",2
"  if (log_time) {
    auto now = std::chrono::system_clock::now();
",2
"
",2
"LogMessageFatal::LogMessageFatal(const char* file, int line)
    : LogMessage(file, line, LogLevel::FATAL) {}
",2
"  std::string min_log_level(env_var_val);
  std::transform(min_log_level.begin(), min_log_level.end(), min_log_level.begin(), ::tolower);
  if (min_log_level == ""trace"") {
    return LogLevel::TRACE;
  } else if (min_log_level == ""debug"") {
",2
"    return LogLevel::DEBUG;
  } else if (min_log_level == ""info"") {
    return LogLevel::INFO;
  } else if (min_log_level == ""warning"") {
",2
"  }
  return ParseLogLevelStr(env_var_val);
",2
"    return false;
  } else {
",2
"
#include <Eigen/Cholesky>

namespace horovod {
namespace common {
",2
"//
// We use Gaussian Processes to infer functions directly as an alternative to inferring
// point estimates of the functions or posterior distributions. A Gaussian Process defines
",2
"// This implementation is based on the blog by Martin Krasser on Gaussian Processes, along with
// scikit-learn, and is an adaptation of the Python + NumPy code to C++.
//
// See: http://krasserm.github.io/2018/03/19/gaussian-processes
",2
"  // Machine Learning (GPML) by Rasmussen and Williams.
  //
  // Args:
  //  alpha: Value added to the diagonal of the kernel matrix during fitting.
",2
"  //         Larger values correspond to increased noise level in the observations.
  //         This can also prevent a potential numerical issue during fitting, by
  //         ensuring that the calculated values form a positive definite matrix.
  GaussianProcessRegressor(double alpha);

",2
"private:
  // Kernel parameter for noise. Higher values make more coarse approximations which avoids overfitting to noisy data.
  double alpha_;

",2
"  // Kernel parameter that controls the vertical variation of functions drawn from the GP. Higher values lead to wider
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================
",2
"#include <iostream>
",2
"  y_train_ = y_train;

  // This function will apply the natural logarithm element-wise to a matrix
  auto ln = [](double x) {
",2
"
",2
"  // We wish to minimize the negative log-likelihood of f(x) above by evaluating it at a given point, then
  // empirically approximating the derivative to follow the gradient downwards.
  double f_min = std::numeric_limits<double>::max();
  VectorXd x_min;
  auto nll_fn = [&](const VectorXd& x, VectorXd& grad) {
",2
"    // f(x) computed at the current point x
    double fx = f(x);

    // Update the best value observed so far, if x is a valid point
    if (!isnan(x) && fx < f_min) {
",2
"    return fx;
  };
",2
"    length_ = x[0];
    sigma_f_ = x[1];
  } else {
    length_ = x_min[0];
",2
"
",2
"      return std::sqrt(x);
    };
    *sigma = cov.diagonal().unaryExpr(sqrt);
  }
}
",2
"  MatrixXd k_inv = k.inverse();

  // Compute sufficient statistics of the posterior predictive distribution: mean and covariance.
  mu_s = (k_s.transpose() * k_inv) * y_train;
  cov_s = k_ss - (k_s.transpose() * k_inv) * k_s;
",2
"  auto& dot = x1 * x2.transpose();
",2
"  auto sqdist = x1_x2 - (dot.array() * 2).matrix();

",2
"  // the same l for all input dimensions (isotropic kernel).
",2
"// limitations under the License.
// =============================================================================
",2
"// See: http://krasserm.github.io/2018/03/21/bayesian-optimization
class BayesianOptimization {
public:
  // Performs binary optimization over the observed data by predicting the next sample to evaluate.
",2
"  //  bounds: Vector of (min, max) range values for each parameter (d x 1).
  //  alpha: Gaussian process noise parameter (see GaussianProcessRegressor).
  //  xi: Exploitation-exploration trade-off parameter, increase to explore more of the space.
  BayesianOptimization(std::vector<std::pair<double, double>> bounds, double alpha, double xi=0.01);

",2
"
  // Provides the next sample point to evaluate subject to maximizing the
  // expected improvement of the target acquisition function.
  Eigen::VectorXd NextSample(bool normalize=true);
",2
"  // Args:
  //  acquisition: Acquisition function.
  //  x_sample: Sample locations (n x d).
",2
"  //  y_sample: Sample values (n x 1).
  //  n_restarts: How many times to run minimization routine with random restarts.
",2
"      const Eigen::MatrixXd& x_sample, const Eigen::MatrixXd& y_sample, int n_restarts=25);

  // Computes the Expected Improvement at points X based on existing samples X_sample and Y_sample
  // using a Gaussian process surrogate model fitted to the samples.
  //
",2
"  // Args:
",2
"  //  x: Proposed points at which EI shall be computed (m x d).
  //  x_sample: Sample locations observed (n x d).
  //
",2
"  std::vector<std::pair<double, double>> bounds_;
  double xi_;

",2
"};

",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"  *sigma = std::sqrt(sq_sum / v.size());
}

// Returns a list of distributions that generate real values uniformly and random between the bounds.
std::vector<std::uniform_real_distribution<>> GetDistributions(std::vector<std::pair<double, double>> bounds) {
",2
"  return dists;
}
",2
"}
",2
"
    VectorXd y_i(1);
",2
"  return ProposeLocation(x_sample, y_sample);
}

",2
"  y_samples_.clear();
}

VectorXd BayesianOptimization::ProposeLocation(const MatrixXd& x_sample, const MatrixXd& y_sample, int n_restarts) {
",2
"  // Objective function we wish to minimize, the negative acquisition function.
  auto f = [&](const VectorXd& x) {
",2
"    return -ExpectedImprovement(x.transpose(), x_sample)[0];
  };

  // Minimization routine. To approximate bounded LBFGS, we set to infinity the value of any input outside of bound.
",2
"  double fx_min = std::numeric_limits<double>::max();
  for (int i = 0; i < n_restarts; ++i) {
    // Generate a random starting point by drawing from our bounded distributions.
    VectorXd x = VectorXd::Zero(d_);
",2
"    for (unsigned int j = 0; j < d_; ++j) {
      x[j] = dists_[j](gen_);
",2
"  // Compute sufficient statistics for the observed locations.
  Eigen::VectorXd mu_sample;
  gpr_.Predict(x_sample, mu_sample);

  // Needed for noise-based model, otherwise use y_sample.maxCoeff().
",2
"  VectorXd ei = imp.cwiseProduct(z.unaryExpr(cdf)) + sigma.cwiseProduct(z.unaryExpr(pdf));
",2
"  return ei;
}

bool BayesianOptimization::CheckBounds(const Eigen::VectorXd& x) {
",2
"#include ""memory_store.h""

#include <chrono>
#include <thread>
",2
"
#include ""gloo/common/error.h""

",2
"namespace horovod {
namespace common {

void MemoryStore::set(const std::string& key, const std::vector<char>& data) {
",2
"
} // namespace common
} // namespace horovod

",2
"// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"
#ifndef HOROVOD_GLOO_STORE_H
#define HOROVOD_GLOO_STORE_H
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"namespace horovod {
namespace common {
",2
"
  void Barrier(Communicator communicator) override;

protected:
",2
"
template <typename T>
void BitOr(void* c_, const void* a_, const void* b_, size_t n) {
  T* c = static_cast<T*>(c_);
",2
"  const T* a = static_cast<const T*>(a_);
  const T* b = static_cast<const T*>(b_);
",2
"  for (size_t i = 0; i < n; i++) {
    c[i] = a[i] | b[i];
  }
",2
"  const T* a = static_cast<const T*>(a_);
",2
"  const T* b = static_cast<const T*>(b_);
  for (size_t i = 0; i < n; i++) {
",2
"// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
",2
"//
// Unless required by applicable law or agreed to in writing, software
",2
"#include <unordered_map>
#include <vector>

#include ""gloo_store.h""
",2
"  std::unordered_map<std::string, std::vector<char>> map_;
};

} // namespace common
} // namespace horovod
",2
"//
//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================
",2
"  void Initialize(const std::string& gloo_iface);
",2
"
  void Finalize();

  std::shared_ptr<gloo::Context> GetGlooContext(Communicator communicator);
",2
"
  bool IsEnabled() { return enabled_; }
",2
"
private:
  // Flag indicating whether gloo is enabled.
  bool enabled_ = false;
",2
"
#include ""gloo/common/error.h""

#include ""../logging.h""

",2
"namespace horovod {
",2
"  HTTP_PUT(key, data);
}

std::vector<char> HTTPStore::get(const std::string& key) {
",2
"    std::this_thread::sleep_for(std::chrono::milliseconds(10));
",2
"bool HTTPStore::CheckKeys(const std::vector<std::string>& keys) {
  std::vector<char> result;
  for (const auto& key : keys) {
",2
"    if (!HTTP_GET(key, result)) {
      return false;
    }
  }
  return true;
",2
"      LOG(DEBUG) << ""Exception: "" << e.what();
    }

    // sleep for 500ms before another try.
",2
"  std::string url = url_prefix_ + key;
  LOG(TRACE) << ""Send GET request to "" << url;
  http::Request request(url);

  http::Response response = PerformHTTP(request, HTTP_GET_METHOD);
",2
"  if (response.status == HTTP_NOT_FOUND) {
",2
"} // namespace horovod
// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
//
",2
"  // HTTP DELETE: send HTTP DELETE request to server, informing the server that
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"
namespace horovod {
namespace common {
",2
"      opts.setInput(&local_size_, 1);
      opts.setOutput(local_sizes.data(), size_);
      gloo::allgather(opts);
    }
    is_homogeneous_ = true;
",2
"}

int GlooController::GetTypeSize(DataType dtype) {
  switch (dtype) {
  case HOROVOD_FLOAT16:
",2
"
  // 1. Get message lengths from every rank.
  std::unique_ptr<int[]> recvcounts(new int[size_]);

",2
"    if (i == 0) {
",2
"
void GlooController::SendFinalTensors(ResponseList& response_list) {
  // Notify all nodes which tensors we'd like to reduce at this step.
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"
#include ""gloo_context.h""

#include <chrono>
",2
"
#include ""gloo/rendezvous/context.h""
#include ""gloo/rendezvous/file_store.h""
#include ""gloo/rendezvous/prefix_store.h""
",2
"#include ""gloo/transport/tcp/device.h""

#if HAVE_MPI
#include ""gloo/mpi/context.h""
",2
"#define HOROVOD_GLOO_GET_RANK_AND_SIZE ""rank_and_size""
#define HOROVOD_HOSTNAME ""HOROVOD_HOSTNAME""
#define HOROVOD_RANK ""HOROVOD_RANK""
#define HOROVOD_SIZE ""HOROVOD_SIZE""
#define HOROVOD_LOCAL_RANK ""HOROVOD_LOCAL_RANK""
",2
"  getline(ss, substr, ',');

  return (int) std::strtol(substr.c_str(), nullptr, 10);
",2
"  }
",2
"  LOG(DEBUG) << prefix << "" rendezvous started for rank="" << rank << "", size="" << size
",2
"  attr.iface = gloo_iface;
  attr.ai_family = AF_UNSPEC;
  auto dev = gloo::transport::tcp::CreateDevice(attr);
  auto timeout = GetTimeoutFromEnv();

",2
"void GlooContext::Initialize(const std::string& gloo_iface) {
  if (!enabled_) {
    return;
  }

",2
"  // Create a tcp device for communication
  // TODO(sihan): Add support for multiple interfaces:
",2
"  int rank = GetIntEnvOrDefault(HOROVOD_RANK, 0);
  int size = GetIntEnvOrDefault(HOROVOD_SIZE, 1);
  int local_rank = GetIntEnvOrDefault(HOROVOD_LOCAL_RANK, 0);
  int local_size = GetIntEnvOrDefault(HOROVOD_LOCAL_SIZE, 1);
",2
"  int cross_rank = GetIntEnvOrDefault(HOROVOD_CROSS_RANK, 0);
  int cross_size = GetIntEnvOrDefault(HOROVOD_CROSS_SIZE, 1);

  auto rendezvous_addr_env = std::getenv(HOROVOD_GLOO_RENDEZVOUS_ADDR);
  auto rendezvous_port = GetIntEnvOrDefault(HOROVOD_GLOO_RENDEZVOUS_PORT, -1);
",2
"
  bool elastic = GetBoolEnvOrDefault(HOROVOD_ELASTIC, false);
  if (elastic && reset_) {
    LOG(DEBUG) << ""elastic mode reinitialization started, reset rank="" << rank << "" size="" << size;
",2
"    std::string hostname = std::getenv(HOROVOD_HOSTNAME);
    std::string server_addr = rendezvous_addr_env;
    std::string scope = HOROVOD_GLOO_GET_RANK_AND_SIZE;
",2
"
    rank = ParseNextInt(ss);
    if (rank == -1) {
      // Signals that this host is not part of the job
      std::ostringstream out;
",2
"
    SetEnv(HOROVOD_RANK, std::to_string(rank).c_str());
    SetEnv(HOROVOD_SIZE, std::to_string(size).c_str());
",2
"    SetEnv(HOROVOD_CROSS_RANK, std::to_string(cross_rank).c_str());
    SetEnv(HOROVOD_CROSS_SIZE, std::to_string(cross_size).c_str());
    LOG(DEBUG) << ""elastic mode reinitialization complete, updated"" <<
                  "" rank: "" << last_rank << "" -> "" << rank <<
                  "" size: "" << last_size << "" -> "" << size <<
",2
"  local_ctx.reset();
  reset_ = true;
}

std::shared_ptr<gloo::Context>
",2
"    throw std::logic_error(""Unsupported communicator type."");
  }
}

",2
"// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"// ============================================================================

",2
"#include ""../operations.h""
#include ""../stall_inspector.h""
",2
"
namespace horovod {
",2
"namespace common {

std::string TypeName(LibType type) {
  switch (type) {
  case LibType::MPI:
",2
"  controller = LibType::GLOO;
#elif HOROVOD_CONTROLLER_DEFAULT == 'M'
  controller = LibType::MPI;
#endif
",2
"  }
",2
"
  LOG(DEBUG) << ""Using "" << TypeName(controller)
            << "" to perform controller operations."";
  return controller;
}
",2
"  return gloo_iface;
}
",2
"void ParseStallInspectorFromEnv(StallInspector& stall_inspector) {
",2
"        std::strtol(env_value, nullptr, 10));
",2
"  }
",2
"
void SetIntFromEnv(const char* env, int& val) {
  auto env_value = std::getenv(env);
",2
"int GetIntEnvOrDefault(const char* env_variable, int default_value) {
",2
"} // namespace common
}
// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
//
",2
"//
// Unless required by applicable law or agreed to in writing, software
",2
"
int GetIntEnvOrDefault(const char* env_variable, int default_value);
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"  switch (tensor->dtype()) {
  case HOROVOD_FLOAT32:
",2
"  case HOROVOD_INT32:
    return ccl_dtype_int;
  case HOROVOD_INT64:
",2
"                           "" is not supported in CCL."");
  }
}
",2
"  // Initialize CCL
",2
"}

void CCLContext::Finalize() {
  LOG(DEBUG) << ""Background thread destroy"";
",2
"  auto& first_entry = entries[0];
",2
"  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
",2
"    timeline.ActivityStartAll(entries, MEMCPY_OUT_FUSION_BUFFER);
    MemcpyOutFusionBuffer(buffer_data, entries);
    timeline.ActivityEndAll(entries);
",2
"  }

  return Status::OK();
",2
"
",2
"CCLAllgather::CCLAllgather(CCLContext* ccl_context, HorovodGlobalState* global_state)
",2
"}

Status CCLAllgather::Execute(std::vector<TensorTableEntry>& entries, const Response& response) {
  auto& timeline = global_state_->timeline;
",2
"
  // Sizes of subcomponents of each entry from all ranks
  auto** entry_component_sizes = new int64_t* [entries.size()];
",2
"
  int global_size = global_state_->controller->GetSize();
  auto* recvcounts = new int[global_size]();
",2
"  auto* displcmnts = new int[global_size]();

  for (size_t ec = 0; ec < entries.size(); ++ec) {
",2
"
  timeline.ActivityStartAll(entries, ALLOCATE_OUTPUT);
  Status status = AllocateOutput(entries, response, entry_component_sizes, recvcounts);
",2
"    /* Cleanup */
    for (size_t ec = 0; ec < entries.size(); ++ec) {
",2
"    delete[] entry_component_offsets;
    delete[] recvcounts;
",2
"  for (unsigned int rc = 0; rc < global_size; rc++) {
    rcounts[rc] = recvcounts[rc] * element_size;
  }

  global_state_->timeline.ActivityStartAll(entries, CCL_ALLGATHER);
",2
"    timeline.ActivityStartAll(entries, MEMCPY_OUT_FUSION_BUFFER);
    MemcpyOutFusionBuffer(entry_component_offsets, entry_component_sizes,
                          buffer_data, element_size, entries);
    timeline.ActivityEndAll(entries);
",2
"Status CCLBroadcast::Execute(std::vector<TensorTableEntry>& entries, const Response& response) {
  assert(entries.size() == 1);
  auto e = entries[0];

",2
"// Modifications copyright (C) 2019 Uber Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"  }

  buffer_len = (size_t)offset;

",2
"  // Set the input data to originate from the buffer.
  fused_input_data = buffer_data;
}

",2
"    void* buffer_data_at_offset = (uint8_t*)buffer_data + offset;
    MemcpyEntryOutFusionBuffer(entries, buffer_data_at_offset, e);
    offset += e.output->size();
  }
",2
"
void AllreduceOp::MemcpyEntryInFusionBuffer(
    const std::vector<TensorTableEntry>& entries, const TensorTableEntry& e,
",2
"                                   int64_t**& entry_component_sizes,
                                   int*& recvcounts) {
  int global_size = global_state_->controller->GetSize();
  for (size_t ec = 0; ec < entries.size(); ++ec) {
",2
"    auto& e = entries[ec];
    // Every tensor participating in Allgather operation may have different
    // first dimension size, but the rest of dimensions are same for all
    // tensors.  Here we get shape of tensor sliced by first dimension.
    TensorShape single_slice_shape;
",2
"    for (int i = 1; i < e.tensor->shape().dims(); ++i) {
      single_slice_shape.AddDim(e.tensor->shape().dim_size(i));
    }

    // Copy tensor sizes from the response into a vector of int64_t
",2
"    // and compute total size.  This is size of first dimension.
    int64_t total_entry_dimension_size = 0;
    const auto& tensor_sizes = response.tensor_sizes();
    for (int rc = 0; rc < global_size; ++rc) {
",2
"
    Status status = e.context->AllocateOutput(output_shape, &e.output);
    if (!status.ok()) {
      return status;
",2
"    if (rc == 0) {
      displcmnts[rc] = 0;
",2
"    const int64_t* const* entry_component_sizes, const int* recvcounts,
    int64_t**& entry_component_offsets) {
  unsigned int rank_displacement = 0;
  int global_size = global_state_->controller->GetSize();
  for (int rc = 0; rc < global_size; ++rc) {
",2
"      }
    }
",2
"    const std::vector<TensorTableEntry>& entries, const int* displcmnts,
    int element_size, void*& buffer_data) {
  // Access the fusion buffer.
  auto& first_entry = entries[0];
  auto buffer = global_state_->fusion_buffer.GetBuffer(
",2
"      first_entry.device, first_entry.context->framework(), global_state_->current_nccl_stream);
",2
"  for (auto& e : entries) {
    void* buffer_data_at_offset = (uint8_t*)buffer_data + offset;
    MemcpyEntryInFusionBuffer(entries, e, buffer_data_at_offset);
    offset += e.tensor->size();
",2
"void AllgatherOp::MemcpyOutFusionBuffer(
    const int64_t* const* entry_component_offsets,
    const int64_t* const* entry_component_sizes, const void* buffer_data,
    int element_size, std::vector<TensorTableEntry>& entries) {
  // Copy memory out of the fusion buffer.
",2
"      MemcpyEntryOutFusionBuffer(entries, buffer_data_at_offset, e,
                                 copy_offset, entry_size);
",2
"void AllgatherOp::MemcpyEntryInFusionBuffer(
    const std::vector<TensorTableEntry>& entries, const TensorTableEntry& e,
    void* buffer_data_at_offset) {
  std::memcpy(buffer_data_at_offset, e.tensor->data(),
",2
"              (size_t)e.tensor->size());
}
",2
"Status ErrorOp::Execute(std::vector<TensorTableEntry>& entries, const Response& response) {
  return Status::PreconditionError(response.error_message());
}

",2
"// You may obtain a copy of the License at
//
",2
"
#include ""nccl_operations.h""

namespace horovod {
namespace common {
",2
"    case HOROVOD_FLOAT16:
      return ncclFloat16;
",2
"    case HOROVOD_FLOAT32:
      return ncclFloat32;
",2
"    case HOROVOD_FLOAT64:
      return ncclFloat64;
    default:
",2
"      throw std::logic_error(""Type "" + DataType_Name(tensor->dtype()) +
                             "" is not supported in NCCL mode."");
  }
}

",2
"void NCCLContext::ErrorCheck(std::string op_name, ncclResult_t nccl_result, ncclComm_t& nccl_comm) {
  if (nccl_result != ncclSuccess) {
",2
"    ncclCommAbort(nccl_comm);
    throw std::logic_error(std::string(op_name) + "" failed: "" + ncclGetErrorString(nccl_result));
  }
}
",2
"      ncclCommDestroy(entry->second);
",2
"  nccl_comms.clear();
",2
"
",2
"  } else {
    throw std::logic_error(""Communicator type "" + std::to_string(communicator_type_) +
",2
"
    if (global_state_->timeline.Initialized()) {
      gpu_context_->RecordEvent(gpu_op_context_.event_queue, MEMCPY_IN_FUSION_BUFFER, *gpu_op_context_.stream);
    }
",2
"  int64_t num_elements = 0;
  for (auto& e : entries) {
",2
"    num_elements += e.tensor->shape().num_elements();
  }
",2
"  // Do allreduce.
  auto nccl_result = ncclAllReduce(fused_input_data, buffer_data,
                                   (size_t) num_elements,
",2
"                                   GetNCCLDataType(first_entry.tensor), ncclSum,
                                   *nccl_op_context_.nccl_comm_, *gpu_op_context_.stream);
  nccl_context_->ErrorCheck(""ncclAllReduce"", nccl_result, *nccl_op_context_.nccl_comm_);
  if (global_state_->timeline.Initialized()) {
    gpu_context_->RecordEvent(gpu_op_context_.event_queue, NCCL_ALLREDUCE, *gpu_op_context_.stream);
",2
"    MemcpyOutFusionBuffer(buffer_data, entries);

    if (global_state_->timeline.Initialized()) {
",2
"Status
",2
"                                 : buffer_len_per_rank;

  auto& timeline = global_state_->timeline;
  if (num_elements_per_rank > 0) {
",2
"                                            (size_t) num_elements_per_rank,
                                            GetNCCLDataType(first_entry.tensor),
                                            *nccl_op_context_.nccl_comm_, *gpu_op_context_.stream),
                              *nccl_op_context_.nccl_comm_);
    if (global_state_->timeline.Initialized()) {
",2
"    }
  }

  // Copy memory out of the fusion buffer.
  if (entries.size() > 1) {
",2
"    return false;
  }
  return param_manager.HierarchicalAllreduce();
}
",2
"  gpu_op_context_.InitGPUQueue(entries, response);

  // On root rank, ncclbcast sends data, on other ranks it receives data.
",2
"    for (size_t ec = 0; ec < entries.size(); ++ec) {
      delete[] entry_component_sizes[ec];
",2
"      if (tensor_sizes[ec * global_size + rc] != tensor_sizes[ec * global_size]) {
        same_shape = false;
      }
    }
",2
"    delete[] entry_component_sizes[ec];
    delete[] entry_component_offsets[ec];
  }
  delete[] entry_component_sizes;
  delete[] entry_component_offsets;
",2
"                              const std::vector<TensorTableEntry>& entries,
",2
"  auto& timeline = global_state_->timeline;
  auto& gpu_context = gpu_context_;

",2
"bool GPUAllreduce::Enabled(const ParameterManager& param_manager,
",2
"
bool GPUBroadcast::Enabled(const ParameterManager& param_manager,
                           const std::vector<TensorTableEntry>& entries,
",2
"  return entries[0].device != CPU_DEVICE_ID;
}

} // namespace common
} // namespace horovod
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
",2
"                                   std::vector<std::shared_ptr<AllreduceOp>> adasum_ops,
                                   std::shared_ptr<ErrorOp> error_op)
    : param_manager_(param_manager),
      allreduce_ops_(std::move(allreduce_ops)),
      allgather_ops_(std::move(allgather_ops)),
",2
"      return op->Execute(entries, response);
    }
",2
"}

Status OperationManager::ExecuteAllgather(std::vector<TensorTableEntry>& entries,
                                          const Response& response) const {
  for (auto& op : allgather_ops_) {
",2
"      return op->Execute(entries, response);
    }
  }
  throw std::logic_error(""No Broadcast operation enabled"");
",2
"}

Status OperationManager::ExecuteJoin(std::vector<TensorTableEntry>& entries,
                                          const Response& response) const {
",2
"Status OperationManager::ExecuteAdasum(std::vector<TensorTableEntry>& entries,
",2
"                                      const Response& response) const {
  return error_op_->Execute(entries, response);
}
",2
"    throw std::logic_error(""No operation found for response type provided"");
  }
}

",2
"DDLAllreduce::DDLAllreduce(DDLContext* ddl_context,
                           GPUContext* gpu_context,
                           HorovodGlobalState* global_state)
",2
"  gpu_op_context_.InitGPUQueue(entries, response);
",2
"  auto& timeline = global_state_->timeline;
  if (ddl_context_->ddl_local_device_id != first_entry.device) {
    throw std::logic_error(""DDL does not support more than one GPU device per process."");
",2
"
  // Copy memory into the fusion buffer.
",2
"    buffer_data = (void*) first_entry.output->data();
    buffer_len = (size_t) first_entry.output->size();
",2
"  }

  int64_t num_elements = 0;
  for (auto& e : entries) {
",2
"
  // Do allreduce.
",2
"
    if (timeline.Initialized()) {
      gpu_context_->RecordEvent(gpu_op_context_.event_queue, MEMCPY_OUT_FUSION_BUFFER, *gpu_op_context_.stream);
    }
  }
",2
"  }
  auto ddl_result = ddl_init(ddl_options);
  if (ddl_result != DDL_SUCCESS) {
    throw std::logic_error(""ddl_init failed."");
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"    auto status = hipGetDevice(&device);
",2
"    }

",2
"    auto& mutex = hip_events_mutex;
    {
      std::lock_guard<std::mutex> guard(mutex);
",2
"        *event = queue.front();
",2
"
  void ErrorCheck(std::string op_name, hipError_t hip_result) {
    if (hip_result != hipSuccess) {
",2
"    int greatest_priority;
    ErrorCheck(""hipDeviceGetStreamPriorityRange"",
        hipDeviceGetStreamPriorityRange(NULL, &greatest_priority));
    ErrorCheck(""hipStreamCreateWithPriority"",
        hipStreamCreateWithPriority(stream, hipStreamNonBlocking, greatest_priority));
",2
"  int GetDevice() {
    int device;
    ErrorCheck(""hipGetDevice"", hipGetDevice(&device));
",2
"    return device;
  }

  void SetDevice(int device) {
",2
"    ErrorCheck(""hipMemcpyAsync"", hipMemcpyAsync(dst, src, count, hipMemcpyDeviceToDevice, stream));
  }
",2
"    ErrorCheck(""hipMemcpyAsync"", hipMemcpyAsync(dst, src, count, hipMemcpyHostToDevice, stream));
",2
"  }

",2
"    ErrorCheck(""hipMemcpyAsync"", hipMemcpyAsync(dst, src, count, hipMemcpyDeviceToHost, stream));
  }

private:
  // We reuse HIP events as it appears that their creation carries non-zero cost.
",2
"} // namespace common
} // namespace horovod
// Copyright 2019 Microsoft. All Rights Reserved.
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"
",2
"AdasumGpuAllreduceOp::AdasumGpuAllreduceOp(MPIContext* mpi_context,
                                           NCCLContext* nccl_context,
                                           GPUContext* gpu_context,
",2
"                                           HorovodGlobalState* global_state)
    : AdasumMPI(mpi_context, global_state),
      NCCLAllreduce(nccl_context, gpu_context, global_state, Communicator::LOCAL) {
",2
"  // Pre-allocate host buffer size equal to the fusion buffer length
  current_host_buffer_length =
      global_state->parameter_manager.TensorFusionThresholdBytes();
  gpu_op_context_.host_buffer = (uint8_t*)malloc(current_host_buffer_length);
}
",2
"  if (gpu_op_context_.host_buffer != nullptr) {
    free(gpu_op_context_.host_buffer);
",2
"  }
}
Status AdasumGpuAllreduceOp::Execute(std::vector<TensorTableEntry>& entries,
                                     const Response& response) {
",2
"
",2
"  size_t buffer_len;
  uint8_t* host_buffer;
  // Copy memory into the fusion buffer.
  if (entries.size() > 1) {
",2
"  } else {
    fused_input_data = first_entry.tensor->data();
",2
"
  // If cluster is homogeneous and we are using fusion buffer, include
",2
"  // set the fusion buffer size divisible by local_size.
  if (global_state_->controller->IsHomogeneous() && entries.size() > 1) {
",2
"    num_elements = ((num_elements + div - 1) / div) * div;
    buffer_len = num_elements * element_size;
  }
",2
"
  size_t buffer_len_remaining = element_size * num_elements_remaining;

  void* buffer_data_remainder =
",2
"      (uint8_t*)buffer_data + buffer_len_per_rank * local_size;

  void* fused_input_data_remainder =
      (uint8_t*)fused_input_data + buffer_len_per_rank * local_size;

",2
"  int root_rank =
",2
"      global_state_->controller->IsHomogeneous() ? local_size - 1 : 0;
  bool is_root_rank = local_rank == root_rank;

  int64_t total_num_elements =
",2
"  auto& timeline = global_state_->timeline;
",2
"    auto nccl_result = ncclReduceScatter(
        fused_input_data, buffer_data_at_rank_offset,
",2
"
  if (num_elements_remaining > 0) {
    // Reduce the remaining data at local_size-1 to append to
",2
"    // existing buffer
    auto nccl_result = ncclReduce(
",2
"    // cudaHostAlloc is significantly slower than malloc.  Pre-allocating
",2
"
    // Since Adasum is not a per-element operation, an allreduce for fused
    // tensors needs to know boundaries of tensors. Calculate here the count
    // of elements for each tensor owned by this rank.
",2
"    std::vector<int> tensor_counts(entries.size());
    if (global_state_->controller->IsHomogeneous()) {
",2
"
    timeline.ActivityStartAll(entries, MEMCPY_OUT_HOST_BUFFER);
    gpu_context_->MemcpyAsyncH2D(buffer_data_at_rank_offset,
",2
"        ""ncclAllGather"", ncclAllGather(buffer_data_at_rank_offset, buffer_data,
                                       (size_t)num_elements_per_rank,
                                       GetNCCLDataType(first_entry.tensor),
                                       *nccl_op_context_.nccl_comm_, *gpu_op_context_.stream),
",2
"    if (global_state_->timeline.Initialized()) {
      gpu_context_->RecordEvent(gpu_op_context_.event_queue, NCCL_BCAST,
                                *gpu_op_context_.stream);
    }
",2
"  }

  // Copy memory out of the fusion buffer.
  if (entries.size() > 1) {
    MemcpyOutFusionBuffer(buffer_data, entries);
",2
"
    if (global_state_->timeline.Initialized()) {
",2
"
#include ""collective_operations.h""
",2
"
  bool Enabled(const ParameterManager& param_manager,
               const std::vector<TensorTableEntry>& entries,
               const Response& response) const override;
",2
"               const Response& response) const override;

protected:
",2
"  Status Execute(std::vector<TensorTableEntry>& entries, const Response& response) override;

  bool Enabled(const ParameterManager& param_manager,
               const std::vector<TensorTableEntry>& entries,
",2
"// Copyright 2016 The TensorFlow Authors. All Rights Reserved.
// Modifications copyright (C) 2019 Uber Technologies, Inc.
//
",2
"
",2
"  // Copy memory into the fusion buffer.
  auto& timeline = global_state_->timeline;
  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
    const void* fused_input_data;
",2
"
    timeline.ActivityEndAll(entries);
  } else {
    buffer_data = (void*) first_entry.output->data();
",2
"    buffer_len = (size_t) first_entry.output->size();
  }

",2
"  // Do allreduce.
  timeline.ActivityStartAll(entries, MPI_ALLREDUCE);
  const void* sendbuf = entries.size() > 1 || first_entry.tensor->data() == first_entry.output->data()
                        ? MPI_IN_PLACE : first_entry.tensor->data();
  int op = MPI_Allreduce(sendbuf, buffer_data,
",2
"
  // Copy memory out of the fusion buffer.
",2
"MPI_GPUAllgather::MPI_GPUAllgather(MPIContext* mpi_context,
                                   GPUContext* gpu_context,
                                   HorovodGlobalState* global_state)
    : GPUAllgather(gpu_context, global_state),
      mpi_context_(mpi_context) {}
",2
"  // allgatherv
",2
"  int element_size = mpi_context_->GetMPITypeSize(first_entry.tensor->dtype());

",2
"  void* buffer_data;
  int64_t total_num_elements = NumElements(entries);

  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
",2
"
    timeline.ActivityEndAll(entries);
  } else {
    sendbuf = first_entry.tensor->data();
",2
"  auto dtype = mpi_context_->GetMPIDataType(first_entry.tensor->dtype());
",2
"                          dtype,
                          buffer_data,
                          recvcounts,
",2
"                          displcmnts,
                          dtype,
                          mpi_context_->GetMPICommunicator(Communicator::GLOBAL));
  if (op != MPI_SUCCESS) {
",2
"  for (size_t ec = 0; ec < entries.size(); ++ec) {
    delete[] entry_component_sizes[ec];
    delete[] entry_component_offsets[ec];
  }
",2
"// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
",2
"#include ""gloo/broadcast.h""
#include ""gloo/math.h""
",2
"namespace horovod {
namespace common {
",2
"
IGlooAlgorithms* GetAlgorithmsForType(DataType dtype,
                                      GlooContext* gloo_context) {
  switch (dtype) {
",2
"  case HOROVOD_UINT8:
    return new GlooAlgorithms<u_int8_t>(gloo_context);
  case HOROVOD_INT8:
    return new GlooAlgorithms<int8_t>(gloo_context);
  case HOROVOD_UINT16:
",2
"    return new GlooAlgorithms<float>(gloo_context);
",2
"void GlooAlgorithms<T>::Allreduce(void* buffer_data, int num_elements) {
  gloo::AllreduceOptions opts(gloo_context_->ctx);
  opts.setOutput<T>(static_cast<T*>(buffer_data), (size_t) num_elements);

",2
"  gloo::AllgathervOptions opts(gloo_context_->ctx);
  opts.setInput<T>(static_cast<T*>(buffer_data) +
                       displcmnts[gloo_context_->ctx->rank],
                   counts[gloo_context_->ctx->rank]);
  opts.setOutput<T>(static_cast<T*>(buffer_out), counts);
",2
"  gloo::broadcast(opts);
",2
"
  // Copy memory into the fusion buffer.
",2
"    timeline.ActivityEndAll(entries);
  } else {
    buffer_data = (void*)first_entry.output->data();
    std::memcpy(buffer_data, first_entry.tensor->data(),
                (size_t)first_entry.tensor->size());
",2
"bool GlooAllgather::Enabled(const ParameterManager& param_manager,
",2
"  auto& timeline = global_state_->timeline;

  // Sizes of subcomponents of each entry from all ranks
",2
"  auto** entry_component_sizes = new int64_t*[entries.size()];
",2
"
  timeline.ActivityStartAll(entries, ALLOCATE_OUTPUT);
",2
"    }   
    delete[] entry_component_sizes;
",2
"
",2
"  if (entries.size() > 1) {
    timeline.ActivityStartAll(entries, MEMCPY_IN_FUSION_BUFFER);
",2
"    // need to move input data to its corresponding location in the output
    sendbuf = (void*)first_entry.tensor->data();
    buffer_data = (void*)first_entry.output->data();
    int buffer_offset = displcmnts[gloo_context_->ctx->rank] * element_size;
",2
"    std::memcpy((uint8_t*)buffer_data + buffer_offset, sendbuf,
                (size_t)first_entry.tensor->size());
",2
"    timeline.ActivityStartAll(entries, MEMCPY_OUT_FUSION_BUFFER);
    MemcpyOutFusionBuffer(entry_component_offsets, entry_component_sizes,
                          buffer_data, element_size, entries);
",2
"    timeline.ActivityEndAll(entries);
  }
",2
"}
",2
"
GlooBroadcast::GlooBroadcast(GlooContext* gloo_context,
",2
"
",2
"  assert(entries.size() == 1);
  auto e = entries[0];

  // On root rank, MPI_Bcast sends data, on other ranks it receives data.
",2
"  std::unique_ptr<IGlooAlgorithms> gloo_algos(
      GetAlgorithmsForType(e.tensor->dtype(), gloo_context_));
  gloo_algos->Broadcast(data_ptr, (int)e.tensor->shape().num_elements(),
                        e.root_rank);
  global_state_->timeline.ActivityEndAll(entries);
",2
"// =============================================================================

",2
"#ifndef HOROVOD_GLOO_OPERATIONS_H
#define HOROVOD_GLOO_OPERATIONS_H

#include ""collective_operations.h""
",2
"
  ~GlooAlgorithms() = default;

",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"// =============================================================================
",2
"namespace horovod {
namespace common {

",2
"}

Status AdasumMPIAllreduceOp::Execute(std::vector<TensorTableEntry>& entries,
                                     const Response& response) {
  if (entries.empty()) {
",2
"
",2
"    timeline.ActivityEndAll(entries);
  } else {
    buffer_data = (void*)first_entry.output->data();
    buffer_len = (size_t)first_entry.output->size();
    if (first_entry.tensor->data() != first_entry.output->data()) {
",2
"  timeline.ActivityStartAll(entries, MPI_ADASUM_ALLREDUCE);
  std::vector<int> tensor_counts;
",2
"} // namespace common
",2
"} // namespace horovod
// Copyright 2016 The TensorFlow Authors. All Rights Reserved.
// Modifications copyright (C) 2019 Uber Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"
",2
"  } else {
    buffer_data = (void*) first_entry.output->data();
",2
"    buffer_len = (size_t) first_entry.output->size();
  }

",2
"  const void* sendbuf = entries.size() > 1 || first_entry.tensor->data() == first_entry.output->data()
                        ? MPI_IN_PLACE : first_entry.tensor->data();
  int op = MPI_Allreduce(sendbuf, buffer_data,
",2
"    timeline.ActivityEndAll(entries);
  }
",2
"  void* buffer_data;
  int64_t total_num_elements = NumElements(entries);
",2
"
  if (entries.size() > 1) {
",2
"
  delete[] recvcounts;
  delete[] displcmnts;

  for (size_t ec = 0; ec < entries.size(); ++ec) {
",2
"    delete[] entry_component_offsets[ec];
",2
"MPIHierarchicalAllgather::MPIHierarchicalAllgather(MPIContext* mpi_context,
                                                   HorovodGlobalState* global_state)
    : MPIAllgather(mpi_context, global_state) {}

Status MPIHierarchicalAllgather::Execute(std::vector<TensorTableEntry>& entries, const Response& response) {
",2
"  // Offset of each subcomponent of every entry in the final buffer after
  // allgatherv
",2
"      delete[] entry_component_sizes[ec];
",2
"  SetDisplacements(recvcounts, displcmnts);
  SetEntryComponentOffsets(entries, entry_component_sizes, recvcounts, entry_component_offsets);

  int element_size = mpi_context_->GetMPITypeSize(first_entry.tensor->dtype());
",2
"      MPI_Win_free(&mpi_context_->window);
      global_state_->shared_buffer = nullptr;
",2
"    timeline.ActivityStartAll(entries, ALLOCATE_SHARED_BUFFER);
    int64_t window_size = global_state_->controller->GetLocalRank() == 0 ? total_size_in_bytes : 0;
    MPI_Win_allocate_shared(window_size,
                            element_size,
                            MPI_INFO_NULL,
",2
"
  // Compute cross-node allgather displacements and recvcounts for
",2
"      offset += global_state_->controller->GetLocalSizeAtCrossRank(i);
",2
"    }
  }
",2
"                     mpi_context_->GetMPIDataType(e.tensor->dtype()),
                     e.root_rank,
                     mpi_context_->GetMPICommunicator(Communicator::GLOBAL));
",2
"      }
    }

    return cudaEventCreateWithFlags(event, cudaEventBlockingSync | cudaEventDisableTiming);
",2
"        timeline.ActivityStartAll(entries, name);
      }
      ErrorCheck(""cudaEventSynchronize"", cudaEventSynchronize(event));
",2
"        timeline.ActivityEndAll(entries);
      }
",2
"
#include <ddl.hpp>

",2
"namespace common {
",2
"
  Status Execute(std::vector<TensorTableEntry>& entries, const Response& response) override;
",2
"
class MPI_GPUAllgather : public GPUAllgather {
public:
  MPI_GPUAllgather(MPIContext* mpi_context, GPUContext* gpu_context, HorovodGlobalState* global_state);
  virtual ~MPI_GPUAllgather()=default;
",2
"  MPIContext* mpi_context_;
};
",2
"#define HOROVOD_GPU_OPERATIONS_H

#include <queue>
",2
"#include <vector>

#if HAVE_CUDA
",2
"  // transfers before the GPU calls are complete. In order to wait for those
",2
"
  // GPU events are used as an alternative to host-device synchronization (which stalls the GPU pipeline)
  // for the purpose of recording timing on the Horovod timeline.
  //
  // When an event we wish to record occurs (for example, NCCL_ALLREDUCE), the event is enqueued. After the entire
",2
"
class GPUBroadcast : public BroadcastOp {
public:
  GPUBroadcast(GPUContext* context,
               HorovodGlobalState* global_state);
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"//
// Unless required by applicable law or agreed to in writing, software
",2
"// =============================================================================

",2
"#ifndef HOROVOD_OPERATION_MANAGER_H
#define HOROVOD_OPERATION_MANAGER_H

#include ""collective_operations.h""
#include ""../parameter_manager.h""
",2
"
namespace horovod {
namespace common {

class OperationManager {
",2
"                   std::shared_ptr<JoinOp> join_op,
                   std::vector<std::shared_ptr<AllreduceOp>> adasum_ops,
                   std::shared_ptr<ErrorOp> error_op);

  virtual ~OperationManager() = default;
",2
"  Status ExecuteError(std::vector<TensorTableEntry>& entries, const Response& response) const;
",2
"  ParameterManager* param_manager_;
",2
"
",2
"
#ifndef HOROVOD_COLLECTIVE_OPERATIONS_H
",2
"
#include <iostream>

#include ""../common.h""
#include ""../controller.h""
",2
"
class AllreduceOp : public HorovodOp {
public:
  AllreduceOp(HorovodGlobalState* global_state);
",2
"  virtual ~AllreduceOp() = default;

  virtual Status Execute(std::vector<TensorTableEntry>& entries,
                         const Response& response) = 0;

",2
"  MemcpyEntryOutFusionBuffer(const std::vector<TensorTableEntry>& entries,
                             const void* buffer_data_at_offset,
                             TensorTableEntry& e);
",2
"public:
  AllgatherOp(HorovodGlobalState* global_state);

  virtual ~AllgatherOp() = default;
",2
"
  virtual Status Execute(std::vector<TensorTableEntry>& entries,
",2
"                       const std::vector<TensorTableEntry>& entries,
",2
"
  virtual void SetDisplacements(const int* recvcounts, int*& displcmnts);

  virtual void
  SetEntryComponentOffsets(const std::vector<TensorTableEntry>& entries,
",2
"                        const int64_t* const* entry_component_sizes,
                        const void* buffer_data, int element_size,
                        std::vector<TensorTableEntry>& entries);

  virtual void
",2
"  MemcpyEntryInFusionBuffer(const std::vector<TensorTableEntry>& entries,
",2
"
class JoinOp : public HorovodOp {
public:
  JoinOp(HorovodGlobalState* global_state);

",2
"  ErrorOp(HorovodGlobalState* global_state);

  virtual ~ErrorOp() = default;

  virtual Status Execute(std::vector<TensorTableEntry>& entries, const Response& response);
",2
"// Modifications copyright (C) 2019 Uber Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"// See the License for the specific language governing permissions and
// limitations under the License.
",2
"
#if HAVE_CUDA
",2
"  std::vector<std::unordered_map<std::vector<int32_t>, ncclComm_t>> nccl_comms;

",2
"  void ErrorCheck(std::string op_name, ncclResult_t nccl_result, ncclComm_t& nccl_comm);

  void ShutDown();
};

",2
"        nccl_context_(nccl_context),
        global_state_(global_state),
        communicator_type_(communicator_type){};

  void InitNCCLComm(const std::vector<TensorTableEntry>& entries,
",2
"  ncclComm_t* nccl_comm_;

private:
  void PopulateNCCLCommStrategy(int& nccl_rank, int& nccl_size,
",2
"  horovod::common::Communicator communicator_type_;
};

class NCCLAllreduce : public GPUAllreduce {
",2
"        nccl_context_(nccl_context),
        nccl_op_context_(nccl_context, global_state, communicator_type),
        global_state_(global_state){};

",2
"public:
  NCCLBroadcast(NCCLContext* nccl_context, GPUContext* gpu_context,
                HorovodGlobalState* global_state)
      : GPUBroadcast(gpu_context, global_state),
        nccl_context_(nccl_context),
",2
"        mpi_context_(mpi_context){};
",2
"#endif
",2
"void GPUContext::Finalize() {
",2
"void GPUContext::StreamCreate(gpuStream_t *stream) {
  pimpl->StreamCreate(stream);
}

void GPUContext::StreamSynchronize(gpuStream_t stream) {
",2
"  return pimpl->GetDevice();
",2
"}

void GPUContext::SetDevice(int device) {
",2
"  pimpl->MemcpyAsyncD2D(dst, src, count, stream);
",2
"
void GPUContext::MemcpyAsyncD2H(void* dst, const void* src, size_t count, gpuStream_t stream) {
  pimpl->MemcpyAsyncD2H(dst, src, count, stream);
}

",2
"//
//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"
#include ""ccl.h""
",2
"};

class CCLAllreduce : public AllreduceOp {
public:
  CCLAllreduce(CCLContext* ccl_context, HorovodGlobalState* global_state);
",2
"};

class CCLAllgather : public AllgatherOp {
public:
  CCLAllgather(CCLContext* ccl_context, HorovodGlobalState* global_state);
",2
"  CCLContext* ccl_context_ ;
};

",2
"#ifndef HOROVOD_ADASUM_MPI_H
#define HOROVOD_ADASUM_MPI_H

",2
"
",2
"class AdasumMPI : public Adasum<MPI_Comm> {
public:
  AdasumMPI(MPIContext* mpi_context, HorovodGlobalState* global_state);
",2
"  void PointToPointSendRecv(void* input_data_buffer,
                            int64_t input_buffer_length,
                            void* output_data_buffer,
                            int64_t output_buffer_length,
",2
"//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"
#include <cstring>
#include <float.h>
",2
"#include ""../../global_state.h""

namespace horovod {
namespace common {
",2
"
",2
"                                    HorovodGlobalState* global_state) = 0;
",2
"                              Communicator_type* reduction_comms,
                              DataType data_type,
                              HorovodGlobalState* global_state) {
    switch (data_type) {
",2
"    case DataType::HOROVOD_FLOAT16:
      FusedAllreduce(entries, (uint16_t*)grad_buffer, (uint16_t*)recv_buffer,
                     data_type, tensor_counts, start_level, communicator, tag,
",2
"                     data_type, tensor_counts, start_level, communicator, tag,
",2
"                             bnormsq, layerid);
    } else if (horovod_datatype == DataType::HOROVOD_FLOAT64) {
      ComputeDotAndNormSqrds((double*)a, (double*)b, count, dotProduct, anormsq,
",2
"  virtual uint8_t* CheckBufferAndReallocate(uint8_t** buffer,
                                            uint64_t buffer_length,
                                            uint64_t& current_length) {
    if (buffer_length <= current_length) {
",2
"  uint8_t* recv_buffer_ = nullptr;

  // Keep track of current recv buffer length
  uint64_t current_recv_buffer_length;
",2
"  // recv_buffer: must point to a buffer of the same size as grad_buffer.
  // horovod_datatype: the element type of grad_buffer.
  // tensor_counts: is a list of how many elements grad_buffer contains for each
  // tensor
  //                involved in the allreduce. It should contain a 0 if this
",2
"  // start_level: set to 1 to perform all levels of the operation. When set to
",2
"  //              communication inside the node is implemented using another
  //              reduce-scatter algorithm, e.g. the one in NCCL, which may be
",2
"  // reduction_comms: pointer to an array of communicators for computing dot
  // products and
  //                  norms for Adasum. The communicators should include exactly
  //                  the ranks that this rank has either directly or indirectly
",2
"    int size = GetSizeWithComm(communicator);

    std::vector<std::vector<int>> nghrCountVec;
",2
"         nearest_power_2 = (nearest_power_2 << 1)) {
    }
    int level;
",2
"      if ((rank & level) != 0) {
        myCount = secondHalfMyCount;
        nghrCount = firstHalfMyCount;
        sendOffset = 0;
",2
"        myCount = firstHalfMyCount;
        nghrCount = secondHalfMyCount;
        sendOffset = myCount;
",2
"        recvOffset = 0;

        for (size_t i = 0; i < tensor_counts.size(); i++) {
",2
"
      nghrCountVec_index++;

",2
"      } else {
        recv_buffer = &grad_buffer[-nghrCount];
      }
      this->PointToPointSendRecv(grad_buffer, myCount * per_element_size,
                                 recv_buffer, nghrCount * per_element_size,
",2
"                                   DataType horovod_datatype,
                                   std::vector<int>& tensor_counts, int layerid,
                                   Communicator_type& comm, bool isLeftNeighbor,
                                   std::vector<double>& normAndDots,
                                   HorovodGlobalState* global_state) {
",2
"      double bnormsq = 0.;

      DispatchComputeDotAndNormSqrds(&a[bytesSoFar], &b[bytesSoFar],
",2
"                         comm, global_state);
",2
"
    bytesSoFar = 0;
    for (size_t i = 0; i < tensor_counts.size(); i++) {
      double dotProduct = normAndDots[i * 3];
      double anormsq;
",2
"      } else {
        bnormsq = normAndDots[i * 3 + 1];
",2
"        anormsq = normAndDots[i * 3 + 2];
      }
",2
"    bnormsq = 0.;

    for (int i = 0; i < count; i++) {
      dotProduct += (double)a[i] * (double)b[i];
",2
"  // Update a vector to a linear combination of itself and another vector.
  template <typename T>
  void ScaledAdd(int n, double acoeff, T* __restrict__ a, double bcoeff,
",2
"      anormVec = _mm256_fmadd_pd(aBot, aBot, anormVec);
      anormVec = _mm256_fmadd_pd(aTop, aTop, anormVec);
      bnormVec = _mm256_fmadd_pd(bBot, bBot, bnormVec);
",2
"      __m256 aVec = MmLoaduPhPartial(&a[i], len - i);
      __m256 bVec = MmLoaduPhPartial(&b[i], len - i);
      __m256d aBot = _mm256_cvtps_pd(_mm256_extractf128_ps(aVec, 0));
      __m256d aTop = _mm256_cvtps_pd(_mm256_extractf128_ps(aVec, 1));
",2
"      __m256d bBot = _mm256_cvtps_pd(_mm256_extractf128_ps(bVec, 0));
      __m256d bTop = _mm256_cvtps_pd(_mm256_extractf128_ps(bVec, 1));
      dotProductVec = _mm256_fmadd_pd(aBot, bBot, dotProductVec);
      dotProductVec = _mm256_fmadd_pd(aTop, bTop, dotProductVec);
      anormVec = _mm256_fmadd_pd(aBot, aBot, anormVec);
",2
"      MmStorePh(&a[i], _mm256_fmadd_ps(bcoeffVec, bVec, aVec));
",2
"      __m256 aVec = MmLoaduPhPartial(&a[i], len - i);
      __m256 bVec = MmLoaduPhPartial(&b[i], len - i);
",2
"      MmStorePhPartial(&a[i], _mm256_fmadd_ps(bcoeffVec, bVec, aVec), len - i);
",2
"  inline double Mm256ReductionPd(__m256d v) {
    __m128d vlow = _mm256_castpd256_pd128(v);
    __m128d vhigh = _mm256_extractf128_pd(v, 1); // high 128
    vlow = _mm_add_pd(vlow, vhigh);              // reduce down to 128
",2
"
  // store 8 float16 from val into a
  inline void MmStorePh(uint16_t* a, __m256 val) {
    __m128i r = _mm256_cvtps_ph(val, 0);
",2
"    _mm_storeu_si128((__m128i*)a, r);
  }

  // load len (< 8) float16s from a, fill the rest with 0s, and return the
  // __m256 register
",2
"} // namespace horovod

#endif // HOROVOD_ADASUM_H
// Copyright 2019 Microsoft. All Rights Reserved.
",2
"// You may obtain a copy of the License at
//
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"
#include ""adasum_mpi.h""

namespace horovod {
namespace common {
",2
"  // norms for tensors whose elements are split across multiple ranks, which
  // is required for implementing the Adasum operation. The first group
  // includes two elements: this rank and it's first VHDD neighbor. The
  // subsequent groups grow to include any ranks the previous group
  // communicates with. Thus the sizes of the groups are 2,4,8... up to the
",2
"  return local_rank;
}

int AdasumMPI::GetSizeWithComm(MPI_Comm comm) {
",2
"                          mpi_context_->GetMPIDataType(horovod_datatype),
                          dst_src_rank, tag, communicator, MPI_STATUS_IGNORE);
",2
"}

void DDL_MPIContextManager::EnvFinalize() {
",2
"namespace horovod {
",2
"
  void Enable() {
    enabled_ = true;
    LOG(DEBUG) << ""MPI context enabled."";
  };
",2
"
  MPI_Datatype GetMPIDataType(DataType dtype);

",2
"
  // MPI custom data type for float16.
  MPI_Datatype mpi_float16_t;
  MPI_Op mpi_float16_sum;
",2
"
  // Cross-node communicator for hierarchical allreduce.
  MPI_Comm cross_comm;

  // MPI Window used for shared memory allgather
",2
"  MPI_Win window;

",2
"  // Whether mpi context should be finalize.
  bool should_finalize = false;
};

",2
"
#endif // HOROVOD_MPI_CONTEXT_H
// Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
",2
"      : Controller(response_cache, tensor_queue, timeline, parameter_manager),
        mpi_ctx_(mpi_ctx) {
    LOG(DEBUG) << ""MPI Controller Initialized."";
",2
"
",2
"} // namespace horovod
#endif // HOROVOD_MPI_CONTROLLER_H
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"
namespace horovod {
namespace common {

",2
"// MPIController
",2
"void MPIController::DoInitialization() {
  // Check if multi-thread is supported.
  int provided;
",2
"
  // Determine if cluster is homogeneous, i.e., if every node has the same
  // local_size
  auto local_sizes = std::vector<int>(size_);
  MPI_Allgather(&local_size_, 1, MPI_INT, local_sizes.data(), 1, MPI_INT,
",2
"  for (int i = 0; i < size_; ++i) {
    if (local_sizes[i] != local_size_) {
",2
"  // Get cross-node rank and size in case of hierarchical allreduce.
  MPI_Comm_rank(mpi_ctx_.cross_comm, &cross_rank_);
  MPI_Comm_size(mpi_ctx_.cross_comm, &cross_size_);

  // Construct a shorter local sizes vector with length cross size.
",2
"  LOG(DEBUG) << ""MPI controller initialized."";
}

int MPIController::GetTypeSize(DataType dtype) {
  return mpi_ctx_.GetMPITypeSize(dtype);
",2
"  int ret_code = MPI_Allreduce(MPI_IN_PLACE, bitvector.data(), count,
                               MPI_LONG_LONG_INT, MPI_BAND, mpi_ctx_.mpi_comm);
  if (ret_code != MPI_SUCCESS) {
    throw std::runtime_error(
",2
"void MPIController::CrossRankBitwiseOr(std::vector<long long>& bitvector,
                                       int count) {
  int ret_code = MPI_Allreduce(MPI_IN_PLACE, bitvector.data(), count,
                               MPI_LONG_LONG_INT, MPI_BOR, mpi_ctx_.mpi_comm);
",2
"    throw std::runtime_error(
        ""MPI_AllReduce failed, see MPI output for details."");
  }
}

",2
"  size_t total_size = 0;
  for (int i = 0; i < size_; ++i) {
    if (i == 0) {
      displcmnts[i] = 0;
    } else {
",2
"  auto buffer = new uint8_t[total_size];
  MPI_Gatherv(nullptr, 0, MPI_BYTE, buffer, recvcounts, displcmnts, MPI_BYTE,
              RANK_ZERO, mpi_ctx_.mpi_comm);
",2
"
  // 4. Process messages.
",2
"    RequestList::ParseFromBytes(received_message_list, rank_buffer_ptr);
    ready_list.push_back(std::move(received_message_list));
  }

",2
"  // 5. Free buffers.
",2
"}

",2
"  MPI_Bcast(&encoded_response_length, 1, MPI_INT, RANK_ZERO, mpi_ctx_.mpi_comm);
",2
"  }
}

",2
"void MPIController::RecvFinalTensors(ResponseList& response_list) {
  int msg_length;
  int ret_code =
      MPI_Bcast(&msg_length, 1, MPI_INT, RANK_ZERO, mpi_ctx_.mpi_comm);
  if (ret_code != MPI_SUCCESS) {
",2
"}

void MPIController::Bcast(void* buffer, size_t size, int root_rank,
                          Communicator communicator) {
",2
"  MPI_Comm comm = mpi_ctx_.GetMPICommunicator(communicator);
",2
"// Modifications copyright (C) 2019 Uber Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",2
"#include <vector>

#include ""../common.h""
#include ""../half.h""
#include ""../logging.h""
",2
"
namespace horovod {
namespace common {

MPI_Datatype MPIContext::GetMPIDataType(const std::shared_ptr<Tensor> tensor) {
",2
"  return GetMPIDataType(tensor->dtype());
}

MPI_Datatype MPIContext::GetMPIDataType(const DataType dtype) {
",2
"  switch (dtype) {
",2
"  case HOROVOD_UINT8:
    return MPI_UINT8_T;
  case HOROVOD_INT8:
    return MPI_INT8_T;
",2
"    return MPI_INT16_T;
  case HOROVOD_INT32:
    return MPI_INT32_T;
  case HOROVOD_INT64:
",2
"  case HOROVOD_FLOAT32:
",2
"    return MPI_C_BOOL;
  default:
",2
"
MPI_Op MPIContext::GetMPISumOp(DataType dtype) {
",2
"    return local_comm;
  case CROSS:
    return cross_comm;
  default:
    throw std::logic_error(""Communicator "" + CommunicatorName(comm) +
",2
"
int MPIContext::GetMPITypeSize(DataType dtype) {
  int out;
",2
"
void MPIContext::Initialize(const std::vector<int>& ranks,
                            MPIContextManager& ctx_manager) {

  if (!enabled_) {
",2
"  }
  int is_mpi_initialized = 0;
  MPI_Initialized(&is_mpi_initialized);
  if (is_mpi_initialized) {
",2
"  if (!ranks.empty()) {
    MPI_Group world_group;
    MPI_Comm_group(MPI_COMM_WORLD, &world_group);
",2
"      mpi_comm = MPI_COMM_WORLD;
",2
"  MPI_Type_contiguous(2, MPI_BYTE, &mpi_float16_t);
  MPI_Type_commit(&mpi_float16_t);

  // Create custom MPI float16 summation op.
  MPI_Op_create(&float16_sum, 1, &mpi_float16_sum);
",2
"  }
",2
"  }
}

void MPIContextManager::EnvInitialize(int mpi_threads_required) {
",2
"
} // namespace common
} // namespace horovod
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"
namespace horovod {
namespace common {
namespace wire {

",2
"  DataType_HOROVOD_FLOAT64 = 8,
  DataType_HOROVOD_BOOL = 9,
",2
"  return values;
}

",2
"inline const char * const *EnumNamesDataType() {
  static const char * const names[] = {
    ""HOROVOD_UINT8"",
    ""HOROVOD_INT8"",
    ""HOROVOD_UINT16"",
",2
"}

inline const char *EnumNameDataType(DataType e) {
  if (e < DataType_HOROVOD_UINT8 || e > DataType_HOROVOD_BOOL) return """";
  const size_t index = static_cast<size_t>(e);
",2
"  return EnumNamesDataType()[index];
}
",2
"  RequestType_BROADCAST = 2,
  RequestType_JOIN = 3,
  RequestType_MIN = RequestType_ALLREDUCE,
",2
"  };
  return names;
}

",2
"inline const char *EnumNameRequestType(RequestType e) {
  if (e < RequestType_ALLREDUCE || e > RequestType_JOIN) return """";
  const size_t index = static_cast<size_t>(e);
",2
"
inline const ResponseType (&EnumValuesResponseType())[6] {
  static const ResponseType values[] = {
    ResponseType_ALLREDUCE,
    ResponseType_ALLGATHER,
",2
"    ""ALLGATHER"",
    ""BROADCAST"",
    ""JOIN"",
    ""ADASUM"",
",2
"}

inline const char *EnumNameResponseType(ResponseType e) {
  if (e < ResponseType_ALLREDUCE || e > ResponseType_ERROR) return """";
",2
"    VT_ROOT_RANK = 12,
    VT_DEVICE = 14,
    VT_TENSOR_SHAPE = 16
  };
",2
"    return static_cast<DataType>(GetField<int8_t>(VT_TENSOR_TYPE, 0));
  }
  const flatbuffers::String *tensor_name() const {
",2
"    return GetField<int32_t>(VT_ROOT_RANK, 0);
  }
",2
"  }
  const flatbuffers::Vector<int64_t> *tensor_shape() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_TENSOR_SHAPE);
",2
"  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
",2
"           VerifyField<int32_t>(verifier, VT_ROOT_RANK) &&
           VerifyField<int32_t>(verifier, VT_DEVICE) &&
",2
"
struct RequestBuilder {
",2
"  }
  void add_request_type(RequestType request_type) {
    fbb_.AddElement<int8_t>(Request::VT_REQUEST_TYPE, static_cast<int8_t>(request_type), 0);
  }
",2
"  }
  void add_tensor_shape(flatbuffers::Offset<flatbuffers::Vector<int64_t>> tensor_shape) {
    fbb_.AddOffset(Request::VT_TENSOR_SHAPE, tensor_shape);
",2
"        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  RequestBuilder &operator=(const RequestBuilder &);
",2
"    DataType tensor_type = DataType_HOROVOD_UINT8,
",2
"    const char *tensor_name = nullptr,
    int32_t root_rank = 0,
    int32_t device = 0,
",2
"    const std::vector<int64_t> *tensor_shape = nullptr) {
",2
"}

struct RequestList FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
",2
"    VT_REQUESTS = 4,
    VT_SHUTDOWN = 6
",2
"    return VerifyTableStart(verifier) &&
",2
"           VerifyOffset(verifier, VT_REQUESTS) &&
           verifier.VerifyVector(requests()) &&
           verifier.VerifyVectorOfTables(requests()) &&
           VerifyField<uint8_t>(verifier, VT_SHUTDOWN) &&
",2
"        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
",2
"  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *tensor_names() const {
",2
"    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_DEVICES);
  }
  const flatbuffers::Vector<int64_t> *tensor_sizes() const {
    return GetPointer<const flatbuffers::Vector<int64_t> *>(VT_TENSOR_SIZES);
",2
"           verifier.VerifyVectorOfStrings(tensor_names()) &&
           VerifyOffset(verifier, VT_ERROR_MESSAGE) &&
",2
"           VerifyField<int8_t>(verifier, VT_TENSOR_TYPE) &&
",2
"    fbb_.AddElement<int8_t>(Response::VT_RESPONSE_TYPE, static_cast<int8_t>(response_type), 0);
  }
  void add_tensor_names(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensor_names) {
",2
"  builder_.add_response_type(response_type);
  return builder_.Finish();
",2
"inline flatbuffers::Offset<Response> CreateResponseDirect(
",2
"    VT_SHUTDOWN = 6
  };
  const flatbuffers::Vector<flatbuffers::Offset<Response>> *responses() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Response>> *>(VT_RESPONSES);
",2
"           VerifyField<uint8_t>(verifier, VT_SHUTDOWN) &&
           verifier.EndTable();
  }
};

",2
"  void add_responses(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Response>>> responses) {
",2
"  }
};
",2
"const DataType TensorUtil::GetDType(NDArray* tensor) {
  switch (tensor->dtype()) {
  case mshadow::kFloat32:
",2
"  case mshadow::kFloat64:
    return static_cast<void*>(tensor->data().dptr<double>());
",2
"  default:
    throw std::logic_error(""Type "" + std::to_string(tensor->dtype()) +
                           "" is not supported in MPI mode."");
  }
}
",2
"
// Return size of tensor in bytes
",2
"int64_t TensorUtil::GetSize(NDArray* tensor) {
  int64_t element_size = 0;
",2
"  switch (tensor->dtype()) {
  case mshadow::kFloat32:
    element_size = kFloat32Size;
    break;
  case mshadow::kFloat64:
",2
"    break;
  case mshadow::kInt8:
    element_size = kInt8Size;
    break;
",2
"    throw std::logic_error(""Type "" + std::to_string(tensor->dtype()) +
",2
"                           "" is not supported in MPI mode."");
",2
"#endif
",2
"namespace horovod {
",2
"
// This class intentionally does not have destructor at the moment.
//
// Unfortunately, by the time this destructor would be called in normal
",2
"  if (device_ == CPU_DEVICE_ID) {
",2
"
",2
"MXOpContext::AllocatePersistent(int64_t size,
                                std::shared_ptr<PersistentBuffer>* tensor) {
  // Allocation errors are handled using PyMX exceptions.
  *tensor = std::make_shared<MXPersistentBuffer>(device_, size);
",2
"
#if HAVE_CUDA
#include ""cuda_runtime.h""
#include <mxnet/base.h>
#endif
",2
"#endif
  }
}

",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"from horovod.common.basics import HorovodBasics as _HorovodBasics
_basics = _HorovodBasics(__file__, 'mpi_lib')

",2
"    the same on all Horovod processes for a given name. The reduction will not
    start until all processes are ready to send and receive the tensor.

    This acts as a thin wrapper around an autograd function.  If your input
    tensor requires gradients, then callings this function will allow gradients
",2
"            c_in, c_out, c_str(name), ctypes.c_bool(average),
            ctypes.c_int(priority)))
    else:
",2
"

def allreduce_(tensor, average=True, name=None, priority=0):
",2
"        average: A flag indicating whether to compute average or summation,
",2
"    else:
        check_call(MPI_MXNET_LIB_CTYPES.horovod_mxnet_allreduce_async(
            c_in, c_out, name, ctypes.c_bool(average),
",2
"        A tensor of the same shape and type as `tensor`, with the value
        broadcasted from root rank.
    """"""
    c_in = tensor.handle
",2
" * \brief Protected CUDA call.
 * \param func Expression to call.
 *
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"#define HOROVOD_MXNET_MPI_OPS_H

",2
"        output_tensor(output_tensor),
        cpu_tensor(cpu_tensor),
        op_type(op_type),
",2
"  delete ops_param;
",2
"    def __init__(self, optimizer):
        self._optimizer = optimizer
        # Normalizing rescale_grad by Horovod size, which is equivalent to
",2
"        return getattr(self._optimizer, item)

    def create_state_multi_precision(self, index, weight):
        return self._optimizer.create_state_multi_precision(index, weight)

",2
"    def _do_allreduce(self, index, grad):
        if size() == 1: return

",2
"        if isinstance(index, (tuple, list)):
",2
"                allreduce_(grad[i], average=False,
",2
"    def set_lr_mult(self, args_lr_mult):
        self._optimizer.set_lr_mult(args_lr_mult)

",2
"class DistributedTrainer(mx.gluon.Trainer):
    def __init__(self, params, optimizer, optimizer_params=None):
",2
"
        # _scale is used to check and set rescale_grad for optimizer in Trainer.step()
        # function. Normalizing it by Horovod size, which is equivalent to performing
",2
"        # average in allreduce, has better performance. 
        self._scale /= size()

    def _allreduce_grads(self):
",2
"            if param.grad_req != 'null':
                allreduce_(param.list_grad()[0], average=False,
                           name=param.name, priority=-i)

",2
"

def broadcast_parameters(params, root_rank=0):
    """"""
    Broadcasts the parameters from root rank to all other processes.
",2
"        names, tensors = zip(*params.items())
    elif isinstance(params, mx.gluon.parameter.ParameterDict):
",2
"                new_init = _append_broadcast_init(p, root_rank)
                p._init_impl = types.MethodType(new_init, p)
    else:
",2
"
",2
"std::string GetOpName(const char* prefix, const char* name) {
  if (name != nullptr) {
    return std::string(prefix) + ""."" + std::string(name);
  }

",2
"static const char* ALLGATHER_OP_TYPE_NAME = ""horovod_allgather"";
static const char* BROADCAST_OP_TYPE_NAME = ""horovod_broadcast"";
",2
"    case OperationType::BROADCAST:
",2
"    case OperationType::ALLGATHER:
      enqueue_result = EnqueueTensorAllgather(
          hvd_context, hvd_tensor, nullptr, name, device,
          [on_complete](const Status& status) {
            InvokeCompleteCallback(on_complete, status);
",2
"        hvd_output = std::make_shared<MXTensor>(output);
      }
",2
"
  ThrowIfError(enqueue_result);
}

inline void PushHorovodOperation(OperationType op_type, NDArray* input,
",2
"  if (input_var != output_var) {
    MXEnginePushAsync(DoHorovodOperation, ops_param, DeleteMpiOpsParam,
                      &MX_EXEC_CTX, &input_var, 1, &output_var, 1,
",2
"}

#if HAVE_CUDA
void DoHorovodOperationCudaOnCPU(void*, void* on_complete_ptr, void* param) {
",2
"  auto name = ops_param->op_name;
",2
"  auto hvd_cpu_buffer = std::make_shared<MXTensor>(ops_param->cpu_tensor.get());
  auto hvd_context = std::make_shared<MXOpContext>(
",2
"    default:
      throw std::logic_error(""Unsupported Horovod operation type."");
  }

",2
"  auto op_type_name = GetOpTypeName(op_type);
  auto op_name = GetOpName(op_type_name, name);
",2
"
bool IsTensorOnCPU(NDArray* tensor) {
  return tensor->ctx().dev_mask() == cpu::kDevMask;
}

",2
"extern ""C"" int horovod_mxnet_allreduce_async(NDArray* input, NDArray* output,
                                             const char* name, bool average,
                                             int priority) {
",2
"    PushHorovodOperation(OperationType::ALLREDUCE, input, output,
                         name, priority);
  } else {
    PushHorovodOperationCudaOnCPU(OperationType::ALLREDUCE, input, output,
                                  name, priority);
",2
"  }

  MX_API_END();
",2
"                         name, priority);
",2
"  } else {
    PushHorovodOperationCudaOnCPU(OperationType::ALLGATHER, input, output,
",2
"
  MX_API_END();
}
",2
"  MX_API_END();
}

} // namespace mxnet
} // namespace horovod
",2
"// Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
//
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================

",2
"namespace mxnet {

class with_device {
public:
",2
"  with_device(int device);
  ~with_device();

private:
  int restore_device_;
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"//     http://www.apache.org/licenses/LICENSE-2.0
//
",2
"// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
",2
"private:
  int device_;
  void* buffer_;
};

",2
"  virtual const void* data() const override;
  virtual int64_t size() const override;

protected:
",2
"TENSOR_UTIL_DEFINE_CPU_TYPE(DataType::HOROVOD_FLOAT32, THFloatTensor,
                            THFloatStorage)
TENSOR_UTIL_DEFINE_CPU_TYPE(DataType::HOROVOD_FLOAT64, THDoubleTensor,
",2
"#define HOROVOD_TORCH_ADAPTER_V2_H
",2
"
",2
"// See the License for the specific language governing permissions and
",2
"#else
    throw std::logic_error(""Internal error. Requested TorchPersistentBuffer ""
                           ""with GPU device but not compiled with CUDA."");
#endif
  }
",2
"template <DataType DT, DeviceType Dev, class T>
TorchTensor<DT, Dev, T>::TorchTensor(T* tensor) : tensor_(tensor) {}
",2
"
template <DataType DT, DeviceType Dev, class T>
const void* TorchTensor<DT, Dev, T>::data() const {
",2
"template <DataType DT, DeviceType Dev, class T>
",2
"TorchOpContext<DT, Dev, T>::TorchOpContext(int device, T* output)
",2
"    : device_(device), output_(output) {}

template <DataType DT, DeviceType Dev, class T>
Status TorchOpContext<DT, Dev, T>::AllocatePersistent(
",2
"    int64_t size, std::shared_ptr<PersistentBuffer>* tensor) {
  // Allocation errors are handled using PyTorch exceptions.
  *tensor = std::make_shared<TorchPersistentBuffer>(device_, size);
  return Status::OK();
}
",2
"  TensorUtil::ResizeNd<DT, Dev>(output_, shape.dims(), shape_array, nullptr);
",2
"  delete[] shape_array;
  *tensor = std::make_shared<TorchTensor<DT, Dev, T>>(output_);
  return Status::OK();
",2
"  case StatusType::INVALID_ARGUMENT:
",2
"
ADAPTER_DEFINE_TYPE(DataType::HOROVOD_UINT8, DeviceType::CPU, THByteTensor)
",2
"                    THCudaDoubleTensor)
#endif

",2
"namespace torch {
",2
"
",2
"}

",2
"std::shared_ptr<Status> HandleManager::ReleaseHandle(int handle) {
  std::lock_guard<std::mutex> guard(mutex_);
",2
"} // namespace horovod# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",2
"
",2
"

class Compressor(object):
    """"""Interface for compressing and decompressing a given tensor.""""""
    @staticmethod
",2
"class Compression(object):
    """"""Optional gradient compression algorithm used during allreduce.""""""

    """"""Do not compress the gradients. This is the default.""""""
    none = NoneCompressor
",2
"// Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
// Modifications copyright Microsoft
//
",2
"  if (tensor.device().is_cuda()) {
",2
"    return tensor.device().index();
  }
  return CPU_DEVICE_ID;
}
",2
"  auto device = GetDeviceID(tensor);
  auto ready_event = RecordReadyEvent(device);
",2
"  auto hvd_tensor = std::make_shared<TorchTensor>(tensor);
  auto hvd_context = std::make_shared<TorchOpContext>(device, output);
  auto hvd_output = std::make_shared<TorchTensor>(output);

",2
"      hvd_context, hvd_cpu_tensor, ready_event,
",2
"
  auto device = GetDeviceID(tensor);
",2
"  if (horovod_rank() == root_rank) {
    if (tensor.data_ptr() != output.data_ptr()) {
",2
"    hvd_output = std::make_shared<TorchTensor>(output);
  }

  auto handle = handle_manager.AllocateHandle();
",2
"  auto enqueue_result =
      EnqueueTensorBroadcast(hvd_context, hvd_tensor, hvd_output, root_rank,
                             ready_event, GetOpName(""broadcast"", name, handle),
",2
"  return handle;
}

",2
"int DoBroadcastCudaOnCPU(::torch::Tensor tensor, ::torch::Tensor output, int root_rank,
                         const std::string& name) {
  ThrowIfError(common::CheckInitialized());

",2
"    std::this_thread::sleep_for(std::chrono::milliseconds(1));
  }
  auto status = handle_manager.ReleaseHandle(handle);
  ThrowIfError(*status);
}
",2
"
",2
"
",2
"  return handle;
}


",2
"        &DoAllreduceCudaOnCPU);
",2
"  m.def(""horovod_torch_allreduce_async_torch_cuda_DoubleTensor"",
        &DoAllreduceCudaOnCPU);
#endif

  // allgather
",2
"  m.def(""horovod_torch_allgather_async_torch_cuda_LongTensor"", &DoAllgather);
  m.def(""horovod_torch_allgather_async_torch_cuda_HalfTensor"", &DoAllgather);
  m.def(""horovod_torch_allgather_async_torch_cuda_FloatTensor"", &DoAllgather);
  m.def(""horovod_torch_allgather_async_torch_cuda_DoubleTensor"", &DoAllgather);
#else
",2
"  m.def(""horovod_torch_allgather_async_torch_cuda_FloatTensor"",
        &DoAllgatherCudaOnCPU);
  m.def(""horovod_torch_allgather_async_torch_cuda_DoubleTensor"",
        &DoAllgatherCudaOnCPU);
#endif
",2
"#if HOROVOD_GPU_BROADCAST
  m.def(""horovod_torch_broadcast_async_torch_cuda_ByteTensor"", &DoBroadcast);
  m.def(""horovod_torch_broadcast_async_torch_cuda_CharTensor"", &DoBroadcast);
  m.def(""horovod_torch_broadcast_async_torch_cuda_ShortTensor"", &DoBroadcast);
",2
"        &DoBroadcastCudaOnCPU);
  m.def(""horovod_torch_broadcast_async_torch_cuda_DoubleTensor"",
        &DoBroadcastCudaOnCPU);
#endif
",2
"
",2
"  std::shared_ptr<Status> ReleaseHandle(int handle);

private:
  std::atomic_int last_handle_;
",2
"int horovod_torch_allreduce_async_torch_LongTensor(THLongTensor* tensor,
                                                   THLongTensor* output,
",2
"                                                     int divisor, char* name,
                                                     int reduce_op);

int horovod_torch_allgather_async_torch_ByteTensor(THByteTensor* tensor,
",2
"                                                   THByteTensor* output,
",2
"                                                  THIntTensor* output,
                                                  char* name);
int horovod_torch_allgather_async_torch_LongTensor(THLongTensor* tensor,
                                                   THLongTensor* output,
                                                   char* name);
",2
"                                                   int root_rank, char* name);
int horovod_torch_broadcast_async_torch_FloatTensor(THFloatTensor* tensor,
                                                    THFloatTensor* output,
                                                    int root_rank, char* name);
int horovod_torch_broadcast_async_torch_DoubleTensor(THDoubleTensor* tensor,
",2
"                                                     THDoubleTensor* output,
                                                     int root_rank, char* name);
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"
import torch
from torch.autograd.function import Function
import torch.nn.functional as F
from torch.nn.modules.batchnorm import _BatchNorm
",2
"            learnable affine parameters. Default: `True`
        track_running_stats: a boolean value that when set to `True`, this
",2
"        super().__init__(num_features, eps, momentum, affine, track_running_stats)
",2
"    def _run_bn(self, input):
        return F.batch_norm(
            input, self.running_mean, self.running_var, self.weight, self.bias,
            self.training or not self.track_running_stats, self.momentum, self.eps)
",2
"        return _SyncBatchNorm.apply(
            input, self.weight, self.bias, self.running_mean, self.running_var,
            self.eps, self.momentum)

",2
"            return self._run_bn(input)
        else:
            return self._maybe_run_sync_bn(input)

",2
"        input = input.contiguous()

        size = input.numel() // input.size(1)
",2
"        mean, invstd = torch.batch_norm_stats(input, eps)
",2
"        count_all = synchronize(count_handle)
        mean_all = synchronize(mean_handle)
        invstd_all = synchronize(invstd_handle)

        if _SYNC_BN_V2:
",2
"            mean_all,
            invstd_all,
            running_mean,
",2
"            counts_for_bngswc
",2
"
        # apply element-wise normalization
        return torch.batch_norm_elemt(input, weight, bias, mean, invstd, eps)

    @staticmethod
",2
"        # calculate local stats as well as grad_weight / grad_bias
        sum_dy, sum_dy_xmu, grad_weight, grad_bias = torch.batch_norm_backward_reduce(
            grad_output,
            saved_input,
            mean,
",2
"                mean_dy,
                mean_dy_xmu
            )
        else:
",2
"            grad_input = None

        # synchronizing of grad_weight / grad_bias is not needed as distributed
        # training would handle all reduce.
",2
"
import copy

from horovod.common.elastic import run_fn, ObjectState
from horovod.torch.mpi_ops import init, rank, shutdown
",2
"from horovod.torch.functions import broadcast_object, broadcast_optimizer_state, broadcast_parameters


",2
"    its state needs to be brought to the same point as the other workers, which is done by synchronizing
",2
"        broadcast_parameters(self.model.state_dict(), root_rank=0)
",2
"// You may obtain a copy of the License at
",2
"// limitations under the License.
// =============================================================================

",2
"
",2
"namespace torch {

with_device::with_device(int device) {
",2
"#if HAVE_GPU
    THCudaCheck(cudaGetDevice(&restore_device_));
",2
"
} // namespace torch
} // namespace horovod
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
",2
"import warnings

from contextlib import contextmanager

import torch
",2
"

class _DistributedOptimizer(torch.optim.Optimizer):
",2
"
        if named_parameters is not None:
            named_parameters = list(named_parameters)
        else:
            named_parameters = [('allreduce.noname.%s' % i, v)
",2
"                                for param_group in self.param_groups
                                for i, v in enumerate(param_group['params'])]
        # make sure that named_parameters are tuples
",2
"        if any([not isinstance(p, tuple) for p in named_parameters]):
            raise ValueError('named_parameters should be a sequence of '
                             'tuples (name, parameter), usually produced by '
",2
"            raise ValueError('Parameter names in named_parameters must be unique. '
",2
"
        all_param_ids = {id(v)
                         for param_group in self.param_groups
                         for v in param_group['params']}
",2
"                    p.grad = p.data.new(p.size()).zero_()
",2
"
    def synchronize(self):
",2
"        self._handles.clear()
",2
"            yield
        finally:
            self._should_synchronize = True

",2
"                              ""optimizer.skip_synchronize() context if you use ""
                              ""optimizer.synchronize() in your code."")
            self.synchronize()
        self._synchronized = False
",2
"                                 ""but before optimizer.step() or optimizer.synchronize(). ""
                                 ""This is prohibited as it can cause a race condition."")
        return super(self.__class__, self).zero_grad()


",2
"            raise ValueError('named_parameters should be a sequence of '
                             'tuples (name, parameter), usually produced by '
                             'model.named_parameters().')
",2
"        unnamed_param_ids = all_param_ids - named_param_ids
        if len(unnamed_param_ids):
            raise ValueError('named_parameters was specified, but one or more model '
                             'parameters were not named. Python object ids: '
",2
"
        start.data.copy_(p)
",2
"
        # reset stashed parameters
        for stashed, group in zip(stashed_params, self.param_groups):
",2
"        return handle, ctx

    def _make_hook(self, p):
        def hook(*ignore):
",2
"                        ""to step(). Increase backward_passes_per_step to ""
",2
"    def synchronize(self):
        pass

",2
"
    def step(self, closure=None):
        loss = None
        if closure is not None:
            loss = closure()
",2
"
",2
"            handle, ctx = self._allreduce_grad_async(p)
            self._handles[p] = (handle, ctx)

        for p, (handle, ctx) in self._handles.items():
            # This means step() is called before backward_passes_per_steps finished.
",2
"            self._allreduce_delay[p] = self.backward_passes_per_step
        self._handles.clear()
        return loss

",2
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"if _v2_api:
    from horovod.torch import mpi_lib_v2 as mpi_lib
    from horovod.common.basics import HorovodBasics as _HorovodBasics
",2
"
from horovod.torch.compression import Compression

# import basic methods
",2
"size = _basics.size
local_size = _basics.local_size
rank = _basics.rank
local_rank = _basics.local_rank
mpi_threads_supported = _basics.mpi_threads_supported
",2
"Average = _basics.Average
",2
"Sum = _basics.Sum
Adasum = _basics.Adasum

",2
"# before the operation is finished.
_handle_map = {}

",2
"                    raise NotImplementedError('Running GPU Adasum on heterogeneous cluster is not supported yet.')
",2
"        else:
            if not num_rank_is_power_2(size()):
                raise NotImplementedError('Running Adasum with non-power of 2 ranks is not supported yet.')
",2
"                                            name.encode() if name is not None else _NULL, true_op)
    except RuntimeError as e:
        raise HorovodInternalError(e)
    _handle_map[handle] = (tensor, output)
",2
"    return handle


def allreduce_async(tensor, average=None, name=None, op=None):
    """"""
",2
"
    Arguments:
        tensor: A tensor to reduce.
",2
"    are ready to send and receive the tensor.

    This acts as a thin wrapper around an autograd function.  If your input
",2
"                     of data sent during the each parameter update step.  Defaults to
                     not using compression.
        op: The reduction operation to combine tensors across different ranks. Defaults
            to Average if None is given.
",2
"
    Returns:
        A tensor of the same shape and type as `tensor`, averaged or summed across all
",2
"        processes.
",2
"
def allreduce_async_(tensor, average=None, name=None, op=None):
    """"""
",2
"        `synchronize()`.
    """"""
",2
"    A function that performs in-place averaging or summation of the input tensor over
    all the Horovod processes.

    The reduction operation is keyed by the name. If name is not provided, an incremented
",2
"

def _allgather_async(tensor, output, name):
    function = _check_function(_allgather_function_factory, tensor)
",2
"    dimension, which is allowed to be different.

    Arguments:
        tensor: A tensor to allgather.
",2
"class HorovodAllgather(torch.autograd.Function):
    """"""An autograd function that performs allgather on a tensor.""""""

    @staticmethod
",2
"        name: A name of the allgather operation.

",2
"
",2
"        tensor: A tensor to broadcast.
        root_rank: The rank to broadcast the value from.
",2
"            grad_reduced *= 0
        return grad_reduced, None, None


def broadcast(tensor, root_rank, name=None):
",2
"    Returns:
",2
"    """"""
    handle = broadcast_async_(tensor, root_rank, name)
",2
"    return synchronize(handle)

",2
"
def poll(handle):
",2
"

",2
"    """"""
    if handle not in _handle_map:
        return

    try:
",2
"    except RuntimeError as e:
        raise HorovodInternalError(e)
// Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
//
",2
"//
",2
"// See the License for the specific language governing permissions and
// limitations under the License.
",2
"#include ""cuda_util.h""

",2
"namespace horovod {
namespace torch {

using namespace horovod::common;
",2
"
// TH<xxx>Tensor are all aliased to THTensor as of PyTorch 0.4.1, so we need
// an additional template parameter to distinguish between them.
class TensorUtil {
public:
",2
"  template <DataType DT, DeviceType Dev, class T>
  static const TensorShape GetShape(T* tensor);
  template <DataType DT, DeviceType Dev, class T>
",2
"  template <DataType DT, DeviceType Dev, class T> static T* New(int device);
  template <DataType DT, DeviceType Dev, class T>
  static void Free(T* tensor);
",2
"  template <DataType DT, class TC, class T>
  static void AsyncCopyCudaToCPU(TC* cuda, T* cpu);
",2
"
#define TENSOR_UTIL_DEFINE_TYPE_H(HorovodType, DeviceType, THTensor)           \
",2
"      THTensor * tensor);                                                      \
",2
"  const void* TensorUtil::GetData<HorovodType, DeviceType, THTensor>(          \
      THTensor * tensor);                                                      \
  template <>                                                                  \
  int64_t TensorUtil::GetSize<HorovodType, DeviceType, THTensor>(THTensor *    \
                                                                 tensor);      \
",2
"  template <>                                                                  \
  THTensor* TensorUtil::New<HorovodType, DeviceType, THTensor>(int device);    \
  template <>                                                                  \
  void TensorUtil::Free<HorovodType, DeviceType, THTensor>(THTensor * tensor); \
  template <>                                                                  \
",2
"#define TENSOR_UTIL_DEFINE_CPU_TYPE_H(HorovodType, THTensor)                   \
  TENSOR_UTIL_DEFINE_TYPE_H(HorovodType, DeviceType::CPU, THTensor)

#define TENSOR_UTIL_DEFINE_CUDA_TYPE_H(HorovodType, THCTensor, THTensor)       \
  TENSOR_UTIL_DEFINE_TYPE_H(HorovodType, DeviceType::GPU, THCTensor)           \
",2
"  template <>                                                                  \
",2
"  template <>                                                                  \
",2
"  const TensorShape TensorUtil::GetShape<HorovodType, DeviceType::CPU,         \
                                         THTensor>(THTensor * tensor) {        \
    TensorShape shape;                                                         \
",2
"  }                                                                            \
",2
"                                                                               \
  template <>                                                                  \
  void TensorUtil::Free<HorovodType, DeviceType::CPU, THTensor>(THTensor *     \
",2
"                                                                tensor) {      \
    THTensor##_free(tensor);                                                   \
",2
"  template <>                                                                  \
  void TensorUtil::Copy<HorovodType, DeviceType::CPU, THTensor>(               \
      THTensor * output, THTensor * tensor) {                                  \
    THTensor##_copy(output, tensor);                                           \
  }                                                                            \
",2
"                                                                               \
  template <>                                                                  \
  void                                                                         \
  TensorUtil::DivideTensorInPlace<HorovodType, DeviceType::CPU, THTensor>(     \
      THTensor * tensor, int value) {                                          \
",2
"  }                                                                            \
                                                                               \
  template <>                                                                  \
  int TensorUtil::GetDevice<HorovodType, DeviceType::GPU, THCTensor>(          \
      THCTensor * tensor) {                                                    \
",2
"    with_device device_context(THCTensor##_getDevice(state, tensor));          \
    THCTensor##_resizeNd(state, tensor, nDimension, size, stride);             \
  }                                                                            \
",2
"  void TensorUtil::Copy<HorovodType, DeviceType::GPU, THCTensor>(              \
      THCTensor * output, THCTensor * tensor) {                                \
",2
"                                                                               \
  template <>                                                                  \
",2
"  void TensorUtil::AsyncCopyCudaToCPU<HorovodType, THCTensor, THTensor>(       \
      THCTensor * cuda, THTensor * cpu) {                                      \
    with_device device_context(THCTensor##_getDevice(state, cuda));            \
",2
"TENSOR_UTIL_DEFINE_CPU_TYPE_H(DataType::HOROVOD_FLOAT32, THFloatTensor)
TENSOR_UTIL_DEFINE_CPU_TYPE_H(DataType::HOROVOD_FLOAT64, THDoubleTensor)

#if HAVE_GPU
",2
"TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_UINT8, THCudaByteTensor,
                               THByteTensor)
TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_INT8, THCudaCharTensor,
                               THCharTensor)
",2
"TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_INT16, THCudaShortTensor,
                               THShortTensor)
TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_INT32, THCudaIntTensor,
                               THIntTensor)
",2
"TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_INT64, THCudaLongTensor,
                               THLongTensor)
TENSOR_UTIL_DEFINE_CUDA_TYPE_H(DataType::HOROVOD_FLOAT32, THCudaTensor,
",2
"//
",2
"// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =============================================================================

",2
"                                                       char* name);
int horovod_torch_allgather_async_torch_cuda_LongTensor(
    THCudaLongTensor* tensor, THCudaLongTensor* output, char* name);
",2
"int horovod_torch_broadcast_async_torch_cuda_CharTensor(
    THCudaCharTensor* tensor, THCudaCharTensor* output, int root_rank,
",2
"                                                         int root_rank,
                                                         char* name);
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"
#include <TH/TH.h>

",2
"#if HAVE_GPU
#include <THC/THC.h>
#endif

",2
"
#if HAVE_GPU
ALLREDUCE_H(torch_cuda_IntTensor, THCudaIntTensor)
ALLREDUCE_H(torch_cuda_LongTensor, THCudaLongTensor)
",2
"BROADCAST_H(torch_cuda_IntTensor, THCudaIntTensor)
",2
"#ifndef HOROVOD_TORCH_READY_EVENT_H
#define HOROVOD_TORCH_READY_EVENT_H

",2
"
#include ""../common/common.h""

namespace horovod {
",2
"namespace torch {

using namespace horovod::common;

#if HAVE_GPU
",2
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",2
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
",2
"from horovod.torch.compression import Compression
",2
"from horovod.torch.functions import broadcast_object, broadcast_optimizer_state, broadcast_parameters
from horovod.torch.mpi_ops import allreduce, allreduce_async, allreduce_, allreduce_async_
from horovod.torch.mpi_ops import allgather, allgather_async
",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
",2
"
",2
"        params: One of the following:
            - list of parameters to broadcast
            - dict of parameters to broadcast
",2
"

def broadcast_optimizer_state(optimizer, root_rank):
    """"""
",2
"    if len(state_dict['state']) == 0:
        for group in optimizer.param_groups:
            for p in group['params']:
                if p.requires_grad and id(p) not in state_dict['state']:
",2
"            optimizer.step()
        state_dict = optimizer.state_dict()

    # If the state_dict is still empty after initialization, then
",2
"    # tensors.  In such cases, we need to wrap the scalar in a tensor, then
    # broadcast, then update the appropriate value in the state_dict with the
    # new unwrapped scalar value via a callback.
",2
"        for option_key, option_value in group.items():
            if option_key == 'params':
                continue

            # Options like the learning rate are scalar, and need to be wrapped in tensors
",2
"                continue

            param_state = state_dict['state'][pid]
            for name, p in param_state.items():
",2
"                if not torch.is_tensor(p):
                    # Wrap the scalar in a FloatTensor, and remember its type
                    # so we can cast it back after unwrapping
                    t = type(p)
",2
"        sz = torch.IntTensor([t.shape[0]])
        broadcast_(sz, root_rank, name + '.sz')
",2
"
    if rank() != root_rank:
        buf = io.BytesIO(t.numpy().tobytes())
        obj = cloudpickle.load(buf)
",2
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"#include ""adapter_v2.h""
#include ""cuda_util.h""

namespace horovod {
namespace torch {
",2
"    return ::torch::kChar;
  case common::HOROVOD_INT16:
    return ::torch::kShort;
  case common::HOROVOD_INT32:
    return ::torch::kInt;
",2
"  case common::HOROVOD_INT64:
    return ::torch::kLong;
  case common::HOROVOD_FLOAT16:
    return ::torch::kHalf;
  case common::HOROVOD_FLOAT32:
",2
"    return common::HOROVOD_FLOAT16;
  case ::torch::kFloat:
    return common::HOROVOD_FLOAT32;
",2
"    shape.AddDim(tensor_.size(idx));
  }
  return shape;
",2
"# if TORCH_VERSION >= 1001000000
  return tensor_.element_size() * tensor_.numel();
#else
",2
"#endif
}

",2
"  return Status::OK();
}

",2
"  *tensor = std::make_shared<TorchTensor>(zero_tensor);
",2
"  return Status::OK();
}

Framework TorchOpContext::framework() const {
",2
"  return Framework::PYTORCH;
}

",2
"  switch (status.type()) {
  case StatusType::OK:
    return;
",2
"  case StatusType::PRECONDITION_ERROR:
    throw std::logic_error(status.reason());
  case StatusType::ABORTED:
    throw std::runtime_error(status.reason());
  case StatusType::INVALID_ARGUMENT:
",2
"// limitations under the License.
",2
"#include <c10/cuda/CUDAException.h>
#else
",2
"#include <queue>
#include <unordered_map>
",2
"#endif
",2
"#endif
#endif
",2
"namespace horovod {
",2
"static ReadyEventRegistry ready_event_registry;

TorchReadyEvent::TorchReadyEvent(int device) : device_(device) {
",2
"  {
    std::lock_guard<std::mutex> guard(ready_event_registry.mutex);
    auto& queue = ready_event_registry.cuda_events[device_];
    if (!queue.empty()) {
",2
"      C10_CUDA_CHECK(cudaEventCreateWithFlags(
          &cuda_event_, cudaEventBlockingSync | cudaEventDisableTiming));
      #else
",2
"  #else
  auto stream = THCState_getCurrentStreamOnDevice(state, device_);
  THCudaCheck(cudaEventRecord(cuda_event_, stream));
",2
"}
#endif

",2
"std::shared_ptr<ReadyEvent> RecordReadyEvent(int device) {
  if (device == CPU_DEVICE_ID) {
    return std::shared_ptr<ReadyEvent>();
  } else {
#if HAVE_GPU
",2
"#include ""ready_event.h""
",2
"#include ""tensor_util.h""

",2
"      GetOpName(""allreduce"", name, handle), device,
      [handle, divisor, output](const Status& status) {
        if (divisor > 1) {
          TensorUtil::DivideTensorInPlace<DT, Dev, T>(output, divisor);
        }
",2
"  ReduceOp reduce_op = static_cast<ReduceOp>(reduce_op_int);
  auto handle = handle_manager.AllocateHandle();
  auto enqueue_result = EnqueueTensorAllreduce(
      hvd_context, hvd_cpu_buffer, hvd_cpu_buffer, ready_event,
",2
"  ThrowIfError(common::CheckInitialized());

  auto device = TensorUtil::GetDevice<DT, Dev>(tensor);
  auto ready_event = RecordReadyEvent(device);
  auto hvd_tensor = std::make_shared<TorchTensor<DT, Dev, T>>(tensor);
",2
"  std::shared_ptr<Tensor> hvd_output = nullptr;
  if (horovod_rank() == root_rank) {
    if (tensor != output) {
",2
"      TensorUtil::Copy<DT, Dev>(output, tensor);
    }
  } else {
    hvd_output = std::make_shared<TorchTensor<DT, Dev, T>>(output);
  }
",2
"  return handle;
}
",2
"
#define ALLREDUCE(torch_Tensor, HorovodType, DeviceType, THTensor)                    \
  extern ""C"" int horovod_torch_allreduce_async_##torch_Tensor(                        \
      THTensor* tensor, THTensor* output, int divisor, char* name, int reduce_op) {   \
    return DoAllreduce<HorovodType, DeviceType>(tensor, output, divisor,              \
",2
"          THCudaIntTensor)
ALLREDUCE(torch_cuda_LongTensor, DataType::HOROVOD_INT64, DeviceType::GPU,
          THCudaLongTensor)
",2
"ALLREDUCE_CUDA_ON_CPU(torch_cuda_IntTensor, DataType::HOROVOD_INT32,
",2
"ALLREDUCE_CUDA_ON_CPU(torch_cuda_LongTensor, DataType::HOROVOD_INT64,
",2
"ALLREDUCE_CUDA_ON_CPU(torch_cuda_DoubleTensor, DataType::HOROVOD_FLOAT64,
",2
"          THFloatTensor)
ALLGATHER(torch_DoubleTensor, DataType::HOROVOD_FLOAT64, DeviceType::CPU,
          THDoubleTensor)

",2
"          THCudaShortTensor)
ALLGATHER(torch_cuda_IntTensor, DataType::HOROVOD_INT32, DeviceType::GPU,
",2
"                                                name);                         \
  }

BROADCAST(torch_ByteTensor, DataType::HOROVOD_UINT8, DeviceType::CPU,
",2
"          THFloatTensor)
BROADCAST(torch_DoubleTensor, DataType::HOROVOD_FLOAT64, DeviceType::CPU,
          THDoubleTensor)
",2
"
#define BROADCAST_CUDA_ON_CPU(torch_Tensor, HorovodType, THCTensor, THTensor)  \
  extern ""C"" int horovod_torch_broadcast_async_##torch_Tensor(                 \
",2
"#endif

extern ""C"" int horovod_torch_join(int device) {
",2
"
extern ""C"" int horovod_torch_poll(int handle) {
  return handle_manager.PollHandle(handle) ? 1 : 0;
",2
"//
// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
",2
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
",2
"template <DataType DT, DeviceType Dev, class T>
class TorchTensor : public Tensor {
",2
"  virtual int64_t size() const override;

protected:
  T* tensor_ = nullptr;
",2
"};

template <DataType DT, DeviceType Dev, class T>
",2
"class TorchOpContext : public OpContext {
public:
  TorchOpContext(int device, T* output);
  virtual Status
",2
"  virtual Status AllocateZeros(int64_t num_elements, DataType dtype,
                               std::shared_ptr<Tensor>* tensor) override;
",2
"#define ADAPTER_DEFINE_TYPE(HorovodType, DeviceType, THTensor)                     \
  template class TorchTensor<HorovodType, DeviceType, THTensor>;                   \
  template class TorchTemporaryBuffer<HorovodType, DeviceType, THTensor>;          \
  template class TorchOpContext<HorovodType, DeviceType, THTensor>;

",2
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",2
"        if callable(fn):
            locals[symbol] = _wrap_function(fn, _ffi)
        else:
",2
"_import_symbols(locals())
# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
",2
"    for symbol in dir(_lib):
        fn = getattr(_lib, symbol)
        if callable(fn):
",2
"

",2
"        self.state.epoch = epoch
# Copyright 2018 Uber Technologies, Inc. All Rights Reserved.
",2
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",2
"# limitations under the License.
# ==============================================================================

",2
"import warnings

import horovod.tensorflow as hvd
import tensorflow as tf
",2
"            else:
                bcast_op = hvd.broadcast_global_variables(self.root_rank)
                self.backend.get_session().run(bcast_op)
",2
"            self.backend.get_session().run(var.initializer)
            allreduce_op = hvd.allreduce(var, device_dense=self.device)
",2
"            self.multiplier = multiplier

        if self.initial_lr is None:
            warnings.warn('Parameter `initial_lr` will be required in v0.21.0', DeprecationWarning)

",2
"        if hasattr(self.model.optimizer, 'momentum') and self.momentum_correction:
            # See the paper cited above for more information about momentum correction.
",2
"    def on_train_begin(self, logs=None):
",2
"
    def on_epoch_begin(self, epoch, logs=None):
        self.current_epoch = epoch

    def on_batch_begin(self, batch, logs=None):
",2
"        if (self.current_epoch < self.start_epoch or
",2
"            # learning rate graphs look better.
",2
"        _HAS_AGGREGATE_GRAD = True

",2
"            self._aggregated_gradients = False
            super(self.__class__, self).__init__(**kwargs)

",2
"            return self._allreduce(gradients)

        def _aggregate_gradients(self, grads_and_vars):
            gradients = [grad for grad, var in grads_and_vars]
            return self._allreduce(gradients)
",2
"                                'using TensorFlow 2.0, please specify '
",2
"    # This class will have the same name as the optimizer it's wrapping, so that the saved
    # model could be easily restored without Horovod.
",2
"
def _eval(backend, op_or_result):
    if hvd._executing_eagerly():
        return op_or_result
    else:
",2
"    return _eval(backend, hvd.allreduce(tf.constant(value, name=name), average=average))
",2
"    if custom_optimizers is not None:
        horovod_objects.update({
            cls.__name__: wrap_optimizer(cls)
            for cls in custom_optimizers
",2
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",2
"class Params(object):
    @staticmethod
    def _dummy():
        return MagicMock()

",2
"
    'pyspark',
    'pyspark.ml',
    'pyspark.ml.linalg',
",2
"    'pyspark.sql.types',

    'tensorflow',
    'tensorflow.python',
",2
"    'mxnet.base',

    'horovod.common.util',
    'horovod.torch.mpi_lib_v2',
]
",2
"        },
        'keras': {
            'callbacks': {
",2
"                'batchnorm': {
                    '_BatchNorm': MagicMock,
                }
            },
        },
",2
"            'keras': {
                'estimator': {
                    'KerasEstimatorParamsReadable': MagicMock,
                    'KerasEstimatorParamsWritable': MagicMock,
",2
"
def instrument():
    sys.modules.update((mod_name, gen_mock_package(mod_name))
",2
"                       for mod_name in MOCK_MODULES)
# Configuration file for the Sphinx documentation builder.
#
# This file only contains a selection of the most common options. For a full
# list see the documentation:
",2
"
",2
"
# The master toctree document.
",2
"# -- Options for HTML output -------------------------------------------------
",2
"#
# For alabaster: https://alabaster.readthedocs.io/en/latest/customization.html
#
html_theme_options = {
    'logo': 'logo.png',
",2
"import sys
from os import path

",3
"
            # add tag `all` at the end
",3
"class PostDevelopCommand(develop):
    """"""Post-installation for development mode.""""""

    def run(self):
        develop.run(self)
",3
"        'Development Status :: 5 - Production/Stable',
        'Intended Audience :: Developers',
        'Intended Audience :: Education',
        'Intended Audience :: Science/Research',
        'Programming Language :: Python :: 3.7',
",3
"
""""""
Miscellaneous enums used in jina


",3
"To use these enums in YAML config, following the example below:

",3
".. highlight:: yaml
.. code-block:: yaml

",3
"    with:
      logserver_config: yaml/test-server-config.yml
",3
"        """"""Required by :mod:`ruamel.yaml.constructor` """"""
        return representer.represent_scalar('!' + cls.__name__, str(data))
",3
"
    @classmethod
",3
"class SchedulerType(BetterEnum):
    LOAD_BALANCE = 0  #: balance the workload between Peas, faster peas get more work
    ROUND_ROBIN = 1  #: workload are scheduled round-robin manner to the peas, assuming all peas have uniform processing speed.


",3
"class PollingType(BetterEnum):
    """"""The enum for representing the parallel type of peas in a pod

    """"""
    ANY = 1  #: one of the replica will receive the message
",3
"        """"""
",3
"        return self.value == 1

    @property
    def is_block(self) -> bool:
",3
"    PULL_BIND = 0
",3
"
        :return: if this socket is using `bind` protocol
",3
"        return self.value % 2 == 0

    @property
",3
"
        :return: a paired
",3
"            SocketType.PUSH_BIND: SocketType.PULL_CONNECT,
            SocketType.PUB_CONNECT: SocketType.SUB_BIND,
            SocketType.PUB_BIND: SocketType.SUB_CONNECT,
            SocketType.PAIR_CONNECT: SocketType.PAIR_BIND
",3
"

class FlowOutputType(BetterEnum):
    """"""The enum for representing flow output config """"""
",3
"    """"""The enum for representing a flow's build level

    Some :class:`jina.flow.Flow` class functions require certain build level to run.
",3
"    """"""
",3
"    EMPTY = 0  #: Nothing is built
",3
"import random
import re
",3
"    return deco
",3
"                f'and will be removed in the next version; please use ""{new}"" instead')
            kwargs[new] = kwargs.pop(alias)


",3
"    fp.write('\n'.join(treeview))

    fp.write(f'\n\n## Modules in a Table View \n\n| Class | Module |\n')
",3
"        yield data
",3
"        return
    if isinstance(data, np.ndarray):
",3
"    if v.startswith('[') and v.endswith(']'):
        # function args must be immutable tuples not list
        tmp = v.replace('[', '').replace(']', '').strip().split(',')
",3
"        if len(tmp) > 0:
            return [parse_arg(vv.strip()) for vv in tmp]
        else:
",3
"        except ValueError:
            if len(v) == 0:
",3
"        sys.stdout.write('\n')
        sys.stdout.flush()
    while t > 0:
",3
"
def load_contrib_module():
",3
"        os.environ['JINA_CONTRIB_MODULE_IS_LOADING'] = 'true'

        modules = []
",3
"
        if contrib:
            from .logging import default_logger
            default_logger.info(
",3
"    def add_modules(*paths):
        for p in paths:
            if not os.path.exists(p):
                raise FileNotFoundError('cannot import module from %s, file not exist', p)
",3
"
_random_names = (('first', 'great', 'local', 'small', 'right', 'large', 'young', 'early', 'major', 'clear', 'black',
                  'whole', 'third', 'white', 'short', 'human', 'royal', 'wrong', 'legal', 'final', 'close', 'total',
                  'prime', 'happy', 'sorry', 'basic', 'aware', 'ready', 'green', 'heavy', 'extra', 'civil', 'chief',
                  'usual', 'front', 'fresh', 'joint', 'alone', 'rural', 'light', 'equal', 'quiet', 'quick', 'daily',
",3
"                  'voice', 'stage', 'light', 'march', 'board', 'month', 'music', 'field', 'award', 'issue', 'basis',
                  'front', 'heart', 'force', 'model', 'space', 'peter',))

",3
"                if (stack_id is not None and s['id'] == stack_id) or stack_id is None:
",3
"    config_path = os.environ.get('JINA_STACK_CONFIG', '.jina-stack.yml')
    _all = {'stacks': []}
    if os.path.exists(config_path):
",3
"        for s in _all['stacks']:
            if s['id'] == stack_id:
                _all['stacks'].remove(s)
                break
    with open(config_path, 'w') as fp:
",3
"
",3
"                    p.__dict__[k] = SimpleNamespace()
                    _scan(v, p.__dict__[k])
                elif isinstance(v, list):
                    p.__dict__[k] = list()
                    _scan(v, p.__dict__[k])
",3
"    def _replace(sub_d: Union[Dict, List], p):
        if isinstance(sub_d, Dict):
            for k, v in sub_d.items():
                if isinstance(v, dict) or isinstance(v, list):
                    _replace(v, p.__dict__[k])
",3
"                else:
",3
"                if isinstance(v, dict) or isinstance(v, list):
                    _replace(v, p[idx])
                else:
                    if isinstance(v, str) and (re.match(r'{.*?}', v) or re.match(r'\$.*\b', v)):
",3
"               'on_red': 41,
               'on_green': 42,
               'on_yellow': 43,
               'on_blue': 44,
               'on_magenta': 45,
",3
"    'magenta': 35,
    'cyan': 36,
",3
"        if color:
            text = fmt_str % (_COLORS[color], text)

        if on_color:
            text = fmt_str % (_HIGHLIGHTS[on_color], text)
",3
"

def get_tags_from_node(node) -> List[str]:
    """"""Traverse the YAML by node and return all tags
",3
"                    yield from node_recurse_generator(k)
            elif isinstance(nn, nodes.Node):
",3
"    args = []
    for k, v in kwargs.items():
        k = k.replace('_', '-')
",3
"    return args

",3
"
def valid_yaml_path(path: str, to_stream: bool = False):
    # priority, filepath > classname > default
    import io
",3
"        # possible class name
        return io.StringIO(f'!{path}')
    else:
        raise FileNotFoundError('%s can not be resolved, it should be a readable stream,'
                                ' or a valid file path, or a supported class name.' % path)
",3
"    try:
",3
"        p_args, unknown_args = parser.parse_known_args(args)
        if unknown_args:
            from .logging import default_logger
            default_logger.warning(
                f'parser {parser_name} can not '
",3
"                f'recognize the following args: {unknown_args}, '
                f'they are ignored. if you are using them from a global args (e.g. Flow), '
",3
"    _defaults = vars(parser.parse_args([]))
",3
"                'platform-version': platform.version(),
                'architecture': platform.machine(),
                'processor': platform.processor(),
",3
"        version_info = '\n'.join(f'{k:30s}{v}' for k, v in info.items())
",3
"        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url_pat.match(text) is not None
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

",3
"class BadDriverGroup(Exception):
",3
"
class NoIdleDealer(Exception):
    """"""All dealers are exhausted no more idle dealer""""""
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"__version__ = '0.2.0'

",3
"if sys.version_info < (3, 7, 0):
    raise OSError('Jina requires Python 3.7 and above, but yours is %s' % sys.version_info)

",3
"__jina_env__ = ('JINA_ARRAY_QUANT',
                'JINA_CONTRIB_MODULE',
                'JINA_CONTRIB_MODULE_IS_LOADING',
",3
"    if namespace == 'jina.executors':
",3
"    else:
        raise TypeError('namespace: %s is unrecognized' % namespace)

",3
"    for info in iter_modules([path]):
        if not info.ispkg:
            modules.add('.'.join([namespace, info.name]))

    for pkg in find_packages(path):
",3
"        pkgpath = path + '/' + pkg.replace('.', '/')
        if sys.version_info.major == 2 or (sys.version_info.major == 3 and sys.version_info.minor < 6):
            for _, name, ispkg in iter_modules([pkgpath]):
                if not ispkg:
                    modules.add('.'.join([namespace, pkg, name]))
",3
"
    if targets:
",3
"
",3
"import signal

signal.signal(signal.SIGINT, signal.default_int_handler)

",3
"def raise_nofile(nofile_atleast=4096):
",3
"
",3
"        try:
            res.setrlimit(res.RLIMIT_NOFILE, (soft, hard))
        except (ValueError, res.error):
            try:
                hard = soft
",3
"    return soft, hard


",3
"__license__ = ""Apache-2.0""

import os


",3
"    port_attr = ('help', 'choices', 'default', 'required', 'option_strings', 'dest')
",3
"    all_d = {'name': 'Jina',
             'description': 'Jina is the cloud-native neural search solution powered by state-of-the-art AI and deep learning technology',
             'license': 'Apache 2.0',
             'vendor': 'Jina AI Limited',
",3
"             'source': 'https://github.com/jina-ai/jina/tree/' + os.environ.get('JINA_VCS_VERSION', 'master'),
",3
"             'url': 'https://jina.ai',
             'docs': 'https://docs.jina.ai',
             'authors': 'dev-team@jina.ai',
",3
"            if a.default != b.default:
                random_dest.add(a.dest)
        for a in parser._actions:
            if isinstance(a, _StoreAction) or isinstance(a, _StoreTrueAction):
                ddd = {p: getattr(a, p) for p in port_attr}
",3
"                else:
                    ddd['type'] = a.type
                if ddd['choices']:
                    ddd['choices'] = [str(k) if isinstance(k, BetterEnum) else k for k in ddd['choices']]
",3
"
def _update_autocomplete():
    from jina.main.parser import get_main_parser

",3
"                '--check-version', '--array-in-pb', '--compress-hwm', '--compress-lwm', '--num-part', '--role',
                '--memory-hwm', '--runtime', '--max-idle-time', '--log-sse', '--log-remote', '--log-profile',
",3
"        'Jina 101': ('ð£', 'https://101.jina.ai'),
",3
"        epilog=f'Jina (v{colored(__version__, ""green"")}) is the cloud-native neural search solution '
",3
"    parser.add_argument('--refresh-time', type=int,
                        default=5,
                        help='refresh time interval in seconds, set to -1 to persist all grouped logs')
    return parser
",3
"

def set_hw_parser(parser=None):
    if not parser:
        parser = set_base_parser()
",3
"    gp.add_argument('--top-k', type=int, default=50,
                    help='top-k results to retrieve and visualize')

    return parser
",3
"                    help='output path of the flow')
",3
"    from ..helper import random_port, get_random_identity
    from .. import __default_host__
    import os
    if not parser:
        parser = set_base_parser()
",3
"    gp0 = add_arg_group(parser, 'pea basic arguments')
",3
"                          '> a YAML file path, '
",3
"                     default=SocketType.PUSH_BIND,
                     help='socket type for output port')
    gp2.add_argument('--port-ctrl', type=int, default=os.environ.get('JINA_CONTROL_PORT', random_port()),
                     help='port for controlling the pod, default a random port between [49152, 65535]')
",3
"    gp3.add_argument('--exit-no-dump', action='store_true', default=False,
                     help='do not serialize the model when the pod exits')
    gp3.add_argument('--read-only', action='store_true', default=False,
                     help='do not allow the pod to modify the model, '
",3
"                          'only effective when BasePod\'s `replicas` > 1')
",3
"
    gp5 = add_arg_group(parser, 'pea messaging arguments')
    gp5.add_argument('--check-version', action='store_true', default=False,
                     help='comparing the jina and proto version of incoming message with local setup, '
                          'mismatch raise an exception')
",3
"                          '-1 means no restriction')
    gp6.add_argument('--runtime', type=str, choices=['thread', 'process'], default='process',
                     help='the parallel runtime of the pod')
    gp6.add_argument('--max-idle-time', type=int, default=60,
                     help='label this pea as inactive when it does not '
",3
"                     help='the strategy of scheduling workload among peas')
    gp4.add_argument('--reducing-yaml-path', type=str, default='_forward',
                     help='the executor used for reducing the result from all replicas, '
",3
"    if not parser:
",3
"    return parser
",3
"#         parser = set_base_parser()
#     set_pod_parser(parser)
",3
"#     _set_grpc_parser(parser)
#
#     parser.add_argument('--pb2-path',
#                         type=str,
",3
"                     ctrl_with_ipc=True,  # otherwise ctrl port would be conflicted
                     read_only=True)
    gp1.add_argument('--prefetch', type=int, default=50,
                     help='the number of pre-fetched requests from the client')
",3
"    gp1.add_argument('--allow-spawn', action='store_true', default=False,
                     help='accept the spawn requests sent from other remote Jina')
    gp1.add_argument('--rest-api', action='store_true', default=False,
                     help='use REST-API as the interface instead of gRPC with port number '
",3
"                          'set to the value of ""port-grpc""')
    return parser
",3
"                     default=10,
                     help='top_k results returned in the search mode')
    gp1.add_argument('--input-type', choices=list(ClientInputType), default=ClientInputType.BUFFER,
                     type=ClientInputType.from_string,
",3
"    gp1.add_argument('--first-request-id', type=int,
                     default=0,
",3
"                     default=0,
                     help='the starting number of doc_id, the consequent doc_id will increment by one')
    _gp.add_argument('--random-doc-id', action='store_true', default=False,
",3
"                    current_indent, '', colored(captial_heading, 'cyan', attrs=['underline', 'bold', 'reverse']))
",3
"    def start_section(self, heading):
        self._indent()
        section = self._Section(self, self._current_section, heading)
        self._add_item(section.format_help, [])
",3
"        help = action.help
",3
"                    help += colored(' (type: %(type)s; default: %(default)s)', attrs=['dark'])
        return help

    def _get_default_metavar_for_optional(self, action):
",3
"        with Pea(args) as p:
            p.join()
    except KeyboardInterrupt:
",3
"        pass


def gateway(args):
",3
"

def log(args):
",3
"def check(args):
    """"""Check jina config, settings, imports, network etc""""""
    from .checker import ImportChecker
    ImportChecker(args)

",3
"    """"""Start a client connects to the gateway""""""
    from ..clients.python import PyClient
    PyClient(args)

",3
"
def export_api(args):
",3
"    if args.yaml_path:
        for yp in args.yaml_path:
",3
"            f_name = (jp % __version__) if '%s' in jp else jp
            import json
            with open(f_name, 'w', encoding='utf8') as fp:
",3
"

def _quick_ac_lookup():
    from .autocomplete import ac_table
    if len(sys.argv) > 1:
",3
"    _quick_ac_lookup()
    from . import api
    args = _get_run_args()
    getattr(api, args.cli.replace('-', '_'))(args)
",3
"        _r = import_classes('jina.drivers', show_import_table=True, import_once=False)

",3
"__license__ = ""Apache-2.0""

import copy
",3
"
",3
"
        @build_required(FlowBuildLevel.RUNTIME)
        def foo():
            print(1)

",3
"        def arg_wrapper(self, *args, **kwargs):
            if hasattr(self, '_build_level'):
                if self._build_level.value >= required_level.value:
                    return func(self, *args, **kwargs)
",3
"        self._update_args(args, **kwargs)
",3
"    @staticmethod
    def _dump_instance_to_yaml(data):
        # note: we only save non-default property for the sake of clarity
        r = {}

",3
"        if data._kwargs:
            r['with'] = data._kwargs

        if data._pod_nodes:
            r['pods'] = {}
",3
"            kwargs.update(v._kwargs)

",3
"        Serialize the object to a yaml file

        :param filename: file path of the yaml file, if not given then :attr:`config_abspath` is used
        :return: successfully dumped or not
",3
"        """"""
        f = filename
        if not f:
",3
"        # yaml.representer.add_representer(OrderedDict, yaml.Representer.represent_dict)

        with open(f, 'w', encoding='utf8') as fp:
            yaml.dump(self, fp)
",3
"        yaml.dump(self, stream)
        return stream.getvalue().strip()

    @classmethod
    def load_config(cls: Type['Flow'], filename: Union[str, TextIO]) -> 'Flow':
",3
"            # deserialize from the yaml
",3
"                endpoint = []
",3
"        # graph is now changed so we need to
",3
"        """"""
",3
"        :param kwargs: other keyword-value arguments that the pod CLI supports
        :return: a (new) flow object with modification
",3
"
",3
"            raise ValueError('name: %s is invalid, please follow the python variable name conventions' % pod_name)

        needs = op_flow._parse_endpoints(op_flow, pod_name, needs, connect_to_last_pod=True)

",3
"
        op_flow.set_last_pod(pod_name, False)
",3
"
        return op_flow

",3
"    def build(self, inplace: bool = True) -> 'Flow':
        """"""
        Build the current flow and make it ready to use
",3
"        _pod_edges = set()

        if 'gateway' not in op_flow._pod_nodes:
            op_flow._add_gateway(needs={op_flow._last_changed_pod[-1]})
",3
"                    else:
",3
"                    if self.args.optimize_level > FlowOptimizeLevel.NONE and e_pod.is_head_router and not s_pod.is_tail_router:
                        e_pod.connect_to_tail_of(s_pod)
                    elif self.args.optimize_level > FlowOptimizeLevel.NONE and s_pod.is_tail_router and s_pod.tail_args.num_part == 1:
                        s_pod.connect_to_head_of(e_pod)
                    else:
",3
"                raise FlowTopologyError('found %d edges start with %s and %d edges end with %s, '
                                        'this type of topology is ambiguous and should not exist, '
                                        'i can not determine the socket type' % (
                                            len(edges_with_same_start), s_name, len(edges_with_same_end), e_name))

",3
"    def __call__(self, *args, **kwargs):
        return self.build(*args, **kwargs)

    def __enter__(self):
        return self.start()
",3
"        which is inherited all the way from :class:`jina.peapods.peas.BasePea`
        """"""

",3
"            self.build(inplace=True)

        if self.args.logserver:
",3
"    def close(self):
        """"""Close the flow and release all resources associated to it. """"""
        if hasattr(self, '_pod_stack'):
",3
"
    def __eq__(self, other: 'Flow'):
        """"""
",3
"        """"""
",3
"        kwargs.update(self._common_kwargs)
        from ..clients import py_client
        if 'port_grpc' not in kwargs:
            kwargs['port_grpc'] = self.port_grpc
",3
"            with f.build(runtime='thread') as flow:
                flow.train(bytes_gen=my_reader())

        :param input_fn: An iterator of bytes. If not given, then you have to specify it in `kwargs`.
",3
"

        This will call the pre-built reader to read files into an iterator of bytes and feed to the flow.
",3
"                flow.index(bytes_gen=my_reader())

        It will start a :py:class:`CLIClient` and call :py:func:`index`.

        :param input_fn: An iterator of bytes. If not given, then you have to specify it in `kwargs`.
",3
"
            with f.build(runtime='thread') as flow:
                flow.search(bytes_gen=my_reader())
",3
"    def dry_run(self, **kwargs):
",3
"            }

",3
"        return self._pod_nodes['gateway'].port_grpc

    @property
",3
"
    def use_rest_gateway(self):
        """"""Change to use REST gateway for IO """"""
        self._common_kwargs['rest_api'] = True

",3
"                chunk_head +
",3
"        png_pack(b'IDAT', zlib.compress(raw_data, 9)),
",3
"    return base64.b64encode(png_bytes)


def input_fn(fp, index=True, num_doc=None):
",3
"        result_html.append('</td></tr>\n')

",3
"    with open(resource_filename('jina', '/'.join(('resources', 'helloworld.html'))), 'r') as fp, \
            open(html_path, 'w') as fw:
        t = fp.read()
",3
"            if not os.path.exists(v['filename']):
",3
"

def hello_world(args):
",3
"    """"""
    Path(args.workdir).mkdir(parents=True, exist_ok=True)

    targets = {
",3
"            'url': args.index_data_url,
            'filename': os.path.join(args.workdir, 'index-original')
",3
"        }
    }

    # download the data
",3
"    os.environ['HW_WORKDIR'] = args.workdir
    os.environ['WITH_LOGSERVER'] = str(args.logserver)

    # reduce the network load by using `fp16`, or even `uint8`
    os.environ['JINA_ARRAY_QUANT'] = 'fp16'
",3
"    with f:
",3
"    countdown(8, reason=colored('behold! im going to switch to query mode', 'cyan',
                                attrs=['underline', 'bold', 'reverse']))
",3
"    # run it!
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

",3
"
class MyDocCrafter(BaseDocCrafter):
    """"""Simple DocCrafter used in :command:`jina hello-world`,
",3
"      type=None),
    _descriptor.EnumValueDescriptor(
",3
"  filename=None,
  file=DESCRIPTOR,
",3
"      name='TERMINATE', index=0, number=0,
      serialized_options=None,
      type=None),
",3
"      serialized_options=None,
      type=None),
  ],
  containing_type=None,
  serialized_options=None,
",3
"  file=DESCRIPTOR,
  values=[
    _descriptor.EnumValueDescriptor(
      name='SUCCESS', index=0, number=0,
",3
"      type=None),
    _descriptor.EnumValueDescriptor(
",3
"      type=None),
",3
"  serialized_start=2704,
  serialized_end=2785,
)
",3
"      name='scale', full_name='jina.NdArray.scale', index=6,
      number=7, type=2, cpp_type=6, label=1,
      has_default_value=False, default_value=float(0),
      message_type=None, enum_type=None, containing_type=None,
",3
"    _descriptor.FieldDescriptor(
      name='original_dtype', full_name='jina.NdArray.original_dtype', index=7,
      number=8, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""".decode('utf-8'),
",3
"      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
",3
"    _NDARRAY_QUANTIZATIONMODE,
",3
"  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
",3
"  serialized_start=54,
  serialized_end=287,
)


",3
"_SCOREDRESULT_SCORE = _descriptor.Descriptor(
",3
"    _descriptor.FieldDescriptor(
",3
"      name='description', full_name='jina.ScoredResult.Score.description', index=2,
      number=3, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""".decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
",3
"      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='operands', full_name='jina.ScoredResult.Score.operands', index=3,
      number=4, type=11, cpp_type=10, label=3,
",3
"      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
",3
"  oneofs=[
  ],
  serialized_start=420,
",3
"      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
",3
"      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"      number=5, type=12, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""",
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"  name='Document',
",3
"      name='length', full_name='jina.Document.length', index=6,
      number=6, type=13, cpp_type=3, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
",3
"      has_default_value=False, default_value=b"""",
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
      name='topk_results', full_name='jina.Document.topk_results', index=8,
      number=8, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
",3
"    _descriptor.OneofDescriptor(
      name='content', full_name='jina.Document.content',
",3
"  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
",3
"      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
  ],
",3
"  extensions=[
  ],
  nested_types=[],
  enum_types=[
",3
"      name='jina', full_name='jina.Envelope.Version.jina', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=b"""".decode('utf-8'),
",3
"  ],
  nested_types=[],
  enum_types=[
",3
"      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
",3
"      name='request_id', full_name='jina.Envelope.request_id', index=2,
      number=3, type=13, cpp_type=3, label=1,
      has_default_value=False, default_value=0,
",3
"      number=7, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
",3
"      name='request', full_name='jina.Message.request', index=1,
      number=2, type=11, cpp_type=10, label=1,
",3
"

",3
"  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
",3
"    _descriptor.FieldDescriptor(
      name='flush', full_name='jina.Request.TrainRequest.flush', index=1,
      number=2, type=8, cpp_type=7, label=1,
      has_default_value=False, default_value=False,
      message_type=None, enum_type=None, containing_type=None,
",3
"  nested_types=[],
  enum_types=[
  ],
  serialized_options=None,
  is_extendable=False,
",3
"      name='docs', full_name='jina.Request.IndexRequest.docs', index=0,
      number=1, type=11, cpp_type=10, label=3,
      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"      serialized_options=None, file=DESCRIPTOR),
",3
"  ],
  serialized_options=None,
  is_extendable=False,
  syntax='proto3',
",3
"  serialized_start=1864,
  serialized_end=1908,
)

",3
"      number=1, type=11, cpp_type=10, label=3,
",3
"      serialized_options=None, file=DESCRIPTOR),
",3
"      serialized_options=None, file=DESCRIPTOR),
  ],
  extensions=[
  ],
",3
"  serialized_options=b'8\001',
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
",3
"  oneofs=[
  ],
  serialized_start=2100,
  serialized_end=2143,
)
",3
"  fields=[
",3
"      has_default_value=False, default_value=[],
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
",3
"  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
",3
"    _descriptor.FieldDescriptor(
",3
"      name='train', full_name='jina.Request.train', index=1,
      number=2, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
",3
"      is_extension=False, extension_scope=None,
",3
"  nested_types=[_REQUEST_TRAINREQUEST, _REQUEST_INDEXREQUEST, _REQUEST_SEARCHREQUEST, _REQUEST_CONTROLREQUEST, ],
  enum_types=[
",3
"  extension_ranges=[],
  oneofs=[
",3
"    _descriptor.OneofDescriptor(
      name='body', full_name='jina.Request.body',
      index=0, containing_type=None, fields=[]),
",3
"_SPAWNREQUEST_PEASPAWNREQUEST = _descriptor.Descriptor(
  name='PeaSpawnRequest',
",3
"  extensions=[
  ],
  nested_types=[],
  enum_types=[
",3
"  name='PodSpawnRequest',
  full_name='jina.SpawnRequest.PodSpawnRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
",3
"  oneofs=[
  ],
  serialized_start=2494,
  serialized_end=2525,
",3
")

_SPAWNREQUEST_MUTABLEPODSPAWNREQUEST = _descriptor.Descriptor(
  name='MutablepodSpawnRequest',
",3
"  fields=[
    _descriptor.FieldDescriptor(
      name='head', full_name='jina.SpawnRequest.MutablepodSpawnRequest.head', index=0,
",3
"      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
",3
"      is_extension=False, extension_scope=None,
",3
"    _descriptor.FieldDescriptor(
",3
"      name='pea', full_name='jina.SpawnRequest.pea', index=0,
      number=1, type=11, cpp_type=10, label=1,
      has_default_value=False, default_value=None,
      message_type=None, enum_type=None, containing_type=None,
",3
"      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      serialized_options=None, file=DESCRIPTOR),
    _descriptor.FieldDescriptor(
",3
"      name='mutable_pod', full_name='jina.SpawnRequest.mutable_pod', index=2,
      number=3, type=11, cpp_type=10, label=1,
",3
"      name='status', full_name='jina.SpawnRequest.status', index=4,
      number=5, type=14, cpp_type=8, label=1,
      has_default_value=False, default_value=0,
",3
"      name='body', full_name='jina.SpawnRequest.body',
",3
"_ENVELOPE_VERSION.containing_type = _ENVELOPE
_ENVELOPE.fields_by_name['routes'].message_type = _ENVELOPE_ROUTE
_ENVELOPE.fields_by_name['version'].message_type = _ENVELOPE_VERSION
_ENVELOPE.fields_by_name['status'].enum_type = _ENVELOPE_STATUS
",3
"_REQUEST_CONTROLREQUEST_ARGSENTRY.containing_type = _REQUEST_CONTROLREQUEST
_REQUEST_CONTROLREQUEST.fields_by_name['command'].enum_type = _REQUEST_CONTROLREQUEST_COMMAND
_REQUEST_CONTROLREQUEST.fields_by_name['args'].message_type = _REQUEST_CONTROLREQUEST_ARGSENTRY
",3
"_sym_db.RegisterMessage(NdArray)

ScoredResult = _reflection.GeneratedProtocolMessageType('ScoredResult', (_message.Message,), {
",3
"
  'Score' : _reflection.GeneratedProtocolMessageType('Score', (_message.Message,), {
    'DESCRIPTOR' : _SCOREDRESULT_SCORE,
    '__module__' : 'jina_pb2'
",3
"    # @@protoc_insertion_point(class_scope:jina.ScoredResult.Score)
    })
  ,
  'DESCRIPTOR' : _SCOREDRESULT,
",3
"_sym_db.RegisterMessage(ScoredResult)
_sym_db.RegisterMessage(ScoredResult.Score)

Chunk = _reflection.GeneratedProtocolMessageType('Chunk', (_message.Message,), {
",3
"
Envelope = _reflection.GeneratedProtocolMessageType('Envelope', (_message.Message,), {

",3
"  'Route' : _reflection.GeneratedProtocolMessageType('Route', (_message.Message,), {
    'DESCRIPTOR' : _ENVELOPE_ROUTE,
",3
"    '__module__' : 'jina_pb2'
    # @@protoc_insertion_point(class_scope:jina.Request.SearchRequest)
    })
",3
"_sym_db.RegisterMessage(Request.SearchRequest)
_sym_db.RegisterMessage(Request.ControlRequest)
_sym_db.RegisterMessage(Request.ControlRequest.ArgsEntry)

",3
"_sym_db.RegisterMessage(SpawnRequest.MutablepodSpawnRequest)


_REQUEST_CONTROLREQUEST_ARGSENTRY._options = None
",3
"  file=DESCRIPTOR,
  index=0,
  serialized_options=None,
  serialized_start=2796,
",3
"    input_type=_REQUEST,
",3
"    full_name='jina.JinaRPC.CallUnary',
",3
"    containing_service=None,
    input_type=_REQUEST,
    output_type=_REQUEST,
",3
"    index=2,
    containing_service=None,
    input_type=_SPAWNREQUEST,
    output_type=_SPAWNREQUEST,
",3
"        '/jina.JinaRPC/Spawn',
",3
"
",3
"
class BaseClientExecutor(BaseExecutor):
    """"""
",3
"        self.timeout = timeout if timeout >= 0 else 200


class BaseTFServingClientExecutor(BaseClientExecutor):
",3
"            def encode(self, data: Any, *args, **kwargs) -> Any:
                _req = self.get_request(data)
                return self.get_response(_req)

",3
"                return np.array(response.result().outputs['output_feature'].float_val)
",3
"
    """"""
    def __init__(self, model_name: str, signature_name: str = 'serving_default', method_name: str = 'Predict',
",3
"
",3
"    def get_response(self, request: 'predict_pb2.PredictRequest'):
        """"""
        Get the response from the tf server and postprocess the response
",3
"    def get_output(self, response: grpc.UnaryUnaryMultiCallable):
        """"""
        Postprocess the response from the tf server
        """"""
",3
"        request.model_spec.signature_name = self.signature_name
        return request

",3
"        for k, v in data_dict.items():
            request.inputs[k].CopyFrom(tf.make_tensor_proto(v))
",3
"        """""" Fill in the ``ClassificationRequest`` with the data dict
        """"""
",3
"        ..notes:
            In the case of using GPUs, we only use the first gpu from the visible gpus. To specify which gpu to use,
            please use the environment variable `CUDA_VISIBLE_DEVICES`.
        """"""
",3
"                    cpus.append(gpus[0])
                return cpus
            elif self.framework == 'paddlepaddle':
",3
"    :class:`BaseTorchExecutor` implements the base class for the executors using :mod:`torch` library. The common setups
         go into this class.
",3
"
    To implement your own executor with the :mod:`torch` library,
",3
"
        class MyAwesomeTorchEncoder(BaseTorchExecutor):
",3
"            def encode(self, data, *args, **kwargs):
                # use your awesome model to encode/craft/score
                import torch
                _input = torch.from_numpy(data)
                if self.on_gpu:
",3
"
",3
"    framework = 'pytorch'

",3
"    .. code-block:: python

        class MyAwesomePaddleEncoder(BasePaddleExecutor):
",3
"                inputs, outputs, self.model = module.context(trainable=False)
                self.inputs_name = input_dict['image'].name
",3
"                    input_shape=(self.img_shape, self.img_shape, 3),
                    include_top=False,
                    pooling=self.pool_strategy,
",3
"
            def encode(self, data, *args, **kwargs):
                # use your awesome model to encode/craft/score
",3
"
    def to_device(self):
        import tensorflow as tf
",3
"                self.model = onnxruntime.InferenceSession(self.model_path, None)
                self.inputs_name = self.model.get_inputs()[0].name
                self.to_device(self.model)
",3
"                for idx in data:
                    data_encoded, *_ = self.model.run(
                        [self.outputs_name, ], {self.inputs_name: data})
",3
"        model.set_providers(self.device)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"
",3
"    @wraps(func)
",3
"    return arg_wrapper

",3
"    """"""Mark an :class:`BaseExecutor` function as training required, so it can only be called
",3
"            if self.is_trained:
                return func(self, *args, **kwargs)
            else:
",3
"
    return arg_wrapper


",3
"            raise TypeError('this decorator should only be used on __init__ method of an executor')
        taboo = {'self', 'args', 'kwargs'}
        _defaults = get_default_metas()
        taboo.update(_defaults.keys())
        all_pars = inspect.signature(func).parameters
",3
"        for k, v in kwargs.items():
            if k in tmp:
                tmp[k] = v

        if self.store_args_kwargs:
",3
"            if kwargs: tmp['kwargs'] = {k: v for k, v in kwargs.items() if k not in taboo}

",3
"        if hasattr(self, '_init_kwargs_dict'):
            self._init_kwargs_dict.update(tmp)
        else:
",3
"    :param batch_size: size of each batch
    :param num_batch: number of batches to take, the rest will be ignored
",3
"
    """"""

    def _batching(func):
",3
"            # priority: decorator > class_attribute
            b_size = (batch_size(data) if callable(batch_size) else batch_size) or getattr(self, 'batch_size', None)
",3
"            # no batching if b_size is None
",3
"            if label is not None:
                data = (data, label)

            for b in batch_iterator(data[:total_size], b_size, split_over_axis):
                if label is None:
",3
"
            if len(final_result) == 1:
                # the only result of one batch
                return final_result[0]
",3
"                    # if chunk_dim != -1:
",3
"
    When you define your own Executor class, make sure your attributes/methods name do not
",3
"    metas defined in YAML > metas defined as class attribute > metas default values listed below


Any executor inherited from :class:`BaseExecutor` always has the following **meta** fields:
",3
"
",3
"        :type: str
        :default: environment variable :confval:`JINA_EXECUTOR_WORKDIR`, if not set then using current working dir, aka ``cwd``.

    .. confval:: name

",3
"        the name of the executor.
",3
"
    .. confval:: on_gpu

",3
"        with:
          ...
",3
"        metas:
          name: my_transformer  # a customized name
          is_trained: true  # indicate the model has been trained
          workspace: ./  # path for serialize/deserialize

",3
"
",3
"def fill_metas_with_defaults(d: Dict) -> Dict:
    """"""Fill the incomplete ``metas`` field with complete default values

    :param d: the loaded YAML map
",3
"import tempfile
",3
"import uuid
from datetime import datetime
",3
"from pathlib import Path
from types import SimpleNamespace
from typing import Dict, Any, Union, TypeVar, Type, TextIO, List

import ruamel.yaml.constructor
",3
"if False:
    from ..drivers import BaseDriver
",3
"        return cls.register_class(_cls)
",3
"    def __call__(cls, *args, **kwargs):
        # do _preload_package
        getattr(cls, 'pre_init', lambda *x: None)()

        m = kwargs.pop('metas') if 'metas' in kwargs else {}
",3
"    The base class of the executor, can be used to build encoder, indexer, etc.

    Any executor inherited from :class:`BaseExecutor` always has the **meta** defined in :mod:`jina.executors.metas.defaults`.

    All arguments in the :func:`__init__` can be specified with a ``with`` map in the YAML config. Example:
",3
"
    .. highlight:: python
    .. code-block:: python

",3
"    .. seealso::
",3
"        self._post_init_vars = set()
        self._last_snapshot_ts = datetime.now()
        self._drivers = {}  # type: Dict[str, List['BaseDriver']]
        self._attached_pea = None

",3
"                if isinstance(req_type, str):
                    req_type = [req_type]
                for r in req_type:
                    if r not in self._drivers:
",3
"                else:
                    setattr(self, k, v)
        if not getattr(self, 'name', None):
            _id = str(uuid.uuid4()).split('-')[0]
            _name = '%s-%s' % (self.__class__.__name__, _id)
",3
"
            # set self values filtered by those non-exist, and non-expandable
",3
"        pass

    @classmethod
    def pre_init(cls):
",3
"        """"""This function is called before the object initiating (i.e. :func:`__call__`)
",3
"    def current_workspace(self) -> str:
        """""" Get the path of the current workspace.

",3
"        Path(self.current_workspace).mkdir(parents=True, exist_ok=True)
        return os.path.join(self.current_workspace, name)

",3
"        """"""
        Train this executor, need to be overrided
        """"""
        pass

",3
"    def touch(self):
        """"""Touch the executor and change ``is_updated`` to ``True`` so that one can call :func:`save`. """"""
        self.is_updated = True

    def save(self, filename: str = None) -> bool:
",3
"        These are some of the common data that you might want to persist:

            - binary dump/pickle of the executor
            - the indexed files
            - (pre)trained models
",3
"        It uses ``pickle`` for dumping. For members/attributes that are not valid or not efficient for ``pickle``, you
        need to implement their own persistence strategy in the :func:`__getstate__`.
",3
"                             'If you really want to save it, call ""touch()"" before ""save()"" to force saving')
            return False
",3
"
",3
"        self.is_updated = False
",3
"        f = filename or self.save_abspath
        if not f:
",3
"            bak_f = f + '.snapshot-%s' % (self._last_snapshot_ts.strftime('%Y%m%d%H%M%S') or 'NA')
            os.rename(f, bak_f)
            self._snapshot_files.append(bak_f)
            if len(self._snapshot_files) > self.max_snapshot:
                d_f = self._snapshot_files.pop(0)
",3
"
        self.is_updated = _updated
        return True
",3
"        :param replica_id: the id of the storage of this replica, only effective when ``separated_workspace=True``
        :return: an executor object
        """"""
        if not filename: raise FileNotFoundError
        filename = valid_yaml_path(filename)
",3
"        # first scan, find if external modules are specified
",3
"            stream = StringIO()
",3
"            yaml.dump(tmp, stream)
",3
"        """"""Build an executor from a binary file

        :param filename: the file path of the binary serialized file
        :return: an executor object

",3
"        if not filename: raise FileNotFoundError
        try:
            with open(filename, 'rb') as fp:
                return pickle.load(fp)
",3
"    def from_yaml(cls, constructor, node):
        """"""Required by :mod:`ruamel.yaml.constructor` """"""
        return cls._get_instance_from_yaml(constructor, node)[0]

    @classmethod
",3
"                if os.path.exists(dump_path):
                    return dump_path
",3
"
    @staticmethod
    def _dump_instance_to_yaml(data):
        # note: we only save non-default property for the sake of clarity
        _defaults = get_default_metas()
",3
"        p = {k: getattr(data, k) for k, v in _defaults.items() if getattr(data, k) != v}
        a = {k: v for k, v in data._init_kwargs_dict.items() if k not in _defaults}
        r = {}
        if a:
",3
"                d.attach(executor=self, *args, **kwargs)

    def __call__(self, req_type, *args, **kwargs):
        if req_type in self._drivers:
            for d in self._drivers[req_type]:
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
",3
"from typing import Dict, List

_defaults = {}

",3
"    :param cls_mro: the MRO inherited order followed.
    """"""
    import copy

",3
"__license__ = ""Apache-2.0""

",3
"    **Example 1: a compound Chunk Indexer that does vector indexing and key-value index**
",3
"              name: vecidx_exec  # a customized name
              workspace: $TEST_WORKDIR
          - !BasePbIndexer
            with:
",3
"              index_filename: chunk.gz
            metas:
              name: chunkidx_exec
",3
"              - !VectorIndexDriver
                with:
                  executor: vecidx_exec
",3
"          py_modules: gif2chunk.py
        requests:
          on:
            IndexRequest:
              - !DocCraftDriver
",3
"                with:
                  executor: name_split
              - !SegmentDriver
",3
"            ControlRequest:
",3
"            return r

    class _FnAllWrapper(_FnWrapper):
        def __call__(self, *args, **kwargs):
            return all(super().__call__(*args, **kwargs))
",3
"
        :param routes: a map of function routes. The key is the function name, the value is a tuple of two pieces,
            where the first element is the name of the referred component (``metas.name``) and the second element
",3
"
                def sayB(self):
                    print('B: im B')
",3
"
        and we create a :class:`CompoundExecutor` consisting of these two via

",3
"        .. highlight:: python
        .. code-block:: python
",3
"
            da, db = dummyA(), dummyB()
            ce = CompoundExecutor()
            ce.components = lambda: [da, db]

",3
"
            ce.add_route('say', db.name, 'say')
            assert b.say() == 'b'

        Such resolution is what we call **routes** here, and it can be specified in advance with the
",3
"    @is_trained.setter
    def is_trained(self, val: bool):
",3
"        return True

",3
"            self._set_routes()
            self._resolve_routes()
        else:
            self.logger.debug('components is omitted from construction, as it is initialized from yaml config')

",3
"    def _set_comp_workspace(self):
",3
"        """"""Create a new function for this executor which refers to the component's function

        This will create a new function :func:`fn_name` which actually refers to ``components[comp_name].comp_fn_name``.
",3
"        :param fn_name: the name of the new function
",3
"        :param comp_name: the name of the referred component, defined in ``metas.name``
        :param comp_fn_name: the name of the referred function of ``comp_name``
        :param is_stored: if ``True`` then this change will be stored in the config and affects future :func:`save` and
            :func:`save_config`
",3
"            self.logger.warning('unresolvable functions: %r' % bad_routes)
",3
"            for c in self.components:
                c.close()

    @classmethod
",3
"    def to_yaml(cls, representer, data):
",3
"            raise TypeError('CompoundExecutor only support string type ""in""')

    def __getitem__(self, item: Union[int, str]):
        if isinstance(item, int):
",3
"            return self.components[item]
        elif isinstance(item, str):
",3
"            for c in self.components:
                if c.name == item:
                    return c
        else:
            raise TypeError('CompoundExecutor only supports int or string index')
",3
"from . import BaseRanker


class TfIdfRanker(BaseRanker):
",3
"    """"""
    :class:`TfIdfRanker` calculates the weighted score from the matched chunks. The weights of each chunk is based on
        the tf-idf algorithm. Each query chunk is considered as a ``term``, and the frequency of the query chunk in a
        specific matched document is considered as the naive ``term-frequency``. All the matched results as a whole is
",3
"        as the naive ``document-frequency``. Please refer to the functions for the details of calculating ``tf`` and
        ``idf``.
    """"""
",3
"        self.threshold = threshold

    def score(self, match_idx: 'np.ndarray', query_chunk_meta: Dict, match_chunk_meta: Dict) -> 'np.ndarray':
        """"""

",3
"        :param query_chunk_meta: a dict of meta info for the query chunks with **ONLY** the ``required_keys`` are kept.
        :param match_chunk_meta: a dict of meta info for the matched chunks with **ONLY** the ``required_keys`` are
            kept.

        :return: an `ndarray` of the size ``M x 2``. ``M`` is the number of matched docs. The columns correspond to the
",3
"            ``doc_id`` and ``score``.

        .. note::
            In both `query_chunk_meta` and `match_chunk_meta`, ONLY the fields from the ``required_keys`` are kept.
",3
"            kept.

        :return: a dict in the size of query chunks
        .. note::
",3
"            To avoid the effects of long texts, the term-frequency of a query chunk is normalized by the total number of
                 chunks in the matched doc, i.e. tf = (n / n_doc). ``n`` denotes the frequency of the query chunk in the
",3
"        a = match_idx[match_idx[:, self.col_query_chunk_id].argsort()]
        q_id, q_df = np.unique(a[:, self.col_query_chunk_id], return_counts=True)
        return q_df, q_id

    def _get_tf(self, match_idx):
",3
"            with the query doc.

",3
"
",3
"        """"""
        _m = match_idx[match_idx[:, self.col_score] >= self.threshold]
",3
"    """"""

",3
"
",3
"        self.k = k
        self.b = b

",3
"                 the matched chunks.
        """"""
        _q_df, _q_id = self._get_df(match_idx)
        _total_df = np.sum(_q_df)
        return {idx: np.log10((_total_df + 1.) / (df + 0.5)) ** 2 for idx, df in zip(_q_id, _q_df)}
",3
"            In BM25, tf = (1 + k) * tf / (k * (1 - b + b * n_doc / avg_n_doc) + tf). ``n`` denotes the
",3
"        _q_tf_list, _q_id_list, _c_id_list = self._get_tf(match_idx)
        _avg_n_doc = np.mean([c_meta['length'] for c_meta in match_chunk_meta.values()])
        return {q_idx: (1 + self.k) * tf / (
                self.k * (1 - self.b + self.b * match_chunk_meta[c_idx]['length'] / _avg_n_doc) + tf)
",3
"
import numpy as np

",3
"                - ``match_idx[:, 3]``: distance/metric/score between the query and matched chunks, float
        :param query_chunk_meta: the meta information of the query chunks, where the key is query chunks' ``chunk_id``,
            the value is extracted by the ``required_keys``.
        :param match_chunk_meta: the meta information of the matched chunks, where the key is matched chunks'
            ``chunk_id``, the value is extracted by the ``required_keys``.
",3
"        :return: a [N x 2] numpy ``ndarray``, where the first column is the matched documents' ``doc_id`` (integer)
",3
"            _doc_id, _doc_score = self._get_score(_g, query_chunk_meta, match_chunk_meta)
            r.append((_doc_id, _doc_score))
        return self.sort_doc_by_score(r)

",3
"    def _group_by(match_idx, col):
        # sort by ``col``
        _sorted_m = match_idx[match_idx[:, col].argsort()]
        _, _doc_counts = np.unique(_sorted_m[:, col], return_counts=True)
        # group by ``col``
",3
"        return np.split(_sorted_m, np.cumsum(_doc_counts))[:-1]

",3
"        """"""
        r = np.array(r, dtype=np.float64)
        r = r[r[:, -1].argsort()[::-1]]
",3
"
",3
"
    .. warning: Here we suppose that the larger chunk score means the more similar.
    """"""

    def _get_score(self, match_idx, query_chunk_meta, match_chunk_meta, *args, **kwargs):
",3
"class MinRanker(BaseRanker):
    """"""
    :class:`MinRanker` calculates the score of the matched doc form the matched chunks. For each matched doc, the score
",3
"    """"""
",3
"import numpy as np

from . import BaseRanker

",3
"    .. warning:: Here we suppose that the smaller chunk score means the more similar.
",3
"        s1 = self._directional_score(match_idx, match_chunk_meta, col=self.col_chunk_id)
        s2 = self._directional_score(match_idx, query_chunk_meta, col=self.col_query_chunk_id)
",3
"
from typing import Any
",3
"
class BaseTFServingClientEncoder(BaseTFServingClientExecutor, BaseEncoder):
    """"""
    :class:`BaseTFServingEncoder` is the base class for the encoders that wrap up a tf serving client. The client call
",3
"        _req = self.get_request(data)
        return self.get_response(_req)


class UnaryTFServingClientEncoder(BaseTFServingClientEncoder):
",3
"        case, in which both the request and the response have a single data field.
",3
"        return np.array(response.result().outputs[self.output_name].float_val)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"

def reduce_mean(data, mask_2d):
    emb_dim = data.shape[2]
    mask = np.tile(mask_2d, (emb_dim, 1, 1))
",3
"    mask = np.rollaxis(mask, 0, 3)
    output = mask * data
    neg_mask = (mask_2d - 1) * (-1e10)
",3
"__license__ = ""Apache-2.0""

import os
",3
"        self.tmp_model_path = self.get_file_from_workspace(f'{self.model_name}.tmp')
        if is_url(self.raw_model_path):
",3
"        self.to_device(self.model)

",3
"class BaseTorchEncoder(BaseTorchExecutor, BaseEncoder):
    pass


",3
"class BasePaddlehubEncoder(BasePaddleExecutor, BaseEncoder):
",3
"class BaseTextPaddlehubEncoder(BasePaddlehubEncoder):
    def encode(self, data: 'np.ndarray', *args, **kwargs) -> 'np.ndarray':
",3
"        pass
",3
"        _feature = _feature.numpy()
",3
"
",3
"class BaseCVPaddlehubEncoder(BasePaddlehubEncoder):
    """"""
",3
"    def __init__(self,
",3
"                 output_feature: str = None,
                 pool_strategy: str = None,
",3
"        self.pool_strategy = pool_strategy
        self.outputs_name = output_feature
        self.inputs_name = None
        self.channel_axis = channel_axis
",3
"
    def post_init(self):
        import paddlehub as hub
        module = hub.Module(name=self.model_name)
        inputs, outputs, self.model = module.context(trainable=False)
",3
"            fetch_list=[self.outputs_name],
            feed={self.inputs_name: data.astype('float32')},
            return_numpy=True
",3
"    def get_pooling(self, data: 'np.ndarray', axis=None) -> 'np.ndarray':
",3
"        """"""
        pass
",3
"class BaseVideoEncoder(BaseNumericEncoder):
    """"""BaseVideoEncoder encodes data from a ndarray, potentially B x (Time x Height x Width) into a ndarray of B x D""""""
    pass
",3
"        """"""
        pass
",3
"

class PipelineEncoder(CompoundExecutor):
    def encode(self, data: Any, *args, **kwargs) -> Any:
        if not self.components:
",3
"        for idx, be in enumerate(self.components):
            if not be.is_trained:
                be.train(data, *args, **kwargs)
",3
"
            if idx + 1 < len(self.components):
                data = be.encode(data, *args, **kwargs)
",3
"    Internally, :class:`FlairTextEncoder` wraps the DocumentPoolEmbeddings from Flair.
",3
"    """"""
",3
"                 **kwargs):
        """"""

",3
"        :param embeddings: the name of the embeddings. Supported models include
        - ``word:[ID]``: the classic word embedding model, the ``[ID]`` are listed at https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/CLASSIC_WORD_EMBEDDINGS.md
        - ``flair:[ID]``: the contextual embedding model, the ``[ID]`` are listed at https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md
        - ``pooledflair:[ID]``: the pooled version of the contextual embedding model, the ``[ID]`` are listed at https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md
        - ``byte-pair:[ID]``: the subword-level embedding model, the ``[ID]`` are listed at https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/BYTE_PAIR_EMBEDDINGS.md
",3
"            strategies include ``mean``, ``min``, ``max``.
        """"""
        super().__init__(*args, **kwargs)
        self.embeddings = embeddings
        self.pooling_strategy = pooling_strategy
",3
"            model_name, model_id = e.split(':', maxsplit=1)
",3
"            emb = None
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import numpy as np
",3
"        self.extraction_strategy = extraction_strategy
        self.extraction_layer = extraction_layer

",3
"                                     num_processes=self.num_processes)

    @batching
",3
"            ``ernie``, ``ernie_tiny``, ``ernie_v2_eng_base``, ``ernie_v2_eng_large``,
",3
"    def encode(self, data: 'np.ndarray', *args, **kwargs) -> 'np.ndarray':
        """"""
",3
"        pass
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"        self.off_value = off_value
        self.embeddings = None

    def post_init(self):
",3
"                 max_length: int = 64,
",3
"        ..warning::
",3
"        self.pooling_strategy = pooling_strategy
",3
"        self.max_length = max_length
        self.raw_model_path = model_path

    @batching
",3
"        :param data: a 1d array of string type in size `B`
",3
"        for c_idx in range(data.shape[0]):
",3
"            mask_ids = [0 if t == self.tokenizer.pad_token_id else 1 for t in token_ids]
            token_ids_batch.append(token_ids)
            mask_ids_batch.append(mask_ids)
",3
"                self.logger.error(""pooling strategy not found: {}"".format(self.pooling_strategy))
                raise NotImplementedError
        return output

",3
"        self.cls_pos = 'tail' if self.model_name == 'xlnet-base-cased' else 'head'
",3
"
",3
"    @property
    def model(self):
        if self._model is None:
            self._model = self.get_model()
",3
"        return self._model

    @property
    def session(self):
",3
"        if self._sess_func is None:
            self._sess_func = self.get_session()
",3
"    @property
    def tensor_func(self):
",3
"        if self._tensor_func is None:
            self._tensor_func = self.get_tensor_func()
",3
"            'openai-gpt': OpenAIGPTTokenizer,
            'gpt2': GPT2Tokenizer,
",3
"            'xlm-roberta-base': XLMRobertaTokenizer,
            'flaubert-base-cased': FlaubertTokenizer,
            'camembert-base': CamembertTokenizer,
",3
"        return _tokenizer
",3
"
    def get_cls_pos(self):
        return 'tail' if self.model_name == 'xlnet-base-cased' else 'head'

    def get_tmp_model_path(self):
",3
"            'bert-base-uncased': TFBertModel,
",3
"
    def get_model(self):
        from transformers import BertModel, OpenAIGPTModel, GPT2Model, XLNetModel, XLMModel, DistilBertModel, \
            RobertaModel, XLMRobertaModel, FlaubertModel, CamembertModel, CTRLModel
",3
"        model_dict = {
            'bert-base-uncased': BertModel,
            'openai-gpt': OpenAIGPTModel,
            'gpt2': GPT2Model,
            'xlnet-base-cased': XLNetModel,
",3
"        return tensor.cpu().numpy() if self.on_gpu else tensor.numpy()
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import numpy as np
",3
"    .. note::
",3
"        :class:`IncrementalPCAEncoder` must be trained before calling ``encode()``. This encoder can be trained in an
        incremental way.
    """"""

    def __init__(self,
",3
"        self.output_dim = output_dim
        self.whiten = whiten
        self.num_features = num_features
        self.is_trained = False
        self.model = None
",3
"    Internally, :class:`KerasImageEncoder` wraps the models from `tensorflow.keras.applications`.
",3
"    https://keras.io/applications/
    """"""

    def __init__(self, img_shape: int = 96,
",3
"            ``DenseNet121``, ``DenseNet169``, ``DenseNet201``,
            ``InceptionResNetV2``,
            ``InceptionV3``,
            ``MobileNet``, ``MobileNetV2``,
",3
"            ``NASNetLarge``, ``NASNetMobile``,
            ``ResNet101``, ``ResNet152``, ``ResNet50``, ``ResNet101V2``, ``ResNet152V2``, ``ResNet50V2``,
            ``VGG16``, ``VGG19``,
",3
"        :return: a `B x D` numpy ``ndarray``, `D` is the output dimension
",3
"__license__ = ""Apache-2.0""

import numpy as np

",3
"from ...decorators import batching, as_ndarray


class OnnxImageEncoder(BaseOnnxEncoder):
",3
"        :param data: a `B x (Channel x Height x Width)` numpy ``ndarray``, `B` is the size of the batch
        :return: a `B x D` numpy ``ndarray``, `D` is the output dimension
        """"""
",3
"                If given other, then ``np.moveaxis(data, channel_axis, -1)`` is performed before :meth:`encode`.
        """"""
",3
"
    def __init__(self, *args, **kwargs):
        """"""

        :param model_name: the name of the model. Supported models include
",3
"            ``resnext50_64x4d_imagenet``, ``resnext50_32x4d_imagenet``,
            ``resnext152_vd_64x4d_imagenet``, ``resnext152_64x4d_imagenet``, ``resnext152_32x4d_imagenet``,
            ``resnext101_vd_64x4d_imagenet``, ``resnext101_vd_32x4d_imagenet``,
            ``resnext101_64x4d_imagenet``, ``resnext101_32x4d_imagenet``,
            ``resnext101_32x8d_wsl``, ``resnext101_32x48d_wsl``, ``resnext101_32x32d_wsl``, ``resnext101_32x16d_wsl``,
",3
"class CustomImageTorchEncoder(ImageTorchEncoder):
    """"""
",3
"

class ImageTorchEncoder(BaseCVTorchEncoder):
    """"""
    :class:`ImageTorchEncoder` encodes data from a ndarray, potentially B x (Channel x Height x Width) into a
",3
"            ``vgg16``,
            ``densenet161``,
",3
"            ``resnext50_32x4d``,
            ``wide_resnet50_2``,
",3
"            - `max` means that global max pooling will be applied.
        """"""
        super().__init__(*args, **kwargs)
",3
"        import torchvision.models as models
        if self.pool_strategy is not None:
",3
"        self.to_device(self.model)
",3
"        if feature_map.ndim == 2 or self.pool_strategy is None:
",3
"            supported models:
            ``tsn_kinetics400``: `@HUB_tsn_kinetics400@reduce_mean_0.tmp_0`
            ``stnet_kinetics400``: ``@HUB_stnet_kinetics400@reshape2_6.tmp_0``
            ``tsm_kinetics400``: ``@HUB_tsm_kinetics400@reduce_mean_0.tmp_0``
",3
"__license__ = ""Apache-2.0""

from .. import BaseVideoEncoder
from ..frameworks import BaseCVTorchEncoder

",3
"class FilePath2Buffer(BaseDocCrafter):
    """""" Convert local file path, remote URL doc to a buffer doc.
    """"""
",3
"
class FilePath2DataURI(FilePath2Buffer):
",3
"        :param charset: charset may be any character set registered with IANA
        :param base64: used to encode arbitrary octet sequences into a form that satisfies the rules of 7bit. Designed to be efficient for non-text 8 bit and binary data. Sometimes used for text data that frequently uses non-US-ASCII characters.
        :param args:
        :param kwargs:
        """"""
",3
"    def craft(self, file_path: str, mime_type: str, *args, **kwargs):
        d = super().craft(file_path)
        return dict(data_uri=self.make_datauri(mime_type, d['buffer']))
",3
"
",3
"        :mod:`jina.drivers.handlers.craft`
    """"""

",3
"    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
",3
"        self.required_keys = {k for k in inspect.getfullargspec(self.craft).args if k != 'self'}
        if not self.required_keys:
            self.logger.warning(f'{self.__class__} works on keys, but no keys are specified')
",3
"        in the protobuf.
",3
"        raise NotImplementedError


class BaseChunkCrafter(BaseCrafter):
    """""":class:`BaseChunkCrafter` works on chunk-level and returns new value on chunk-level.
",3
"
    The example below shows a dummy transformer add ``doc_id`` to the ``chunk_id`` and use it as the new ``chunk_id``.

",3
"    .. highlight:: python
    .. code-block:: python

        class DummyTransformer(BaseDocCrafter):
",3
"
    .. highlight:: python
    .. code-block:: python

        class DummyTransformer(BaseDocCrafter):
",3
"__license__ = ""Apache-2.0""

import re
",3
"from .. import BaseSegmenter
",3
"    """"""

    def __init__(self,
                 min_sent_len: int = 1,
",3
"        :param max_sent_len: the maximal number of characters (including white spaces) of the sentence, by default 1e5.
        :param punct_chars: the punctuation characters to split on.
        """"""
        super().__init__(*args, **kwargs)
",3
"        self.min_sent_len = min_sent_len
        self.max_sent_len = max_sent_len
        self.punct_chars = punct_chars
        if not punct_chars:
            self.punct_chars = ['!', '.', '?', 'Ö', 'Ø', 'Û', 'Ü', 'Ü', 'Ü', 'â¼', 'â½', 'â', 'â', 'â', 'â¸®', 'ï¹', 'ï¹',
",3
"        :return: a list of chunk dicts with the cropped images
        """"""

        text = buffer.decode('utf8')
",3
"        all_sentences = self._slit_pat.findall(text)
        results = []
        for idx, s in enumerate(all_sentences):
            if self.min_sent_len <= len(s) <= self.max_sent_len:
",3
"                results.append(dict(
                    doc_id=doc_id,
                    text=s,
                    offset=idx,
",3
"    """"""
    :class:`JiebaSegmenter` split the chinese text on the doc-level into words on the chunk-level with `jieba`.
",3
"        super().__init__(*args, **kwargs)
        if mode not in ('accurate', 'all', 'search'):
",3
"        Split the chinese text into words
        :param buffer: the raw text in the `bytes` format
        :param doc_id: the doc id
        :return: a list of chunk dicts
",3
"
from typing import Dict, List

import numpy as np
from jina.executors.crafters import BaseDocCrafter
",3
"        """"""
        Split string into numbers and convert to numpy array
",3
"
        :param buffer: the raw string in the `bytes` format
        :param doc_id: the doc id
",3
"        :return: a chunk dict with the numpy array
        """"""
        _string = buffer.decode('utf8')
        _string = _string.split(self.delimiter)
",3
"                f'Please refer to the list of data types from Numpy.')
        except ValueError as e:
            self.logger.error(
",3
"    """"""
",3
"            raw_img = Image.open(buffer.decode())
        if raw_img.mode != 'RGB':
            raw_img = raw_img.convert('RGB')
        img = np.array(raw_img).astype('float32')
",3
"        if self.channel_axis != -1:
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

from typing import Tuple, Dict, List, Union
",3
"from . import ImageChunkCrafter


class ImageCropper(ImageChunkCrafter):
    """"""
",3
"    def __init__(self,
                 top: int,
                 left: int,
                 height: int,
",3
"        :param width: the width of the crop box.
        """"""
        super().__init__(*args, **kwargs)
        self.top = top
        self.left = left
",3
"        self.width = width

    def craft(self, blob: 'np.ndarray', chunk_id, doc_id, *args, **kwargs) -> Dict:
",3
"        """"""
        Crop the input image array.

",3
"        return dict(doc_id=doc_id, offset=0, weight=1., blob=img.astype('float32'))


",3
"        """"""
",3
"        Crop the input image array.
",3
"        img = self.restore_channel_axis(np.asarray(_img))
",3
"
    def __init__(self,
",3
"
        :param target_size: desired output size. If size is a sequence like (h, w), the output size will be matched to
            this. If size is an int, the output will have the same height and width as the `target_size`.
",3
"        :param chunk_id: the chunk id
        :param doc_id: the doc id
        :return: a list of chunk dicts with the cropped images
",3
"            img = self.restore_channel_axis(np.asarray(_img))
            result.append(
",3
"                 target_size: int,
                 *args,
                 **kwargs):
        """"""

",3
"        :param target_size: desired output size. If size is a sequence like (h, w), the output size will be matched to
            this. If size is an int, the output will have the same height and width as the `target_size`.
",3
"        """"""
        super().__init__(*args, **kwargs)
        self.target_size = target_size
",3
"            raise ValueError('target_size should be an integer or a tuple of two integers: {}'.format(self.target_size))
        _tl = self._crop_image(raw_img, self.target_size, 0, 0)
        tl = self.restore_channel_axis(np.asarray(_tl))
        _tr = self._crop_image(raw_img, self.target_size, image_width - target_w, 0)
        tr = self.restore_channel_axis(np.asarray(_tr))
",3
"        _center = self._crop_image(raw_img, self.target_size, how='center')
        center = self.restore_channel_axis(np.asarray(_center))
",3
"            dict(doc_id=doc_id, offset=0, weight=1., blob=bl.astype('float32')),
            dict(doc_id=doc_id, offset=0, weight=1., blob=br.astype('float32')),
            dict(doc_id=doc_id, offset=0, weight=1., blob=center.astype('float32')),
        ]

",3
"
class SlidingWindowImageCropper(ImageChunkCrafter):
    """"""
    :class:`SlidingWindowImageCropper` crops the image with a sliding window.
",3
"        :param doc_id: the doc id
        :return: a list of chunk dicts with the cropped images.
",3
"            (
",3
"                c
            ), (
                row_step * self.stride_h,
                col_step * self.stride_w,
                row_step,
",3
"                col_step,
                1))
        expanded_img = expanded_img.reshape((-1, self.target_size, self.target_size, c))
        results = []
        for _blob in expanded_img:
",3
"        :class:`ImageNormalizer` normalize the image.
",3
"        :param doc_id: the doc id
        :return: a chunk dict with the normalized image
        """"""
        raw_img = self.load_image(blob)
        _img = self._normalize(raw_img)
",3
"        img = self.restore_channel_axis(_img)
        return dict(doc_id=doc_id, offset=0, weight=1., blob=img)

",3
"import numbers
",3
"                 *args, **kwargs):
        """"""

        :param target_size: desired output size. If size is a sequence like (h, w), the output size will be matched to
",3
"    .. warning::
        :class:'ImageChunkCrafter' is intended to be used internally.
",3
"        return Image.fromarray(img.astype('uint8'))

    @staticmethod
    def _resize_short(img, target_size: Union[Tuple[int], int], how: str = 'LANCZOS'):
",3
"
    @staticmethod
",3
"        :param target_size: desired output size. If size is a sequence like
            (h, w), the output size will be matched to this. If size is an int,
            the output will have the same height and width as the `target_size`.
        :param top: the vertical coordinate of the top left corner of the crop box.
",3
"            - `center`: crop the center part of the image
            - `random`: crop a random part of the image
",3
"            raise ValueError('target_size should be an integer or a tuple of two integers: {}'.format(target_size))
        w_beg = left
",3
"        if how == 'center':
",3
"            assert (0 <= w_beg <= (img_w - target_w)), 'left must be within [0, {}]: {}'.format(img_w - target_w, w_beg)
            assert (0 <= h_beg <= (img_h - target_h)), 'top must be within [0, {}]: {}'.format(img_h - target_h, h_beg)
",3
"        return img
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"        Calling :func:`save` to save a :class:`BaseIndexer` will create
        more than one files. One is the serialized version of the :class:`BaseIndexer` object, often ends with ``.bin``

    .. warning::
",3
"            with BaseIndexer() as b:
                b.add()

        So that it can safely save the data. Or you have to manually call `b.close()` to close the indexer safely.
",3
"        """"""
        return self.get_file_from_workspace(self.index_filename)

    @property
    def query_handler(self):
",3
"        if self._query_handler is None:
            self.logger.warning(f'you can not query from {self} as its ""query_handler"" is not set. '
                                'If you are indexing data from scratch then it is fine. '
                                'If you are querying data then the index file must be empty or broken.')
        return self._query_handler
",3
"        if self._write_handler is None:
            self.logger.warning('""write_handler"" is None, you may not add data to this index, '
",3
"    def get_add_handler(self):
        """"""Get a *writable* index handler when the ``index_abspath`` already exist, need to be overrided""""""
        raise NotImplementedError
",3
"        call_obj_fn(self._write_handler, 'close')
        call_obj_fn(self._query_handler, 'close')
",3
"    .. highlight:: yaml
    .. code-block:: yaml
",3
"                pruned:
                  - embedding
                  - buffer
",3
"                executor: BaseKVIndexer
                level: chunk
          IndexRequest:
            - !VectorIndexDriver
",3
"              with:
                executor: BaseVectorIndexer
            - !PruneDriver
",3
"                  - blob
                  - text
            - !KVIndexDriver
              with:
",3
"
import numpy as np
",3
"
",3
"    """"""Faiss powered vector indexer
",3
"
    For more information about the Faiss supported parameters and installation problems, please consult:
        - https://github.com/spotify/annoy
",3
"        return self.int2ext_key[ids], dist
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import gzip
",3
"                        `matching`, `minkowski`, `rogerstanimoto`, `russellrao`, `seuclidean`, `sokalmichener`, 
                        `sokalsneath`, `sqeuclidean`, `wminkowski`, `yule`.
        :param backend: `numpy` or `scipy`, `numpy` only supports `euclidean` and `cosine` distance
",3
"        :param compress_level: The compresslevel argument is an integer from 0 to 9 controlling the
                        level of compression; 1 is fastest and produces the least compression,
                        and 9 is slowest and produces the most compression. 0 is no compression
",3
"
        """"""
        super().__init__(*args, **kwargs)
",3
"        """"""Open a binary gzip file for adding new vectors

",3
"            return None

    def get_create_handler(self):
        """"""Create a new gzip file for adding new vectors
",3
"    def add(self, keys: 'np.ndarray', vectors: 'np.ndarray', *args, **kwargs):
        if len(vectors.shape) != 2:
",3
"            self.dtype = vectors.dtype.name
",3
"        self._size += keys.shape[0]

    def query(self, keys: np.ndarray, top_k: int, *args, **kwargs) -> Tuple['np.ndarray', 'np.ndarray']:
        """""" Find the top-k vectors with smallest ``metric`` and return their ids.

",3
"
        .. warning::
            This operation is memory-consuming.

            Distance (the smaller the better) is returned, not the score.
",3
"
        """"""
",3
"        if self.metric not in {'cosine', 'euclidean'} or self.backend == 'scipy':
            try:
",3
"    nB = B.shape[0]
    B_ext = np.ones((dim * 3, nB))
    B_ext[:dim] = (B ** 2).T
    B_ext[dim:2 * dim] = -2.0 * B.T
    return A_ext, B_ext
",3
"                             B / np.linalg.norm(B, ord=2, axis=1, keepdims=True))
    return A_ext.dot(B_ext).clip(min=0) / 2
",3
"                 *args, **kwargs):
        """"""
        Initialize an NmslibIndexer

",3
"        :param num_threads: The number of threads to use
        :param args:
        :param kwargs:
        """"""
        super().__init__(*args, **kwargs)
",3
"        self.space = dist_calc_method
        self.num_threads = num_threads

    def get_query_handler(self):
",3
"        vecs = super().get_query_handler()
        if vecs is not None:
",3
"__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

from typing import Tuple
",3
"            vecs = vecs.astype(np.float32)
            for idx, v in enumerate(vecs):
",3
"
from typing import Tuple
",3
"
",3
"        - https://github.com/nmslib/nmslib/blob/master/manual/methods.md
",3
"
    .. note::
",3
"        """"""
        Initialize an NmslibIndexer

",3
"        :param space: The metric space to create for this index
        :param method: The index method to use
        :param num_threads: The number of threads to use
        :param print_progress: Whether or not to display progress bar when creating index
",3
"        :param args:
        :param kwargs:
        """"""
        super().__init__(*args, **kwargs)
",3
"            _index.createIndex({'post': 2}, print_progress=self.print_progress)
",3
"import json
from typing import Union

from google.protobuf.json_format import Parse
",3
"        json.dump(obj, self.write_handler)
        self.write_handler.write('\n')
",3
"    def get_add_handler(self):
",3
"        return self.db_handler

",3
"        """"""Get the database handler
",3
"        """"""
        v = self.query_handler.get(key.encode('utf8'))
        value = None
        if v is not None:
            _parser = jina_pb2.Chunk if key[0] == 'c' else jina_pb2.Document
",3
"        for d in self.req.docs:
            _topk = [k for k in d.topk_results[:self.req.top_k]]
            d.ClearField('topk_results')
",3
"class TopKSortDriver(BaseDriver):
    """"""Sort the ``topk_results``

",3
"            d.topk_results.extend(_sort)
            for c in d.chunks:
",3
"                for c in d.chunks:
                    for k in self.pruned:
                        c.ClearField(k)
",3
"                for k in self.pruned:
                    d.ClearField(k)
",3
"
",3
"class ChunkPruneDriver(PruneDriver):
    """"""Clean some fields from the chunk-level protobuf to reduce the total size of the request

    Removed fields are ``embedding``, ``buffer``, ``blob``, ``text``.
",3
"
    def __init__(self, pruned=('chunks', 'buffer'), level='doc', *args, **kwargs):
        super().__init__(pruned, level, *args, **kwargs)
",3
"    return x.reshape(blob.shape)

",3
"        blob.quantization = jina_pb2.NdArray.UINT8
",3
"        blob.max_val, blob.min_val = x.max(), x.min()
",3
"    return blob
",3
"    :param docs: an iterable of protobuf documents
    :param embedding: an indicator of extracting embedding or not.
                    If ``True`` then all chunk-level embedding are extracted.
",3
"
    if embedding:
        _extract_fn = lambda c: c.embedding.buffer and pb2array(c.embedding)
",3
"
    for d in docs:
        if not d.chunks:
            no_chunk_docs.append(d.doc_id)
",3
"    return colored('â¸', 'green').join(route_str)


def add_route(evlp: 'jina_pb2.Envelope', name: str, identity: str) -> None:
",3
"    r.pod_id = identity


",3
"
    .. warning::
        This driver loops over all chunk/chunk's top-K results, each step fires a query.
        This may not be very efficient, as the total number of queries depends on ``level``

",3
"             - ``level=chunk``: D x C x K
             - ``level=doc``: D x K
             - ``level=all``: D x C x K

        where:
",3
"        super().__init__(*args, **kwargs)
        self.level = level

    def __call__(self, *args, **kwargs):
",3
"        if self.level == 'doc':
            for d in self.req.docs:
                self._update_topk_docs(d)
",3
"                for c in d.chunks:
                    self._update_topk_chunks(c)
        elif self.level == 'all':
            for d in self.req.docs:
                self._update_topk_docs(d)
",3
"                for c in d.chunks:
                    self._update_topk_chunks(c)
        else:
            raise TypeError(f'level={self.level} is not supported, must choose from ""chunk"" or ""doc"" ')
",3
"            r = self.exec_fn(f'c{tk.match_chunk.chunk_id}')
            if r:
                sr = ScoredResult()
                sr.score.CopyFrom(tk.score)
",3
"        c.topk_results.extend(hit_sr)


class DocKVSearchDriver(KVSearchDriver):
    """"""A shortcut to :class:`KVSearchDriver` with ``level=doc``""""""
",3
"
    def __init__(self, level: str = 'doc', *args, **kwargs):
        super().__init__(level, *args, **kwargs)


",3
"    def __init__(self, level: str = 'chunk', *args, **kwargs):
        super().__init__(level, *args, **kwargs)


",3
"                r.score.value = s
                r.score.op_name = op_name
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
",3
"from . import BaseExecutableDriver
from .helper import pb_obj2dict
",3
"    """"""

",3
"                    match_chunk_meta[k.match_chunk.chunk_id] = pb_obj2dict(k.match_chunk, exec.required_keys)

            # np.uint32 uses 32 bits. np.float32 uses 23 bit mantissa, so integer greater than 2^23 will have their
            # least significant bits truncated.
",3
"            match_idx = np.array(match_idx, dtype=np.float64)

            doc_idx = self.exec_fn(match_idx, query_chunk_meta, match_chunk_meta)
",3
"
class BaseCraftDriver(BaseExecutableDriver):
    """"""Drivers inherited from this Driver will bind :meth:`craft` by default """"""
",3
"
    def __init__(self, executor: str = None, method: str = 'craft', *args, **kwargs):
        super().__init__(executor, method, *args, **kwargs)
",3
"                continue
            _chunks_to_add = []
",3
"                        else:
                            setattr(c, k, v)
",3
"                    continue
                elif isinstance(ret, list):
                    _chunks_to_add.extend(ret)
",3
"    def __call__(self, *args, **kwargs):
        for d in self.req.docs:
            ret = self.exec_fn(**pb_obj2dict(d, self.exec.required_keys))
",3
"            for k, v in ret.items():
                setattr(d, k, v)


class DocMIMEDriver(DocCraftDriver):
",3
"    """"""

    def __init__(self, default_mime: str = 'application/octet-stream', *args, **kwargs):
        """"""
",3
"                    except (ImportError, ModuleNotFoundError):
",3
"
            if m_type:
                d.mime_type = m_type
            else:
",3
"
",3
"                                                f'anyway')
                        else:
",3
"                            setattr(c, k, v)
                    c.length = len(ret)
                    c.chunk_id = self.first_chunk_id if not self.random_chunk_id else random.randint(0, ctypes.c_uint(
                        -1).value)
                    c.doc_id = d.doc_id
",3
"                    c.mime_type = d.mime_type
",3
"        super().__init__(executor, method, *args, **kwargs)


class EncodeDriver(BaseEncodeDriver):
    """"""Extract the chunk-level content from documents and call executor and do encoding
",3
"                        'mismatched %d chunks and a %s shape embedding, '
                        'the first dimension must be the same' % (len(chunk_pts), embeds.shape))
                for c, emb in zip(chunk_pts, embeds):
",3
"    """"""

",3
"
",3
"class KVIndexDriver(BaseIndexDriver):
    """"""Serialize the documents/chunks in the request to key-value JSON pairs and write it using the executor
",3
"        :param kwargs:
        """"""
",3
"        elif self.level == 'chunk':
",3
"        else:
            raise TypeError(f'level={self.level} is not supported, must choose from ""chunk"" or ""doc"" ')
        if content:
            self.exec_fn(content)

",3
"from functools import wraps
from typing import Callable, List

import ruamel.yaml.constructor

",3
"    import logging
",3
"        tmp_list = [k for k in all_pars.keys() if k not in taboo]
        # set args by aligning tmp_list with arg values
        for k, v in zip(tmp_list, args):
",3
"
        if self.store_args_kwargs:
            if args: tmp['args'] = args
",3
"    @staticmethod
    def register_class(cls):
        reg_cls_set = getattr(cls, '_registered_class', set())
",3
"    def __init__(self, *args, **kwargs):
",3
"    @property
    def msg(self) -> 'jina_pb2.Message':
        """"""Get the current request, shortcut to ``self.pea.message``""""""
        return self.pea.message

",3
"
    @property
    def prev_msgs(self) -> List['jina_pb2.Message']:
        """"""Get all previous messages that has the same ``request_id``, shortcut to ``self.pea.prev_messages``

",3
"    def logger(self) -> 'logging.Logger':
        """"""Shortcut to ``self.pea.logger``""""""
        return self.pea.logger

    def __call__(self, *args, **kwargs) -> None:
",3
"        # note: we only save non-default property for the sake of clarity
        a = {k: v for k, v in data._init_kwargs_dict.items()}
        r = {}
        if a:
",3
"            r['with'] = a
        return r

    @classmethod
    def to_yaml(cls, representer, data):
",3
"    def __init__(self, executor: str = None, method: str = None, *args, **kwargs):
        """""" Initialize a :class:`BaseExecutableDriver`
",3
"        """"""
        super().__init__(*args, **kwargs)
        self._executor_name = executor
        self._method_name = method
",3
"
    def attach(self, executor: 'AnyExecutor', *args, **kwargs):
        """"""Attach the driver to a :class:`jina.executors.BaseExecutor`""""""
        super().attach(*args, **kwargs)
        if self._executor_name and isinstance(executor, CompoundExecutor):
",3
"            if self._executor_name in executor:
                self._exec = executor[self._executor_name]
",3
"            else:
",3
"                        break
            if self._exec is None:
                self.logger.critical(f'fail to attach the driver to {executor}, '
                                     f'no executor is named or typed as {self._executor_name}')
",3
"import time
",3
"            self.envelope.status = jina_pb2.Envelope.SUCCESS
            raise RequestLoopEnd
        elif self.req.command == jina_pb2.Request.ControlRequest.STATUS:
            self.envelope.status = jina_pb2.Envelope.READY
",3
"
",3
"    - The dealer never receives a control request from the router,
      everytime it finishes a job and send via out_sock, it returns the envelope with control
      request idle back to the router. The dealer also sends control request idle to the router
      when it first starts.
",3
"                self.pea.zmqlet.resume_pollin()
                self.is_pollin_paused = False
            raise NoExplicitMessage
        else:
",3
"        self.msg.envelope.routes.extend(
            sorted(routes.values(), key=lambda x: (x.start_time.seconds, x.start_time.nanos)))

",3
"        else:
            raise TypeError(f'level={self.level} is not supported, must choose from ""chunk"" or ""doc"" ')

        super().__call__(*args, **kwargs)
",3
"
from .zmq import send_ctrl_message, Zmqlet
from .. import __ready_msg__, __stop_msg__
from ..drivers.helper import routes2str, add_route
from ..enums import PeaRoleType
",3
"from ..executors import BaseExecutor
from ..logging import get_logger
from ..logging.profile import used_memory, TimeDict
from ..proto import jina_pb2, is_data_request

",3
"
    def __call__(cls, *args, **kwargs):
",3
"    else:
        raise NotImplementedError


def _make_or_event(obj, *events):
",3
"        e._set = e.set
        e._clear = e.clear
        e.changed = changed_callback
        e.set = lambda: or_set(e)
",3
"
class BasePea(metaclass=PeaMeta):
",3
"        """""" Create a new :class:`BasePea` object

        :param args: the arguments received from the CLI
        :param replica_id: the id used to separate the storage of each pea, only used when ``args.separate_storage=True``
        """"""
",3
"        self._timer = TimeDict()

        self._request = None
        self._message = None
        self._prev_requests = None
",3
"            if args.role == PeaRoleType.HEAD:
                self.name = '%s-head' % self.name
",3
"        """"""Register the current message to this pea, so that all message-related properties are up-to-date, including
        :attr:`request`, :attr:`prev_requests`, :attr:`message`, :attr:`prev_messages`. And then call the executor to handle
        this message.

",3
"        req_type = type(self._request)

        if self.args.num_part > 1 and is_data_request(self._request):
",3
"    def request(self) -> 'jina_pb2.Request':
        """"""Get the current request body inside the protobuf message""""""
        return self._request
",3
"        return self._request.__class__.__name__
",3
"        This returns ``None`` when ``num_part=1``.
        """"""
",3
"        if self.args.yaml_path:
            try:
                self.executor = BaseExecutor.load_config(self.args.yaml_path,
",3
"                self.logger.debug('executor is not saved as ""read_only"" is set to true for this BasePea')
            elif not hasattr(self, 'executor'):
",3
"    def pre_hook(self, msg: 'jina_pb2.Message') -> 'BasePea':
        """"""Pre-hook function, what to do after first receiving the message """"""
        msg_type = msg.request.WhichOneof('body')
",3
"        try:
",3
"
    def loop_body(self):
        """"""The body of the request loop

",3
"        self.zmqlet = Zmqlet(self.args, logger=self.logger)
        self.set_ready()

        while True:
",3
"
            if msg:
                self.zmqlet.send_message(msg)
",3
"            # self.logger.info(f'handle {(t_callback - t_loop_start) / (t_loop_end - t_loop_start):2.2f}')

    def load_plugins(self):
        if self.args.py_modules:
",3
"            from ..helper import PathImporter
            PathImporter.add_modules(*self.args.py_modules)

",3
"        if hasattr(self, 'executor'):
            if not self.args.exit_no_dump:
                self.save_executor(dump_interval=0)
            self.executor.close()
        if hasattr(self, 'zmqlet'):
",3
"            self.logger.error('zmqlet can not be initiated')
        except Exception as ex:
            self.logger.error('unknown exception: %s' % str(ex), exc_info=True)
        finally:
",3
"            self.loop_teardown()
            self.unset_ready()
            self.is_shutdown.set()

    def check_memory_watermark(self):
",3
"        """"""Gracefully close this pea and release all resources """"""
        if self.is_ready.is_set() and hasattr(self, 'ctrl_addr'):
            return send_ctrl_message(self.ctrl_addr, jina_pb2.Request.ControlRequest.TERMINATE,
",3
"                                     timeout=self.args.timeout_ctrl)

    @property
",3
"            raise TimeoutError(
                f'{self.__class__} with name {self.name} can not be initialized after {_timeout * 1e3}ms')

    def __enter__(self):
        return self.start()
",3
"
    def load_executor(self):
",3
"        self.channel = grpc.insecure_channel(
            '%s:%s' % (self.args.host, self.args.port_grpc),
            options=[('grpc.max_send_message_length', self.args.max_message_size),
",3
"                     ('grpc.max_receive_message_length', self.args.max_message_size)])

        m = PathImporter.add_modules(self.args.pb2_path, self.args.pb2_grpc_path)

        # build stub
",3
"        if self.args.socket_in.is_bind:
            _expose_port.append(self.args.port_in)
        if self.args.socket_out.is_bind:
",3
"            net_mode = 'host'
",3
"        self._container = self._client.containers.run(self.args.image, _args,
                                                      detach=True, auto_remove=True,
",3
"        # wait until the container is ready
",3
"        if getattr(self, '_container', None):
            import docker
            try:
                self._container.stop()
",3
"                import lz4
                self.logger.success(f'compression is enabled and the high watermark is {args.compress_hwm} bytes')
            except ModuleNotFoundError:
",3
"                self.logger.error(f'compression is enabled but you do not have lz4 package. '
",3
"                                  f'use pip install ""jina[lz4]"" to install this dependency')
                args.compress_hwm = -1  # disable the compression
",3
"    def resume_pollin(self):
        """"""Put :attr:`in_sock` back to the poller """"""
",3
"        """"""Get the address of the control socket

        :param args: the parsed arguments from the CLI
        :return: A tuple of two pieces:
",3
"        else:
            return 'tcp://%s:%d' % (args.host, args.port_ctrl), ctrl_with_ipc
",3
"        """"""
        ctx = self._get_zmq_ctx()
",3
"                (colored(in_addr, 'yellow'), self.args.socket_in,
                 colored(out_addr, 'yellow'), self.args.socket_out,
                 colored(ctrl_addr, 'yellow'), SocketType.PAIR_BIND))
",3
"            self.ctx.term()
        self.print_stats()

    def print_stats(self):
",3
"        _req_type = type(_req)

        if is_data_request(_req):
            o_sock = self.out_sock
        else:
",3
"            o_sock = self.ctrl_sock

        self.bytes_sent += send_message(o_sock, msg, **self.send_recv_kwargs)
",3
"        """"""Tell the upstream router this dealer is idle """"""
        if msg:
",3
"            msg.request.control.command = jina_pb2.Request.ControlRequest.IDLE
        else:
            req = jina_pb2.Request()
            req.control.command = jina_pb2.Request.ControlRequest.IDLE
",3
"            self.bytes_recv += num_bytes
            self.msg_recv += 1
            if callback:
                return callback(msg)

",3
"    def clear_stats(self):
        """"""Reset the internal counter of send and receive bytes to zero. """"""
        self.bytes_recv = 0
        self.bytes_sent = 0
",3
"    The :func:`send_message` and :func:`recv_message` works in the async manner.
    """"""

",3
"        return zmq.asyncio.Context()

    async def send_message(self, msg: 'jina_pb2.Message', sleep: float = 0, **kwargs):
        """"""Send a protobuf message in async via the output socket

",3
"        try:
",3
"    with zmq.Context() as ctx:
        ctx.setsockopt(zmq.LINGER, 0)
        sock, _ = _init_socket(ctx, address, None, SocketType.PAIR_CONNECT)
        req = jina_pb2.Request()
",3
"    except zmq.error.ZMQError as ex:
        default_logger.critical(ex)
    except asyncio.CancelledError:
        default_logger.error('all gateway tasks are cancelled')
    except Exception as ex:
",3
"        _msg = [msg.SerializeToString(),  # 1
",3
"async def send_message_async(sock: 'zmq.Socket', msg: 'jina_pb2.Message', timeout: int = -1,
                             array_in_pb: bool = False, compress_hwm: int = -1, compress_lwm: float = 1.,
                             **kwargs) -> int:
    """"""Send a protobuf message to a socket in async manner

",3
"    :param msg: the protobuf message
    :param timeout: waiting time (in seconds) for sending
",3
"        await sock.send_multipart(_msg)

        return num_bytes
",3
"        raise TimeoutError(
            'cannot send message to sock %s after timeout=%dms, please check the following:'
",3
"
    :param sock: the socket to pull from
",3
"            - the received protobuf message
            - the size of the message in bytes
    """"""
",3
"    try:
",3
"        else:
            sock.setsockopt(zmq.RCVTIMEO, -1)

        msg_data = sock.recv_multipart()
",3
"
        return _prepare_recv_msg(sock, msg_data, check_version)
",3
"    finally:
        sock.setsockopt(zmq.RCVTIMEO, -1)


async def recv_message_async(sock: 'zmq.Socket', timeout: int = -1, check_version: bool = False, **kwargs) -> Tuple[
",3
"    'jina_pb2.Message', int]:
    """""" Receive a protobuf message from a socket in async manner
",3
"    finally:
        try:
            sock.setsockopt(zmq.RCVTIMEO, -1)
",3
"    if _size_before > compress_hwm > 0:
",3
"    return msg, num_bytes

",3
"        # dealer consumes the first part of the message as id, we need to prepend it back
        msg_data = [' '] + msg_data
    elif sock.type == zmq.ROUTER:
        # the router appends dealer id when receive it, we need to remove it
",3
"        # body message is compressed
        import lz4.frame
        for l in range(2, len(msg_data)):
            msg_data[l] = lz4.frame.decompress(msg_data[l])
",3
"    msg = jina_pb2.Message()

    num_bytes = sum(sys.getsizeof(m) for m in msg_data)

",3
"    msg.ParseFromString(msg_data[2])

",3
"        _fill_buffer_to_msg(msg, msg_data, offset=3)

    return msg, num_bytes


",3
"def _init_socket(ctx: 'zmq.Context', host: str, port: int,
                 socket_type: 'SocketType', identity: 'str' = None, use_ipc: bool = False) -> Tuple['zmq.Socket', str]:
    sock = {
        SocketType.PULL_BIND: lambda: ctx.socket(zmq.PULL),
        SocketType.PULL_CONNECT: lambda: ctx.socket(zmq.PULL),
",3
"    if socket_type == SocketType.DEALER_CONNECT:
        sock.set_string(zmq.IDENTITY, identity)

    # if not socket_type.is_pubsub:
    #     sock.hwm = int(os.environ.get('JINA_SOCKET_HWM', 1))
",3
"                    'host is set from %s to %s as the socket is in BIND type' % (host, __default_host__))
                host = __default_host__
            if port is None:
                sock.bind_to_random_port('tcp://%s' % host)
            else:
",3
"                try:
                    sock.bind('tcp://%s:%d' % (host, port))
",3
"                    default_logger.error('error when binding port %d to %s' % (port, host))
                    raise ex
    else:
        if port is None:
",3
"            default_logger.warning('incoming message contains empty ""version.vcs"", '
",3
"def _extract_bytes_from_msg(msg: 'jina_pb2.Message') -> Tuple:
    doc_bytes = []
",3
"    chunk_bytes_len = int(msg_data[offset + 2])
    doc_bytes = msg_data[(offset + 3):(offset + 3 + doc_bytes_len)]
    chunk_bytes = msg_data[(offset + 3 + doc_bytes_len):]
    c_idx = 0
    d_idx = 0
",3
"            d.buffer = doc_bytes[d_idx]
",3
"            d_idx += 1

        for c in d.chunks:
            if chunk_bytes and chunk_bytes[c_idx]:
                c.embedding.buffer = chunk_bytes[c_idx]
",3
"
",3
"    #     self.args.dump_route.flush()
",3
"    r.pod = pod_name
    r.start_time.GetCurrentTime()
    r.pod_id = identity
",3
"    :param req: the protobuf request
    :param pod_name: the name of the current pod
",3
"import functools
import inspect
",3
"import threading
from concurrent import futures

",3
"    asyncio.set_event_loop(loop)
    if not loop.is_running():
        loop.run_forever()

    # If we reach here, the loop was stopped.
",3
"        loop.close()


class AsyncioExecutor(futures.Executor):
",3
"                                        daemon=True)
        self._thread.start()

    def submit(self, fn, *args, **kwargs):

",3
"            self._thread.join()
",3
"            if e not in state.rpc_errors:
",3
"            serialized_response = _server._serialize_response(
                rpc_event, state, response, response_serializer)
            if serialized_response is not None:
                _server._status(rpc_event, state, serialized_response)

",3
"        if proceed:
",3
"                response, proceed = await _take_response_from_response_iterator(
                    rpc_event, state, response_iterator)
                if proceed:
                    if response is None:
                        _server._status(rpc_event, state, None)
",3
"                        break
",3
"                            proceed = _server._send_response(rpc_event, state,
                                                             serialized_response)
",3
"    """"""Initialize a :class:`BasePea`, :class:`RemotePea` or :class:`ContainerPea`
",3
"
    """"""
    if args is None:
",3
"        from ..main.parser import set_pea_parser
        from ..helper import get_parsed_args
        _, args, _ = get_parsed_args(kwargs, set_pea_parser(), 'Pea')
    if not allow_remote:
",3
"    if args.host != __default_host__:
        from .remote import RemotePea
        return RemotePea(args)
    elif args.image:
",3
"                from .pod import MutablePod
                return MutablePod(args)
",3
"        from .remote import RemotePod
        return RemotePod(args)
    else:
        from .pod import BasePod
",3
"
import grpc

from .pea import BasePea
",3
"from ..proto import jina_pb2

if False:
",3
"

class PeaSpawnHelper(GrpcClient):
    body_tag = 'pea'

",3
"
    def call(self, set_ready: Callable = None):
        """"""

",3
"        getattr(req, self.body_tag).args.extend(kwargs2list(vars(self.args)))
",3
"        self.remote_logging(req, set_ready)
",3
"                    set_ready(resp)
                    self.callback_on_first = False
                self._remote_logger.info(resp.log_record)
        except grpc.RpcError:
",3
"
    def __init__(self, peas_args: Dict):
        inited = False
        for k in peas_args.values():
",3
"        self.args = peas_args
",3
"
    def call(self, set_ready: Callable = None):

        self.remote_logging(peas_args2mutable_pod_req(self.args), set_ready)
",3
"        return kwargs2list(vars(args))

    req = jina_pb2.SpawnRequest()
    if peas_args['head']:
        req.mutable_pod.head.args.extend(pod2pea_args_list(peas_args['head']))
",3
"            _a = req.mutable_pod.peas.add()
",3
"def mutable_pod_req2peas_args(req):
    from ..main.parser import set_pea_parser
    return {
        'head': set_pea_parser().parse_known_args(req.head.args)[0] if req.head.args else None,
",3
"class RemotePea(BasePea):
",3
"    """"""A RemotePea that spawns a remote :class:`BasePea`

",3
"        self._remote.close()

",3
"    remote_helper = MutablePodSpawnHelper
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

",3
"import asyncio
import os
import threading

import grpc
",3
"        self._p_servicer = self._Pea(args)
        self._stop_event = threading.Event()
        self.is_ready = threading.Event()
        self.init_server(args)

",3
"    def init_server(self, args):
        self._server = grpc.server(
            AsyncioExecutor(),
",3
"            options=[('grpc.max_send_message_length', args.max_message_size),
                     ('grpc.max_receive_message_length', args.max_message_size)])

",3
"        self._server.start()
        self.logger.success('gateway is listening at: %s' % self._bind_address)
",3
"                return msg.request

        async def CallUnary(self, request, context):
",3
"                        try:
                            asyncio.create_task(
",3
"                    _args = set_pod_parser().parse_known_args(_req.args)[0]
                    self.logger.info('starting a BasePod from a remote request')
",3
"
class RESTGatewayPea(BasePea):
",3
"    synchronous from the client perspective.
",3
"            raise ImportError('Flask or its dependencies are not fully installed, '
",3
"            return jsonify({'reason': reason}), code

        @app.route('/ready')
        @cross_origin()
        def is_ready():
",3
"            return Response(status=200)

        @app.route('/api/<mode>', methods=['POST'])
        @cross_origin()
        def api(mode):
",3
"            content['mode'] = ClientMode.from_string(mode)
",3
"                return http_error('""data"" field is empty', 406)

",3
"        signal.signal(signal.SIGINT, close)  # CTRL C
        self.set_ready()
        self.logger.warning('you are using a REST gateway, which is still in early beta version. '
                            'advanced features such as prefetch and streaming are disabled.')
        server.serve_forever()
",3
"        """"""
        self.peas = []
",3
"            if self.is_idle:
                self.close()
",3
"            # can be deducted based on the previous and next pods
            peas_args['head'] = _copy_to_head_args(args, args.polling.is_push)
",3
"        elif self.deducted_head:
",3
"            self.deducted_head = args
",3
"        else:
            raise ValueError('ambiguous head node, maybe it is deducted already?')

",3
"            return self.deducted_tail
        else:
            raise ValueError('ambiguous tail node, maybe it is deducted already?')

    @tail_args.setter
",3
"
",3
"
    @property
    def num_peas(self) -> int:
        """"""Get the number of running :class:`BasePea`""""""
        return len(self.peas)
",3
"    def __eq__(self, other: 'BasePod'):
        return self.num_peas == other.num_peas and self.name == other.name

    def set_runtime(self, runtime: str):
",3
"        if isinstance(self._args, argparse.Namespace) and getattr(self._args, 'shutdown_idle', False):
            self.sentinel_threads.append(Thread(target=self.close_if_idle,
",3
"                                                name='sentinel-shutdown-idle',
",3
"        which is inherited from :class:`jina.peapods.peas.BasePea`
",3
"        """"""
        self.stack = ExitStack()
        # start head and tail
",3
"        if self.peas_args['head']:
",3
"            self.stack.enter_context(p)

        if self.peas_args['tail']:
            p = BasePea(self.peas_args['tail'])
            self.peas.append(p)
",3
"            self.stack.enter_context(p)

        # start real peas and accumulate the storage id
        if len(self.peas_args['peas']) > 1:
            start_rep_id = 1
",3
"            self.stack.enter_context(p)

        self.start_sentinels()
        return self
",3
"        The :class:`BasePod` log iterator goes through all peas :attr:`log_iterator` and
        poll them sequentially. If non all them is active anymore, aka :attr:`is_event_loop`
",3
"            except Empty:
",3
"
",3
"        finally:
",3
"                 needs: Set[str] = None, parser: Callable = set_pod_parser):
        """"""
",3
"            first.tail_args.host_out = __default_host__  # bind always get default 0.0.0.0
            second.head_args.host_in = _fill_in_host(bind_args=first.tail_args,
                                                     connect_args=second.head_args)  # the hostname of s_pod
            second.head_args.port_in = first.tail_args.port_out
        else:
",3
"        if self._args.replicas > 1 and self.is_head_router:
",3
"        _args.port_in = head_args.port_out
        _args.port_out = tail_args.port_in
        _args.port_ctrl = random_port()
        _args.identity = get_random_identity()
        _args.socket_out = SocketType.PUSH_CONNECT
",3
"        if args.polling.is_push:
            if args.scheduling == SchedulerType.ROUND_ROBIN:
                _args.socket_in = SocketType.PULL_CONNECT
",3
"            _args.socket_in = SocketType.SUB_CONNECT
        _args.host_in = _fill_in_host(bind_args=head_args, connect_args=_args)
        _args.host_out = _fill_in_host(bind_args=tail_args, connect_args=_args)
        result.append(_args)
    return result
",3
"                _head_args.yaml_path = '_route'
    else:
        _head_args.socket_out = SocketType.PUB_BIND
        if as_router:
",3
"
    # head and tail never run in docker, reset their image to None
",3
"
",3
"    _tail_args.port_ctrl = random_port()
",3
"
",3
"def _fill_in_host(bind_args, connect_args):
    from sys import platform

    bind_local = (bind_args.host == '0.0.0.0')
    bind_docker = (bind_args.image is not None and bind_args.image)
",3
"    bind_conn_same_remote = not bind_local and not conn_local and (bind_args.host == connect_args.host)
    if platform == ""linux"" or platform == ""linux2"":
        local_host = '0.0.0.0'
",3
"    else:
        local_host = 'host.docker.internal'

    if bind_local and conn_local and conn_docker:
",3
"            return local_host
        else:
            return __default_host__
    else:
        return bind_args.host
",3
"
class GatewayFlowPod(GatewayPod, FlowPod):
    """"""A :class:`FlowPod` that holds a Gateway """"""
",3
"
    def __init__(self, kwargs: Dict = None, needs: Set[str] = None):
        FlowPod.__init__(self, kwargs, needs, parser=set_gateway_parser)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
",3
"

def clear_queue():
    """"""Clear the log queue and profile queue when the program exit

",3
"import logging
import os
",3
"import re
import sys
from copy import copy
from logging import Formatter
from logging.handlers import QueueHandler
",3
"        'DEBUG': dict(color='white', on_color=None),  # white
",3
"
    def format(self, record):
        cr = copy(record)
",3
"
class PlainFormatter(Formatter):
    """"""Remove all control chars from the log and format it as plain text """"""

",3
"            sort_keys=True)


",3
"

class EventHandler(logging.StreamHandler):
    """"""
    A cross-thread/process logger that allows fetching via iterator
",3
"        Some logs may be missing, no clear reason why.
    """"""

    def __init__(self, event):
",3
"    def emit(self, record):
        if record.levelno >= self.level:
            self._event.record = self.format(record)
            self._event.set()

",3
"    def info(self, msg: str, **kwargs):
        """"""log info-level message""""""
        if self.log_level <= LogVerbosity.INFO:
            sys.stdout.write('I:%s:%s' % (self.context, self._planify(msg)))
",3
"    :param fmt_str: use customized logging format, otherwise respect the ``JINA_LOG_LONG`` environment variable
    :param event_trigger: a ``threading.Event`` or ``multiprocessing.Event`` for event-based logger
    :return: the configured logger
",3
"
    .. note::
",3
"
    timed_fmt_str = f'%(asctime)s:' + fmt_str

",3
"    verbose_level = LogVerbosity.from_string(os.environ.get('JINA_LOG_VERBOSITY', 'INFO'))

    if os.name == 'nt':  # for Windows
        return NTLogger(context, verbose_level)
",3
"        logger.addHandler(h)

        # profile logger do not need other handler
",3
"        return logger

",3
"    console_handler.setFormatter(ColorFormatter(fmt_str))
",3
"    import logging

",3
"    :param unit: unit of the memory, default in Gigabytes
    """"""
    try:
        import resource
",3
"def profiling(func):
    """"""Decorator to mark a function for profiling. The time and memory usage will be recorded and printed.

    Example:

",3
"
        @profiling
        def foo():
            print(1)

",3
"    from . import default_logger

    @wraps(func)
    def arg_wrapper(*args, **kwargs):
",3
"        # level_prefix = ''.join('-' for v in inspect.stack() if v and v.index is not None and v.index >= 0)
",3
"class TimeDict:
",3
"    def __init__(self):
        self.accum_time = defaultdict(float)
        self.first_start_time = defaultdict(float)
        self.start_time = defaultdict(float)
",3
"        .. code-block:: python

",3
"        self._msg = msg
        self._logger = logger
        self.duration = 0
",3
"
if False:
",3
"    def __init__(self, args: 'argparse.Namespace'):
        """""" Start a pipe logger to beautify the log
",3
"from .queue import __sse_queue__, __profile_queue__
from .. import JINA_GLOBAL, __version__
",3
"            stream.close()
        };

    """"""
    try:
",3
"        from flask import Flask, Response, jsonify
        from flask_cors import CORS
    except ImportError:
        raise ImportError('Flask or its dependencies are not fully installed, '
                          'they are required for serving HTTP requests.'
",3
"        """"""Get the logs, endpoint `/log/stream`  """"""
        return Response(_log_stream(), mimetype=""text/event-stream"")

    @app.route(_config['endpoints']['yaml'])
    def get_yaml():
",3
"        from jina.main.parser import set_pod_parser
        from argparse import _StoreAction, _StoreTrueAction
        port_attr = ('help', 'choices', 'default')
        d = {}
",3
"        return 'Server shutting down...'
",3
"    except Exception as ex:
",3
"        default_logger.error(ex)
",3
"            message = __sse_queue__.get()
            yield 'data: {}\n\n'.format(message.msg)
",3
"            message = __profile_queue__.get()
            yield 'data: {}\n\n'.format(message.msg)
        except EOFError:
",3
"            d.weight = 1.0
            first_doc_id += 1
        yield req
        first_request_id += 1

",3
"                                 'ip and grpc port number of the server'
                                 % (args.host, args.port_grpc, args.timeout_ready))
            raise GRPCServerError('can not connect to the server at %s:%d' % (args.host, args.port_grpc))

",3
"        self.is_closed = False

",3
"        try:
            self.call(*args, **kwargs)
        except KeyboardInterrupt:
            self.logger.warning('user cancel the process')
",3
"
    def close(self):
        """"""Gracefully shutdown the client and release all grpc-related resources """"""
",3
"            with ProgressBar('loop'):
",3
"                do_busy()
",3
"        sys.stdout.flush()
        profile_logger.debug({'num_bars': num_bars,
",3
"        if self.num_docs > 0:
",3
"        sys.stdout.write('\t%s\n' % colored(f'â done in â± {elapsed:3.1f}s ð {speed:3.1f}/s', 'green'))
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""
",3
"if False:
    # fix type-hint complain for sphinx and flake
",3
"
    Assuming a Flow is ""standby"" on 192.168.1.100, with port_grpc at 55555.

",3
"    .. highlight:: python
    .. code-block:: python

        from jina.clients import py_client

",3
"        py_client(port_grpc='192.168.1.100', host=55555).search(input_fn, output_fn)

",3
"    @mode.setter
    def mode(self, value: ClientMode):
        if isinstance(value, ClientMode):
            self._mode = value
            self.args.mode = value
",3
"        try:
            r = next(getattr(request, 'index')(**kwargs))
            if r is not None:
                default_logger.success(f'input_fn is valid and the first request is as follows:\n{r}')
",3
"            else:
                raise TypeError
",3
"        req_iter = getattr(request, tname)(**_kwargs)
        # next(req_iter)

",3
"        with ProgressBar(task_name=tname) as p_bar, TimeContext(tname):
            for resp in self._stub.Call(req_iter):
                if callback:
",3
"            self._input_fn = bytes_gen()
",3
"        else:
            self._input_fn = bytes_gen
",3
"        for resp in self._stub.Call(req_gen()):
            self.logger.info(resp)
            return True

",3
"import os
",3
"from jina.proto import jina_pb2
from tests import JinaTestCase

replicas = 10
",3
"

def random_docs():
    c_id = 0
",3
"    np.random.seed(531)

    err = 0
",3
"
",3
"            yaml_path='_forward').add(yaml_path='_forward').add(yaml_path='_forward').add(yaml_path='_forward')
        with f as fl:
",3
"        for j in ('fp32', 'fp16', 'uint8'):
            self.f1(j)
            self.f2(j)
import unittest

",3
"                pass

            FlowPod(args).start().close()

",3
"import time

import requests
",3
"        f = Flow().add(yaml_path='_forward')
        with f:
            print(py_client(port_grpc=f.port_grpc).call_unary(b'a1234', mode=ClientMode.INDEX))

",3
"
    def test_check_input(self):
        input_fn = iter([b'1234', b'45467'])
        PyClient.check_input(input_fn)
",3
"        # self.assertRaises(TypeError, PyClient.check_input, bad_input_fn)
",3
"        with RESTGatewayPea(p):
            a = requests.get(f'http://0.0.0.0:{p.port_grpc}/ready')
            self.assertEqual(a.status_code, 200)

        with RESTGatewayPea(p):
",3
"        with f:
            a = requests.post(f'http://0.0.0.0:{f.port_grpc}/api/index',
                              json={'data': [
                                  'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAIAAABLbSncAAAA2ElEQVR4nADIADf/AxWcWRUeCEeBO68T3u1qLWarHqMaxDnxhAEaLh0Ssu6ZGfnKcjP4CeDLoJok3o4aOPYAJocsjktZfo4Z7Q/WR1UTgppAAdguAhR+AUm9AnqRH2jgdBZ0R+kKxAFoAME32BL7fwQbcLzhw+dXMmY9BS9K8EarXyWLH8VYK1MACkxlLTY4Eh69XfjpROqjE7P0AeBx6DGmA8/lRRlTCmPkL196pC0aWBkVs2wyjqb/LABVYL8Xgeomjl3VtEMxAeaUrGvnIawVh/oBAAD///GwU6v3yCoVAAAAAElFTkSuQmCC',
",3
"                             'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAIAAABLbSncAAAA2ElEQVR4nADIADf/AxWcWRUeCEeBO68T3u1qLWarHqMaxDnxhAEaLh0Ssu6ZGfnKcjP4CeDLoJok3o4aOPYAJocsjktZfo4Z7Q/WR1UTgppAAdguAhR+AUm9AnqRH2jgdBZ0R+kKxAFoAME32BL7fwQbcLzhw+dXMmY9BS9K8EarXyWLH8VYK1MACkxlLTY4Eh69XfjpROqjE7P0AeBx6DGmA8/lRRlTCmPkL196pC0aWBkVs2wyjqb/LABVYL8Xgeomjl3VtEMxAeaUrGvnIawVh/oBAAD///GwU6v3yCoVAAAAAElFTkSuQmCC')
",3
"import time
",3
"def random_docs(num_docs, chunks_per_doc=5, embed_dim=10):
    c_id = 0
    for j in range(num_docs):
",3
"        d = jina_pb2.Document()
        for k in range(chunks_per_doc):
            c = d.chunks.add()
            c.embedding.CopyFrom(array2pb(np.random.random([embed_dim])))
",3
"    n = np.array(n)
    # each chunk should return a list of top-100
    np.testing.assert_equal(n.shape[0], 5)
    np.testing.assert_equal(n.shape[1], 100)

",3
"    # the add() function is simply copied from NumpyIndexer
    def add(self, *args, **kwargs):
        pass

",3
"        if not self.num_dim:
            self.num_dim = vectors.shape[1]
            self.dtype = vectors.dtype.name
        elif self.num_dim != vectors.shape[1]:
            raise ValueError(
",3
"        elif keys.shape[0] != vectors.shape[0]:
            raise ValueError('number of key %d not equal to number of vectors %d' % (keys.shape[0], vectors.shape[0]))
        elif self.key_dtype != keys.dtype.name:
            raise TypeError(
",3
"        self.write_handler.write(vectors.tobytes())
",3
"        t = mp.Process(target=start_gateway)
        t.daemon = True
        t.start()

",3
"    def test_logging_message(self):
        os.environ['JINA_LOG_VERBOSITY'] = 'success'
",3
"    RemoteMutablePod
from tests import JinaTestCase


@unittest.skipIf('GITHUB_WORKFLOW' in os.environ, 'skip the network test on github workflow')
",3
"        logger.warning('warn, warn, warn')
        time.sleep(.1)
",3
"        logger.debug('warn, warn, warn')
        time.sleep(.1)
        logger.success('crit')
        time.sleep(.1)
",3
"
    def test_remote_pod(self):
        f_args = set_gateway_parser().parse_args(['--allow-spawn'])
        p_args = set_pod_parser().parse_args(
",3
"            ['--host', 'localhost', '--replicas', '3',
",3
"                time.sleep(5)

        t = Process(target=start_gateway)
        t.daemon = True
        t.start()
",3
"
    def test_remote_two_pea(self):
        # NOTE: right now there is no way to spawn two peas with one gateway!!!
        f_args = set_gateway_parser().parse_args(['--allow-spawn'])

",3
"        def start_gateway():
            with GatewayPod(f_args):
                time.sleep(5)
",3
"        MutablePodSpawnHelper(p.peas_args).start()

",3
"                time.sleep(5)
",3
"
        t = Process(target=start_gateway)
        t.daemon = True
",3
"        p_args = set_pea_parser().parse_args(['--host', 'localhost', '--port-grpc', str(f_args.port_grpc)])

        def start_gateway():
",3
"        with RemotePea(p_args):
            pass
        t.join()

",3
"
        t = Process(target=start_gateway)
        t.daemon = True
",3
"        def start_gateway():
            with GatewayPod(f_args):
                time.sleep(5)
",3
"        time.sleep(1)
",3
"

if __name__ == '__main__':
",3
"
from jina.drivers import BaseDriver
from jina.drivers.control import ControlReqDriver
",3
"        self.assertTrue(isinstance(a[0], KVSearchDriver))
        self.assertTrue(isinstance(a[1], ControlReqDriver))
        self.assertTrue(isinstance(a[2], BaseDriver))

",3
"
        self.assertTrue(isinstance(b, KVSearchDriver))
        self.assertEqual(b._executor_name, a[0]._executor_name)

        self.add_tmpfile('test_driver.yml')
",3
"        a.save()
        c = BaseExecutor.load(a.save_abspath)
        self.assertEqual(a._drivers, c._drivers)
        self.add_tmpfile(a.save_abspath)
",3
"        a = BaseExecutor.load_config(resource_filename('jina', '/'.join(('resources', 'executors._forward.yml'))))
        self.assertEqual(a.name, 'forward')
        self.assertEqual(len(a._drivers), 4)
        a = BaseExecutor.load_config(resource_filename('jina', '/'.join(('resources', 'executors._merge.yml'))))
",3
"from jina.helper import yaml, expand_dict
from jina.main.parser import set_pea_parser
from jina.peapods.pea import BasePea
from tests import JinaTestCase
",3
"

class MyTestCase(JinaTestCase):
",3
"        with open('yaml/test-expand.yml') as fp:
            a = yaml.load(fp)
        b = expand_dict(a)
",3
"        print(b)

",3
"        self.assertEqual(b['components'][0]['metas']['bad_var'], 'real-compound')
        self.assertEqual(b['components'][1]['metas']['bad_var'], 2)
        self.assertEqual(b['components'][1]['metas']['float_var'], 0.232)
",3
"        a.__dict__['sda'] = 1
        self.assertEqual(a.sda, 1)
        a.__dict__['components'] = list()
        self.assertTrue(isinstance(a.components, list))

",3
"
        yaml.register_class(DummyClass)
",3
"
        with BasePea(args) as p:
            pass

        from jina.executors.requests import _defaults
",3
"from jina.helper import expand_env_var
from jina.logging import default_logger
from tests import JinaTestCase

",3
"def random_docs(num_docs, chunks_per_doc=5, embed_dim=10):
    c_id = 0
    for j in range(num_docs):
",3
"
    def setUp(self) -> None:
",3
"
        with ContainerPea(args):
            time.sleep(2)

    def test_flow_with_one_container_pod(self):
",3
"        f = (Flow()
",3
"        f = (Flow()
             .add(name='dummyEncoder',
                  image=img_name,
",3
"             .add(name='d2', yaml_path='_logforward')
             .add(name='d3', image='jinaai/jina:devel', yaml_path='_logforward',
                  needs='d1', entrypoint='jina pod')
             .join(['d3', 'd2'])
",3
"             )

        with f:
            f.index(input_fn=random_docs(10), input_type=ClientInputType.PROTOBUF)

",3
"    def test_flow_topo_replicas(self):
        f = (Flow()
             .add(name='d1', image='jinaai/jina:devel', entrypoint='jina pod', yaml_path='_forward', replicas=3)
             .add(name='d2', yaml_path='_forward', replicas=3)
",3
"        f = (Flow()
             .add(name='d1', image='jinaai/jina:devel', entrypoint='jina pod', yaml_path='_forward', replicas=3)
             .add(name='d2', yaml_path='_forward'))
        with f:
            self.assertEqual(getattr(f._pod_nodes['d1'].peas_args['tail'], 'host_out'), defaulthost)
",3
"import time
import unittest
",3
"from tests import JinaTestCase


",3
"            while True:
                _event.wait()
                print('thread: %s' % _event.record)
                print(type(_event.record))
                _event.clear()
",3
"            PeaSpawnHelper(p_args).start()

",3
"

if __name__ == '__main__':
",3
"import unittest

import numpy as np

",3
"def random_docs(num_docs, chunks_per_doc=5, embed_dim=10):
    c_id = 0
    for j in range(num_docs):
        d = jina_pb2.Document()
",3
"            c.chunk_id = c_id
",3
"def get_result(resp):
    n = []
",3
"            self.num_dim = vectors.shape[1]
            self.dtype = vectors.dtype.name
",3
"                (vectors.shape[0], vectors.shape[1], self.num_dim))
        elif self.dtype != vectors.dtype.name:
",3
"
    def tearDown(self) -> None:
        super().tearDown()
",3
"        b = DummyIndexer2(index_filename='testb.bin')
        b.save()
        self.assertFalse(os.path.exists(b.save_abspath))
",3
"        self.assertFalse(os.path.exists(b.index_abspath))
",3
"            self.assertEqual(f1.num_peas, 6)
            t1 = mp.Process(target=start_client, args=(f1,))
",3
"            self.assertTrue(os.path.exists(f'test2-{j + 1}/tmp2'))
            self.add_tmpfile(f'test2-{j + 1}/test2.bin', f'test2-{j + 1}/tmp2', f'test2-{j + 1}')

        time.sleep(3)
",3
"        with f:
            f.search(input_fn=random_docs(1), input_type=ClientInputType.PROTOBUF, output_fn=get_result, top_k=100)


",3
"
from jina import JINA_GLOBAL
",3
"
class MyTestCase(JinaTestCase):
",3
"             .add(name='r10', yaml_path='_merge', needs=['r9', 'r8']))

        with f:
",3
"        def bytes_fn():
",3
"
        with f:
            f.index(input_fn=bytes_fn)

        with f:
",3
"        f = (Flow()
             .add(name='dummyEncoder', yaml_path='mwu-encoder/mwu_encoder.yml'))
",3
"
        with f:
",3
"        self.assertEqual(f.args.optimize_level, fl.args.optimize_level)
        self.add_tmpfile('test1.yml')
",3
"
        def validate(req):
            self.assertEqual(len(req.docs), 1)
",3
"            self.assertEqual(len(req.docs[0].topk_results), index_docs)

            for d in req.docs[0].topk_results:
",3
"                self.assertTrue(hasattr(d.match_doc, 'weight'))
                self.assertIsNotNone(d.match_doc.weight)
                self.assertEqual(d.match_doc.meta_info, b'hello world')

        f = Flow().add(name='doc_pb', yaml_path='yaml/test-docpb.yml', replicas=replicas, separated_workspace=True)
",3
"             .add(name='r4', yaml_path='_forward', needs='r2')
             .add(name='r5', yaml_path='_forward', needs='r3')
",3
"             .add(name='r10', yaml_path='_merge', needs=['r9', 'r8']))
",3
"        with f:
",3
"
",3
"    def test_share_workspace(self):
        for j in range(3):
            a = BaseExecutor.load_config('yaml/test-workspace.yml', True, j)
",3
"            a = BaseExecutor.load_config('yaml/test-compound-indexer2.yml', True, j)
            self.assertEqual(a[0], a['test_meta'])
            self.assertFalse(a[0].is_updated)
",3
"            self.assertTrue(os.path.exists(a[0].save_abspath))
            self.assertTrue(os.path.exists(a[0].index_abspath))
            self.assertTrue(os.path.exists(a[1].save_abspath))
            self.assertTrue(os.path.exists(a[1].index_abspath))
            self.add_tmpfile(a[0].save_abspath, a[1].save_abspath, a[0].index_abspath, a[1].index_abspath,
",3
"                             a.current_workspace)

",3
"        np.testing.assert_almost_equal(all_vecs, np.concatenate(recovered_vecs))
import os
import subprocess
",3
"import unittest
from pathlib import Path

from jina.clients import py_client
from jina.flow import Flow
",3
"        os.environ['RESOURCE_DIR'] = resource_filename('jina', 'resources')
        os.environ['SHARDS'] = str(args.shards)
        os.environ['REPLICAS'] = str(args.replicas)
        os.environ['HW_WORKDIR'] = args.workdir
        os.environ['WITH_LOGSERVER'] = str(args.logserver)
",3
"
        f = Flow.load_config(resource_filename('jina', '/'.join(('resources', 'helloworld.flow.index.yml'))))

        targets = {
            'index': {
",3
"                'url': args.query_data_url,
                'filename': os.path.join(args.workdir, 'query-original')
",3
"if __name__ == '__main__':
    unittest.main()
",3
"import sys
import unittest
from os.path import dirname


",3
"class JinaTestCase(unittest.TestCase):
",3
"
    def tearDown(self) -> None:
        for k in self.tmp_files:
            if os.path.exists(k):
",3
"        d = jina_pb2.Document()
        for k in range(chunks_per_doc):
",3
"            c = d.chunks.add()
            c.embedding.CopyFrom(array2pb(np.random.random([embed_dim])))
",3
"            f.index(input_fn=random_docs(100), input_type=ClientInputType.PROTOBUF, batch_size=10)
",3
"        with f:
",3
"    def __call__(self, *args, **kwargs):
        print('hello from customized drivers')
",3
"import os
import unittest
",3
"
",3
"
        b = CompoundExecutor({'say': {da.name: 'say'}})
        b.components = lambda: [da, db]
        self.assertEqual(b.say_all(), ['a', 'b'])
        self.assertEqual(b.say(), 'a')
",3
"
        b.add_route('say', db.name, 'say', is_stored=True)
        b.save_config()
        c = BaseExecutor.load_config(b.config_abspath)
        self.assertEqual(c.say_all(), ['a', 'b'])
",3
"        self.tmp_files.append(b.config_abspath)
        self.tmp_files.append(b.save_abspath)
",3
"        a = CompoundExecutor()
        a.components = lambda: [BaseExecutor(), BaseExecutor()]
        self.assertIsNotNone(a.name)
        self.tmp_files.append(a.save_abspath)
",3
"        self.tmp_files.append(a.config_abspath)
        a.touch()
        a.save()
",3
"

",3
"    def metas(self):
",3
"        if 'JINA_TEST_GPU' in os.environ:
            metas['on_gpu'] = True
        return metas
",3
"

if __name__ == '__main__':
",3
"from jina.executors.rankers.bi_match import BiMatchRanker
from tests.executors.rankers import RankerTestCase


class MyTestCase(RankerTestCase):
",3
"
if __name__ == '__main__':
    unittest.main()
",3
"
",3
"class MyTestCase(RankerTestCase):
    def __init__(self, *args, **kwargs):
",3
"                match_chunk_meta[c['chunk_id']] = {'length': c['length']}
                match_idx.append([
",3
"                    c['doc_id'],
                    c['chunk_id'],
                    query_chunk_id,
",3
"        self.assertGreater(doc_idx[0][1], doc_idx[1][1])
        self.assertEqual(doc_idx[0][0], 1)
        self.assertEqual(doc_idx[1][0], 4294967294)
        # check the number of matched docs
        self.assertEqual(len(doc_idx), 2)
",3
"class MyTestCase(RankerTestCase):
",3
"    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.ranker = TfIdfRanker(threshold=0.2)


",3
"        kwargs.update(default_kwargs)
        super().__init__(*args, **kwargs)


@unittest.skip('add grpc mocking for this test')
",3
"        result = encoder.encode(data)
        self.assertEqual(result.shape, (10, ))

    def test_save_and_load(self):
",3
"        encoder.save_config()
        self.assertTrue(os.path.exists(encoder.config_abspath))
        encoder_loaded = BaseExecutor.load_config(encoder.config_abspath)
        self.assertEqual(encoder_loaded.model_name, encoder.model_name)
",3
"

",3
"if __name__ == '__main__':
    unittest.main()
import unittest
",3
"from jina.executors.encoders.nlp.flair import FlairTextEncoder
from tests.executors.encoders.nlp import NlpTestCase

",3
"
class MyTestCase(NlpTestCase):
    def _get_encoder(self, metas):
        return FlairTextEncoder(embeddings=('word:glove',), pooling_strategy='mean', metas=metas)
",3
"
",3
"        encoded_data_control = encoder.encode(test_data)

        encoder.touch()
        encoder.save()
",3
"        self.assertTrue(os.path.exists(encoder.save_abspath))
        encoder_loaded = BaseExecutor.load(encoder.save_abspath)
",3
"        np.testing.assert_array_equal(encoded_data_control, encoded_data_test)
",3
"            encoder.config_abspath, encoder.save_abspath, encoder_loaded.config_abspath, encoder_loaded.save_abspath)
",3
"
if __name__ == '__main__':
    unittest.main()
import os
import unittest
",3
"
import numpy as np

",3
"from jina.executors import BaseExecutor
from tests.executors import ExecutorTestCase


",3
"
    @target_output_dim.setter
    def target_output_dim(self, output_dim):
        self._target_output_dim = output_dim
",3
"
",3
"        if encoder is None:
",3
"from tests.executors.encoders.nlp import NlpTestCase


class MyTestCase(NlpTestCase):
",3
"            encoder.workspace = self.workspace
",3
"        encoder_loaded = BaseExecutor.load(encoder.save_abspath)
        encoded_data_test = encoder_loaded.encode(test_data)
        np.testing.assert_array_equal(
",3
"        return ImageTorchEncoder(metas=metas)
",3
"
class TestNet(nn.Module):
    def __init__(self):
        super(TestNet, self).__init__()
",3
"import unittest

import numpy as np

from jina.executors import BaseExecutor
",3
"    @property
    def input_dim(self):
        return self._input_dim
",3
"        if encoder is None:
            return
",3
"        self.assertEqual(encoder_loaded.channel_axis, encoder.channel_axis)
",3
"            return
",3
"from tests.executors.encoders.video import VideoTestCase


class MyTestCase(VideoTestCase):
    def _get_encoder(self, metas):
",3
"        self.target_output_dim = 512
        self.input_dim = 112
        return VideoTorchEncoder(metas=metas)

",3
"

class VideoTestCase(ExecutorTestCase):
    @property
",3
"        encoder = self.get_encoder()
        if encoder is None:
            return
",3
"        test_data = np.random.rand(2, 3, 3, 224, 224)
        encoded_data = encoder.encode(test_data)
        self.assertEqual(encoded_data.shape, (2, self._target_output_dim))

",3
"        encoded_data_control = encoder.encode(test_data)
        encoder.touch()
",3
"        encoder.save()
        self.assertTrue(os.path.exists(encoder.save_abspath))
        encoder_loaded = BaseExecutor.load(encoder.save_abspath)
        encoded_data_test = encoder_loaded.encode(test_data)
",3
"        self.assertEqual(encoder_loaded.model_name, encoder.model_name)
",3
"        if encoder is None:
            return
        encoder.save_config()
        self.assertTrue(os.path.exists(encoder.config_abspath))
        encoder_loaded = BaseExecutor.load_config(encoder.config_abspath)
",3
"class MyTestCase(VideoTestCase):
    def _get_encoder(self, metas):
        self.target_output_dim = 2048
        self.input_dim = 224
",3
"        return VideoPaddlehubEncoder(metas=metas)

",3
"        for d in req.index.docs:
            for c in d.chunks:
",3
"            yield fp.read()
            idx += 1


",3
"        with f:
",3
"            f.index(input_fn=input_fn2, output_fn=print, input_type=ClientInputType.FILE_PATH)

",3
"    def test_aba(self):
        f = (Flow().add(yaml_path='!Buffer2DataURI\nwith: {mimetype: png}')
             .add(yaml_path='DataURI2Buffer')
             .add(yaml_path='!Buffer2DataURI\nwith: {mimetype: png}'))
",3
"                 b'tokenized in 2 sentences.'
        crafted_chunk_list = sentencizer.craft(buffer, 0)
        self.assertEqual(len(crafted_chunk_list), 2)
",3
"        sentencizer = Sentencizer()
        buffer = 'ä»å¤©æ¯ä¸ªå¤§æ´å¤©ï¼å®è¿ªåæ¥ä»¥åï¼æä»¬åå¤å»å¨ç©å­ã'.encode('utf8')
        crafted_chunk_list = sentencizer.craft(buffer, 0)
        self.assertEqual(len(crafted_chunk_list), 2)
",3
"if __name__ == '__main__':
    unittest.main()
",3
"

class MyTestCase(JinaTestCase):
    def test_array_reader(self):
        size = 8
",3
"
import numpy as np

",3
"        output_dim = 20
",3
"        crafted_chunk_list = crafter.craft(img_array, 0, 0)
        self.assertEqual(len(crafted_chunk_list), 9)

",3
"
",3
"from tests.executors.crafters.image import JinaImageTestCase

",3
"    unittest.main()
from tests import JinaTestCase


class JinaImageTestCase(JinaTestCase):
",3
"    def create_random_img_array(img_height, img_width):
",3
"        import numpy as np
        return np.random.randint(0, 256, (img_height, img_width, 3))

",3
"    def test_resize(self):
        img_width = 20
        img_height = 17
",3
"from jina.executors.indexers.vector.numpy import NumpyIndexer
from tests import JinaTestCase

# fix the seed here
np.random.seed(500)
",3
"        self.assertEqual(idx.shape, dist.shape)
        self.assertEqual(idx.shape, (10, 4))
        self.add_tmpfile(a.index_abspath, a.save_abspath)
",3
"
    def test_scipy_indexer(self):
        a = NumpyIndexer(index_filename='np.test.gz', backend='scipy')
        a.add(vec_idx, vec)
        a.save()
",3
"        self.assertEqual(idx.shape, dist.shape)
        self.assertEqual(idx.shape, (10, 4))
        self.add_tmpfile(a.index_abspath, a.save_abspath)

",3
"    def test_nmslib_indexer(self):
        a = NmslibIndexer(index_filename='np.test.gz', space='l2')
        a.add(vec_idx, vec)
        a.save()
",3
"            np.testing.assert_almost_equal(retr_idx, idx)
        self.assertEqual(idx.shape, dist.shape)
        self.assertEqual(idx.shape, (10, 4))
",3
"        self.add_tmpfile(a.index_abspath, a.save_abspath)
",3
"import os
import unittest
",3
"
from google.protobuf.json_format import MessageToJson

",3
"        data = {
            'd1': MessageToJson(self._create_Document(1, 'cat', 0.1, 3)),
",3
"        indexer.add(data)
        indexer.save()
",3
"        self.add_tmpfile(indexer.save_abspath, indexer.index_abspath)

",3
"import os
",3
"slug = re.sub(r'\W+', '-', project.lower())
author = 'Jina AI Dev Team'
copyright = 'Jina AI Limited. All rights reserved.'
source_suffix = ['.rst', '.md']
master_doc = 'index'
",3
"language = 'en'
",3
"    'style_external_links': True,
    # 'vcs_pageview_mode': '',
",3
"    # 'navigation_depth': 4,
    'includehidden': True,
    'titles_only': True,
",3
"    'sphinx_rtd_theme',
    'recommonmark',
    'sphinx_markdown_tables',
",3
"    'sphinx_copybutton'
]

apidoc_module_dir = '../jina/'
apidoc_output_dir = 'api'
",3
"        'confval',
        'confval',
",3
"            PyField(
                'type',
                label=_('Type'),
                has_arg=False,
",3
"                names=('type',),
",3
"import tempfile
",3
"    .. highlight:: python
",3
"
",3
"
        As an example, the following flow will generates a 6 Peas,

        .. highlight:: python
        .. code-block:: python
",3
"            f = Flow(optimize_level=FlowOptimizeLevel.NONE).add(yaml_path='forward', replicas=3)

        The optimized version, i.e. :code:`Flow(optimize_level=FlowOptimizeLevel.FULL)`
        will generate 4 Peas, but it will force the :class:`GatewayPea` to take BIND role,
        as the head and tail routers are removed.
",3
"
        self._update_args(args, **kwargs)
",3
"        self.args = args
        if kwargs and self.args.logserver and 'log_sse' not in kwargs:
",3
"        return representer.represent_mapping('!' + cls.__name__, tmp)

    @staticmethod
    def _dump_instance_to_yaml(data):
",3
"
    @property
    def yaml_spec(self):
",3
"    @classmethod
    def load_config(cls: Type['Flow'], filename: Union[str, TextIO]) -> 'Flow':
",3
"            constructor, node, deep=True)
",3
"                endpoint = []

        if isinstance(endpoint, list) or isinstance(endpoint, tuple):
            for idx, s in enumerate(endpoint):
                if s == pod_name:
",3
"        if name not in op_flow._pod_nodes:
            raise FlowMissingPodError('%s can not be found in this Flow' % name)

        if op_flow._last_changed_pod and name == op_flow._last_changed_pod[-1]:
",3
"        # reset the build level to the lowest
        op_flow._build_level = FlowBuildLevel.EMPTY

        return op_flow

",3
"        pod_name = 'gateway'

",3
"            raise FlowTopologyError('no need to wait for a single service, need len(needs) > 1')
        return self.add(name='joiner', yaml_path='_merge', needs=needs, *args, **kwargs)

",3
"        Note there are shortcut versions of this method.
        Recommend to use :py:meth:`add_encoder`, :py:meth:`add_preprocessor`,
        :py:meth:`add_router`, :py:meth:`add_indexer` whenever possible.

",3
"        if not pod_name.isidentifier():
            # hyphen - can not be used in the name
            raise ValueError('name: %s is invalid, please follow the python variable name conventions' % pod_name)
",3
"
        needs = op_flow._parse_endpoints(op_flow, pod_name, needs, connect_to_last_pod=True)

",3
"        kwargs.update(op_flow._common_kwargs)
        kwargs['name'] = pod_name
        kwargs['num_part'] = len(needs)
",3
"
                f = Flow()
",3
"            op_flow._add_gateway(needs={op_flow._last_changed_pod[-1]})

        # direct all income peas' output to the current service
        for k, p in op_flow._pod_nodes.items():
            for s in p.needs:
",3
"                    raise FlowMissingPodError('%s is not in this flow, misspelled name?' % s)
                _pod_edges.add('%s-%s' % (s, k))

",3
"        for k in _pod_edges:
            s_name, e_name = k.split('-')
            edges_with_same_start = [ed for ed in _pod_edges if ed.startswith(s_name)]
            edges_with_same_end = [ed for ed in _pod_edges if ed.endswith(e_name)]

",3
"
            # Rule
",3
"                # check if either node is gateway
                # this is the only place where gateway appears
                if s_name == 'gateway':
                    if self.args.optimize_level > FlowOptimizeLevel.IGNORE_GATEWAY and e_pod.is_head_router:
",3
"                        FlowPod.connect(s_pod, e_pod, first_socket_type=SocketType.PUSH_BIND)
                else:
",3
"                raise FlowTopologyError('found %d edges start with %s and %d edges end with %s, '
                                        'this type of topology is ambiguous and should not exist, '
                                        'i can not determine the socket type' % (
                                            len(edges_with_same_start), s_name, len(edges_with_same_end), e_name))
",3
"        return op_flow

",3
"            time.sleep(1)
            urllib.request.urlopen(JINA_GLOBAL.logserver.ready, timeout=5)
            self.logger.success(f'logserver is started and available at {JINA_GLOBAL.logserver.address}')
        except ModuleNotFoundError:
",3
"
        if self.args.logserver:
            self.logger.info('start logserver...')
",3
"        return self

    @property
    def num_pods(self) -> int:
",3
"    def close(self):
        """"""Close the flow and release all resources associated to it. """"""
        if hasattr(self, '_pod_stack'):
            self._pod_stack.close()
        # if hasattr(self, 'sse_logger') and self.sse_logger.is_alive():
",3
"        Comparing the topology of a flow with another flow.
        Identification is defined by whether two flows share the same set of edges.

        :param other: the second flow object
",3
"        else:
            b = other

        return a._pod_nodes == b._pod_nodes
",3
"            kwargs['port_grpc'] = self.port_grpc
",3
"
    @deprecated_alias(buffer='input_fn', callback='output_fn')
    def train(self, input_fn: Union[Iterator['jina_pb2.Document'], Iterator[bytes], Callable] = None,
              output_fn: Callable[['jina_pb2.Message'], None] = None,
",3
"                ...

",3
"                for _ in range(10):
                    yield b'abcdfeg'   # each yield generates a document for training

            with f.build(runtime='thread') as flow:
                flow.train(bytes_gen=my_reader())
",3
"        :param kwargs: accepts all keyword arguments of `jina client` CLI
        """"""
        self._get_client(**kwargs).train(input_fn, output_fn)

    @deprecated_alias(buffer='input_fn', callback='output_fn')
",3
"              output_fn: Callable[['jina_pb2.Message'], None] = None,
              **kwargs):
        """"""Do indexing on the current flow

        Example,
",3
"                flow.index(txt_file='aa.txt')
",3
"                flow.index(image_zip_file='aa.zip', batch_size=64)
                flow.index(video_zip_file='aa.zip')
                ...
",3
"
        Example,

        .. highlight:: python
        .. code-block:: python
",3
"
        :param input_fn: An iterator of bytes. If not given, then you have to specify it in `kwargs`.
",3
"        :param output_fn: the callback function to invoke after indexing
        :param kwargs: accepts all keyword arguments of `jina client` CLI
",3
"    @deprecated_alias(buffer='input_fn', callback='output_fn')
    def search(self, input_fn: Union[Iterator['jina_pb2.Document'], Iterator[bytes], Callable] = None,
               output_fn: Callable[['jina_pb2.Message'], None] = None,
",3
"        .. code-block:: python

",3
"            with f.build(runtime='thread') as flow:
                flow.search(txt_file='aa.txt')
                flow.search(image_zip_file='aa.zip', batch_size=64)
",3
"                flow.search(video_zip_file='aa.zip')
",3
"            pass

",3
"import argparse
",3
"
from . import Pea
from .gateway import GatewayPea, RESTGatewayPea
from .pea import BasePea
",3
"            self.is_tail_router = True
        else:
",3
"    @property
    def tail_args(self):
        """"""Get the arguments for the `tail` of this BasePod. """"""
        if self.is_tail_router and self.peas_args['tail']:
",3
"        elif self.deducted_tail:
            return self.deducted_tail
",3
"        else:
            raise ValueError('ambiguous tail node, maybe it is deducted already?')
",3
"        elif self.deducted_tail:
",3
"
",3
"        if isinstance(self._args, argparse.Namespace) and getattr(self._args, 'shutdown_idle', False):
            self.sentinel_threads.append(Thread(target=self.close_if_idle,
                                                name='sentinel-shutdown-idle',
                                                daemon=True))
        for t in self.sentinel_threads:
",3
"
        Note that this method has a timeout of ``timeout_ready`` set in CLI,
",3
"            self.stack.enter_context(p)

        self.start_sentinels()
        return self

",3
"
            The log may not strictly follow the time order given that we are polling the log
",3
"    @property
    def is_shutdown(self) -> bool:
        return all(not p.is_ready.is_set() for p in self.peas)
",3
"        """"""The status of a BasePod is the list of status of all its Peas """"""
",3
"        return [p.status for p in self.peas]

",3
"    def is_ready(self) -> bool:
        """"""Wait till the ready signal of this BasePod.

",3
"
",3
"
class MutablePod(BasePod):
    """"""A :class:`MutablePod` is a pod where all peas and their connections are given""""""

    def _parse_args(self, args):
",3
"class FlowPod(BasePod):
    """"""A :class:`FlowPod` is like a :class:`BasePod`, but it exposes more interfaces for tweaking its connections with
    other Pods, which comes in handy when used in the Flow API
    """"""

",3
"        """"""

        :param kwargs: unparsed argument in dict, if given the
        :param needs: a list of names this BasePod needs to receive message from
        """"""
",3
"        elif first_socket_type == SocketType.PUSH_CONNECT:
            first.tail_args.socket_out = SocketType.PUSH_CONNECT
            second.head_args.socket_in = SocketType.PULL_BIND

",3
"            first.tail_args.host_out = _fill_in_host(connect_args=first.tail_args,
",3
"            # update peas to receive from it
            self.peas_args['peas'] = _set_peas_args(self._args, self.head_args, pod.head_args)
",3
"            self.is_tail_router = False
",3
"    def start(self):
        if self._args.host == __default_host__:
",3
"            return super().start()
        else:
            from .remote import RemoteMutablePod
",3
"            self.stack = ExitStack()
",3
"

def _set_peas_args(args, head_args, tail_args):
",3
"        if args.polling.is_push:
",3
"        _head_args.socket_out = SocketType.PUB_BIND
        if as_router:
            _head_args.yaml_path = '_forward'
",3
"    _tail_args.socket_in = SocketType.PULL_BIND
    if as_router:
        _tail_args.yaml_path = args.reducing_yaml_path
        _tail_args.name = args.name or ''
        _tail_args.role = PeaRoleType.TAIL
",3
"    if platform == ""linux"" or platform == ""linux2"":
        local_host = '0.0.0.0'
    else:
        local_host = 'host.docker.internal'
",3
"
    if bind_local and conn_local and conn_docker:
",3
"        FlowPod.__init__(self, kwargs, needs, parser=set_gateway_parser)
__copyright__ = ""Copyright (c) 2020 Jina AI Limited. All rights reserved.""
__license__ = ""Apache-2.0""

import argparse
",3
"            or_event.set()
        else:
",3
"
class BasePea(metaclass=PeaMeta):
    """"""BasePea is an unary service unit which provides network interface and
    communicates with others via protobuf and ZeroMQ
    """"""
",3
"        """""" Create a new :class:`BasePea` object

        :param args: the arguments received from the CLI
",3
"        self.args = args
        self.name = self.__class__.__name__  #: this is the process name
",3
"            if args.name:
",3
"
            if num_req == self.args.num_part:
                self._prev_messages = self._pending_msgs.pop(req_id)
                self._prev_requests = [getattr(v.request, v.request.WhichOneof('body')) for v in self._prev_messages]
",3
"
    @property
",3
"        """"""Get the current request body inside the protobuf message""""""
",3
"                yield __log_queue__.get_nowait()
",3
"            ' '.join('%s: %.2f' % (k, v / self._timer.accum_time['loop']) for k, v in self._timer.accum_time.items()))
",3
"    def pre_hook(self, msg: 'jina_pb2.Message') -> 'BasePea':
        """"""Pre-hook function, what to do after first receiving the message """"""
        msg_type = msg.request.WhichOneof('body')
",3
"        self.logger.success(__ready_msg__)

    def unset_ready(self, *args, **kwargs):
        """"""Set the status of the pea to shutdown """"""
",3
"            self.executor.close()
        if hasattr(self, 'zmqlet'):
            if self.request_type == 'ControlRequest' and \
                    self.request.command == jina_pb2.Request.ControlRequest.TERMINATE:
",3
"    @property
    def status(self):
",3
"        if isinstance(self.args, dict):
            _timeout = getattr(self.args['peas'][0], 'timeout_ready', 5e3) / 1e3
        else:
            _timeout = getattr(self.args, 'timeout_ready', 5e3) / 1e3
",3
"__license__ = ""Apache-2.0""

import inspect
from functools import wraps
",3
"                tmp[k] = v

        if self.store_args_kwargs:
            if args: tmp['args'] = args
            if kwargs: tmp['kwargs'] = {k: v for k, v in kwargs.items() if k not in taboo}
",3
"
",3
"        f = func(self, *args, **kwargs)
        return f

",3
"
class DriverType(type):

    def __new__(cls, *args, **kwargs):
        _cls = super().__new__(cls, *args, **kwargs)
",3
"            reg_cls_set.add(cls.__name__)
            setattr(cls, '_registered_class', reg_cls_set)
",3
"    """"""A :class:`BaseDriver` is a logic unit above the :class:`jina.peapods.pea.BasePea`.
    It reads the protobuf message, extracts/modifies the required information and then return
    the message back to :class:`jina.peapods.pea.BasePea`.

",3
"    A :class:`BaseDriver` needs to be :attr:`attached` to a :class:`jina.peapods.pea.BasePea` before using. This is done by
    :func:`attach`. Note that a deserialized :class:`BaseDriver` from file is always unattached.
    """"""
",3
"    def prev_reqs(self) -> List['jina_pb2.Request']:
        """"""Get all previous requests that has the same ``request_id``, shortcut to ``self.pea.prev_requests``
",3
"
        This returns ``None`` when ``num_part=1``.
        """"""
        return self.pea.prev_requests
",3
"
",3
"
",3
"        This returns ``None`` when ``num_part=1``.
        """"""
        return self.pea.prev_messages

    @property
",3
"    def from_yaml(cls, constructor, node):
",3
"        """"""Required by :mod:`ruamel.yaml.constructor` """"""
        return cls._get_instance_from_yaml(constructor, node)

    @classmethod
    def _get_instance_from_yaml(cls, constructor, node):
",3
"
",3
"    def __getstate__(self):
        """"""Do not save the BasePea, as it would be cross-referencing. In other words, a deserialized :class:`BaseDriver` from
",3
"        d['attached'] = False
        return d


class BaseExecutableDriver(BaseDriver):
",3
"
        :param executor: the name of the sub-executor, only necessary when :class:`jina.executors.compound.CompoundExecutor` is used
",3
"        return self._exec

",3
"    def attach(self, executor: 'AnyExecutor', *args, **kwargs):
        """"""Attach the driver to a :class:`jina.executors.BaseExecutor`""""""
        super().attach(*args, **kwargs)
        if self._executor_name and isinstance(executor, CompoundExecutor):
",3
"            if self._executor_name in executor:
                self._exec = executor[self._executor_name]
",3
"__license__ = ""Apache-2.0""

import os
",3
"import uuid
from datetime import datetime
from pathlib import Path
",3
"from ..logging.base import get_logger
from ..logging.profile import TimeContext
",3
"
# some variables may be self-referred and they must be resolved at here
_ref_desolve_map = SimpleNamespace()
_ref_desolve_map.__dict__['metas'] = SimpleNamespace()
_ref_desolve_map.__dict__['metas'].__dict__['replica_id'] = 0
",3
"_ref_desolve_map.__dict__['metas'].__dict__['separated_workspace'] = False


",3
"
    def __call__(cls, *args, **kwargs):
        # do _preload_package
        getattr(cls, 'pre_init', lambda *x: None)()

",3
"        m = kwargs.pop('metas') if 'metas' in kwargs else {}
",3
"
        # set attribute with priority
        # metas in YAML > class attribute > default_jina_config
",3
"
    @staticmethod
",3
"            # print('reg class: %s' % cls.__name__)
            cls.__init__ = store_init_kwargs(cls.__init__)
            # if 'JINA_PROFILING' in os.environ:
            #     wrap_func(prof_funcs, profiling)
",3
"            wrap_func(update_funcs, as_update_method)

",3
"
class BaseExecutor(metaclass=ExecutorType):
",3
"                pass

    is equal to
",3
"        with:
            awesomeness: 5

",3
"        self._last_snapshot_ts = datetime.now()
        self._drivers = {}  # type: Dict[str, List['BaseDriver']]
        self._attached_pea = None

    def _post_init_wrapper(self, _metas: Dict = None, _requests: Dict = None, fill_in_metas: bool = True):
",3
"                    _metas = get_default_metas()
",3
"                for r in req_type:
                    if r not in self._drivers:
                        self._drivers[r] = list()
                    if self._drivers[r] != drivers:
",3
"                        self._drivers[r].extend(drivers)

    def _fill_metas(self, _metas):
        unresolved_attr = False
        # set self values filtered by those non-exist, and non-expandable
",3
"                    setattr(self, k, v)
        if not getattr(self, 'name', None):
            _id = str(uuid.uuid4()).split('-')[0]
",3
"                self.logger.warning(
",3
"            _tmp = vars(self)
",3
"                    else:
                        setattr(self, k, v)
",3
"
",3
"    def post_init(self):
        """"""
        Initialize class attributes/members that can/should not be (de)serialized in standard way.

",3
"        work_dir = self.replica_workspace if self.separated_workspace else self.workspace  # type: str
        return work_dir
",3
"        d = dict(self.__dict__)
        del d['logger']
        for k in self._post_init_vars:
",3
"
    def train(self, *args, **kwargs):
",3
"    def touch(self):
        """"""Touch the executor and change ``is_updated`` to ``True`` so that one can call :func:`save`. """"""
        self.is_updated = True

    def save(self, filename: str = None) -> bool:
",3
"        Serialize the object to a yaml file

        :param filename: file path of the yaml file, if not given then :attr:`config_abspath` is used
",3
"    def load_config(cls: Type[AnyExecutor], filename: Union[str, TextIO], separated_workspace: bool = False,
                    replica_id: int = 0) -> AnyExecutor:
        """"""Build an executor from a YAML file.

        :param filename: the file path of the YAML file or a ``TextIO`` stream to be loaded from
",3
"                tmp['metas']['separated_workspace'] = separated_workspace
                tmp['metas']['replica_id'] = replica_id

            else:
                raise EmptyExecutorYAML('%s is empty? nothing to read from there' % filename)
",3
"        """"""
        pass

    def __enter__(self):
        return self
",3
"        dump_path = cls._get_dump_path_from_config(data.get('metas', {}))
        load_from_dump = False
        if dump_path:
            obj = cls.load(dump_path)
",3
"            cls.init_from_yaml = True

            if cls.store_args_kwargs:
                p = data.get('with', {})  # type: Dict[str, Any]
                a = p.pop('args') if 'args' in p else ()
",3
"                # tmp_p = {kk: expand_env_var(vv) for kk, vv in data.get('with', {}).items()}
                obj = cls(**data.get('with', {}), metas=data.get('metas', {}), requests=data.get('requests', {}))

",3
"            obj.logger.success(f'successfully built {cls.__name__} from a yaml config')
",3
"        if 'name' in meta_config:
",3
"                    raise BadWorkspace('separated_workspace=True but replica_id is unset or set to a bad value')
",3
"        a = {k: v for k, v in data._init_kwargs_dict.items() if k not in _defaults}
",3
"        for v in self._drivers.values():
            for d in v:
                d.attach(executor=self, *args, **kwargs)

",3
"                else:
                    raise UnattachedDriver(d)
        else:
",3
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"    package_data={
        'paddlehub/serving/templates': [
            'paddlehub/serving/templates/serving_config.json',
            'paddlehub/serving/templates/main.html'
        ]
",4
"        'paddlehub/serving/templates/main.html'
    ])],
    include_data_files=True,
    # PyPI package information.
",4
"    ],
    license='Apache 2.0',
    keywords=('paddlehub paddlepaddle fine-tune transfer-learning'),
    entry_points={'console_scripts': ['hub=paddlehub.commands.hub:main']})
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"import six

os.environ[""FLAGS_eager_delete_tensor_gb""] = ""0.0""

",4
"from . import network

",4
"from .common.dir import USER_HOME
from .common.dir import HUB_HOME
from .common.dir import MODULE_HOME
from .common.dir import CACHE_HOME
",4
"from .common.hub_server import server_check
from .common.downloader import download, ResourceNotFoundError, ServerConnectionError
",4
"
",4
"from .finetune.task import DetectionTask
from .finetune.task import TextClassifierTask
from .finetune.task import ImageClassifierTask
",4
"_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode('latin1'))
",4
"            extension_scope=None,
            options=None),
        _descriptor.FieldDescriptor(
",4
"            type=1,
            cpp_type=5,
            label=1,
",4
"            containing_type=None,
            is_extension=False,
            extension_scope=None,
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"from __future__ import division
from __future__ import print_function

",4
"import math
",4
"from paddlehub.common.logger import logger
from paddlehub.finetune.regularizer import L2SPDecayRegularizer
import paddle.fluid.layers.learning_rate_scheduler as lr_scheduler
from paddle.fluid.layers import control_flow

",4
"    for op in global_block.ops[::-1]:
        for input_arg in op.input_arg_names:
            var = global_block.var(input_arg)
            if isinstance(
                    var, fluid.framework.Parameter
",4
"
    return pretrained_parameters
",4
"        depth = op_depth_dict.get(parent_op, 1)
",4
"
def get_opDepth_min(ops, op_depth_dict):
    min_depth = max(op_depth_dict.values())
",4
"    for op in ops:
",4
"
        for output_arg in op.output_arg_names:
            if output_arg not in var_op_dict.keys():
                var_op_dict[output_arg] = {""output_ops"": [], ""input_ops"": []}
",4
"            var_op_dict[output_arg][""input_ops""].append(op)

    op_depth_dict = {}
    for op in global_block.ops:
",4
"                if parent_op not in parent_ops:
                    parent_ops.append(parent_op)
        if not parent_ops:
            op_depth_dict[op] = 1
        else:
",4
"    depth_list = sorted(depth_params_dict.keys())
    len_depth_list = len(depth_list)
    for index, depth in enumerate(depth_list):
",4
"                    if prefix == prefix_next_depth:
                        updated_depth_params_dict[depth].append(
",4
"

def set_gradual_unfreeze(depth_params_dict, unfreeze_depths):
    for depth in unfreeze_depths:
        for index, param in enumerate(depth_params_dict[depth]):
",4
"        for index, param in enumerate(depth_params_dict[depth]):
            depth_params_dict[depth][index].stop_gradient = True
",4
"        self.learning_rate = learning_rate
",4
"    def execute(self, loss, data_reader, config, dev_count):
        if self.optimizer is not None:
            self.optimizer.minimize(loss)
        else:
            raise ValueError(""DefaultStrategy's optimizer is None"")
",4
"                 clip=None):
        super(CombinedStrategy, self).__init__(
            optimizer_name=optimizer_name, learning_rate=learning_rate)

",4
"        # init set
",4
"        self.scheduler = {
            ""warmup"": 0.0,
            ""linear_decay"": {
                ""start_point"": 1.0,
                ""end_learning_rate"": 0.0,
",4
"                ""factor"": 2.6
            },
",4
"        }

        self.regularization = {
",4
"            ""L2"": 0.0,
            ""L2SP"": 0.0,
            ""weight_decay"": 0.0,
        }

",4
"            self.check_assign(self.scheduler, name, scheduler[name])
",4
"        if self.scheduler[""gradual_unfreeze""][
                ""params_layer""] and self.scheduler[""gradual_unfreeze""][""blocks""]:
            logger.warning(
                ""Both params_layer and blocks have been set in gradual_unfreeze, only params_layer will take effect""
            )
",4
"            if isinstance(dictionary[key], dict):
                raise ValueError(
                    ""The type of parameter %s should be a dict with keys: %s"" %
                    (key, dictionary[key].keys()))
",4
"                            fluid.layers.assign(decayed_lr, scheduled_lr)
                    if self.scheduler[""linear_decay""][""start_point""] < 1:
                        linear_decay_start = int(
",4
"                                power=1.0,
                                cycle=False)
                            fluid.layers.assign(decayed_lr, scheduled_lr)

        # slanted_triangle
",4
"            ratio = self.scheduler[""slanted_triangle""][""ratio""]
            global_step = lr_scheduler._decay_step_counter()
",4
"        if self.regularization[""L2""]:
            for param in self.main_program.global_block().all_parameters():
                param.regularizer = fluid.regularizer.L2Decay(
                    regularization_coeff=self.regularization[""L2""])
",4
"                with param.block.program._optimized_guard(
                    [param, grad]), fluid.framework.name_scope(""weight_decay""):
                    updated_param = param - param_list[
",4
"        if self.scheduler[""discriminative""][""blocks""] > 0 or self.scheduler[
                ""gradual_unfreeze""][""blocks""] > 0:
            self.depth_params_dict = get_depth_parameter(self.main_program)
",4
"                    if param.name in self.scheduler[""gradual_unfreeze""][
                            ""params_layer""]:
",4
"                ""params_layer""] else """"
        strategy_name += ""gradual unfreeze, "" if self.scheduler[
            ""gradual_unfreeze""][""blocks""] or self.scheduler[""gradual_unfreeze""][
                ""params_layer""] else """"
",4
"    def __init__(self,
                 learning_rate=1e-4,
",4
"            raise ValueError(""lr_scheduler {} is not setup ""
                             ""correctly"".format(lr_scheduler))
",4
"        scheduler = {}
        regularization = {""L2SP"": regularization_coeff}
        clip = {}
        super(L2SPFinetuneStrategy, self).__init__(
",4
"                ""ratio"": ratio
            },
            ""gradual_unfreeze"": {
",4
"                ""blocks"": frz_blocks,
                ""params_layer"": frz_params_layer
            },
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"
",4
"class L2SPDecayRegularizer(fluid.regularizer.WeightDecayRegularizer):
",4
"        super(L2SPDecayRegularizer, self).__init__()
        self._regularization_coeff = regularization_coeff
",4
"        self.save_dir = os.path.join(hub.CACHE_HOME, ""l2sp"")

",4
"            inputs={},
            outputs={'Out': [startpoint]},
            attrs={'file_path': file_path})

        # Append Op to calculate decay
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
",4
"                    ""global_step={}, best_score={:.5f}"".format(
                        ckpt.current_epoch, ckpt.global_step, best_score))

        return True, ckpt.current_epoch, ckpt.global_step, best_score

",4
"                    exe,
                    main_program=fluid.default_main_program()):
",4
"
    ckpt_meta_path = os.path.join(checkpoint_dir, CKPT_FILE_NAME)
    ckpt = checkpoint_pb2.CheckPoint()

    model_saved_dir = os.path.join(checkpoint_dir, ""step_%d"" % global_step)
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"    """""" This class specifies the configurations for PaddleHub to finetune """"""

    def __init__(self,
                 log_interval=10,
",4
"                 eval_interval=100,
                 use_pyreader=True,
                 use_data_parallel=True,
                 save_ckpt_interval=None,
",4
"        self._batch_size = batch_size
        self._use_pyreader = use_pyreader
        self._use_data_parallel = use_data_parallel
        if strategy is None:
",4
"            self._strategy = DefaultStrategy()
        else:
            self._strategy = strategy
",4
"            self._checkpoint_dir = ""ckpt_"" + time_str
        else:
            self._checkpoint_dir = checkpoint_dir
",4
"
",4
"    @property
    def save_ckpt_interval(self):
        return self._save_ckpt_interval

    @property
",4
"    def use_cuda(self):
        return self._use_cuda

",4
"        return self._num_epoch

    @property
",4
"        return self._strategy

    @property
    def enable_memory_optim(self):
",4
"        return self._enable_memory_optim

    @property
    def use_pyreader(self):
",4
"
    @property
    def use_data_parallel(self):
        return self._use_data_parallel

",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"

",4
"            tag_type = tag // 2
            tag_pos = tag % 2

",4
"                    chunks.append(cur_chunk)
                    cur_chunk = None
                continue

",4
"                    cur_chunk[""en""] = index + 1
                else:
                    chunks.append(cur_chunk)
                    cur_chunk = {""st"": index, ""en"": index + 1, ""type"": tag_type}
",4
"            seq_st = base_index + i * max_len + 1
            seq_en = seq_st + (lens[i] - 2)
",4
"            num_label += len(label_chunks)

            infer_index = 0
",4
"        recall = num_correct * 1.0 / num_label

",4
"    f1 = (2 * p * r) / (p + r) if p + r else 0
",4
"    fp = np.sum((labels == 0) & (preds == 1))
",4
"        eg: [A,B1,1]=0.5, [A,B2,0]=0.8, [A,B3,0]=0.3(Probability of 1)
           If k=2, the prediction for the example A will be considered correct as 0.5 is the top2 Probability
",4
"        curr = sorted(curr, key=lambda x: x[0], reverse=True)
        if curr[k - 1][0] <= pos_score:
            return 1
",4
"# -*- coding: utf-8 -*-
'''
Evaluation script for CMRC 2018
version: v5 - special
",4
"
_PUNKT_URL = ""https://paddlehub.bj.bcebos.com/paddlehub-thirdparty/punkt.tar.gz""


# split Chinese with English
",4
"        default_downloader.download_file_and_uncompress(
            url=_PUNKT_URL, save_path=tokenizers_path, print_progress=True)
",4
"
    in_str = str(in_str).lower().strip()
    segs_out = []
    temp_str = """"
",4
"
# remove punctuation
",4
"    sp_char = [
        '-', ':', '_', '*', '^', '/', '\\', '~', '`', '+', '=', 'ï¼', 'ã', 'ï¼',
",4
"            out_segs.append(char)
    return ''.join(out_segs)
",4
"def evaluate(ground_truth_file, prediction_file):
",4
"    for instance in ground_truth_file:
        # context_id   = instance['context_id'].strip()
        # context_text = instance['context_text'].strip()
        for para in instance[""paragraphs""]:
",4
"        lcs, lcs_len = find_lcs(ans_segs, prediction_segs)
        if lcs_len == 0:
            f1_scores.append(0)
            continue
",4
"This file is expected to map question ID's to the model's predicted probability
",4
"import numpy as np
import os
",4
"        return re.sub(regex, ' ', text)
",4
"
",4
"def compute_exact(a_gold, a_pred):
    return int(normalize_answer(a_gold) == normalize_answer(a_pred))
",4
"

def compute_f1(a_gold, a_pred):
    gold_toks = get_tokens(a_gold)
",4
"    exact_scores = {}
",4
"

def make_eval_dict(exact_scores, f1_scores, qid_list=None):
    if not qid_list:
",4
"def merge_eval(main_eval, new_eval, prefix):
    for k in new_eval:
        main_eval['%s_%s' % (prefix, k)] = new_eval[k]


",4
"def find_all_best_thresh(main_eval, preds, exact_raw, f1_raw, na_probs,
",4
"            else:
                diff = 0
        cur_score += diff
",4
"    qid_to_has_ans = make_qid_to_has_ans(dataset)
    has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]
    no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]
",4
"from __future__ import print_function
from collections import Counter
",4
"

def normalize_answer(s):
    """"""Lower text and remove punctuation, articles and extra whitespace.""""""
",4
"
",4
"    def remove_articles(text):
",4
"        return re.sub(r'\b(a|an|the)\b', ' ', text)
",4
"
",4
"        exclude = set(string.punctuation)
",4
"
    return white_space_fix(remove_articles(remove_punc(lower(s))))


",4
"    num_same = sum(common.values())
    if num_same == 0:
        return 0
",4
"                prediction = predictions[qa['id']]
                exact_match += metric_max_over_ground_truths(
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"                 num_classes,
                 feed_list,
",4
"                 data_reader,
                 startup_program=None,
                 config=None,
                 metrics_choices=""default"",
                 add_crf=False):
",4
"        if metrics_choices == ""default"":
",4
"            feed_list=feed_list,
            startup_program=startup_program,
            config=config,
            metrics_choices=metrics_choices)
        self.feature = feature
",4
"                bias_attr=fluid.ParamAttr(
",4
"
            logits = self.logits
            logits = fluid.layers.flatten(logits, axis=2)
            logits = fluid.layers.softmax(logits)
            self.num_labels = logits.shape[1]
",4
"
",4
"            chunk_evaluator = fluid.metrics.ChunkEvaluator()
            chunk_evaluator.reset()
            return [precision, recall, f1_score]
        else:
            self.ret_labels = fluid.layers.reshape(
",4
"        run_step = run_time_used = run_examples = 0
        precision_sum = recall_sum = f1_score_sum = 0
",4
"                precision_sum += np.mean(
",4
"                np_lens = run_state.run_results[2]
                label_num, infer_num, correct_num = chunk_eval(
",4
"        avg_loss = loss_sum / run_examples
",4
"        else:
            precision, recall, f1 = calculate_f1(total_label, total_infer,
                                                 total_correct)
",4
"            elif metric == ""f1"":
                scores[""f1""] = f1
",4
"            val: key
            for key, val in self._base_data_reader.label_map.items()
        }
        results = []
        for batch_states in run_states:
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"from __future__ import print_function
",4
"from paddlehub.finetune.checkpoint import load_checkpoint, save_checkpoint
from paddlehub.finetune.config import RunConfig
",4
"        self.run_examples = 0
        self.run_results = [0] * length
        self.run_time_used = 0
",4
"
    def __add__(self, other):
        self.run_step += other.run_step
        self.run_examples += other.run_examples
        for index in range(len(self.run_results)):
",4
"        self.run_time_used = time.time() - self.run_time_begin
        self.run_speed = self.run_step / self.run_time_used
        return self

",4
"class RunEnv(object):
    """"""
",4
"    RunEnv saves the running environment of the train/dev/predict phase, including program, reader, metrics and so on.
    """"""
",4
"        self.reader = None
        self.loss = None
",4
"            ""build_env_end_event"": 1,
            ""finetune_start_event"": 1,
            ""finetune_end_event"": 2,
            ""predict_start_event"": 1,
",4
"            ""predict_end_event"": 2,
            ""eval_start_event"": 1,
            ""eval_end_event"": 2,
            ""log_interval_event"": 2,
            ""save_ckpt_interval_event"": 1,
",4
"            ""eval_interval_event"": 1,
",4
"        if not isinstance(name, str) or name.strip() == """":
            raise TypeError(""The hook name must be a non-empty string"")
",4
"            args_num = len(get_args(func).args)
            if args_num != self._hook_params_num[hook_type]:
                raise ValueError(
                    ""The number of parameters to the hook hook_type:%s should be %i""
                    % (hook_type, self._hook_params_num[hook_type]))
",4
"        """"""
        if self.exist(hook_type, name):
",4
"            del self._registered_hooks[hook_type][name]
",4
"        Args:
            hook_type (str): the spectific event name
",4
"            self._registered_hooks[hook_type][name] = func
",4
"        else:
            raise ValueError(
                ""No hook_type: %s exists or name: %s does not exist in hook_type: %s""
                % (hook_type, name, hook_type))

",4
"
",4
"    def __repr__(self):
        return self.info(show_default=False)

",4
"
    Args:
",4
"                 config=None,
                 metrics_choices=""default""):
        # base item
        self._base_data_reader = data_reader
        self._base_feed_list = feed_list
",4
"            metrics_choices = [""acc""]
        elif metrics_choices == None:
            metrics_choices = []
",4
"                logger.warning(""Batch size automatically adjusted to {}"".format(
                    self.device_count))
                self.config._batch_size = self.device_count
",4
"        # run environment
        self._phases = []
        self._envs = {}
        self._predict_data = None
",4
"            self._hooks.add(hook_type, ""default"",
                            eval(""self._default_%s"" % hook_type))
            setattr(BaseTask, ""_%s"" % hook_type,
                    self.create_event_function(hook_type))
",4
"
",4
"        # accelerate predict
        self.is_best_model_loaded = False
        self._predictor = None

        # set default phase
",4
"            if not self.load_checkpoint():
                self.exe.run(self._base_startup_program)
",4
"                self.env.outputs = self._build_net()
                if self.is_train_phase or self.is_test_phase:
                    self.env.labels = self._add_label()
                    self.env.loss = self._add_loss()
                    self.env.metrics = self._add_metrics()
",4
"                        self.device_count)

        if self.is_train_phase:
            loss_name = self.env.loss.name
",4
"        if not self.config.use_data_parallel:
            self.env.main_program_compiled = None
",4
"        else:
            self.env.main_program_compiled = fluid.CompiledProgram(
                self.env.main_program).with_data_parallel(
                    loss_name=loss_name,
                    share_vars_from=share_vars_from,
",4
"                    places=self.places)
",4
"        if self.config.use_cuda:
            _places = fluid.framework.cuda_places()
        else:
            _places = fluid.framework.cpu_places()
",4
"
",4
"    def return_numpy(self):
        return True

    @property
",4
"
    @property
    def is_predict_phase(self):
        return self.phase in [""predict"", ""inference""]
",4
"
    @property
    def main_program(self):
        if not self.env.is_inititalized:
",4
"    def reader(self):
        if self.is_predict_phase:
",4
"
",4
"    def unique_name_generator(self):
        return self.env.UNG

",4
"        if self.is_train_phase or self.is_test_phase:
            feed_list += [label.name for label in self.labels]
",4
"        return [output.name for output in self.outputs]

    @property
    def fetch_var_list(self):
        vars = self.main_program.global_block().vars
",4
"        return [vars[varname] for varname in self.fetch_list]

    @property
    def vdl_writer(self):
        """"""
",4
"        get vdl_writer for visualization.
        """"""
        if not os.path.exists(self.config.checkpoint_dir):
            mkdir(self.config.checkpoint_dir)
        tb_log_dir = os.path.join(self.config.checkpoint_dir, ""visualization"")
",4
"        """"""

",4
"        Args:
            show_default (bool): show the information of Paddlehub default hooks or not, default False

",4
"
        Args:
            hook_type (str): the spectific event name
",4
"        """"""
        self._hooks.delete(hook_type, name)
        logger.info(""Delete hook %s:%s successfully"" % (hook_type, name))
",4
"         Args:
             hook_type (str): the spectific event name
             name (str): the handler function name
",4
"
    def _default_finetune_start_event(self):
        logger.info(""PaddleHub finetune start"")

    def _default_finetune_end_event(self, run_states):
",4
"        logger.info(""PaddleHub finetune finished."")

    def _default_predict_start_event(self):
        logger.info(""PaddleHub predict start"")

",4
"                    step=self._envs['train'].current_step)

            log_scores += ""%s=%.5f "" % (metric, eval_scores[metric])
",4
"        logger.eval(
            ""[%s dataset evaluation result] loss=%.5f %s[step/sec: %.2f]"" %
            (self.phase, eval_loss, log_scores, run_speed))

",4
"        for metric in scores:
            self.vdl_writer.add_scalar(
                tag=""{}_{}"".format(metric, self.phase),
                value=scores[metric],
                step=self._envs['train'].current_step)
",4
"    def _add_loss(self):
        raise NotImplementedError

    def _add_label(self):
        raise NotImplementedError
",4
"        raise NotImplementedError

    # NOTE: current saved checkpoint machanism is not completed,
",4
"        fluid.io.save_persistables(
            self.exe, dirname=model_saved_dir, main_program=self.main_program)
        save_checkpoint(
",4
"            global_step=self.current_step,
            best_score=self.best_score,
",4
"            main_program=self.main_program)

    def load_checkpoint(self):
",4
"            self.config.checkpoint_dir,
            self.exe,
            main_program=self.main_program)
",4
"    def save_inference_model(self,
                             dirname,
                             model_filename=None,
",4
"                dirname=dirname,
                executor=self.exe,
",4
"                main_program=self.main_program,
                model_filename=model_filename,
                params_filename=params_filename)

    def finetune_and_eval(self):
",4
"        train and finetune the module parameters.

        Args:
            do_eval (bool): do eval during train phase or not

",4
"            RunState: the running result of train phase
        """"""

",4
"                    run_states = self._run(do_eval=do_eval)
",4
"                    self.env.current_epoch += 1

",4
"                if self._base_data_reader.get_dev_examples() != []:
",4
"            if load_best_model:
                self.init_if_load_best_model()
            else:
                self.init_if_necessary()
            self._eval_start_event()
",4
"            run_states = self._run()
            self._eval_end_event(run_states)
            return run_states
",4
"        """"""
        with tmp_dir() as _dir:
            self.save_inference_model(dirname=_dir)
",4
"                predictor_config.switch_ir_optim(True)
            else:
                predictor_config.disable_gpu()
            predictor_config.enable_memory_optim()
",4
"            RunState: the running result of predict phase
",4
"            step_run_state.run_examples += num_batch_examples
",4
"            period_run_states += [step_run_state]
",4
"
    def predict(self,
                data,
",4
"            self._predict_start_event()
",4
"                self.init_if_necessary()
            if not self.accelerate_mode:
                run_states = self._run()
            else:
",4
"                if not self._predictor:
                    self._predictor = self._create_predictor()
                run_states = self._run_with_predictor()
",4
"            self._predict_data = None
            if return_result:
                return self._postprocessing(run_states)
        return run_states
",4
"        Args:
            run_states (RunState): the raw run result to be processed
",4
"            batch_result = batch_state.run_results[0]
            results += [result[0] for result in batch_result]
        return results

",4
"        Returns:
            RunState: the running result of specific phase
        """"""
",4
"                    drop_last=True)

",4
"            for run_step, batch in enumerate(data_reader(), start=1):
                step_run_state = RunState(len(self.fetch_list))
",4
"
                for index, result in enumerate(fetch_result):
                    step_run_state.run_results[index] = result
",4
"                        global_run_states += period_run_states
                        period_run_states = []

                    if self.config.save_ckpt_interval and self.current_step % self.config.save_ckpt_interval == 0:
",4
"#
",4
"#
",4
"                 feed_list,
                 data_reader,
",4
"                 startup_program=None,
                 config=None,
                 hidden_units=None,
                 metrics_choices=""default""):
",4
"        super(ClassifierTask, self).__init__(
            data_reader=data_reader,
",4
"        self.feature = feature
        self.num_classes = num_classes
        self.hidden_units = hidden_units
",4
"
    def _build_net(self):
        cls_feats = self.feature
        if self.hidden_units is not None:
",4
"            for n_hidden in self.hidden_units:
                cls_feats = fluid.layers.fc(
                    input=cls_feats, size=n_hidden, act=""relu"")
",4
"
        logits = fluid.layers.fc(
",4
"                initializer=fluid.initializer.TruncatedNormal(scale=0.02)),
            bias_attr=fluid.ParamAttr(
",4
"            all_labels = np.hstack((all_labels, np_labels.reshape([-1])))
            all_infers = np.hstack((all_infers, np_infers.reshape([-1])))

        run_time_used = time.time() - run_states[0].run_time_begin
        avg_loss = loss_sum / run_examples
",4
"                avg_acc = acc_sum / run_examples
                scores[""acc""] = avg_acc
            elif metric == ""f1"":
                f1 = calculate_f1_np(all_infers, all_labels)
",4
"        return results


",4
"            exit(1)
        elif feature and token_feature:
            logger.error(
                'Both token_feature and feature are setted. One should be setted, the other should be None.'
",4
"                token_feature.shape
",4
"            else:
                cls_feats = net_func(unpad_feature)
            logger.info(
                ""%s has been added in the TextClassifierTask!"" % self.network)
",4
"        else:
            # predict phase
",4
"                 metrics_choices=""default""):
        if metrics_choices == ""default"":
            metrics_choices = [""auc""]

",4
"            dropout_prob=0.1,
            dropout_implementation=""upscale_in_train"")

        if self.hidden_units is not None:
            for n_hidden in self.hidden_units:
",4
"
        probs = []
        for i in range(self.num_classes):
            probs.append(
",4
"            name=""label"", shape=[self.num_classes], dtype='int64')
",4
"            eval_list.append(current_auc)
        return eval_list

",4
"
",4
"        avg_loss = loss_sum / (run_examples * self.num_classes)
        run_speed = run_step / run_time_used

        # The first key will be used as main metrics to update the best model
",4
"                #      and their mean value will also be reported.
                for index, auc in enumerate(auc_list):
                    scores[""auc_"" + self.class_name[index]] = auc_list[index][0]
",4
"
    def _postprocessing(self, run_states):
        results = []
",4
"                for category_id in range(
",4
"                results.append(sample_result)
        return results
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"from ...common import detection_config as dconf
",4
"from paddlehub.common.paddle_helper import clone_program
",4
"        'lod_level': 1
    },
    {
        'name': 'gt_label',
        'shape': [1],
",4
"        'dtype': 'int32',
        'lod_level': 1
    },
    {
",4
"        'name': 'is_crowd',
        'shape': [1],
        'dtype': 'int32',
        'lod_level': 1
",4
"    },
    {
        'name': 'is_difficult',
        'shape': [1],
",4
"                 predict_feed_list=None,
",4
"        else:
            self._predict_base_main_program = None
        self._predict_base_feed_list = predict_feed_list
",4
"
",4
"            l = fluid.layers.data(
                name=feed_var_map[key]['name'],
                shape=feed_var_map[key]['shape'],
                dtype=feed_var_map[key]['dtype'],
",4
"            labels.append(l)
        return labels

",4
"        feature_list = self.feature
        image = self.base_feed_var_list[0]

        # fix input size according to its module
        mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(
",4
"            max_sizes=[51.0, 133.0, 215.0, 296.0, 378.0, 460.0,
                       542.0],  # [[], 150.0, 195.0, 240.0, 285.0, 300.0],
            steps=[8, 16, 32, 64, 128, 256, 512],
            min_ratio=15,
",4
"        return self._add_label_by_fields(idx_list)
",4
"        if self.is_train_phase:
            gt_box = self.labels[0]
            gt_label = self.labels[1]
        else:  # xTodo: update here when using new module
            gt_box = self.labels[1]
",4
"        mbox_locs, mbox_confs, box, box_var = self.env.mid_vars
",4
"            gt_box=gt_box,
            gt_label=gt_label,
            prior_box=box,
",4
"        # Rename following layers for: ValueError: Variable cls_score_w has been created before.
",4
"                learning_rate=2.,
                regularizer=L2Decay(0.)))
        bbox_pred = fluid.layers.fc(
            input=head_feat,
            size=4 * self.num_classes,
",4
"
        if self.is_train_phase:
            rpn_cls_loss, rpn_reg_loss, outs = self.feature[1:]
            labels_int32 = outs[1]
",4
"            loss_bbox = fluid.layers.reduce_mean(loss_bbox)
            total_loss = fluid.layers.sum(
                [loss_bbox, loss_cls, rpn_cls_loss, rpn_reg_loss])
",4
"            im_shape = self.base_feed_var_list[2]
            im_scale = fluid.layers.slice(im_info, [1], starts=[2], ends=[3])
",4
"            cliped_box = fluid.layers.box_clip(
",4
"                scores=cls_prob,
                score_threshold=.05,
                nms_top_k=-1,
                keep_top_k=100,
                nms_threshold=.5,
",4
"                self.env.labels = self._rcnn_add_label()
",4
"            idx_list = [
                2,
            ]  # 'im_id'
",4
"            # im_shape, im_id, bbox
            return [
                self.feed_list[2], self.labels[0].name, self.outputs[0].name,
                self.loss.name
",4
"            self.mask_anchors.append([])
",4
"            return outputs
",4
"        for i, output in enumerate(outputs):
            box, score = fluid.layers.yolo_box(
                x=output,
                img_size=im_size,
                anchors=self.mask_anchors[i],
",4
"            bboxes=yolo_boxes,
",4
"            scores=yolo_scores,
            score_threshold=.01,
            nms_top_k=1000,
            keep_top_k=100,
            nms_threshold=0.45,
",4
"            normalized=False,
            nms_eta=1.0,
",4
"        else:  # predict
            idx_list = [2]
        return self._add_label_by_fields(idx_list)

    def _yolo_add_loss(self):
",4
"                    gt_score=gt_score,
                    anchors=self.anchors,
",4
"                    name=""yolo_loss"" + str(i))
                losses.append(fluid.layers.reduce_mean(loss))
                downsample //= 2

            loss = sum(losses)
",4
"                shape=[1], value=-1, dtype='float32')
        return loss
",4
"            ]

        # im_shape, im_id, bbox
        if for_export:
            return [self.outputs[0].name]
",4
"    def _build_net(self):
        if self.model_type == 'ssd':
            outputs = self._ssd_build_net()
        elif self.model_type == 'rcnn':
",4
"        return outputs

    def _add_label(self):
",4
"        return labels

    def _add_loss(self):
",4
"        # ensure fetch loss at last element in train/test phase
        # ensure fetch 'im_shape', 'im_id', 'bbox' at first three elements in test phase
        return self._fetch_list(False)

",4
"
    @property
    def labels(self):
",4
"                             dirname,
                             model_filename=None,
                             params_filename=None):
        with self.phase_guard(""predict""):
            fluid.io.save_inference_model(
",4
"            run_step += run_state.run_step
            loss_sum += np.mean(np.array(
",4
"                run_state.run_results[-1])) * run_state.run_examples

",4
"        eval_feed = Feed()
        eval_feed.with_background = dconf.conf[
",4
"        for metric in self.metrics_choices:
            if metric == ""ap"":
                box_ap_stats = eval_results(
                    results, eval_feed, 'COCO', self.num_classes, None,
",4
"                    is_bbox_normalized, self.config.checkpoint_dir)
                print(""box_ap_stats"", box_ap_stats)
",4
"# You may obtain a copy of the License at
#
",4
"from __future__ import division
from __future__ import print_function

import time
",4
"import json
",4
"from paddlehub.finetune.evaluator import cmrc2018_evaluate

",4
"
def _get_best_indexes(logits, n_best_size):
    """"""Get the n-best logits from a list.""""""
    index_and_score = sorted(
        enumerate(logits), key=lambda x: x[1], reverse=True)
",4
"
    best_indexes = []
    for i in range(len(index_and_score)):
",4
"        if max_score is None or score > max_score:
            max_score = score

    exp_scores = []
    total_sum = 0.0
",4
"    # However, `orig_text` may contain extra characters that we don't want in
",4
"    #
    # We don't want to return `orig_text` because it contains the extra ""'s"".
",4
"    #
    # We don't want to return `pred_text` because it's already been normalized
    # (the SQuAD eval script also does punctuation stripping/lower casing but
",4
"    # Therefore, we have to apply a semi-complicated alignment heruistic between
    # `pred_text` and `orig_text` to get a character-to-charcter alignment. This
    # can fail in certain cases in which case we just return `orig_text`.

    def _strip_spaces(text):
",4
"        ns_chars = []
        ns_to_s_map = collections.OrderedDict()
        for (i, c) in enumerate(text):
",4
"
    # We first tokenize `orig_text`, strip whitespace from the result
    # and `pred_text`, and check if they are the same length. If they are
    # NOT the same length, the heuristic has failed. If they are the same
    # length, we assume the characters are one-to-one aligned.
",4
"    if orig_start_position is None:
",4
"        if ns_end_position in orig_ns_to_s_map:
",4
"    example_index_to_features = collections.defaultdict(list)
    for feature in all_features:
        example_index_to_features[feature.example_index].append(feature)
",4
"        # keep track of the minimum score of null start+end of position 0
        score_null = 1000000  # large and positive
        min_null_feature_index = 0  # the paragraph slice with min mull score
        null_start_logit = 0  # the start logit at the slice with min null score
",4
"
",4
"                    if start_index >= len(feature.tokens):
                        continue
                    if end_index >= len(feature.tokens):
",4
"                        continue
",4
"                    if start_index not in feature.token_to_orig_map:
                        continue
",4
"                    feature_index=min_null_feature_index,
",4
"                    start_logit=null_start_logit,
                    end_logit=null_end_logit))
        prelim_predictions = sorted(
",4
"                    orig_text = "" "".join(orig_tokens)
                else:
                    orig_text = """".join(orig_tokens)

",4
"                final_text = get_final_text(tok_text, orig_text, do_lower_case,
                                            is_english)
                if final_text in seen_predictions:
                    continue

",4
"                    text=final_text,
",4
"        # In very rare edge cases we could have no valid predictions. So we
        # just create a nonce prediction in this case to avoid failure.
        if not nbest:
            nbest.append(
",4
"            # predict """" iff the null score - the score of best non-null > threshold
            score_diff = score_null
            if best_non_null_entry:
",4
"                 metrics_choices=None,
                 sub_task=""squad"",
                 null_score_diff_threshold=0.0,
",4
"                 n_best_size=20,
                 max_answer_length=30):

        main_program = feature.block.program
        super(ReadingComprehensionTask, self).__init__(
",4
"            raise Exception(""No language type of data set is sepecified"")

        self.null_score_diff_threshold = null_score_diff_threshold
        self.n_best_size = n_best_size
        self.max_answer_length = max_answer_length
",4
"        _ = fluid.layers.assign(self.unique_ids)
        logits = fluid.layers.fc(
",4
"                for idx in range(np_unique_ids.shape[0]):
                    unique_id = int(np_unique_ids[idx])
",4
"            if self.phase == 'val' or self.phase == 'dev':
                with io.open(
",4
"                        self.data_reader.dataset.dev_path, 'r',
",4
"            if self.sub_task == ""squad"":
                scores = squad1_evaluate.evaluate(dataset, all_predictions)
",4
"        return scores, avg_loss, run_speed

    def _postprocessing(self, run_states):
",4
"        all_features = self.data_reader.all_features[self.phase]
        all_predictions, all_nbest_json, scores_diff_json = get_predictions(
            all_examples=all_examples,
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"

class RegressionTask(BaseTask):
    def __init__(self,
                 feature,
",4
"        return [logits]

    def _add_label(self):
        return [fluid.layers.data(name=""label"", dtype=""float32"", shape=[1])]
",4
"
    def _add_loss(self):
        cost = fluid.layers.square_error_cost(
            input=self.outputs[0], label=self.labels[0])
",4
"        if self.is_train_phase or self.is_test_phase:
",4
"    def _postprocessing(self, run_states):
",4
"        return results
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"# you may not use this file except in compliance with the License.
",4
"    lstm_h, c = fluid.layers.dynamic_lstm(
        input=fc0, size=hid_dim * 4, is_reverse=False)
    rlstm_h, c = fluid.layers.dynamic_lstm(
",4
"          hid_dim=128,
          channel_size=250,
          emb_dim=1024,
",4
"            conv_features,
            pool_size=(3, 1),
            pool_stride=(2, 1),
",4
"    """"""
    # lstm layer
    fc0 = fluid.layers.fc(input=token_embeddings, size=hid_dim * 4)
    lstm_h, c = fluid.layers.dynamic_lstm(
",4
"    name = ""hub""

",4
"    argv = []
",4
"    for item in sys.argv:
        if six.PY2:
            argv.append(item.decode(sys_stdin_encoding()).decode(""utf8""))
        else:
            argv.append(item)
",4
"    command.execute(argv[1:])


",4
"            argv.append(item)
    command.execute(argv[1:])
",4
"import argparse
import os

from paddlehub.common import utils
",4
"            self.help()
            return False
        extra = {""command"": ""install""}

",4
"                module_package=argv[0], extra=extra)
        elif os.path.exists(argv[0]) and os.path.isdir(argv[0]):
            result, tips, module_dir = default_module_manager.install_module(
",4
"            CacheUpdater(""hub_install"", module_name, module_version).start()
            result, tips, module_dir = default_module_manager.install_module(
",4
"                extra=extra)
",4
"command = InstallCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
",4
"from __future__ import division
from __future__ import print_function

",4
"from paddlehub.commands.base_command import BaseCommand, ENTRY
from paddlehub.common.cml_utils import TablePrinter
from paddlehub.common.hub_server import CacheUpdater
",4
"                )
        for resource_name, resource_type, resource_version, resource_summary in resource_list:
            if resource_type == ""Module"":
",4
"                    resource_name, resource_type, resource_version,
                    resource_summary
                ],
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
",4
"        self.description = """"

    def help(self):
        self.parser.print_help()
",4
"
    def add_arg(self, argument, type=""str"", default=None, help=None):
",4
"    def print_args(self):
        print_arguments(self.args)
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"
",4
"
    def __init__(self, name):
        super(HelpCommand, self).__init__(name)
        self.show_in_help = True
        self.description = ""Show help for commands.""
",4
"        hub_command = BaseCommand.command_dict[""hub""]
        help_text = ""\n""
        help_text += ""Usage:\n""
        help_text += ""%s <command> [options]\n"" % hub_command.name
        help_text += ""\n""
",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
",4
"
command = UninstallCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
    def find_module(self, module_name):
",4
"            self.arg_config_group.add_argument(
                config[""dest""],
                type=config['type'],
",4
"    def add_module_input_arg(self):
        module_type = self.module.type.lower()
        expect_data_format = self.module.processor.data_format(
            self.module.default_signature)
        self.arg_input_group.add_argument(
",4
"                if 'help' in expect_data_format[key]:
                    help_str = expect_data_format[key]['help']
                self.arg_input_group.add_argument(
                    ""--%s"" % key, type=str, default=None, help=help_str)
",4
"
    def get_config(self):
        yaml_config = {}
        if self.args.config:
",4
"        return module_config

",4
"                elif module_type.startswith(""nlp""):
                    input_data[key] = [self.args.input_text]
        else:
            for key in expect_data_format.keys():
",4
"
        module_name = argv[0]
        CacheUpdater(""hub_run"", module_name).start()
        self.parser.prog = '%s %s %s' % (ENTRY, self.name, module_name)
",4
"            self.add_module_input_arg()

",4
"                self.help()
                return False

            results = self.module(
",4
"                sign_name=self.module.default_signature,
",4
"        self.description = ""Download PaddlePaddle pretrained model/module files.""
        self.parser = self.parser = argparse.ArgumentParser(
            description=self.__class__.__doc__,
            prog='%s %s <model_name/module_name>' % (ENTRY, name),
",4
"            usage='%(prog)s [options]',
            add_help=False)
        # yapf: disable
        self.add_arg(""--type"",         str,  ""All"", ""choice: Module/Model/All"")
        self.add_arg('--output_path',  str,  ""."",   ""path to save the model/module"" )
",4
"        self.add_arg('--uncompress',   bool, False,  ""uncompress the download package or not"" )
        # yapf: enable

",4
"            self.args.type = ""Module""
            if search_result == {}:
                search_result = hub.HubServer().get_resource_url(
",4
"            print(tips)
            return True

",4
"            file_md5_value = utils.md5_of_file(file)
            if except_md5_value == file_md5_value:
                print(""MD5 check pass."")
",4
"                need_to_download_file = False
",4
"            result, tips, file = default_downloader.download_file(
",4
"                url=url, save_path=self.args.output_path, print_progress=True)
            if not result:
                print(tips)
                return False
",4
"            if self.args.type == ""Model"":
                os.rename(file, ""./"" + mod_name)
        return True
",4
"        if mod_type == ""module"":
            mod_type = ""Module""
        elif mod_type == ""model"":
            mod_type = ""Model""
",4
"from paddlehub.common.hub_server import CacheUpdater
from paddlehub.serving.model_service.base_model_service import cv_module_info
from paddlehub.serving.model_service.base_model_service import nlp_module_info
import multiprocessing
import time
",4
"
",4
"        def load_config(self):
            pass

        def load(self):
            pass
",4
"else:
    import gunicorn.app.base
",4
"
",4
"    class StandaloneApplication(gunicorn.app.base.BaseApplication):
        def __init__(self, app, options=None):
",4
"                if key in self.cfg.settings and value is not None
",4
"        self.parser.add_argument(""bert_service"", nargs=""?"")
        self.sub_parse = self.parser.add_mutually_exclusive_group(
            required=False)
        self.parser.add_argument(
            ""--use_gpu"", action=""store_true"", default=False)
",4
"        self.parser.add_argument(
            ""--use_multiprocess"", action=""store_true"", default=False)
        self.parser.add_argument(""--modules"", ""-m"", nargs=""+"")
        self.parser.add_argument(""--config"", ""-c"", nargs=""?"")
        self.parser.add_argument(""--port"", ""-p"", nargs=""?"", default=8866)
",4
"            ""--modules_info"", ""-mi"", default={}, type=json.loads)
        self.parser.add_argument(
",4
"            ""--workers"", ""-w"", nargs=""?"", default=number_of_workers())
        self.modules_info = {}

    def dump_pid_file(self):
        pid = os.getpid()
",4
"        if not os.path.exists(filepath):
            print(
",4
"        start_time = info[""start_time""]
        if os.path.exists(filepath):
            os.remove(filepath)
",4
"        for key, value in self.modules_info.items():
            init_args = value[""init_args""]
",4
"        self.modules_info = self.args.config.get(""modules_info"")
        self.preinstall_modules()
        self.dump_pid_file()
",4
"        StandaloneApplication(
            app.create_app(init_flag=False, configs=configs), options).run()
",4
"        print(""PaddleHub Serving has been stopped."")

    def start_app_with_args(self, workers):
        module = self.args.modules
",4
"            options = {""bind"": ""0.0.0.0:%s"" % port, ""workers"": workers}
",4
"                return False
            self.preinstall_modules()
            options = {""bind"": ""0.0.0.0:%s"" % port, ""workers"": workers}
            configs = {""modules_info"": self.module_info}
            StandaloneApplication(
",4
"                    module = item.split(""=="")[0]
                    version = item.split(""=="")[1]
",4
"            if use_multiprocess is False:
                self.start_single_app_with_file()
",4
"                )
                self.start_single_app_with_file()
            else:
                self.start_app_with_file()

",4
"        str += ""2. stop\n""
        str += ""\tStop PaddleHub Serving.\n""
",4
"
command = ServingCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
",4
"from __future__ import print_function
",4
"from paddlehub.commands.base_command import BaseCommand, ENTRY
from paddlehub.common.cml_utils import TablePrinter
from paddlehub.module.manager import default_module_manager
from paddlehub.module.module import Module
from paddlehub.io.parser import yaml_parser
",4
"            placeholders=placeholders,
            title_colors=[""yellow"", None],
            title_aligns=[""^"", ""<""])
",4
"            contents=[""Summary"", model_info['description']],
",4
"            titles=[""ModuleName"", module.name],
            placeholders=placeholders,
",4
"            colors=[""light_red"", None],
            aligns=[""^"", ""<""])
        tp.add_line(
            contents=[""Author"", module.author],
            colors=[""light_red"", None],
",4
"            aligns=[""^"", ""<""])
        tp.add_line(
            contents=[""Location"", module_dir[0]],
",4
"        if not argv:
            print(""ERROR: Please specify a module or a model\n"")
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
",4
"
HubServer()

",4
"            usage='%(prog)s',
            add_help=True)
        self.parser.add_argument(""command"")
        self.parser.add_argument(""option"", nargs=""?"")
        self.parser.add_argument(""value"", nargs=""?"")
",4
"    @staticmethod
    def set_server_url(server_url):
        with open(os.path.join(CONF_HOME, ""config.json""), ""r"") as fp:
            config = json.load(fp)
            re_str = ""^(?:http(s)?:\/\/)?[\w.-]+(?:\.[\w\.-]+)+[\w\-\._~:/?#[\]@!\$&'\*\+,;=.]+$""
",4
"    def set_config(config):
        with open(os.path.join(CONF_HOME, ""config.json""), ""w"") as fp:
",4
"        if level not in [
                ""NOLOG"", ""DEBUG"", ""INFO"", ""WARNING"", ""ERROR"", ""CRITICAL""
        ]:
            print(""Allowed values include: ""
                  ""NOLOG, DEBUG, INFO, WARNING, ERROR, CRITICAL"")
",4
"            return
        with open(os.path.join(CONF_HOME, ""config.json""), ""r"") as fp:
            current_config = json.load(fp)
",4
"        with open(os.path.join(CONF_HOME, ""config.json""), ""w"") as fp:
            current_config[""log_level""] = level
            fp.write(json.dumps(current_config))
            print(""Set success! The current configuration is shown below."")
            print(json.dumps(current_config, indent=4))
",4
"    @staticmethod
    def show_help():
",4
"#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# You may obtain a copy of the License at
#
",4
"        self.description = ""Show PaddleHub's version.""

    def execute(self, argv):
        CacheUpdater(""hub_version"").start()
        print(""hub %s"" % version.hub_version)
",4
"        return True


",4
"command = VersionCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"            subfile = os.path.join(dirname, subfile)
            cnt += file_num_in_dir(subfile)
    return cnt

",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"
class AutoFineTuneCommand(BaseCommand):
",4
"        self.show_in_help = True
        self.name = name
        self.description = ""PaddleHub helps to finetune a task by searching hyperparameters automatically.""
",4
"            ""--param_file"",
            type=str,
            default=None,
            required=True,
            help=
",4
"            ""Hyperparameters to be searched in the yaml format. The number of hyperparameters searched must be greater than 1.""
        )

    def add_autoft_config_arg(self):
",4
"            default=""0"",
            required=True,
            help=""The list of gpu devices to be used"")
        self.arg_config_group.add_argument(
            ""--round"", type=int, default=10, help=""Number of searches"")
",4
"        for key, value in zip(config_list[0::2], config_list[1::2]):
            options_str += ""--"" + key + ""="" + value + "" ""
        return options_str

",4
"        self.arg_finetuned_task_group = self.parser.add_argument_group(
            title=""Finetuned task config options"",
            description=
            ""Finetuned task configuration for controlling finetuned task behavior, not required""
",4
"        )

        self.add_params_file_arg()
",4
"                self.args.param_file,
",4
"            autoft = PSHE2(
                evaluator,
",4
"        best_hparams_origin = autoft.get_best_hparams()
        best_hparams_origin = autoft.mpi.bcast(best_hparams_origin)

        with open(autoft._output_dir + ""/log_file.txt"", ""w"") as f:
            best_hparams = evaluator.convert_params(best_hparams_origin)
",4
"                best_hparams_origin)]

",4
"                      autoft._output_dir + ""/best_model ."")
",4
"            else:
",4
"                    f.write(""\t"".join(param) + ""\t"" + modeldir[0] + ""\n"")
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"from . import show
",4
"from . import autofinetune
from . import serving
#coding:utf-8
",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"        if utils.is_windows():
            placeholders = [20, 40]
",4
"        tp = TablePrinter(
            titles=[""ModuleName"", ""Path""], placeholders=placeholders)
",4
"

command = ListCommand.instance()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

import threading
",4
"

def synchronized(func):
",4
"    func.__lock__ = threading.Lock()

",4
"        return _instance[cls]
",4
"import time
",4
"
",4
"            '%(log_color)s[%(asctime)-15s] [%(levelname)8s] - %(message)s',
            log_colors={
",4
"                self.setLevel(level)
",4
"
            maxlen = -1
            for text in msgarr:
                if len(text) > maxlen:
",4
"                    maxlen = len(text)

            result = ["" "", ph * (maxlen + 2 + lrspace * 2)]
            tbline = ""%s%s%s"" % (ph, "" "" * (maxlen + lrspace * 2), ph)
",4
"
        if self._is_no_log():
",4
"    def critical(self, msg):
        self(logger.CRITICAL, msg)

",4
"    def train(self, msg):
",4
"    },
",4
"        ""is_bbox_normalized"": False,
        # ""norm_type"": ""affine_channel"",
",4
"
ssd_train_ops = [
    dict(op='DecodeImage', to_rgb=True, with_mixup=False),
    dict(op='NormalizeBox'),
",4
"        brightness_upper=1.125,
        is_order=True),
    dict(op='ExpandImage', max_ratio=4, prob=0.5),
    dict(
        op='CropImage',
",4
"]

ssd_eval_fields = [
",4
"    dict(op='NormalizeBox'),
    dict(op='ResizeImage', target_size=512, use_cv2=False, interp=1),
",4
"        is_scale=False),
    dict(op='ArrangeEvalSSD', fields=ssd_eval_fields)
]

ssd_predict_ops = [
",4
"    dict(op='ResizeImage', target_size=800, max_size=1333, interp=1),
",4
"    dict(op='DecodeImage', to_rgb=True),
    dict(
        op='NormalizeImage',
        mean=[0.485, 0.456, 0.406],
",4
"        std=[0.229, 0.224, 0.225],
        is_scale=True,
        is_channel_first=False),
",4
"    dict(op='ResizeImage', target_size=800, max_size=1333, interp=1),
",4
"    dict(op='ArrangeTestYOLO'),
",4
"            ""fields"": ['image', 'gt_box', 'gt_label'],
",4
"        ""train"": {
            ""fields"":
            ['image', 'im_info', 'im_id', 'gt_box', 'gt_label', 'is_crowd'],
            ""OPS"":
",4
"        },
",4
"            ""USE_PADDED_IM_INFO"":
",4
"            True,
",4
"        },
        ""predict"": {
            ""fields"": ['image', 'im_info', 'im_id', 'im_shape'],
            ""OPS"": rcnn_predict_ops,
            ""IS_PADDING"": True,
",4
"        },
",4
"        },
        ""predict"": {
            ""fields"": ['image', 'im_size', 'im_id'],
            ""OPS"": yolo_predict_ops,
",4
"        raise ValueError(""module {} not supported"".format(module_name))


def get_feed_list(module_name, input_dict, input_dict_pred=None):
",4
"        feed_list = [image.name, image_shape.name]
    elif 'rcnn' in module_name:
        image = input_dict['image']
",4
"        head_feat = output_dict_pred['head_feat']
        rois = output_dict_pred['rois']
        feature_pred = [head_feat, rois]
    else:
        raise NotImplementedError
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"import os
import time
import re
",4
"from paddlehub.common.decorator_utils import singleton
from paddlehub.common.server_config import default_server_config
from paddlehub.io.parser import yaml_parser
from paddlehub.common.lock import lock
",4
"
",4
"            utils.mkdir(CONF_HOME)
        if not os.path.exists(config_file_path) or 0 == os.path.getsize(
                config_file_path):
",4
"        self.server_url = self.config['server_url']
        self.request()
        self._load_resource_list_file_if_valid()
",4
"
        # if file is out of date, remove it
        if now_time - file_create_time >= CACHE_TIME:
",4
"            if resource_type:
                payload['type'] = resource_type
            api_url = srv_utils.uri_path(self.get_server_url(), 'search')
            r = srv_utils.hub_request(api_url, payload, extra=extra)
",4
"                         version=None,
",4
"                resource_type is None
                or self.resource_list_file['type'][index] == resource_type)
        ]
",4
"            resource_type=""Module"",
            version=version,
            update=update,
            extra=extra)
",4
"            resource_name=module_name,
            resource_type=""Model"",
            version=version,
            update=update,
",4
"            else:
                pass
",4
"        if addition is not None:
            extra.update({""addition"": addition})
        try:
            r = srv_utils.hub_request(api_url, payload, extra, timeout=0.1)
",4
"
",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# See the License for the specific language governing permissions and
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import distutils.util
",4
"
import six

",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
",4
"import time
import uuid
import os
",4
"
from paddlehub import version
",4
"        if os.path.exists(self.filepath):
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"import hashlib
import platform
import base64

import paddle.fluid as fluid
",4
"import six
import numpy as np
import cv2
",4
"
from paddlehub.module import module_desc_pb2
from paddlehub.common.logger import logger

",4
"    version2 = version2.split(""."")
",4
"        pic_str = base64.b64encode(buffer)
",4
"    _item = {
        ""data"": [],
        ""path"": results[0].get(""path"", """"),
        ""id"": results[0][""id""]
",4
"        else:
",4
"    return platform.platform()

",4
"
def is_windows():
    return get_platform().lower().startswith(""windows"")
",4
"    if not isinstance(input, list):
        if not isinstance(input, tuple):
            input = [input]
",4
"
",4
"    md5.update(text)
    return md5.hexdigest()
",4
"

def get_keyed_type_of_pyobj(pyobj):
",4
"        return module_desc_pb2.BOOLEAN
",4
"        module_attr.type = module_desc_pb2.STRING
        module_attr.s = pyobj
    elif isinstance(pyobj, six.binary_type):
        module_attr.type = module_desc_pb2.STRING
",4
"            logger.warning(
                ""python obj %s has not __dict__ attr"" % module_attr.name)
            return
        for key, value in pyobj.__dict__.items():
            from_pyobj_to_module_attr(value, module_attr.object.data[str(key)],
",4
"    if module_attr.type == module_desc_pb2.BOOLEAN:
        result = module_attr.b
    elif module_attr.type == module_desc_pb2.INT:
        result = module_attr.i
",4
"    elif module_attr.type == module_desc_pb2.SET:
        result = set()
        for index in range(len(module_attr.set.data)):
            result.add(
                from_module_attr_to_pyobj(module_attr.set.data[str(index)]))
",4
"
    return result

",4
"
def is_csv_file(file_path):
    return get_file_ext(file_path) == "".csv""

",4
"    """"""
    get sum(version), eg: version_sum(1.4.5) = 1*100*100*100 + 4*100*100 + 5*100
",4
"    if version_sum(version_a[1]) > version_sum(version_b[1]):
        return -1
    elif version_sum(version_a[1]) == version_sum(version_b[1]):
        return 0
    else:
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# TODO: Change dir.py's filename, this naming rule is not qualified


",4
"def gen_user_home():
    if ""HUB_HOME"" in os.environ:
        home_path = os.environ[""HUB_HOME""]
",4
"        if os.path.exists(home_path) and os.path.isdir(home_path):
            return home_path
",4
"if not os.path.exists(TMP_HOME):
    os.makedirs(TMP_HOME)

if not os.path.exists(CACHE_HOME):
    os.makedirs(CACHE_HOME)
",4
"        yield file.name


@contextlib.contextmanager
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an 'AS IS' BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"import requests
import tarfile

from paddlehub.common import utils
",4
"
__all__ = ['Downloader', 'progress']
FLUSH_INTERVAL = 0.1
",4
"        lasttime = 0
    if time.time() - lasttime >= FLUSH_INTERVAL:
        sys.stdout.write('\r%s' % str)
        lasttime = time.time()
",4
"

class Downloader(object):
",4
"    def download_file(self,
                      url,
                      save_path,
",4
"                      save_name=None,
                      retry_limit=3,
                      print_progress=False,
",4
"                return False, tips, None
",4
"            r = requests.get(url, stream=True)
            total_length = r.headers.get('content-length')

            if total_length is None:
",4
"                            progress(
                                '[%-50s] %.2f%%' %
                                ('=' * done, float(dl / total_length * 100)))
                if print_progress:
",4
"                    progress('[%-50s] %.2f%%' % ('=' * 50, 100), end=True)
",4
"            module_dir = os.path.join(dirname, file_names[0])
            for index, file_name in enumerate(file_names):
                if print_progress:
                    done = int(50 * float(index) / size)
                    progress('[%-50s] %.2f%%' % ('=' * done,
",4
"        if delete_file:
            os.remove(file)
",4
"                                     retry_limit=3,
",4
"                                     delete_file=True,
                                     print_progress=False,
                                     replace=False):
        result, tips_1, file = self.download_file(
",4
"    def __init__(self, name, version=None):
        self.name = name
        self.version = version

",4
"        return

    if not hub.HubServer()._server_check():
        raise ServerConnectionError

",4
"            url=url, save_path=_dir, print_progress=True)
",4
"#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"    fluid.core.VarDesc.VarType.INT64: ""int64"",
    fluid.core.VarDesc.VarType.BOOL: ""bool"",
    fluid.core.VarDesc.VarType.INT16: ""int16"",
    fluid.core.VarDesc.VarType.UINT8: ""uint8"",
",4
"def convert_dtype_to_string(dtype):
    if dtype in dtype_map:
",4
"                              module_attr.map.data['optimize_attr'])
    from_pyobj_to_module_attr(
",4
"
def from_module_attr_to_param(module_attr):
    param = {'gradient_clip_attr': None, 'regularizer': None}
    param['trainable'] = from_module_attr_to_pyobj(
",4
"    if module_attr.map.data['regularizer'].type != module_desc_pb2.NONE:
        regularizer_type = module_attr.map.data['regularizer'].name
        regularization_coeff = from_module_attr_to_pyobj(
            module_attr.map.data['regularizer'].object.
",4
"                module_attr.map.data['gradient_clip_attr'].object.
",4
"
    return param

",4
"            to_block.create_var(**var_info)

    for op in from_block.ops:
        op_info = {
            'type': op.type,
",4
"                    inplace=True,
                    need_log=True):

    if not isinstance(pre_program, fluid.Program):
        raise TypeError(""pre_program shoule be an instance of fluid.Program"")
",4
"                ""block_%d in next_program merge into block_%d in pre_program"" %
                (index, block_map[index]))
            new_block = output_program._create_block(
                parent_idx=block_map[block.parent_idx])
",4
"def set_parameter_trainable(program, trainable=True):
",4
"

def remove_vars_prefix(program, prefix, vars=None, excludes=None):
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"# limitations under the License.

",4
"from .dir import tmp_dir, tmp_file
import os
if os.name == ""posix"":
",4
"    def __init__(self):
        self.LOCK_EX = ""WIN_LOCK_EX""
        self.LOCK_UN = ""WIN_LOCK_UN""
",4
"        return self.lock
",4
"        elif cmd == self.lock.LOCK_EX:
            if Lock._owner is None:
                Lock._owner = os.getpid()
                self.lock.flock(fp, cmd)
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
from __future__ import division
",4
"    ""dark_gray"": ""\033[1;30m%s\033[0m"",
    ""light_gray"": ""\033[0;37m%s\033[0m"",
    ""blue"": ""\033[0;34m%s\033[0m"",
",4
"windows_color_dict = {key: ""%s"" for key in linux_color_dict}


",4
"    color_dict = get_color_dict()
    if color not in color_dict:
",4
"        line = '+'
        for value in self.placeholders:
            line += '-' * (value + 2) + '+'
",4
"        for index, title in enumerate(self.titles):
            if self.title_colors[index]:
                title = colorful_text(self.title_colors[index], title)
                _ph = get_ph_value()
            else:
",4
"                _ph = 0
",4
"            title_text += (""{0:%s%d}|"" %
                           (self.title_aligns[index],
                            self.placeholders[index] + 2 + _ph)).format(title)
",4
"                max_lines = content_length

        line = ''
        for cnt in range(max_lines + 1):
            line += '|'
",4
"        self.add_horizontal_line()
        return self.text
",4
"        placeholders = [30, 8, 16, 16]
",4
"    return tp.get_text()
# coding: utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"
def gen_result(status, msg, data):
",4
"        if item in module_info.keys():
            predict_args.update({item: module_info[item]})
",4
"        print(curr, "" - "", err)
        return gen_result(""-1"", ""Please check data format!"", """")
    return gen_result(""0"", """", output)

",4
"
def predict_v2_advanced(module_info, input):
    serving_method_name = module_info[""method_name""]
",4
"    predict_method = getattr(module_info[""module""], method_name)
",4
"        user_dict = extra.get(""user_dict"", [])
",4
"    if isinstance(predict_method, functools.partial):
",4
"    finally:
        for item in input_img:
            if os.path.exists(item):
                os.remove(item)
    return gen_result(""0"", """", str(results))
",4
"        predict_args.update({""sign_name"": method_name})
    for item in predict_method.__code__.co_varnames:
        if item in module_info.keys():
            predict_args.update({item: module_info[item]})
",4
"    results = predict_method(**predict_args)
",4
"    try:
        pass
    except Exception as err:
        curr = time.strftime(""%Y-%m-%d %H:%M:%S"", time.localtime(time.time()))
        print(curr, "" - "", err)
",4
"def predict_mask(module_info, input_img, id, extra=None, r_img=False):
    output_folder = ""detection_result""
    method_name = module_info[""method_name""]
    module = module_info[""module""]
",4
"    predict_method = getattr(module, method_name)
    data_len = len(input_img) if input_img is not None else 0
    data = {}
    if input_img is not None:
        input_img = {""image"": input_img}
",4
"        if input_img is not None:
",4
"                            results_pack.append(results[index])
                        os.remove(item)
",4
"
    predict_args = module_info[""predict_args""].copy()
    predict_args.update({""data"": {""image"": input_img}})

    if isinstance(predict_method, functools.partial):
",4
"        return gen_result(""-1"", ""Please check data format!"", """")
    finally:
        base64_list = []
        results_pack = []
        for index in range(len(input_img)):
",4
"                b_body = str(b_body).replace(""b'"", """").replace(""'"", """")
",4
"                results_pack.append(results[index])
",4
"            os.remove(item)
            os.remove(os.path.join(output_folder, item))
",4
"    predict_method = getattr(module, method_name)

",4
"            predict_args.update({item: module_info[item]})
    try:
        results = predict_method(**predict_args)
",4
"    finally:
        base64_list = []
",4
"    return gen_result(""0"", """", str(results_pack))

",4
"            module_info.update({""nlp_module"": [{""Choose..."": ""Choose...""}]})
            for item in nlp_module_info.nlp_modules:
",4
"                module_info[""nlp_module""].append({item: item})
",4
"
    @app_instance.route(""/predict/image/<module_name>"", methods=[""POST""])
",4
"    def predict_image(module_name):
        if request.path.split(""/"")[-1] not in cv_module_info.modules_info:
",4
"            return {""error"": ""Module {} is not available."".format(module_name)}
",4
"                filename = req_id + ""_"" \
",4
"            file = request.files.getlist(""image"")
            for item in file:
",4
"        module_info = nlp_module_info.get_module_info(module_name)
        if module_info[""code_version""] == ""v2"":
            results = ""This usage is out of date, please use 'application/json' as content-type to post to /predict/%s. See 'https://github.com/PaddlePaddle/PaddleHub/blob/release/v1.6/docs/tutorial/serving.md' for more details."" % (
",4
"            for file in request.files.getlist(file_key):
",4
"            return gen_result(""-1"", msg, """")
        inputs = request.json
        if inputs is None:
            results = ""This usage is out of date, please use 'application/json' as content-type to post to /predict/%s. See 'https://github.com/PaddlePaddle/PaddleHub/blob/release/v1.6/docs/tutorial/serving.md' for more details."" % (
",4
"def run(configs=None, port=8866):
",4
"    if configs is not None:
        config_with_file(configs)
    else:
        print(""Start failed cause of missing configuration."")
",4
"        u'version': u'1.0.0',
        u'module': 'lac',
        u'batch_size': 20
",4
"
class Manager(BaseManager):
",4
"    if module_name in nlp_module:
        predict_nlp(input_data, module_name, batch_size)
    elif module_name in cv_module:
",4
"        try:
            real_input_data = {""text"": real_input_data}
            results = predict_method(
                data=real_input_data, use_gpu=use_gpu, batch_size=batch_size)
",4
"        result_data = []
",4
"                        queue_name_list[latest_num]].empty() is not True:
                    input_data = []
                    lock.acquire()
                    try:
",4
"                    finally:
",4
"                    if len(input_data) != 0:
                        choose_module_category(input_data,
",4
"                latest_num = (latest_num + 1) % len(queue_name_list)
    except KeyboardInterrupt:
        print(""Process %s is end."" % (os.getpid()))


",4
"def create_app():
",4
"            module_info.update({""cv_module"": [{""Choose..."": ""Choose...""}]})
",4
"        img_base64 = request.form.get(""image"", """")
        if img_base64 != """":
            img_base64 = request.form.get(""image"", """")
",4
"        results = []
        result_len = 0
        start_time = time.time()
        while result_len != data_num:
",4
"        if item[""category""] == ""CV"":
",4
"        config_with_file(configs)
    else:
        print(""Start failed cause of missing configuration."")
",4
"    },
               {
                   'category': 'NLP',
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"        pass

    def _pre_processing(self):
        pass

",4
"#     http://www.apache.org/licenses/LICENSE-2.0
",4
"        module = hub.Module(name=name)
        return module

",4
"    def set_modules_info(self, modules_info):
",4
"        return self._modules_info


",4
"class CVModuleInfo(BaseModuleInfo):
    def __init__(self):
",4
"        self.cv_module_method = {
            ""vgg19_imagenet"": ""predict_classification"",
",4
"            ""alexnet_imagenet"": ""predict_classification"",
            ""yolov3_coco2017"": ""predict_object_detection"",
            ""ultra_light_fast_generic_face_detector_1mb_640"":
            ""predict_object_detection"",
",4
"            ""deeplabv3p_xception65_humanseg"": ""predict_semantic_segmentation"",
",4
"
",4
"    @property
",4
"class NLPModuleInfo(BaseModuleInfo):
    def __init__(self):
        super(NLPModuleInfo, self).__init__()

    @property
",4
"    @abc.abstractmethod
    def _inference(self, data):
",4
"            max_seq_len=max_seq_len,
            show_ids=show_ids,
            do_lower_case=do_lower_case,
",4
"
    def get_result(self, input_text):
        return self.bs.encode(input_text)
# coding: utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"import ujson
import random
",4
"from paddlehub.common.logger import logger
",4
"        self.feed_var_names = input_ids.name + ';' + position_ids.name + ';' + segment_ids.name + ';' + input_mask.name
        self.reader = hub.reader.ClassifyReader(
            vocab_path=module.get_vocab_path(),
            dataset=None,
",4
"        self.server_list.append(server)
",4
"        for server_str in server_list:
            self.server_list.append(server_str)
        self.check_server()
",4
"            server_ip = server.split(':')[0]
            server_port = int(server.split(':')[1])
            client.connect((server_ip, server_port))
            client.send(b'pending server')
",4
"                    server, error_msg))
",4
"                cur_con.request('POST', ""/BertService/inference"", request_msg,
",4
"            try:
                random.seed()
                self.con_index = random.randint(0, len(self.serving_list) - 1)
                logger.info(self.con_index)
                cur_con = httplib.HTTPConnection(
",4
"            try:
                self.con_index = int(self.process_id) % len(self.serving_list)
                cur_con = httplib.HTTPConnection(
",4
"
                return response_msg
            except BaseException as err:

",4
"                logger.warning(""Infer Error with server {} : {}"".format(
                    self.serving_list[self.con_index], err))
",4
"                if len(self.serving_list) == 0:
                    logger.error('All server failed, process will exit')
                    return 'fail'
                else:
",4
"        data_generator = self.reader.data_generator(
            batch_size=self.batch_size, phase='predict', data=text)
        request_msg = """"
        for run_step, batch in enumerate(data_generator(), start=1):
            request = []
",4
"            token_list = batch[0][0].reshape(-1).tolist()
            pos_list = batch[0][1].reshape(-1).tolist()
",4
"                instance_dict = {}
",4
"        retry = 0
        while type(response_msg) == str and response_msg == 'retry':
",4
"            if retry < self.retry:
",4
"                retry += 1
                logger.info('Try to connect another servers')
",4
"
        return result
# coding: utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"import codecs
",4
"                title = self.title[index]
                self.content[title].append(item)
",4
"
class YAMLFileParser(object):
",4
"    def _check(self):
        pass
",4
"        pass

",4
"        return contents


csv_parser = CSVFileParser()
",4
"yaml_parser = YAMLFileParser()
txt_parser = TextFileParser()
#coding:utf-8
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
",4
"from __future__ import division
from __future__ import print_function

",4
"    return low, high
",4
"    if isinstance(img, str):
        utils.check_path(img)
        img = Image.open(img)
    return img

",4
"
def image_crop_from_position(img, width, height, w_start, h_start):
    img, width, height = _check_img_and_size(img, width, height)
    w_end = w_start + width
    h_end = h_start + height
",4
"    return image_crop_from_position(img, width, height, w_start, h_start)


def image_crop_from_BL(img, width, height):
    img, width, height = _check_img_and_size(img, width, height)
",4
"
",4
"def image_crop_from_centor(img, width, height):
    img = _check_img(img)
    w_start = (img.size[0] - width) / 2
",4
"        int(img.size[0] / 10), img.size[0])
    height = height if height else np.random.randint(
        int(img.size[1] / 10), img.size[1])
    return image_resize(img, width, height, interpolation_method)

",4
"def image_saturation_adjust(img, delta):
    delta = _check_range_0_1(delta)
    img = _check_img(img)
",4
"    delta = np.random.uniform(low, high)
",4
"    return image_saturation_adjust(img, delta)
",4
"                         enable_brightness_adjust=True,
                         enable_contrast_adjust=True,
",4
"    operator_list = []
",4
"    if enable_rotate:
        operator_list.append(image_rotate_random)
    if enable_brightness_adjust:
",4
"        operator_list.append(image_brightness_adjust_random)
    if enable_contrast_adjust:
",4
"        return img

    random_op_index = np.random.randint(0, len(operator_list) - 1)
",4
"# Unless required by applicable law or agreed to in writing, software
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"from __future__ import division
from __future__ import print_function

import os

",4
"#   Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"            train_file=""train.csv"",
            dev_file=""dev.csv"",
",4
"            text = row[""comment_text""]
            labels = [int(value) for value in row[2:]]
            example = InputExample(guid=guid, label=labels, text_a=text)
            examples.append(example)

",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"import os
import csv

from paddlehub.dataset import InputExample
from paddlehub.common.dir import DATA_HOME
",4
"from paddlehub.dataset.base_nlp_dataset import BaseNLPDataset

_DATA_URL = ""https://bj.bcebos.com/paddlehub-dataset/lcqmc.tar.gz""

",4
"                example = InputExample(
                    guid=seq_id, label=line[2], text_a=line[0], text_b=line[1])
                seq_id += 1
                examples.append(example)

",4
"    ds = LCQMC()
    print(""first 10 dev"")
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"    def _read_file(self, input_file, phase=None):
        """"""Reads a tab separated value file.""""""
        with io.open(input_file, ""r"", encoding=""UTF-8"") as file:
            examples = []
            for (i, line) in enumerate(file):
",4
"                data = line.strip().split(""_!_"")
                try:
                    example = InputExample(
",4
"from paddlehub.dataset.base_nlp_dataset import BaseNLPDataset

_DATA_URL = ""https://bj.bcebos.com/paddlehub-dataset/nlpcc-dbqa.tar.gz""
",4
"    for more information
    """"""
",4
"            for line in reader:
                example = InputExample(
                    guid=seq_id, label=line[3], text_a=line[1], text_b=line[2])
                seq_id += 1
                examples.append(example)
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
import paddlehub as hub
from paddlehub.dataset.base_cv_dataset import BaseCVDataset

",4
"
",4
"    for e in ds.get_dev_examples()[:10]:
        print(e)
",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# You may obtain a copy of the License at
#
",4
"            label_list=[""0"", ""1"", ""2""],
",4
"                examples.append(example)
",4
"            return examples


if __name__ == ""__main__"":
    ds = INews()
",4
"#
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
from __future__ import division
",4
"
        # test.tsv has not label,so it is a predict file
        dev_file = ""dev.tsv""
        predict_file = ""test.tsv""
        if sub_dataset == 'MNLI' and not mismatch:
",4
"        elif sub_dataset == 'MNLI' and mismatch:
            dev_file = 'dev_mismatched.tsv'
            predict_file = ""test_mismatched.tsv""

",4
"
        super(GLUE, self).__init__(
            base_path=base_path,
            train_file=""train.tsv"",
",4
"                    label_index, text_a_index, text_b_index = [None, 1, 2]
                else:
                    label_index, text_a_index, text_b_index = [3, 1, 2]
",4
"            elif self.sub_dataset in [
                    'SST-2',
            ]:
                if phase == ""predict"":
",4
"                    label_index, text_a_index, text_b_index = [None, 8, 9]
                else:
                    label_index, text_a_index, text_b_index = [-1, 8, 9]
            elif self.sub_dataset in ['CoLA']:
",4
"                if phase == ""predict"":
                    label_index, text_a_index, text_b_index = [None, 1, None]
                else:
                    label_index, text_a_index, text_b_index = [1, 3, None]
",4
"                        text_a=line[text_a_index],
                        text_b=line[text_b_index]
",4
"        print()
",4
"        print()
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"from paddlehub.dataset.base_cv_dataset import BaseCVDataset


",4
"class StanfordDogsDataset(BaseCVDataset):
    def __init__(self):
",4
"    for e in ds.get_train_examples()[:10]:
        print(e)
    print(""first 10 test"")
    for e in ds.get_test_examples()[:10]:
        print(e)
",4
"    print(ds)
#coding:utf-8
#   Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"import os
import codecs
",4
"from paddlehub.common.dir import DATA_HOME
",4
"

class MSRA_NER(BaseNLPDataset):
    """"""
",4
"            train_file=""train.tsv"",
            dev_file=""dev.tsv"",
            test_file=""test.tsv"",
",4
"                examples.append(example)

            return examples
",4
"      guid: Unique id for the example.
      text_a: string. The untokenized text of the first sequence. For single
        sequence tasks, only this sequence must be specified.
",4
"      text_b: (Optional) string. The untokenized text of the second sequence.
        Only must be specified for sequence pair tasks.
      label: (Optional) string. The label of the example. This should be
        specified for train and dev examples, but not for test examples.
    """"""
",4
"

class BaseDataset(object):
    def __init__(self,
",4
"        self.label_file = label_file
",4
"        self.predict_examples = []

        self.if_file_with_header = {
",4
"            ""predict"": predict_file_with_header
        }

        if train_file:
",4
"    @property
    def num_labels(self):
",4
"                replace=True)
            if not result:
                raise Exception(tips)
        else:
",4
"HubDataset = BaseDataset
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"from paddlehub.dataset.base_cv_dataset import BaseCVDataset

",4
"    print(ds)
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"import io
",4
"class THUCNEWS(BaseNLPDataset):
",4
"    def __init__(self):
        dataset_dir = os.path.join(DATA_HOME, ""thucnews"")
        base_path = self._download_dataset(dataset_dir, url=_DATA_URL)
        super(THUCNEWS, self).__init__(
",4
"                    examples.append(example)
                except:
                    pass
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"    for e in ds.get_dev_examples()[:10]:
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"        self.question_text = question_text
        self.doc_tokens = doc_tokens
",4
"        s += "", doc_tokens: [%s]"" % ("" "".join(self.doc_tokens))
        if self.start_position is not None:
            s += "", orig_answer_text: %s"" % (self.orig_answer_text)
",4
"
class CMRC2018(BaseNLPDataset):
    """"""A single set of features of data.""""""

    def __init__(self):
",4
"                    or (cp >= 0x3400 and cp <= 0x4DBF)
                    or (cp >= 0x20000 and cp <= 0x2A6DF)
",4
"            return False

        def _tokenize_chinese_chars(text):
            """"""Because Chinese (and Japanese Kanji and Korean Hanja) does not have whitespace
            characters, we add spaces around every character in the CJK Unicode range before
",4
"                doc_tokens = []
                char_to_word_offset = []
                prev_is_whitespace = True
",4
"                    # Only select the first answer
                    answer = qa[""answers""][0]
                    orig_answer_text = answer[""text""]
",4
"                    if end_offset >= len(char_to_word_offset):
                        end_offset = len(char_to_word_offset) - 1
",4
"
        logger.warning(""%i bad examples has been dropped"" % drop)
        return examples


",4
"        if index < 10:
            print(e)
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"                 doc_tokens,
                 orig_answer_text=None,
                 start_position=None,
",4
"                 end_position=None,
                 is_impossible=False):
",4
"        self.orig_answer_text = orig_answer_text
        self.start_position = start_position
        self.end_position = end_position
        self.is_impossible = is_impossible
",4
"
class SQUAD(BaseNLPDataset):
",4
"        if not version_2_with_negative:
",4
"        with open(input_file, ""r"") as reader:
            input_data = json.load(reader)[""data""]

",4
"        for entry in input_data:
",4
"                doc_tokens = []
                char_to_word_offset = []
                prev_is_whitespace = True
",4
"                for c in paragraph_text:
                    if is_whitespace(c):
                        prev_is_whitespace = True
",4
"                for qa in paragraph[""qas""]:
                    qas_id = qa[""id""]
                    question_text = qa[""question""]
",4
"                    orig_answer_text = None
                    is_impossible = False
                    if phase in [""train"", ""dev""]:
                        if self.version_2_with_negative:
",4
"                            #
                            # Note that this means for training mode, every example is NOT
                            # guaranteed to be preserved.
",4
"                    example = SquadExample(
                        qas_id=qas_id,
                        question_text=question_text,
",4
"    for e in ds.get_dev_examples()[:2]:
        print(e)
    print(""first 10 train"")
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"
from paddlehub.dataset import InputExample
from paddlehub.common.dir import DATA_HOME
",4
"        dataset_dir = os.path.join(DATA_HOME, ""chnsenticorp"")
        base_path = self._download_dataset(
            dataset_dir,
",4
"            dev_file=""dev.tsv"",
            test_file=""test.tsv"",
            label_file=None,
",4
"
if __name__ == ""__main__"":
    ds = ChnSentiCorp()
",4
"    for e in ds.get_train_examples()[:10]:
        print(""{}\t{}\t{}\t{}"".format(e.guid, e.text_a, e.text_b, e.label))
",4
"#coding:utf-8
",4
"# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"
import os
import numpy as np

from paddlehub.dataset import BaseDataset
",4
"                        image_path = os.path.join(self.base_path, image_path)
                label = items[-1]
",4
"# discarded. please use BaseCVDataset
class ImageClassificationDataset(object):
    def __init__(self):
        logger.warning(
",4
"            ""ImageClassificationDataset is no longer recommended from PaddleHub v1.5.0, ""
            ""please use BaseCVDataset instead of ImageClassificationDataset. ""
            ""It's more easy-to-use with more functions and support evaluating test set ""
",4
"        self.test_list_file = None
        self.validate_list_file = None
        self.label_list_file = None
        self.num_labels = 0
        self.label_list = []
",4
"                    image_path = "" "".join(items[0:-1])
",4
"            self.dev_examples = data
        elif phase == 'test':
",4
"
    def train_data(self, shuffle=True):
        train_data_path = os.path.join(self.base_path, self.train_list_file)
",4
"                                          self.validate_list_file)
        return self._parse_data(validate_data_path, shuffle, phase='dev')

",4
"    def get_train_examples(self):
        return self.train_examples

    def get_dev_examples(self):
        return self.dev_examples
",4
"            validate_list_file=validate_list_file,
            test_list_file=test_list_file)
",4
"        self.base_path = base_path
        self.train_image_dir = train_image_dir
",4
"        self.train_list_file = train_list_file
        self.validate_image_dir = validate_image_dir
        self.validate_list_file = validate_list_file
",4
"        self.test_image_dir = test_image_dir
        self.test_list_file = test_list_file
",4
"        if phase == 'train':
",4
"            self.train_examples = data
        elif phase == 'dev':
            self.dev_examples = data
        elif phase == 'test':
            self.test_examples = data
",4
"        train_data_path = os.path.join(self.base_path, self.train_list_file)
        train_image_dir = os.path.join(self.base_path, self.train_image_dir)
",4
"        if not self._train_data:
",4
"class XNLI(BaseNLPDataset):
    """"""
    Please refer to
    https://arxiv.org/pdf/1809.05053.pdf
    for more information
",4
"    """"""
",4
"
    def __init__(self, language='zh'):
        if language not in [
                ""ar"", ""bg"", ""de"", ""el"", ""en"", ""es"", ""fr"", ""hi"", ""ru"", ""sw"",
                ""th"", ""tr"", ""ur"", ""vi"", ""zh""
",4
"    def _read_file(self, input_file, phase=None):
        """"""Reads a tab separated value file.""""""
",4
"            for line in reader:
                example = InputExample(
                    guid=seq_id, label=line[2], text_a=line[0], text_b=line[1])
                seq_id += 1
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import absolute_import
",4
"            label_list_file=""label_list.txt"")

",4
"
if __name__ == ""__main__"":
    ds = Food101Dataset()
    print(""first 10 dev"")
",4
"    print(""first 10 test"")
    for e in ds.get_test_examples()[:10]:
        print(e)
    print(ds)
#coding:utf-8
",4
"# See the License for the specific language governing permissions and
# limitations under the License.

# NLP Dataset
",4
"# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

",4
"    ""113"": ""news_world"",
    ""114"": ""stock"",
",4
"
class TNews(BaseDataset):
    """"""
    TNews is the chinese news classification dataset on Jinri Toutiao App.
",4
"        dataset_dir = os.path.join(DATA_HOME, ""tnews"")
        base_path = self._download_dataset(dataset_dir, url=_DATA_URL)
        label_list = [
            '100', '101', '102', '103', '104', '106', '107', '108', '109',
            '110', '112', '113', '114', '115', '116'
",4
"        ]
        super(TNews, self).__init__(
            base_path=base_path,
            train_file=""toutiao_category_train.txt"",
",4
"                example = InputExample(
                    guid=data[0], label=data[1], text_a=data[3])
                examples.append(example)
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"            validate_list_file=""validate_list.txt"",
            test_list_file=""test_list.txt"",
            label_list_file=""label_list.txt"",
            label_list=None)
",4
"

if __name__ == ""__main__"":
",4
"from __future__ import division
",4
"from __future__ import print_function

import io
import csv
",4
"            label_list=label_list,
            train_file_with_header=train_file_with_header,
            dev_file_with_header=dev_file_with_header,
",4
"                        continue
                if phase != ""predict"":
",4
"                    if ncol == 1:
                        example = InputExample(guid=i, text_a=line[0])
                    elif ncol == 2:
",4
"                        if not has_warned:
                            logger.warning(
",4
"                            guid=i, text_a=line[0], text_b=line[1])
                    else:
                        raise Exception(
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"# limitations under the License.
",4
"SPIECE_UNDERLINE = 'â'


",4
"        self.orig_answer_text = orig_answer_text
        self.start_position = start_position
        self.end_position = end_position

    def __str__(self):
",4
"                    'ã', 'ã', ',', 'ã', '""', 'â', 'â', '$', 'ã', 'ã', 'â', ';',
                    'ã', '(', ')', '-', 'ï½', 'ã', 'â', 'â', 'â', ':'
            ]:
                return True
",4
"            return False

        def _tokenize_chinese_chars(text):
            """"""Because Chinese (and Japanese Kanji and Korean Hanja) does not have whitespace
",4
"        with open(input_file, ""r"") as reader:
            input_data = json.load(reader)[""data""]
        for entry in input_data:
            for paragraph in entry[""paragraphs""]:
",4
"                paragraph_text = paragraph[""context""]
                context = _tokenize_chinese_chars(paragraph_text)

                doc_tokens = []
                char_to_word_offset = []
",4
"                prev_is_whitespace = True
                for c in context:
                    if is_whitespace(c):
",4
"                        prev_is_whitespace = True
                    else:
",4
"                        if prev_is_whitespace:
                            doc_tokens.append(c)
",4
"                        else:
                            doc_tokens[-1] += c
",4
"                    qas_id = qa[""id""]
                    question_text = qa[""question""]

",4
"                    # Only select the first answer
                    answer = qa[""answers""][0]
",4
"                    while paragraph_text[answer_offset] in [
                            "" "", ""\t"", ""\r"", ""\n"", ""ã"", ""ï¼"", ""ï¼"", "":"", ""."", "",""
                    ]:
                        answer_offset += 1
",4
"                    end_position = char_to_word_offset[answer_offset +
",4
"                                                       answer_length - 1]
                    # Only add answers where the text can be exactly recovered from the
                    # document. If this CAN'T happen it's likely due to weird Unicode
                    # stuff so we will just skip the example.
                    #
",4
"                    cleaned_answer_text = """".join(
",4
"                        tokenization.whitespace_tokenize(orig_answer_text))
",4
"                        end_position=end_position)
",4
"                    examples.append(example)
        return examples

",4
"    for index, e in enumerate(examples):
        if index < 10:
",4
"
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"import six
import sentencepiece as spm
import pickle
",4
"def convert_to_unicode(text):
    """"""Converts `text` to Unicode (if it's not already), assuming utf-8 input.""""""
    if six.PY3:
",4
"    else:
        raise ValueError(""Not running on Python2 or Python 3?"")


def printable_text(text):
",4
"    vocab = collections.OrderedDict()
    fin = io.open(vocab_file, ""r"", encoding=""UTF-8"")
",4
"        index = items[1] if len(items) == 2 else num
        token = token.strip()
        vocab[token] = int(index)
    fin.close()
",4
"    output = []
",4
"    def convert_tokens_to_ids(self, tokens):
        return convert_by_vocab(self.vocab, tokens)

    def convert_ids_to_tokens(self, ids):
        return convert_by_vocab(self.inv_vocab, ids)
",4
"        text = convert_to_unicode(text)
        if self.ws:
            text = [s for s in self.cut(text) if s != ' ']
",4
"        else:
            text = text.split(' ')
        if self.lower:
",4
"
    def tokenize(self, text):
        """"""Tokenizes a piece of text.""""""
        text = convert_to_unicode(text)
        text = self._clean_text(text)
",4
"        # characters in the vocabulary because Wikipedia does have some Chinese
        # words in the English Wikipedia.).
        text = self._tokenize_chinese_chars(text)
",4
"        return """".join(output)

    def _run_split_on_punc(self, text):
        """"""Splits punctuation on a piece of text.""""""
",4
"    def _tokenize_chinese_chars(self, text):
        """"""Adds whitespace around any CJK character.""""""
        output = []
",4
"        for char in text:
",4
"
        return False

    def _clean_text(self, text):
",4
"        This uses a greedy longest-match-first algorithm to perform tokenization
        using the given vocabulary.
",4
"        for token in whitespace_tokenize(text):
",4
"                        substr = ""##"" + substr
                    if substr in self.vocab:
",4
"                    end -= 1
",4
"
            if is_bad:
                output_tokens.append(self.unk_token)
            else:
",4
"
def _is_whitespace(char):
",4
"    if cat == ""Zs"":
        return True
    return False

",4
"
def _is_control(char):
    """"""Checks whether `chars` is a control character.""""""
    # These are technically control characters but we count them as whitespace
    # characters.
",4
"        return True
",4
"#coding:utf-8
#   Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"from __future__ import division
from __future__ import print_function

import collections
",4
"import numpy as np
import six
from collections import namedtuple
",4
"                break
            if len(tokens_a) > len(tokens_b):
                tokens_a.pop()
            else:
",4
"                tokens_b.pop()

",4
"
        if tokens_b:
",4
"        # embedding vector (and position vector). This is not *strictly* necessary
        # since the [SEP] token unambiguously separates the sequences, but it makes
        # it easier for the model to learn the concept of sequences.
        #
        # For classification tasks, the first vector (corresponding to [CLS]) is
",4
"        # the entire model is fine-tuned.
",4
"        for token in tokens_a:
            tokens.append(token)
            text_type_ids.append(0)
        tokens.append(""[SEP]"")
",4
"        text_type_ids.append(0)

        if tokens_b:
            for token in tokens_b:
                tokens.append(token)
",4
"
",4
"
        return record

    def _pad_batch_records(self, batch_records, phase):
",4
"                to_append = (len(batch_records) + 1) * max_len <= batch_size
            else:
",4
"            if to_append:
                batch_records.append(record)
            else:
",4
"                       phase='train',
                       shuffle=True,
",4
"        if phase == 'train':
",4
"            shuffle = True
            examples = self.get_train_examples()
            self.num_examples['train'] = len(examples)
",4
"        elif phase == 'val' or phase == 'dev':
            shuffle = False
            examples = self.get_dev_examples()
            self.num_examples['dev'] = len(examples)
",4
"            seq_id = 0

",4
"                    )
",4
"
            for batch_data in self._prepare_batch_data(
                    examples, batch_size, phase=phase):
",4
"                if return_list:
                    # for DataFeeder
",4
"

class ClassifyReader(BaseNLPReader):
    def _pad_batch_records(self, batch_records, phase=None):
        batch_token_ids = [record.token_ids for record in batch_records]
",4
"        batch_text_type_ids = [record.text_type_ids for record in batch_records]
        batch_position_ids = [record.position_ids for record in batch_records]
",4
"            max_seq_len=self.max_seq_len,
            pad_idx=self.pad_id,
            return_input_mask=True,
            return_seq_lens=True)
        padded_text_type_ids = pad_batch_data(
",4
"        if phase != ""predict"":
            batch_label_ids = [record.label_id for record in batch_records]
            padded_label_ids = pad_batch_data(
                batch_label_ids,
                max_seq_len=self.max_seq_len,
",4
"                if len(sub_token) < 2:
                    continue
",4
"                sub_label = label
                if label.startswith(""B-""):
                    sub_label = ""I-"" + label[2:]
                ret_labels.extend([sub_label] * (len(sub_token) - 1))
",4
"            return ret_tokens, ret_labels
        else:
            ret_tokens = []
            for token in tokens:
                sub_token = tokenizer.tokenize(token)
",4
"            if len(tokens) > max_seq_length - 2:
",4
"    def _pad_batch_records(self, batch_records, phase=None):
        batch_token_ids = [record.token_ids for record in batch_records]
        batch_text_type_ids = [record.text_type_ids for record in batch_records]
        batch_position_ids = [record.position_ids for record in batch_records]
",4
"
",4
"
        text_a = tokenization.convert_to_unicode(example.text_a)
",4
"        tokens_a = tokenizer.tokenize(text_a)
",4
"        if example.text_b is not None:
            #if ""text_b"" in example._fields:
            text_b = tokenization.convert_to_unicode(example.text_b)
            tokens_b = tokenizer.tokenize(text_b)

",4
"
        token_ids = tokenizer.convert_tokens_to_ids(tokens)
",4
"                label_ids.append(int(label))

        if phase != ""predict"":
            record = self.Record_With_Label_Id(
                token_ids=token_ids,
",4
"                       shuffle=True,
                       data=None,
                       return_list=True):
        if phase != 'predict' and not self.dataset:
            raise ValueError(""The dataset is none and it's not allowed."")
",4
"        if phase == 'train':
            shuffle = True
            examples = self.get_train_examples()
            self.num_examples['train'] = len(examples)
",4
"                        guid=seq_id,
                        text_a=item[0],
                        text_b=item[1],
                        label=label)
",4
"                        ""The length of input_text is out of handling, which must be 1 or 2!""
",4
"                    )
                examples.append(item_i)
",4
"            raise ValueError(
                ""Unknown phase, which should be in ['train', 'dev', 'test', 'predict'].""
            )

        def wrapper():
",4
"        self.unique_id = unique_id
        self.example_index = example_index
        self.doc_span_index = doc_span_index
        self.tokens = tokens
        self.token_to_orig_map = token_to_orig_map
",4
"        self.token_is_max_context = token_is_max_context
        self.token_ids = token_ids
        self.position_ids = position_ids
        self.text_type_ids = text_type_ids
        self.start_position = start_position
",4
"                 max_seq_len=512,
                 doc_stride=128,
                 max_query_length=64,
",4
"            do_lower_case=do_lower_case,
            random_seed=random_seed,
            use_task_id=use_task_id,
            sp_model_path=sp_model_path,
            word_dict_path=word_dict_path,
",4
"    def _pad_batch_records(self, batch_records, phase):
        batch_token_ids = [record.token_ids for record in batch_records]
",4
"        batch_text_type_ids = [record.text_type_ids for record in batch_records]
",4
"            pad_idx=self.pad_id,
",4
"            input_mask, batch_unique_ids
        ]
        if phase != ""predict"":
",4
"            batch_start_position = [
                record.start_position for record in batch_records
",4
"            batch_end_position = np.array(batch_end_position).astype(
                ""int64"").reshape([-1, 1])
",4
"
",4
"            return_list += [batch_start_position, batch_end_position]

        return return_list
",4
"
",4
"                yield self._pad_batch_records(batch_records, phase)
                batch_records, max_len = [record], len(record.token_ids)

        if batch_records:
            yield self._pad_batch_records(batch_records, phase)
",4
"            elif phase == 'dev':
",4
"                )
",4
"        else:
            features = self._convert_examples_to_records(
                examples, self.max_seq_len, self.tokenizer, phase)
            self.all_features[phase] = features

",4
"        def wrapper():
            if shuffle:
",4
"                else:
                    tok_end_position = len(all_doc_tokens) - 1
                (tok_start_position,
                 tok_end_position) = self.improve_answer_span(
                     all_doc_tokens, tok_start_position, tok_end_position,
",4
"
            for (doc_span_index, doc_span) in enumerate(doc_spans):
                tokens = []
                token_to_orig_map = {}
",4
"                    token_is_max_context[len(tokens)] = is_max_context
",4
"                        end_position = tok_end_position - doc_start + doc_offset
",4
"                feature = Features(
",4
"        return features

    def improve_answer_span(self, doc_tokens, input_start, input_end, tokenizer,
                            orig_answer_text):
        """"""Returns tokenized answer spans that better match the annotated answer.""""""
",4
"        #   Question: What year was John Smith born?
        #   Context: The leader was John Smith (1895-1943).
        #   Answer: 1895
",4
"            for new_end in range(input_end, new_start - 1, -1):
                text_span = "" "".join(doc_tokens[new_start:(new_end + 1)])
                if text_span == tok_answer_text:
                    return (new_start, new_end)

",4
"        # right context will always be the same, of course).
",4
"            if position < doc_span.start:
                continue
            if position > end:
",4
"                continue
            num_left_context = position - doc_span.start
            num_right_context = end - position
",4
"class LACClassifyReader(BaseReader):
",4
"        super(LACClassifyReader, self).__init__(dataset)
",4
"        self.has_processed = {
            ""train"": False,
            ""dev"": False,
            ""val"": False,
",4
"            data = self.dataset.get_test_examples()
            self.num_examples['test'] = len(data)
        elif phase == ""val"" or phase == ""dev"":
            shuffle = False
",4
"                    data[i] = preprocess(data[i])
                else:
",4
"            self.has_processed[phase] = True

        def _data_reader():
",4
"            if phase == ""predict"":
                for text in data:
                    if not text:
                        continue
",4
"                        texts = []
",4
"                                fluid.CPUPlace())
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"import numpy as np
",4
"                       return_input_mask=True,
                       return_max_len=True,
                       return_num_token=False):
    """"""
    1. generate Tensor of data
",4
"    """"""

    batch_src_ids = [inst[0] for inst in insts]
",4
"    # or unique id

    for i in range(3, len(insts[0]), 1):
        labels = [inst[i] for inst in insts]
",4
"        max_seq_len=max_seq_len,
        return_pos=False,
        return_input_mask=False)
",4
"    return return_list if len(return_list) > 1 else return_list[0]


def pad_batch_data(insts,
                   pad_idx=0,
",4
"    corresponding position data and input mask.
    """"""
    return_list = []
",4
"    if return_num_token:
",4
"    def __init__(self, dataset, random_seed=None):
",4
"            for index, label in enumerate(self.dataset.get_labels()):
                self.label_map[label] = index
",4
"                ""Dataset is None or it has not any labels, label map = {}"".
                format(self.label_map))
",4
"#   Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"from __future__ import print_function

import paddle
",4
"    ""RBG"": [0, 2, 1],
    ""GBR"": [1, 2, 0],
",4
"    ""GRB"": [1, 0, 2],
    ""BGR"": [2, 1, 0],
    ""BRG"": [2, 0, 1]
",4
"}

",4
"                 images_std=None,
                 data_augmentation=False,
                 random_seed=None):
        super(ImageClassificationReader, self).__init__(dataset, random_seed)
",4
"        self.data_augmentation = data_augmentation
        self.images_std = images_std
        self.images_mean = images_mean
",4
"            raise ValueError(""Image width and height should not be negative."")

    def data_generator(self,
                       batch_size=1,
                       phase=""train"",
",4
"            shuffle = False
            if hasattr(self.dataset, ""validate_data""):
                # Compatible with ImageClassificationDataset
                self.dataset.validate_data()
",4
"            if hasattr(self.dataset, ""test_data""):
",4
"                image = image_augmentation.image_random_process(
                    image, enable_resize=False, enable_crop=False)

            # only support RGB
",4
"            image = image.convert('RGB')

",4
"            if phase == ""predict"":
                for image_path in data:
                    image = preprocess(image_path)
                    images.append(image.astype('float32'))
                    if len(images) == batch_size:
",4
"                            # for DataFeeder
",4
"                if images:
                    images = np.array([images]).astype('float32')
",4
"                        yield images
                    images = []
            else:
                for image_path, label in data:
",4
"                    labels = []

        return _data_reader
",4
"

class ObjectDetectionReader(BaseReader):
    def __init__(self,
",4
"            self.num_examples['dev'] = len(self.get_dev_examples())
        else:  # phase == ""predict"":
            from ..contrib.ppdet.data.source import build_source
            data_config = {""IMAGES"": data, ""TYPE"": ""SimpleSource""}
",4
"        if phase in phase_trans:
            phase = phase_trans[phase]
        assert phase in ('train', 'dev', 'predict')
        feed_config = dconf.feed_config[self.model_type][phase]
",4
"            self._name = socket.gethostname()
        else:
            # in mpi environment
",4
"            self._comm = MPI.COMM_WORLD
            self._size = self._comm.Get_size()
",4
"
    @property
    def size(self):
        return self._size

",4
"            return data

    def gather(self, data):
",4
"            return self._comm.allgather(data)
        else:
            # do nothing
            return [data]

",4
"                return (average_count + 1) * self._rank, (average_count + 1) * (
",4
"                    self._rank + 1)
            else:
                start = (average_count + 1) * (array_length % self._size) \
                      + average_count * (self._rank - array_length % self._size)
                return start, start + average_count
",4
"
",4
"    all_node_names = mpi.gather(mpi.name)
    print(""all node names using gather: {}"".format(all_node_names))

",4
"# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"if six.PY3:
    INF = math.inf
else:
    INF = float(""inf"")

",4
"            cudas=[""0""],
            popsize=5,
            output_dir=None,
    ):
        self._num_thread = len(cudas)
",4
"
        if output_dir is None:
",4
"
    @property
    def popsize(self):
        return self._popsize

",4
"    @property
    def output_dir(self):
        return self._output_dir
",4
"            if ratio >= 0:
                solut[i] = (
",4
"                    1.0 - self.init_input[i]) * ratio + self.init_input[i]
            else:
                solut[i] = (
                    self.init_input[i] + 1.0) * ratio + self.init_input[i]
",4
"
",4
"                else:
                    self.current_hparams[i][j] = (
                        self.current_hparams[i][j] +
                        1.0) * ratio * self.epsilon + self.current_hparams[i][j]
",4
"
",4
"
    def is_stop(self):
",4
"        my_solutions = solutions[range_start:range_end]

        for idx, solution in enumerate(my_solutions):
",4
"            modeldir = output_dir + ""/model-"" + str(idx) + ""/""
            log_file = output_dir + ""/log-"" + str(idx) + "".info""
            params_cudas_dirs.append([solution, cuda, modeldir, log_file])
",4
"                                           params_cudas_dirs)
                cnt += 1
                tp.close()
                tp.join()
",4
"                for param_cuda in params_cudas_dirs:
                    self.is_cuda_free[""free""].append(param_cuda[1])
                    self.is_cuda_free[""busy""].remove(param_cuda[1])
",4
"
        all_solution_results = self.mpi.gather(solution_results)

        if self.mpi.rank == 0:
            # only rank 0 need to feedback
",4
"    def __init__(
            self,
            evaluator,
            cudas=[""0""],
            popsize=1,
",4
"    def sigma(self):
        return self._sigma

",4
"        return self.evolution_stratefy.ask()

    def is_stop(self):
        return self.evolution_stratefy.stop()

",4
"        for index, hparam_name in enumerate(self.hparams_name_list):
            print(""%s=%s"" % (hparam_name, local_hparams[index]))

        if local_min_reward <= self.best_reward_all_pop:
",4
"            self.best_reward_all_pop = local_min_reward
            self.best_hparams_all_pop = params_list[local_min_reward_index]

",4
"            value=self.get_best_eval_value(),
            step=self.round)
        for pop_num in range(self.popsize):
            params = self.evaluator.convert_params(params_list[pop_num])
            for index, name in enumerate(self.hparams_name_list):
",4
"                self.writer_pop_trails[pop_num].add_scalar(
                    tag=""population_transformation/"" + name,
",4
"            self.writer_pop_trails[pop_num].add_scalar(
                tag=""population_transformation/eval_value"",
                value=(REWARD_SUM - reward_list[pop_num]),
                step=self.round)

",4
"        self.evolution_stratefy.tell(params_list, reward_list)
",4
"        self.evolution_stratefy.disp()

    def get_best_hparams(self):
",4
"    ):
",4
"            else:
                solut[i] = (
                    self.init_input[i] + 1.0) * ratio + self.init_input[i]
        return solut
",4
"                if ratio >= 0:
",4
"                    ) * ratio * self.epsilon + self.current_hparams[i][j]
                else:
",4
"    def estimate_local_gradients(self):
",4
"        local_min_reward = min(reward_list)
        local_min_reward_index = reward_list.index(local_min_reward)
",4
"        print(""The local best eval value in the %s-th round is %s."" %
              (self._round - 1, REWARD_SUM - local_min_reward))
        print(""The local best hyperparameters are as:"")
        for index, hparam_name in enumerate(self.hparams_name_list):
",4
"            step=self.round)
        for pop_num in range(self.popsize):
            params = self.evaluator.convert_params(params_list[pop_num])
",4
"    with open(tmp_file, 'a') as f:
        f.write(trial_id + ""\t"" + str(float(result)) + ""\n"")


",4
"def unique_name():
    return ''.join(random.sample(string.ascii_letters + string.digits, 8))

",4
"        init_params = []
        for param in self.params[""param_list""]:
",4
"            if params[i] > float(self.params[""param_list""][i][""lower_than""]):
                return False
",4
"    def format_params_str(self, params):
",4
"        if is_windows():
            run_cmd = ""set PaddleHub_AutoDL_Trial_ID=%s&set FLAGS_eager_delete_tensor_gb=0.0&set CUDA_VISIBLE_DEVICES=%s&python -u %s --saved_params_dir=%s %s %s >%s 2>&1"" % \
                    (rand_str, num_cuda, self.finetunee_script, saved_params_dir, param_str, self.options_str, log_file)
        else:
            run_cmd = ""export PaddleHub_AutoDL_Trial_ID=%s; export FLAGS_eager_delete_tensor_gb=0.0; export CUDA_VISIBLE_DEVICES=%s; python -u %s --saved_params_dir=%s %s %s >%s 2>&1"" % \
",4
"                    (rand_str, num_cuda, self.finetunee_script, saved_params_dir, param_str, self.options_str, log_file)

        try:
",4
"                    if rand_str == data[0]:
",4
"        reward = self.get_reward(eval_result)
        self.model_rewards[saved_params_dir] = reward
        return reward
",4
"    def __init__(self, params_file, finetunee_script, options_str=""""):
        super(PopulationBasedEvaluator, self).__init__(
            params_file, finetunee_script, options_str=options_str)
        self.half_best_model_path = []
",4
"
            eval_result = []
            tmp_file = os.path.join(TMP_HOME, 'tmp.txt')
",4
"                        eval_result = float(data[1])
",4
"                eval_result = 0.0
",4
"            print(e)
            print(
",4
"            key
            for key in sorted(
                self.model_rewards, key=self.model_rewards.get, reverse=False)
            [:half_size]
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
",4
"    serialized_pb=_b(
",4
"    values=[
",4
")
_sym_db.RegisterEnumDescriptor(_FILE_TYPE)

FILE_TYPE = enum_type_wrapper.EnumTypeWrapper(_FILE_TYPE)
_REQUIRE_TYPE = _descriptor.EnumDescriptor(
",4
"        _descriptor.EnumValueDescriptor(
            name='COMMAND', index=3, number=3, options=None, type=None),
        _descriptor.EnumValueDescriptor(
",4
"            name='PY_VERSION', index=4, number=4, options=None, type=None),
    ],
",4
"            containing_type=None,
",4
"        _descriptor.FieldDescriptor(
            name='type',
            full_name='paddlehub.module.checkinfo.FileInfo.type',
            index=1,
            number=2,
",4
"            number=3,
            type=8,
",4
"            containing_type=None,
            is_extension=False,
",4
"    extension_ranges=[],
    oneofs=[],
",4
"    serialized_start=49,
    serialized_end=182,
)

_REQUIRES = _descriptor.Descriptor(
",4
"    name='Requires',
    full_name='paddlehub.module.checkinfo.Requires',
",4
"            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
",4
"            extension_scope=None,
            options=None),
",4
"            full_name='paddlehub.module.checkinfo.Requires.version',
            index=1,
",4
"            extension_scope=None,
",4
"            index=3,
            number=4,
            type=9,
",4
"            default_value=_b("""").decode('utf-8'),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
",4
"    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
    serialized_start=185,
",4
"    serialized_end=317,
)

_CHECKINFO = _descriptor.Descriptor(
    name='CheckInfo',
",4
"    full_name='paddlehub.module.checkinfo.CheckInfo',
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
",4
"        _descriptor.FieldDescriptor(
            name='paddle_version',
            full_name='paddlehub.module.checkinfo.CheckInfo.paddle_version',
",4
"            message_type=None,
",4
"            name='hub_version',
            full_name='paddlehub.module.checkinfo.CheckInfo.hub_version',
",4
"            cpp_type=9,
            label=1,
",4
"            'paddlehub.module.checkinfo.CheckInfo.module_proto_version',
",4
"            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=1,
",4
"            has_default_value=False,
",4
"            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
",4
"            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
",4
"            is_extension=False,
            extension_scope=None,
",4
"
",4
"
    def _wrapper(*args, **kwargs):
        return func(*args, **kwargs)

",4
"
",4
"        cls._name = name
        cls._version = version
        cls._author = author
        cls._author_email = author_email
        cls._summary = summary
",4
"                    os.path.abspath(sys.modules[cls.__module__].__file__))
",4
"        self._initialize(**kwargs)
        self._is_initialize = True
        self._code_version = ""v2""

",4
"            for base_class in current_cls.__bases__:
",4
"    def init_with_name(cls, name, version=None, **kwargs):
        fp_lock = open(os.path.join(CACHE_HOME, name), ""a"")
        lock.flock(fp_lock, lock.LOCK_EX)
        log_msg = ""Installing %s module"" % name
        if version:
",4
"        result, tips, module_dir = default_module_manager.install_module(
            module_name=name, module_version=version, extra=extra)
        if not result:
            logger.error(tips)
            raise RuntimeError(tips)
",4
"    @classmethod
    def init_with_directory(cls, directory, **kwargs):
        desc_file = os.path.join(directory, MODULE_DESC_PBNAME)
",4
"            _file = os.path.realpath(sys.modules[_item.__module__].__file__)
",4
"
    @property
    def run_func(self):
        return self._run_func

",4
"    @property
",4
"    def directory(self):
        return self._directory
",4
"    @property
    def author_email(self):
",4
"        return self.__class__._author_email

",4
"    @property
    def summary(self):
",4
"
    @property
    def is_runnable(self):
",4
"        return self._run_func != None

    @property
",4
"
    def forward(self, *args, **kwargs):
",4
"
",4
"        self._code_version = ""v1""
",4
"        self._type = utils.from_module_attr_to_pyobj(
            module_info.map.data['type'])
        self._summary = utils.from_module_attr_to_pyobj(
            module_info.map.data['summary'])
",4
"        self._load_assets()
        self._recover_from_desc()
        self._generate_sign_attr()
",4
"        self._recover_variable_info(self.program)

    @property
    def serving_func_name(self):
",4
"        serving_func_name = self.desc.attr.map.data['default_signature'].s
        return serving_func_name if serving_func_name != """" else None

    @property
    def desc(self):
",4
"        return self._desc

    @property
",4
"    def _dump_processor(self):
        import inspect
        pymodule = inspect.getmodule(self.processor)
        pycode = inspect.getsource(pymodule)
        processor_path = self.helper.processor_path()
",4
"        output_file = os.path.join(processor_path, processor_name + "".py"")
        utils.mkdir(processor_path)
",4
"        with open(output_file, ""w"") as file:
            file.write(pycode)
        utils.from_pyobj_to_module_attr(
",4
"                error_clip=var.error_clip,
                stop_gradient=var.stop_gradient,
                is_data=var.is_data,
",4
"        for var_info in var_infos.map.data:
",4
"    def get_extra_info(self, key):
",4
"        for sign in self.signatures:
            self.__dict__[sign] = functools.partial(
                self.__call__, sign_name=sign)

",4
"        for assets_file in self.assets:
            if ""spm_cased_simp_sampled.model"" in assets_file:
                return assets_file
",4
"        default_signature_name = utils.from_module_attr_to_pyobj(
            self.desc.attr.map.data['default_signature'])
        self.default_signature = self.signatures[
",4
"        self._type = utils.from_module_attr_to_pyobj(
            module_info.map.data['type'])
        self._summary = utils.from_module_attr_to_pyobj(
",4
"        def _get_reader_and_feeder(data_format, data, place):
            def _reader(process_data):
",4
"            index = 0
",4
"            except:
                use_gpu = False

            place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()

",4
"                    for key, value in data.items()
                }
                result += self.processor.postprocess(sign_name, data_out,
                                                     sub_data, **kwargs)
",4
"                index += len(batch)
",4
"
        return result

",4
"                max_seq_len=128,
                learning_rate=1e-3):
        """"""
",4
"        Args:
            max_seq_len(int): maximum sequence length, this option is only
            available for BERT/ERNIE module
        """"""

",4
"        else:
",4
"                for input in signature.inputs
            ]
            outputs = [
",4
"                ""Set maximum sequence length of input tensor to {}"".format(
                    max_seq_len))
            if self.name.startswith(""ernie_v2""):
                feed_list = [
                    ""input_ids"", ""position_ids"", ""segment_ids"", ""input_mask"",
",4
"                feed_list = [
                    ""input_ids"", ""position_ids"", ""segment_ids"", ""input_mask""
",4
"        num_param_loaded = 0
        for param in program.global_block().iter_parameters():
            num_param_loaded += 1
",4
"                if not self.program == _tmp_program:
                    raise ValueError(
                        ""All input and outputs variables in signature should come from the same Program""
",4
"
    def data_format(self, sign_name):
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

",4
"import six

import paddle
import numpy as np
",4
"from paddlehub.io.parser import txt_parser
from paddlehub.module.module import runnable

",4
"        """"""
        predictor config setting
        """"""
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"            gpu_config.enable_use_gpu(memory_pool_init_size_mb=500, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def texts2tensor(self, texts):
",4
"        """"""
        Tranform the texts(dict) to PaddleTensor
        Args:
             texts(list): each element is a dict that must have a named 'processed' key whose value is word_ids, such as
                          texts = [{'processed': [23, 89, 43, 906]}]
",4
"            data += text['processed']
            lod.append(len(text['processed']) + lod[i])
        tensor = PaddleTensor(np.array(data).astype('int64'))
",4
"            description=
            ""Run configuration for controlling module behavior, not required."")

",4
"            type=ast.literal_eval,
            default=False,
            help=""whether use GPU for prediction"")

        self.arg_config_group.add_argument(
",4
"    def add_module_input_arg(self):
        """"""
        Add the command input options
        """"""
        self.arg_input_group.add_argument(
",4
"            if args.input_text.strip() != '':
                if six.PY2:
",4
"                    input_data = [
                        args.input_text.decode(
",4
"            feed_list=feed_list,
            config=config,
",4
"        return fetch_list
",4
"

class TransformerModule(NLPBaseModule):
    """"""
",4
"            name=name,
            directory=directory,
",4
"        if version_compare(paddle.__version__, '1.8'):
            with tmp_dir() as _dir:
                input_dict, output_dict, program = self.context(
                    max_seq_len=max_seq_len)
",4
"                fluid.io.save_inference_model(
                    dirname=_dir,
",4
"                    target_vars=[
                        output_dict[""pooled_output""],
                        output_dict[""sequence_output""]
                    ],
                    executor=fluid.Executor(fluid.CPUPlace()))
",4
"
    def context(
            self,
",4
"                position_ids = fluid.layers.data(
                    name='position_ids',
                    shape=[-1, max_seq_len, 1],
                    dtype='int64',
",4
"            program=module_program, prefix=self.param_prefix(), vars=vars)
        self.init_pretraining_params(
            exe, self.params_path, main_program=module_program)

",4
"        self.params_layer = {}
",4
"        for param in module_program.global_block().iter_parameters():
            param.trainable = trainable
            match = re.match(r'.*layer_(\d+).*', param.name)
",4
"                # layer num begins from 0
",4
"
    def get_embedding(self, texts, max_seq_len=512, use_gpu=False,
                      batch_size=1):
        """"""
        get pooled_output and sequence_output for input texts.
",4
"        Warnings: this method depends on Paddle Inference Library, it may not work properly in PaddlePaddle <= 1.6.2.

        Args:
",4
"            pooled_outputs(list): its element is a numpy array, the first feature of each text sample.
            sequence_outputs(list): its element is a numpy array, the whole features of each text sample.
        """"""
        if not hasattr(
                self, ""emb_job""
",4
"        ) or self.emb_job[""batch_size""] != batch_size or self.emb_job[
                ""use_gpu""] != use_gpu:
            inputs, outputs, program = self.context(
                trainable=True, max_seq_len=max_seq_len)
",4
"
            reader = hub.reader.ClassifyReader(
",4
"                data_reader=reader,
                config=config,
            )
            self.emb_job[""batch_size""] = batch_size
",4
"        else:
            return None

    def get_params_layer(self):
        if not hasattr(self, ""params_layer""):
",4
"        if version_compare(paddle.__version__, '1.8'):
            pooled_output, sequence_output = self.model_runner(
                input_ids, position_ids, segment_ids, input_mask)
            return {
                'pooled_output': pooled_output,
",4
"            raise RuntimeError(
                '{} only support dynamic graph mode in paddle >= 1.8'.format(
                    self.name))
",4
"from __future__ import division
from __future__ import print_function

import os
import shutil
",4
"
from functools import cmp_to_key
import tarfile
import sys
",4
"

class LocalModuleManager(object):
    def __init__(self, module_home=None):
        self.local_modules_dir = module_home if module_home else MODULE_HOME
",4
"        try:
            desc_pb_path = os.path.join(module_path, 'module_desc.pb')
            if os.path.exists(desc_pb_path) and os.path.isfile(desc_pb_path):
                info = {}
                desc = module_desc_pb2.ModuleDesc()
",4
"                    ""name""].s
                return True, info
            else:
                module_file = os.path.realpath(
                    os.path.join(module_path, 'module.py'))
",4
"                            sys.modules[_item.__module__].__file__)
",4
"                installed_module_version = search_result.get('version', None)
                if not url or (module_version is not None
",4
"                    ]:
",4
"                result, tips, module_dir = default_downloader.uncompress(
                    file=module_zip_file,
                    dirname=os.path.join(_dir, ""tmp_module""),
                    delete_file=True,
",4
"                    print_progress=True)

            if module_package:
                with tarfile.open(module_package, ""r:gz"") as tar:
",4
"                    file_names = tar.getnames()
                    size = len(file_names) - 1
",4
"                    module_dir = os.path.join(_dir, module_name)
                    for index, file_name in enumerate(file_names):
",4
"                        tips = ""Module %s already installed in %s"" % (
",4
"                save_path = os.path.join(MODULE_HOME,
                                         module_name.replace(""-"", ""_""))
                if save_path != module_dir:
                    if os.path.exists(save_path):
",4
"        if module_version and module_version != self.modules_dict[module_name][
",4
"            tips += '-%s' % module_version
        module_dir = self.modules_dict[module_name][0]
        shutil.rmtree(module_dir)
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"from __future__ import division
",4
"
from paddlehub.common.utils import to_list

",4
"
class Signature(object):
    def __init__(self,
                 name,
",4
"        if len(inputs) != len(feed_names):
",4
"        for item in inputs:
            if not isinstance(item, Variable):
                raise TypeError(
                    ""Item in inputs list shoule be an instance of fluid.framework.Variable""
                )
",4
"
        for item in outputs:
            if not isinstance(item, Variable):
                raise TypeError(
",4
"        self.fetch_names = fetch_names
        self.for_predict = for_predict
",4
"#coding:utf-8
# Generated by the protocol buffer compiler.  DO NOT EDIT!
",4
"    package='paddlehub.module.desc',
    syntax='proto3',
    serialized_pb=_b(
        '\n\x11module_desc.proto\x12\x15paddlehub.module.desc\""\x9e\x02\n\x06KVData\x12<\n\x08key_type\x18\x01 \x03(\x0b\x32*.paddlehub.module.desc.KVData.KeyTypeEntry\x12\x35\n\x04\x64\x61ta\x18\x02 \x03(\x0b\x32\'.paddlehub.module.desc.KVData.DataEntry\x1aO\n\x0cKeyTypeEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0e\x32\x1f.paddlehub.module.desc.DataType:\x02\x38\x01\x1aN\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x30\n\x05value\x18\x02 \x01(\x0b\x32!.paddlehub.module.desc.ModuleAttr:\x02\x38\x01\""\xb7\x02\n\nModuleAttr\x12-\n\x04type\x18\x01 \x01(\x0e\x32\x1f.paddlehub.module.desc.DataType\x12\t\n\x01i\x18\x02 \x01(\x03\x12\t\n\x01\x66\x18\x03 \x01(\x01\x12\t\n\x01\x62\x18\x04 \x01(\x08\x12\t\n\x01s\x18\x05 \x01(\t\x12*\n\x03map\x18\x06 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12+\n\x04list\x18\x07 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12*\n\x03set\x18\x08 \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12-\n\x06object\x18\t \x01(\x0b\x32\x1d.paddlehub.module.desc.KVData\x12\x0c\n\x04name\x18\n \x01(\t\x12\x0c\n\x04info\x18\x0b \x01(\t\""+\n\x08\x46\x65\x65\x64\x44\x65sc\x12\x10\n\x08var_name\x18\x01 \x01(\t\x12\r\n\x05\x61lias\x18\x02 \x01(\t\"",\n\tFetchDesc\x12\x10\n\x08var_name\x18\x01 \x01(\t\x12\r\n\x05\x61lias\x18\x02 \x01(\t\""u\n\tModuleVar\x12\x34\n\nfetch_desc\x18\x01 \x03(\x0b\x32 .paddlehub.module.desc.FetchDesc\x12\x32\n\tfeed_desc\x18\x02 \x03(\x0b\x32\x1f.paddlehub.module.desc.FeedDesc\""\xd3\x01\n\nModuleDesc\x12\x41\n\x08sign2var\x18\x02 \x03(\x0b\x32/.paddlehub.module.desc.ModuleDesc.Sign2varEntry\x12/\n\x04\x61ttr\x18\x03 \x01(\x0b\x32!.paddlehub.module.desc.ModuleAttr\x1aQ\n\rSign2varEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .paddlehub.module.desc.ModuleVar:\x02\x38\x01*i\n\x08\x44\x61taType\x12\x08\n\x04NONE\x10\x00\x12\x07\n\x03INT\x10\x01\x12\t\n\x05\x46LOAT\x10\x02\x12\n\n\x06STRING\x10\x03\x12\x0b\n\x07\x42OOLEAN\x10\x04\x12\x08\n\x04LIST\x10\x05\x12\x07\n\x03MAP\x10\x06\x12\x07\n\x03SET\x10\x07\x12\n\n\x06OBJECT\x10\x08\x42\x02H\x03\x62\x06proto3'
",4
"    ))
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

_DATATYPE = _descriptor.EnumDescriptor(
    name='DataType',
",4
"    full_name='paddlehub.module.desc.DataType',
    filename=None,
",4
"    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name='NONE', index=0, number=0, options=None, type=None),
",4
"            name='INT', index=1, number=1, options=None, type=None),
        _descriptor.EnumValueDescriptor(
",4
"            name='MAP', index=6, number=6, options=None, type=None),
        _descriptor.EnumValueDescriptor(
            name='SET', index=7, number=7, options=None, type=None),
",4
"BOOLEAN = 4
",4
"            has_default_value=False,
            default_value=_b("""").decode('utf-8'),
            message_type=None,
            enum_type=None,
",4
"            name='value',
",4
"            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
",4
"    extensions=[],
",4
"        _descriptor.FieldDescriptor(
            name='value',
            full_name='paddlehub.module.desc.KVData.DataEntry.value',
            index=1,
            number=2,
",4
"                                      _b('8\001')),
    is_extendable=False,
    syntax='proto3',
    extension_ranges=[],
    oneofs=[],
",4
"        _descriptor.FieldDescriptor(
            name='key_type',
",4
"            index=0,
            number=1,
            type=11,
            cpp_type=10,
",4
"            extension_scope=None,
            options=None),
        _descriptor.FieldDescriptor(
            name='data',
            full_name='paddlehub.module.desc.KVData.data',
",4
"            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
",4
"            containing_type=None,
            is_extension=False,
            extension_scope=None,
",4
"    serialized_start=45,
",4
"        _descriptor.FieldDescriptor(
            name='type',
            full_name='paddlehub.module.desc.ModuleAttr.type',
            index=0,
            number=1,
",4
"            containing_type=None,
",4
"            is_extension=False,
            extension_scope=None,
            options=None),
        _descriptor.FieldDescriptor(
",4
"            name='f',
            full_name='paddlehub.module.desc.ModuleAttr.f',
            index=2,
            number=3,
            type=1,
",4
"            containing_type=None,
",4
"            index=5,
            number=6,
",4
"            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
",4
"            options=None),
        _descriptor.FieldDescriptor(
            name='set',
",4
"            containing_type=None,
",4
"            is_extension=False,
",4
"            default_value=_b("""").decode('utf-8'),
",4
"    extension_ranges=[],
    oneofs=[],
    serialized_start=334,
",4
"    serialized_end=645,
)

_FEEDDESC = _descriptor.Descriptor(
",4
"            name='var_name',
            full_name='paddlehub.module.desc.FeedDesc.var_name',
",4
"            options=None),
    ],
    extensions=[],
    nested_types=[],
",4
"_FETCHDESC = _descriptor.Descriptor(
    name='FetchDesc',
    full_name='paddlehub.module.desc.FetchDesc',
    filename=None,
    file=DESCRIPTOR,
",4
"            is_extension=False,
            extension_scope=None,
            options=None),
        _descriptor.FieldDescriptor(
            name='alias',
",4
"            full_name='paddlehub.module.desc.FetchDesc.alias',
            index=1,
            number=2,
            type=9,
",4
"    extension_ranges=[],
    oneofs=[],
    serialized_start=692,
    serialized_end=736,
)
",4
"            name='fetch_desc',
            full_name='paddlehub.module.desc.ModuleVar.fetch_desc',
            index=0,
",4
"            has_default_value=False,
            default_value=[],
            message_type=None,
",4
"            type=11,
",4
"            default_value=[],
            message_type=None,
            enum_type=None,
",4
"    nested_types=[],
    enum_types=[],
    options=None,
",4
"    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
",4
"            name='value',
            full_name='paddlehub.module.desc.ModuleDesc.Sign2varEntry.value',
            index=1,
",4
"            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
",4
")

",4
"            options=None),
",4
"_MODULEDESC_SIGN2VARENTRY.containing_type = _MODULEDESC
_MODULEDESC.fields_by_name['sign2var'].message_type = _MODULEDESC_SIGN2VARENTRY
",4
"    'ModuleAttr',
",4
"        DESCRIPTOR=_FEEDDESC,
        __module__='module_desc_pb2'
        # @@protoc_insertion_point(class_scope:paddlehub.module.desc.FeedDesc)
    ))
",4
"ModuleVar = _reflection.GeneratedProtocolMessageType(
    'ModuleVar',
    (_message.Message, ),
    dict(
        DESCRIPTOR=_MODULEVAR,
",4
"# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
from . import module
from . import signature
#coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"
",4
"            file_list = file_list[1:]
            abs_path = os.path.join(self.directory, file)
            if os.path.isdir(abs_path):
                for sub_file in os.listdir(abs_path):
",4
"                file_info.file_name = file
                file_info.type = check_info_pb2.FILE
                file_info.is_need = True

",4
"        return self.check_info.module_code_version

    @property
    def module_proto_version(self):
",4
"
    @property
    def paddle_version(self):
",4
"        return self.check_info.file_infos

",4
"    @property
",4
"        if not (os.path.exists(self.pb_path) or os.path.isfile(self.pb_path)):
            logger.warning(
                ""This module lacks core file %s"" % CHECK_INFO_PB_FILENAME)
            result = False

",4
"                    logger.warning(
                        ""File [%s] is incomplete"" % CHECK_INFO_PB_FILENAME)
                    result = False
        except Exception as e:
            result = False
",4
"
        if not self.check_compatibility():
            result = False

",4
"        if not self._check_module_proto_version():
            result = False

",4
"        if version_compare(self.hub_version, hub_version):
            logger.warning(
                ""This Module is generated by the PaddleHub with version %s, and the local PaddleHub version is %s, which may cause serious incompatible bug. Please upgrade PaddleHub to the latest version.""
                % (self.hub_version, hub_version))
            return False
",4
"                    logger.warning(
                        ""Module integrity check failed! Missing file [%s]"" %
                        file_path)
                    result = False
",4
"                if file_type == check_info_pb2.DIR:
                    if not os.path.isdir(file_path):
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"from __future__ import print_function
from __future__ import unicode_literals

",4
"
def jaccard_overlap(pred, gt, is_bbox_normalized=False):
    """"""
",4
"    Args:
        class_num (int): the class number.
        overlap_thresh (float): The threshold of overlap
            ratio between prediction bounding box and
            ground truth bounding box for deciding
",4
"            true/false positive. Default 0.5.
        map_type (str): calculation method of mean average
",4
"            precision, currently support '11point' and
            'integral'. Default '11point'.
        is_bbox_normalized (bool): whther bounding boxes
            is normalized to range[0, 1]. Default False.
",4
"    def update(self, bbox, gt_box, gt_label, difficult=None):
",4
"        truth infomations.
        """"""
        if difficult is None:
            difficult = np.zeros_like(gt_label)
",4
"            max_overlap = -1.0
            for i, gl in enumerate(gt_label):
",4
"                    if overlap > max_overlap:
",4
"    def reset(self):
",4
"        Accumulate metric results and calculate mAP
        """"""
        mAP = 0.
",4
"                import math
                ap = 0.
                prev_recall = 0.
",4
"                mAP += ap
                valid_cnt += 1
            else:
                logger.error(""Unspported mAP type {}"".format(self.map_type))
                sys.exit(1)
",4
"        Get mAP result
        """"""
        if self.mAP is None:
            logger.error(""mAP is not calculated."")
",4
"        [score, pos] records
",4
"        return accum_tp_list, accum_fp_list
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"
from __future__ import absolute_import
",4
"import os.path as osp
import re
import random
import shutil
",4
"
__all__ = ['create_list']


",4
"    trainval_list = []
",4
"    with open(osp.join(output_dir, 'trainval.txt'), 'w') as ftrainval:
",4
"                img_path = osp.join(
                    osp.relpath(img_dir, output_dir), name_prefix + '.jpg')
                img_ann_list.append((img_path, ann_path))

    return trainval_list, test_list
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"
",4
"import numpy as np
import os
import time

",4
"import paddle.fluid as fluid

from ..utils.voc_eval import bbox_eval as voc_bbox_eval
",4
"    return keys, values, cls


",4
"def length2lod(length_lod):
    offset_lod = [0]
",4
"

def get_sub_feed(input, place):
",4
"        if k in input.keys():
            new_dict[k] = input[k]
",4
"    return clean_result
",4
"    if len(cls) != 0:
        values = []
        for i in range(len(cls)):
            _, accum_map = cls[i].get_map_var()
            cls[i].reset(exe)
",4
"                    fetch_list=sub_values,
                    return_numpy=False)
                sub_prog_res = {
",4
"                res = clean_res(
                    res, ['im_info', 'bbox', 'im_id', 'im_shape', 'mask'])
            results.append(res)
",4
"    fps = images_num / (end_time - start_time)
",4
"            'Total number of images: {}, inference time: {} fps.'.format(
                images_num, fps))
    else:
        logger.info('Total iteration: {}, inference time: {} batch/s.'.format(
            images_num, fps))
",4
"            if output_directory:
",4
"                output = os.path.join(output_directory, 'proposal.json')
            proposal_eval(results, anno_file, output)
",4
"                is_bbox_normalized=is_bbox_normalized)

",4
"        if 'accum_map' in results[-1]:
            res = np.mean(results[-1]['accum_map'][0])
            logger.info('mAP: {:.2f}'.format(res * 100.))
            box_ap_stats.append(res * 100.)
",4
"        elif 'bbox' in results[0]:
            box_ap = voc_bbox_eval(
",4
"                results,
                num_classes,
                is_bbox_normalized=is_bbox_normalized,
",4
"        if os.path.exists(v_json):
            cocoapi_eval(v_json, coco_eval_style[i], anno_file=anno_file)
        else:
",4
"            logger.info(""{} not exists!"".format(v_json))
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"logger = logging.getLogger(__name__)


def box_flip(boxes, im_shape):
",4
"    flipped_boxes[:, 0::4] = im_width - boxes[:, 2::4] - 1
    flipped_boxes[:, 2::4] = im_width - boxes[:, 0::4] - 1
    return flipped_boxes

",4
"    y2 = dets[:, 4]
",4
"    ndets = dets.shape[0]
    suppressed = np.zeros((ndets), dtype=np.int)

    # nominal indices
",4
"    return w * h


def bbox_overlaps(x, y):
    N = x.shape[0]
",4
"    K = y.shape[0]
    overlaps = np.zeros((N, K), dtype=np.float32)
    for k in range(K):
",4
"                    x_area = bbox_area(x[n])
                    ua = x_area + y_area - iw * ih
                    overlaps[n, k] = iw * ih / ua
    return overlaps

",4
"        keep = nms(dets_j, cfg.MultiScaleTEST['nms_thresh'])
",4
"        [cls_boxes[j][:, 1] for j in range(1, cfg.num_classes)])
    if len(image_scores) > cfg.MultiScaleTEST['detections_per_im']:
",4
"                use_flip = True
",4
"

def mstest_mask_post_process(result, cfg):
    mask_list = []
    im_shape = result['im_shape'][0]
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"
from ..data.source.voc_loader import pascalvoc_label
from .map_utils import DetectionMAP
from .coco_eval import bbox2out
",4
"    Args:
        results (list): prediction bounding box results.
        class_num (int): evaluation class number.
        overlap_thresh (float): the postive threshold of
                        bbox overlap
",4
"        map_type (string): method for mAP calcualtion,
",4
"
    detection_map = DetectionMAP(
        class_num=class_num,
        overlap_thresh=overlap_thresh,
",4
"    for t in results:
        bboxes = t['bbox'][0]
",4
"                gt_box = gt_boxes[i]
                gt_label = gt_labels[i]
                difficult = None if difficults is None \
                                else difficults[i]
                bbox_num = bbox_lengths[i]
",4
"                    gt_box, gt_label, difficult)
",4
"            bbox_idx = 0
            gt_box_idx = 0
",4
"    map_stat = 100. * detection_map.get_map()
    logger.info(""mAP({:.2f}, {}) = {:.2f}"".format(overlap_thresh, map_type,
                                                  map_stat))
",4
"    valid_cnt = 0
    for i in range(len(gt_box)):
        if gt_box[i, 0] == 0 and gt_box[i, 1] == 0 and \
                gt_box[i, 2] == 0 and gt_box[i, 3] == 0:
            break
",4
"        valid_cnt += 1
    return (gt_box[:valid_cnt], gt_label[:valid_cnt],
            difficult[:valid_cnt] if difficult is not None else None)


",4
"                    ""voc2012 categories."".format(anno_file))
        return vocall_category_info(with_background)
    else:
",4
"
    if cats[0] != 'background' and with_background:
        cats.insert(0, 'background')
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
",4
"import numpy as np
",4
"    'bbox2out',
    'mask2out',
",4
"              is_bbox_normalized=False):
    assert 'bbox' in results[0]
    assert outfile.endswith('.json')
",4
"
    if len(xywh_results) == 0:
",4
"def cocoapi_eval(jsonfile,
                 style,
                 coco_gt=None,
                 anno_file=None,
",4
"        coco_eval.params.maxDets = list(max_dets)
",4
"                    'bbox': bbox,
                    'score': 1.0
                }
                xywh_res.append(coco_res)
",4
"    Args:
        results: request a dict, should include: `bbox`, `im_id`,
                 if is_bbox_normalized=True, also need `im_shape`.
        clsid2catid: class id to category id map of COCO2017 dataset.
        is_bbox_normalized: whether or not bbox is normalized.
",4
"    for t in results:
        bboxes = t['bbox'][0]
        lengths = t['bbox'][1][0]
        im_ids = np.array(t['im_id'][0])
",4
"        if bboxes.shape == (1, 1) or bboxes is None:
",4
"                catid = (clsid2catid[int(clsid)])

                if is_bbox_normalized:
                    xmin, ymin, xmax, ymax = \
",4
"                            clip_bbox([xmin, ymin, xmax, ymax])
                    w = xmax - xmin
",4
"                coco_res = {
                    'image_id': im_id,
                    'category_id': catid,
",4
"    return xywh_res


def mask2out(results, clsid2catid, resolution, thresh_binarize=0.5):
    import pycocotools.mask as mask_util
",4
"
            im_h = int(im_shape[0])
            im_w = int(im_shape[1])
",4
"
                resized_mask = cv2.resize(padded_mask, (w, h))
",4
"                im_mask[y0:y1, x0:x1] = resized_mask[(y0 - ymin):(y1 - ymin), (
                    x0 - xmin):(x1 - xmin)]
                segm = mask_util.encode(
                    np.array(im_mask[:, :, np.newaxis], order='F'))[0]
                catid = clsid2catid[clsid]
",4
"                coco_res = {
                    'image_id': im_id,
",4
"                    'category_id': catid,
                    'segmentation': segm,
                    'score': score
                }
",4
"def expand_boxes(boxes, scale):
    """"""
    Expand an array of boxes by a given scale.
    """"""
    w_half = (boxes[:, 2] - boxes[:, 0]) * .5
",4
"    h_half = (boxes[:, 3] - boxes[:, 1]) * .5
    x_c = (boxes[:, 2] + boxes[:, 0]) * .5
    y_c = (boxes[:, 3] + boxes[:, 1]) * .5
",4
"
",4
"def get_category_info_from_anno(anno_file, with_background=True):
    """"""
    Get class id to category id map and category id
",4
"    from pycocotools.coco import COCO
    coco = COCO(anno_file)
    cats = coco.loadCats(coco.getCatIds())
    clsid2catid = {
        i + int(with_background): cat['id']
",4
"        4: 4,
        5: 5,
        6: 6,
        7: 7,
",4
"        29: 33,
        30: 34,
        31: 35,
        32: 36,
",4
"        33: 37,
        34: 38,
        35: 39,
        36: 40,
",4
"        53: 58,
        54: 59,
        55: 60,
",4
"        64: 73,
        65: 74,
        66: 75,
",4
"        13: 'stop sign',
        14: 'parking meter',
",4
"        48: 'fork',
        49: 'knife',
",4
"        55: 'orange',
        56: 'broccoli',
",4
"        57: 'carrot',
        58: 'hot dog',
        59: 'pizza',
",4
"        60: 'donut',
        61: 'cake',
        62: 'chair',
        63: 'couch',
        64: 'potted plant',
",4
"        70: 'toilet',
        72: 'tv',
        73: 'laptop',
        74: 'mouse',
        75: 'remote',
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
    def __init__(self):
        self._epoch = -1
",4
"
    def __next__(self):
        return self.next()

",4
"        """"""return epoch id for latest sample""""""
        raise NotImplementedError(
            '%s.epoch_id not available' % (self.__class__.__name__))
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"
# function:
",4
"    def _make_reader(self, mode, my_source=None):
        """"""Build reader for training or validation""""""
",4
"            sc = my_source

        # 2, Buid a transformed dataset
        ops = self._trans_conf[mode]['OPS']
        batchsize = self._trans_conf[mode]['BATCH_SIZE']
",4
"        trans_conf = {k.lower(): v for k, v in self._trans_conf[mode].items()}
        need_keys = {
            'is_padding',
",4
"        maxit = -1 if self._maxiter <= 0 else self._maxiter

        def _reader():
            n = 0
            while True:
",4
"                for _batch in batched_ds:
                    yield _batch
                    n += 1
                    if maxit > 0 and n == maxit:
                        return
",4
"    def create(cls,
",4
"        if ret_iter:
            return reader._make_reader(mode, my_source)
        else:
            return reader
# coding:utf-8
",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"    """"""
    Load VOC records with annotations in xml directory 'anno_path'

",4
"    Notes:
    ${anno_path} must contains xml file and image file path for annotations

",4
"            'w': im_w, # width
            'is_crowd': is_crowd,
",4
"
            objs = tree.findall('object')
            im_w = float(tree.find('size').find('width').text)
            im_h = float(tree.find('size').find('height').text)
",4
"                _difficult = int(obj.find('difficult').text)
                x1 = float(obj.find('bndbox').find('xmin').text)
                y1 = float(obj.find('bndbox').find('ymin').text)
                x2 = float(obj.find('bndbox').find('xmax').text)
                y2 = float(obj.find('bndbox').find('ymax').text)
",4
"                'w': im_w,
",4
"                'gt_poly': [],
                'difficult': difficult
            }
            if len(objs) != 0:
",4
"    Load VOC records with annotations in
    xml directory 'anno_path'

    Notes:
    ${anno_path} must contains xml file and image file path for annotations
",4
"            'gt_poly': gt_poly,
        }
        'cname2id' is a dict to map category name to class id
    """"""

",4
"    #   background:0, first_class:1, second_class:2, ...
    # if with_background is False:
    #   first_class:0, second_class:1, ...
    records = []
    ct = 0
",4
"            else:
",4
"                gt_bbox[i] = [x1, y1, x2, y2]
",4
"                'is_crowd': is_crowd,
",4
"                'gt_class': gt_class,
                'gt_score': gt_score,
                'gt_bbox': gt_bbox,
                'gt_poly': [],
                'difficult': difficult
",4
"    return [records, cname2cid]


",4
"        'motorbike': 14,
        'person': 15,
        'pottedplant': 16,
",4
"
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

",4
"
class RoiDbSource(Dataset):
    """""" interface to load roidb data from files
",4
"            use_default_label (bool):whether use the default mapping of label to id
            mixup_epoch (int): parse mixup in first n epoch
            with_background (bool): whether load background
",4
"        self._fname = anno_file
        self._image_dir = image_dir if image_dir is not None else ''
        if image_dir is not None:
            assert os.path.isdir(image_dir), \
                    'image_dir {} is not a directory'.format(image_dir)
",4
"            mix_pos = (mix_idx + self._pos) % self._samples
            sample['mixup'] = copy.deepcopy(self._roidb[mix_pos])
            if self._load_img:
                sample['mixup']['image'] = \
",4
"        from . import loader
        records, cname2cid = loader.load(self._fname, self._samples,
                                         self._with_background, True,
                                         self.use_default_label, self.cname2cid)
        self.cname2cid = cname2cid
",4
"
    def reset(self):
        """""" implementation of Dataset.reset
        """"""
        if self._roidb is None:
",4
"            self._roidb = self._load()

        self._samples = len(self._roidb)
        if self._is_shuffle:
",4
"            random.shuffle(self._roidb)

",4
"        self._pos = 0
        self._drained = False

    def size(self):
        """""" implementation of Dataset.size
",4
"        """"""
        return len(self._roidb)

    def drained(self):
",4
"    def epoch_id(self):
        """""" return epoch id for latest sample
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

",4
"
logger = logging.getLogger(__name__)
",4
"

def load_roidb(anno_file, sample_num=-1):
    """""" load normalized data records from file
",4
"        'anno_file' which is a pickled file.
        And the records should has a structure:
",4
"        {
            'im_file': str, # image file name
            'im_id': int, # image id
            'h': int, # height of image
            'w': int, # width of image
",4
"            'is_crowd': bool,
            'gt_class': list of np.ndarray, # classids info
",4
"
    if sample_num > 0 and sample_num < len(records):
        records = records[:sample_num]

    return records, cname2cid
",4
"

",4
"    """""" Load data records from 'fnames'

    Args:
",4
"            instances_val2017.json or COCO17_val2017.roidb
        samples (int): number of samples to load, default to all
        with_background (bool): whether load background as a class.
",4
"        cname2cid (dict): the mapping of category name to id
",4
"            'w': int, # width of image
            'is_crowd': bool,
            'gt_class': list of np.ndarray, # classids info
",4
"                fname, samples, cname2cid, with_background=with_background)
        else:
            records, cname2cid = voc_loader.load(
",4
"#
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"    """"""
",4
"        self._epoch = -1
        for image in images:
",4
"        self._imid2path = {}

    def next(self):
        if self._epoch < 0:
",4
"            self._pos += 1
            return sample

    def _load(self):
",4
"# You may obtain a copy of the License at
",4
"import numpy as np
from pycocotools.coco import COCO

import logging
",4
"        sample_num (int): number of samples to load, -1 means all
        with_background (bool): whether load background as a class.
                                if True, total class number will
                                be 81. default True
",4
"            'w': im_w, # width
            'is_crowd': is_crowd,
",4
"    """"""
",4
"    coco = COCO(anno_path)
    img_ids = coco.getImgIds()
    cat_ids = coco.getCatIds()
    records = []
    ct = 0
",4
"        img_anno = coco.loadImgs(img_id)[0]
",4
"        bboxes = []
        for inst in instances:
",4
"            is_crowd[i][0] = box['iscrowd']
            if 'segmentation' in box:
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"                 samples=-1,
",4
"                 is_shuffle=True,
                 load_img=False,
                 cname2cid=None,
                 use_default_label=None,
",4
"                 mixup_epoch=-1,
                 with_background=True):
        """""" Init
",4
"            image_dir (str): root dir for images
            samples (int): samples to load, -1 means all
",4
"        _pos = np.random.choice(
            self._samples, 1, replace=False, p=self._img_weights)[0]
        sample = copy.deepcopy(self._roidb[_pos])

",4
"        if self._load_img:
            sample['image'] = self._load_image(sample['im_file'])
        else:
            sample['im_file'] = os.path.join(self._image_dir, sample['im_file'])

",4
"                    num_per_cls[c] = 1
                else:
                    num_per_cls[c] += 1

        for i in range(len(self._roidb)):
",4
"            weights = 0
            for c in imgs_cls[i]:
",4
"        img_weights = img_weights / np.sum(img_weights)
",4
"        return img_weights

    def reset(self):
        """""" implementation of Dataset.reset
",4
"        if self._roidb is None:
            self._roidb = self._load()
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"
def build_source(config):
    """"""
    Build dataset from source data, default source type is 'RoiDbSource'
    Args:
",4
"    else:
",4
"
    data_cf = {k.lower(): v for k, v in data_cf.items()}
",4
"            if 'class_aware_sampling' in args:
                del args['class_aware_sampling']
        else:
            source_type = data_cf['type']
        del args['type']
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"        samples (int): number of samples to load, -1 means all
",4
"            except StopIteration as e:
                if self._sample_num <= 0:
                    self._sample_num = self._pos
",4
"                elif self._sample_num != self._pos:
                    logger.info('num of loaded samples is different '
                                'with previouse setting[prev:%d,now:%d]' %
",4
"                                (self._sample_num, self._pos))
                    self._sample_num = self._pos

                self._data_iter = None
                self._drained = True
",4
"            raise StopIteration(""no more data in "" + str(self))
",4
"        else:
            return ret

",4
"        return self._sample_num

    def drained(self):
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"import logging
",4
"    Args:
        anno_path (str): root directory for voc annotation data
",4
"        {
            'im_file': im_fname, # image file name
            'im_id': im_id, # image id
",4
"        }
        'cname2id' is a dict to map category name to class id
    """"""

    txt_file = anno_path
",4
"        im_id = np.array([ct])
        gt_bbox = np.zeros((len(item) - 2, 4), dtype=np.float32)
",4
"            break
    assert len(records) > 0, 'not found any widerface in %s' % (anno_path)
    logger.info('{} samples in file {}'.format(ct, anno_path))
    return records, cname2cid

",4
"
def _load_file_list(input_txt):
",4
"        labels_map = {k: v - 1 for k, v in labels_map.items()}
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"from .transformer import ProxiedDataset

logger = logging.getLogger(__name__)

",4
"
class EndSignal(object):
    def __init__(self, errno=0, errmsg=''):
        self.errno = errno
",4
"
class ParallelMappedDataset(ProxiedDataset):
",4
"    """"""
    Transform samples to mapped samples which is similar to 'basic.MappedDataset',
",4
"        args = {
            'bufsize': 100,
            'worker_num': 8,
",4
"                ""invalid param for memsize[%s], should be ended with 'G' or 'g'"" % (args['memsize'])
            gb = args['memsize'][:-1]
            args['memsize'] = int(gb) * 1024**3

",4
"                from queue import Queue
            else:
                from Queue import Queue
            from threading import Thread as Worker
",4
"            self._outq = Queue(bufsize)

",4
"            if self._exit:
                break
            try:
                inq.put(source.next())
                self._produced += 1
",4
"    def drained(self):
        assert self._epoch >= 0, ""first epoch has not started yet""
        return self._source.drained() and self._produced == self._consumed
",4
"        """"""
        self._exit = True
",4
"
",4
"                logger.warn(""do not reset before epoch[%d] finishes"".format(
                    self._epoch))
                self._produced = self._produced - self._consumed
            else:
",4
"                self._produced = 0
",4
"
",4
"        self._feeding_ev.set()

",4
"import logging
import traceback

",4
"        ops (list of operator.BaseOperator or list of op dict):
            configs for oprators, eg:
",4
"        new_dict = {}
        for i, j in _dict.items():
            new_dict[i.lower()] = j
        new_ops.append(new_dict)
",4
"            params = copy.deepcopy(op)
            del params['op']
            o = op_func(**params)
",4
"            o = op_func(**params)
        else:
",4
"        op_repr.append('{{{}}}'.format(str(o)))
",4
"    Apply 'mapper' to 'ds'

",4
"        return MappedDataset(ds, mapper)
",4
"    """"""
",4
"    Batch data samples to batches
",4
"    Args:
",4
"    return BatchedDataset(
        ds, batchsize, drop_last=drop_last, drop_empty=drop_empty)


",4
"    from collections import Sequence

from numbers import Number

import uuid
",4
"    pass
",4
"            context (dict): info about this sample processing
        Returns:
            result (dict): a processed sample
",4
"        self.with_mixup = with_mixup
        if not isinstance(self.to_rgb, bool):
            raise TypeError(""{}: input type is invalid."".format(self))
        if not isinstance(self.with_mixup, bool):
            raise TypeError(""{}: input type is invalid."".format(self))
",4
"
",4
"            with open(sample['im_file'], 'rb') as f:
                sample['image'] = f.read()
",4
"    def __init__(self,
                 origin_target_size=800,
",4
"        self.use_flip = use_flip

        if not isinstance(target_size, list):
",4
"            raise TypeError(
                ""Type of target_size is invalid. Must be List, now is {}"".
                format(type(target_size)))
",4
"            resize_h = np.round(im_scale_y * float(im_shape[0]))
            im_resize = cv2.resize(
",4
"                origin_ims[base_name],
                None,
                None,
",4
"                resize_h = np.round(im_scale_y * float(im_shape[0]))
                im_resize = cv2.resize(
                    origin_ims[base_name],
                    None,
                    None,
",4
"                sample[name] = im_resize
        sample['im_info'] = np.array(im_info, dtype=np.float32)
",4
"                 interp=cv2.INTER_LINEAR,
                 use_cv2=True):
",4
"
        Args:
",4
"                multi-scale training is adopted when type is list.
            max_size (int): the max size of image
            interp (int): the interpolation method
",4
"        if not (isinstance(self.max_size, int)
",4
"                sample['im_info'] = np.array(im_info).astype(np.float32)
        else:
            im_scale_x = float(selected_size) / float(im_shape[1])
",4
"            im = np.array(im)
",4
"        Args:
            prob (float): the probability of flipping image
            is_normalized (bool): whether the bbox scale to [0,1]
            is_mask_flip (bool): whether flip the segmentation
        """"""
",4
"
        def _flip_rle(rle, height, width):
            if 'counts' in rle and type(rle['counts']) == list:
                rle = mask_util.frPyObjects([rle], height, width)
",4
"        if np.random.uniform(0, 1) < self.prob:
",4
"            im = im[:, ::-1, :]
            if gt_bbox.shape[0] == 0:
                return sample
            oldx1 = gt_bbox[:, 0].copy()
            oldx2 = gt_bbox[:, 2].copy()
",4
"            mean (list): the pixel mean
            std (list): the pixel variance
        """"""
        super(NormalizeImage, self).__init__()
        self.mean = mean
",4
"                im = sample[k]
                im = im.astype(np.float32, copy=False)
",4
"                im -= mean
                im /= std
                sample[k] = im
",4
"                contrast_lower and contrast_lower
            saturation_lower/ saturation_upper (float): the saturation
                between saturation_lower and saturation_upper
            hue_lower/ hue_upper (float): the hue between
                hue_lower and hue_upper
",4
"        self.contrast_prob = contrast_prob
        self.saturation_prob = saturation_prob
        self.hue_prob = hue_prob
        self.count = count
",4
"        contrast_delta = np.random.uniform(self.contrast_lower,
",4
"        prob = np.random.uniform(0, 1)
        if prob < self.contrast_prob:
",4
"            img = ImageEnhance.Contrast(img).enhance(contrast_delta)
",4
"        saturation_delta = np.random.uniform(self.saturation_lower,
                                             self.saturation_upper)
        prob = np.random.uniform(0, 1)
",4
"            self.random_saturation, self.random_hue
        ]
        if self.is_order:
            prob = np.random.uniform(0, 1)
            if prob < 0.5:
",4
"                ]
        else:
            ops = random.sample(ops, self.count)
        assert 'image' in sample, ""image data not found""
        im = sample['image']
",4
"        im = Image.fromarray(im)
        for id in range(self.count):
            im = ops[id](im)
        im = np.asarray(im)
",4
"        self.mean = mean
",4
"                expand_ratio = np.random.uniform(1, self.max_ratio)
                height = int(im_height * expand_ratio)
                width = int(im_width * expand_ratio)
                h_off = math.floor(np.random.uniform(0, height - im_height))
",4
"                expand_im = np.uint8(expand_im * np.squeeze(self.mean))
",4
"                sample['image'] = expand_im
                sample['gt_bbox'] = gt_bbox
                sample['gt_class'] = gt_class
                sample['w'] = width
",4
"                 [1, 50, 0.3, 1.0, 0.5, 2.0, 0.5, 1.0],
                 [1, 50, 0.3, 1.0, 0.5, 2.0, 0.7, 1.0],
                 [1, 50, 0.3, 1.0, 0.5, 2.0, 0.9, 1.0],
",4
"            4. Determine if the new bbox is satisfied in the new image.
        Returns:
            sample: the image, bounding box are replaced.
",4
"        im_width = sample['w']
        im_height = sample['h']
        gt_score = None
",4
"                    break
                sample_bbox = generate_sample_bbox(sampler)
                if satisfy_sample_constraint(sampler, sample_bbox, gt_bbox,
",4
"            ymax = int(sample_bbox[3] * im_height)
            im = im[ymin:ymax, xmin:xmax]
            sample['image'] = im
            sample['gt_bbox'] = crop_bbox
            sample['gt_class'] = crop_class
",4
"        """"""
        assert 'image' in sample, ""image data not found""
        im = sample['image']
        gt_bbox = sample['gt_bbox']
        gt_class = sample['gt_class']
",4
"        gt_score = None
        if 'gt_score' in sample:
",4
"                        break
                    sample_bbox = generate_sample_bbox_square(
",4
"                        sampler, image_width, image_height)
                    if satisfy_sample_constraint_coverage(
                            sampler, sample_bbox, gt_bbox):
                        sampled_bbox.append(sample_bbox)
",4
"                        found = found + 1
            im = np.array(im)
            while sampled_bbox:
",4
"                if self.avoid_no_bbox:
                    if len(crop_bbox) < 1:
                        continue
                xmin = int(sample_bbox[0] * image_width)
                xmax = int(sample_bbox[2] * image_width)
",4
"                ymin = int(sample_bbox[1] * image_height)
                ymax = int(sample_bbox[3] * image_height)
",4
"                sample['gt_score'] = crop_score
                return sample
            return sample

",4
"
@register_op
class NormalizeBox(BaseOperator):
    """"""Transform the bounding box's coornidates to [0,1].""""""

",4
"        height = sample['h']
        for i in range(gt_bbox.shape[0]):
            gt_bbox[i][0] = gt_bbox[i][0] / width
            gt_bbox[i][1] = gt_bbox[i][1] / height
            gt_bbox[i][2] = gt_bbox[i][2] / width
",4
"
@register_op
class Permute(BaseOperator):
    def __init__(self, to_bgr=True, channel_first=True):
        """"""
",4
"        Change the channel.
        Args:
",4
"                and isinstance(self.channel_first, bool)):
            raise TypeError(""{}: input type is invalid."".format(self))

    def __call__(self, sample, context=None):
        assert 'image' in sample, ""image data not found""
",4
"        for k in sample.keys():
            if 'image' in k:
                im = sample[k]
",4
"        factor = np.random.beta(self.alpha, self.beta)
        factor = max(0.0, min(1.0, factor))
        if factor >= 1.0:
",4
"        sample.pop('mixup')
        return sample
",4
"        self.resizers = []
        for interp in interps:
            self.resizers.append(ResizeImage(target_size, max_size, interp))

    def __call__(self, sample, context=None):
",4
"@register_op
class Resize(BaseOperator):
    """"""Resize image and bbox.

    Args:
",4
"
    def __call__(self, sample, context=None):
",4
"        resize_w = resize_h = dim
        scale_x = dim / w
        scale_y = dim / h
",4
"            sample['image'], (resize_w, resize_h), interpolation=interp)
",4
"        brightness (list): brightness settings.
            in [lower, upper, probability] format.
        random_apply (bool): whether to apply in random (yolo) or fixed (SSD)
",4
"        tyiq = np.array([[0.299, 0.587, 0.114], [0.596, -0.274, -0.321],
",4
"        t = np.dot(np.dot(ityiq, bt), tyiq).T
        img = np.dot(img, t)
        return img

",4
"
        img = img.astype(np.float32)
        gray = img * np.array([[[0.299, 0.587, 0.114]]], dtype=np.float32)
",4
"
        img = img.astype(np.float32)
        img *= delta
        return img
",4
"        delta = np.random.uniform(low, high)
",4
"
    def __call__(self, sample, context=None):
        img = sample['image']
        if self.random_apply:
            distortions = np.random.permutation([
",4
"            sample['image'] = img
            return sample

        img = self.apply_brightness(img)
",4
"    def __call__(self, sample, context=None):
        img = sample['image']
        img = img.astype(np.float32)
",4
"        return sample

",4
"
",4
"        self.fill_value = fill_value

    def __call__(self, sample, context=None):
        if np.random.uniform(0., 1.) < self.prob:
            return sample
",4
"                 num_attempts=50,
                 allow_no_crop=True,
",4
"        self.thresholds = thresholds
        self.scaling = scaling
        self.num_attempts = num_attempts
",4
"                    max(min_ar, scale**2), min(max_ar, scale**-2))
                crop_h = int(h * scale / np.sqrt(aspect_ratio))
",4
"                    continue

",4
"        br_i = np.minimum(a[:, np.newaxis, 2:], b[:, 2:])

        area_i = np.prod(br_i - tl_i, axis=2) * (tl_i < br_i).all(axis=2)
        area_a = np.prod(a[:, 2:] - a[:, :2], axis=1)
",4
"                               centers < crop[2:]).all(axis=1)
        valid = np.logical_and(
            valid, (cropped_box[:, :2] < cropped_box[:, 2:]).all(axis=1))

        return cropped_box, np.where(valid)[0]
",4
"
    def _crop_image(self, img, crop):
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"# See the License for the specific language governing permissions and
",4
"# limitations under the License.
",4
"import random
import math
import cv2


",4
"def meet_emit_constraint(src_bbox, sample_bbox):
    center_x = (src_bbox[2] + src_bbox[0]) / 2
    center_y = (src_bbox[3] + src_bbox[1]) / 2
    if center_x >= sample_bbox[0] and \
",4
"    src_bbox[2] = max(min(src_bbox[2], 1.0), 0.0)
",4
"    else:
        width = src_bbox[2] - src_bbox[0]
",4
"        new_bbox[3] = (obj_bbox[3] - sample_bbox[1]) / sample_height
        new_bbox = clip_bbox(new_bbox)
        if bbox_area(new_bbox) > 0:
            new_bboxes.append(new_bbox)
",4
"    bboxes = np.array(new_bboxes)
    labels = np.array(new_labels)
",4
"    aspect_ratio = np.random.uniform(sampler[4], sampler[5])
    aspect_ratio = max(aspect_ratio, (scale**2.0))
",4
"    aspect_ratio = min(aspect_ratio, 1 / (scale**2.0))
    bbox_width = scale * (aspect_ratio**0.5)
    bbox_height = scale / (aspect_ratio**0.5)
    if image_height < image_width:
",4
"                w_off_orig = np.random.uniform(xmin,
                                               xmin + wid - sample_bbox_size)

            if hei <= sample_bbox_size:
                h_off_orig = np.random.uniform(ymin + hei - sample_bbox_size,
",4
"    else:
",4
"    intersect_ymax = min(sample_bbox[3], object_bbox[3])
    intersect_size = (intersect_xmax - intersect_xmin) * (
        intersect_ymax - intersect_ymin)
    sample_bbox_size = bbox_area(sample_bbox)
",4
"    object_bbox_size = bbox_area(object_bbox)
    overlap = intersect_size / (
        sample_bbox_size + object_bbox_size - intersect_size)
    return overlap

",4
"                              sample_bbox,
",4
"        if sampler[6] != 0 and \
                overlap < sampler[6]:
            satisfied.append(False)
            continue
",4
"        if sampler[7] != 0 and \
",4
"

def satisfy_sample_constraint_coverage(sampler, sample_bbox, gt_bboxes):
    if sampler[6] == 0 and sampler[7] == 0:
        has_jaccard_overlap = False
",4
"        has_object_coverage = True

    if not has_jaccard_overlap and not has_object_coverage:
        return True
    found = False
",4
"
    Args:
",4
"    """"""
",4
"        for data in batch_data:
            im_c, im_h, im_w = data[0].shape[:]
            padding_im = np.zeros((im_c, max_shape[1], max_shape[2]),
                                  dtype=np.float32)
            padding_im[:, :im_h, :im_w] = data[0]
",4
"
    def padding_multiscale_test(batch_data):
        if len(batch_data) != 1:
            raise NotImplementedError(
                ""Batch size must be 1 when using multiscale test, but now batch size is {}""
",4
"                .format(len(batch_data)))
        if coarsest_stride > 1:
            padding_batch = []
",4
"            padding_images = []
            data = batch_data[0]
",4
"                    max_w = int(
",4
"        h, w = batch_data[0][0].shape[1:3]
        scale_x = float(shape) / w
        scale_y = float(shape) / h
        for data in batch_data:
            im = cv2.resize(
",4
"        # For RCNN: image shape in record in im_info.
",4
"        scaled_batch = []
        for data in batch_data:
            im = cv2.resize(
                data[0].transpose((1, 2, 0)),
",4
"                None,
                None,
                fx=scale,
                fy=scale,
",4
"        except Exception as e:
            errmsg = ""post-process failed with error: "" + str(e)
            logger.warn(errmsg)
",4
"    """"""

    def __init__(self, is_mask=False):
        super(ArrangeRCNN, self).__init__()
",4
"        self.is_mask = is_mask
        assert isinstance(self.is_mask, bool), ""wrong type for is_mask""

",4
"        if 'is_crowd' in keys:
            is_crowd = sample['is_crowd']
        else:
            raise KeyError(""The dataset doesn't have 'is_crowd' key."")
        if 'im_info' in keys:
",4
"            im_info = sample['im_info']
",4
"        gt_masks = []
        if self.is_mask and len(sample['gt_poly']) != 0 \
",4
"                            break
                        gt_segm.append(np.array(poly).reshape(-1, 2))
",4
"    Transform dict to the tuple format needed for evaluation.
    """"""

    def __init__(self):
        super(ArrangeEvalRCNN, self).__init__()
",4
"            sample: a dict which contains image
                    info and annotation info.
            context: a dict which contains additional info.
        Returns:
            sample: a tuple containing the following items:
",4
"        w = sample['w']
        # For rcnn models in eval and infer stage, original image size
        # is needed to clip the bounding boxes. And box clip op in
        # bbox prediction needs im_info as input in format of [N, 3],
        # so im_shape is appended by 1 to match dimension.
",4
"        """"""
",4
"

@register_op
class ArrangeSSD(BaseOperator):
    """"""
",4
"            sample: a dict which contains image
                    info and annotation info.
",4
"        if len(sample['gt_bbox']) != len(sample['gt_class']):
            raise ValueError(""gt num mismatch: bbox and class."")
        for field in self.fields:
            if field == 'im_shape':
                h = sample['h']
",4
"        im_shape = np.array((h, w))
        outs = (im, im_id, im_shape)
        return outs
",4
"
    def __init__(self):
        super(ArrangeYOLO, self).__init__()

    def __call__(self, sample, context=None):
",4
"            sample: a dict which contains image
",4
"    def __call__(self, sample, context=None):
        """"""
        Args:
",4
"            sample: a dict which contains image
                    info and annotation info.
            context: a dict which contains additional info.
        Returns:
",4
"        gt_bbox = np.zeros((50, 4), dtype=im.dtype)
        gt_class = np.zeros((50, ), dtype=np.int32)
",4
"        gt_num = min(50, len(sample['gt_bbox']))
        if gt_num > 0:
            gt_bbox[:gt_num, :] = sample['gt_bbox'][:gt_num, :]
",4
"            gt_class[:gt_num] = sample['gt_class'][:gt_num, 0]
",4
"        h = sample['h']
",4
"        w = sample['w']
        im_shape = np.array((h, w))
        outs = (im, im_shape, im_id)
        return outs
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"    """"""proxy method called to 'self._ds' when if not defined""""""

    def __init__(self, ds):
        super(ProxiedDataset, self).__init__()
",4
"        whose name is the same with func.__name__
        """"""
        method = func.__name__
",4
"        sample = self._ds.next()
        return self._mapper(sample)


",4
"        drop_empty (bool): drop samples which have empty field
",4
"    """"""

    def __init__(self, ds, batchsize, drop_last=False, drop_empty=True):
        super(BatchedDataset, self).__init__(ds)
",4
"        """"""proxy to self._ds.next""""""

        def empty(x):
            if isinstance(x, np.ndarray) and x.size == 0:
",4
"                return True
            elif isinstance(x, collections.Sequence) and len(x) == 0:
                return True
            else:
                return False
",4
"                if not self._drop_last and len(batch) > 0:
                    return batch
                else:
                    raise StopIteration
        return batch
",4
"import six
if six.PY3:
    import pickle
",4
"    from io import BytesIO as StringIO
",4
"
import logging
import traceback
import multiprocessing as mp
",4
"
logger = logging.getLogger(__name__)


class SharedQueueError(ValueError):
",4
"    pass


class SharedQueue(Queue):
    """""" a Queue based on shared memory to communicate data between Process,
",4
"
",4
"        if mem_mgr is not None:
            self._shared_mem = mem_mgr
",4
"            if buff is not None:
",4
"        self._shared_mem.release()
        self._shared_mem = None
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
",4
"from .sharedmemory import SharedBuffer
",4
"from .sharedmemory import SharedMemoryMgr
from .sharedmemory import SharedMemoryError
from .queue import SharedQueue
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# utils for memory management which is allocated on sharedmemory,
",4
"import six
",4
"
if six.PY3:
    import pickle
",4
"    """""" SharedMemoryError
    """"""
",4
"
    def __init__(self, errmsg=''):
",4
"        if type(src) is str and six.PY3:
",4
"    def __init__(self, owner, capacity, pos, size=0, alloc_status=''):
",4
"        """""" Init

            Args:
",4
"                owner (str): manager to own this buffer
                capacity (int): capacity in bytes for this buffer
                pos (int): page position in shared memory
                size (int): bytes already used
",4
"        self._size = size
        self._alloc_status = alloc_status
        assert self._pos >= 0 and self._cap > 0, \
            ""invalid params[%d:%d] to construct SharedBuffer"" \
",4
"    def owner(self):
        """""" get owner
",4
"
        Args:
            data (str): data to be stored in this buffer

        Returns:
",4
"            SharedMemoryError when not enough space in this buffer
        """"""
        assert type(data) in [str, bytes], \
            'invalid type[%s] for SharedBuffer::put' % (str(type(data)))
",4
"        """""" get the data stored this buffer

        Args:
",4
"
        Returns:
            data (np.ndarray('uint8')): user's data in numpy
                which is passed in by 'put'
",4
"            return None
",4
"        return self._size

    def resize(self, size):
",4
"            self.owner().free(self)
            self._owner = None
            self._cap = 0
",4
"        header_pages = int(
            math.ceil((total_pages + self.s_allocator_header) / page_size))

        self._header_pages = header_pages
        self._free_pages = total_pages - header_pages
",4
"    def _dump_alloc_info(self, fname):
        hpages, tpages, pos, used = self.header()

",4
"        alloc_page_pos = self._header_pages
        used_pages = self._header_pages
        header_info = struct.pack(
            str('III'), self._magic_num, alloc_page_pos, used_pages)
        assert len(header_info) == self.s_allocator_header, \
",4
"        self.set_page_status(self._header_pages, self._free_pages, '0')

",4
"        assert magic == self._magic_num, \
            'invalid header magic[%d] in shared memory' % (magic)
",4
"        return self._header_pages, self._total_pages, pos, used
",4
"    def __str__(self):
",4
"        return 'PageAllocator:%s' % (desc)

    def set_alloc_info(self, alloc_pos, used_pages):
        """""" set allocating position to new value
",4
"        start += self.s_allocator_header
        end = start + page_num
        assert start >= 0 and end <= self._header_size, 'invalid end[%d] of pages '\
",4
"            'in allocator[%s]' % (end, str(self))
        status = self._base[start:end].tostring().decode()
",4
"        header_pages, pages, pos, used = self.header()
        end = pos + page_num
        if end > pages:
            pos = self._header_pages
            end = pos + page_num
",4
"                break

",4
"                pos = self._header_pages
",4
"        if page_status != (page_num, 0):
            free_pages = self._total_pages - used
            if free_pages == 0:
                err_msg = 'all pages have been used:%s' % (str(self))
            else:
",4
"                err_msg = 'not found available pages with page_status[%s] '\
",4
"            raise MemoryFullError(err_msg)

        self.set_page_status(pos, page_num, '1')
        used += page_num
        self.set_alloc_info(end, used)
",4
"        return pos

",4
"    s_log_statis = False

    @classmethod
    def get_mgr(cls, id):
",4
"
    def __init__(self, capacity=None, pagesize=None):
        """""" init
",4
"        """"""
        logger.debug('create SharedMemoryMgr')

        pagesize = 64 * 1024 if pagesize is None else pagesize
",4
"        assert type(pagesize) is int, ""invalid type of pagesize[%s]"" \
            % (str(pagesize))

        capacity = DEFAULT_SHARED_MEMORY_SIZE if capacity is None else capacity
",4
"        assert type(capacity) is int, ""invalid type of capacity[%s]"" \
            % (str(capacity))

        assert capacity > 0, '""size of shared memory should be greater than 0'
        self._released = False
",4
"
        assert self._cap % self._page_size == 0, \
            ""capacity[%d] and pagesize[%d] are not consistent"" \
",4
"            % (self._cap, self._page_size)
",4
"
    def _setup(self):
        self._shared_mem = RawArray('c', self._cap)
        self._base = np.frombuffer(
",4
"            self._allocator = PageAllocator(self._base, self._total_pages,
                                            self._page_size)
        finally:
            self._locker.release()
",4
"    def malloc(self, size, wait=True):
        """""" malloc a new SharedBuffer
",4
"
        Args:
            size (int): buffer size to be malloc
",4
"
",4
"                self._locker.release()

            if start is None:
                time.sleep(0.1)
                if ct % 100 == 0:
",4
"                    logger.warn('not enough space for reason[%s]' % (errmsg))
",4
"                ct += 1
",4
"
        Raises:
            SharedMemoryError when failed to release this buffer
        """"""
        assert shared_buf._owner == self._id, ""invalid shared_buf[%s] ""\
",4
"            ""for it's not allocated from me[%s]"" % (str(shared_buf), str(self))
        cap = shared_buf.capacity()
        start_page = shared_buf._pos
",4
"        page_num = cap // self._page_size

        #maybe we don't need this lock here
        self._locker.acquire()
",4
"        assert start >= 0 and end <= self._cap, ""invalid start ""\
            ""position[%d] when put data to buff:%s"" % (start, str(shared_buf))
",4
"
        if not self._released and not self._allocator.empty():
            logger.debug(
                'not empty when delete this SharedMemoryMgr[%s]' % (self))
",4
"        else:
",4
"# coding=utf-8
",4
"        results = lac.lexical_analysis(data=inputs)
        self.assertEqual(results[0]['word'], ['ä»å¤©', 'æ¯', 'ä¸ª', 'å¥½æ¥å­'])
        self.assertEqual(results[0]['tag'], ['TIME', 'v', 'q', 'n'])
        self.assertEqual(results[1]['word'], ['å¤©æ°é¢æ¥', 'è¯´', 'ä»å¤©', 'è¦', 'ä¸é¨'])
",4
"        self.assertEqual(results[1]['tag'], ['n', 'v', 'TIME', 'v', 'v'])
        self.assertEqual(results[2]['word'],
                         ['ä¸', 'ä¸ç­', 'å°é', 'é©¬ä¸', 'å°±è¦', 'å°', 'äº'])
        self.assertEqual(results[2]['tag'],
",4
"                         ['f', 'm', 'n', 'd', 'v', 'v', 'xc'])

    def test_senta(self):
        senta = hub.Module(name=""senta_bilstm"")
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# limitations under the License.
import os
from unittest import TestCase, main
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
",4
"                (res['data'].all() == results_2[index]['data'].all()), True)
            self.assertEqual(
",4
"    main()
# coding=utf-8
from __future__ import absolute_import
",4
"from __future__ import print_function
",4
"        ""Call tearDown to restore environment.\n""
        self.test_prog = None

",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            print('\n')
",4
"                model_filename='model',
                combined=True)

",4
"
if __name__ == ""__main__"":
    suite = unittest.TestSuite()
",4
"
    def test_single_pic(self):
",4
"                    paths=[pic_path],
",4
"                visualization=True,
                output_dir='batch_out',
                use_multi_scale=True,
",4
"                shrink=0.5,
                confs_threshold=0.6)
            print(result)

",4
"
if __name__ == ""__main__"":
    suite = unittest.TestSuite()
    suite.addTest(TestPyramidBoxLiteServerMask('test_single_pic'))
    suite.addTest(TestPyramidBoxLiteServerMask('test_batch'))
",4
"    runner = unittest.TextTestRunner(verbosity=2)
",4
"import paddlehub as hub
",4
"            if get_prediction:
                bbox_out = outputs['bbox_out']
            else:
",4
"                body_features = outputs['body_features']

",4
"            print(
                self.ssd.object_detection(
                    paths=[
                        os.path.join(image_dir, 'cat.jpg'),
                        os.path.join(image_dir, 'dog.jpg'),
",4
"import paddlehub as hub

content_dir = '../image_dataset/style_tranfer/content/'
style_dir = '../image_dataset/style_tranfer/style/'

",4
"        self.test_prog = None

",4
"                os.path.join(content_dir, f) for f in os.listdir(content_dir)
",4
"                    alpha=0.8,
",4
"                    use_gpu=True)
                t2 = time.time()
                print('\nCost time: {}'.format(t2 - t1))
",4
"                    use_gpu=True,
                    visualization=True)
                print('#' * 100)
",4
"                    output_dir='transfer_out',
                    visualization=True)

",4
"    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
",4
"        self.animal_classify = None

",4
"    def test_single_pic(self):
",4
"                paths=pics_path_list, batch_size=3, use_gpu=False, top_k=2)
",4
"import numpy as np
import paddle.fluid as fluid
",4
"
    def test_single_pic(self):
",4
"            print('\n')
",4
"
    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"# limitations under the License.
import os
from unittest import TestCase, main
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

",4
"        # sequence embedding and token embedding results per sample
        self.assertEqual(len(results[0]), 2)
        self.assertEqual(len(results_2[0]), 2)
",4
"        self.assertEqual(self.module.get_word_dict_path(), None)

    def test_get_vocab_path(self):
",4
"        self.assertEqual(vocab_path, true_vocab_path)

",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.""""""
        self.yolov3 = None

    def setUp(self):
",4
"        self.test_prog = fluid.Program()
        ""Call setUp() to prepare environment\n""
",4
"            zebras = [zebra, zebra]
            detection_results = self.yolov3.object_detection(
                paths=[
",4
"import unittest
",4
"
import cv2
",4
"        self.face_detector = hub.Module(name=""pyramidbox_lite_mobile"")

    @classmethod
",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
        self.face_detector = None
",4
"                dirname='pyramidbox_lite_mobile',
",4
"if __name__ == ""__main__"":
    suite = unittest.TestSuite()
    suite.addTest(TestPyramidBoxLiteMobile('test_single_pic'))
    suite.addTest(TestPyramidBoxLiteMobile('test_ndarray'))
",4
"        """"""clean up the environment after the execution of all tests.\n""""""
        self.human_seg = None

",4
"    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None

    def test_single_pic(self):
",4
"                result = self.human_seg.segmentation(
                    images=[cv2.imread(pic_path)],
                    output_dir='ndarray_output',
                    use_gpu=True,
",4
"                    visualization=True)

    def test_save_inference_model(self):
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"            'sentiment_label': 1,
",4
"            'negative_probs': 0.0593
        },
                        {
                            'text': 'è¿é¨çµå½±ççå¾å·®å²',
",4
"            texts=self.test_text, use_gpu=False, batch_size=1)
        self.assertEqual(results, self.results)
        results = self.module.sentiment_classify(
",4
"
import os
import unittest

",4
"        self.animal_classify = hub.Module(name=""resnet50_vd_animals"")

    @classmethod
",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
        self.animal_classify = None
",4
"        self.animal_classify.context(pretrained=True)

    def test_single_pic(self):
",4
"    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"
    def test_ndarray(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"            ]
",4
"            pics_ndarray = list()
            print('\n')
            for pic_path in pics_path_list:
",4
"                im = cv2.cvtColor(cv2.imread(pic_path), cv2.COLOR_BGR2RGB)
                result = self.animal_classify.classification(
",4
"                    images=np.expand_dims(im, axis=0), use_gpu=False, top_k=5)
                print(result)
",4
"                dirname='resnet50_vd_animals',
                model_filename='model',
                combined=False)
",4
"from __future__ import absolute_import
from __future__ import division
",4
"
    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            print(result)

    def test_ndarray(self):
        with fluid.program_guard(self.test_prog):
",4
"import os
import unittest
",4
"            if get_prediction:
                bbox_out = outputs['bbox_out']
            else:
",4
"                paths=[
                    os.path.join(image_dir, 'bird.jpg'),
                    os.path.join(image_dir, 'bike.jpg'),
",4
"

if __name__ == ""__main__"":
",4
"from __future__ import print_function

import os
import unittest

",4
"class TestMobileNetV2Dish(unittest.TestCase):
    @classmethod
    def setUpClass(self):
        """"""Prepare the environment once before execution of all tests.\n""""""
        self.dish_classify = hub.Module(name=""mobilenet_v2_dishes"")
",4
"
    @classmethod
",4
"
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            print('\n')
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
",4
"            self.dish_classify.save_inference_model(
                dirname='mobilenet_v2_dishes',
                model_filename='model',
                combined=True)

",4
"    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# coding=utf-8
from __future__ import absolute_import
",4
"
pic_dir = '../image_dataset/classification/animals/'

",4
"
class TestResNet50vdAnimal(unittest.TestCase):
",4
"    @classmethod
",4
"        self.test_prog = None
",4
"
    def test_context(self):
        self.classifier.context(pretrained=True)

    def test_single_pic(self):
",4
"            result = self.classifier.classification(
                paths=pics_path_list, batch_size=3, use_gpu=False, top_k=2)
            print(result)
",4
"
",4
"    def test_ndarray(self):
",4
"            ]
            pics_ndarray = list()
",4
"    suite.addTest(TestResNet50vdAnimal('test_ndarray'))
",4
"    suite.addTest(TestResNet50vdAnimal('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# coding=utf-8
",4
"import paddle.fluid as fluid
import paddlehub as hub


",4
"    def test_context(self):
        with fluid.program_guard(self.test_prog):
            image = fluid.layers.data(
                name='image', shape=[3, 224, 224], dtype='float32')
            inputs, outputs, program = self.resnet.context(
",4
"                images=airplanes,
                batch_size=2)
            print(classification_results)

",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"                        }]
        self.labels = {""porn"": 1, ""not_porn"": 0}

",4
"        results = self.module.detection(
",4
"        self.test_prog = fluid.Program()
        ""Call setUp() to prepare environment\n""

    def tearDown(self):
",4
"        ""Call tearDown to restore environment.\n""
        self.test_prog = None
",4
"
    def test_context(self):
        with fluid.program_guard(self.test_prog):
            get_prediction = True
",4
"            image = inputs[""image""]
            im_size = inputs[""im_size""]
            if get_prediction:
",4
"                    paths=[os.path.join(image_dir, 'cat.jpg')]))
            ## only images
            print(self.ssd.object_detection(images=zebras))
",4
"    suite.addTest(TestSSDVGG300('test_object_detection'))
    suite.addTest(TestSSDVGG300('test_context'))
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
",4
"import paddle.fluid as fluid
import paddlehub as hub

image_dir = '../image_dataset/face_detection/'
",4
"import cv2
",4
"    def setUpClass(self):
",4
"        self.test_prog = None
",4
"            image = inputs[""image""]
            im_info = inputs[""im_info""]
",4
"            image_dir = '../image_dataset/object_detection'
            zebra = cv2.imread(os.path.join(image_dir,
                                            'zebra.jpg')).astype('float32')
            zebras = [zebra, zebra]
            detection_results = self.retinanet.object_detection(
",4
"    suite = unittest.TestSuite()
    suite.addTest(TestRetinaNet('test_object_detection'))
    suite.addTest(TestRetinaNet('test_context'))
",4
"from __future__ import division
from __future__ import print_function

import os
",4
"import paddle.fluid as fluid
import paddlehub as hub

pic_dir = '../image_dataset/face_detection'

",4
"        """"""Prepare the environment once before execution of all tests.\n""""""
        self.face_detector = hub.Module(
            name=""ultra_light_fast_generic_face_detector_1mb_640"")
        self.face_detector._initialize()
",4
"
    @classmethod
    def tearDownClass(self):
",4
"        self.face_detector = None
",4
"            ]
            t1 = time.time()
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            t1 = time.time()
            result = self.face_detector.face_detection(
",4
"                paths=pics_path_list,
                batch_size=5,
",4
"            print(result)

    def test_ndarray(self):
        with fluid.program_guard(self.test_prog):
",4
"
import cv2
",4
"        self.wildanimals_classify = hub.Module(name=""resnet50_vd_wildanimals"")

    @classmethod
    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
",4
"    def tearDown(self):
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"                print(result)

    def test_batch(self):
",4
"            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"
    def test_save_inference_model(self):
        with fluid.program_guard(self.test_prog):
            self.wildanimals_classify.save_inference_model(
",4
"                dirname='resnet50_vd_wildanimals',
                model_filename=None,
",4
"        """"""Prepare the environment once before execution of all tests.\n""""""
        self.face_detector = hub.Module(name='pyramidbox_lite_server')

    @classmethod
",4
"        self.test_prog = fluid.Program()

",4
"    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None

",4
"                model_filename='model',
",4
"    suite.addTest(TestPyramidBoxLiteServer('test_single_pic'))
    suite.addTest(TestPyramidBoxLiteServer('test_ndarray'))
    suite.addTest(TestPyramidBoxLiteServer('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
",4
"import unittest

import cv2
",4
"        self.mask_detector = hub.Module(name=""pyramidbox_lite_mobile_mask"")

",4
"    @classmethod
    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
",4
"
    def setUp(self):
        ""Call setUp() to prepare environment\n""
",4
"                print(result)

    def test_batch(self):
        with fluid.program_guard(self.test_prog):
",4
"            paths_list = [os.path.join(pic_dir, f) for f in os.listdir(pic_dir)]
            result = self.mask_detector.face_detection(
                paths=paths_list,
                batch_size=5,
                use_gpu=True,
",4
"                visualization=True,
",4
"            im_list = list()
",4
"    suite.addTest(TestPyramidBoxLiteMobileMask('test_single_pic'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_batch'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_ndarray'))
    suite.addTest(TestPyramidBoxLiteMobileMask('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
",4
"    def setUpClass(self):
        """"""Prepare the environment once before execution of all tests.""""""
",4
"        self.yolov3 = None

    def setUp(self):
        self.test_prog = fluid.Program()
        ""Call setUp() to prepare environment\n""
",4
"
    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None

",4
"            zebra = cv2.imread(os.path.join(image_dir,
                                            'zebra.jpg')).astype('float32')
            zebras = [zebra, zebra]
            detection_results = self.yolov3.object_detection(
",4
"if __name__ == ""__main__"":
    suite = unittest.TestSuite()
    suite.addTest(TestYoloV3MoobileNetV1('test_object_detection'))
    suite.addTest(TestYoloV3MoobileNetV1('test_context'))
",4
"                'tag': ['n', 'n', 'v', 'a', 'w', 'd', 'a', 'w', 'n', 'v', 'd']
            }
        ]
        self.results_notag = [
",4
"            'v': 'æ®éå¨è¯',
            'vd': 'å¨å¯è¯',
            'vn': 'åå¨è¯',
",4
"            'a': 'å½¢å®¹è¯',
            'ad': 'å¯å½¢è¯',
",4
"            'q': 'éè¯',
            'r': 'ä»£è¯',
",4
"        self.assertEqual(self.module.interventer, None)
",4
"
    def test_lexical_analysis(self):
        self.module.del_user_dict()

        # test batch_size
",4
"        results = self.module.lexical_analysis(
            texts=self.test_text, use_gpu=False, batch_size=1, return_tag=False)
        self.assertEqual(results, self.results_notag)
        results = self.module.lexical_analysis(
            texts=self.test_text,
",4
"            use_gpu=False,
            batch_size=10,
            return_tag=False)
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"# you may not use this file except in compliance with the License.
",4
"from unittest import TestCase, main
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
",4
"        self.assertTrue((diff < 1e-6).all)
",4
"        self.assertTrue((diff < 1e-6).all)

    def test_get_params_layer(self):
        self.module.context()
        layers = self.module.get_params_layer()
",4
"
import cv2
import numpy as np
import paddle.fluid as fluid
import paddlehub as hub
",4
"class TestResNet(unittest.TestCase):
",4
"
    @classmethod
    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.""""""
",4
"                    os.path.join(image_dir, 'sheep.jpg'),
                    os.path.join(image_dir, 'train.jpg')
                ],
                images=airplanes,
",4
"    suite.addTest(TestResNet('test_classification'))
    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# coding=utf-8
",4
"
image_dir = '../image_dataset/object_detection/'


class TestYoloV3DarkNet53(unittest.TestCase):
",4
"        """"""Prepare the environment once before execution of all tests.""""""
        self.yolov3 = hub.Module(name=""yolov3_darknet53_coco2017"")

    @classmethod
    def tearDownClass(self):
",4
"            detection_results = self.yolov3.object_detection(
                paths=[
",4
"                    os.path.join(image_dir, 'dog.jpg'),
                    os.path.join(image_dir, 'giraffe.jpg')
                ],
                images=zebras,
                batch_size=2)
",4
"
    def setUp(self):
        ""Call setUp() to prepare environment\n""
        self.test_prog = fluid.Program()

",4
"    def tearDown(self):
",4
"                output_dir='batch_output',
                use_gpu=True,
                visualization=True)
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            for pic_path in pics_path_list:
                result = self.pose.keypoint_detection(
                    images=[cv2.imread(pic_path)],
                    output_dir='ndarray_output',
",4
"    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"            paths=self.test_images, use_gpu=True)
        results_2 = self.module.recognize_text(
",4
"
            for j, item in enumerate(res['data']):
                self.assertEqual(item['confidence'],
                                 results_2[i]['data'][j]['confidence'])
                self.assertEqual(item['confidence'],
",4
"
if __name__ == '__main__':
    main()
# coding=utf-8
from __future__ import absolute_import
",4
"    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None

",4
"    def test_context(self):
        self.classifier.context(pretrained=True)

",4
"    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            print('\n')
            result = self.classifier.classification(
                paths=pics_path_list, batch_size=3, use_gpu=False, top_k=2)
            print(result)

",4
"            print('\n')
            for pic_path in pics_path_list:
                im = cv2.cvtColor(cv2.imread(pic_path), cv2.COLOR_BGR2RGB)
                result = self.classifier.classification(
                    images=[im], use_gpu=True, top_k=5)
",4
"                print(result)
",4
"            self.classifier.save_inference_model(
                dirname='se_resnet18_vd_imagenet_model',
                model_filename='model',
",4
"    suite = unittest.TestSuite()
    suite.addTest(TestSEResnet18vdImagenet('test_single_pic'))
    suite.addTest(TestSEResnet18vdImagenet('test_batch'))
    suite.addTest(TestSEResnet18vdImagenet('test_ndarray'))
    suite.addTest(TestSEResnet18vdImagenet('test_save_inference_model'))
",4
"import unittest
import paddlehub as hub


",4
"                    for key, value in default_expect1.items():
",4
"import paddlehub as hub
",4
"
pic_dir = '../image_dataset/classification/animals/'


",4
"class TestMobileNetV3LargeSSLD(unittest.TestCase):
",4
"        self.animal_classify = None

    def setUp(self):
",4
"            result = self.animal_classify.classification(
",4
"                    images=np.expand_dims(im, axis=0), use_gpu=False)
                print(result)

    def test_save_inference_model(self):
",4
"    runner = unittest.TextTestRunner(verbosity=2)
",4
"    runner.run(suite)
# coding=utf-8
",4
"
",4
"    def tearDown(self):
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            t1 = time.time()
",4
"            ]
",4
"if __name__ == ""__main__"":
    suite = unittest.TestSuite()
    suite.addTest(TestFaceDetector320('test_single_pic'))
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"import paddlehub as hub


",4
"class EmotionDetectionTextCNNTestCase(TestCase):
    def setUp(self):
        self.module = hub.Module(name='emotion_detection_textcnn')
        self.test_text = [""è¿å®¶é¤åå¾å¥½å"", ""è¿é¨çµå½±ççå¾å·®å²""]
        self.results = [{
",4
"            'text': 'è¿å®¶é¤åå¾å¥½å',
            'emotion_label': 1,
",4
"        results = self.module.emotion_classify(
            texts=self.test_text, use_gpu=False, batch_size=1)
        self.assertEqual(results, self.results)
",4
"            texts=self.test_text, use_gpu=True, batch_size=1)
        self.assertEqual(results, self.results)

    def test_get_vocab_path(self):
        true_vocab_path = os.path.join(self.module.directory, ""assets"",
",4
"        self.assertEqual(labels, self.labels)


if __name__ == '__main__':
    main()
",4
"import unittest

",4
"
",4
"
    def setUp(self):
        ""Call setUp() to prepare environment\n""
",4
"        self.test_prog = fluid.Program()
",4
"
",4
"        ""Call tearDown to restore environment.\n""
",4
"import paddle.fluid as fluid
import paddlehub as hub

pic_dir = '../image_dataset/classification/animals/'

",4
"    def setUpClass(self):
",4
"                paths=pics_path_list, batch_size=3, use_gpu=False, top_k=2)
            print(result)

    def test_ndarray(self):
",4
"            ]
            pics_ndarray = list()
            print('\n')
",4
"            for pic_path in pics_path_list:
                im = cv2.cvtColor(cv2.imread(pic_path), cv2.COLOR_BGR2RGB)
                result = self.classifier.classification(
",4
"    def test_save_inference_model(self):
        with fluid.program_guard(self.test_prog):
            self.classifier.save_inference_model(
",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
        self.animal_classify = None
",4
"
    def setUp(self):
",4
"            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            print('\n')
            for pic_path in pics_path_list:
",4
"    def test_batch(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"            print('\n')
",4
"            result = self.animal_classify.classification(
                paths=pics_path_list, batch_size=3, use_gpu=False)
            print(result)

",4
"    suite.addTest(TestMobileNetV3SmallSSLD('test_context'))
    suite.addTest(TestMobileNetV3SmallSSLD('test_single_pic'))
    suite.addTest(TestMobileNetV3SmallSSLD('test_batch'))
",4
"        self.mobilenet_v1 = hub.Module(name='mobilenet_v1_imagenet')

    @classmethod
    def tearDownClass(self):
",4
"                    os.path.join(image_dir, 'train.jpg')
",4
"        """"""clean up the environment after the execution of all tests.""""""
",4
"
    def tearDown(self):
        ""Call tearDown to restore environment.\n""
",4
"        self.test_prog = None

    def test_context(self):
        with fluid.program_guard(self.test_prog):
",4
"import cv2
import numpy as np
",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
",4
"                im = cv2.imread(pic_path)
                result = self.animal_classify.classification(
",4
"    runner.run(suite)
# coding=utf-8
import os
import unittest

",4
"        # self.mobilenet_v1 = hub.Module(name=""mobilenet_v1"")
        self.vgg16 = hub.Module(name='vgg16_imagenet')
",4
"
    @classmethod
",4
"                    os.path.join(image_dir, 'train.jpg')
                ],
                images=airplanes,
",4
"        self.test_prog = fluid.Program()
",4
"
    def tearDown(self):
        ""Call tearDown to restore environment.\n""
        self.test_prog = None
",4
"                batch_size=2)
            print(classification_results)


if __name__ == ""__main__"":
",4
"    runner = unittest.TextTestRunner(verbosity=2)
    runner.run(suite)
",4
"from unittest import TestCase, main
",4
"os.environ['CUDA_VISIBLE_DEVICES'] = '0'
",4
"        self.assertEqual(len(results_2[0]), 2)
        # sequence embedding shape
        self.assertEqual(results[0][0].shape, (768, ))
        self.assertEqual(results_2[0][0].shape, (768, ))
",4
"        self.assertEqual(results_2[0][1].shape, (512, 768))

        # test gpu
        results_3 = self.module.get_embedding(
            texts=self.test_text, use_gpu=True, batch_size=1)
",4
"        diff = np.abs(results[0][1] - results_3[0][1])
        self.assertTrue((diff < 1e-6).all)
",4
"        self.assertEqual(layers, true_layers)
",4
"
pic_dir = '../image_dataset/semantic_segmentation/'
",4
"        ""Call setUp() to prepare environment\n""
        self.test_prog = fluid.Program()

    def tearDown(self):
",4
"            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"                result = self.human_parsing.segmentation(
",4
"            self.human_parsing.save_inference_model(
                dirname='ace2p', model_filename='model', combined=True)
",4
"

if __name__ == ""__main__"":
    suite = unittest.TestSuite()
",4
"    runner.run(suite)
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
        self.face_detector = None

",4
"        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
            for pic_path in pics_path_list:
",4
"    def test_ndarray(self):
        with fluid.program_guard(self.test_prog):
            pics_path_list = [
                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
",4
"if __name__ == ""__main__"":
    suite = unittest.TestSuite()
",4
"            inputs, outputs, program = self.faster_rcnn_r50_fpn.context(
                pretrained=False, trainable=True, phase='train')
            image = inputs['image']
            im_info = inputs['im_info']
",4
"            gt_class = inputs['gt_class']
            gt_bbox = inputs['gt_bbox']
            is_crowd = inputs['is_crowd']
            head_feat = outputs['head_feat']
            rpn_cls_loss = outputs['rpn_cls_loss']
",4
"from __future__ import absolute_import
from __future__ import division
",4
"import paddle.fluid as fluid
",4
"
    @classmethod
    def tearDownClass(self):
        """"""clean up the environment after the execution of all tests.\n""""""
",4
"        self.dish_classify = None

    def setUp(self):
        ""Call setUp() to prepare environment\n""
        self.test_prog = fluid.Program()
",4
"        with fluid.program_guard(self.test_prog):
",4
"            ]
",4
"            pics_path_list = [
",4
"                os.path.join(pic_dir, f) for f in os.listdir(pic_dir)
            ]
",4
"                combined=True)

",4
"    suite.addTest(TestResNet50vdDish('test_ndarray'))
    suite.addTest(TestResNet50vdDish('test_save_inference_model'))
    runner = unittest.TextTestRunner(verbosity=2)
",4
"
    def tearDown(self):
",4
"            gt_class = inputs['gt_class']
            gt_bbox = inputs['gt_bbox']
            is_crowd = inputs['is_crowd']
",4
"            generate_proposal_labels = outputs['generate_proposal_labels']

    def test_object_detection(self):
        with fluid.program_guard(self.test_prog):
",4
"

if __name__ == ""__main__"":
",4
"    runner.run(suite)
from __future__ import print_function
from __future__ import division
from __future__ import print_function
",4
"        lasttime = 0
    if time.time() - lasttime >= FLUSH_INTERVAL:
        sys.stdout.write(""\r%s"" % str)
        lasttime = time.time()
",4
"            total_length = r.headers.get('content-length')
",4
"                    starttime = time.time()
                    if print_progress:
",4
"            print(""Uncompress %s"" % file)
        flag = ""r:gz"" if file.endswith(""tar.gz"") else ""r:""
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
        tar_filter = lambda tarinfo: None if any([
            exclude_file_name in tarinfo.name.replace(name + os.sep, """")
            for exclude_file_name in config.get(""exclude"", [])
        ]) else tarinfo
",4
"                if item.startswith('version'):
                    module_version = item.split('=')[1].replace(',', '')
                if item.startswith('name'):
                    module_name = item.split('=')[1].replace(',', '')
",4
"import paddlehub as hub
from paddlehub.common.paddle_helper import add_vars_prefix
",4
"from paddlehub.module.module import moduleinfo, serving
",4
"        """"""
        initialize with the necessary elements
        """"""
        self.pretrained_model_path = os.path.join(self.directory, ""infer_model"")
        self.vocab_path = os.path.join(self.directory, ""assets/vocab.txt"")
",4
"        """"""
",4
"            self._word_seg_module = hub.Module(name=""lac"")
",4
"        return self._word_seg_module

    def context(self, trainable=False):
",4
"        """"""
        Get the input ,output and program of the pretrained senta_gru
",4
"                return os.path.exists(
                    os.path.join(self.pretrained_model_path, var.name))

",4
"                main_program.global_block().vars[prefix_name + data_name]
            }
            outputs = {
                ""class_probs"":
                main_program.global_block().vars[prefix_name + pred_name],
",4
"                ""sentence_feature"":
                main_program.global_block().vars[prefix_name + fc_name]
            }
",4
"             data(dict): key must be 'text', value is the texts to be predicted, if data not texts
             use_gpu(bool): whether use gpu to predict or not
             batch_size(int): the program deals once with one batch

",4
"        Returns:
             results(list): the word segmentation results
        """"""
        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"                                           self.word_dict, use_gpu, batch_size)
            tensor_words = self.texts2tensor(processed_results)
",4
"
",4
"    def get_labels(self):
        """"""
        Get the labels which was used when pretraining
",4
"        return self.labels


if __name__ == ""__main__"":
    senta = SentaGRU()
",4
"    # Data to be predicted
",4
"    results = senta.sentiment_classify(data=input_dict)
    for index, result in enumerate(results):
        if six.PY2:
            print(
                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
",4
"            print(results[index])
# -*- coding:utf-8 -*-
import io
import numpy as np

",4
"            parts = line.rstrip().split('\t')
            vocab[parts[0]] = int(parts[1])
    vocab[""<unk>""] = len(vocab)
",4
"    """"""
    result = []
    input_dict = {'text': texts}
    processed = lac.lexical_analysis(
",4
"    return result


def postprocess(predict_out, texts):
    """"""
",4
"        result_i = {}
        result_i['text'] = texts[index]['origin']
        label = int(np.argmax(predict_out[index]))
        if label == 0:
            key = 'negative'
",4
"
    # full connect layer
",4
"from emotion_detection_textcnn.processor import load_vocab, preprocess, postprocess


",4
"    author_email="""",
    type=""nlp/sentiment_analysis"")
class EmotionDetectionTextCNN(hub.NLPPredictionModule):
",4
"        self._word_seg_module = None

        self.predict = self.emotion_classify

",4
"        if not self._word_seg_module:
            self._word_seg_module = hub.Module(name=""lac"")
",4
"        Args:
             trainable(bool): whether fine-tune the pretrained parameters of emotion_detection_textcnn or not
",4
"        main_program = fluid.Program()
        startup_program = fluid.Program()
        with fluid.program_guard(main_program, startup_program):
",4
"            }
            outputs = {
",4
"                main_program.global_block().vars[prefix_name + pred_name],
                ""sentence_feature"":
                main_program.global_block().vars[prefix_name + fc_name]
            }

",4
"        Args:
             texts(list): the input texts to be predicted, if texts not data
             data(dict): key must be 'text', value is the texts to be predicted, if data not texts
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
",4
"            predicted_data = texts
        elif texts == [] and isinstance(data, dict) and isinstance(
                data.get('text', None), list) and data['text']:
",4
"    return result
# -*- coding:utf-8 -*-
import paddle.fluid as fluid


",4
"    """"""
",4
"    if win_sizes is None:
",4
"        win_sizes = [1, 2, 3]

    # embedding layer
    emb = fluid.layers.embedding(input=data, size=[dict_dim, emb_dim])

",4
"from paddlehub.common.paddle_helper import add_vars_prefix
from paddlehub.module.module import moduleinfo, serving

from senta_bilstm.net import bilstm_net
",4
"    def _initialize(self):
        """"""
        initialize with the necessary elements
        """"""
        self.pretrained_model_path = os.path.join(self.directory, ""infer_model"")
",4
"        self.predict = self.sentiment_classify

        self._set_config()
",4
"        Args:
             trainable(bool): whether fine-tune the pretrained parameters of senta_bilstm or not

        Returns:
             inputs(dict): the input variables of senta_bilstm (words)
",4
"
            prefix_name = ""@HUB_{}@"".format(self.name)
            add_vars_prefix(program=main_program, prefix=prefix_name)

",4
"            inputs = {
                ""words"":
                main_program.global_block().vars[prefix_name + data_name]
",4
"            }
            outputs = {
                ""class_probs"":
                main_program.global_block().vars[prefix_name + pred_name],
                ""sentence_feature"":
",4
"             data(dict): key must be 'text', value is the texts to be predicted, if data not texts
",4
"            int(_places[0])
        except:
            use_gpu = False

        if texts != [] and isinstance(texts, list) and data == {}:
",4
"        predicted_data = self.to_unicode(predicted_data)
        start_idx = 0
        iteration = int(math.ceil(len(predicted_data) / batch_size))
",4
"                batch_out = self.gpu_predictor.run([tensor_words])
            else:
                batch_out = self.cpu_predictor.run([tensor_words])
",4
"
if __name__ == ""__main__"":
",4
"    senta = SentaBiLSTM()
    # Data to be predicted
    test_text = [""è¿å®¶é¤åå¾å¥½å"", ""è¿é¨çµå½±ççå¾å·®å²""]

",4
"    unk_id = word_dict[""<unk>""]
    for index, data in enumerate(processed):
",4
"        result_i = {'processed': []}
        result_i['origin'] = texts[index]
",4
"    batch_size = len(texts)
",4
"        result_i['positive_probs'] = float('%.4f' % predict_out[index, 1])
        result_i['negative_probs'] = float('%.4f' % (1 - predict_out[index, 1]))
        result.append(result_i)
    return result
# -*- coding:utf-8 -*-
",4
"import paddle.fluid as fluid

",4
"               emb_dim=128,
               hid_dim=128,
               hid_dim2=96,
               class_dim=2,
               emb_lr=30.0):
",4
"    )

    # bi-lstm layer
",4
"    rfc0 = fluid.layers.fc(input=emb, size=hid_dim * 4)
    lstm_h, c = fluid.layers.dynamic_lstm(
        input=fc0, size=hid_dim * 4, is_reverse=False)
    rlstm_h, c = fluid.layers.dynamic_lstm(
",4
"        input=rfc0, size=hid_dim * 4, is_reverse=True)

",4
"    # extract last layer
    lstm_last = fluid.layers.sequence_last_step(input=lstm_h)
    rlstm_last = fluid.layers.sequence_last_step(input=rlstm_h)
    lstm_last_tanh = fluid.layers.tanh(lstm_last)
    rlstm_last_tanh = fluid.layers.tanh(rlstm_last)
",4
"from __future__ import division
from __future__ import print_function

",4
"
import paddle.fluid as fluid
import paddlehub as hub
from paddlehub.common.paddle_helper import add_vars_prefix
",4
"    name=""senta_bow"",
",4
"        self._word_seg_module = None
",4
"        Get the input ,output and program of the pretrained senta_bow

        Args:
",4
"             inputs(dict): the input variables of senta_bow (words)
",4
"        startup_program = fluid.Program()
        with fluid.program_guard(main_program, startup_program):
            data = fluid.layers.data(
",4
"            # load the senta_bow pretrained model
            def if_exist(var):
                return os.path.exists(
                    os.path.join(self.pretrained_model_path, var.name))

",4
"                main_program.global_block().vars[prefix_name + pred_name],
                ""sentence_feature"":
                main_program.global_block().vars[prefix_name + fc_name]
            }

",4
"    def get_labels(self):
        """"""
        Get the labels which was used when pretraining
        Returns:
             self.labels(dict)
",4
"                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
",4
"
",4
"def load_vocab(file_path):
    """"""
",4
"            if word in word_dict:
",4
"                _index = word_dict[word]
            else:
                _index = unk_id
            result_i['processed'].append(_index)
",4
"def postprocess(predict_out, texts):
    """"""
    Convert model's output tensor to sentiment label
    """"""
    predict_out = predict_out.as_ndarray()
",4
"        result_i['text'] = texts[index]['origin']
        label = int(np.argmax(predict_out[index]))
        if label == 0:
            key = 'negative'
        else:
",4
"
    return prediction, fc_2
",4
"import os
import six

",4
"    version=""1.1.0"",
",4
"    type=""nlp/sentiment_analysis"")
class SentaCNN(hub.NLPPredictionModule):
    def _initialize(self, user_dict=None):
",4
"        """"""
        initialize with the necessary elements
        """"""
        self.pretrained_model_path = os.path.join(self.directory, ""infer_model"")
        self.vocab_path = os.path.join(self.directory, ""assets/vocab.txt"")
",4
"
            fluid.io.load_vars(
                exe, self.pretrained_model_path, predicate=if_exist)

            inputs = {
",4
"        Get the sentiment prediction results results with the texts as input

",4
"            else:
                batch_data = predicted_data[start_idx:]
",4
"             self.labels(dict)
        """"""
        self.labels = {""positive"": 1, ""negative"": 0}
        return self.labels

",4
"                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
            print(results[index])
    results = senta.sentiment_classify(texts=test_text)
    for index, result in enumerate(results):
",4
"        if six.PY2:
            print(
                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
",4
"

",4
"def load_vocab(file_path):
",4
"    with io.open(file_path, 'r', encoding='utf8') as f:
        wid = 0
        for line in f:
            parts = line.rstrip().split('\t')
",4
"    """"""
    predict_out = predict_out.as_ndarray()
    batch_size = len(texts)
    result = []
",4
"import json
import math
",4
"    name=""senta_lstm"",
    version=""1.1.0"",
    summary=""Baidu's open-source Sentiment Classification System."",
",4
"        """"""
        self.module_name = 'senta_lstm'
",4
"        self.pretrained_model_path = os.path.join(self.directory, ""infer_model"")
        self.vocab_path = os.path.join(self.directory, ""assets"", ""vocab.txt"")
        self.word_dict = load_vocab(self.vocab_path)
        self._word_seg_module = None

",4
"                ""words"":
                main_program.global_block().vars[prefix_name + data_name]
            }
            outputs = {
                ""class_probs"":
",4
"            print(
                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
            print(results[index])
",4
"# -*- coding:utf-8 -*-
import io
import numpy as np


",4
"def load_vocab(file_path):
    """"""
    load the given vocabulary
    """"""
",4
"    then, the word segmention results input into senta
    """"""
",4
"    batch_size = len(texts)
    result = []
",4
"             hid_dim=128,
",4
"             emb_lr=30.0):
    """"""
    Lstm net
    """"""
    # embedding layer
",4
"# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"from paddlehub.module.module import moduleinfo

from rbt3.model.bert import BertConfig, BertModel
",4
"    type=""nlp/semantic_model"",
",4
"    def net(self, input_ids, position_ids, segment_ids, input_mask):
        """"""
",4
"            sequence_output (tensor): token-level output for sequence task.
        """"""
",4
"        bert = BertModel(
            src_ids=input_ids,
            position_ids=position_ids,
            sentence_ids=segment_ids,
",4
"        return pooled_output, sequence_output


if __name__ == '__main__':
    test_module = BertWwm()
",4
"

def multi_head_attention(queries,
",4
"    they will not considered in attention weights.
    """"""
    keys = queries if keys is None else keys
",4
"        """"""
        Add linear projection to queries, keys, and values.
        """"""
",4
"            bias_attr=name + '_value_fc.b_0')
",4
"    def __split_heads(x, n_head):
        """"""
        Reshape the last dimension of inpunt tensor x so that it becomes two
",4
"        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
",4
"        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
",4
"        reshaped = layers.reshape(
",4
"            x=x, shape=[0, 0, n_head, hidden_size // n_head], inplace=True)

",4
"        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
                dropout_prob=dropout_rate,
",4
"        input=out,
        size=d_model,
",4
"                              d_hid,
                              dropout_rate,
                              hidden_act,
",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_0.b_0')
    if dropout_rate:
",4
"        size=d_hid,
",4
"        num_flatten_dims=2,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
    return out
",4
"                           name=''):
    """"""
    Add residual connection, layer normalization and droput to the out tensor
",4
"                    dropout_prob=dropout_rate,
                    dropout_implementation=""upscale_in_train"",
                    is_test=False)
",4
"    return out
",4
"                  d_inner_hid,
                  prepostprocess_dropout,
                  attention_dropout,
",4
"                  relu_dropout,
                  hidden_act,
                  preprocess_cmd=""n"",
                  postprocess_cmd=""da"",
",4
"        pre_process_layer(
            enc_input,
",4
"        relu_dropout,
        hidden_act,
",4
"            param_initializer=None,
            name=''):
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"                 input_mask,
                 config,
                 weight_sharing=True,
                 use_fp16=False):

",4
"        self._sent_types = config['type_vocab_size']
        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
",4
"        sent_emb_out = fluid.layers.embedding(
",4
"
        emb_out = emb_out + position_emb_out
        emb_out = emb_out + sent_emb_out

",4
"        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

        if self._dtype == ""float16"":
",4
"        self_attn_mask = fluid.layers.matmul(
",4
"            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

        self._enc_out = encoder(
            enc_input=emb_out,
",4
"            input=self._enc_out, axes=[1], starts=[0], ends=[1])
",4
"        next_sent_feat = fluid.layers.fc(
            input=next_sent_feat,
",4
"
",4
"        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')

        # extract the first token feature in each sentence
        next_sent_feat = self.get_pooled_output()
",4
"                name='mask_lm_trans_fc.w_0',
                initializer=self._param_initializer),
            bias_attr=fluid.ParamAttr(name='mask_lm_trans_fc.b_0'))
        # transform: layer norm
",4
"                transpose_y=True)
            fc_out += fluid.layers.create_parameter(
                shape=[self._voc_size],
                dtype=self._dtype,
                attr=mask_lm_out_bias_attr,
",4
"                bias_attr=mask_lm_out_bias_attr)

        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)
",4
"            logits=next_sent_fc_out, label=labels, return_softmax=True)

        next_sent_acc = fluid.layers.accuracy(
            input=next_sent_softmax, label=labels)
",4
"
",4
"from __future__ import division
from __future__ import print_function

import os

",4
"        Args:
            input_ids (tensor): the word ids.
            position_ids (tensor): the position ids.
",4
"            segment_ids (tensor): the segment ids.
",4
"        ernie = ErnieModel(
            src_ids=input_ids,
            position_ids=position_ids,
            sentence_ids=segment_ids,
            input_mask=input_mask,
",4
"
",4
"    test_module = Ernie()
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
""""""Transformer encoder.""""""

",4
"def multi_head_attention(queries,
",4
"                         d_key,
",4
"    they will not considered in attention weights.
    """"""
    keys = queries if keys is None else keys
    values = keys if values is None else values

",4
"        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
",4
"        if len(x.shape) == 3: return x
        if len(x.shape) != 4:
            raise ValueError(""Input(x) should be a 4-D Tensor."")
",4
"        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
                dropout_prob=dropout_rate,
",4
"        return out

",4
"        # Since the inplace reshape in __split_heads changes the shape of k and
        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
        k = cache[""k""] = layers.concat(
            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
",4
"    q = __split_heads(q, n_head)
    k = __split_heads(k, n_head)
",4
"        size=d_model,
        num_flatten_dims=2,
        param_attr=fluid.ParamAttr(
",4
"        bias_attr=name + '_output_fc.b_0')
    return proj_out


",4
"                              hidden_act,
                              param_initializer=None,
                              name='ffn'):
    """"""
    Position-wise Feed-Forward Networks.
",4
"

",4
"    """"""
    for cmd in process_cmd:
",4
"        if cmd == ""a"":  # add residual connection
",4
"
def encoder_layer(enc_input,
",4
"                  d_key,
                  d_value,
                  d_model,
",4
"                  prepostprocess_dropout,
                  attention_dropout,
                  relu_dropout,
",4
"        attn_output,
        postprocess_cmd,
        prepostprocess_dropout,
        name=name + '_post_att')
    ffd_output = positionwise_feed_forward(
",4
"        d_model,
",4
"

def encoder(enc_input,
            attn_bias,
",4
"            n_layer,
            n_head,
            d_key,
            d_value,
            d_model,
",4
"            preprocess_cmd=""n"",
",4
"            d_value,
",4
"            name=name + '_layer_' + str(i))
        enc_input = enc_output
    enc_output = pre_process_layer(
",4
"
",4
"    def _parse(self, config_path):
        try:
            with open(config_path, 'r', encoding='utf8') as json_file:
                config_dict = json.load(json_file)
",4
"                 input_mask,
",4
"                 weight_sharing=True,
                 use_fp16=False):

",4
"        self._pos_emb_name = ""pos_embedding""
        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""
",4
"            is_sparse=False)
",4
"
        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))
",4
"
        if self._dtype == ""float16"":
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)
        self_attn_mask = fluid.layers.matmul(
            x=input_mask, y=input_mask, transpose_y=True)
",4
"        n_head_self_attn_mask.stop_gradient = True

",4
"    def get_pretraining_output(self, mask_label, mask_pos, labels):
",4
"        # extract the first token feature in each sentence
        next_sent_feat = self.get_pooled_output()
        reshaped_emb_out = fluid.layers.reshape(
            x=self._enc_out, shape=[-1, self._emb_size])
        # extract masked tokens' feature
",4
"                initializer=self._param_initializer),
            bias_attr=fluid.ParamAttr(name='mask_lm_trans_fc.b_0'))
        # transform: layer norm
        mask_trans_feat = pre_process_layer(
            mask_trans_feat, 'n', name='mask_lm_trans')
",4
"            param_attr=fluid.ParamAttr(
                name=""next_sent_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""next_sent_fc.b_0"")

",4
"            logits=next_sent_fc_out, label=labels, return_softmax=True)

        next_sent_acc = fluid.layers.accuracy(
            input=next_sent_softmax, label=labels)
",4
"# Unless required by applicable law or agreed to in writing, software
",4
"
import os

",4
"
from chinese_bert_wwm_ext.model.bert import BertConfig, BertModel


",4
"            input_mask (tensor): the padding mask.
",4
"from __future__ import absolute_import
from __future__ import division
",4
"import paddle.fluid as fluid
import paddle.fluid.layers as layers


",4
"                         n_head=1,
",4
"    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
",4
"        k = layers.fc(
            input=keys,
            size=d_key * n_head,
",4
"        out = layers.matmul(weights, v)
        return out
",4
"
    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

    if cache is not None:  # use cache and concat time steps
        # Since the inplace reshape in __split_heads changes the shape of k and
",4
"            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
        v = cache[""v""] = layers.concat(
            [layers.reshape(cache[""v""], shape=[0, 0, d_model]), v], axis=1)

",4
"    q = __split_heads(q, n_head)
    k = __split_heads(k, n_head)
    v = __split_heads(v, n_head)
",4
"                              d_inner_hid,
                              d_hid,
",4
"        size=d_inner_hid,
        num_flatten_dims=2,
        act=hidden_act,
        param_attr=fluid.ParamAttr(
",4
"            hidden,
            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
",4
"        input=hidden,
",4
"
def pre_post_process_layer(prev_out, out, process_cmd, dropout_rate=0.,
                           name=''):
    """"""
    Add residual connection, layer normalization and droput to the out tensor
",4
"def encoder_layer(enc_input,
                  attn_bias,
                  n_head,
                  d_key,
                  d_value,
",4
"            d_value,
            d_model,
            d_inner_hid,
            prepostprocess_dropout,
            attention_dropout,
",4
"            postprocess_cmd=""da"",
            param_initializer=None,
            name=''):
",4
"    encoder_layer.
    """"""
    for i in range(n_layer):
        enc_output = encoder_layer(
",4
"            enc_input,
            attn_bias,
            n_head,
            d_key,
            d_value,
",4
"            preprocess_cmd,
            postprocess_cmd,
            param_initializer=param_initializer,
            name=name + '_layer_' + str(i))
        enc_input = enc_output
",4
"    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"from __future__ import division
from __future__ import print_function

import six
import json
",4
"
    def _parse(self, config_path):
        try:
            with open(config_path) as json_file:
                config_dict = json.load(json_file)
",4
"                 sentence_ids,
",4
"        self._max_position_seq_len = config['max_position_embeddings']
        self._sent_types = config['type_vocab_size']
",4
"        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing
",4
"        self._word_emb_name = ""word_embedding""
        self._pos_emb_name = ""pos_embedding""
        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._word_emb_name, initializer=self._param_initializer),
            is_sparse=False)
        position_emb_out = fluid.layers.embedding(
",4
"
        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')
",4
"            n_layer=self._n_layer,
            n_head=self._n_head,
            d_key=self._emb_size // self._n_head,
            d_value=self._emb_size // self._n_head,
            d_model=self._emb_size,
",4
"            postprocess_cmd=""dan"",
",4
"            input=next_sent_feat,
            size=self._emb_size,
",4
"            act=""tanh"",
            param_attr=fluid.ParamAttr(
                name=""pooled_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""pooled_fc.b_0"")
        return next_sent_feat
",4
"                name='mask_lm_trans_fc.w_0',
                initializer=self._param_initializer),
",4
"                input=mask_trans_feat,
                size=self._voc_size,
                param_attr=fluid.ParamAttr(
",4
"                    name=""mask_lm_out_fc.w_0"",
                    initializer=self._param_initializer),
                bias_attr=mask_lm_out_bias_attr)
",4
"            input=next_sent_softmax, label=labels)
",4
"

@moduleinfo(
    name=""bert_chinese_L-12_H-768_A-12"",
    version=""1.1.0"",
",4
"        self.MAX_SEQ_LEN = 512
        self.params_path = os.path.join(self.directory, ""assets"", ""params"")
        self.vocab_path = os.path.join(self.directory, ""assets"", ""vocab.txt"")

        bert_config_path = os.path.join(self.directory, ""assets"",
",4
"
        Args:
            input_ids (tensor): the word ids.
            position_ids (tensor): the position ids.
            segment_ids (tensor): the segment ids.
",4
"        bert = BertModel(
            src_ids=input_ids,
            position_ids=position_ids,
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"
",4
"    Multi-Head Attention. Note that attn_bias is added to the logit before
    computing softmax activiation to mask certain selected positions so that
    they will not considered in attention weights.
",4
"            param_attr=fluid.ParamAttr(
                name=name + '_query_fc.w_0', initializer=param_initializer),
            bias_attr=name + '_query_fc.b_0')
",4
"        [bs, max_sequence_length, n_head * hidden_dim] then output a tensor
        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
        # The value 0 in shape attr means copying the corresponding dimension
",4
"            product += attn_bias
",4
"        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
",4
"        bias_attr=name + '_output_fc.b_0')
",4
"    return proj_out

",4
"        input=x,
",4
"        act=hidden_act,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
",4
"        bias_attr=name + '_fc_0.b_0')
    if dropout_rate:
        hidden = layers.dropout(
",4
"            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
",4
"                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
post_process_layer = pre_post_process_layer
",4
"                  n_head,
                  d_key,
",4
"            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_att'),
        None,
        None,
",4
"        name=name + '_multi_head_att')
    attn_output = post_process_layer(
        enc_input,
        attn_output,
",4
"        ffd_output,
        postprocess_cmd,
",4
"            attn_bias,
",4
"            d_value,
            d_model,
            d_inner_hid,
            prepostprocess_dropout,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
""""""BERT model.""""""
",4
"
",4
"

",4
"        self._n_head = config['num_attention_heads']
        self._voc_size = config['vocab_size']
        self._max_position_seq_len = config['max_position_embeddings']
        self._sent_types = config['type_vocab_size']
",4
"        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing
",4
"        emb_out = fluid.layers.embedding(
            input=src_ids,
",4
"                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
",4
"            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

        self._enc_out = encoder(
            enc_input=emb_out,
",4
"            postprocess_cmd=""dan"",
            param_initializer=self._param_initializer,
",4
"            name=""mask_lm_out_fc.b_0"",
            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
",4
"                dtype=self._dtype,
",4
"                attr=mask_lm_out_bias_attr,
                is_bias=True)

",4
"            fc_out = fluid.layers.fc(
                input=mask_trans_feat,
                size=self._voc_size,
",4
"        return next_sent_acc, mean_mask_lm_loss, loss
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
",4
"
@moduleinfo(
",4
"            use_fp16=False)
        pooled_output = bert.get_pooled_output()
        sequence_output = bert.get_sequence_output()
        return pooled_output, sequence_output

",4
"# You may obtain a copy of the License at
#
",4
"                         keys,
                         values,
                         attn_bias,
                         d_key,
",4
"        """"""
        Transpose and then reshape the last two dimensions of inpunt tensor x
        so that it becomes one dimension, which is reverse to __split_heads.
        """"""
        if len(x.shape) == 3: return x
",4
"    ctx_multiheads = scaled_dot_product_attention(q, k, v, attn_bias, d_key,
",4
"                                                  dropout_rate)

    out = __combine_heads(ctx_multiheads)

",4
"    Position-wise Feed-Forward Networks.
    This module consists of two linear transformations with a ReLU activation
",4
"        input=hidden,
        size=d_hid,
",4
"                param_attr=fluid.ParamAttr(
",4
"                  n_head,
",4
"        attn_output,
",4
"            attn_output,
            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_ffn'),
",4
"        prepostprocess_dropout,
        name=name + '_post_ffn')


def encoder(enc_input,
",4
"            attn_bias,
",4
"            param_initializer=None,
            name=''):
    """"""
    The encoder is composed of a stack of identical layers returned by calling
    encoder_layer.
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
""""""BERT model.""""""

",4
"
",4
"                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
            return config_dict

",4
"        self._sent_types = config['type_vocab_size']
        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
",4
"        # will be initialized by constant zero by default.
        self._param_initializer = fluid.initializer.TruncatedNormal(
",4
"            scale=config['initializer_range'])

        self._build_model(src_ids, position_ids, sentence_ids, input_mask)

    def _build_model(self, src_ids, position_ids, sentence_ids, input_mask):
",4
"        # padding id in vocabulary must be set to 0
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))

",4
"
        self_attn_mask = fluid.layers.matmul(
",4
"        n_head_self_attn_mask.stop_gradient = True
",4
"
    def get_pooled_output(self):
        """"""Get the first feature of each sequence for classification""""""

",4
"        next_sent_feat = fluid.layers.slice(
            input=self._enc_out, axes=[1], starts=[0], ends=[1])
        next_sent_feat = fluid.layers.fc(
            input=next_sent_feat,
            size=self._emb_size,
",4
"            mask_trans_feat, 'n', name='mask_lm_trans')

",4
"            fc_out = fluid.layers.matmul(
",4
"                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
",4
"
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"from __future__ import division
from __future__ import print_function
",4
"from paddlehub.module.module import moduleinfo
",4
"    version=""1.0.0"",
    summary=""chinese-bert-wwm, 12-layer, 768-hidden, 12-heads, 110M parameters "",
    author=""ymcui"",
    author_email=""ymcui@ir.hit.edu.cn"",
",4
"    type=""nlp/semantic_model"",
)
class BertWwm(TransformerModule):
    def _initialize(self):
",4
"        """"""
        bert = BertModel(
            src_ids=input_ids,
",4
"        pooled_output = bert.get_pooled_output()
        sequence_output = bert.get_sequence_output()
        return pooled_output, sequence_output
",4
"# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"import paddle.fluid as fluid
import paddle.fluid.layers as layers


def multi_head_attention(queries,
",4
"        """"""
        q = layers.fc(
",4
"            input=queries,
",4
"        k = layers.fc(
            input=keys,
            size=d_key * n_head,
",4
"        """"""
",4
"
    if cache is not None:  # use cache and concat time steps
        # Since the inplace reshape in __split_heads changes the shape of k and
        # v, which is the cache input for next time step, reshape the cache
",4
"
def positionwise_feed_forward(x,
                              d_inner_hid,
                              d_hid,
                              dropout_rate,
",4
"        act=hidden_act,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_0.b_0')
    if dropout_rate:
",4
"                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
",4
"        param_initializer=param_initializer,
        name=name + '_multi_head_att')
",4
"            prepostprocess_dropout,
            name=name + '_pre_ffn'),
",4
"        attn_output,
        ffd_output,
        postprocess_cmd,
        prepostprocess_dropout,
        name=name + '_post_ffn')
",4
"        enc_input = enc_output
    enc_output = pre_process_layer(
        enc_output, preprocess_cmd, prepostprocess_dropout, name=""post_encoder"")

    return enc_output
",4
"# you may not use this file except in compliance with the License.
",4
"
import six
import json
",4
"
import paddle.fluid as fluid

",4
"from chinese_bert_wwm.model.transformer_encoder import encoder, pre_process_layer

",4
"        except Exception:
",4
"                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
            return config_dict

",4
"    def __getitem__(self, key):
        return self._config_dict[key]
",4
"                 use_fp16=False):
",4
"        self._max_position_seq_len = config['max_position_embeddings']
        self._sent_types = config['type_vocab_size']
        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
",4
"        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing
",4
"        self._pos_emb_name = ""pos_embedding""
        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""

        # Initialize all weigths by truncated normal initializer, and all biases
",4
"        # will be initialized by constant zero by default.
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))
",4
"
        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
            size=[self._sent_types, self._emb_size],
            dtype=self._dtype,
",4
"
        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')
",4
"        n_head_self_attn_mask.stop_gradient = True

        self._enc_out = encoder(
",4
"            d_model=self._emb_size,
            d_inner_hid=self._emb_size * 4,
            prepostprocess_dropout=self._prepostprocess_dropout,
",4
"            postprocess_cmd=""dan"",
            param_initializer=self._param_initializer,
            name='encoder')
",4
"
    def get_pooled_output(self):
        """"""Get the first feature of each sequence for classification""""""

",4
"                param_attr=fluid.ParamAttr(
                    name=""mask_lm_out_fc.w_0"",
                    initializer=self._param_initializer),
                bias_attr=mask_lm_out_bias_attr)
",4
"
        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
",4
"    author=""baidu-nlp"",
",4
"    author_email="""",
",4
"        Args:
",4
"            use_fp16=False)
        pooled_output = ernie.get_pooled_output()
        sequence_output = ernie.get_sequence_output()
        return pooled_output, sequence_output

",4
"
from __future__ import absolute_import
",4
"
from functools import partial
",4
"                         n_head=1,
                         dropout_rate=0.,
",4
"            num_flatten_dims=2,
",4
"        # size of the input as the output dimension size.
        reshaped = layers.reshape(
",4
"
        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
        return layers.reshape(
",4
"                is_test=False)
        out = layers.matmul(weights, v)
",4
"        return out

    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

",4
"        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
",4
"        input=x,
        size=d_inner_hid,
        num_flatten_dims=2,
        act=hidden_act,
",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
",4
"        if cmd == ""a"":  # add residual connection
            out = out + prev_out if prev_out else out
        elif cmd == ""n"":  # add layer normalization
",4
"                param_attr=fluid.ParamAttr(
",4
"    return out
",4
"
def encoder_layer(enc_input,
                  attn_bias,
",4
"                  param_initializer=None,
",4
"                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
",4
"    return post_process_layer(
",4
"    """"""
    for i in range(n_layer):
        enc_output = encoder_layer(
            enc_input,
            attn_bias,
",4
"            relu_dropout,
            hidden_act,
            preprocess_cmd,
",4
"            postprocess_cmd,
            param_initializer=param_initializer,
            name=name + '_layer_' + str(i))
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
from __future__ import absolute_import
",4
"from paddlehub.common.logger import logger

from ernie_v2_eng_base.model.transformer_encoder import encoder, pre_process_layer

",4
"
",4
"            logger.info('%s: %s' % (arg, value))
        logger.info('------------------------------------------------')


class ErnieModel(object):
",4
"                 src_ids,
",4
"                 task_ids,
                 input_mask,
                 config,
                 weight_sharing=True,
                 use_fp16=False):
",4
"        if config['sent_type_vocab_size']:
",4
"        self._pos_emb_name = ""pos_embedding""
        self._sent_emb_name = ""sent_embedding""
        self._task_emb_name = ""task_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""
        self._emb_dtype = ""float32""
",4
"            input=src_ids,
            size=[self._voc_size, self._emb_size],
            dtype=self._emb_dtype,
",4
"
        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

",4
"        if self._dtype == ""float16"":
            emb_out = fluid.layers.cast(x=emb_out, dtype=self._dtype)
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)
        self_attn_mask = fluid.layers.matmul(
            x=input_mask, y=input_mask, transpose_y=True)
",4
"        n_head_self_attn_mask = fluid.layers.stack(
            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

",4
"            d_inner_hid=self._emb_size * 4,
",4
"            prepostprocess_dropout=self._prepostprocess_dropout,
            attention_dropout=self._attention_dropout,
            relu_dropout=0,
",4
"
        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')

",4
"        mask_trans_feat = fluid.layers.layer_norm(
",4
"            mask_trans_feat,
            begin_norm_axis=len(mask_trans_feat.shape) - 1,
            param_attr=fluid.ParamAttr(
                name='mask_lm_trans_layer_norm_scale',
                initializer=fluid.initializer.Constant(1.)),
",4
"            bias_attr=fluid.ParamAttr(
                name='mask_lm_trans_layer_norm_bias',
                initializer=fluid.initializer.Constant(1.)))
",4
"            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
                x=mask_trans_feat,
",4
"                bias_attr=mask_lm_out_bias_attr)

        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
",4
"        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

",4
"        mean_task_loss = fluid.layers.mean(task_loss)
        return mean_task_loss, task_acc
",4
"from __future__ import division
from __future__ import print_function

",4
"import argparse
",4
"from paddlehub.module.module import serving
from paddlehub.module.module import moduleinfo
",4
"    name=""simnet_bow"",
    version=""1.1.0"",
",4
"        self._set_config()

    @property
    def word_seg_module(self):
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
",4
"            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(memory_pool_init_size_mb=500, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)
",4
"
    def to_unicode(self, texts):
        """"""
        Convert each element's type(str) of texts(list) to unicode in python2.7
        Args:
",4
"        if six.PY2:
",4
"                    unicode_texts.append(
                        text.decode(sys_stdin_encoding()).decode(""utf8""))
                else:
                    unicode_texts.append(text)
            texts = unicode_texts
",4
"             data(dict): key must be 'text_1' and 'text_2', value is the texts(list) to be predicted
        Returns:
",4
"            data=input_data, use_gpu=args.use_gpu, batch_size=args.batch_size)

        return results
",4
"        """"""
        Add the command config options
",4
"            help=""whether use GPU for prediction"")

",4
"            help=""file contain input data"")
        self.arg_input_group.add_argument(
            '--text_1', type=str, default=None, help=""text to predict"")
        self.arg_input_group.add_argument(
",4
"    def check_input_data(self, args):
        input_data = {}
        if args.input_file:
            if not os.path.exists(args.input_file):
                print(""File %s is not exist."" % args.input_file)
",4
"            parts = line.split('\t')
            vocab[parts[0]] = int(parts[1])
    vocab[""<unk>""] = len(vocab)
    return vocab
",4
"        result[text_a_key].append(result_i)

",4
"        result_i = {'processed': []}
        result_i['origin'] = data_dict[text_b_key][index]
        for word in text_b['word']:
            _index = word_dict.get(word, unk_id)
",4
"
from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo

",4
"    name=""chinese-electra-small"",
    version=""1.0.0"",
    summary=
",4
"class Electra(TransformerModule):
    def _initialize(self):
        self.MAX_SEQ_LEN = 512
        self.params_path = os.path.join(self.directory, ""assets"", ""params"")
        self.vocab_path = os.path.join(self.directory, ""assets"", ""vocab.txt"")
",4
"        Returns:
            pooled_output (tensor):  sentence-level output for classification task.
            sequence_output (tensor): token-level output for sequence task.
        """"""
",4
"            input_mask=input_mask,
            config=self.electra_config,
            use_fp16=False)
        pooled_output = electra.get_pooled_output()
        sequence_output = electra.get_sequence_output()
",4
"
from functools import partial
",4
"    def __split_heads(x, n_head):
        """"""
        Reshape the last dimension of inpunt tensor x so that it becomes two
        dimensions and then transpose. Specifically, input a tensor with shape
",4
"        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
        reshaped = layers.reshape(
            x=x, shape=[0, 0, n_head, hidden_size // n_head], inplace=True)

",4
"        if len(x.shape) == 3: return x
",4
"        if len(x.shape) != 4:
            raise ValueError(""Input(x) should be a 4-D Tensor."")

",4
"    def scaled_dot_product_attention(q, k, v, attn_bias, d_key, dropout_rate):
        """"""
        Scaled Dot-Product Attention
        """"""
",4
"                dropout_prob=dropout_rate,
",4
"                is_test=False)
        out = layers.matmul(weights, v)
        return out

",4
"        # input from the previous time step first.
        k = cache[""k""] = layers.concat(
            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
        v = cache[""v""] = layers.concat(
",4
"            [layers.reshape(cache[""v""], shape=[0, 0, d_model]), v], axis=1)

    q = __split_heads(q, n_head)
    k = __split_heads(k, n_head)
",4
"def positionwise_feed_forward(x,
                              d_inner_hid,
                              d_hid,
                              dropout_rate,
",4
"                              hidden_act,
                              param_initializer=None,
",4
"        size=d_inner_hid,
        num_flatten_dims=2,
        act=hidden_act,
        param_attr=fluid.ParamAttr(
",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
    return out
",4
"                           name=''):
    """"""
    Add residual connection, layer normalization and droput to the out tensor
    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
",4
"        elif cmd == ""d"":  # add dropout
            if dropout_rate:
",4
"

def encoder_layer(enc_input,
",4
"        relu_dropout,
        hidden_act,
        param_initializer=param_initializer,
        name=name + '_ffn')
",4
"            d_model,
            d_inner_hid,
            prepostprocess_dropout,
            attention_dropout,
            relu_dropout,
",4
"            d_inner_hid,
            prepostprocess_dropout,
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"from __future__ import division
from __future__ import print_function

import six
",4
"import json

import paddle.fluid as fluid

",4
"        else:
            return config_dict

",4
"    def __getitem__(self, key):
        return self._config_dict[key]

",4
"    def print_config(self):
",4
"        for arg, value in sorted(six.iteritems(self._config_dict)):
",4
"
class ElectraModel(object):
    def __init__(self,
",4
"                 config,
                 weight_sharing=True,
",4
"        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing

",4
"        # Initialize all weigths by truncated normal initializer, and all biases
        # will be initialized by constant zero by default.
        self._param_initializer = fluid.initializer.TruncatedNormal(
            scale=config['initializer_range'])

",4
"        # padding id in vocabulary must be set to 0
",4
"            size=[self._voc_size, self._emb_size],
            dtype=self._dtype,
",4
"            input=position_ids,
            size=[self._max_position_seq_len, self._emb_size],
            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))
",4
"
        emb_out = emb_out + position_emb_out
        emb_out = emb_out + sent_emb_out

",4
"        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

",4
"        if self._emb_size != self._hidden_size:
            emb_out = fluid.layers.fc(
                input=emb_out,
",4
"                size=self._hidden_size,
",4
"        if self._dtype == ""float16"":
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)

        self_attn_mask = fluid.layers.matmul(
            x=input_mask, y=input_mask, transpose_y=True)
",4
"        self_attn_mask = fluid.layers.scale(
            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)
        n_head_self_attn_mask = fluid.layers.stack(
            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True
",4
"            prepostprocess_dropout=self._prepostprocess_dropout,
",4
"
        # extract the first token feature in each sentence
",4
"        mask_trans_feat = fluid.layers.fc(
            input=mask_feat,
",4
"        if self._weight_sharing:
",4
"                y=fluid.default_main_program().global_block().var(
                    self._word_emb_name),
                transpose_y=True)
            fc_out += fluid.layers.create_parameter(
",4
"                shape=[self._voc_size],
                dtype=self._dtype,
                attr=mask_lm_out_bias_attr,
",4
"
        else:
            fc_out = fluid.layers.fc(
                input=mask_trans_feat,
                size=self._voc_size,
",4
"        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

",4
"        next_sent_fc_out = fluid.layers.fc(
            input=next_sent_feat,
",4
"            logits=next_sent_fc_out, label=labels, return_softmax=True)

",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"            sequence_output (tensor): token-level output for sequence task.
        """"""
        bert = BertModel(
            src_ids=input_ids,
",4
"                         cache=None,
                         param_initializer=None,
                         name='multi_head_att'):
    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"    if not (len(queries.shape) == len(keys.shape) == len(values.shape) == 3):
        raise ValueError(
            ""Inputs: quries, keys and values should all be 3-D tensors."")
",4
"
        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
",4
"        return out

    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

    if cache is not None:  # use cache and concat time steps
",4
"        size=d_model,
        num_flatten_dims=2,
        param_attr=fluid.ParamAttr(
            name=name + '_output_fc.w_0', initializer=param_initializer),
        bias_attr=name + '_output_fc.b_0')
",4
"    return proj_out
",4
"

def positionwise_feed_forward(x,
                              d_inner_hid,
",4
"    out = layers.fc(
        input=hidden,
        size=d_hid,
        num_flatten_dims=2,
",4
"            out = layers.layer_norm(
                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"            if out_dtype == fluid.core.VarDesc.VarType.FP16:
                out = layers.cast(x=out, dtype=""float16"")
        elif cmd == ""d"":  # add dropout
            if dropout_rate:
                out = layers.dropout(
",4
"        pre_process_layer(
            enc_input,
            preprocess_cmd,
            prepostprocess_dropout,
",4
"            name=name + '_pre_att'),
        None,
        None,
",4
"        d_key,
        d_value,
",4
"        hidden_act,
        param_initializer=param_initializer,
        name=name + '_ffn')
    return post_process_layer(
",4
"            attn_bias,
            n_layer,
            n_head,
            d_key,
",4
"            name=''):
    """"""
    The encoder is composed of a stack of identical layers returned by calling
    encoder_layer.
    """"""
",4
"            d_key,
            d_value,
            d_model,
            d_inner_hid,
            prepostprocess_dropout,
",4
"            attention_dropout,
            relu_dropout,
            hidden_act,
            preprocess_cmd,
            postprocess_cmd,
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"

class BertConfig(object):
",4
"        else:
            return config_dict
",4
"                 use_fp16=False):

        self._emb_size = config['hidden_size']
        self._n_layer = config['num_hidden_layers']
",4
"            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

        if self._dtype == ""float16"":
",4
"            act=self._hidden_act,
            param_attr=fluid.ParamAttr(
                name='mask_lm_trans_fc.w_0',
",4
"            mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
            name=""mask_lm_out_fc.b_0"",
",4
"            fc_out = fluid.layers.matmul(
                x=mask_trans_feat,
",4
"                dtype=self._dtype,
",4
"        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

        next_sent_fc_out = fluid.layers.fc(
",4
"# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"    def _initialize(self):
",4
"        """"""
        create neural network.

        Args:
            input_ids (tensor): the word ids.
",4
"            position_ids (tensor): the position ids.
            segment_ids (tensor): the segment ids.
            input_mask (tensor): the padding mask.
",4
"        """"""
        bert = BertModel(
",4
"            sentence_ids=segment_ids,
            input_mask=input_mask,
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"                         dropout_rate=0.,
                         cache=None,
                         param_initializer=None,
",4
"    values = keys if values is None else values
",4
"            ""Inputs: quries, keys and values should all be 3-D tensors."")

    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
",4
"        """"""
        Add linear projection to queries, keys, and values.
        """"""
        q = layers.fc(
            input=queries,
",4
"            size=d_key * n_head,
            num_flatten_dims=2,
",4
"        so that it becomes one dimension, which is reverse to __split_heads.
        """"""
",4
"            inplace=True)

",4
"        if attn_bias:
            product += attn_bias
        weights = layers.softmax(product)
",4
"def positionwise_feed_forward(x,
",4
"        elif cmd == ""n"":  # add layer normalization
            out_dtype = out.dtype
",4
"

def encoder_layer(enc_input,
                  attn_bias,
                  n_head,
",4
"                  prepostprocess_dropout,
                  attention_dropout,
                  relu_dropout,
                  hidden_act,
",4
"                  param_initializer=None,
                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
    This module consits of a multi-head (self) attention followed by
",4
"        d_model,
        n_head,
",4
"        param_initializer=param_initializer,
        name=name + '_multi_head_att')
",4
"        d_inner_hid,
",4
"        name=name + '_post_ffn')


def encoder(enc_input,
            attn_bias,
",4
"            n_layer,
            n_head,
            d_key,
            d_value,
",4
"    for i in range(n_layer):
        enc_output = encoder_layer(
            enc_input,
            attn_bias,
",4
"
    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
",4
"#
",4
"    def __init__(self, config_path):
        self._config_dict = self._parse(config_path)

    def _parse(self, config_path):
",4
"        except Exception:
            raise IOError(
                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
",4
"        self._n_layer = config['num_hidden_layers']
        self._n_head = config['num_attention_heads']
        self._voc_size = config['vocab_size']
        self._max_position_seq_len = config['max_position_embeddings']
",4
"        self._weight_sharing = weight_sharing

        self._word_emb_name = ""word_embedding""
        self._pos_emb_name = ""pos_embedding""
",4
"        self._sent_emb_name = ""sent_embedding""
",4
"        self._dtype = ""float16"" if use_fp16 else ""float32""

        # Initialize all weigths by truncated normal initializer, and all biases
        # will be initialized by constant zero by default.
",4
"                name=self._word_emb_name, initializer=self._param_initializer),
            is_sparse=False)
",4
"                name=self._pos_emb_name, initializer=self._param_initializer))

",4
"        self_attn_mask = fluid.layers.scale(
",4
"            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)
",4
"
    def get_sequence_output(self):
        return self._enc_out

    def get_pooled_output(self):
",4
"            size=self._emb_size,
            act=""tanh"",
",4
"
    def get_pretraining_output(self, mask_label, mask_pos, labels):
        """"""Get the loss & accuracy for pretraining""""""

        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')
",4
"        reshaped_emb_out = fluid.layers.reshape(
            x=self._enc_out, shape=[-1, self._emb_size])
",4
"        # extract masked tokens' feature
        mask_feat = fluid.layers.gather(input=reshaped_emb_out, index=mask_pos)
",4
"        # transform: layer norm
        mask_trans_feat = pre_process_layer(
            mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
",4
"                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
                    self._word_emb_name),
                transpose_y=True)
",4
"                    name=""mask_lm_out_fc.w_0"",
",4
"            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

        next_sent_fc_out = fluid.layers.fc(
",4
"            input=next_sent_feat,
            size=2,
            param_attr=fluid.ParamAttr(
",4
"
from bert_uncased_L_12_H_768_A_12.model.bert import BertConfig, BertModel


@moduleinfo(
",4
"    name=""bert_uncased_L-12_H-768_A-12"",
    version=""1.1.0"",
    summary=
    ""bert_uncased_L-12_H-768_A-12, 12-layer, 768-hidden, 12-heads, 110M parameters"",
    author=""paddlepaddle"",
",4
"    author_email=""paddle-dev@baidu.com"",
    type=""nlp/semantic_model"",
",4
"        create neural network.

        Args:
",4
"            input_ids (tensor): the word ids.
",4
"            config=self.bert_config,
            use_fp16=False)
        pooled_output = bert.get_pooled_output()
        sequence_output = bert.get_sequence_output()
        return pooled_output, sequence_output
",4
"
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
        """"""
        q = layers.fc(
",4
"            input=keys,
            size=d_key * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
                name=name + '_key_fc.w_0', initializer=param_initializer),
",4
"        hidden_size = x.shape[-1]
",4
"    def __combine_heads(x):
",4
"        """"""
        if len(x.shape) == 3: return x
        if len(x.shape) != 4:
            raise ValueError(""Input(x) should be a 4-D Tensor."")
",4
"            shape=[0, 0, trans_x.shape[2] * trans_x.shape[3]],
            inplace=True)

    def scaled_dot_product_attention(q, k, v, attn_bias, d_key, dropout_rate):
",4
"        if dropout_rate:
            weights = layers.dropout(
",4
"        # input from the previous time step first.
        k = cache[""k""] = layers.concat(
",4
"    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
    feed-forward networks.
    """"""
",4
"        elif cmd == ""n"":  # add layer normalization
            out_dtype = out.dtype
            if out_dtype == fluid.core.VarDesc.VarType.FP16:
                out = layers.cast(x=out, dtype=""float32"")
            out = layers.layer_norm(
",4
"                    initializer=fluid.initializer.Constant(0.)))
",4
"            if out_dtype == fluid.core.VarDesc.VarType.FP16:
                out = layers.cast(x=out, dtype=""float16"")
        elif cmd == ""d"":  # add dropout
            if dropout_rate:
",4
"                out = layers.dropout(
                    out,
                    dropout_prob=dropout_rate,
                    dropout_implementation=""upscale_in_train"",
                    is_test=False)
",4
"        d_model,
        n_head,
        attention_dropout,
",4
"        prepostprocess_dropout,
        name=name + '_post_ffn')

",4
"            name=''):
    """"""
    The encoder is composed of a stack of identical layers returned by calling
",4
"    """"""
    for i in range(n_layer):
        enc_output = encoder_layer(
            enc_input,
",4
"            attn_bias,
",4
"            n_head,
            d_key,
            d_value,
",4
"            relu_dropout,
            hidden_act,
            preprocess_cmd,
            postprocess_cmd,
            param_initializer=param_initializer,
",4
"            name=name + '_layer_' + str(i))
        enc_input = enc_output
    enc_output = pre_process_layer(
        enc_output, preprocess_cmd, prepostprocess_dropout, name=""post_encoder"")

",4
"from __future__ import print_function

",4
"        self._config_dict = self._parse(config_path)
",4
"                config_dict = json.load(json_file)
        except Exception:
            raise IOError(
                ""Error in parsing bert model config file '%s'"" % config_path)
",4
"        else:
",4
"        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')

        if self._dtype == ""float16"":
",4
"            d_key=self._emb_size // self._n_head,
            d_value=self._emb_size // self._n_head,
            d_model=self._emb_size,
            d_inner_hid=self._emb_size * 4,
            prepostprocess_dropout=self._prepostprocess_dropout,
",4
"            relu_dropout=0,
            hidden_act=self._hidden_act,
",4
"
        next_sent_feat = fluid.layers.slice(
            input=self._enc_out, axes=[1], starts=[0], ends=[1])
",4
"        # extract the first token feature in each sentence
        next_sent_feat = self.get_pooled_output()
        reshaped_emb_out = fluid.layers.reshape(
            x=self._enc_out, shape=[-1, self._emb_size])
        # extract masked tokens' feature
",4
"
        mask_lm_out_bias_attr = fluid.ParamAttr(
            name=""mask_lm_out_fc.b_0"",
            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
",4
"                dtype=self._dtype,
                attr=mask_lm_out_bias_attr,
                is_bias=True)

        else:
",4
"            fc_out = fluid.layers.fc(
                input=mask_trans_feat,
                size=self._voc_size,
                param_attr=fluid.ParamAttr(
                    name=""mask_lm_out_fc.w_0"",
",4
"                bias_attr=mask_lm_out_bias_attr)

        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
",4
"        return next_sent_acc, mean_mask_lm_loss, loss
# coding:utf-8
# Copyright (c) 2019  PaddlePaddle Authors. All Rights Reserved.
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"
from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo
",4
"    summary=""rbtl3, 3-layer, 1024-hidden, 16-heads, 61M parameters "",
    author=""ymcui"",
    author_email=""ymcui@ir.hit.edu.cn"",
    type=""nlp/semantic_model"",
",4
")
class BertWwm(TransformerModule):
    def _initialize(self):
",4
"        Args:
            input_ids (tensor): the word ids.
            position_ids (tensor): the position ids.
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"                         param_initializer=None,
                         name='multi_head_att'):
    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"        """"""
        Add linear projection to queries, keys, and values.
        """"""
        q = layers.fc(
            input=queries,
",4
"        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
",4
"        # permuate the dimensions into:
",4
"        # [batch_size, n_head, max_sequence_len, hidden_size_per_head]
        return layers.transpose(x=reshaped, perm=[0, 2, 1, 3])

",4
"        """"""
",4
"        product = layers.matmul(x=scaled_q, y=k, transpose_y=True)
        if attn_bias:
",4
"            [layers.reshape(cache[""v""], shape=[0, 0, d_model]), v], axis=1)

",4
"    q = __split_heads(q, n_head)
    k = __split_heads(k, n_head)
",4
"
    # Project back to the model size.
",4
"    proj_out = layers.fc(
",4
"        input=out,
        size=d_model,
",4
"    """"""
    Position-wise Feed-Forward Networks.
    This module consists of two linear transformations with a ReLU activation
",4
"        act=hidden_act,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_0.w_0', initializer=param_initializer),
",4
"            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
            is_test=False)
    out = layers.fc(
        input=hidden,
",4
"                    out,
                    dropout_prob=dropout_rate,
                    dropout_implementation=""upscale_in_train"",
                    is_test=False)
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
post_process_layer = pre_post_process_layer
",4
"                  d_key,
                  d_value,
",4
"            n_head,
            d_key,
            d_value,
            d_model,
            d_inner_hid,
",4
"        enc_output, preprocess_cmd, prepostprocess_dropout, name=""post_encoder"")

",4
"    return enc_output
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
from __future__ import absolute_import
from __future__ import division
",4
"            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
            sentence_ids,
",4
"        """"""Get the first feature of each sequence for classification""""""

        next_sent_feat = fluid.layers.slice(
            input=self._enc_out, axes=[1], starts=[0], ends=[1])
",4
"            param_attr=fluid.ParamAttr(
                name=""pooled_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""pooled_fc.b_0"")
",4
"        reshaped_emb_out = fluid.layers.reshape(
            x=self._enc_out, shape=[-1, self._emb_size])
        # extract masked tokens' feature
        mask_feat = fluid.layers.gather(input=reshaped_emb_out, index=mask_pos)

",4
"                dtype=self._dtype,
",4
"            size=2,
            param_attr=fluid.ParamAttr(
",4
"
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo

",4
"    summary=
    ""bert_uncased_L-24_H-1024_A-16, 24-layer, 1024-hidden, 16-heads, 340M parameters "",
",4
"        self.vocab_path = os.path.join(self.directory, ""assets"", ""vocab.txt"")

        bert_config_path = os.path.join(self.directory, ""assets"",
                                        ""bert_config.json"")
",4
"        self.bert_config = BertConfig(bert_config_path)

    def net(self, input_ids, position_ids, segment_ids, input_mask):
        """"""
",4
"        create neural network.
",4
"            position_ids (tensor): the position ids.
            segment_ids (tensor): the segment ids.
",4
"            bias_attr=name + '_query_fc.b_0')
        k = layers.fc(
",4
"        """"""
        hidden_size = x.shape[-1]
",4
"
        # permuate the dimensions into:
",4
"        if len(x.shape) == 3: return x
",4
"        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
        return layers.reshape(
            x=trans_x,
",4
"        """"""
",4
"    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

    if cache is not None:  # use cache and concat time steps
",4
"        # v, which is the cache input for next time step, reshape the cache
        # input from the previous time step first.
",4
"    ctx_multiheads = scaled_dot_product_attention(q, k, v, attn_bias, d_key,
                                                  dropout_rate)

    out = __combine_heads(ctx_multiheads)
",4
"            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
            is_test=False)
    out = layers.fc(
        input=hidden,
",4
"    for cmd in process_cmd:
        if cmd == ""a"":  # add residual connection
            out = out + prev_out if prev_out else out
        elif cmd == ""n"":  # add layer normalization
",4
"                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"        elif cmd == ""d"":  # add dropout
            if dropout_rate:
                out = layers.dropout(
                    out,
",4
"def encoder_layer(enc_input,
                  attn_bias,
                  n_head,
",4
"            enc_input,
            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_att'),
",4
"        d_model,
        n_head,
        attention_dropout,
",4
"        param_initializer=param_initializer,
",4
"        relu_dropout,
        hidden_act,
        param_initializer=param_initializer,
",4
"            relu_dropout,
            hidden_act,
            preprocess_cmd=""n"",
            postprocess_cmd=""da"",
            param_initializer=None,
",4
"# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"    def __init__(self, config_path):
        self._config_dict = self._parse(config_path)

    def _parse(self, config_path):
        try:
",4
"        self._emb_size = config['hidden_size']
        self._n_layer = config['num_hidden_layers']
",4
"        self._n_head = config['num_attention_heads']
        self._voc_size = config['vocab_size']
        self._max_position_seq_len = config['max_position_embeddings']
        self._sent_types = config['type_vocab_size']
        self._hidden_act = config['hidden_act']
",4
"        self._pos_emb_name = ""pos_embedding""
        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""
",4
"
    def _build_model(self, src_ids, position_ids, sentence_ids, input_mask):
        # padding id in vocabulary must be set to 0
        emb_out = fluid.layers.embedding(
",4
"            input=position_ids,
            size=[self._max_position_seq_len, self._emb_size],
            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))
",4
"            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))
",4
"        emb_out = pre_process_layer(
            emb_out, 'nd', self._prepostprocess_dropout, name='pre_encoder')
",4
"            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)

        self_attn_mask = fluid.layers.matmul(
",4
"        self_attn_mask = fluid.layers.scale(
            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)
",4
"            postprocess_cmd=""dan"",
            param_initializer=self._param_initializer,
",4
"        next_sent_feat = fluid.layers.slice(
",4
"
    def get_pretraining_output(self, mask_label, mask_pos, labels):
",4
"            size=self._emb_size,
            act=self._hidden_act,
            param_attr=fluid.ParamAttr(
                name='mask_lm_trans_fc.w_0',
",4
"            size=2,
            param_attr=fluid.ParamAttr(
                name=""next_sent_fc.w_0"", initializer=self._param_initializer),
",4
"from __future__ import division
from __future__ import print_function
",4
"
",4
"    author_email=""ymcui@ir.hit.edu.cn"",
    type=""nlp/semantic_model"",
)
class BertWwm(TransformerModule):
    def _initialize(self):
",4
"
        Returns:
            pooled_output (tensor):  sentence-level output for classification task.
",4
"# You may obtain a copy of the License at
#
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"from __future__ import absolute_import
from __future__ import division
",4
"from __future__ import print_function

from functools import partial
",4
"import paddle.fluid.layers as layers


def multi_head_attention(queries,
",4
"    keys = queries if keys is None else keys
    values = keys if values is None else values

",4
"        Add linear projection to queries, keys, and values.
        """"""
",4
"            bias_attr=name + '_query_fc.b_0')
",4
"            size=d_value * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
                name=name + '_value_fc.w_0', initializer=param_initializer),
            bias_attr=name + '_value_fc.b_0')
",4
"        with shape [bs, n_head, max_sequence_length, hidden_dim].
        """"""
        hidden_size = x.shape[-1]
        # The value 0 in shape attr means copying the corresponding dimension
        # size of the input as the output dimension size.
",4
"    def __combine_heads(x):
        """"""
        Transpose and then reshape the last two dimensions of inpunt tensor x
        so that it becomes one dimension, which is reverse to __split_heads.
",4
"        return layers.reshape(
            x=trans_x,
            shape=[0, 0, trans_x.shape[2] * trans_x.shape[3]],
            inplace=True)
",4
"            product += attn_bias
        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
",4
"                is_test=False)
",4
"        param_attr=fluid.ParamAttr(
            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
    return out
",4
"
pre_process_layer = partial(pre_post_process_layer, None)
",4
"            name=name + '_pre_att'),
        None,
",4
"        None,
        attn_bias,
        d_key,
",4
"        enc_input,
",4
"        prepostprocess_dropout,
        name=name + '_post_att')
    ffd_output = positionwise_feed_forward(
        pre_process_layer(
            attn_output,
",4
"            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_ffn'),
        d_inner_hid,
        d_model,
",4
"        postprocess_cmd,
",4
"
def encoder(enc_input,
            attn_bias,
            n_layer,
",4
"            n_head,
",4
"            d_model,
",4
"            attention_dropout,
            relu_dropout,
            hidden_act,
            preprocess_cmd,
            postprocess_cmd,
",4
"
",4
"    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"""""""BERT model.""""""

from __future__ import absolute_import
from __future__ import division
",4
"
from chinese_roberta_wwm_ext_large.model.transformer_encoder import encoder, pre_process_layer

",4
"
",4
"            with open(config_path) as json_file:
                config_dict = json.load(json_file)
        except Exception:
            raise IOError(
",4
"                 src_ids,
                 position_ids,
",4
"        self._dtype = ""float16"" if use_fp16 else ""float32""
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
",4
"                name=self._sent_emb_name, initializer=self._param_initializer))

",4
"            x=input_mask, y=input_mask, transpose_y=True)
        self_attn_mask = fluid.layers.scale(
            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)
        n_head_self_attn_mask = fluid.layers.stack(
            x=[self_attn_mask] * self._n_head, axis=1)
",4
"        return self._enc_out

    def get_pooled_output(self):
        """"""Get the first feature of each sequence for classification""""""
",4
"
",4
"
    def get_pretraining_output(self, mask_label, mask_pos, labels):
",4
"        # transform: layer norm
        mask_trans_feat = pre_process_layer(
",4
"                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
                    self._word_emb_name),
                transpose_y=True)
            fc_out += fluid.layers.create_parameter(
",4
"                    name=""mask_lm_out_fc.w_0"",
                    initializer=self._param_initializer),
",4
"            logits=fc_out, label=mask_label)
        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

        next_sent_fc_out = fluid.layers.fc(
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License""
",4
"            input_ids (tensor): the word ids.
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"import paddle.fluid as fluid
",4
"

",4
"                         param_initializer=None,
                         name='multi_head_att'):
    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
",4
"            size=d_value * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
                name=name + '_value_fc.w_0', initializer=param_initializer),
            bias_attr=name + '_value_fc.b_0')
",4
"        return out

    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

",4
"    # Project back to the model size.
    proj_out = layers.fc(
",4
"                              hidden_act,
                              param_initializer=None,
",4
"    Position-wise Feed-Forward Networks.
",4
"        input=x,
        size=d_inner_hid,
        num_flatten_dims=2,
",4
"    Add residual connection, layer normalization and droput to the out tensor
",4
"    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
",4
"                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
                    initializer=fluid.initializer.Constant(1.)),
",4
"                out = layers.cast(x=out, dtype=""float16"")
",4
"def encoder_layer(enc_input,
                  attn_bias,
",4
"                  preprocess_cmd=""n"",
                  postprocess_cmd=""da"",
                  param_initializer=None,
                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
",4
"        name=name + '_multi_head_att')
    attn_output = post_process_layer(
",4
"            attn_output,
            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_ffn'),
        d_inner_hid,
",4
"
def encoder(enc_input,
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"        else:
            self._sent_types = config['type_vocab_size']

",4
"        self._weight_sharing = weight_sharing

        self._word_emb_name = ""word_embedding""
",4
"
        # Initialize all weigths by truncated normal initializer, and all biases
",4
"            input=position_ids,
",4
"
",4
"        emb_out = emb_out + position_emb_out
",4
"            n_head=self._n_head,
            d_key=self._emb_size // self._n_head,
            d_value=self._emb_size // self._n_head,
",4
"            act=""tanh"",
            param_attr=fluid.ParamAttr(
",4
"                name=""pooled_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""pooled_fc.b_0"")
        return next_sent_feat

    def get_lm_output(self, mask_label, mask_pos):
",4
"        """"""Get the loss & accuracy for pretraining""""""

",4
"        mask_pos = fluid.layers.cast(x=mask_pos, dtype='int32')

        # extract the first token feature in each sentence
        self.next_sent_feat = self.get_pooled_output()
",4
"        # extract masked tokens' feature
        mask_feat = fluid.layers.gather(input=reshaped_emb_out, index=mask_pos)
        if self._dtype == ""float16"":
",4
"            mask_feat = fluid.layers.cast(x=mask_feat, dtype=self._emb_dtype)

        # transform: fc
        mask_trans_feat = fluid.layers.fc(
",4
"            input=mask_feat,
",4
"                name='mask_lm_trans_layer_norm_scale',
",4
"        #mask_trans_feat = pre_process_layer(
        #    mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
            name=""mask_lm_out_fc.b_0"",
",4
"            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
",4
"        return mean_mask_lm_loss

    def get_task_output(self, task, task_labels):
        task_fc_out = fluid.layers.fc(
",4
"        task_acc = fluid.layers.accuracy(input=task_softmax, label=task_labels)
        mean_task_loss = fluid.layers.mean(task_loss)
        return mean_task_loss, task_acc
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"from __future__ import absolute_import
from __future__ import division
",4
"
from paddlehub import TransformerModule
from paddlehub.module.module import moduleinfo
",4
"@moduleinfo(
    name=""ernie_tiny"",
    version=""1.1.0"",
    summary=
    ""Baidu's ERNIE-tiny, Enhanced Representation through kNowledge IntEgration, tiny version, max_seq_len=512"",
",4
")
",4
"class ErnieTiny(TransformerModule):
    def _initialize(self):
        ernie_config_path = os.path.join(self.directory, ""assets"",
                                         ""ernie_tiny_config.json"")
        self.ernie_config = ErnieConfig(ernie_config_path)
",4
"        self.ernie_config._config_dict['use_task_id'] = False
        ernie = ErnieModel(
",4
"            config=self.ernie_config,
            use_fp16=False)
        pooled_output = ernie.get_pooled_output()
        sequence_output = ernie.get_sequence_output()
        return pooled_output, sequence_output
",4
"    test_module = ErnieTiny()
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"import paddle.fluid as fluid
import paddle.fluid.layers as layers


def multi_head_attention(queries,
",4
"                         param_initializer=None,
                         name='multi_head_att'):
",4
"
    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
        """"""
",4
"        v = layers.fc(
            input=values,
            size=d_value * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
",4
"                name=name + '_value_fc.w_0', initializer=param_initializer),
            bias_attr=name + '_value_fc.b_0')
",4
"        return q, k, v

    def __split_heads(x, n_head):
        """"""
",4
"        Scaled Dot-Product Attention
        """"""
        scaled_q = layers.scale(x=q, scale=d_key**-0.5)
        product = layers.matmul(x=scaled_q, y=k, transpose_y=True)
        if attn_bias:
",4
"        weights = layers.softmax(product)
        if dropout_rate:
            weights = layers.dropout(
                weights,
                dropout_prob=dropout_rate,
",4
"
",4
"    proj_out = layers.fc(
",4
"            hidden,
            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
            is_test=False)
    out = layers.fc(
",4
"    """"""
    for cmd in process_cmd:
        if cmd == ""a"":  # add residual connection
            out = out + prev_out if prev_out else out
        elif cmd == ""n"":  # add layer normalization
",4
"            out_dtype = out.dtype
            if out_dtype == fluid.core.VarDesc.VarType.FP16:
                out = layers.cast(x=out, dtype=""float32"")
            out = layers.layer_norm(
",4
"                out,
                begin_norm_axis=len(out.shape) - 1,
                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
",4
"    return out


pre_process_layer = partial(pre_post_process_layer, None)
",4
"        pre_process_layer(
            enc_input,
            preprocess_cmd,
            prepostprocess_dropout,
            name=name + '_pre_att'),
",4
"        attn_output,
        postprocess_cmd,
",4
"        postprocess_cmd,
        prepostprocess_dropout,
",4
"            attn_bias,
",4
"            d_value,
            d_model,
            d_inner_hid,
            prepostprocess_dropout,
            attention_dropout,
",4
"        enc_input = enc_output
    enc_output = pre_process_layer(
        enc_output, preprocess_cmd, prepostprocess_dropout, name=""post_encoder"")

    return enc_output
",4
"# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"from __future__ import absolute_import

import json
",4
"        self._config_dict = self._parse(config_path)

    def _parse(self, config_path):
        try:
            with open(config_path, 'r', encoding='utf8') as json_file:
",4
"        return self._config_dict.get(key, None)

    def print_config(self):
",4
"        logger.info('------------------------------------------------')


",4
"                 position_ids,
",4
"                 sentence_ids,
                 task_ids,
                 input_mask,
",4
"        if self._use_task_id:
            self._task_types = config['task_type_vocab_size']
        self._hidden_act = config['hidden_act']
        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
",4
"
        # Initialize all weigths by truncated normal initializer, and all biases
        # will be initialized by constant zero by default.
        self._param_initializer = fluid.initializer.TruncatedNormal(
",4
"            dtype=self._emb_dtype,
            param_attr=fluid.ParamAttr(
                name=self._pos_emb_name, initializer=self._param_initializer))

        sent_emb_out = fluid.layers.embedding(
",4
"            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))

",4
"                task_ids,
",4
"                    name=self._task_emb_name,
                    initializer=self._param_initializer))
",4
"
        self_attn_mask = fluid.layers.scale(
",4
"            d_model=self._emb_size,
            d_inner_hid=self._emb_size * 4,
            prepostprocess_dropout=self._prepostprocess_dropout,
            attention_dropout=self._attention_dropout,
            relu_dropout=0,
",4
"                x=self._enc_out, dtype=self._emb_dtype)

",4
"    def get_pooled_output(self):
        """"""Get the first feature of each sequence for classification""""""
        next_sent_feat = fluid.layers.slice(
",4
"            input=self._enc_out, axes=[1], starts=[0], ends=[1])
        next_sent_feat = fluid.layers.fc(
",4
"
        # extract the first token feature in each sentence
",4
"            param_attr=fluid.ParamAttr(
                name='mask_lm_trans_fc.w_0',
",4
"            logits=task_fc_out, label=task_labels, return_softmax=True)
        task_acc = fluid.layers.accuracy(input=task_softmax, label=task_labels)
        mean_task_loss = fluid.layers.mean(task_loss)
        return mean_task_loss, task_acc
",4
"# You may obtain a copy of the License at
#
",4
"class Electra(TransformerModule):
    def _initialize(self):
        self.MAX_SEQ_LEN = 512
        self.params_path = os.path.join(self.directory, ""assets"", ""params"")
",4
"        Returns:
",4
"            pooled_output (tensor):  sentence-level output for classification task.
            sequence_output (tensor): token-level output for sequence task.
        """"""
        electra = ElectraModel(
",4
"            sentence_ids=segment_ids,
",4
"        sequence_output = electra.get_sequence_output()
        return pooled_output, sequence_output

",4
"
if __name__ == '__main__':
    test_module = Electra()
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"#
# Unless required by applicable law or agreed to in writing, software
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"            ""Inputs: quries, keys and values should all be 3-D tensors."")

",4
"            num_flatten_dims=2,
",4
"            input=values,
            size=d_value * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
                name=name + '_value_fc.w_0', initializer=param_initializer),
",4
"        reshaped = layers.reshape(
            x=x, shape=[0, 0, n_head, hidden_size // n_head], inplace=True)

        # permuate the dimensions into:
",4
"        # [batch_size, n_head, max_sequence_len, hidden_size_per_head]
        return layers.transpose(x=reshaped, perm=[0, 2, 1, 3])

",4
"        if len(x.shape) != 4:
            raise ValueError(""Input(x) should be a 4-D Tensor."")

        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
        # The value 0 in shape attr means copying the corresponding dimension
",4
"        """"""
        Scaled Dot-Product Attention
        """"""
        scaled_q = layers.scale(x=q, scale=d_key**-0.5)
",4
"                                                  dropout_rate)

",4
"        bias_attr=name + '_output_fc.b_0')
    return proj_out

",4
"        bias_attr=name + '_fc_0.b_0')
    if dropout_rate:
        hidden = layers.dropout(
",4
"            dropout_prob=dropout_rate,
            dropout_implementation=""upscale_in_train"",
            is_test=False)
    out = layers.fc(
        input=hidden,
",4
"    """"""
    for cmd in process_cmd:
        if cmd == ""a"":  # add residual connection
            out = out + prev_out if prev_out else out
        elif cmd == ""n"":  # add layer normalization
",4
"                    initializer=fluid.initializer.Constant(0.)))
",4
"            if dropout_rate:
                out = layers.dropout(
                    out,
                    dropout_prob=dropout_rate,
                    dropout_implementation=""upscale_in_train"",
",4
"    return out

",4
"
pre_process_layer = partial(pre_post_process_layer, None)
post_process_layer = pre_post_process_layer
",4
"

def encoder_layer(enc_input,
",4
"                  attn_bias,
",4
"                  d_model,
                  d_inner_hid,
                  prepostprocess_dropout,
                  attention_dropout,
",4
"                  param_initializer=None,
                  name=''):
    """"""The encoder layers that can be stacked to form a deep encoder.
",4
"        d_value,
        d_model,
        n_head,
",4
"    ffd_output = positionwise_feed_forward(
",4
"    The encoder is composed of a stack of identical layers returned by calling
    encoder_layer.
    """"""
",4
"import paddle.fluid as fluid

from chinese_electra_base.model.transformer_encoder import encoder, pre_process_layer
",4
"
    def __getitem__(self, key):
        return self._config_dict[key]
",4
"        for arg, value in sorted(six.iteritems(self._config_dict)):
",4
"        self._prepostprocess_dropout = config['hidden_dropout_prob']
        self._attention_dropout = config['attention_probs_dropout_prob']
        self._weight_sharing = weight_sharing

        self._word_emb_name = ""word_embedding""
",4
"        # Initialize all weigths by truncated normal initializer, and all biases
        # will be initialized by constant zero by default.
",4
"            size=[self._sent_types, self._emb_size],
            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
                name=self._sent_emb_name, initializer=self._param_initializer))
",4
"
        self._enc_out = encoder(
            enc_input=emb_out,
",4
"        # transform: fc
        mask_trans_feat = fluid.layers.fc(
            input=mask_feat,
",4
"            mask_trans_feat, 'n', name='mask_lm_trans')

        mask_lm_out_bias_attr = fluid.ParamAttr(
",4
"            initializer=fluid.initializer.Constant(value=0.0))
        if self._weight_sharing:
            fc_out = fluid.layers.matmul(
                x=mask_trans_feat,
                y=fluid.default_main_program().global_block().var(
",4
"                is_bias=True)

        else:
            fc_out = fluid.layers.fc(
",4
"
        next_sent_fc_out = fluid.layers.fc(
            input=next_sent_feat,
            size=2,
",4
"# Licensed under the Apache License, Version 2.0 (the ""License""
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"

@moduleinfo(
",4
"        bert_config_path = os.path.join(self.directory, ""assets"",
                                        ""bert_config.json"")
        self.bert_config = BertConfig(bert_config_path)
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"from functools import partial

import paddle.fluid as fluid
",4
"    """"""
    Multi-Head Attention. Note that attn_bias is added to the logit before
",4
"        q = layers.fc(
            input=queries,
            size=d_key * n_head,
            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
",4
"            num_flatten_dims=2,
            param_attr=fluid.ParamAttr(
",4
"        Reshape the last dimension of inpunt tensor x so that it becomes two
        dimensions and then transpose. Specifically, input a tensor with shape
        [bs, max_sequence_length, n_head * hidden_dim] then output a tensor
        with shape [bs, n_head, max_sequence_length, hidden_dim].
",4
"            shape=[0, 0, trans_x.shape[2] * trans_x.shape[3]],
",4
"        bias_attr=name + '_output_fc.b_0')
    return proj_out


def positionwise_feed_forward(x,
",4
"                              d_inner_hid,
                              d_hid,
                              dropout_rate,
",4
"        size=d_hid,
        num_flatten_dims=2,
        param_attr=fluid.ParamAttr(
            name=name + '_fc_1.w_0', initializer=param_initializer),
        bias_attr=name + '_fc_1.b_0')
",4
"    Add residual connection, layer normalization and droput to the out tensor
    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
    feed-forward networks.
",4
"                param_attr=fluid.ParamAttr(
                    name=name + '_layer_norm_scale',
                    initializer=fluid.initializer.Constant(1.)),
",4
"        prepostprocess_dropout,
        name=name + '_post_att')
",4
"        param_initializer=param_initializer,
        name=name + '_ffn')
    return post_process_layer(
        attn_output,
",4
"        ffd_output,
        postprocess_cmd,
        prepostprocess_dropout,
",4
"        name=name + '_post_ffn')


def encoder(enc_input,
            attn_bias,
",4
"            param_initializer=None,
            name=''):
    """"""
    The encoder is composed of a stack of identical layers returned by calling
    encoder_layer.
",4
"            d_key,
            d_value,
",4
"    return enc_output
",4
"#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"import paddle.fluid as fluid

from bert_multi_uncased_L_12_H_768_A_12.model.transformer_encoder import encoder, pre_process_layer
",4
"            with open(config_path) as json_file:
                config_dict = json.load(json_file)
        except Exception:
",4
"            print('%s: %s' % (arg, value))
        print('------------------------------------------------')


class BertModel(object):
",4
"
        self._emb_size = config['hidden_size']
        self._n_layer = config['num_hidden_layers']
        self._n_head = config['num_attention_heads']
        self._voc_size = config['vocab_size']
",4
"        self._sent_emb_name = ""sent_embedding""
        self._dtype = ""float16"" if use_fp16 else ""float32""

",4
"        # Initialize all weigths by truncated normal initializer, and all biases
",4
"        # will be initialized by constant zero by default.
        self._param_initializer = fluid.initializer.TruncatedNormal(
",4
"    def _build_model(self, src_ids, position_ids, sentence_ids, input_mask):
",4
"            input=src_ids,
            size=[self._voc_size, self._emb_size],
",4
"            dtype=self._dtype,
            param_attr=fluid.ParamAttr(
",4
"
        self_attn_mask = fluid.layers.matmul(
            x=input_mask, y=input_mask, transpose_y=True)
        self_attn_mask = fluid.layers.scale(
            x=self_attn_mask, scale=10000.0, bias=-1.0, bias_after_scale=False)
",4
"            d_inner_hid=self._emb_size * 4,
            prepostprocess_dropout=self._prepostprocess_dropout,
            attention_dropout=self._attention_dropout,
            relu_dropout=0,
",4
"            act=""tanh"",
            param_attr=fluid.ParamAttr(
                name=""pooled_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""pooled_fc.b_0"")
",4
"                    name=""mask_lm_out_fc.w_0"",
                    initializer=self._param_initializer),
                bias_attr=mask_lm_out_bias_attr)

",4
"        mask_lm_loss = fluid.layers.softmax_with_cross_entropy(
            logits=fc_out, label=mask_label)
",4
"        mean_mask_lm_loss = fluid.layers.mean(mask_lm_loss)

        next_sent_fc_out = fluid.layers.fc(
",4
"            input=next_sent_feat,
            size=2,
",4
"        next_sent_loss, next_sent_softmax = fluid.layers.softmax_with_cross_entropy(
            logits=next_sent_fc_out, label=labels, return_softmax=True)

        next_sent_acc = fluid.layers.accuracy(
            input=next_sent_softmax, label=labels)
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"        self.bert_config = BertConfig(bert_config_path)

    def net(self, input_ids, position_ids, segment_ids, input_mask):
        """"""
",4
"            pooled_output (tensor):  sentence-level output for classification task.
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"    def __compute_qkv(queries, keys, values, n_head, d_key, d_value):
        """"""
        Add linear projection to queries, keys, and values.
",4
"            param_attr=fluid.ParamAttr(
                name=name + '_key_fc.w_0', initializer=param_initializer),
            bias_attr=name + '_key_fc.b_0')
        v = layers.fc(
            input=values,
",4
"        trans_x = layers.transpose(x, perm=[0, 2, 1, 3])
",4
"        if dropout_rate:
            weights = layers.dropout(
                weights,
",4
"        return out

    q, k, v = __compute_qkv(queries, keys, values, n_head, d_key, d_value)

    if cache is not None:  # use cache and concat time steps
",4
"            [layers.reshape(cache[""k""], shape=[0, 0, d_model]), k], axis=1)
        v = cache[""v""] = layers.concat(
            [layers.reshape(cache[""v""], shape=[0, 0, d_model]), v], axis=1)
",4
"                              d_hid,
                              dropout_rate,
                              hidden_act,
                              param_initializer=None,
",4
"                              name='ffn'):
    """"""
",4
"

def pre_post_process_layer(prev_out, out, process_cmd, dropout_rate=0.,
",4
"                           name=''):
",4
"    """"""
    Add residual connection, layer normalization and droput to the out tensor
    optionally according to the value of process_cmd.
    This will be used before or after multi-head attention and position-wise
    feed-forward networks.
",4
"                  attention_dropout,
                  relu_dropout,
                  hidden_act,
",4
"                  preprocess_cmd=""n"",
                  postprocess_cmd=""da"",
                  param_initializer=None,
                  name=''):
",4
"        d_key,
        d_value,
        d_model,
        n_head,
",4
"        attention_dropout,
        param_initializer=param_initializer,
        name=name + '_multi_head_att')
    attn_output = post_process_layer(
",4
"        enc_input,
        attn_output,
",4
"    """"""
    for i in range(n_layer):
        enc_output = encoder_layer(
            enc_input,
            attn_bias,
",4
"            name=name + '_layer_' + str(i))
        enc_input = enc_output
    enc_output = pre_process_layer(
        enc_output, preprocess_cmd, prepostprocess_dropout, name=""post_encoder"")

",4
"    return enc_output
# Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
""""""BERT model.""""""

",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"        except Exception:
            raise IOError(
                ""Error in parsing bert model config file '%s'"" % config_path)
        else:
            return config_dict
",4
"
    def __getitem__(self, key):
        return self._config_dict[key]
",4
"            print('%s: %s' % (arg, value))
",4
"            scale=config['initializer_range'])

        self._build_model(src_ids, position_ids, sentence_ids, input_mask)

",4
"
",4
"        if self._dtype == ""float16"":
            input_mask = fluid.layers.cast(x=input_mask, dtype=self._dtype)

",4
"            x=[self_attn_mask] * self._n_head, axis=1)
        n_head_self_attn_mask.stop_gradient = True

        self._enc_out = encoder(
            enc_input=emb_out,
",4
"            n_head=self._n_head,
            d_key=self._emb_size // self._n_head,
            d_value=self._emb_size // self._n_head,
            d_model=self._emb_size,
",4
"            postprocess_cmd=""dan"",
            param_initializer=self._param_initializer,
            name='encoder')
",4
"            param_attr=fluid.ParamAttr(
                name='mask_lm_trans_fc.w_0',
                initializer=self._param_initializer),
",4
"                size=self._voc_size,
",4
"            size=2,
            param_attr=fluid.ParamAttr(
                name=""next_sent_fc.w_0"", initializer=self._param_initializer),
            bias_attr=""next_sent_fc.b_0"")

",4
"
        next_sent_acc = fluid.layers.accuracy(
            input=next_sent_softmax, label=labels)
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import json
",4
"        """"""
",4
"
        with open(self.param_file, 'r') as file:
            params_list = file.readlines()
        for param in params_list:
            param = param.strip()
",4
"        for param in program.global_block().iter_parameters():
            param.trainable = trainable
",4
"        for name, var in program.global_block().vars.items():
            if name == feed_target_names[0]:
                inputs = {""words"": var}
            # output of sencond layer from the end prediction layer (fc-softmax)
",4
"            use_gpu = False
",4
"            predicted_data = data[""text""]
        else:
            raise ValueError(
                ""The input data is inconsistent with expectations."")
",4
"
        predicted_data = self.to_unicode(predicted_data)
",4
"        start_idx = 0
        iteration = int(math.ceil(len(predicted_data) / batch_size))
        results = []
",4
"            if i < (iteration - 1):
                batch_data = predicted_data[start_idx:(start_idx + batch_size)]
            else:
                batch_data = predicted_data[start_idx:]
",4
"            results += batch_result
",4
"    porn_detection_cnn = PornDetectionCNN()
    test_text = [""é»çä¸è½½"", ""æå»é»çå""]

    results = porn_detection_cnn.detection(texts=test_text, batch_size=9)
",4
"    for index, text in enumerate(test_text):
        results[index][""text""] = text
    for index, result in enumerate(results):
",4
"            print(results[index])
    input_dict = {""text"": test_text}
",4
"        label, key = 1, ""porn""
    else:
        label, key = 0, ""not_porn""
    return label, key

",4
"        label = int(np.argmax(predict_out[index]))
",4
"        result_i['porn_detection_key'] = key
        result_i['porn_probs'] = float('%.4f' % predict_out[index, 1])
        result_i['not_porn_probs'] = float('%.4f' % (predict_out[index, 0]))
        result.append(result_i)
    return result
",4
"class PornDetectionLSTM(hub.NLPPredictionModule):
    def _initialize(self):
        """"""
        initialize with the necessary elements
        """"""
",4
"        place = fluid.CPUPlace()
        exe = fluid.Executor(place)
        program, feed_target_names, fetch_targets = fluid.io.load_inference_model(
            dirname=self.pretrained_model_path, executor=exe)

",4
"                    ""sentence_feature"": var
                }
        return inputs, outputs, program

    @serving
",4
"             batch_size(int): the program deals once with one batch

",4
"        except:
            use_gpu = False

        if texts != [] and isinstance(texts, list) and data == {}:
            predicted_data = texts
",4
"    porn_detection_lstm.context()
",4
"    for index, text in enumerate(test_text):
        results[index][""text""] = text
    for index, result in enumerate(results):
        if six.PY2:
            print(
",4
"                json.dumps(results[index], encoding=""utf8"", ensure_ascii=False))
        else:
",4
"            print(results[index])
# -*- coding: utf-8 -*-
import io
import numpy as np
",4
"        label, key = 0, ""not_porn""
",4
"    """"""
    result = []
    padding = vocab['<PAD>']
    unknown = vocab['<UNK>']
    for index, text in enumerate(predicted_data):
",4
"
def postprocess(predict_out, texts):
",4
"    """"""
    Convert model's output tensor to pornography label
    """"""
    result = []
",4
"        result.append(result_i)
    return result
# -*- coding:utf-8 -*-
from __future__ import absolute_import
from __future__ import division
",4
"from __future__ import print_function

import json
import math
import os
",4
"        Get the input ,output and program of the pretrained porn_detection_gru
        Args:
             trainable(bool): whether fine-tune the pretrained parameters of porn_detection_gru or not
        Returns:
             inputs(dict): the input variables of porn_detection_gru (words)
",4
"        Get the porn prediction results results with the texts as input

",4
"        elif texts == [] and isinstance(data, dict) and isinstance(
                data.get('text', None), list) and data['text']:
            predicted_data = data[""text""]
        else:
",4
"        iteration = int(math.ceil(len(predicted_data) / batch_size))
        results = []
",4
"
    def get_labels(self):
        """"""
        Get the labels which was used when pretraining
",4
"    for index, text in enumerate(test_text):
        results[index][""text""] = text
    for index, result in enumerate(results):
        if six.PY2:
",4
"            print(
",4
"    """"""
    load the given vocabulary
    """"""
    vocab = {}
    with io.open(file_path, 'r', encoding='utf8') as f:
",4
"            vocab[line.rstrip()] = int(i)
    return vocab


",4
"def get_predict_label(pos_prob):
    """"""
    Convert the prediction probabilities to label
    """"""
",4
"    """"""
    Convert model's output tensor to pornography label
    """"""
",4
"
",4
"import paddlehub as hub
from paddlehub.common.logger import logger
",4
"
",4
"            gpu_config.disable_glog_info()
",4
"        Get the input ,output and program of the pretrained lac

        Args:
             trainable(bool): whether fine-tune the pretrained parameters of lac or not

",4
"        self.interventer = Interventer(self.unigram_dict_path, dict_path)

",4
"    def del_user_dict(self, ):
        """"""
        Delete the costomized dictionary if you don't wanna exploit the self-defined dictionary any longer
",4
"        """"""

",4
"             texts(list): each element's type is unicode in python2.7
        """"""
        if six.PY2:
            unicode_texts = []
            for text in texts:
",4
"        for i, text in enumerate(texts):
            text_inds = word_to_ids(
                text,
",4
"            lod.append(len(text_inds) + lod[i])
",4
"             use_gpu(bool): whether use gpu to predict or not
             batch_size(int): the program deals once with one batch
             user_dict(None): the parameter is not to be recommended. Please set the dictionause the function set_user_dict()

        Returns:
",4
"        elif texts == [] and isinstance(data, dict) and isinstance(
",4
"        predicted_data = self.to_unicode(predicted_data)

        # drop the empty string like """" in predicted_data
        empty_str_indexes = self._get_index(predicted_data)
        predicted_data = [data for data in predicted_data if data != """"]
",4
"        results = []
        for i in range(iteration):
            if i < (iteration - 1):
                batch_data = predicted_data[start_idx:(start_idx + batch_size)]
            else:
",4
"            results += batch_result

        for index in empty_str_indexes:
",4
"        results = self.lexical_analysis(
            texts=input_data,
",4
"        return self.tag_name_dict

    def add_module_config_arg(self):
        """"""
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
",4
"            '--return_tag',
            type=ast.literal_eval,
            default=True,
            help=""whether return tags of results or not"")
",4
"                    input_data = [args.input_text]
",4
"    lac = LAC(user_dict=""user.dict"")
    # or use the fuction user_dict to set
    # lac.set_user_dict(""user.dict"")
",4
"
    test_text = [
        ""ä»å¤©æ¯ä¸ªå¥½æ¥å­"", ""å¤©æ°é¢æ¥è¯´ä»å¤©è¦ä¸é¨"", """", ""ä¸ä¸ç­å°éé©¬ä¸å°±è¦å°äº"", """", ""è°æä»½éä¸è½å¤ï¼ä¹ä¸è½å°ï¼å³éæè½æ­£å¥½"",
        """", """"
",4
"    ]

",4
"            print(result['word'])
",4
"            print(result['tag'])

    # delete the costomized dictionary
    lac.del_user_dict()
",4
"            print(result['word'])

",4
"            param_attr=fluid.ParamAttr(
                initializer=fluid.initializer.Uniform(
                    low=-init_bound, high=init_bound),
",4
"                    low=-init_bound, high=init_bound),
                regularizer=fluid.regularizer.L2DecayRegularizer(
",4
"
",4
"        if six.PY2:
            self.lac_query_list = [
                lac_query[""word""][index].encode(""utf8"") + ""/"" +
                lac_query[""tag""][index].encode(""utf8"")
                for index in range(length)
",4
"            ]
        else:
            self.lac_query_list = [
                lac_query[""word""][index] + ""/"" + lac_query[""tag""][index]
                for index in range(length)
",4
"            index = phrase.rfind(""/"")
            word = phrase[0:index]
            self.seg_query_list.append(word)
        self.seg_query_str = "" "".join(self.seg_query_list)
",4
"                 left_bound=0,
                 right_bound=0,
                 left_char_bound=0,
                 right_char_bound=0):
",4
"        self.start_index = start_index  # å½ä¸­çè¯çèµ·å§ä½ç½®ï¼charçº§å«
        self.end_index = end_index  # å½ä¸­çè¯çç»æä½ç½®ï¼charçº§å«
",4
"
",4
"
    def load_dict(self):
        """"""load unigram dict and user dict""""""
        import ahocorasick
        self.total_count = 0.0
",4
"        query_len = 0
        for word_index, word in enumerate(query.seg_query_list):
            query_len += len(word)
            if query_len > end_index:
                bound.right_bound = word_index
",4
"        æ¯è¾ç¨æ·è¯å¸ç»åºçè¯åååè¯ç»æï¼æ ¹æ®æåå³å®æ¯å¦æ¿æ¢
        """"""
",4
"            phrase_left += ""/"" + query.lac_query_list[bound.left_bound].split(
                '/')[1]
            new_phrase_list.append(phrase_left)
        new_phrase_list.append(match_info[1][0] + ""/"" + match_info[1][1])
        if phrase_right != """":
",4
"                '/')[1]
            new_phrase_list.append(phrase_right)
",4
"                #print >> sys.stderr, ""skipped %s, old_lm_score: %.5f, "" \
",4
"                #        ""new_lm_score: %.5f"" % ("" "".join(new_phrase_list), old_lm_score, new_lm_score)
                continue
            # éå°çç¬¬ä¸ä¸ªå¹éå°çç»æ
",4
"                last_bound = bound
                last_phrase_list = new_phrase_list
                last_lm_score = new_lm_score
            else:
",4
"                    # è¥åæ°é«äºä¸æ¬¡ç»æï¼åè¦çï¼å¦åä¸¢å¼
                    last_bound = bound
                    last_phrase_list = new_phrase_list
                    last_lm_score = new_lm_score
",4
"                 value_func=None):
",4
"            continue
        if reverse:
",4
"        sent_out = []
",4
"                continue
            # for the beginning of word
",4
"            parital_word += sent[ind]
        # append the last word, except for len(tags)=0
        if len(sent_out) < len(tags_out):
",4
"            self.directory, ""deeplabv3p_xception65_humanseg_model"")
        self._set_config()

    def _set_config(self):
        """"""
",4
"        predictor config setting
",4
"            data (dict): key is 'image', the corresponding value is the path to image.
",4
"            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            visualization (bool): Whether to save image or not.
",4
"                data (numpy.ndarray): data of post processed image.
        """"""
",4
"                paths = list()
            paths += data['image']

",4
"                    output_dir=output_dir,
",4
"            prog='hub run {}'.format(self.name),
            usage='%(prog)s',
            add_help=True)

        self.arg_input_group = self.parser.add_argument_group(
",4
"
    def add_module_config_arg(self):
",4
"            type=str,
            default='humanseg_output',
            help=""The directory to save output images."")
",4
"        self.arg_input_group.add_argument(
            '--input_path', type=str, help=""path to image."")
",4
"from collections import OrderedDict

",4
"        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        paths (list[str]): paths to images.
",4
"        for im_path in paths:
            each = OrderedDict()
            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
            im = cv2.imread(im_path).astype('float32')
",4
"            each = OrderedDict()
            each['org_im'] = im
",4
"        element['image'] = img
        yield element
# coding=utf-8
",4
"from __future__ import absolute_import
from __future__ import division
",4
"
        if visualization:
            check_dir(output_dir)
",4
"            result['data'] = rgba[:, :, 3]
    return result


",4
"        save_im_path = os.path.join(
            output_dir, im_prefix + 'time={}'.format(int(time.time())) + ext)

    return save_im_path
",4
"    type=""CV/semantic-segmentation"",
",4
"    def _initialize(self):
        self.default_pretrained_model_path = os.path.join(
            self.directory, ""ace2p_human_parsing"")
",4
"        cpu_config.disable_glog_info()
        cpu_config.disable_gpu()
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def segmentation(self,
",4
"                     data=None,
",4
"                     batch_size=1,
                     use_gpu=False,
                     output_dir='ace2p_output',
                     visualization=False):
",4
"                int(_places[0])
            except:
                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"        # get all data
",4
"        rotation = 0  # rotation angle, used for obtaining affine matrix in preprocess.
",4
"            for image_id in range(batch_size):
                try:
                    batch_data.append(all_data[handle_id + image_id])
                except:
",4
"                out = postprocess(
                    data_out=data_out[0].as_ndarray()[i],
                    org_im=batch_data[i]['org_im'],
",4
"        return res

",4
"            params_filename=params_filename)

    @serving
",4
"        images_decode = [base64_to_cv2(image) for image in images]
",4
"        results = self.segmentation(images_decode, **kwargs)
        results = [{
            'data': cv2_to_base64(result['data'])
        } for result in results]
        return results
",4
"        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
        results = self.segmentation(
",4
"        """"""
        Add the command config options.
        """"""
",4
"            '--visualization',
",4
"            type=ast.literal_eval,
            default=False,
            help=""whether to save output as images."")
        self.arg_config_group.add_argument(
            '--batch_size',
",4
"    x, y, w, h = box[:4]
    return _xywh2cs(x, y, w, h, aspect_ratio)


def _xywh2cs(x, y, w, h, aspect_ratio, pixel_std=200):
",4
"    return center, scale


def preprocess(org_im, scale, rotation):
    image = org_im.copy()
",4
"    img_mean = np.array([0.406, 0.456, 0.485]).reshape((1, 1, 3))
",4
"    img_std = np.array([0.225, 0.224, 0.229]).reshape((1, 1, 3))
    image = image.astype(np.float)
",4
"

def reader(images, paths, scale, rotation):
",4
"            each = OrderedDict()
            each['org_im'] = im
            each['org_im_path'] = 'ndarray_time={}.jpg'.format(
                round(time.time(), 6) * 1e6)
            component.append(each)
",4
"
    for element in component:
",4
"import base64
import cv2
import numpy as np
from PIL import Image

",4
"    data = cv2.imencode('.jpg', image)[1]
    return base64.b64encode(data.tostring()).decode('utf8')


",4
"    # save image path
",4
"def get_affine_transform(center,
",4
"                         scale,
                         rot,
                         output_size,
                         shift=np.array([0, 0], dtype=np.float32),
",4
"                         inv=0):
    if not isinstance(scale, np.ndarray) and not isinstance(
",4
"
    image_center = image_info['image_center']
    image_scale = image_info['image_scale']
",4
"
",4
"            int(_places[0])
            use_gpu = True
",4
"        except:
",4
"        Set face detector.
        Args:
            face_detector_module (class): module to detect faces.
        """"""
",4
"        for iter_id in range(loop_num):
            batch_data = list()
            handle_id = iter_id * batch_size
            for element_id in range(batch_size):
                try:
",4
"            image_tensor = PaddleTensor(image_arr.copy())
            data_out = self.gpu_predictor.run([
                image_tensor
",4
"            ]) if use_gpu else self.cpu_predictor.run([image_tensor])
            # len(data_out) == 1
",4
"            ]
            interval_left = sum(element_image_num[0:i])
            interval_right = interval_left + element_image_num[i]
",4
"                detected_faces=detect_faces_list,
                output_dir=output_dir,
",4
"                visualization=visualization)
            res.append(out)
        return res

    def save_inference_model(self,
",4
"                                  combined)

    def _save_detector_model(self,
",4
"        self.face_detector.save_inference_model(dirname, model_filename,
                                                params_filename, combined)

    def _save_classifier_model(self,
",4
"        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
",4
"        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
",4
"            description=
            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
",4
"        results = self.face_detection(
",4
"            default='detection_result',
            help=""The directory to save output images."")
        self.arg_config_group.add_argument(
            '--visualization',
",4
"        self.arg_input_group.add_argument(
",4
"            '--confs_threshold',
            type=ast.literal_eval,
            default=0.6,
            help=""confidence threshold."")
# coding=utf-8
",4
"import time
",4
"        # IOU
        area = (det[:, 2] - det[:, 0] + 1) * (det[:, 3] - det[:, 1] + 1)
",4
"        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        o = inter / (area[0] + area[:] - inter)
        # nms
",4
"        max_score = np.max(det_accu[:, 4])
        det_accu_sum = np.zeros((1, 5))
        det_accu_sum[:, 0:4] = np.sum(
            det_accu[:, 0:4], axis=0) / np.sum(det_accu[:, -1:])
        det_accu_sum[:, 4] = max_score
",4
"    dets = dets[0:750, :]
    return dets
",4
"         shift=0,
",4
"    image_out = cv2.warpAffine(image, M, res)
    return image_out, M


def color_normalize(image, mean, std=None):
",4
"    return image_in


",4
"
    Args:
",4
"    """"""
    component = list()
    if paths is not None:
        assert type(paths) is list, ""paths should be a list.""
        for im_path in paths:
",4
"
    for element in component:
        if use_multi_scale:
",4
"            scale_res = list()
            detect_faces = list()
            for scale in multi_scales:
                _detect_res = face_detector.face_detection(
",4
"                }
",4
"        yield element
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"    """"""
    if not os.path.exists(dir_path):
",4
"    # extension
    img = Image.fromarray(org_im[:, :, ::-1])
    if img.mode == 'RGBA':
        ext = '.png'
",4
"                       (bbox['left'], bbox['bottom']),
                       (bbox['right'], bbox['bottom']),
                       (bbox['right'], bbox['top']),
",4
"            draw.rectangle(
                xy=(bbox['left'], bbox['top'] - (textsize_height + 5),
                    bbox['left'] + textsize_width + 10, bbox['top'] - 3),
                fill=box_fill)
            draw.text(
",4
"
",4
"    output = dict()
",4
"        check_dir(output_dir)
        save_im_path = get_save_image_name(org_im, org_im_path, output_dir)
        cv2.imwrite(save_im_path, org_im)
        draw_bounding_box_on_image(save_im_path, output['data'])
",4
"
import ast
import argparse
import os

",4
"from paddlehub.module.module import moduleinfo, runnable, serving

from ultra_light_fast_generic_face_detector_1mb_320.processor import postprocess, base64_to_cv2
from ultra_light_fast_generic_face_detector_1mb_320.data_feed import reader

",4
"@moduleinfo(
",4
"    summary=
    ""Ultra-Light-Fast-Generic-Face-Detector-1MB is a high-performance object detection model release on https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB."",
    version=""1.1.2"")
class FaceDetector320(hub.Module):
",4
"
        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
            use_gpu = True
",4
"        except:
            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
",4
"                             model_filename=None,
                             params_filename=None,
",4
"                       batch_size=1,
",4
"            except:
                raise RuntimeError(
",4
"        loop_num = int(np.ceil(total_num / batch_size))

        res = []
        for iter_id in range(loop_num):
",4
"            for image_id in range(batch_size):
                try:
                    batch_data.append(all_data[handle_id + image_id])
                except:
                    pass
",4
"
            # postprocess one by one
            for i in range(len(batch_data)):
                out = postprocess(
",4
"        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.face_detection(images_decode, **kwargs)
        return results
",4
"            add_help=True)
        self.arg_input_group = self.parser.add_argument_group(
            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
",4
"            paths=[args.input_path],
",4
"            batch_size=args.batch_size,
            use_gpu=args.use_gpu,
            output_dir=args.output_dir,
            visualization=args.visualization)
",4
"
    Args:
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        paths (list[str]): paths to images.
",4
"    if images is not None:
        assert type(images) is list, ""images should be a list.""
        for im in images:
            each = OrderedDict()
",4
"import time
",4
"
import base64
import cv2
",4
"    data = cv2.imdecode(data, cv2.IMREAD_COLOR)
    return data


",4
"def area_of(left_top, right_bottom):
    hw = np.clip(right_bottom - left_top, 0.0, None)
    return hw[..., 0] * hw[..., 1]


",4
"    area0 = area_of(boxes0[..., :2], boxes0[..., 2:])
    area1 = area_of(boxes1[..., :2], boxes1[..., 2:])
    return overlap_area / (area0 + area1 - overlap_area + eps)
",4
"    picked = []
    # _, indexes = scores.sort(descending=True)
",4
"    while len(indexes) > 0:
        # current = indexes[0]
        current = indexes[-1]
        picked.append(current)
        if 0 < top_k == len(picked) or len(indexes) == 1:
",4
"            break
        current_box = boxes[current, :]
        # indexes = indexes[1:]
        indexes = indexes[:-1]
",4
"                orig_im_shape,
                orig_im_path,
                output_dir,
                visualization,
",4
"        subset_boxes = boxes[mask, :]
        box_probs = np.concatenate([subset_boxes, probs.reshape(-1, 1)], axis=1)
",4
"
    for data in picked_box_probs:
",4
"
def face_detector_320():
    _319 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
    _322 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _323 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=2)
",4
"    _440 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _441 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=2)
    _449 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
    _452 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=-1)
    _453 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=4)
",4
"    _463 = fluid.layers.fill_constant(
",4
"        shape=[1], dtype='float32', value=0.10000000149011612)
    _465 = fluid.layers.create_parameter(
        dtype='float32',
        shape=[1, 4420, 2],
",4
"        name='_473',
",4
"        default_initializer=Constant(0.0))
    _478 = fluid.layers.fill_constant(shape=[1], dtype='float32', value=2.0)
    _483 = fluid.layers.fill_constant(shape=[1], dtype='float32', value=2.0)
    _input = fluid.layers.data(
",4
"        dtype='float32',
        shape=[1, 3, 240, 320],
        name='_input',
        append_batch_size=False)
    _325 = fluid.layers.assign(_322)
",4
"    _412 = fluid.layers.assign(_409)
    _425 = fluid.layers.assign(_422)
    _426 = fluid.layers.assign(_423)
    _443 = fluid.layers.assign(_440)
    _444 = fluid.layers.assign(_441)
",4
"        momentum=0.8999999761581421,
",4
"        filter_size=[3, 3],
",4
"        is_test=True,
        param_attr='_base_net_1_1_weight',
",4
"        use_global_stats=False,
        name='_255')
    _256 = fluid.layers.relu(_255, name='_256')
",4
"        stride=[1, 1],
",4
"        param_attr='_base_net_2_3_weight',
        name='_257',
        bias_attr=False)
",4
"    _258 = fluid.layers.batch_norm(
        _257,
        momentum=0.8999999761581421,
",4
"    _260 = fluid.layers.conv2d(
        _259,
        num_filters=32,
",4
"        param_attr='_base_net_3_0_weight',
        name='_260',
        bias_attr=False)
    _261 = fluid.layers.batch_norm(
",4
"        groups=1,
        param_attr='_base_net_3_3_weight',
        name='_263',
",4
"        data_layout='NCHW',
        is_test=True,
        param_attr='_base_net_3_4_weight',
        bias_attr='_base_net_3_4_bias',
        moving_mean_name='_base_net_3_4_running_mean',
",4
"        use_global_stats=False,
        name='_264')
    _265 = fluid.layers.relu(_264, name='_265')
",4
"        param_attr='_base_net_4_1_weight',
        bias_attr='_base_net_4_1_bias',
        moving_mean_name='_base_net_4_1_running_mean',
",4
"        momentum=0.8999999761581421,
        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"        dilation=[1, 1],
        groups=64,
        param_attr='_base_net_5_0_weight',
        name='_272',
",4
"        bias_attr='_base_net_5_1_bias',
",4
"        groups=1,
        param_attr='_base_net_5_3_weight',
        name='_275',
",4
"        data_layout='NCHW',
",4
"        is_test=True,
        param_attr='_base_net_5_4_weight',
        bias_attr='_base_net_5_4_bias',
        moving_mean_name='_base_net_5_4_running_mean',
",4
"        groups=1,
        param_attr='_base_net_6_3_weight',
",4
"        name='_281',
        bias_attr=False)
    _282 = fluid.layers.batch_norm(
        _281,
        momentum=0.8999999761581421,
",4
"        moving_mean_name='_base_net_6_4_running_mean',
        moving_variance_name='_base_net_6_4_running_var',
",4
"        num_filters=8,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"        _283,
        num_filters=8,
        filter_size=[1, 1],
        stride=[1, 1],
        padding=[0, 0],
",4
"        name='_311',
        bias_attr=False)
    _285 = fluid.layers.batch_norm(
",4
"        data_layout='NCHW',
        is_test=True,
",4
"        use_global_stats=False,
",4
"        _291,
        momentum=0.9900000095367432,
        epsilon=9.999999747378752e-06,
",4
"        bias_attr='_base_net_7_branch1_0_bn_bias',
        moving_mean_name='_base_net_7_branch1_0_bn_running_mean',
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"        name='_299')
    _312 = fluid.layers.batch_norm(
        _311,
        momentum=0.9900000095367432,
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"        filter_size=[3, 3],
        stride=[1, 1],
",4
"        bias_attr=False)
    _300 = fluid.layers.conv2d(
        _299,
        num_filters=12,
        filter_size=[3, 3],
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
        is_test=True,
",4
"        param_attr='_base_net_7_branch0_1_bn_weight',
        bias_attr='_base_net_7_branch0_1_bn_bias',
        moving_mean_name='_base_net_7_branch0_1_bn_running_mean',
        moving_variance_name='_base_net_7_branch0_1_bn_running_var',
",4
"        filter_size=[3, 3],
        stride=[1, 1],
",4
"        name='_296',
        bias_attr=False)
    _303 = fluid.layers.conv2d(
        _302,
        num_filters=16,
",4
"        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
        dilation=[1, 1],
",4
"        _296,
        momentum=0.9900000095367432,
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
        is_test=True,
",4
"        is_test=True,
        param_attr='_base_net_7_branch2_2_bn_weight',
        bias_attr='_base_net_7_branch2_2_bn_bias',
",4
"        _305,
        num_filters=16,
        filter_size=[3, 3],
",4
"        _306,
",4
"        name='_310')
    _313 = fluid.layers.elementwise_add(x=_310, y=_312, name='_313')
",4
"        param_attr='_classification_headers_0_0_weight',
        name='_315',
        bias_attr='_classification_headers_0_0_bias')
    _329 = fluid.layers.conv2d(
        _314,
",4
"        param_attr='_base_net_8_0_weight',
        name='_343',
",4
"        param_attr='_classification_headers_0_2_weight',
",4
"        name='_346',
        bias_attr=False)
    _320 = fluid.layers.shape(_318)
",4
"    _350 = fluid.layers.batch_norm(
        _349,
        momentum=0.8999999761581421,
        epsilon=9.999999747378752e-06,
",4
"        is_test=True,
        param_attr='_base_net_9_1_weight',
",4
"    _328 = fluid.layers.reshape(
        _318, name='_328', actual_shape=_327_cast, shape=[1, -1, 2])
    _341_cast = fluid.layers.cast(_341, dtype='int32')
    _342 = fluid.layers.reshape(
        _332, name='_342', actual_shape=_341_cast, shape=[1, -1, 4])
",4
"        filter_size=[1, 1],
        stride=[1, 1],
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
        is_test=True,
",4
"        _355,
        momentum=0.8999999761581421,
",4
"        bias_attr='_base_net_10_1_bias',
",4
"        _358,
        momentum=0.8999999761581421,
",4
"        moving_mean_name='_base_net_10_4_running_mean',
",4
"    _361 = fluid.layers.conv2d(
        _360,
        num_filters=128,
        filter_size=[3, 3],
",4
"        num_filters=128,
        filter_size=[3, 3],
",4
"        padding=[0, 0],
        dilation=[1, 1],
",4
"        num_filters=256,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"    _366 = fluid.layers.shape(_364)
    _380 = fluid.layers.shape(_378)
    _393 = fluid.layers.batch_norm(
        _392,
",4
"        data_layout='NCHW',
",4
"        is_test=True,
        param_attr='_base_net_11_4_weight',
        bias_attr='_base_net_11_4_bias',
        moving_mean_name='_base_net_11_4_running_mean',
        moving_variance_name='_base_net_11_4_running_var',
",4
"        use_global_stats=False,
        name='_393')
    _367 = fluid.layers.gather(input=_366, index=_365)
",4
"        padding=[0, 0],
",4
"        momentum=0.8999999761581421,
",4
"        name='_399')
    _400 = fluid.layers.relu(_399, name='_400')
    _401 = fluid.layers.conv2d(
        _400,
",4
"        num_filters=256,
        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
",4
"        dilation=[1, 1],
        groups=256,
        param_attr='_classification_headers_2_0_weight',
        name='_401',
        bias_attr='_classification_headers_2_0_bias')
",4
"        padding=[0, 0],
        dilation=[1, 1],
        groups=1,
        param_attr='_extras_0_0_weight',
",4
"        name='_417',
        bias_attr='_regression_headers_2_2_bias')
    _431 = fluid.layers.conv2d(
        _430,
",4
"        dilation=[1, 1],
        groups=1,
        param_attr='_extras_0_2_2_weight',
        name='_433',
",4
"        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
",4
"        dilation=[1, 1],
        groups=1,
        param_attr='_classification_headers_3_weight',
",4
"        num_filters=12,
        filter_size=[3, 3],
",4
"        param_attr='_regression_headers_3_weight',
        name='_447',
",4
"    _438 = fluid.layers.shape(_436)
    _450 = fluid.layers.shape(_448)
    _439 = fluid.layers.gather(input=_438, index=_437)
    _451 = fluid.layers.gather(input=_450, index=_449)
    _442 = fluid.layers.assign(_439)
",4
"    _454 = fluid.layers.assign(_451)
    _445 = fluid.layers.concat([_442, _443, _444], axis=0)
    _457 = fluid.layers.concat([_454, _455, _456], axis=0)
",4
"    _484 = fluid.layers.elementwise_div(x=_482, y=_483, name='_484')
    _480 = fluid.layers.elementwise_sub(x=_476, y=_479, name='_480')
",4
"
    def if_exist(var):
        b = os.path.exists(os.path.join(param_dir, var.name))
        return b
",4
"import paddlehub as hub
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
from paddlehub.module.module import moduleinfo, runnable, serving
",4
"from ultra_light_fast_generic_face_detector_1mb_640.processor import postprocess, base64_to_cv2
from ultra_light_fast_generic_face_detector_1mb_640.data_feed import reader

",4
"    author=""paddlepaddle"",
    author_email=""paddle-dev@baidu.com"",
    summary=
    ""Ultra-Light-Fast-Generic-Face-Detector-1MB is a high-performance object detection model release on https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB."",
",4
"    def _initialize(self):
        self.default_pretrained_model_path = os.path.join(
            self.directory, ""ultra_light_fast_generic_face_detector_1mb_640"")
",4
"            gpu_config.disable_glog_info()
",4
"                             dirname,
                             model_filename=None,
                             params_filename=None,
",4
"            output_dir (str): The path to store output images.
",4
"            ]) if use_gpu else self.cpu_predictor.run([batch_image])
",4
"                    orig_im_shape=batch_data[i]['orig_im_shape'],
",4
"    @runnable
    def run_cmd(self, argvs):
        """"""
        Run as a command.
        """"""
",4
"        results = self.face_detection(
            paths=[args.input_path],
            batch_size=args.batch_size,
            use_gpu=args.use_gpu,
",4
"            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
            '--output_dir',
            type=str,
",4
"            default=False,
            help=""whether to save output as images."")
",4
"        self.arg_config_group.add_argument(
            '--batch_size',
            type=ast.literal_eval,
            default=1,
",4
"
    def add_module_input_arg(self):
        """"""
",4
"        Add the command input options.
        """"""
",4
"        self.arg_input_group.add_argument(
            '--input_path', type=str, help=""path to image."")
",4
"
    Args:
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        paths (list[str]): paths to images.
",4
"
    Yield:
        each (collections.OrderedDict): info of original image, preprocessed image.
    """"""
    component = list()
",4
"            each['orig_im_shape'] = im.shape  # height, width, channel
",4
"
",4
"    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
    elif os.path.isfile(dir_path):
",4
"        os.remove(dir_path)
        os.makedirs(dir_path)


",4
"def get_image_ext(image):
    if image.shape[2] == 4:
        return "".png""
",4
"        boxes (numpy.ndaray): boxes coordinate,  with shape [num, 4]
        orig_im (numpy.ndarray): original image.
        orig_im_shape (list): shape pf original image.
        orig_im_path (list): path of riginal image.
        output_dir (str): output directory to store image.
",4
"
",4
"# coding=utf-8
",4
"from paddle.fluid.initializer import Constant
from paddle.fluid.param_attr import ParamAttr
import paddle.fluid as fluid


",4
"    _369 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=2)
",4
"    _379 = fluid.layers.fill_constant(shape=[1], dtype='int32', value=0)
",4
"    _463 = fluid.layers.fill_constant(
",4
"        name='_467',
        attr='_467',
",4
"    _443 = fluid.layers.assign(_440)
    _444 = fluid.layers.assign(_441)
    _455 = fluid.layers.assign(_452)
",4
"        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
",4
"        name='_246')
",4
"        num_filters=16,
        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
        dilation=[1, 1],
",4
"        name='_248',
",4
"        dilation=[1, 1],
        groups=1,
        param_attr='_base_net_1_3_weight',
        name='_251',
        bias_attr=False)
",4
"        moving_mean_name='_base_net_1_4_running_mean',
        moving_variance_name='_base_net_1_4_running_var',
        use_global_stats=False,
",4
"        name='_254',
        bias_attr=False)
    _255 = fluid.layers.batch_norm(
        _254,
        momentum=0.8999999761581421,
",4
"        name='_258')
",4
"        moving_variance_name='_base_net_3_1_running_var',
        use_global_stats=False,
",4
"        _263,
        momentum=0.8999999761581421,
        epsilon=9.999999747378752e-06,
        data_layout='NCHW',
        is_test=True,
",4
"        param_attr='_base_net_3_4_weight',
        bias_attr='_base_net_3_4_bias',
",4
"    _269 = fluid.layers.conv2d(
        _268,
        num_filters=64,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"        groups=64,
",4
"        param_attr='_base_net_5_0_weight',
        name='_272',
        bias_attr=False)
    _273 = fluid.layers.batch_norm(
",4
"    _274 = fluid.layers.relu(_273, name='_274')
",4
"    _275 = fluid.layers.conv2d(
        _274,
        num_filters=64,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"        use_global_stats=False,
        name='_279')
",4
"    _283 = fluid.layers.relu(_282, name='_283')
    _284 = fluid.layers.conv2d(
",4
"        bias_attr=False)
    _298 = fluid.layers.conv2d(
        _283,
        num_filters=8,
        filter_size=[1, 1],
",4
"        padding=[0, 0],
        dilation=[1, 1],
",4
"        _291,
        momentum=0.9900000095367432,
        epsilon=9.999999747378752e-06,
",4
"        param_attr='_base_net_7_branch2_0_bn_weight',
        bias_attr='_base_net_7_branch2_0_bn_bias',
        moving_mean_name='_base_net_7_branch2_0_bn_running_mean',
        moving_variance_name='_base_net_7_branch2_0_bn_running_var',
        use_global_stats=False,
",4
"        param_attr='_base_net_7_branch1_1_conv_weight',
        name='_293',
        bias_attr=False)
    _300 = fluid.layers.conv2d(
",4
"        _299,
        num_filters=12,
        filter_size=[3, 3],
        stride=[1, 1],
",4
"        padding=[1, 1],
        dilation=[1, 1],
        groups=1,
",4
"        data_layout='NCHW',
        is_test=True,
        param_attr='_base_net_7_branch0_1_bn_weight',
        bias_attr='_base_net_7_branch0_1_bn_bias',
        moving_mean_name='_base_net_7_branch0_1_bn_running_mean',
",4
"    _302 = fluid.layers.relu(_301, name='_302')
    _289 = fluid.layers.conv2d(
        _288,
        num_filters=16,
        filter_size=[3, 3],
",4
"        is_test=True,
        param_attr='_base_net_7_branch1_2_bn_weight',
",4
"        bias_attr='_base_net_7_branch1_2_bn_bias',
",4
"        _305,
        num_filters=16,
        filter_size=[3, 3],
        stride=[1, 1],
",4
"        padding=[5, 5],
        dilation=[5, 5],
        groups=1,
        param_attr='_base_net_7_branch2_3_conv_weight',
",4
"        param_attr='_base_net_7_branch2_3_bn_weight',
        bias_attr='_base_net_7_branch2_3_bn_bias',
        moving_mean_name='_base_net_7_branch2_3_bn_running_mean',
        moving_variance_name='_base_net_7_branch2_3_bn_running_var',
        use_global_stats=False,
",4
"        dilation=[1, 1],
",4
"        moving_mean_name='_base_net_8_1_running_mean',
",4
"    _345 = fluid.layers.relu(_344, name='_345')
    _318 = fluid.layers.transpose(_317, perm=[0, 2, 3, 1], name='_318')
    _332 = fluid.layers.transpose(_331, perm=[0, 2, 3, 1], name='_332')
    _346 = fluid.layers.conv2d(
",4
"        use_global_stats=False,
        name='_347')
    _321 = fluid.layers.gather(input=_320, index=_319)
    _335 = fluid.layers.gather(input=_334, index=_333)
",4
"        _348,
        num_filters=128,
        filter_size=[3, 3],
",4
"    _341 = fluid.layers.concat([_338, _339, _340], axis=0)
",4
"    _350 = fluid.layers.batch_norm(
",4
"        name='_350')
    _327_cast = fluid.layers.cast(_327, dtype='int32')
    _328 = fluid.layers.reshape(
        _318, name='_328', actual_shape=_327_cast, shape=[1, -1, 2])
",4
"    _352 = fluid.layers.conv2d(
",4
"        filter_size=[1, 1],
",4
"        moving_variance_name='_base_net_10_4_running_var',
",4
"        filter_size=[3, 3],
",4
"        padding=[1, 1],
        dilation=[1, 1],
",4
"        _360,
        num_filters=128,
        filter_size=[3, 3],
",4
"        param_attr='_base_net_11_0_weight',
        name='_389',
",4
"        momentum=0.8999999761581421,
        epsilon=9.999999747378752e-06,
",4
"        num_filters=4,
        filter_size=[1, 1],
        stride=[1, 1],
        padding=[0, 0],
        dilation=[1, 1],
",4
"        data_layout='NCHW',
",4
"        padding=[1, 1],
        dilation=[1, 1],
",4
"        bias_attr=False)
    _373 = fluid.layers.concat([_370, _371, _372], axis=0)
    _387 = fluid.layers.concat([_384, _385, _386], axis=0)
    _396 = fluid.layers.batch_norm(
        _395,
",4
"        use_global_stats=False,
        name='_399')
    _400 = fluid.layers.relu(_399, name='_400')
    _401 = fluid.layers.conv2d(
",4
"        filter_size=[3, 3],
        stride=[1, 1],
        padding=[1, 1],
",4
"        dilation=[1, 1],
        groups=256,
        param_attr='_regression_headers_2_0_weight',
        name='_415',
        bias_attr='_regression_headers_2_0_bias')
",4
"        padding=[0, 0],
",4
"        _402,
        num_filters=4,
",4
"        groups=1,
        param_attr='_classification_headers_2_2_weight',
        name='_403',
",4
"    _417 = fluid.layers.conv2d(
        _416,
        num_filters=8,
        filter_size=[1, 1],
        stride=[1, 1],
",4
"    _424 = fluid.layers.assign(_421)
    _435 = fluid.layers.conv2d(
        _434,
",4
"    _414 = fluid.layers.reshape(
        _404, name='_414', actual_shape=_413_cast, shape=[1, -1, 2])
    _427_cast = fluid.layers.cast(_427, dtype='int32')
",4
"    _445_cast = fluid.layers.cast(_445, dtype='int32')
    _446 = fluid.layers.reshape(
",4
"        _436, name='_446', actual_shape=_445_cast, shape=[1, -1, 2])
    _457_cast = fluid.layers.cast(_457, dtype='int32')
",4
"    _458 = fluid.layers.reshape(
        _448, name='_458', actual_shape=_457_cast, shape=[1, -1, 4])
    _459 = fluid.layers.concat([_328, _374, _414, _446], axis=1)
    _460 = fluid.layers.concat([_342, _388, _428, _458], axis=1)
",4
"        b = os.path.exists(os.path.join(param_dir, var.name))
        return b

",4
"from __future__ import division

import ast
",4
"import numpy as np
",4
"    author_email="""",
    summary=
    ""Pyramidbox-Lite-Mobile-Mask is a high-performance face detection model used to detect whether people wear masks."",
    version=""1.3.0"")
class PyramidBoxLiteMobileMask(hub.Module):
",4
"    def _initialize(self, face_detector_module=None):
        """"""
        Args:
            face_detector_module (class): module to detect face.
",4
"        """"""
        predictor config setting
",4
"            use_gpu = True
        except:
            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"            gpu_config.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def set_face_detector_module(self, face_detector_module):
",4
"                       use_gpu=False,
                       visualization=False,
                       output_dir='detection_result',
",4
"                       use_multi_scale=False,
                       shrink=0.5,
                       confs_threshold=0.6):
",4
"        API for face detection.
",4
"            paths (list[str]): The paths of images.
",4
"        Returns:
            res (list[dict]): The result of face detection and save path of images.
",4
"                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
",4
"                images += data['data']

        # get all data
        all_element = list()
        for yield_data in reader(self.face_detector, shrink, confs_threshold,
",4
"        for iter_id in range(loop_num):
            batch_data = list()
            handle_id = iter_id * batch_size
            for element_id in range(batch_size):
                try:
",4
"                    batch_data.append(image_list[handle_id + element_id])
",4
"                except:
",4
"        predict_out = predict_out[1:]
        # postprocess one by one
        res = list()
        for i in range(len(all_element)):
",4
"                handled['face'] for handled in all_element[i]['preprocessed']
            ]
            interval_left = sum(element_image_num[0:i])
            interval_right = interval_left + element_image_num[i]
",4
"        return res

    def save_inference_model(self,
",4
"                               params_filename=None,
                               combined=True):
        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
",4
"            params_filename=params_filename)

    @serving
    def serving_method(self, images, **kwargs):
",4
"
    def add_module_config_arg(self):
        """"""
",4
"        Add the command config options.
",4
"            help=""confidence threshold."")
# coding=utf-8
import os
import math
import time
",4
"from collections import OrderedDict

import cv2
",4
"        det = np.delete(det, merge_index, 0)
",4
"         shift=0,
",4
"         scale=1.5,
         rotate=0,
         res_width=128,
         res_height=128):
    res = (res_width, res_height)
",4
"            idx1, 1] != -1:
        alpha = math.atan2(pts[idx2, 1] - pts[idx1, 1],
",4
"    rotate = rotate + alpha
    M = cv2.getRotationMatrix2D((c[0], c[1]), rotate,
                                res[0] / (2 * max_wh * scale))
    M[0, 2] = M[0, 2] - (c[0] - res[0] / 2.0)
",4
"    if image.shape[-1] == 1:
        image = np.repeat(image, axis=2)
    h, w, c = image.shape
    image = np.transpose(image, (2, 0, 1))
",4
"    image = np.subtract(image.reshape(c, -1), mean[:, np.newaxis]).reshape(
        -1, h, w)
",4
"    return image_in


def reader(face_detector, shrink, confs_threshold, images, paths, use_gpu,
           use_multi_scale):
",4
"    Args:
        face_detector (class): class to detect faces.
        shrink (float): parameter to control the resize scale in face_detector.
        confs_threshold (float): confidence threshold of face_detector.
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C], color space is BGR.
",4
"        element (collections.OrderedDict): info of original image, preprocessed image, contains 3 keys:
            org_im (numpy.ndarray) : original image.
            org_im_path (str): path to original image.
            preprocessed (list[OrderedDict]):each element contains 2 keys:
               face  (dict): face detected in the original image.
",4
"            component.append(each)
",4
"        for im in images:
            each = OrderedDict()
",4
"            component.append(each)
",4
"
    for element in component:
        if use_multi_scale:
            scale_res = list()
",4
"            detect_faces = list()
            for scale in multi_scales:
                _detect_res = face_detector.face_detection(
",4
"                    _s.append(_face_list)

",4
"
        yield element
# coding=utf-8
",4
"import time
",4
"from PIL import Image, ImageDraw

__all__ = ['base64_to_cv2', 'postprocess']
",4
"def base64_to_cv2(b64str):
",4
"    elif img.mode == 'RGB':
        ext = '.jpg'
",4
"    elif img.mode == 'L':  # black and white
",4
"                      width=2,
                      fill='red')
        # draw label
        text = bbox['label'] + "": %.2f%%"" % (100 * bbox['confidence'])
",4
"        textsize_width, textsize_height = draw.textsize(text=text)
        if image.mode == 'RGB' or image.mode == 'RGBA':
",4
"        detected_faces (list): faces detected in a picture.
",4
"        label_idx = np.argmax(confidence_out[index])
        label_confidence = confidence_out[index][label_idx]
        bbox = dict()
        bbox['label'] = label_list[label_idx]
        bbox['confidence'] = label_confidence
",4
"        cv2.imwrite(save_im_path, org_im)
        draw_bounding_box_on_image(save_im_path, output['data'])

    return output
",4
"import numpy as np
import paddle.fluid as fluid
import paddlehub as hub
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
",4
"from paddlehub.module.module import moduleinfo, runnable, serving

from pyramidbox_lite_mobile.data_feed import reader
from pyramidbox_lite_mobile.processor import postprocess, base64_to_cv2

",4
"        predictor config setting
",4
"            confs_threshold (float): confidence threshold.

",4
"                paths += data['image']
            elif 'data' in data:
                if images is None:
                    images = list()
",4
"                images += data['data']

        res = list()
        # process one by one
        for element in reader(images, paths, shrink):
",4
"
        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"            executor=exe,
            feeded_var_names=feeded_var_names,
            target_vars=target_vars,
",4
"            model_filename=model_filename,
            params_filename=params_filename)
",4
"        """"""
        images_decode = [base64_to_cv2(image) for image in images]
",4
"        results = self.face_detection(images_decode, **kwargs)
        return results

",4
"        Run as a command.
        """"""
        self.parser = argparse.ArgumentParser(
",4
"            usage='%(prog)s',
            add_help=True)
        self.arg_input_group = self.parser.add_argument_group(
",4
"            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
",4
"            default=False,
            help=""whether to save output as images."")

",4
"    image = image * scale
    return image, image_height, image_width


",4
"    if images is not None:
",4
"        assert type(images) is list, ""images should be a list.""
        for im in images:
",4
"    # save image path
    save_im_path = os.path.join(output_dir, im_prefix + ext)
    if os.path.exists(save_im_path):
",4
"
def postprocess(data_out, org_im, org_im_path, image_height, image_width,
                output_dir, visualization, shrink, confs_threshold):
    """"""
",4
"    Postprocess output of network. one image at a time.

",4
"
",4
"                              (bbox['right'], bbox['bottom']), (255, 255, 0), 2)
        cv2.imwrite(save_im_path, im_out)

    return output
",4
"
",4
"    def _set_config(self):
        """"""
        predictor config setting
",4
"        """"""
        cpu_config = AnalysisConfig(self.default_pretrained_model_path)
        cpu_config.disable_glog_info()
        cpu_config.disable_gpu()
",4
"            use_gpu = True
        except:
            use_gpu = False
        if use_gpu:
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
",4
"            elif 'data' in data:
                if images is None:
                    images = list()
                images += data['data']

",4
"        res = list()
        # process one by one
        for element in reader(images, paths, shrink):
            image = np.expand_dims(element['image'], axis=0).astype('float32')
",4
"            res.append(out)
        return res
",4
"            target_vars=target_vars,
            model_filename=model_filename,
            params_filename=params_filename)
",4
"
    @serving
",4
"            output_dir=args.output_dir,
            visualization=args.visualization,
            shrink=args.shrink,
            confs_threshold=args.confs_threshold)
        return results
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not"")
",4
"            type=ast.literal_eval,
",4
"import os
import time
from collections import OrderedDict

import cv2
",4
"    if images is not None:
        assert type(images) is list, ""images should be a list.""
        for im in images:
            each = OrderedDict()
",4
"import time
from collections import OrderedDict

import base64
",4
"    # save image path
    save_im_path = os.path.join(output_dir, im_prefix + ext)
    if os.path.exists(save_im_path):
",4
"
    Args:
",4
"        image_height (int): height of preprocessed image.
        image_width (int): width of preprocessed image.
",4
"import argparse
import os

import numpy as np
",4
"import paddle.fluid as fluid
import paddlehub as hub
",4
"
",4
"            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
",4
"                       images=None,
                       paths=None,
                       data=None,
                       use_gpu=False,
                       output_dir='detection_result',
",4
"        Returns:
            res (list[dict]): The result of face detection, keys are 'data' and 'path', the correspoding values are:
",4
"            try:
",4
"                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
",4
"                org_im_path=element['org_im_path'],
                org_im_width=element['org_im_width'],
",4
"            params_filename = ""__params__"" if not params_filename else params_filename
        place = fluid.CPUPlace()
        exe = fluid.Executor(place)

",4
"        Run as a service.
",4
"        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.face_detection(images_decode, **kwargs)
        return results
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
",4
"        self.arg_config_group.add_argument(
            '--output_dir',
            type=str,
            default='detection_result',
",4
"        self.arg_config_group.add_argument(
",4
"        image = image.convert('RGB')
    shrink, max_shrink = get_shrink(image.size[1], image.size[0])
",4
"
def to_chw_bgr(image):
",4
"    if len(image.shape) == 3:
        image = np.swapaxes(image, 1, 2)
        image = np.swapaxes(image, 1, 0)
    # RBG to BGR
",4
"                return x

    max_shrink = get_round(min(max_shrink_v1, max_shrink_v2), 2) - 0.3
",4
"    Args:
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C], color space is BGR.
",4
"    component = list()
",4
"

",4
"    Create directory to save processed image.
",4
"
    Args:
        dir_path (str): directory path to save images.

",4
"        os.remove(dir_path)
        os.makedirs(dir_path)


def get_save_image_name(img, org_im_path, output_dir):
",4
"    Draw bounding boxes on image.

    Args:
        bboxes (np.array): bounding boxes.
",4
"        org_im_width (int): width of original image.
        org_im_height (int): height of original image.
        output_dir (str): output directory to store image.
        visualization (bool): whether to save image or not.
",4
"
",4
"            print(""No face detected in {}"".format(org_im_path))
",4
"                dt_i['left'] = float(detect_face[0])
                dt_i['top'] = float(detect_face[1])
                dt_i['right'] = float(detect_face[2])
                dt_i['bottom'] = float(detect_face[3])
                dt_i['confidence'] = float(detect_face[4])
",4
"# coding=utf-8
",4
"    version=""1.0.0"")
class FixResnext10132x48dwslImagenet(hub.Module):
",4
"            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

",4
"        Returns:
",4
"                image = fluid.layers.data(
",4
"                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
                inputs = {
                    key: global_vars[value]
",4
"                        predicate=_if_exist)
                else:
                    exe.run(startup_prog)
                # trainable
                for param in context_prog.global_block().iter_parameters():
",4
"                    param.trainable = trainable
        return inputs, outputs, context_prog

",4
"            res (list[dict]): The classfication results.
",4
"
        if not self.predictor_set:
            self._set_config()
            self.predictor_set = True
",4
"                top_k=top_k)
            res += out
        return res
",4
"        exe = fluid.Executor(place)
",4
"            dirname=self.default_pretrained_model_path, executor=exe)

",4
"    def run_cmd(self, argvs):
",4
"        """"""
        Run as a command.
        """"""
        self.parser = argparse.ArgumentParser(
",4
"        results = self.classification(
",4
"            default=1,
            help=""batch size."")
",4
"        """"""
        Add the command input options.
        """"""
        self.arg_input_group.add_argument(
            '--input_path', type=str, help=""path to image."")
",4
"import time
from collections import OrderedDict

",4
"import cv2
import numpy as np
from PIL import Image

__all__ = ['reader']
",4
"    return img


def crop_image(img, target_size, center):
    width, height = img.size
",4
"
",4
"            each = OrderedDict()
            each['org_im'] = Image.fromarray(im[:, :, ::-1])
            each['org_im_path'] = 'ndarray_time={}'.format(
                round(time.time(), 6) * 1e6)
",4
"        element['image'] = process_image(element['org_im'])
",4
"

def softmax(x):
    orig_shape = x.shape
    if len(x.shape) > 1:
",4
"        tmp = np.max(x, axis=1)
        x -= tmp.reshape((x.shape[0], 1))
        x = np.exp(x)
        tmp = np.sum(x, axis=1)
        x /= tmp.reshape((x.shape[0], 1))
",4
"        tmp = np.sum(x)
        x /= tmp
    return x

",4
"    Postprocess output of network, one image at a time.

    Args:
",4
"        data_out (numpy.ndarray): output data of network.
        label_list (list): list of label.
        top_k (int): Return top k results.
    """"""
    output = []
",4
"    for result in data_out:
",4
"        result_i = softmax(result)
        output_i = {}
        indexs = np.argsort(result_i)[::-1][0:top_k]
",4
"    ""ResNeXt101_32x48d_wsl"", ""Fix_ResNeXt101_32x48d_wsl""
]

",4
"
class ResNeXt101_wsl():
    def __init__(self, layers=101, cardinality=32, width=48):
        self.layers = layers
        self.cardinality = cardinality
",4
"        cardinality = self.cardinality
        width = self.width

        depth = [3, 4, 23, 3]
",4
"            input=input,
            num_filters=64,
",4
"            name=""conv1"")  #debug
        conv = fluid.layers.pool2d(
            input=conv,
            pool_size=3,
            pool_stride=2,
",4
"        out = fluid.layers.fc(
            input=pool,
",4
"            param_attr=fluid.param_attr.ParamAttr(
",4
"                initializer=fluid.initializer.Uniform(-stdv, stdv),
                name='fc.weight'),
            bias_attr=fluid.param_attr.ParamAttr(name='fc.bias'))
        return out, pool

",4
"    def conv_bn_layer(self,
",4
"                bn_name = 'bn' + name[-1]
            else:
                bn_name = (name[:10] if name[7:9].isdigit() else
                           name[:9]) + 'bn' + name[-1]
",4
"        return fluid.layers.batch_norm(
            input=conv,
            act=act,
            param_attr=ParamAttr(name=bn_name + '.weight'),
",4
"
    def shortcut(self, input, ch_out, stride, name):
        ch_in = input.shape[1]
        if ch_in != ch_out or stride != 1:
",4
"            name=name + "".conv1"")
",4
"            stride=stride,
            groups=cardinality,
            act='relu',
            name=name + "".conv2"")
",4
"            name=name + "".downsample"")

        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu')

",4
"
def ResNeXt101_32x48d_wsl():
    model = ResNeXt101_wsl(cardinality=32, width=48)
    return model

",4
"
",4
"    def fix_conv_norm_name(self, name):
",4
"        return conv_name1, conv_name2, conv_name3, shortcut_name

    def fix_layer_warp_name(self, stage_num, count, i):
",4
"            if i == 0:
                conv_name = name + ""a""
",4
"    def fix_c1_stage_name(self):
",4
"import paddlehub as hub
import paddle.fluid as fluid
from paddlehub.module.module import moduleinfo, runnable
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
from paddlehub.io.parser import txt_parser
",4
"from resnet34_v2_imagenet.data_feed import test_reader
",4
"    type=""cv/classification"",
    summary=
    ""ResNet34 is a image classfication model trained with ImageNet-2012 dataset."",
    author=""paddlepaddle"",
",4
"    def _initialize(self):
",4
"            os.path.join(self.directory, ""label_file.txt""))
        self.infer_prog = None
        self.pred_out = None
",4
"
    def get_pretrained_images_mean(self):
",4
"        cpu_config.disable_glog_info()
        cpu_config.disable_gpu()
        self.cpu_predictor = create_paddle_predictor(cpu_config)
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(memory_pool_init_size_mb=500, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

",4
"    def context(self,
                input_image=None,
                trainable=True,
",4
"        :type trainable: bool
        :param pretrained: whether to load default pretrained model.
",4
"            if False, outputs is {'head_features': head_features}.
        :type get_prediction: bool
        :param depth: depth of network
        :type depth: int
",4
"        :type feature_maps: list
        """"""
",4
"                              feature_maps=feature_maps, get_prediction=get_prediction)

            out = backbone(image)
",4
"
                def _if_exist(var):
",4
"        """"""API of Classification.
        :param paths: the path of images.
        :type paths: list, each element is correspond to the path of an image.
",4
"        """"""
        self.arg_config_group.add_argument(
",4
"            '--input_path', type=str, default=None, help=""input data"")
",4
"            else:
",4
"from __future__ import unicode_literals

import paddle.fluid as fluid
from paddle.fluid import ParamAttr

",4
"nonlocal_params = {
    ""use_zero_init_conv"": False,
    ""conv_init_std"": 0.01,
    ""no_bias"": True,
",4
"    ""use_maxpool"": False,
    ""use_softmax"": True,
    ""use_bn"": False,
",4
"    ""bn_init_gamma"": 0.9,
    ""weight_decay_bn"": 1.e-4,
",4
"    theta_shape_op = fluid.layers.shape(theta)
    theta_shape_op.stop_gradient = True

",4
"                                        pool_type = 'max', \
                                        pool_stride = [max_pool_stride, max_pool_stride], \
                                        pool_padding = [0, 0], \
",4
"                             param_attr = ParamAttr(name = prefix + '_phi' + ""_w"", \
                                 initializer = fluid.initializer.Normal(loc = 0.0,
                                 scale = nonlocal_params[""conv_init_std""])), \
                             bias_attr = ParamAttr(name = prefix + '_phi' + ""_b"", \
                                 initializer = fluid.initializer.Constant(value = 0.)) \
",4
"
    g = fluid.layers.conv2d(input = max_pool, num_filters = dim_inner, \
                 filter_size = [1, 1], stride = [1, 1], \
                 padding = [0, 0], \
                 param_attr = ParamAttr(name = prefix + '_g' + ""_w"", \
",4
"                 bias_attr = ParamAttr(name = prefix + '_g' + ""_b"", \
                     initializer = fluid.initializer.Constant(value = 0.)) if (nonlocal_params[""no_bias""] == 0) else False, \
                 name = prefix + '_g')
    g_shape = g.shape
",4
"        if nonlocal_params[""use_scale""]:
            theta_phi_sc = fluid.layers.scale(theta_phi, scale=dim_inner**-.5)
",4
"                                  param_attr = ParamAttr(name = prefix + '_out' + ""_w"", \
                                      initializer = fluid.initializer.Constant(value = 0.) \
                                        if nonlocal_params[""use_zero_init_conv""] \
                                        else fluid.initializer.Normal(loc = 0.0,
",4
"                       shape=[blob_out_shape[1]], dtype = blob_out.dtype, \
                       attr=ParamAttr(name=prefix + '_affine' + '_s'), \
                       default_initializer = fluid.initializer.Constant(value = 1.))
        affine_bias = fluid.layers.create_parameter(\
",4
"                      shape=[blob_out_shape[1]], dtype = blob_out.dtype, \
                      attr=ParamAttr(name=prefix + '_affine' + '_b'), \
                      default_initializer = fluid.initializer.Constant(value = 0.))
        blob_out = fluid.layers.affine_channel(blob_out, scale = affine_scale, \
",4
"                      bias = affine_bias, name = prefix + '_affine')   # add affine

    return blob_out
",4
"

def add_space_nonlocal(input, dim_in, dim_out, prefix, dim_inner):
",4
"    add_space_nonlocal:
        Non-local Neural Networks: see https://arxiv.org/abs/1711.07971
    '''
",4
"from collections import OrderedDict

",4
"import cv2
import numpy as np
from PIL import Image, ImageEnhance
from paddle import fluid
",4
"
def resize_short(img, target_size):
    percent = float(target_size) / min(img.size[0], img.size[1])
    resized_width = int(round(img.size[0] * percent))
    resized_height = int(round(img.size[1] * percent))
",4
"    width, height = img.size
    size = target_size
",4
"
from .nonlocal_helper import add_space_nonlocal
from .name_adapter import NameAdapter

__all__ = ['ResNet', 'ResNetC5']
",4
"        feature_maps (list): index of stages whose feature maps are returned
",4
"        nonlocal_stages (list): index of stages who select nonlocal networks
    """"""
    __shared__ = ['norm_type', 'freeze_norm', 'weight_prefix_name']

    def __init__(self,
",4
"        self._model_type = 'ResNet'
",4
"        self.dcn_v2_stages = dcn_v2_stages
",4
"            param_attr=ParamAttr(initializer=Constant(0.0), name=name + "".w_0""),
            bias_attr=ParamAttr(initializer=Constant(0.0), name=name + "".b_0""),
            act=act,
            name=name)
        return out
",4
"    def _conv_norm(self,
                   input,
",4
"                name=_name + '.conv2d.output.1')
",4
"        else:
            # select deformable conv""
            offset_mask = self._conv_offset(
",4
"                name=_name + ""_conv_offset"")
            offset_channel = filter_size**2 * 2
",4
"            mask_channel = filter_size**2
            offset, mask = fluid.layers.split(
                input=offset_mask,
                num_or_sections=[offset_channel, mask_channel],
",4
"                mask=mask,
",4
"                im2col_step=1,
                param_attr=ParamAttr(name=_name + ""_weights""),
                bias_attr=False,
                name=_name + "".conv2d.output.1"")

",4
"            name=bn_name + '_offset',
            learning_rate=norm_lr,
",4
"                   name,
                   dcn_v2=False):
        if self.variant == 'a':
",4
"        elif (groups * group_width) == 256:
            expand = 1
",4
"        else:  # FIXME hard code for now, handles 32x4d, 64x4d and 32x8d
            num_filters = num_filters // 2
            expand = 2
",4
"        if std_senet:
            conv_def = [[
",4
"                int(num_filters / 2), 1, stride1, 'relu', 1, conv_name1
",4
"            ], [num_filters, 3, stride2, 'relu', groups, conv_name2],
                        [num_filters * expand, 1, 1, None, 1, conv_name3]]
        else:
            conv_def = [[num_filters, 1, stride1, 'relu', 1, conv_name1],
                        [num_filters, 3, stride2, 'relu', groups, conv_name2],
",4
"                act=act,
                groups=g,
                name=_name,
                dcn_v2=(i == 1 and dcn_v2))
        short = self._shortcut(
",4
"                input=residual, num_channels=num_filters, name='fc' + name)
        return fluid.layers.elementwise_add(
",4
"            input=conv0,
            num_filters=num_filters,
            filter_size=3,
            act=None,
            name=name + ""_branch2b"")
",4
"                self.depth] if stage_num == 4 else 2
",4
"
        # Make the layer name and parameter name consistent
        # with ImageNet pre-trained model
        conv = input
        for i in range(count):
",4
"            conv = block_func(
",4
"                input=conv,
                num_filters=ch_out,
                stride=2 if i == 0 and stage_num != 2 else 1,
                is_first=is_first,
                name=conv_name,
",4
"            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
",4
"                                          nonlocal_name + '_{}'.format(i),
",4
"                input=input,
                num_filters=c,
",4
"                act='relu',
                name=_name)
",4
"
        output = fluid.layers.pool2d(
            input=input,
            pool_size=3,
",4
"            pool_stride=2,
            pool_padding=1,
            pool_type='max')
        return output
",4
"            pool = fluid.layers.pool2d(
",4
"                input=res, pool_type='avg', global_pooling=True)
            stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)

            out = fluid.layers.fc(
",4
"import ast
import argparse

import numpy as np
import paddle.fluid as fluid
",4
"    ""DarkNet53 is a image classfication model trained with ImageNet-2012 dataset."",
    author=""paddlepaddle"",
",4
"        return 224
",4
"    def get_expected_image_height(self):
        return 224

    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"        try:
",4
"        )
        startup_program = fluid.Program()
        with fluid.program_guard(context_prog, startup_program):
",4
"            image = input_image if input_image else fluid.data(
",4
"
                def _if_exist(var):
                    return os.path.exists(
                        os.path.join(self.default_pretrained_model_path,
                                     var.name))
",4
"        :param batch_size: batch size.
        :type batch_size: int
        :param top_k : top k
        :type top_k : int
",4
"            self.pred_out = outputs['pred_out']
        place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()
        exe = fluid.Executor(place)
",4
"            all_images.append(yield_data)

        images_num = len(all_images)
        loop_num = int(np.ceil(images_num / batch_size))

",4
"        for iter_id in range(loop_num):
",4
"            batch_data = []
            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
",4
"                    pass
            batch_data = np.array(batch_data).astype('float32')
",4
"                    max_prob = res[k]
",4
"            help=""file contain input data"")

",4
"    def check_input_data(self, args):
        input_data = []
        if args.input_path:
",4
"        self.parser = argparse.ArgumentParser(
            description=""Run the {}"".format(self.name),
            prog=""hub run {}"".format(self.name),
            usage='%(prog)s',
",4
"        if len(input_data) == 0:
            self.parser.print_help()
            exit(1)
        else:
            for image_path in input_data:
",4
"
",4
"
def resize_short(img, target_size):
    percent = float(target_size) / min(img.size[0], img.size[1])
    resized_width = int(round(img.size[0] * percent))
",4
"        im = process_image(im)
        yield im
# coding=utf-8
def load_label_info(file_path):
    with open(file_path, 'r') as fr:
",4
"        return fr.read().split(""\n"")[:-1]
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"import math

from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay
",4
"    """"""

    def __init__(self,
                 depth=53,
",4
"                 norm_type='sync_bn',
                 norm_decay=0.,
",4
"                 weight_prefix_name='',
                 get_prediction=False,
",4
"                 class_dim=1000):
",4
"                   stride,
                   padding,
                   act='leaky',
                   name=None):
        conv = fluid.layers.conv2d(
",4
"            input=input,
            num_filters=ch_out,
            filter_size=filter_size,
            stride=stride,
            padding=padding,
",4
"        bn_name = name + "".bn""
        bn_param_attr = ParamAttr(
            regularizer=L2Decay(float(self.norm_decay)),
            name=bn_name + '.scale')
        bn_bias_attr = ParamAttr(
",4
"
        return out
",4
"
    def _downsample(self,
                    input,
                    ch_out,
                    filter_size=3,
",4
"            input,
            ch_out=ch_out,
            filter_size=filter_size,
            stride=stride,
",4
"            input,
            ch_out=ch_out,
            filter_size=1,
",4
"            padding=1,
            name=name + "".1"")
        out = fluid.layers.elementwise_add(x=input, y=conv2, act=None)
",4
"        conv = self._conv_norm(
",4
"            ch_out=32,
            filter_size=3,
",4
"        for i, stage in enumerate(stages):
            block = self.layer_warp(
",4
"                size=self.class_dim,
                param_attr=ParamAttr(
                    initializer=fluid.initializer.Uniform(-stdv, stdv),
                    name='fc_weights'),
                bias_attr=ParamAttr(name='fc_offset'))
",4
"            out = fluid.layers.softmax(out)
            return out
        else:
            return blocks
# coding=utf-8
",4
"                 class_dim=1000,
                 yolo_v3=False):
        self.norm_type = norm_type
        self.norm_decay = norm_decay
        self.conv_group_scale = conv_group_scale
",4
"        self.yolo_v3 = yolo_v3
",4
"                   filter_size,
                   num_filters,
                   stride,
                   padding,
",4
"        conv = fluid.layers.conv2d(
            input=input,
            num_filters=num_filters,
",4
"
        bn_name = name + ""_bn""
        norm_decay = self.norm_decay
        bn_param_attr = ParamAttr(
",4
"            regularizer=L2Decay(norm_decay), name=bn_name + '_scale')
        bn_bias_attr = ParamAttr(
            regularizer=L2Decay(norm_decay), name=bn_name + '_offset')
        return fluid.layers.batch_norm(
            input=conv,
",4
"
    def depthwise_separable(self,
                            input,
                            num_filters1,
                            num_filters2,
",4
"        pointwise_conv = self._conv_norm(
",4
"            num_filters=int(num_filters2 * scale),
            stride=1,
            padding=0,
            name=name + ""_sep"")
        return pointwise_conv
",4
"
",4
"                     input,
                     num_filters1,
                     num_filters2,
                     num_groups,
",4
"            num_filters=int(num_filters1),
",4
"            num_groups=int(num_groups),
",4
"            padding=1,
",4
"        # 1/16
        blocks.append(out)
        for i in range(5):
            out = self.depthwise_separable(
",4
"
        out = self.depthwise_separable(
            out, 512, 1024, 512, 2, scale, name=self.prefix_name + ""conv5_6"")
",4
"        out = self.depthwise_separable(
",4
"                input=out,
                size=self.class_dim,
                param_attr=ParamAttr(
                    initializer=fluid.initializer.MSRA(), name=""fc7_weights""),
",4
"        module15 = self._extra_block(module14, num_filters[1][0],
",4
"        module17 = self._extra_block(module16, num_filters[3][0],
",4
"# coding=utf-8
import os
import ast
",4
"import argparse
",4
"from mobilenet_v1_imagenet.processor import load_label_info
from mobilenet_v1_imagenet.data_feed import test_reader

",4
"
@moduleinfo(
",4
"    name=""mobilenet_v1_imagenet"",
",4
"        return 224

    def get_expected_image_height(self):
        return 224
",4
"        try:
",4
"        :type pretrained: bool
",4
"                with_extra_blocks=not get_prediction,
                yolo_v3=yolo_v3)
",4
"            out = backbone(image)

            inputs = {'image': image}
            if get_prediction:
",4
"                outputs = {'pred_out': out[-1]}
            else:
                outputs = {'body_feats': out}

            place = fluid.CPUPlace()
",4
"                if not param_prefix:
                    fluid.io.load_vars(
                        exe,
",4
"
    def classification(self,
                       paths=None,
                       images=None,
",4
"        :param paths: the path of images.
",4
"            inputs, outputs, self.infer_prog = self.context(
",4
"                trainable=False, pretrained=True, get_prediction=True)
            self.infer_prog = self.infer_prog.clone(for_test=True)
            self.pred_out = outputs['pred_out']

        place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()
",4
"            for i, res in enumerate(result[0].as_ndarray()):
                res_dict = {}
                pred_label = np.argsort(res)[::-1][:top_k]
",4
"    def add_module_config_arg(self):
        """"""
        Add the command config options
        """"""
        self.arg_config_group.add_argument(
",4
"            help=""batch size for prediction"")

    def add_module_input_arg(self):
",4
"
    @runnable
    def run_cmd(self, argvs):
        self.parser = argparse.ArgumentParser(
",4
"            prog=""hub run {}"".format(self.name),
            usage='%(prog)s',
            add_help=True)
",4
"        self.arg_input_group = self.parser.add_argument_group(
            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
            description=
",4
"            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
",4
"    percent = float(target_size) / min(img.size[0], img.size[1])
    resized_width = int(round(img.size[0] * percent))
    resized_height = int(round(img.size[1] * percent))
",4
"def process_image(img):
    img = resize_short(img, target_size=256)
    img = crop_image(img, target_size=DATA_DIM, center=True)
    if img.mode != 'RGB':
",4
"        img = img.convert('RGB')
    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = np.array(img).astype('float32').transpose((2, 0, 1)) / 255
    img -= img_mean
",4
"    img /= img_std
",4
"    :param paths: path to images.
    :type paths: list, each element is a str
    :param images: data of images, [N, H, W, C]
",4
"# coding=utf-8
def load_label_info(file_path):
    with open(file_path, 'r') as fr:
",4
"            self.label_list = file.read().split(""\n"")[:-1]
        self.predictor_set = False

    def get_expected_image_width(self):
        return 224
",4
"        self.cpu_predictor = create_paddle_predictor(cpu_config)

        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"            gpu_config.disable_glog_info()
",4
"            gpu_config.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def context(self, trainable=True, pretrained=True):
",4
"        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
                image = fluid.layers.data(
                    name=""image"", shape=[3, 224, 224], dtype=""float32"")
                resnet_vd = Res2Net101_vd_26w_4s()
",4
"                name_prefix = '@HUB_{}@'.format(self.name)
                inputs = {'image': name_prefix + image.name}
                outputs = {
                    'classification': name_prefix + output.name,
                    'feature_map': name_prefix + feature_map.name
",4
"                }
                add_vars_prefix(context_prog, name_prefix)
",4
"                exe = fluid.Executor(place)
                # pretrained
                if pretrained:

",4
"                    def _if_exist(var):
                        b = os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
                        return b
",4
"                        predicate=_if_exist)
                else:
                    exe.run(startup_prog)
                # trainable
                for param in context_prog.global_block().iter_parameters():
",4
"    def classification(self,
                       images=None,
                       paths=None,
                       batch_size=1,
                       use_gpu=False,
",4
"                       top_k=1):
        """"""
        API for image classification.
",4
"            all_data.append(yield_data)

        total_num = len(all_data)
",4
"            for image_id in range(batch_size):
                try:
                    batch_data.append(all_data[handle_id + image_id])
                except:
                    pass
",4
"            # feed batch image
            batch_image = np.array([data['image'] for data in batch_data])
            batch_image = PaddleTensor(batch_image.copy())
            predictor_output = self.gpu_predictor.run([
                batch_image
",4
"                             params_filename=None,
",4
"
        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"            params_filename=params_filename)

",4
"        Run as a command.
        """"""
        self.parser = argparse.ArgumentParser(
            description=""Run the {} module."".format(self.name),
",4
"        self.arg_input_group = self.parser.add_argument_group(
",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not."")
",4
"#limitations under the License.

",4
"from __future__ import division
from __future__ import print_function

import paddle
",4
"            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)
",4
"            depth = [3, 4, 23, 3]
        elif layers == 152:
            depth = [3, 8, 36, 3]
        elif layers == 200:
",4
"        conv = self.conv_bn_layer(
            input=input,
            num_filters=32,
            filter_size=3,
",4
"            pool_size=3,
",4
"            pool_stride=2,
            pool_padding=1,
            pool_type='max')
        for block in range(len(depth)):
            for i in range(depth[block]):
",4
"                initializer=fluid.initializer.Uniform(-stdv, stdv),
                name='fc_weights'),
            bias_attr=fluid.param_attr.ParamAttr(name='fc_offset'))
        return out, pool
",4
"                      num_filters,
                      filter_size,
                      stride=1,
",4
"            input=input,
            num_filters=num_filters,
            filter_size=filter_size,
            stride=stride,
",4
"            padding=(filter_size - 1) // 2,
            groups=groups,
            act=None,
            param_attr=ParamAttr(name=name + ""_weights""),
            bias_attr=False)
",4
"            input=conv,
            act=act,
            param_attr=ParamAttr(name=bn_name + '_scale'),
            bias_attr=ParamAttr(bn_name + '_offset'),
",4
"            moving_mean_name=bn_name + '_mean',
",4
"            else:
                return self.conv_bn_layer_new(
                    input, ch_out, 1, stride, name=name)
        elif if_first:
            return self.conv_bn_layer(input, ch_out, 1, stride, name=name)
",4
"            num_filters=num_filters1,
            filter_size=1,
            stride=1,
",4
"
        short = self.shortcut(
            input,
            num_filters2,
            stride,
",4
"    return model


",4
"
def Res2Net50_vd_26w_8s():
    model = Res2Net_vd(layers=50, scales=8, width=26)
",4
"    return model


def Res2Net101_vd_26w_4s():
",4
"    model = Res2Net_vd(layers=200, scales=4, width=26)
    return model
",4
"from collections import OrderedDict
",4
"
import cv2
import numpy as np
from PIL import Image
",4
"
",4
"

def crop_image(img, target_size, center):
    width, height = img.size
    size = target_size
",4
"

def process_image(img):
    img = resize_short(img, target_size=256)
    img = crop_image(img, target_size=DATA_DIM, center=True)
",4
"        img = img.convert('RGB')
    img = np.array(img).astype('float32').transpose((2, 0, 1)) / 255
    img -= img_mean
",4
"    Postprocess output of network, one image at a time.

    Args:
        data_out (numpy.ndarray): output data of network.
",4
"        top_k (int): Return top k results.
",4
"        indexs = np.argsort(result_i)[::-1][0:top_k]
        for index in indexs:
            label = label_list[index].split(',')[0]
",4
"class EfficientNetB0ImageNet(hub.Module):
    def _initialize(self):
",4
"        self.predictor_set = False

    def get_expected_image_width(self):
",4
"    def get_pretrained_images_std(self):
        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
        return im_std
",4
"        cpu_config = AnalysisConfig(self.default_pretrained_model_path)
        cpu_config.disable_glog_info()
        cpu_config.disable_gpu()
        self.cpu_predictor = create_paddle_predictor(cpu_config)

",4
"        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
",4
"            use_gpu = True
        except:
",4
"            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"    def context(self, trainable=True, pretrained=True):
        """"""context for transfer learning.

        Args:
",4
"            pretrained (bool) : Whether to load pretrained model.
",4
"        """"""
        context_prog = fluid.Program()
        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
",4
"                efficientnet_b0 = EfficientNetB0_small()
",4
"                if pretrained:

                    def _if_exist(var):
",4
"
                    fluid.io.load_vars(
                        exe,
                        self.default_pretrained_model_path,
",4
"                        context_prog,
                        predicate=_if_exist)
                    print(inputs.keys())

                    fluid.io.save_inference_model(
",4
"                        dirname=os.path.join(
                            self.directory,
                            'efficientnetb0_small_imagenet_model'),
                        feeded_var_names=[name_prefix + 'image'],
",4
"
    def classification(self,
                       images=None,
                       paths=None,
",4
"                batch_image
            ]) if use_gpu else self.cpu_predictor.run([batch_image])
            out = postprocess(
",4
"        place = fluid.CPUPlace()
        exe = fluid.Executor(place)

",4
"
        fluid.io.save_inference_model(
",4
"            target_vars=target_vars,
            model_filename=model_filename,
            params_filename=params_filename)

    @serving
",4
"            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
            description=
",4
"            batch_size=args.batch_size,
            use_gpu=args.use_gpu)
        return results
",4
"import copy

",4
"    'EfficientNetB6', 'EfficientNetB7'
]
",4
"    'batch_norm_epsilon',
    'dropout_rate',
    'num_classes',
",4
"
GlobalParams.__new__.__defaults__ = (None, ) * len(GlobalParams._fields)
BlockArgs.__new__.__defaults__ = (None, ) * len(BlockArgs._fields)


",4
"

",4
"        'r3_k5_s11_e6_i80_o112_se0.25',
        'r4_k5_s22_e6_i112_o192_se0.25',
        'r1_k3_s11_e6_i192_o320_se0.25',
    ]
    blocks_args = BlockDecoder.decode(blocks_args)
",4
"        drop_connect_rate=drop_connect_rate,
        num_classes=1000,
        width_coefficient=width_coefficient,
",4
"        w, d, _, p = efficientnet_params(model_name)
",4
"        blocks_args, global_params = efficientnet(
            width_coefficient=w, depth_coefficient=d, dropout_rate=p)
    else:
",4
"        raise NotImplementedError(
            'model name is not pre-defined: %s' % model_name)
    if override_params:
        global_params = global_params._replace(**override_params)
",4
"    min_depth = min_depth or divisor
    new_filters = max(min_depth,
                      int(filters + divisor / 2) // divisor * divisor)
    if new_filters < 0.9 * filters:  # prevent rounding by more than 10%
",4
"                 is_test=False,
",4
"                 use_se=True):
        valid_names = ['b' + str(i) for i in range(8)]
",4
"            filter_size=1,
            bn_act='swish',
            bn_mom=self._bn_mom,
            bn_eps=self._bn_eps,
            padding_type=self.padding_type,
",4
"        param_attr, bias_attr = init_fc_layer(class_dim, '_fc')
        out = fluid.layers.fc(
            pool,
            class_dim,
",4
"            name='_fc',
            param_attr=param_attr,
            bias_attr=bias_attr)
        return out, pool
",4
"                num_filters=oup,
                filter_size=1,
                bn_act=None,
",4
"                bn_mom=self._bn_mom,
                bn_eps=self._bn_eps,
                padding_type=self.padding_type,
                name=name,
                conv_name=name + '_expand_conv',
",4
"            num_filters=oup,
            filter_size=k,
            stride=s,
            num_groups=oup,
            bn_act=None,
",4
"            bn_eps=self._bn_eps,
            name=name,
            use_cudnn=False,
",4
"    def _project_conv_norm(self, inputs, block_args, is_test, name=None):
        final_oup = block_args.output_filters
        conv = self.conv_bn_layer(
            inputs,
            num_filters=final_oup,
",4
"            use_bias=use_bias)

        if use_bn == False:
            return conv
        else:
",4
"            bn_name = name + bn_name
            param_attr, bias_attr = init_batch_norm_layer(bn_name)
            return fluid.layers.batch_norm(
                input=conv,
                act=bn_act,
",4
"            filter_size=3,
            stride=2,
",4
"                      name=None):
        # Expansion and Depthwise Convolution
        oup = block_args.input_filters * block_args.expand_ratio  # number of output channels
",4
"        conv = self._project_conv_norm(conv, block_args, is_test, name)
",4
"        input_filters, output_filters = block_args.input_filters, block_args.output_filters
        if id_skip and block_args.stride == 1 and input_filters == output_filters:
",4
"            x_squeezed,
            num_filters=num_squeezed_channels,
            filter_size=1,
            use_bias=True,
            padding_type=self.padding_type,
",4
"        """""" Returns output of the final convolution layer """"""

        conv = fluid.layers.swish(self._conv_stem_norm(inputs, is_test=is_test))

",4
"                                             self._global_params),
                num_repeat=round_repeats(block_arg.num_repeat,
                                         self._global_params))
",4
"        return conv

    def shortcut(self, input, data_residual):
        return fluid.layers.elementwise_add(input, data_residual)
",4
"

class BlockDecoder(object):
    """""" Block Decoder for readability, straight from the official TensorFlow repository """"""

",4
"                key, value = splits[:2]
                options[key] = value

",4
"                (len(options['s']) == 2 and options['s'][0] == options['s'][1]))

        return BlockArgs(
            kernel_size=int(options['k']),
",4
"        assert isinstance(string_list, list)
        blocks_args = []
        for block_string in string_list:
",4
"        use_se=use_se)
    return model


def EfficientNetB1(is_test=False,
",4
"                   padding_type='SAME',
",4
"

def EfficientNetB2(is_test=False,
",4
"        is_test=is_test,
        padding_type=padding_type,
        override_params=override_params,
        use_se=use_se)
    return model
",4
"

def EfficientNetB3(is_test=False,
                   padding_type='SAME',
                   override_params=None,
",4
"        override_params=override_params,
        use_se=use_se)
",4
"

def initial_type(name,
                 input,
",4
"
    else:
        param_attr = fluid.ParamAttr(
",4
"            name=name + ""_weights"",
            initializer=fluid.initializer.NormalInitializer(
",4
"        initializer=fluid.initializer.Constant(value=0.0))
    return param_attr, bias_attr

",4
"    init_range = 1.0 / math.sqrt(n)

    param_attr = fluid.ParamAttr(
",4
"

def conv2d(input,
",4
"           padding=0,
           groups=None,
           name=""conv2d"",
           norm=None,
",4
"        if top_padding != bottom_padding or left_padding != right_padding:
",4
"            height_padding = top_padding + stride
            width_padding = left_padding + stride
            need_crop = True
",4
"    elif padding_type == ""DYNAMIC"":
        padding = get_padding(filter_size, stride)
",4
"        filter_size,
        groups=groups,
        name=name,
",4
"        conv = fluid.layers.sigmoid(conv, name=name + '_sigmoid')
    elif act == 'swish':
        conv = fluid.layers.swish(conv, name=name + '_swish')
",4
"    else:
        raise NotImplementedError(""activation: [%s] is not support"" % act)

",4
"
",4
"        h_start = np.random.randint(0, height - size + 1)
    w_end = w_start + size
    h_end = h_start + size
    img = img.crop((w_start, h_start, w_end, h_end))
    return img
",4
"

def reader(images=None, paths=None):
    """"""
",4
"            each['org_im'] = Image.fromarray(im[:, :, ::-1])
            each['org_im_path'] = 'ndarray_time={}'.format(
                round(time.time(), 6) * 1e6)
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
",4
"            component.append(each)
",4
"from __future__ import division
from __future__ import print_function

import base64
import cv2
",4
"    return data


def softmax(x):
",4
"        x -= tmp.reshape((x.shape[0], 1))
        x = np.exp(x)
        tmp = np.sum(x, axis=1)
        x /= tmp.reshape((x.shape[0], 1))
    else:
",4
"        tmp = np.max(x)
        x -= tmp
        x = np.exp(x)
        tmp = np.sum(x)
",4
"        top_k (int): Return top k results.
    """"""
    output = []
    for result in data_out:
        result_i = softmax(result)
",4
"
import ast
import argparse
import os
",4
"    name=""resnet18_vd_imagenet"",
    type=""CV/image_classification"",
    author=""paddlepaddle"",
    author_email=""paddle-dev@baidu.com"",
    summary=
",4
"    ""ResNet18vd is a image classfication model, this module is trained with imagenet datasets."",
    version=""1.0.0"")
",4
"    def get_expected_image_width(self):
",4
"        return 224

",4
"        return im_mean

",4
"    def get_pretrained_images_std(self):
        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
        return im_std

    def _set_config(self):
",4
"        cpu_config = AnalysisConfig(self.default_pretrained_model_path)
        cpu_config.disable_glog_info()
",4
"        Returns:
",4
"                global_vars = context_prog.global_block().vars
                inputs = {
                    key: global_vars[value]
                    for key, value in inputs.items()
                }
",4
"                place = fluid.CPUPlace()
                exe = fluid.Executor(place)
                # pretrained
",4
"                if pretrained:

                    def _if_exist(var):
                        b = os.path.exists(
",4
"            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.

",4
"        all_data = list()
        for yield_data in reader(images, paths):
            all_data.append(yield_data)
",4
"            handle_id = iter_id * batch_size
",4
"            for image_id in range(batch_size):
",4
"            target_vars=target_vars,
            model_filename=model_filename,
",4
"    def run_cmd(self, argvs):
        """"""
        Run as a command.
",4
"        """"""
        self.parser = argparse.ArgumentParser(
            description=""Run the {} module."".format(self.name),
",4
"        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
        results = self.classification(
            paths=[args.input_path],
",4
"            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not."")
        self.arg_config_group.add_argument(
            '--batch_size',
",4
"            help=""Return top k results."")

    def add_module_input_arg(self):
        """"""
",4
"#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"import paddle
import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr

",4
"        stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)

        out = fluid.layers.fc(
            input=pool,
",4
"            size=class_dim,
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv)))
",4
"    def conv_bn_layer(self,
",4
"        if name == ""conv1"":
",4
"            input=input,
            pool_size=2,
            pool_stride=2,
            pool_padding=0,
            pool_type='avg',
",4
"            filter_size=filter_size,
            stride=1,
",4
"            padding=(filter_size - 1) // 2,
",4
"            groups=groups,
            act=None,
",4
"            else:
                return self.conv_bn_layer_new(
                    input, ch_out, 1, stride, name=name)
        elif if_first:
",4
"        conv1 = self.conv_bn_layer(
            input=conv0,
            num_filters=num_filters,
            filter_size=3,
",4
"
",4
"

def ResNet34_vd():
    model = ResNet(layers=34, is_3x3=True)
    return model
",4
"    """"""
    Preprocess to yield image.
",4
"        for im_path in paths:
",4
"            each = OrderedDict()
            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
",4
"from __future__ import division
from __future__ import print_function

import base64
import cv2
",4
"import os

import numpy as np


",4
"def base64_to_cv2(b64str):
",4
"    orig_shape = x.shape
    if len(x.shape) > 1:
        tmp = np.max(x, axis=1)
        x -= tmp.reshape((x.shape[0], 1))
",4
"        output_i = {}
        indexs = np.argsort(result_i)[::-1][0:top_k]
        for index in indexs:
            label = label_list[index].split(',')[0]
            output_i[label] = float(result_i[index])
",4
"        output.append(output_i)
    return output
# coding=utf-8
",4
"
import numpy as np
",4
"        return im_std
",4
"    def _set_config(self):
        """"""
",4
"                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def context(self, trainable=True, pretrained=True):
        """"""context for transfer learning.
",4
"                'classification', corresponding value is the result of classification.
",4
"        """"""
        context_prog = fluid.Program()
        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
",4
"                }
                add_vars_prefix(context_prog, name_prefix)
",4
"                place = fluid.CPUPlace()
                exe = fluid.Executor(place)
                # pretrained
",4
"                    def _if_exist(var):
                        b = os.path.exists(
",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
",4
"
                    fluid.io.load_vars(
                        exe,
                        self.default_pretrained_model_path,
",4
"                       use_gpu=False,
",4
"        API for image classification.

        Args:
",4
"                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"            predictor_output = self.gpu_predictor.run([
",4
"    def save_inference_model(self,
                             dirname,
                             model_filename=None,
                             params_filename=None,
",4
"            model_filename = ""__model__"" if not model_filename else model_filename
            params_filename = ""__params__"" if not params_filename else params_filename
        place = fluid.CPUPlace()
        exe = fluid.Executor(place)

",4
"        images_decode = [base64_to_cv2(image) for image in images]
        results = self.classification(images=images_decode, **kwargs)
        return results

    @runnable
",4
"            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
",4
"            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
",4
"            paths=[args.input_path],
            batch_size=args.batch_size,
",4
"            use_gpu=args.use_gpu)
        return results

",4
"        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
",4
"
    def add_module_input_arg(self):
        """"""
        Add the command input options.
",4
"        supported_layers = [50, 101, 152, 200]
        assert layers in supported_layers, \
            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)
",4
"            conv = self.conv_bn_layer(
                input=conv,
                num_filters=32,
                filter_size=3,
",4
"                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
                else:
                    conv_name = ""res"" + str(block + 2) + chr(97 + i)
                conv = self.bottleneck_block(
",4
"            moving_mean_name=bn_name + '_mean',
            moving_variance_name=bn_name + '_variance')

    def conv_bn_layer_new(self,
                          input,
",4
"            pool_stride=2,
            pool_padding=0,
            pool_type='avg')

        conv = fluid.layers.conv2d(
",4
"            input=pool,
            num_filters=num_filters,
            filter_size=filter_size,
            stride=1,
",4
"            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]
        return fluid.layers.batch_norm(
            input=conv,
",4
"            act=act,
            param_attr=ParamAttr(name=bn_name + '_scale'),
            bias_attr=ParamAttr(bn_name + '_offset'),
            moving_mean_name=bn_name + '_mean',
",4
"                return self.conv_bn_layer_new(
",4
"        else:
",4
"
    def bottleneck_block(self, input, num_filters, stride, name, if_first):
        conv0 = self.conv_bn_layer(
            input=input,
            num_filters=num_filters,
",4
"            name=name + ""_branch1"")

",4
"
DATA_DIM = 224
",4
"        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
        w_start = np.random.randint(0, width - size + 1)
",4
"
",4
"
    Yield:
",4
"            each = OrderedDict()
            assert os.path.isfile(
",4
"
    for element in component:
        element['image'] = process_image(element['org_im'])
        yield element
# coding=utf-8
",4
"
import numpy as np
",4
"        x -= tmp
        x = np.exp(x)
        tmp = np.sum(x)
        x /= tmp
",4
"    return x


",4
"        self.default_pretrained_model_path = os.path.join(
            self.directory, ""model"")
        label_file = os.path.join(self.directory, ""label_list.txt"")
        with open(label_file, 'r', encoding='utf-8') as file:
",4
"
    def get_expected_image_height(self):
",4
"    def get_pretrained_images_mean(self):
",4
"        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
        return im_mean

    def get_pretrained_images_std(self):
        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
",4
"                name_prefix = '@HUB_{}@'.format(self.name)
                inputs = {'image': name_prefix + image.name}
                outputs = {
                    'classification': name_prefix + output.name,
",4
"                    'feature_map': name_prefix + feature_map.name
                }
                add_vars_prefix(context_prog, name_prefix)
",4
"        API for image classification.

",4
"            top_k (int): Return top k results.

        Returns:
            res (list[dict]): The classfication results.
",4
"                int(_places[0])
            except:
                raise RuntimeError(
",4
"                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )

",4
"            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"        results = self.classification(
            paths=[args.input_path],
            batch_size=args.batch_size,
            use_gpu=args.use_gpu)
",4
"            '--top_k',
            type=ast.literal_eval,
            default=1,
",4
"            help=""Return top k results."")

    def add_module_input_arg(self):
        """"""
        Add the command input options.
",4
"img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))


def resize_short(img, target_size):
    percent = float(target_size) / min(img.size[0], img.size[1])
",4
"        each (collections.OrderedDict): info of original image, preprocessed image.
    """"""
    component = list()
    if paths:
        for im_path in paths:
",4
"        assert type(images), ""images is a list.""
        for im in images:
",4
"
import base64
import cv2
",4
"
",4
"    Args:
        data_out (numpy.ndarray): output data of network.
        label_list (list): list of label.
",4
"        top_k (int): Return top k results.
",4
"            output_i[label] = float(result_i[index])
        output.append(output_i)
    return output
",4
"# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"        if model_name == ""large"":
            self.cfg = [
                # k, exp, c,  se,     nl,  s,
",4
"                [3, 16, 16, False, 'relu', 1],
",4
"            self.cls_ch_expand = 1280
        elif model_name == ""small"":
            self.cfg = [
                # k, exp, c,  se,     nl,  s,
",4
"                [5, 144, 48, True, 'hard_swish', 1],
                [5, 288, 96, True, 'hard_swish', 2],
                [5, 576, 96, True, 'hard_swish', 1],
",4
"            input=drop,
            size=class_dim,
            param_attr=ParamAttr(name='fc_weights'),
            bias_attr=ParamAttr(name='fc_offset'))
        return out, drop
",4
"        if if_act:
",4
"        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)
        if new_v < 0.9 * v:
            new_v += divisor
        return new_v
",4
"            filter_size=1,
",4
"    def residual_unit(self,
                      input,
                      num_in_filter,
                      num_mid_filter,
",4
"            act=act,
",4
"            name=name + '_expand')

        conv1 = self.conv_bn_layer(
            input=conv0,
",4
"            filter_size=filter_size,
            num_filters=num_mid_filter,
            stride=stride,
            padding=int((filter_size - 1) // 2),
            if_act=True,
",4
"        if num_in_filter != num_out_filter or stride != 1:
            return conv2
        else:
",4
"            return fluid.layers.elementwise_add(x=input, y=conv2, act=None)


def MobileNetV3_small_x0_35():
    model = MobileNetV3(model_name='small', scale=0.35)
",4
"    return model


",4
"
def MobileNetV3_large_x0_35():
    model = MobileNetV3(model_name='large', scale=0.35)
    return model
",4
"
",4
"
def MobileNetV3_large_x0_5():
    model = MobileNetV3(model_name='large', scale=0.5)
    return model

",4
"    return model
# coding=utf-8
",4
"
",4
"                add_vars_prefix(context_prog, name_prefix)
",4
"                inputs = {
",4
"                place = fluid.CPUPlace()
                exe = fluid.Executor(place)
",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
                        return b

",4
"        API for image classification.

        Args:
            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR.
",4
"        """"""
        if use_gpu:
            try:
",4
"        for iter_id in range(loop_num):
            batch_data = list()
            handle_id = iter_id * batch_size
",4
"        exe = fluid.Executor(place)

",4
"            params_filename=params_filename)

    @serving
",4
"        """"""
        images_decode = [base64_to_cv2(image) for image in images]
",4
"        results = self.classification(images=images_decode, **kwargs)
        return results
",4
"        results = self.classification(
            paths=[args.input_path],
",4
"    def add_module_config_arg(self):
        """"""
        Add the command config options.
        """"""
        self.arg_config_group.add_argument(
",4
"#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#Unless required by applicable law or agreed to in writing, software
",4
"#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#See the License for the specific language governing permissions and
#limitations under the License.

",4
"
import paddle
import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr

",4
"__all__ = [
",4
"
",4
"                name='conv1_3')
",4
"
        conv = fluid.layers.pool2d(
",4
"            pool_type='max')

",4
"
    def conv_bn_layer(self,
                      input,
                      num_filters,
",4
"        if name == ""conv1"":
            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]
        return fluid.layers.batch_norm(
",4
"            pool_size=2,
",4
"
        conv = fluid.layers.conv2d(
            input=pool,
            num_filters=num_filters,
            filter_size=filter_size,
",4
"        return fluid.layers.batch_norm(
            input=conv,
",4
"
",4
"            num_filters=num_filters,
            filter_size=3,
            stride=stride,
",4
"            input=conv1,
            num_filters=num_filters * 4,
",4
"

def crop_image(img, target_size, center):
    width, height = img.size
",4
"    size = target_size
    if center == True:
        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
",4
"        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
        paths (list[str]): paths to images.

    Yield:
        each (collections.OrderedDict): info of original image, preprocessed image.
",4
"            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
            each['org_im_width'], each['org_im_height'] = each['org_im'].size
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)

    for element in component:
        element['image'] = process_image(element['org_im'])
",4
"        yield element
# coding=utf-8
from __future__ import absolute_import
",4
"import os

",4
"        x /= tmp.reshape((x.shape[0], 1))
",4
"import paddle.fluid as fluid
import paddlehub as hub
",4
"
    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"
",4
"            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
",4
"                memory_pool_init_size_mb=1000, device_id=0)
",4
"        Args:
            trainable (bool): Set parameters in program to be trainable.
            pretrained (bool) : Whether to load pretrained model.

        Returns:
",4
"                }
                add_vars_prefix(context_prog, name_prefix)
",4
"                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
                inputs = {
                    key: global_vars[value]
",4
"                if pretrained:

                    def _if_exist(var):
                        b = os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
",4
"
        Args:
",4
"            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR.
            paths (list[str]): The paths of images.
",4
"            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"                             params_filename=None,
                             combined=True):
        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
            params_filename = ""__params__"" if not params_filename else params_filename
",4
"
        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

",4
"            feeded_var_names=feeded_var_names,
            target_vars=target_vars,
",4
"    @serving
",4
"            usage='%(prog)s',
",4
"        results = self.classification(
",4
"            use_gpu=args.use_gpu)
        return results
",4
"    def add_module_input_arg(self):
",4
"import numpy as np
from PIL import Image

__all__ = ['reader']
",4
"    size = target_size
    if center == True:
",4
"        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
        w_start = np.random.randint(0, width - size + 1)
",4
"        img = img.convert('RGB')
    img = np.array(img).astype('float32').transpose((2, 0, 1)) / 255
    img -= img_mean
    img /= img_std
",4
"    return img

",4
"    Args:
        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
        paths (list[str]): paths to images.

",4
"    component = list()
    if paths:
",4
"    if images is not None:
",4
"
    for element in component:
        element['image'] = process_image(element['org_im'])
",4
"    return data


def softmax(x):
",4
"        tmp = np.max(x)
        x -= tmp
",4
"def postprocess(data_out, label_list, top_k):
    """"""
",4
"            label = label_list[index].split(',')[0]
            output_i[label] = float(result_i[index])
        output.append(output_i)
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"    def __init__(self, scale=1.0, model_name='small'):
",4
"                [3, 184, 80, False, 'hard_swish', 1],
                [3, 184, 80, False, 'hard_swish', 1],
",4
"            self.cls_ch_squeeze = 576
            self.cls_ch_expand = 1280
        else:
",4
"        cls_ch_expand = self.cls_ch_expand
        #conv1
        conv = self.conv_bn_layer(
            input,
",4
"            padding=1,
            num_groups=1,
",4
"            if_act=True,
            act='hard_swish',
",4
"                num_in_filter=inplanes,
                num_mid_filter=self.make_divisible(scale * layer_cfg[1]),
                num_out_filter=self.make_divisible(scale * layer_cfg[2]),
                act=layer_cfg[4],
",4
"                      if_act=True,
                      act=None,
                      name=None,
",4
"            act=None,
",4
"                    regularization_coeff=0.0)),
",4
"            if act == 'relu':
                bn = fluid.layers.relu(bn)
            elif act == 'hard_swish':
                bn = fluid.layers.hard_swish(bn)
",4
"
    def make_divisible(self, v, divisor=8, min_value=None):
        if min_value is None:
            min_value = divisor
",4
"            filter_size=1,
            num_filters=num_mid_filter,
",4
"            act=act,
            num_groups=num_mid_filter,
",4
"            use_cudnn=False,
            name=name + '_depthwise')
        if use_se:
            conv1 = self.se_block(
                input=conv1, num_out_filter=num_mid_filter, name=name + '_se')
",4
"
",4
"            return conv2
        else:
            return fluid.layers.elementwise_add(x=input, y=conv2, act=None)

",4
"

def MobileNetV3_large_x0_35():
",4
"    model = MobileNetV3(model_name='large', scale=0.35)
    return model
",4
"

def MobileNetV3_large_x0_75():
",4
"
from mobilenet_v2_dishes.processor import postprocess, base64_to_cv2
",4
"    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"        im_std = np.array([0.229, 0.224, 0.225]).reshape(1, 3)
        return im_std
",4
"        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"            self.gpu_predictor = create_paddle_predictor(gpu_config)

    def context(self, trainable=True, pretrained=True):
",4
"
        Args:
            trainable (bool): Set parameters in program to be trainable.
",4
"        Returns:
            inputs (dict): key is 'image', corresponding vaule is image tensor.
            outputs (dict): key is :
                'classification', corresponding value is the result of classification.
",4
"                # pretrained
",4
"                if pretrained:
",4
"                    exe.run(startup_prog)
                # trainable
                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
        return inputs, outputs, context_prog
",4
"            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR. .
            paths (list[str]): The paths of images.
            batch_size (int): batch size.
",4
"            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"                )

        all_data = list()
        for yield_data in reader(images, paths):
",4
"        total_num = len(all_data)
        loop_num = int(np.ceil(total_num / batch_size))

",4
"            # feed batch image
            batch_image = np.array([data['image'] for data in batch_data])
            batch_image = PaddleTensor(batch_image.copy())
",4
"            main_program=program,
",4
"        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
            description=
",4
"            help=""whether use GPU or not."")
        self.arg_config_group.add_argument(
            '--batch_size',
",4
"            type=ast.literal_eval,
",4
"            default=1,
",4
"import cv2
import numpy as np
",4
"        w_start = np.random.randint(0, width - size + 1)
        h_start = np.random.randint(0, height - size + 1)
    w_end = w_start + size
    h_end = h_start + size
",4
"    """"""
    component = list()
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)

    for element in component:
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import base64
",4
"        x /= tmp.reshape((x.shape[0], 1))
    else:
        tmp = np.max(x)
        x -= tmp
",4
"        data_out (numpy.ndarray): output data of network.
        label_list (list): list of label.
        top_k (int): Return top k results.
    """"""
    output = []
",4
"            label = label_list[index]
            output_i[label] = float(result_i[index])
",4
"
import paddle.fluid as fluid
",4
"
train_parameters = {
    ""input_size"": [3, 224, 224],
    ""input_mean"": [0.485, 0.456, 0.406],
    ""input_std"": [0.229, 0.224, 0.225],
",4
"    }
}


class MobileNetV2():
",4
"    def __init__(self):
        self.params = train_parameters
",4
"        input = self.conv_bn_layer(
            input,
",4
"            num_filters=int(32 * scale),
",4
"        i = 1
        in_c = int(32 * scale)
        for layer_setting in bottleneck_params_list:
",4
"            in_c = int(c * scale)
        #last_conv
        input = self.conv_bn_layer(
",4
"        input = fluid.layers.pool2d(
            input=input,
",4
"            global_pooling=True)

        output = fluid.layers.fc(
",4
"            filter_size=filter_size,
            stride=stride,
            padding=padding,
            groups=num_groups,
",4
"            return fluid.layers.relu6(bn)
        else:
            return bn
",4
"    def shortcut(self, input, data_residual):
        return fluid.layers.elementwise_add(input, data_residual)
",4
"                               stride,
                               filter_size,
                               padding,
                               expansion_factor,
",4
"            filter_size=filter_size,
            stride=stride,
",4
"            padding=padding,
            num_groups=num_expfilter,
            if_act=True,
",4
"        else:
            return linear_out

    def invresi_blocks(self, input, in_c, t, c, n, s, name=None):
",4
"            num_filters=c,
            ifshortcut=False,
            stride=s,
            filter_size=3,
            padding=1,
",4
"from paddlehub.common.paddle_helper import add_vars_prefix
",4
"    ""SE_ResNet18_vd is a image classfication model, this module is trained with imagenet datasets."",
    version=""1.0.0"")
",4
"            self.directory, ""se_resnet18_vd_imagenet_model"")
        label_file = os.path.join(self.directory, ""label_list.txt"")
        with open(label_file, 'r', encoding='utf-8') as file:
",4
"        """"""
",4
"                'classification', corresponding value is the result of classification.
                'feature_map', corresponding value is the result of the layer before the fully connected layer.
            context_prog (fluid.Program): program for transfer learning.
        """"""
",4
"                outputs = {
                    'classification': name_prefix + output.name,
                    'feature_map': name_prefix + feature_map.name
                }
                add_vars_prefix(context_prog, name_prefix)
",4
"                        return b
",4
"                        exe,
",4
"
        Args:
",4
"            images (list[numpy.ndarray]): data of images, shape of each is [H, W, C], color space must be BGR.
            paths (list[str]): The paths of images.
            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"        Returns:
            res (list[dict]): The classfication results.
        """"""
        if use_gpu:
",4
"            try:
",4
"        for iter_id in range(loop_num):
",4
"    def save_inference_model(self,
                             dirname,
",4
"        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
            dirname=dirname,
",4
"    def run_cmd(self, argvs):
",4
"        """"""
        Run as a command.
",4
"        self.arg_input_group = self.parser.add_argument_group(
",4
"            '--use_gpu',
            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not."")
",4
"        self.arg_config_group.add_argument(
            '--batch_size',
",4
"            type=ast.literal_eval,
            default=1,
            help=""batch size."")
        self.arg_config_group.add_argument(
            '--top_k',
",4
"#you may not use this file except in compliance with the License.
",4
"
from __future__ import absolute_import
from __future__ import division
",4
"from __future__ import print_function

import math

",4
"import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr
",4
"        self.layers = layers
        self.is_3x3 = is_3x3

    def net(self, input, class_dim=1000):
",4
"                num_filters=64,
                filter_size=7,
                stride=2,
                act='relu')
",4
"                name='conv1_1')
            conv = self.conv_bn_layer(
",4
"            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv)))

",4
"                          input,
                          num_filters,
",4
"        pool = fluid.layers.pool2d(
            input=input,
            pool_size=2,
            pool_stride=2,
            pool_padding=0,
",4
"            input=pool,
            num_filters=num_filters,
            filter_size=filter_size,
            stride=1,
            padding=(filter_size - 1) // 2,
",4
"        ch_in = input.shape[1]
        if ch_in != ch_out or stride != 1:
            if if_first:
                return self.conv_bn_layer(input, ch_out, 1, stride, name=name)
",4
"        else:
",4
"        conv1 = self.conv_bn_layer(
            input=conv0,
            num_filters=num_filters,
            filter_size=3,
",4
"            stride,
            if_first=if_first,
            name=name + ""_branch1"")

",4
"            if_first=if_first,
            name=name + ""_branch1"")
        return fluid.layers.elementwise_add(x=short, y=conv1, act='relu')
",4
"    model = ResNet(layers=200, is_3x3=True)
    return model
",4
"img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))

",4
"
",4
"    resized_height = int(round(img.size[1] * percent))
    img = img.resize((resized_width, resized_height), Image.LANCZOS)
    return img

",4
"
def crop_image(img, target_size, center):
    width, height = img.size
    size = target_size
    if center == True:
",4
"        w_start = (width - size) / 2
        h_start = (height - size) / 2
",4
"def process_image(img):
    img = resize_short(img, target_size=256)
    img = crop_image(img, target_size=DATA_DIM, center=True)
    if img.mode != 'RGB':
        img = img.convert('RGB')
",4
"                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
            each['org_im_width'], each['org_im_height'] = each['org_im'].size
",4
"#
#Licensed under the Apache License, Version 2.0 (the ""License"");
#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at
",4
"        supported_layers = [18, 34, 50, 101, 152, 200]
        assert layers in supported_layers, \
            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)

",4
"        elif layers == 152:
            depth = [3, 8, 36, 3]
        elif layers == 200:
            depth = [3, 12, 48, 3]
",4
"                num_filters=64,
                filter_size=7,
                stride=2,
",4
"            pool_stride=2,
",4
"            pool_padding=1,
            pool_type='max')
        if layers >= 50:
",4
"                            conv_name = ""res"" + str(block + 2) + ""a""
",4
"                        if_first=block == i == 0,
                        reduction_ratio=reduction_ratio,
                        name=conv_name)

",4
"            input=pool,
            size=class_dim,
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv),
",4
"
",4
"                          name=None):
        pool = fluid.layers.pool2d(
            input=input,
            pool_size=2,
            pool_stride=2,
",4
"            input=conv,
            act=act,
            param_attr=ParamAttr(name=bn_name + '_scale'),
",4
"        if ch_in != ch_out or stride != 1:
            if if_first:
                return self.conv_bn_layer(input, ch_out, 1, stride, name=name)
            else:
                return self.conv_bn_layer_new(
",4
"            reduction_ratio=reduction_ratio,
            name='fc_' + name)
",4
"            input=conv0,
            num_filters=num_filters,
            filter_size=3,
            act=None,
",4
"            act='sigmoid',
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv),
",4
"def SE_ResNet34_vd():
",4
"    model = SE_ResNet_vd(layers=34, is_3x3=True)
    return model

",4
"
def SE_ResNet200_vd():
    model = SE_ResNet_vd(layers=200, is_3x3=True)
    return model
# coding=utf-8
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import base64
",4
"
def base64_to_cv2(b64str):
    data = base64.b64decode(b64str.encode('utf8'))
    data = np.fromstring(data, np.uint8)
",4
"        tmp = np.sum(x)
        x /= tmp
",4
"

",4
"    def _initialize(self):
        self.default_pretrained_model_path = os.path.join(
            self.directory, ""vgg16_model"")
        self.label_names = load_label_info(
",4
"        return im_std

    def _set_config(self):
",4
"        """"""
        cpu_config = AnalysisConfig(self.default_pretrained_model_path)
        cpu_config.disable_glog_info()
        cpu_config.disable_gpu()
        cpu_config.switch_ir_optim(False)
",4
"        self.cpu_predictor = create_paddle_predictor(cpu_config)

        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"                    return os.path.exists(
                        os.path.join(self.default_pretrained_model_path,
                                     var.name))

",4
"        :param images: data of images, [N, H, W, C]
        :type images: numpy.ndarray
",4
"                trainable=False, pretrained=True, get_prediction=True)
            self.infer_prog = self.infer_prog.clone(for_test=True)
            self.pred_out = outputs['pred_out']
",4
"        place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()
        exe = fluid.Executor(place)
        all_images = []
        paths = paths if paths else []
",4
"            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
                try:
                    batch_data.append(all_images[handle_id + image_id])
                except:
",4
"                    pass
            batch_data = np.array(batch_data).astype('float32')
",4
"            data_tensor = PaddleTensor(batch_data.copy())
            if use_gpu:
",4
"            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not"")

        self.arg_config_group.add_argument(
",4
"                raise RuntimeError(""File %s is not exist."" % args.input_file)
",4
"            else:
                input_data = txt_parser.parse(args.input_file, use_strip=True)
        return input_data

    @runnable
",4
"    def run_cmd(self, argvs):
        self.parser = argparse.ArgumentParser(
",4
"            description=""Run the {}"".format(self.name),
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
from paddle import fluid
from paddle.fluid.param_attr import ParamAttr

__all__ = ['VGG']
",4
"    """"""

",4
"                conv, v, nums[k], name=""conv{}_"".format(k + 1))
",4
"            fc1 = fluid.layers.fc(
                input=conv,
                size=fc_dim,
                act='relu',
",4
"                param_attr=fluid.param_attr.ParamAttr(
                    name=fc_name[0] + ""_weights""),
",4
"            return [layers[3], fc7]
",4
"
    def _add_extras_block(self, input):
",4
"        layers = []
        for k, v in enumerate(cfg):
            assert len(v) == 5, ""extra_block_filters size not fix""
            conv = self._extra_block(
",4
"                conv,
",4
"        return conv

",4
"                       pool_stride,
                       pool_padding=0,
                       ceil_mode=True):
        pool = fluid.layers.pool2d(
            input=conv,
",4
"            pool_size=pool_size,
            pool_type='max',
",4
"            pool_stride=pool_stride,
            pool_padding=pool_padding,
            ceil_mode=ceil_mode)
        return pool

",4
"            attr=helper.param_attr,
            shape=shape,
",4
"            name=""conv4_3_norm_scale"")
        return out
# coding=utf-8
from __future__ import absolute_import
",4
"    if center == True:
        w_start = (width - size) / 2
        h_start = (height - size) / 2
    else:
        w_start = np.random.randint(0, width - size + 1)
",4
"def process_image(img):
    img = resize_short(img, target_size=256)
    img = crop_image(img, target_size=DATA_DIM, center=True)
    if img.mode != 'RGB':
        img = img.convert('RGB')
",4
"    """"""
    img_list = []
    if paths:
",4
"                img_path), ""The {} isn't a valid file path."".format(img_path)
            img = Image.open(img_path)
            #img = cv2.imread(img_path)
",4
"    if images is not None:
",4
"# coding=utf-8

",4
"        return getattr(self.model, '_model_type', '')

    @property
    def variant(self):
",4
"        if self.model_type == 'SEResNeXt':
            bn_name = name + ""_bn""
",4
"
    def fix_bottleneck_name(self, name):
        if self.model_type == 'SEResNeXt':
            conv_name1 = 'conv' + name + '_x1'
",4
"            conv_name2 = name + ""_branch2b""
",4
"    def fix_layer_warp_name(self, stage_num, count, i):
        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
",4
"            conv_name = str(stage_num + 2) + '_' + str(i + 1)
",4
"from paddlehub.module.module import moduleinfo, runnable
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
from paddlehub.io.parser import txt_parser

",4
"
",4
"    type=""cv/classification"",
",4
"        self.pred_out = None
        self._set_config()

",4
"        except:
            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
",4
"        :param depth: depth of network
        :type depth: int
        :param variant: type of resnet
        :type variant: str
",4
"        :param norm_type: type of normlization
        :type norm_type: str
",4
"        :type feature_maps: list
        """"""
        context_prog = input_image.block.program if input_image else fluid.Program(
",4
"            image = input_image if input_image else fluid.data(
                name='image',
                shape=[-1, 3, 224, 224],
                dtype='float32',
                lod_level=0)
",4
"            backbone = ResNet(depth=50, variant=variant, norm_type=norm_type,\
                              feature_maps=feature_maps, get_prediction=get_prediction)

            out = backbone(image)
",4
"            inputs = {'image': image}
            if get_prediction:
                outputs = {'pred_out': out}
            else:
                outputs = {'body_feats': out}
",4
"
            place = fluid.CPUPlace()
            exe = fluid.Executor(place)
            if pretrained:

",4
"                def _if_exist(var):
                    return os.path.exists(
",4
"                                     var.name))

                if not param_prefix:
                    fluid.io.load_vars(
",4
"    def classification(self,
                       paths=None,
                       images=None,
                       use_gpu=False,
",4
"                       top_k=2):
        """"""API of Classification.
        :param paths: the path of images.
        :type paths: list, each element is correspond to the path of an image.
",4
"                    max_prob = res[k]
                    res_dict[class_name] = max_prob
                res_list.append(res_dict)
",4
"        return res_list

    def add_module_config_arg(self):
        """"""
",4
"            if not os.path.exists(args.input_file):
                raise RuntimeError(""File %s is not exist."" % args.input_file)
            else:
",4
"
    @runnable
    def run_cmd(self, argvs):
        self.parser = argparse.ArgumentParser(
",4
"from __future__ import unicode_literals

import paddle.fluid as fluid
from paddle.fluid import ParamAttr

",4
"                   max_pool_stride=2):
",4
"
    g = fluid.layers.conv2d(input = max_pool, num_filters = dim_inner, \
",4
"
",4
"                      moving_variance_name = bn_name + ""_riv"") # add bn
",4
"def add_space_nonlocal(input, dim_in, dim_out, prefix, dim_inner):
    '''
    add_space_nonlocal:
",4
"from __future__ import division

import os
from collections import OrderedDict
",4
"from paddle import fluid

",4
"    img = img.resize((resized_width, resized_height), Image.LANCZOS)
",4
"    else:
        w_start = np.random.randint(0, width - size + 1)
        h_start = np.random.randint(0, height - size + 1)
    w_end = w_start + size
",4
"        img = img.convert('RGB')
    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = np.array(img).astype('float32').transpose((2, 0, 1)) / 255
",4
"    :type images: numpy.ndarray
    """"""
    img_list = []
    if paths:
",4
"    for im in img_list:
        im = process_image(im)
        yield im
# coding=utf-8
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

",4
"import math
from collections import OrderedDict
from numbers import Integral

",4
"                 freeze_at=0,
",4
"            50: ([3, 4, 6, 3], self.bottleneck),
        }
        self.stage_filters = [64, 128, 256, 512]
",4
"                   name=None,
                   dcn_v2=False):
",4
"                filter_size=filter_size,
                stride=stride,
                padding=(filter_size - 1) // 2,
",4
"            offset_mask = self._conv_offset(
",4
"                padding=(filter_size - 1) // 2,
",4
"                act=None,
                name=_name + ""_conv_offset"")
",4
"                im2col_step=1,
                param_attr=ParamAttr(name=_name + ""_weights""),
",4
"                bias_attr=False,
                name=_name + "".conv2d.output.1"")

        bn_name = self.na.fix_conv_norm_name(name)
        bn_name = self.prefix_name + bn_name if self.prefix_name != '' else bn_name
",4
"            if std_senet:
",4
"                    pool_padding=0,
                    ceil_mode=True,
",4
"            return self._conv_norm(input, ch_out, 1, stride, name=name)
        else:
            return input

",4
"                   stride,
                   is_first,
",4
"                   dcn_v2=False):
",4
"        conv_name1, conv_name2, conv_name3, \
            shortcut_name = self.na.fix_bottleneck_name(name)
",4
"        else:
            conv_def = [[num_filters, 1, stride1, 'relu', 1, conv_name1],
                        [num_filters, 3, stride2, 'relu', groups, conv_name2],
",4
"                        [num_filters * expand, 1, 1, None, 1, conv_name3]]

        residual = input
",4
"            stride,
",4
"            num_filters=num_filters,
            filter_size=3,
            act=None,
            name=name + ""_branch2b"")
        short = self._shortcut(
",4
"            input, num_filters, stride, is_first, name=name + ""_branch1"")
        return fluid.layers.elementwise_add(x=short, y=conv1, act='relu')

",4
"        nonlocal_mod = 1000
        if stage_num in self.nonlocal_stages:
            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2
",4
"
",4
"        conv = input
        for i in range(count):
            conv_name = self.na.fix_layer_warp_name(stage_num, count, i)
            if self.depth < 50:
                is_first = True if i == 0 and stage_num == 2 else False
",4
"            conv = block_func(
                input=conv,
                num_filters=ch_out,
                stride=2 if i == 0 and stage_num != 2 else 1,
                is_first=is_first,
",4
"                input=input,
                num_filters=c,
",4
"
        output = fluid.layers.pool2d(
",4
"
        res = input
        feature_maps = self.feature_maps
        severed_head = getattr(self, 'severed_head', False)
",4
"                    initializer=fluid.initializer.Uniform(-stdv, stdv)))
            out = fluid.layers.softmax(out)
            return out
",4
"def load_label_info(file_path):
    with open(file_path, 'r') as fr:
        return fr.read().split(""\n"")[:-1]
",4
"
    def get_expected_image_width(self):
        return 224

    def get_expected_image_height(self):
",4
"        return 224

    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"        return im_std

    def _set_config(self):
        """"""
",4
"            int(_places[0])
            use_gpu = True
",4
"        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
",4
"                        self.default_pretrained_model_path,
                        context_prog,
                        predicate=_if_exist)
                else:
                    exe.run(startup_prog)
",4
"        """"""
",4
"                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
            except:
                raise RuntimeError(
",4
"            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
                try:
                    batch_data.append(all_data[handle_id + image_id])
                except:
",4
"                             params_filename=None,
                             combined=True):
        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
",4
"            dirname=dirname,
            main_program=program,
            executor=exe,
            feeded_var_names=feeded_var_names,
            target_vars=target_vars,
",4
"        """"""
        Run as a service.
        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.classification(images=images_decode, **kwargs)
",4
"            title=""Input options"", description=""Input data. Required"")
        self.arg_config_group = self.parser.add_argument_group(
            title=""Config options"",
",4
"            '--use_gpu',
            type=ast.literal_eval,
",4
"            default=1,
            help=""batch size."")
        self.arg_config_group.add_argument(
",4
"            type=ast.literal_eval,
            default=1,
            help=""Return top k results."")

    def add_module_input_arg(self):
",4
"#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"__all__ = [
    ""ResNet"", ""ResNet50_vd"", ""ResNet101_vd"", ""ResNet152_vd"", ""ResNet200_vd""
]

",4
"
    def net(self, input, class_dim=1000):
        is_3x3 = self.is_3x3
",4
"                num_filters=32,
                filter_size=3,
",4
"                    if i == 0:
",4
"                initializer=fluid.initializer.Uniform(-stdv, stdv)))

        return out, pool

",4
"            num_filters=num_filters,
",4
"            padding=(filter_size - 1) // 2,
            groups=groups,
            act=None,
            param_attr=ParamAttr(name=name + ""_weights""),
            bias_attr=False)
",4
"            pool_type='avg')
",4
"            filter_size=filter_size,
            stride=1,
            padding=(filter_size - 1) // 2,
            groups=groups,
            act=None,
",4
"                return self.conv_bn_layer_new(
                    input, ch_out, 1, stride, name=name)
        else:
            return input

",4
"
def ResNet101_vd():
    model = ResNet(layers=101, is_3x3=True)
    return model

",4
"

def ResNet200_vd():
    model = ResNet(layers=200, is_3x3=True)
",4
"

",4
"    if img.mode != 'RGB':
",4
"        img = img.convert('RGB')
",4
"        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
",4
"    Yield:
",4
"            each = OrderedDict()
            assert os.path.isfile(
                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)

    for element in component:
",4
"    else:
        tmp = np.max(x)
        x -= tmp
",4
"        x = np.exp(x)
        tmp = np.sum(x)
        x /= tmp
    return x

",4
"        output_i = {}
",4
"
",4
"    author_email=""paddle-dev@baidu.com"",
    summary=
    ""ResNet50vd is a image classfication model, this module is trained with Baidu's self-built dataset with 100,000 categories."",
",4
"                image = fluid.layers.data(
                    name=""image"", shape=[3, 224, 224], dtype=""float32"")
",4
"                inputs = {'image': name_prefix + image.name}
                outputs = {'feature_map': name_prefix + feature_map.name}
                add_vars_prefix(context_prog, name_prefix)
                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
",4
"                inputs = {
                    key: global_vars[value]
                    for key, value in inputs.items()
                }
                outputs = {
",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
                        return b

",4
"                # trainable
                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
        return inputs, outputs, context_prog

",4
"
",4
"    ""input_size"": [3, 224, 224],
    ""input_mean"": [0.485, 0.456, 0.406],
    ""input_std"": [0.229, 0.224, 0.225],
    ""learning_strategy"": {
",4
"        ""epochs"": [30, 60, 90],
",4
"                num_filters=64,
",4
"                filter_size=7,
                stride=2,
                act='relu')
        else:
",4
"                if layers in [101, 152, 200] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
",4
"                          act=None,
                          name=None):
        pool = fluid.layers.pool2d(
            input=input,
",4
"            input=pool,
",4
"            param_attr=ParamAttr(name=bn_name + '_scale'),
            bias_attr=ParamAttr(bn_name + '_offset'),
            moving_mean_name=bn_name + '_mean',
",4
"            act=None,
            name=name + ""_branch2c"")
",4
"            input,
            num_filters * 4,
            stride,
            if_first=if_first,
            name=name + ""_branch1"")
",4
"
",4
"
def ResNet152_vd():
    model = ResNet(layers=152, is_3x3=True)
",4
"    width, height = img.size
    size = target_size
    if center == True:
",4
"        w_start = (width - size) / 2
",4
"    img = crop_image(img, target_size=DATA_DIM, center=True)
    if img.mode != 'RGB':
        img = img.convert('RGB')
",4
"
",4
"    if images is not None:
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)
",4
"from __future__ import print_function

",4
"        tmp = np.max(x)
        x -= tmp
",4
"        x /= tmp
",4
"    return x


",4
"        for index in indexs:
            label = label_list[index].split(',')[0]
            output_i[label] = float(result_i[index])
        output.append(output_i)
    return output
",4
"            self.directory, ""model"")
        label_file = os.path.join(self.directory, ""label_list.txt"")
        with open(label_file, 'r', encoding='utf-8') as file:
",4
"            self.label_list = file.read().split(""\n"")[:-1]
        self._set_config()

    def get_expected_image_width(self):
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
",4
"
",4
"                    key: global_vars[value]
                    for key, value in outputs.items()
",4
"                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
        return inputs, outputs, context_prog

    def save_inference_model(self,
",4
"                             dirname,
                             model_filename=None,
",4
"        API for image classification.
",4
"        Returns:
            res (list[dict]): The classfication results.
        """"""
",4
"
        all_data = list()
        for yield_data in reader(images, paths):
            all_data.append(yield_data)
",4
"            batch_data = list()
",4
"            handle_id = iter_id * batch_size
            for image_id in range(batch_size):
",4
"            batch_image = np.array([data['image'] for data in batch_data])
            batch_image = PaddleTensor(batch_image.copy())
",4
"                data_out=predictor_output[0].as_ndarray(),
                label_list=self.label_list,
                top_k=top_k)
            res += out
",4
"        return res

    @serving
    def serving_method(self, images, **kwargs):
        """"""
",4
"            title=""Config options"",
",4
"            description=
            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
",4
"    def add_module_input_arg(self):
        """"""
        Add the command input options.
",4
"
",4
"DATA_DIM = 224
img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))
img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))

",4
"
",4
"    """"""
    Preprocess to yield image.

    Args:
",4
"    component = list()
    if paths:
        for im_path in paths:
",4
"                im_path), ""The {} isn't a valid file path."".format(im_path)
",4
"    else:
        tmp = np.max(x)
        x -= tmp
",4
"        output.append(output_i)
    return output
# copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.
",4
"from __future__ import division
from __future__ import print_function

",4
"                t=t,
                c=int(c * scale),
",4
"                n=n,
                s=s,
                name='conv' + str(i))
            in_c = int(c * scale)
",4
"        #last_conv
        input = self.conv_bn_layer(
            input=input,
",4
"            num_filters=int(1280 * scale) if scale > 1.0 else 1280,
            filter_size=1,
",4
"                      input,
                      filter_size,
                      num_filters,
                      stride,
                      padding,
",4
"                      channels=None,
                      num_groups=1,
                      if_act=True,
                      name=None,
                      use_cudnn=True):
",4
"            return bn
",4
"                               num_filters,
",4
"            if_act=True,
",4
"            num_groups=num_expfilter,
            if_act=True,
",4
"            name=name + '_dwise',
            use_cudnn=False)

        linear_out = self.conv_bn_layer(
            input=bottleneck_conv,
",4
"            stride=s,
            filter_size=3,
",4
"
def MobileNetV2_x0_5():
    model = MobileNetV2(scale=0.5)
    return model
",4
"
def MobileNetV2_x2_0():
    model = MobileNetV2(scale=2.0)
",4
"    return model
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"
import ast
import argparse
import os
",4
"            self.directory, ""model"")
        label_file = os.path.join(self.directory, ""label_list.txt"")
        with open(label_file, 'r', encoding='utf-8') as file:
",4
"        return 224

    def get_expected_image_height(self):
        return 224

",4
"    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
",4
"            int(_places[0])
            use_gpu = True
        except:
            use_gpu = False
        if use_gpu:
",4
"        Returns:
            inputs (dict): key is 'image', corresponding vaule is image tensor.
",4
"        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
",4
"                }
                add_vars_prefix(context_prog, name_prefix)
                add_vars_prefix(startup_prog, name_prefix)
                global_vars = context_prog.global_block().vars
                inputs = {
",4
"                    key: global_vars[value]
                    for key, value in inputs.items()
                }
                outputs = {
",4
"                }

                place = fluid.CPUPlace()
                exe = fluid.Executor(place)
                # pretrained
",4
"                    exe.run(startup_prog)
                # trainable
",4
"            images (numpy.ndarray): data of images, shape of each is [H, W, C], color space must be BGR.
            paths (list[str]): The paths of images.
            batch_size (int): batch size.
            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.
",4
"
        Returns:
            res (list[dict]): The classfication results.
",4
"        for iter_id in range(loop_num):
            batch_data = list()
            handle_id = iter_id * batch_size
",4
"                    batch_data.append(all_data[handle_id + image_id])
                except:
                    pass
            # feed batch image
            batch_image = np.array([data['image'] for data in batch_data])
",4
"
        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
",4
"        """"""
        self.parser = argparse.ArgumentParser(
            description=""Run the {} module."".format(self.name),
",4
"        self.add_module_config_arg()
        self.add_module_input_arg()
",4
"        args = self.parser.parse_args(argvs)
        results = self.classification(
            paths=[args.input_path],
",4
"            default=False,
            help=""whether use GPU or not."")
        self.arg_config_group.add_argument(
            '--batch_size',
            type=ast.literal_eval,
",4
"            type=ast.literal_eval,
            default=1,
            help=""Return top k results."")

    def add_module_input_arg(self):
",4
"        """"""
        Add the command input options.
        """"""
        self.arg_input_group.add_argument(
",4
"                num_filters=64,
                filter_size=7,
                stride=2,
",4
"                act='relu')
",4
"                name='conv1_3')

        conv = fluid.layers.pool2d(
",4
"                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
                else:
",4
"            size=class_dim,
            param_attr=fluid.param_attr.ParamAttr(
                initializer=fluid.initializer.Uniform(-stdv, stdv)))
",4
"            bn_name = ""bn_"" + name
",4
"        else:
            bn_name = ""bn"" + name[3:]
        return fluid.layers.batch_norm(
            input=conv,
            act=act,
",4
"            param_attr=ParamAttr(name=bn_name + '_scale'),
            bias_attr=ParamAttr(bn_name + '_offset'),
            moving_mean_name=bn_name + '_mean',
            moving_variance_name=bn_name + '_variance')
",4
"        ch_in = input.shape[1]
        if ch_in != ch_out or stride != 1:
",4
"        conv2 = self.conv_bn_layer(
            input=conv1,
            num_filters=num_filters * 4,
",4
"    return model


def ResNet152_vd():
",4
"    return model
",4
"import os
",4
"img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))


def resize_short(img, target_size):
    percent = float(target_size) / min(img.size[0], img.size[1])
",4
"    resized_height = int(round(img.size[1] * percent))
    img = img.resize((resized_width, resized_height), Image.LANCZOS)
    return img


",4
"def reader(images=None, paths=None):
    """"""
    Preprocess to yield image.
",4
"
    Args:
        images (list[numpy.ndarray]): images data, shape of each is [H, W, C].
        paths (list[str]): paths to images.
",4
"# coding=utf-8
from __future__ import absolute_import
",4
"import base64
import cv2
import os
",4
"        for index in indexs:
",4
"        output.append(output_i)
    return output
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"
import ast
import argparse
import os

",4
"import numpy as np
",4
"import paddle.fluid as fluid
import paddlehub as hub
from paddle.fluid.core import PaddleTensor, AnalysisConfig, create_paddle_predictor
from paddlehub.module.module import moduleinfo, runnable, serving
from paddlehub.common.paddle_helper import add_vars_prefix
",4
"        return 224

    def get_pretrained_images_mean(self):
        im_mean = np.array([0.485, 0.456, 0.406]).reshape(1, 3)
        return im_mean
",4
"        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
            use_gpu = True
",4
"            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
",4
"        startup_prog = fluid.Program()
        with fluid.program_guard(context_prog, startup_prog):
            with fluid.unique_name.guard():
                image = fluid.layers.data(
",4
"                    'classification': name_prefix + output.name,
                    'feature_map': name_prefix + feature_map.name
                }
",4
"                    key: global_vars[value]
                    for key, value in inputs.items()
                }
                outputs = {
                    key: global_vars[value]
",4
"            use_gpu (bool): Whether to use gpu.
            top_k (int): Return top k results.

        Returns:
            res (list[dict]): The classfication results.
",4
"                int(_places[0])
",4
"                    batch_data.append(all_data[handle_id + image_id])
                except:
                    pass
            # feed batch image
",4
"            batch_image = np.array([data['image'] for data in batch_data])
",4
"                data_out=predictor_output[0].as_ndarray(),
                label_list=self.label_list,
                top_k=top_k)
            res += out
",4
"
        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
            executor=exe,
",4
"            params_filename=params_filename)

    @serving
    def serving_method(self, images, **kwargs):
",4
"            use_gpu=args.use_gpu)
        return results

",4
"            type=ast.literal_eval,
            default=1,
",4
"        """"""
        Add the command input options.
        """"""
",4
"        for im_path in paths:
            each = OrderedDict()
            assert os.path.isfile(
",4
"                im_path), ""The {} isn't a valid file path."".format(im_path)
            each['org_im_path'] = im_path
            each['org_im'] = Image.open(im_path)
",4
"            each['org_im_width'], each['org_im_height'] = each['org_im'].size
            component.append(each)
    if images is not None:
        assert type(images), ""images is a list.""
        for im in images:
",4
"from __future__ import absolute_import
",4
"from __future__ import division
from __future__ import print_function
",4
"        for index in indexs:
            label = label_list[index]
",4
"        self.params = train_parameters

",4
"            (6, 320, 1, 1),
        ]

        #conv1
        input = self.conv_bn_layer(
",4
"            filter_size=3,
",4
"            stride=2,
            padding=1,
            if_act=True,
            name='conv1_1')
",4
"            num_filters=int(1280 * scale) if scale > 1.0 else 1280,
            filter_size=1,
            stride=1,
            padding=0,
",4
"        input = fluid.layers.pool2d(
            input=input,
",4
"            pool_size=7,
            pool_stride=1,
            pool_type='avg',
",4
"    def conv_bn_layer(self,
                      input,
                      filter_size,
                      num_filters,
",4
"                      stride,
                      padding,
                      channels=None,
",4
"            return fluid.layers.relu6(bn)
        else:
",4
"                               num_in_filter,
",4
"            num_groups=1,
            if_act=True,
            name=name + '_expand')
",4
"    def invresi_blocks(self, input, in_c, t, c, n, s, name=None):
        first_block = self.inverted_residual_unit(
            input=input,
",4
"            num_in_filter=in_c,
            num_filters=c,
            ifshortcut=False,
            stride=s,
",4
"                input=last_residual_block,
                num_in_filter=last_c,
                num_filters=c,
                ifshortcut=True,
                stride=1,
",4
"        """"""
        Args:
            face_detector_module (class): module to detect face.
        """"""
",4
"        self.default_pretrained_model_path = os.path.join(
            self.directory, ""face_landmark_localization"")
        if face_detector_module is None:
",4
"        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(
",4
"    def set_face_detector_module(self, face_detector_module):
        """"""
        Set face detector.

",4
"
",4
"        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)
        face_landmark_dir = os.path.join(dirname, ""face_landmark"")
        detector_dir = os.path.join(dirname, ""detector"")
",4
"        fluid.io.save_inference_model(
            dirname=face_landmark_dir,
            main_program=program,
            executor=exe,
            feeded_var_names=feeded_var_names,
",4
"        API for face landmark.

",4
"        # get all data
        all_data = []
        for yield_data in reader(self.face_detector, images, paths, use_gpu):
            all_data.append(yield_data)

",4
"            for idx, sample in enumerate(batch_data):
                sample['points'] = points[idx].reshape(68, -1)
            res += batch_data

        res = postprocess(res, output_dir, visualization)
",4
"    @runnable
    def run_cmd(self, argvs):
        """"""
        Run as a command.
        """"""
",4
"__all__ = [""face_landmark_localization""]


",4
"def face_landmark_localization(image):
    # image = fluid.layers.data(shape=[1, 60, 60], name='data', dtype='float32')
",4
"    Conv2 = fluid.layers.conv2d(
        Pool1,
        param_attr='Conv2_weights',
        name='Conv2',
",4
"        dilation=[1, 1],
",4
"        stride=[1, 1],
        groups=1,
        bias_attr='Conv3_bias',
        padding=[0, 0],
",4
"        ceil_mode=True,
        pool_size=[3, 3])
    Conv4 = fluid.layers.conv2d(
        Pool3,
",4
"    Dense1 = fluid.layers.fc(
        ActivationAbs4,
        param_attr='Dense1_weights',
",4
"        act=None,
        name='Dense1',
        size=512,
        bias_attr='Dense1_bias')
",4
"    ActivationTangH5 = fluid.layers.tanh(Dense1, name='ActivationTangH5')
    ActivationAbs5 = fluid.layers.abs(ActivationTangH5, name='ActivationAbs5')
    Dense3 = fluid.layers.fc(
",4
"        param_attr='Dense3_weights',
",4
"        size=136,
        bias_attr='Dense3_bias')
    return Dense3
# coding=utf-8
",4
"
",4
"
    Args:
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C].
        paths (list[str]): paths to images.

",4
"    """"""
    components = []
    if paths:
        for im_path in paths:
            each = OrderedDict()
",4
"            each['orig_im'] = im
            each['orig_im_shape'] = im.shape
            each['orig_im_path'] = im_path
            components.append(each)
",4
"        for face in item['data']:
            width = int(components[idx]['orig_im_shape'][1])
            height = int(components[idx]['orig_im_shape'][0])
            x1 = 0 if int(face['left']) < 0 else int(face['left'])
",4
"            x2 = width if int(face['right']) > width else int(face['right'])
            y1 = 0 if int(face['top']) < 0 else int(face['top'])
            y2 = height if int(face['bottom']) > height else int(face['bottom'])
",4
"            roi = components[idx]['orig_im'][y1:y2 + 1, x1:x2 + 1, :]
            gray_img = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)
            gray_img = cv2.resize(
                gray_img, (60, 60), interpolation=cv2.INTER_CUBIC)
            mean, std_dev = cv2.meanStdDev(gray_img)
",4
"
import base64
import os
",4
"        os.makedirs(dir_path)
    elif os.path.isfile(dir_path):
",4
"    """"""
    postprocess ouput of network, one face at a time.
    """"""
",4
"        _result['points'][:, 1] *= (_result['y2'] - _result['y1'])
        _result['points'][:, 1] += _result['y1']
        output[-1]['data'].append(_result['points'].tolist())
",4
"
    if visualization:
        check_dir(output_dir)
",4
"from __future__ import division
",4
"    type=""CV/keypoint_detection"",
    author=""paddlepaddle"",
    author_email=""paddle-dev@baidu.comi"",
    summary=
",4
"class HumanPoseEstimation(hub.Module):
",4
"            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
            int(_places[0])
",4
"
    def keypoint_detection(self,
                           images=None,
                           paths=None,
                           batch_size=1,
",4
"                           use_gpu=False,
                           output_dir='output_pose',
",4
"        API for human pose estimation and tracking.
",4
"            for image_id in range(batch_size):
                try:
                    batch_data.append(all_data[handle_id + image_id])
",4
"                    org_im_path=batch_data[i]['org_im_path'],
                    output_dir=output_dir,
                    visualization=visualization)
                res.append(out)
        return res
",4
"        program, feeded_var_names, target_vars = fluid.io.load_inference_model(
            dirname=self.default_pretrained_model_path, executor=exe)

        fluid.io.save_inference_model(
            dirname=dirname,
",4
"            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
        self.add_module_input_arg()
        args = self.parser.parse_args(argvs)
        results = self.keypoint_detection(
",4
"from __future__ import division
from __future__ import print_function
",4
"        self.layers = layers
        self.test_mode = test_mode
",4
"            depth = [3, 8, 36, 3]
        num_filters = [64, 128, 256, 512]

        conv = self.conv_bn_layer(
",4
"            input=input, num_filters=64, filter_size=7, stride=2, act='relu')
        conv = fluid.layers.pool2d(
",4
"            pool_padding=1,
",4
"            input=conv, act='relu', momentum=BN_MOMENTUM)
        conv = fluid.layers.conv2d_transpose(
            input=conv,
            num_filters=256,
            filter_size=4,
",4
"        conv = fluid.layers.batch_norm(
            input=conv, act='relu', momentum=BN_MOMENTUM)
",4
"                      num_filters,
",4
"
    def calc_loss(self, heatmap, target, target_weight):
        _, c, h, w = heatmap.shape
        x = fluid.layers.reshape(heatmap, (-1, self.k, h * w))
        y = fluid.layers.reshape(target, (-1, self.k, h * w))
",4
"
        _loss = fluid.layers.concat(_list, axis=0)
",4
"            act='relu')
        conv2 = self.conv_bn_layer(
            input=conv1, num_filters=num_filters * 4, filter_size=1, act=None)
",4
"
import cv2
import numpy as np
",4
"
    Args:
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        paths (list[str]): paths to images.
",4
"    component = list()
    if paths:
        for im_path in paths:
            each = OrderedDict()
",4
"
import cv2
import numpy as np
",4
"
__all__ = ['base64_to_cv2', 'postprocess']

",4
"
    Args:
        batch_heatmaps (numpy.ndarray): output of the network, with shape [N, C, H, W]
    """"""
    assert isinstance(batch_heatmaps, np.ndarray), \
",4
"    idx = idx.reshape((batch_size, num_joints, 1))
    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)
",4
"    preds *= pred_mask
    return preds, maxvals
",4
"    """"""
    Postprocess output of network. one image at a time.

    Args:
",4
"        res (dict): Output of postprocess. keys contains 'path', 'data', the corresponding valus are:
            path (str): the path of original image.
",4
"    res['data'] = OrderedDict()
    preds, num_joints = predict_results(out_heatmaps)
    scale_horizon = org_im_shape[1] * 1.0 / 384
    scale_vertical = org_im_shape[0] * 1.0 / 384
",4
"            cv2.circle(rendered_im, (x, y), 3, icolor, -1, 16)
            cv2.circle(rendered_im, (x, y), 6, ocolor, 1, 16)
        check_dir(output_dir)
        save_im_name = get_save_image_name(org_im, org_im_path, output_dir)
",4
"    Args:
        dir_path (str): directory path to save images.
    """"""
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)
",4
"    org_im_name = os.path.split(org_im_path)[-1]
    im_prefix = os.path.splitext(org_im_name)[0]
    # extension
",4
"    ext = '.jpg'
    # save image path
    save_im_path = os.path.join(output_dir, im_prefix + ext)
",4
"# -*- coding:utf-8 -*-
from __future__ import absolute_import
",4
"import paddlehub as hub

",4
"    def check_requirements(self):
        try:
            import shapely, pyclipper
        except:
            logger.error(
",4
"                'This module requires the shapely, pyclipper tools. The running enviroment does not meet the requirments. Please install the two packages.'
            )
            exit()
",4
"
        rect = np.array([tl, tr, br, bl], dtype=""float32"")
        return rect

    @serving
",4
"
",4
"                all_imgs.append(im)
                all_ratios.append(ratio_list)
                if visualization:
                    img = Image.fromarray(
                        cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))
",4
"                        os.makedirs(output_dir)
",4
"
    def save_inference_model(self,
                             dirname,
                             model_filename=None,
",4
"            default=False,
            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
            '--output_dir',
",4
"    res = db.detect_text(paths=image_path, visualization=True)
    db.save_inference_model('save')
    print(res)
# -*- coding:utf-8 -*-
from __future__ import absolute_import
",4
"
        # limit the max side
        if max(resize_h, resize_w) > self.max_side_len:
            if resize_h > resize_w:
",4
"        resize_h = int(resize_h * ratio)
        resize_w = int(resize_w * ratio)
",4
"            resize_w = (resize_w // 32 - 1) * 32
",4
"        img_mean = [0.485, 0.456, 0.406]
        img_std = [0.229, 0.224, 0.225]
        im = im.astype(np.float32, copy=False)
        im = im / 255
",4
"        return [im, (ratio_h, ratio_w)]


class DBPostProcess(object):
    """"""
",4
"                whose values are binarized as {0, 1}
",4
"            points, sside = self.get_mini_boxes(contour)
            if sside < self.min_size:
",4
"            if self.box_thresh > score:
",4
"            box[:, 0] = np.clip(
                np.round(box[:, 0] / width * dest_width), 0, dest_width)
            box[:, 1] = np.clip(
                np.round(box[:, 1] / height * dest_height), 0, dest_height)
            boxes[index, :, :] = box.astype(np.int16)
",4
"    def unclip(self, box, unclip_ratio=2.0):
        poly = Polygon(box)
        distance = poly.area * unclip_ratio / poly.length
",4
"        offset.AddPath(box, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)
        expanded = np.array(offset.Execute(distance))
        return expanded
",4
"        points = sorted(list(cv2.boxPoints(bounding_box)), key=lambda x: x[0])

",4
"        index_1, index_2, index_3, index_4 = 0, 1, 2, 3
        if points[1][1] > points[0][1]:
            index_1 = 0
",4
"        h, w = bitmap.shape[:2]
",4
"            height, width = pred.shape[-2:]
            tmp_boxes, tmp_scores = self.boxes_from_bitmap(
",4
"                boxes[:, :, 1] = boxes[:, :, 1] / ratio_h

            boxes_batch.append(boxes)
",4
"        draw.line([(box[0][0], box[0][1]), (box[1][0], box[1][1])], fill='red')
",4
"        draw.line([(box[1][0], box[1][1]), (box[2][0], box[2][1])], fill='red')
        draw.line([(box[2][0], box[2][1]), (box[3][0], box[3][1])], fill='red')
        draw.line([(box[3][0], box[3][1]), (box[0][0], box[0][1])], fill='red')
        draw.line([(box[0][0] - 1, box[0][1] + 1),
                   (box[1][0] - 1, box[1][1] + 1)],
",4
"from __future__ import absolute_import
from __future__ import division
",4
"
from chinese_ocr_db_crnn.character import CharacterOps
from chinese_ocr_db_crnn.utils import draw_ocr, get_image_ext, sorted_boxes


",4
"            'character_type': 'ch',
            'character_dict_path': self.character_dict_path,
            'loss_type': 'ctc'
",4
"        predictor config setting
        """"""
        model_file_path = os.path.join(self.pretrained_model_path, 'model')
        params_file_path = os.path.join(self.pretrained_model_path, 'params')
",4
"
    def get_rotate_crop_image(self, img, points):
        img_height, img_width = img.shape[0:2]
        left = int(np.min(points[:, 0]))
",4
"            borderMode=cv2.BORDER_REPLICATE)
        dst_img_height, dst_img_width = dst_img.shape[0:2]
",4
"        else:
            resized_w = int(math.ceil(imgH * ratio))
",4
"            output_dir (str): The directory to store output images.
            visualization (bool): Whether to save image or not.
",4
"                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
            except:
                raise RuntimeError(
",4
"                rec_res_final = []
                for index, res in enumerate(rec_results):
",4
"                    text, score = res
                    if score >= text_thresh:
",4
"                          original_image,
                          detection_boxes,
                          rec_results,
",4
"        rec_res = []
        predict_time = 0
        for beg_img_no in range(0, img_num, batch_num):
",4
"            predict_lod = self.output_tensors[1].lod()[0]

",4
"                end = rec_idx_lod[rno + 1]
                rec_idx_tmp = rec_idx_batch[beg:end, 0]
                preds_text = self.char_ops.decode(rec_idx_tmp)
                beg = predict_lod[rno]
",4
"                ind = np.argmax(probs, axis=1)
",4
"                             model_filename=None,
                             params_filename=None,
                             combined=True):
        detector_dir = os.path.join(dirname, 'text_detector')
",4
"                             dirname,
",4
"                             model_filename=None,
                             params_filename=None,
",4
"
        args = self.parser.parse_args(argvs)
        results = self.recognize_text(
            paths=[args.input_path],
            use_gpu=args.use_gpu,
",4
"            default=False,
            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
            '--output_dir',
",4
"        """"""
        self.arg_input_group.add_argument(
            '--input_path', type=str, default=None, help=""diretory to image"")


",4
"if __name__ == '__main__':
    ocr = ChineseOCRDBCRNN()
",4
"    image_path = [
        '../doc/imgs/11.jpg', '../doc/imgs/12.jpg', '../test_image.jpg'
    ]
",4
"from PIL import Image, ImageDraw, ImageFont
import cv2
import numpy as np


",4
"                  fill='red')
        draw.line([(box[1][0] - 1, box[1][1] + 1),
",4
"        draw.line([(box[2][0] - 1, box[2][1] + 1),
                   (box[3][0] - 1, box[3][1] + 1)],
                  fill='red')
",4
"
",4
"        count = 0
        for idx, txt in enumerate(txts):
            if scores[idx] < drop_score:
",4
"                continue
            font = ImageFont.truetype(font_file, font_size, encoding=""utf-8"")
            new_txt = str(count) + ':  ' + txt + '    ' + str(scores[count])
            draw_txt.text((20, gap * (count + 1)),
                          new_txt,
",4
"                          txt_color,
                          font=font)
            count += 1
        img = np.concatenate([np.array(img), np.array(blank_img)], axis=1)
    return img
",4
"def get_image_ext(image):
    if image.shape[2] == 4:
",4
"    """"""
    num_boxes = dt_boxes.shape[0]
    sorted_boxes = sorted(dt_boxes, key=lambda x: x[0][1])
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

",4
"import numpy as np
import string

",4
"
class CharacterOps(object):
",4
"
    def __init__(self, config):
",4
"        self.character_type = config['character_type']
        self.loss_type = config['loss_type']
        if self.character_type == ""en"":
            self.character_str = ""0123456789abcdefghijklmnopqrstuvwxyz""
",4
"        elif self.character_type == ""en_sensitive"":
            # same with ASTER setting (use 94 char).
            self.character_str = string.printable[:-6]
            dict_character = list(self.character_str)
        else:
",4
"        return text

    def decode(self, text_index, is_remove_duplicate=False):
        """""" convert text-index into text-label. """"""
",4
"            beg_idx = self.get_beg_end_flag_idx(""beg"")
",4
"    def get_beg_end_flag_idx(self, beg_or_end):
        if self.loss_type == ""attention"":
            if beg_or_end == ""beg"":
                idx = np.array(self.dict[self.beg_str])
            elif beg_or_end == ""end"":
",4
"            return idx
        else:
            err = ""error in get_beg_end_flag_idx when using the loss %s""\
",4
"                % (self.loss_type)
            assert False, err
",4
"                          labels,
                          labels_lod,
                          is_remove_duplicate=False):
    acc_num = 0
    img_num = 0
",4
"    img_num = preds.shape[0]
",4
"
def convert_rec_label_to_lod(ori_labels):
",4
"        convert_ids = convert_ids + list(ori_labels[ino])
    convert_ids = np.array(convert_ids)
",4
"            conv_name1 = 'conv' + name + '_x1'
            conv_name2 = 'conv' + name + '_x2'
",4
"    def fix_layer_warp_name(self, stage_num, count, i):
",4
"        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
            if i == 0:
                conv_name = name + ""a""
",4
"import argparse
import os
from functools import partial
",4
"
",4
"        if use_gpu:
",4
"             context_prog (Program): the program to execute transfer learning.
        """"""
        context_prog = fluid.Program()
        startup_program = fluid.Program()
        with fluid.program_guard(context_prog, startup_program):
",4
"                    dcn_v2_stages=[5],
                    depth=50,
                    variant='d',
",4
"                # yolo_head
                yolo_head = YOLOv3Head(num_classes=80)
                # head_features
                head_features, body_features = yolo_head._get_outputs(
                    body_feats, is_train=trainable)
",4
"                         batch_size=1,
",4
"                data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
                    left (float): The X coordinate of the upper left corner of the bounding box;
                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
",4
"                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
                    confidence (float): The confidence of detection result.
",4
"                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"
        paths = paths if paths else list()
",4
"            feed_data = np.array(feed_data)
            image_tensor = PaddleTensor(np.array(list(feed_data[:, 0])))
            im_size_tensor = PaddleTensor(np.array(list(feed_data[:, 1])))
            if use_gpu:
",4
"                data_out = self.gpu_predictor.run(
                    [image_tensor, im_size_tensor])
            else:
",4
"                paths=paths,
                images=images,
",4
"        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"            model_filename=model_filename,
",4
"
    @runnable
    def run_cmd(self, argvs):
        """"""
        Run as a command.
",4
"        """"""
        self.parser = argparse.ArgumentParser(
",4
"            title=""Input options"", description=""Input data. Required"")
",4
"from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
",4
"    ""use_zero_init_conv"": False,
",4
"    ""conv_init_std"": 0.01,
",4
"    ""use_affine"": False,
    ""bn_momentum"": 0.9,
    ""bn_epsilon"": 1.0000001e-5,
",4
"                                 initializer = fluid.initializer.Normal(loc = 0.0,
                                 scale = nonlocal_params[""conv_init_std""])), \
                             bias_attr = ParamAttr(name = prefix + '_phi' + ""_b"", \
                                 initializer = fluid.initializer.Constant(value = 0.)) \
",4
"    g = fluid.layers.conv2d(input = max_pool, num_filters = dim_inner, \
                 filter_size = [1, 1], stride = [1, 1], \
",4
"                     initializer = fluid.initializer.Constant(value = 0.)) if (nonlocal_params[""no_bias""] == 0) else False, \
                 name = prefix + '_g')
    g_shape = g.shape
    # we have to use explicit batch size (to support arbitrary spacetime size)
",4
"    # e.g. (8, 1024, 4, 14, 14) => (8, 1024, 784)
    theta = fluid.layers.reshape(theta, shape=(0, 0, -1))
    theta = fluid.layers.transpose(theta, [0, 2, 1])
",4
"        p = fluid.layers.softmax(
            theta_phi_sc, name=prefix + '_affinity' + '_prob')
    else:
",4
"                                        else fluid.initializer.Normal(loc = 0.0,
",4
"                                           if (nonlocal_params[""no_bias""] == 0) else False, \
                                  name = prefix + '_out')
",4
"        bn_name = prefix + ""_bn""
        blob_out = fluid.layers.batch_norm(blob_out, \
                      # is_test = test_mode, \
",4
"                      momentum = nonlocal_params[""bn_momentum""], \
",4
"                       shape=[blob_out_shape[1]], dtype = blob_out.dtype, \
                       attr=ParamAttr(name=prefix + '_affine' + '_s'), \
",4
"                      shape=[blob_out_shape[1]], dtype = blob_out.dtype, \
                      attr=ParamAttr(name=prefix + '_affine' + '_b'), \
                      default_initializer = fluid.initializer.Constant(value = 0.))
        blob_out = fluid.layers.affine_channel(blob_out, scale = affine_scale, \
",4
"from __future__ import absolute_import
from __future__ import print_function
from __future__ import division

import os
",4
"
def reader(paths=[], images=None):
    """"""
    data generator

",4
"    if paths:
        assert type(paths) is list, ""type(paths) is not list.""
        for img_path in paths:
            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"        im = cv2.resize(
",4
"        mean = np.array(mean)[np.newaxis, np.newaxis, :]
",4
"        im /= std

        # permute
        im = np.swapaxes(im, 1, 2)
",4
"        im = np.swapaxes(im, 1, 0)

",4
"class MultiClassNMS(object):
    # __op__ = fluid.layers.multiclass_nms
",4
"    def __init__(self, background_label, keep_top_k, nms_threshold, nms_top_k,
                 normalized, score_threshold):
        super(MultiClassNMS, self).__init__()
        self.background_label = background_label
        self.keep_top_k = keep_top_k
",4
"class YOLOv3Head(object):
    """"""Head block for YOLOv3 network

    Args:
        norm_decay (float): weight decay for normalization layer weights
",4
"    """"""

    def __init__(self,
                 norm_decay=0.,
                 num_classes=80,
",4
"        assert channel % 2 == 0, \
            ""channel {} cannot be divided by 2 in detection block {}"" \
            .format(channel, name)

",4
"        conv = input
        for j in range(2):
            conv = self._conv_bn(
",4
"                filter_size=3,
                stride=1,
                padding=1,
                is_test=is_test,
",4
"            is_test=is_test,
            name='{}.2'.format(name))
",4
"        tip = self._conv_bn(
            route,
",4
"
    def _parse_anchors(self, anchors):
",4
"
        """"""
        self.anchors = []
        self.mask_anchors = []

",4
"        assert len(self.anchor_masks) > 0, ""ANCHOR_MASKS not set.""

        for anchor in anchors:
",4
"        Args:
",4
"        route = None
        for i, block in enumerate(blocks):
            if i > 0:  # perform concat in first 2 detection_block
",4
"                    filter_size=1,
                    stride=1,
                    padding=0,
                    is_test=(not is_train),
",4
"
    def get_prediction(self, outputs, im_size):
",4
"                name=self.prefix_name + ""yolo_box"" + str(i))
            boxes.append(box)
            scores.append(fluid.layers.transpose(score, perm=[0, 2, 1]))
",4
"        yolo_boxes = fluid.layers.concat(boxes, axis=1)
        yolo_scores = fluid.layers.concat(scores, axis=2)
        pred = fluid.layers.multiclass_nms(
            bboxes=yolo_boxes,
            scores=yolo_scores,
",4
"        return pred
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"from __future__ import print_function

import math
from collections import OrderedDict
from numbers import Integral
",4
"    """"""
    Residual Network, see https://arxiv.org/abs/1512.03385
    Args:
        depth (int): ResNet depth, should be 34, 50.
        freeze_at (int): freeze the backbone at which stage
",4
"            feature_maps = [feature_maps]

        assert depth in [34, 50], \
",4
"        self.na = NameAdapter(self)
        self.prefix_name = weight_prefix_name

",4
"            152: 8,
            200: 12,
",4
"    def _conv_offset(self,
                     input,
                     filter_size,
                     stride,
",4
"            filter_size=filter_size,
            stride=stride,
",4
"
",4
"                   act=None,
                   name=None,
                   dcn_v2=False):
        _name = self.prefix_name + name if self.prefix_name != '' else name
        if not dcn_v2:
",4
"            offset_channel = filter_size**2 * 2
            mask_channel = filter_size**2
",4
"            offset, mask = fluid.layers.split(
                input=offset_mask,
",4
"                deformable_groups=1,
                im2col_step=1,
                param_attr=ParamAttr(name=_name + ""_weights""),
                bias_attr=False,
",4
"                attr=pattr,
",4
"                attr=battr,
",4
"                input = fluid.layers.pool2d(
                    input=input,
                    pool_size=2,
                    pool_stride=2,
                    pool_padding=0,
",4
"            x=short, y=residual, act='relu', name=name + "".add.output.5"")

",4
"                   dcn_v2=False):
        assert dcn_v2 is False, ""Not implemented yet.""
        conv0 = self._conv_norm(
            input=input,
            num_filters=num_filters,
",4
"        stages, block_func = self.depth_cfg[self.depth]
        count = stages[stage_num - 2]

        ch_out = self.stage_filters[stage_num - 2]
",4
"            conv = block_func(
                input=conv,
                num_filters=ch_out,
                stride=2 if i == 0 and stage_num != 2 else 1,
",4
"                act='relu',
                name=_name)

        output = fluid.layers.pool2d(
",4
"            input=input,
            pool_size=3,
            pool_stride=2,
            pool_padding=1,
",4
"            out = fluid.layers.fc(
                input=pool,
                size=self.class_dim,
                param_attr=fluid.param_attr.ParamAttr(
",4
"        return OrderedDict([('res{}_sum'.format(self.feature_maps[idx]), feat)
                            for idx, feat in enumerate(res_endpoints)])

",4
"
",4
"__all__ = ['base64_to_cv2', 'load_label_info', 'postprocess']
",4
"    elif os.path.isfile(dir_path):
",4
"        os.remove(dir_path)
        os.makedirs(dir_path)
",4
"def draw_bounding_box_on_image(image_path, data_list, save_dir):
    image = Image.open(image_path)
",4
"        visualization (bool): Whether to save image or not.
        score_thresh (float): the low limit of bounding box.
        label_names (list[str]): label names.
        handle_id (int): The number of images that have been handled.

",4
"
    output = list()
    for index in range(len(lod) - 1):
",4
"        output_i = {'data': []}
        if index < unhandled_paths_num:
",4
"            dt['confidence'] = float(confidence)
            dt['left'], dt['top'], dt['right'], dt['bottom'] = clip_bbox(
                bbox, org_img_width, org_img_height)
",4
"# coding=utf-8
from __future__ import absolute_import
",4
"import yaml
",4
"
from ssd_vgg16_512_coco2017.vgg import VGG
",4
"    name=""ssd_vgg16_512_coco2017"",
    version=""1.0.0"",
    type=""cv/object_detection"",
    summary=""SSD with backbone VGG16, trained with dataset COCO."",
    author=""paddlepaddle"",
",4
"        if not self.model_config:
            with open(os.path.join(self.directory, 'config.yml')) as fp:
",4
"             inputs(dict): the input variables.
             outputs(dict): the output variables.
             context_prog (Program): the program to execute transfer learning.
        """"""
",4
"                # backbone
                backbone = VGG(
                    depth=16,
                    with_extra_blocks=True,
",4
"                im_size = fluid.layers.data(
                    name='im_size', shape=[2], dtype='int32')
                # var_prefix
                var_prefix = '@HUB_{}@'.format(self.name)
                # names of inputs
",4
"                        **self.output_decoder_config)
                    outputs = {'bbox_out': [var_prefix + pred.name]}
                else:
                    outputs = {
",4
"                        'body_features':
                        [var_prefix + var.name for var in body_feats]
                    }
",4
"
                # add_vars_prefix
                add_vars_prefix(context_prog, var_prefix)
",4
"                    def _if_exist(var):
                        return os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
                                         var.name))

",4
"                        predicate=_if_exist)
                else:
                    exe.run(startup_program)

                return inputs, outputs, context_prog
",4
"    def object_detection(self,
",4
"        Args:
            paths (list[str]): The paths of images.
            images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
            batch_size (int): batch size.
",4
"                    confidence (float): The confidence of detection result.
                save_path (str, optional): The path to save output images.
        """"""
        if use_gpu:
",4
"
        paths = paths if paths else list()
",4
"                output_dir=output_dir,
                handle_id=iter_id * batch_size,
                visualization=visualization)
            res.extend(output)
        return res
",4
"        """"""
        Run as a service.
        """"""
        images_decode = [base64_to_cv2(image) for image in images]
        results = self.object_detection(images=images_decode, **kwargs)
",4
"    def run_cmd(self, argvs):
        """"""
",4
"            prog='hub run {}'.format(self.name),
",4
"            title=""Config options"",
",4
"        Add the command config options.
        """"""
        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
",4
"

class VGG(object):
",4
"    """"""
    VGG, see https://arxiv.org/abs/1409.1556

",4
"        class_dim (int): number of class while classification
",4
"        self.with_extra_blocks = with_extra_blocks
        self.normalizations = normalizations
        self.extra_block_filters = extra_block_filters
        self.class_dim = class_dim

",4
"            fc_name = [""fc6"", ""fc7"", ""fc8""]
            fc1 = fluid.layers.fc(
                input=conv,
                size=fc_dim,
",4
"                act='relu',
",4
"            fc7 = self._conv_layer(fc6, 1024, 1, 1, 0, name=""fc7"")
",4
"                num_filters=num_filter,
                filter_size=3,
                stride=1,
                padding=1,
",4
"                act='relu',
",4
"                     num_filters1,
                     num_filters2,
",4
"        conv_1 = self._conv_layer(
            input=input,
",4
"            act='relu',
            padding=0,
            name=name + ""1"")

        # 3x3 conv
",4
"        conv_2 = self._conv_layer(
",4
"            input=conv_1,
            num_filters=int(num_filters2),
            filter_size=filter_size,
            stride=stride_size,
",4
"            stride=stride,
            padding=padding,
            dilation=dilation,
            act=act,
            use_cudnn=use_cudnn,
",4
"            param_attr=ParamAttr(name=name + ""_weights""),
            bias_attr=ParamAttr(
                name=name + ""_biases"") if self.with_extra_blocks else False,
            name=name + '.conv2d.output.1')
",4
"        l2_norm = fluid.layers.l2_normalize(
            input, axis=1)  # l2 norm along channel
        shape = [1] if channel_shared else [input.shape[1]]
",4
"from __future__ import absolute_import
from __future__ import print_function
from __future__ import division

import os
",4
"class DecodeImage(object):
    def __init__(self, to_rgb=True, with_mixup=False):
        """""" Transform the image data to numpy format.
",4
"            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)

        return im

",4
"            max_size (int): the max size of image
",4
"                fy=im_scale_y,
                interpolation=self.interp)
        else:
            if self.max_size != 0:
                raise TypeError(
",4
"class Permute(object):
    def __init__(self, to_bgr=True, channel_first=True):
        """"""
",4
"    data generator

    Args:
        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]
",4
"        preprocessed_img = permute_image(preprocessed_img)
        preprocessed_img = normalize_image(preprocessed_img)
        yield [preprocessed_img]
# coding=utf-8
",4
"from PIL import Image, ImageDraw

__all__ = ['base64_to_cv2', 'load_label_info', 'postprocess']

",4
"        draw.line([(left, top), (left, bottom), (right, bottom), (right, top),
",4
"

def load_label_info(file_path):
    with open(file_path, 'r') as fr:
        text = fr.readlines()
",4
"        label_names = []
        for info in text:
            label_names.append(info.strip())
        return label_names
",4
"
",4
"            org_img = org_img.astype(np.uint8)
            org_img = Image.fromarray(org_img[:, :, ::-1])
            if visualization:
                org_img_path = get_save_image_name(
",4
"                    org_img, output_dir, 'image_numpy_{}'.format(
",4
"        for row in result_i:
            if len(row) != 6:
",4
"from functools import partial

import numpy as np
import paddle.fluid as fluid
",4
"
from yolov3_darknet53_coco2017.darknet import DarkNet
",4
"
    def _set_config(self):
        """"""
        predictor config setting.
        """"""
",4
"
    def context(self, trainable=True, pretrained=True, get_prediction=False):
        """"""
        Distill the Head Features, so as to perform transfer learning.

",4
"        with fluid.program_guard(context_prog, startup_program):
",4
"                body_feats = backbone(image)
                # im_size
                im_size = fluid.layers.data(
",4
"                var_prefix = '@HUB_{}@'.format(self.name)
                # name of inputs
",4
"                    'im_size': var_prefix + im_size.name
                }
                # name of outputs
",4
"        """"""API of Object Detection.

        Args:
            paths (list[str]): The paths of images.
            images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
",4
"            score_thresh (float): threshold for object detecion.

        Returns:
            res (list[dict]): The result of coco2017 detecion. keys include 'data', 'save_path', the corresponding value is:
                data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
",4
"                    confidence (float): The confidence of detection result.
                save_path (str, optional): The path to save output images.
        """"""
        if use_gpu:
",4
"                    [image_tensor, im_size_tensor])

            output = postprocess(
",4
"            params_filename=params_filename)

    @serving
",4
"        """"""
        self.parser = argparse.ArgumentParser(
            description=""Run the {} module."".format(self.name),
            prog='hub run {}'.format(self.name),
",4
"        args = self.parser.parse_args(argvs)
        results = self.face_detection(
            paths=[args.input_path],
            batch_size=args.batch_size,
",4
"            use_gpu=args.use_gpu,
            output_dir=args.output_dir,
            visualization=args.visualization,
            score_thresh=args.score_thresh)
",4
"        return results

    def add_module_config_arg(self):
        """"""
        Add the command config options.
",4
"            '--output_dir',
            type=str,
",4
"            help=""batch size."")
        self.arg_input_group.add_argument(
",4
"        res (list): preprocessed image and the size of original image.
    """"""
    img_list = []
    if paths:
        assert type(paths) is list, ""type(paths) is not list.""
",4
"        std = [0.229, 0.224, 0.225]
",4
"        self.normalized = normalized
",4
"
class YOLOv3Head(object):
    """"""Head block for YOLOv3 network

",4
"
    def _conv_bn(self,
",4
"                 input,
                 ch_out,
",4
"                 act='leaky',
",4
"            stride=stride,
            padding=padding,
            act=None,
            param_attr=ParamAttr(name=name + "".conv.weights""),
",4
"            conv,
            channel,
            filter_size=1,
            stride=1,
            padding=0,
",4
"            padding=1,
            is_test=is_test,
            name='{}.tip'.format(name))
        return route, tip

",4
"    def _parse_anchors(self, anchors):
",4
"        Args:
            outputs (list): list of Variables, return from _get_outputs
            im_size (Variable): Variable of size([h, w]) of each image

        Returns:
",4
"                name=self.prefix_name + ""yolo_box"" + str(i))
            boxes.append(box)
",4
"            scores.append(fluid.layers.transpose(score, perm=[0, 2, 1]))

            downsample //= 2

",4
"    return data


",4
"

def get_save_image_name(img, output_dir, image_path):
    """"""Get save image name from source image path.
    """"""
",4
"
    if ext == '':
        if img.format == 'PNG':
            ext = '.png'
        elif img.format == 'JPEG':
",4
"                ext = '.png'
",4
"        # draw label
        if image.mode == 'RGB':
",4
"            draw.text(xy=(left, top - 15), text=text, fill=(0, 0, 0))

",4
"    ymax = max(min(bbox[3], img_height), 0.)
    return float(xmin), float(ymin), float(xmax), float(ymax)

",4
"        for info in text:
            label_names.append(info.strip())
        return label_names


",4
"                output_dir,
                handle_id,
",4
"        result_i = results[lod[index]:lod[index + 1]]
",4
"            bbox = row[2:]
",4
"            output_i['save_path'] = draw_bounding_box_on_image(
                org_img_path, output_i['data'], output_dir)
",4
"    Args:
        depth (int): network depth, currently only darknet 53 is supported
        norm_type (str): normalization type, 'bn' and 'sync_bn' are supported
        norm_decay (float): weight decay for normalization layer weights
        get_prediction (bool): whether to get prediction
",4
"
",4
"            act=None,
            param_attr=bn_param_attr,
            bias_attr=bn_bias_attr,
            moving_mean_name=bn_name + '.mean',
",4
"        if act == 'leaky':
            out = fluid.layers.leaky_relu(x=out, alpha=0.1)

",4
"            stride=1,
            padding=0,
",4
"        else:
            return blocks
# coding=utf-8


",4
"class NameAdapter(object):
    """"""Fix the backbones variable names for pretrained weight""""""

",4
"        if name == ""conv1"":
            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]
        # the naming rule is same as pretrained weight
",4
"    def fix_bottleneck_name(self, name):
        if self.model_type == 'SEResNeXt':
            conv_name1 = 'conv' + name + '_x1'
            conv_name2 = 'conv' + name + '_x2'
",4
"            shortcut_name = name + ""_branch1""
",4
"        return conv_name1, conv_name2, conv_name3, shortcut_name

    def fix_layer_warp_name(self, stage_num, count, i):
",4
"
@moduleinfo(
    name=""faster_rcnn_resnet50_fpn_coco2017"",
    version=""1.0.0"",
    type=""cv/object_detection"",
",4
"                    name='im_shape', shape=[3], dtype='float32', lod_level=0)
                body_feat_names = list(body_feats.keys())
                body_feats, spatial_scale = fpn.get_output(body_feats)
                # rpn_head: RPNHead
",4
"                if phase == 'train':
                    gt_bbox = fluid.layers.data(
                        name='gt_bbox', shape=[4], dtype='float32', lod_level=1)
                    is_crowd = fluid.layers.data(
",4
"                        name='is_crowd', shape=[1], dtype='int32', lod_level=1)
                    gt_class = fluid.layers.data(
                        name='gt_class', shape=[1], dtype='int32', lod_level=1)
",4
"                    bbox_assigner = self.bbox_assigner(num_classes)
                    outs = fluid.layers.generate_proposal_labels(
                        rpn_rois=rois,
                        gt_classes=gt_class,
                        is_crowd=is_crowd,
",4
"                        gt_boxes=gt_bbox,
",4
"                        im_info=im_info,
",4
"                roi_extractor = self.roi_extractor()
                roi_feat = roi_extractor(
                    head_inputs=body_feats,
                    rois=rois,
                    spatial_scale=spatial_scale)
",4
"                # head_feat
",4
"
                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
",4
"                            if 'bbox_pred' in var.name or 'cls_score' in var.name:
                                return False
                        return os.path.exists(
",4
"                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
",4
"                post_nms_top_n=2000,
",4
"                nms_thresh=0.7,
                post_nms_top_n=1000,
                pre_nms_top_n=1000),
            anchor_start_size=32,
            num_chan=256,
",4
"            max_level=5,
            min_level=2,
            box_resolution=7,
",4
"    def bbox_head(self, num_classes):
        return BBoxHead(
",4
"            dirname=self.default_pretrained_model_path, executor=exe)
",4
"        fluid.io.save_inference_model(
            dirname=dirname,
",4
"                         images=None,
",4
"                         score_thresh=0.5,
                         visualization=True):
        """"""API of Object Detection.

        Args:
",4
"                    left (float): The X coordinate of the upper left corner of the bounding box;
                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
",4
"                    confidence (float): The confidence of detection result.
",4
"        """"""
        if use_gpu:
            try:
                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
                int(_places[0])
",4
"            except:
                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )
",4
"
        paths = paths if paths else list()
",4
"            output = postprocess(
                paths=paths,
                images=images,
                data_out=data_out,
",4
"
        return res

    def add_module_config_arg(self):
",4
"        """"""
        Add the command config options
        """"""
        self.arg_config_group.add_argument(
",4
"        self.arg_input_group.add_argument(
",4
"            '--input_file',
            type=str,
",4
"            default=None,
",4
"            usage='%(prog)s',
",4
"        self.bg_thresh_hi = bg_thresh_hi
        self.bg_thresh_lo = bg_thresh_lo
        self.bbox_reg_weights = bbox_reg_weights
        self.class_nums = class_nums
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"# limitations under the License.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
",4
"             norm_type='affine_channel',
             norm_groups=32,
             dilation=1,
             lr_scale=1,
",4
"             freeze_norm=False,
             act=None,
             norm_name=None,
             initializer=None,
",4
"    norm_lr = 0. if freeze_norm else 1.
    pattr = ParamAttr(
        name=norm_name + '_scale',
        learning_rate=norm_lr * lr_scale,
",4
"        global_stats = True if freeze_norm else False
        out = fluid.layers.batch_norm(
            input=conv,
            act=act,
            name=norm_name + '.output.1',
",4
"    if freeze_norm:
        scale.stop_gradient = True
",4
"    def __init__(self,
                 num_chan=256,
                 min_level=2,
                 max_level=6,
",4
"        self.max_level = max_level
        self.spatial_scale = spatial_scale
",4
"        self.has_extra_convs = has_extra_convs
        self.norm_type = norm_type

    def _add_topdown_lateral(self, body_name, body_input, upper_output):
",4
"                1,
                param_attr=ParamAttr(
                    name=lateral_name + ""_w"", initializer=Xavier(fan_out=fan)),
",4
"        Args:
            body_dict(OrderedDict): Dictionary of variables and each element is the
                output of backbone.

",4
"        fpn_inner_name = 'fpn_inner_' + body_name_list[0]
        body_input = body_dict[body_name_list[0]]
        fan = body_input.shape[1]
",4
"                1,
                initializer=initializer,
                norm_type=self.norm_type,
                freeze_norm=self.freeze_norm,
                name=fpn_inner_name,
",4
"        fpn_name_list = []
        for i in range(num_backbone_stages):
            fpn_name = 'fpn_' + body_name_list[i]
            fan = self.fpn_inner_output[i].shape[1] * 3 * 3
            if self.norm_type:
",4
"                fpn_name = 'fpn_' + str(i)
                if i > highest_backbone_level + 1:
                    fpn_blob_in = fluid.layers.relu(fpn_blob)
                fan = fpn_blob_in.shape[1] * 3 * 3
                fpn_blob = fluid.layers.conv2d(
",4
"                        name=fpn_name + ""_b"",
                        learning_rate=2.,
                        regularizer=L2Decay(0.)),
                    name=fpn_name)
                fpn_dict[fpn_name] = fpn_blob
",4
"from __future__ import print_function
from __future__ import unicode_literals

",4
"nonlocal_params = {
    ""use_zero_init_conv"": False,
    ""conv_init_std"": 0.01,
    ""no_bias"": True,
    ""use_maxpool"": False,
",4
"                                 initializer = fluid.initializer.Constant(value = 0.)) \
                                      if (nonlocal_params[""no_bias""] == 0) else False, \
",4
"    theta_phi = fluid.layers.matmul(theta, phi, name=prefix + '_affinity')
    g = fluid.layers.reshape(g, [0, 0, -1])

",4
"    if nonlocal_params[""use_softmax""]:
        if nonlocal_params[""use_scale""]:
            theta_phi_sc = fluid.layers.scale(theta_phi, scale=dim_inner**-.5)
",4
"            theta_phi_sc = theta_phi
",4
"    # e.g. g(8, 1024, 784_2) * p(8, 784_1, 784_2) => (8, 1024, 784_1)
",4
"    p = fluid.layers.transpose(p, [0, 2, 1])
",4
"                                          initializer = fluid.initializer.Constant(value = 0.)) \
                                           if (nonlocal_params[""no_bias""] == 0) else False, \
                                  name = prefix + '_out')
",4
"        blob_out = fluid.layers.batch_norm(blob_out, \
                      # is_test = test_mode, \
                      momentum = nonlocal_params[""bn_momentum""], \
                      epsilon = nonlocal_params[""bn_epsilon""], \
                      name = bn_name, \
",4
"                      bias_attr = ParamAttr(name = bn_name + ""_b"", \
                      regularizer = fluid.regularizer.L2Decay(nonlocal_params[""weight_decay_bn""])), \
                      moving_mean_name = bn_name + ""_rm"", \
",4
"                      attr=ParamAttr(name=prefix + '_affine' + '_b'), \
                      default_initializer = fluid.initializer.Constant(value = 0.))
        blob_out = fluid.layers.affine_channel(blob_out, scale = affine_scale, \
                      bias = affine_bias, name = prefix + '_affine')   # add affine
",4
"
    return blob_out


",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import print_function
from __future__ import division
",4
"def test_reader(paths=None, images=None):
    """"""
",4
"    img_list = list()
    if paths:
        for img_path in paths:
",4
"        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        mean = np.array(mean)[np.newaxis, np.newaxis, :]
        std = np.array(std)[np.newaxis, np.newaxis, :]
        im = im / 255.0
",4
"        im -= mean
        im /= std

        target_size = 800
        max_size = 1333
",4
"        # im_shape holds the original shape of image.
        im_shape = np.array([shape[0], shape[1], 1.0]).astype('float32')
        im_size_min = np.min(shape[0:2])
",4
"        if np.round(im_scale * im_size_max) > max_size:
            im_scale = float(max_size) / float(im_size_max)

        resize_w = np.round(im_scale * float(shape[1]))
",4
"            im,
",4
"            None,
            fx=im_scale,
            fy=im_scale,
",4
"        max_shape[1] = int(
            np.ceil(max_shape_org[1] / coarsest_stride) * coarsest_stride)
",4
"    for data in batch_data:
        im_c, im_h, im_w = data['image'].shape
",4
"        data['im_info'][
            1] = max_shape[2] if use_padded_im_info else max_shape_org[2]
        padding_info.append(data['im_info'])
        padding_shape.append(data['im_shape'])
",4
"from __future__ import print_function

from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.initializer import Normal
",4
"
class AnchorGenerator(object):
    # __op__ = fluid.layers.anchor_generator
    def __init__(self,
",4
"                 stride=[16.0, 16.0],
                 anchor_sizes=[32, 64, 128, 256, 512],
                 aspect_ratios=[0.5, 1., 2.],
                 variance=[1., 1., 1., 1.]):
        super(AnchorGenerator, self).__init__()
",4
"        self.rpn_straddle_thresh = rpn_straddle_thresh
        self.rpn_fg_fraction = rpn_fg_fraction
",4
"        self.rpn_negative_overlap = rpn_negative_overlap
        self.use_random = use_random


class GenerateProposals(object):
",4
"        self.post_nms_top_n = post_nms_top_n
        self.nms_thresh = nms_thresh
        self.min_size = min_size
        self.eta = eta
",4
"    """"""
    RPN Head

    Args:
",4
"        anchor_generator (object): `AnchorGenerator` instance
        rpn_target_assign (object): `RPNTargetAssign` instance
        train_proposal (object): `GenerateProposals` instance for training
",4
"        self.anchor_generator = anchor_generator
        self.rpn_target_assign = rpn_target_assign
        self.train_proposal = train_proposal
        self.test_proposal = test_proposal
        self.num_classes = num_classes
",4
"
    def _get_output(self, input):
        """"""
",4
"            padding=1,
            act='relu',
            name='conv_rpn',
",4
"        # Generate anchors self.anchor_generator
",4
"            num_filters=num_anchor * self.num_classes,
            filter_size=1,
",4
"                name=""rpn_cls_logits_w"", initializer=Normal(loc=0.,
                                                            scale=0.01)),
            bias_attr=ParamAttr(
                name=""rpn_cls_logits_b"",
                learning_rate=2.,
",4
"        return self.rpn_cls_score, self.rpn_bbox_pred

    def get_proposals(self, body_feats, im_info, mode='train'):
        """"""
",4
"
        if self.num_classes == 1:
            rpn_cls_prob = fluid.layers.sigmoid(
                rpn_cls_score, name='rpn_cls_prob')
",4
"                rpn_cls_score, shape=(0, 0, 0, -1, self.num_classes))
            rpn_cls_prob_tmp = fluid.layers.softmax(
                rpn_cls_score, use_cudnn=False, name='rpn_cls_prob')
            rpn_cls_prob_slice = fluid.layers.slice(
",4
"            rpn_cls_prob = fluid.layers.transpose(
",4
"            if not getattr(self, attr, None):
",4
"                shape (height, width, scale).
            gt_box(Variable): The ground-truth bounding boxes with shape [M, 4].
                M is the number of groundtruth.
",4
"            Type: dict
                rpn_cls_loss(Variable): RPN classification loss.
                rpn_bbox_loss(Variable): RPN bounding box regression loss.
",4
"                    cls_logits=rpn_cls,
                    anchor_box=anchor,
                    anchor_var=anchor_var,
",4
"            score_tgt = fluid.layers.cast(x=score_tgt, dtype='float32')
            score_tgt.stop_gradient = True
            rpn_cls_loss = fluid.layers.sigmoid_cross_entropy_with_logits(
                x=score_pred, label=score_tgt)
        else:
",4
"            score_pred, loc_pred, score_tgt, loc_tgt, bbox_weight = \
                self.rpn_target_assign(
",4
"

",4
"    Args:
",4
"                 rpn_target_assign,
                 train_proposal,
                 test_proposal,
                 anchor_start_size=32,
                 num_chan=256,
",4
"                 min_level=2,
                 max_level=6,
                 num_classes=1):
",4
"        super(FPNRPNHead, self).__init__(anchor_generator, rpn_target_assign,
                                         train_proposal, test_proposal)
        self.anchor_start_size = anchor_start_size
        self.num_chan = num_chan
        self.min_level = min_level
",4
"
        self.fpn_rpn_list = []
        self.anchors_list = []
        self.anchor_var_list = []
",4
"            rpn_cls_score(Variable): Output of one level of fpn rpn head with
                shape of [N, num_anchors, H, W].
",4
"            num_filters=self.num_chan,
",4
"            name=conv_name,
            param_attr=ParamAttr(
                name=conv_share_name + '_w',
",4
"                name=conv_share_name + '_b',
                learning_rate=2.,
",4
"                regularizer=L2Decay(0.)))

",4
"            variance=self.anchor_generator.variance)

        cls_num_filters = num_anchors * self.num_classes
        self.rpn_cls_score = fluid.layers.conv2d(
            input=conv_rpn_fpn,
",4
"                the feature maps.
",4
"                rpn_cls_prob_fpn, shape=(0, 0, 0, -1))
            rpn_cls_prob_fpn = fluid.layers.transpose(
                rpn_cls_prob_fpn, perm=[0, 3, 1, 2])
        # prop_op
",4
"            fpn_feats(dict): A dictionary represents the output feature map
                of FPN with their name.
            im_info(Variable): The information of image with shape [N, 3] with
",4
"            fpn_feat_name = fpn_feat_names[self.max_level - lvl]
            fpn_feat = fpn_feats[fpn_feat_name]
            rois_fpn, roi_probs_fpn = self._get_single_proposals(
                fpn_feat, im_info, lvl, mode)
            self.fpn_rpn_list.append((self.rpn_cls_score, self.rpn_bbox_pred))
",4
"            post_nms_top_n,
            name='collect')
        return rois_collect
",4
"        rpn_clses = []
        rpn_bboxes = []
        anchors = []
",4
"                self.fpn_rpn_list[i][0], self.fpn_rpn_list[i][1],
",4
"                self.anchors_list[i], self.anchor_var_list[i])
",4
"
        rpn_cls = fluid.layers.concat(rpn_clses, axis=1)
        rpn_bbox = fluid.layers.concat(rpn_bboxes, axis=1)
",4
"        anchors = fluid.layers.concat(anchors)
        anchor_var = fluid.layers.concat(anchor_vars)
        return rpn_cls, rpn_bbox, anchors, anchor_var
# coding=utf-8
import paddle.fluid as fluid
",4
"        max_level (int): highest level of FPN layer
",4
"        canconical_level (int): the canconical FPN feature map level
        canonical_size (int): the canconical FPN feature map size
",4
"
    def __init__(self,
",4
"                 sampling_ratio=0,
                 min_level=2,
                 max_level=5,
",4
"                 canconical_level=4,
",4
"                 canonical_size=224,
                 box_resolution=7,
                 mask_resolution=14):
        super(FPNRoIAlign, self).__init__()
",4
"        features by distributed RoIs and their corresponding feature maps.

        Returns:
            roi_feat(Variable): RoI features with shape of [M, C, R, R],
",4
"from __future__ import absolute_import
from __future__ import division
",4
"from __future__ import print_function

import math
from collections import OrderedDict
",4
"
from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
",4
"

class ResNet(object):
    """"""
    Residual Network, see https://arxiv.org/abs/1512.03385
",4
"        norm_type (str): normalization type, 'bn'/'sync_bn'/'affine_channel'
        freeze_norm (bool): freeze normalization layers
        norm_decay (float): weight decay for normalization layer weights
        variant (str): ResNet variant, supports 'a', 'b', 'c', 'd' currently
        feature_maps (list): index of stages whose feature maps are returned
",4
"    def __init__(self,
                 depth=50,
",4
"        super(ResNet, self).__init__()

        if isinstance(feature_maps, Integral):
            feature_maps = [feature_maps]

",4
"        assert depth in [34, 50], \
            ""depth {} not in [34, 50]""
        assert variant in ['a', 'b', 'c', 'd'], ""invalid ResNet variant""
        assert 0 <= freeze_at <= 4, ""freeze_at should be 0, 1, 2, 3 or 4""
",4
"        self._c1_out_chan_num = 64
        self.na = NameAdapter(self)
        self.prefix_name = weight_prefix_name

        self.nonlocal_stages = nonlocal_stages
",4
"                     stride,
                     padding,
                     act=None,
                     name=None):
",4
"            padding=padding,
            param_attr=ParamAttr(initializer=Constant(0.0), name=name + "".w_0""),
",4
"
    def _conv_norm(self,
                   input,
",4
"                num_filters=num_filters,
                filter_size=filter_size,
",4
"                offset=offset,
",4
"        bn_name = self.prefix_name + bn_name if self.prefix_name != '' else bn_name

",4
"                if is_first:
                    return self._conv_norm(input, ch_out, 1, stride, name=name)
                else:
",4
"                    pool_padding=0,
                    ceil_mode=True,
                    pool_type='avg')
                return self._conv_norm(input, ch_out, 1, 1, name=name)
            return self._conv_norm(input, ch_out, 1, stride, name=name)
",4
"                   num_filters,
                   stride,
                   is_first,
                   name,
                   dcn_v2=False):
",4
"            conv_def = [[
",4
"            name=shortcut_name)
        # Squeeze-and-Excitation
        if callable(getattr(self, '_squeeze_excitation', None)):
",4
"            num_filters=num_filters,
            filter_size=3,
            act='relu',
",4
"            stride=stride,
            name=name + ""_branch2a"")
",4
"            act=None,
",4
"            input, num_filters, stride, is_first, name=name + ""_branch1"")
        return fluid.layers.elementwise_add(x=short, y=conv1, act='relu')

    def layer_warp(self, input, stage_num):
",4
"        nonlocal_mod = 1000
        if stage_num in self.nonlocal_stages:
            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2

",4
"            if i % nonlocal_mod == nonlocal_mod - 1:
                conv = add_space_nonlocal(conv, dim_in, dim_in,
                                          nonlocal_name + '_{}'.format(i),
",4
"                act='relu',
                name=_name)

        output = fluid.layers.pool2d(
",4
"        res_endpoints = []

        res = input
        feature_maps = self.feature_maps
        severed_head = getattr(self, 'severed_head', False)
",4
"        return OrderedDict([('res{}_sum'.format(self.feature_maps[idx]), feat)
                            for idx, feat in enumerate(res_endpoints)])


class ResNetC5(ResNet):
",4
"                 freeze_at=2,
                 norm_type='affine_channel',
                 freeze_norm=True,
",4
"                 norm_decay=0.,
                 variant='b',
",4
"    if ext == '':
        if img.format == 'PNG':
            ext = '.png'
",4
"                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
",4
"
    image.save(save_name)
",4
"    with open(file_path, 'r') as fr:
        text = fr.readlines()
",4
"        label_names = []
        for info in text:
            label_names.append(info.strip())
        return label_names
",4
"    Args:
        paths (list[str]): the path of images.
        images (list(numpy.ndarray)):  list of images, shape of each is [H, W, C].
        data_out (lod_tensor): data produced by executor.run.
",4
"        unhandled_paths_num = 0

    output = []
",4
"            org_img_path = unhandled_paths[index]
            org_img = Image.open(org_img_path)
",4
"                org_img_path = get_save_image_name(
",4
"                 keep_top_k=100,
                 nms_threshold=.5,
                 normalized=False,
                 nms_eta=1.0,
",4
"            sigma=self.sigma)

",4
"
class BoxCoder(object):
    def __init__(self,
",4
"        self.code_type = code_type
        self.box_normalized = box_normalized
        self.axis = axis

",4
"
",4
"        head (object): the head module instance, e.g., `ResNetC5`, `TwoFCHead`
        box_coder (object): `BoxCoder` instance
        nms (object): `MultiClassNMS` instance
",4
"        num_classes: number of output classes
    """"""
    __inject__ = ['head', 'box_coder', 'nms', 'bbox_loss']
    __shared__ = ['num_classes']

",4
"
        Args:
",4
"                [N, num_anchors * 4, H, W].
        """"""
",4
"            outside_weight=bbox_outside_weights)
        loss_bbox = fluid.layers.reduce_mean(loss_bbox)
        return {'loss_cls': loss_cls, 'loss_bbox': loss_bbox}

    def get_prediction(self,
",4
"                       roi_feat,
",4
"                       rois,
                       im_info,
",4
"            roi_feat (Variable): RoI feature from RoIExtractor.
            rois (Variable): Output of generate_proposals in rpn head.
",4
"                number of input images, each element consists of im_height,
",4
"            im_shape (Variable): Actual shape of original image with shape
                [B, 3]. B is the number of images, each element consists of
                original_height, original_width, 1

        Returns:
",4
"        bbox_pred = fluid.layers.reshape(bbox_pred, (-1, self.num_classes, 4))
        # self.box_coder
        decoded_box = fluid.layers.box_coder(
            prior_box=boxes,
",4
"            nms_threshold=self.nms.nms_threshold,
            normalized=self.nms.normalized,
            nms_eta=self.nms.nms_eta,
",4
"            background_label=self.nms.background_label)
",4
"
",4
"            shortcut_name = name
        else:
            conv_name1 = name + ""_branch2a""
",4
"
",4
"    def fix_layer_warp_name(self, stage_num, count, i):
        name = 'res' + str(stage_num)
        if count > 10 and stage_num == 4:
            if i == 0:
                conv_name = name + ""a""
",4
"        with fluid.program_guard(context_prog, startup_program):
            with fluid.unique_name.guard():
                # image
                image = fluid.layers.data(
",4
"                    name='image', shape=[3, 608, 608], dtype='float32')
                # backbone
                backbone = ResNet(
                    norm_type='bn',
                    freeze_at=0,
",4
"                # im_size
                im_size = fluid.layers.data(
                    name='im_size', shape=[2], dtype='int32')
",4
"                exe.run(fluid.default_startup_program())

                # var_prefix
",4
"                var_prefix = '@HUB_{}@'.format(self.name)
                # name of inputs
                inputs = {
",4
"                else:
                    outputs = {
",4
"                        'head_features':
",4
"                inputs = {
                    key: context_prog.global_block().vars[value]
                    for key, value in inputs.items()
                }
",4
"                        context_prog.global_block().vars[varname]
                        for varname in value
",4
"
                    def _if_exist(var):
",4
"                        return os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
                                         var.name))

                    fluid.io.load_vars(
",4
"                         images=None,
                         batch_size=1,
                         use_gpu=False,
",4
"                    top (float): The Y coordinate of the upper left corner of the bounding box;
",4
"                    right (float): The X coordinate of the lower right corner of the bounding box;
                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
",4
"                int(_places[0])
",4
"        return res

    def save_inference_model(self,
                             dirname,
                             model_filename=None,
",4
"        Run as a service.
        """"""
        images_decode = [base64_to_cv2(image) for image in images]
",4
"            score_thresh=args.score_thresh)
        return results

    def add_module_config_arg(self):
",4
"        Add the command config options.
        """"""
        self.arg_config_group.add_argument(
",4
"            help=""The directory to save output images."")
        self.arg_config_group.add_argument(
",4
"nonlocal_params = {
    ""use_zero_init_conv"": False,
    ""conv_init_std"": 0.01,
    ""no_bias"": True,
",4
"                                bias_attr = ParamAttr(name = prefix + '_theta' + ""_b"", \
                                    initializer = fluid.initializer.Constant(value = 0.)) \
                                        if not nonlocal_params[""no_bias""] else False, \
                                name = prefix + '_theta')
    theta_shape = theta.shape
",4
"                             bias_attr = ParamAttr(name = prefix + '_phi' + ""_b"", \
                                 initializer = fluid.initializer.Constant(value = 0.)) \
                                      if (nonlocal_params[""no_bias""] == 0) else False, \
                             name = prefix + '_phi')
",4
"    theta = fluid.layers.reshape(theta, shape=(0, 0, -1))
    theta = fluid.layers.transpose(theta, [0, 2, 1])
",4
"        if nonlocal_params[""use_scale""]:
            theta_phi_sc = fluid.layers.scale(theta_phi, scale=dim_inner**-.5)
",4
"
    # reshape back
    # e.g. (8, 1024, 784) => (8, 1024, 4, 14, 14)
",4
"                      epsilon = nonlocal_params[""bn_epsilon""], \
                      name = bn_name, \
",4
"__all__ = ['reader']


",4
"def reader(paths=[], images=None):
    """"""
    data generator

",4
"    Args:
        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

    Yield:
",4
"        assert type(paths) is list, ""type(paths) is not list.""
        for img_path in paths:
            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"        im_scale_x = float(target_size) / float(im_shape[1])
",4
"        im_scale_y = float(target_size) / float(im_shape[0])
",4
"        im = cv2.resize(
            im, None, None, fx=im_scale_x, fy=im_scale_y, interpolation=2)
",4
"
        # permute
        im = np.swapaxes(im, 1, 2)
        im = np.swapaxes(im, 1, 0)

",4
"        yield [im, im_size]
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"from paddle.fluid.regularizer import L2Decay

__all__ = ['MultiClassNMS', 'YOLOv3Head']


",4
"class MultiClassNMS(object):
",4
"
    Args:
",4
"                 nms=MultiClassNMS(
                     background_label=-1,
",4
"    def _conv_bn(self,
                 input,
                 ch_out,
",4
"        out = fluid.layers.batch_norm(
            input=conv,
            act=None,
            is_test=is_test,
            param_attr=bn_param_attr,
",4
"            moving_mean_name=bn_name + '.mean',
            moving_variance_name=bn_name + '.var')

        if act == 'leaky':
            out = fluid.layers.leaky_relu(x=out, alpha=0.1)
",4
"                channel,
",4
"            filter_size=3,
            stride=1,
",4
"        for anchor in anchors:
            assert len(anchor) == 2, ""anchor {} len should be 2"".format(anchor)
            self.anchors.extend(anchor)

        anchor_num = len(anchors)
",4
"            outputs (list): Variables of each output layer
        """"""

        outputs = []
",4
"
        # get last out_layer_num blocks in reverse order
",4
"            score_threshold=self.nms.score_threshold,
            nms_top_k=self.nms.nms_top_k,
            keep_top_k=self.nms.keep_top_k,
",4
"from paddle.fluid.regularizer import L2Decay
from paddle.fluid.initializer import Constant

from .nonlocal_helper import add_space_nonlocal
",4
"    Residual Network, see https://arxiv.org/abs/1512.03385
    Args:
        depth (int): ResNet depth, should be 34, 50.
        freeze_at (int): freeze the backbone at which stage
",4
"        norm_decay (float): weight decay for normalization layer weights
",4
"        if isinstance(feature_maps, Integral):
            feature_maps = [feature_maps]

        assert depth in [34, 50], \
            ""depth {} not in [34, 50]""
",4
"        self.norm_type = norm_type
",4
"        self.stage_filters = [64, 128, 256, 512]
",4
"        self.nonlocal_mod_cfg = {
",4
"            50: 2,
            101: 5,
            152: 8,
            200: 12,
",4
"        }
",4
"        self.get_prediction = get_prediction
        self.class_dim = class_dim

",4
"    def _conv_offset(self,
                     input,
                     filter_size,
                     stride,
                     padding,
",4
"            input,
",4
"        bn_name = self.prefix_name + bn_name if self.prefix_name != '' else bn_name
",4
"                param_attr=pattr,
                bias_attr=battr,
                moving_mean_name=bn_name + '_mean',
                moving_variance_name=bn_name + '_variance',
                use_global_stats=global_stats)
",4
"                attr=pattr,
",4
"        if self.freeze_norm:
            scale.stop_gradient = True
            bias.stop_gradient = True
",4
"        return out

    def _shortcut(self, input, ch_out, stride, is_first, name):
        max_pooling_in_short_cut = self.variant == 'd'
        ch_in = input.shape[1]
",4
"                   is_first,
                   name,
",4
"            expand = 4
        elif (groups * group_width) == 256:
            expand = 1
        else:  # FIXME hard code for now, handles 32x4d, 64x4d and 32x8d
",4
"                name=_name,
                dcn_v2=(i == 1 and dcn_v2))
        short = self._shortcut(
",4
"            input,
            num_filters * expand,
            stride,
            is_first=is_first,
            name=shortcut_name)
",4
"        return fluid.layers.elementwise_add(
            x=short, y=residual, act='relu', name=name + "".add.output.5"")

    def basicblock(self,
                   input,
",4
"            name=name + ""_branch2a"")
        conv1 = self._conv_norm(
            input=conv0,
            num_filters=num_filters,
            filter_size=3,
",4
"            input, num_filters, stride, is_first, name=name + ""_branch1"")
        return fluid.layers.elementwise_add(x=short, y=conv1, act='relu')

    def layer_warp(self, input, stage_num):
        """"""
",4
"        count = stages[stage_num - 2]

        ch_out = self.stage_filters[stage_num - 2]
        is_first = False if stage_num != 2 else True
        dcn_v2 = True if stage_num in self.dcn_v2_stages else False
",4
"
",4
"    def c1_stage(self, input):
",4
"
",4
"            out = fluid.layers.softmax(out)
            return out
        return OrderedDict([('res{}_sum'.format(self.feature_maps[idx]), feat)
",4
"                            for idx, feat in enumerate(res_endpoints)])


",4
"                 freeze_norm=True,
                 norm_decay=0.,
",4
"__all__ = ['base64_to_cv2', 'load_label_info', 'postprocess']

",4
"    return data


def check_dir(dir_path):
    if not os.path.exists(dir_path):
",4
"                ext = '.png'

    return os.path.join(output_dir, ""{}"".format(name)) + ext


",4
"            text = data['label'] + "": %.2f%%"" % (100 * data['confidence'])
            textsize_width, textsize_height = draw.textsize(text=text)
            draw.rectangle(
                xy=(left, top - (textsize_height + 5),
                    left + textsize_width + 10, top),
",4
"    with open(file_path, 'r') as fr:
",4
"        label_names = []
",4
"                top (float): The Y coordinate of the upper left corner of the bounding box;
                right (float): The X coordinate of the lower right corner of the bounding box;
                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
",4
"            org_img = Image.open(org_img_path)
",4
"        for row in result_i:
            if len(row) != 6:
                continue
",4
"                bbox, org_img_width, org_img_height)
            output_i['data'].append(dt)

        output.append(output_i)
        if visualization:
",4
"# coding=utf-8
",4
"from paddlehub.module.module import moduleinfo, runnable, serving
",4
"from paddlehub.common.paddle_helper import add_vars_prefix

from ssd_vgg16_300_coco2017.vgg import VGG
",4
"from ssd_vgg16_300_coco2017.processor import load_label_info, postprocess, base64_to_cv2
",4
"            os.path.join(self.directory, ""label_file.txt""))
        self.model_config = None
",4
"            int(_places[0])
            use_gpu = True
        except:
",4
"            use_gpu = False
        if use_gpu:
            gpu_config = AnalysisConfig(self.default_pretrained_model_path)
            gpu_config.disable_glog_info()
            gpu_config.enable_use_gpu(memory_pool_init_size_mb=500, device_id=0)
",4
"            self.gpu_predictor = create_paddle_predictor(gpu_config)

        # model config setting.
        if not self.model_config:
",4
"
        Returns:
             inputs(dict): the input variables.
             outputs(dict): the output variables.
",4
"                    normalizations=[20., -1, -1, -1, -1, -1])
",4
"                        inputs=body_feats,
",4
"                        scores=confs,
                        prior_box=box,
                        prior_box_var=box_var,
",4
"                    ]
                    for out_key, out_value in outputs.items()
",4
"
                return inputs, outputs, context_prog

",4
"                    confidence (float): The confidence of detection result.
                save_path (str, optional): The path to save output images.
        """"""
",4
"        paths = paths if paths else list()
        data_reader = partial(reader, paths, images)
        batch_reader = fluid.io.batch(data_reader, batch_size=batch_size)
        res = []
",4
"                data_out=data_out,
                score_thresh=score_thresh,
                label_names=self.label_names,
                output_dir=output_dir,
                handle_id=iter_id * batch_size,
",4
"                             dirname,
",4
"        """"""
        self.arg_config_group.add_argument(
            '--use_gpu',
            type=ast.literal_eval,
            default=False,
",4
"            '--batch_size',
            type=ast.literal_eval,
",4
"# coding=utf-8
",4
"            fc1 = fluid.layers.fc(
                input=conv,
                size=fc_dim,
                act='relu',
",4
"                act='relu',
                param_attr=fluid.param_attr.ParamAttr(
                    name=fc_name[1] + ""_weights""),
                bias_attr=fluid.param_attr.ParamAttr(
                    name=fc_name[1] + ""_offset""))
",4
"                bias_attr=fluid.param_attr.ParamAttr(
                    name=fc_name[2] + ""_offset""))
            out = fluid.layers.softmax(out)
",4
"            fc7 = self._conv_layer(fc6, 1024, 1, 1, 0, name=""fc7"")
            return [layers[3], fc7]
",4
"
    def _add_extras_block(self, input):
        cfg = self.extra_block_filters
        conv = input
",4
"                padding=1,
                act='relu',
                name=name + str(i + 1))
",4
"        return conv

    def _extra_block(self,
                     input,
                     num_filters1,
",4
"            input=conv_1,
            num_filters=int(num_filters2),
",4
"
    def _pooling_block(self,
                       conv,
                       pool_size,
                       pool_stride,
",4
"            pool_type='max',
            pool_stride=pool_stride,
            pool_padding=pool_padding,
",4
"            attr=helper.param_attr,
            shape=shape,
            dtype=input.dtype,
            default_initializer=Constant(init_scale))
",4
"        out = fluid.layers.elementwise_mul(
            x=l2_norm,
            y=scale,
            axis=-1 if channel_shared else 1,
            name=""conv4_3_norm_scale"")
",4
"__all__ = ['reader']

",4
"            with_mixup (bool): whether or not to mixup image and gt_bbbox/gt_score
",4
"                multi-scale training is adopted when type is list.
",4
"        if isinstance(self.target_size, list):
            # Case for multi-scale training
            selected_size = random.choice(self.target_size)
        else:
",4
"            selected_size = self.target_size
        if float(im_size_min) == 0:
            raise ZeroDivisionError('{}: min size of image is 0'.format(self))
",4
"
            resize_w = selected_size
            resize_h = selected_size

        if self.use_cv2:
",4
"            im = cv2.resize(
                im,
                None,
                None,
                fx=im_scale_x,
",4
"                 is_scale=True,
                 is_channel_first=True):
",4
"
    def __call__(self, im):
        """"""Normalize the image.

        Operators:
",4
"            std = np.array(self.std)[:, np.newaxis, np.newaxis]
",4
"    def __call__(self, im):
        if self.channel_first:
",4
"    """"""
    data generator

    Args:
",4
"        decode_image (class object): instance of <class 'DecodeImage' object>
        resize_image (class object): instance of <class 'ResizeImage' object>
        permute_image (class object): instance of <class 'Permute' object>
        normalize_image (class object): instance of <class 'NormalizeImage' object>
",4
"
import cv2
",4
"    data = base64.b64decode(b64str.encode('utf8'))
",4
"
",4
"
def clip_bbox(bbox, img_width, img_height):
",4
"    with open(file_path, 'r') as fr:
        text = fr.readlines()
        label_names = []
        for info in text:
            label_names.append(info.strip())
",4
"    postprocess the lod_tensor produced by fluid.Executor.run

    Args:
        paths (list[str]): the path of images.
        images (list(numpy.ndarray)):  list of images, shape of each is [H, W, C].
",4
"        output_dir (str): output directory.
        handle_id (int): The number of images that have been handled.
        visualization (bool): whether to save as images.

    Returns:
",4
"                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
    """"""
",4
"            if visualization:
",4
"        org_img_width = org_img.width
        result_i = results[lod[index]:lod[index + 1]]
",4
"                continue
            category_id = int(row[0])
",4
"            bbox = row[2:]
            bbox[0] = bbox[0] * org_img_width
            bbox[1] = bbox[1] * org_img_height
",4
"            bbox[2] = bbox[2] * org_img_width
            bbox[3] = bbox[3] * org_img_height
            dt = {}
            dt['label'] = label_names[category_id]
",4
"        self.model = model

    @property
    def model_type(self):
",4
"        return getattr(self.model, '_model_type', '')

",4
"        # the naming rule is same as pretrained weight
        if self.model_type == 'SEResNeXt':
            bn_name = name + ""_bn""
        return bn_name
",4
"
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
",4
"from retinanet_resnet50_fpn_coco2017.retina_head import AnchorGenerator, RetinaTargetAssign, RetinaOutputDecoder, RetinaHead
",4
"
",4
"
        try:
            _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"        Args:
",4
"                name='im_info', shape=[3], dtype='float32', lod_level=0)
            # backbone
",4
"                feature_maps=[3, 4, 5])
            body_feats = backbone(image)
            # retina_head
            retina_head = RetinaHead(
",4
"                target_assign=RetinaTargetAssign(
                    positive_overlap=0.5, negative_overlap=0.4),
                output_decoder=RetinaOutputDecoder(
                    score_thresh=0.05,
",4
"            # fpn
            fpn = FPN(
                max_level=7,
                min_level=3,
                num_chan=256,
",4
"            body_feats, spatial_scale = fpn.get_output(body_feats)
            # inputs, outputs, context_prog
            inputs = {
",4
"            }
            if get_prediction:
",4
"
            # add_vars_prefix
            add_vars_prefix(context_prog, var_prefix)
",4
"                    self.default_pretrained_model_path,
",4
"        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
",4
"            res (list[dict]): The result of coco2017 detecion. keys include 'data', 'save_path', the corresponding value is:
                data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
                    left (float): The X coordinate of the upper left corner of the bounding box;
",4
"        """"""
        if use_gpu:
            try:
                _places = os.environ[""CUDA_VISIBLE_DEVICES""]
",4
"            padding_info_tensor = PaddleTensor(padding_info.copy())
",4
"            feed_list = [padding_image_tensor, padding_info_tensor]
",4
"            output = postprocess(
                paths=paths,
                images=images,
",4
"                data_out=data_out,
                score_thresh=score_thresh,
",4
"                output_dir=output_dir,
                handle_id=handle_id,
                visualization=visualization)
",4
"            res += output
        return res

",4
"    def add_module_config_arg(self):
        """"""
",4
"        Add the command config options
",4
"            help=""whether use GPU or not"")

        self.arg_config_group.add_argument(
",4
"
    def check_input_data(self, args):
        input_data = list()
        if args.input_path:
",4
"        if len(input_data) == 0:
            self.parser.print_help()
",4
"

def ConvNorm(input,
",4
"        bias = fluid.framework._get_var(battr.name)
    elif norm_type == 'gn':
        out = fluid.layers.group_norm(
",4
"            input=conv,
            act=act,
            name=norm_name + '.output.1',
",4
"            param_attr=pattr,
            bias_attr=battr)
        scale = fluid.framework._get_var(pattr.name)
        bias = fluid.framework._get_var(battr.name)
",4
"        max_level (int): highest level of the backbone feature map to use
        spatial_scale (list): feature map scaling factor
",4
"        self.norm_type = norm_type

",4
"        topdown_name = 'fpn_topdown_' + body_name
",4
"        body_input = body_dict[body_name_list[0]]
        fan = body_input.shape[1]
",4
"        if self.norm_type:
            initializer = Xavier(fan_out=fan)
            self.fpn_inner_output[0] = ConvNorm(
                body_input,
",4
"                name=fpn_inner_name,
",4
"        fpn_dict = {}
        fpn_name_list = []
",4
"                fpn_output = ConvNorm(
",4
"        highest_backbone_level = self.min_level + len(spatial_scale) - 1
",4
"        if self.has_extra_convs and self.max_level > highest_backbone_level:
            fpn_blob = body_dict[body_name_list[0]]
",4
"                if i > highest_backbone_level + 1:
                    fpn_blob_in = fluid.layers.relu(fpn_blob)
                fan = fpn_blob_in.shape[1] * 3 * 3
",4
"        res_dict = OrderedDict([(k, fpn_dict[k]) for k in fpn_name_list])
        return res_dict, spatial_scale
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"from paddle.fluid import ParamAttr

nonlocal_params = {
    ""use_zero_init_conv"": False,
    ""conv_init_std"": 0.01,
",4
"    ""no_bias"": True,
",4
"    ""weight_decay_bn"": 1.e-4,
}

",4
"                 filter_size = [1, 1], stride = [1, 1], \
                 padding = [0, 0], \
                 param_attr = ParamAttr(name = prefix + '_g' + ""_w"", \
",4
"                 name = prefix + '_g')
    g_shape = g.shape
    # we have to use explicit batch size (to support arbitrary spacetime size)
    # e.g. (8, 1024, 4, 14, 14) => (8, 1024, 784)
    theta = fluid.layers.reshape(theta, shape=(0, 0, -1))
",4
"    theta_phi = fluid.layers.matmul(theta, phi, name=prefix + '_affinity')
    g = fluid.layers.reshape(g, [0, 0, -1])

    if nonlocal_params[""use_softmax""]:
        if nonlocal_params[""use_scale""]:
",4
"        p = fluid.layers.softmax(
",4
"            theta_phi_sc, name=prefix + '_affinity' + '_prob')
    else:
",4
"    blob_out = fluid.layers.conv2d(input = blob_out, num_filters = dim_out, \
",4
"
    if nonlocal_params[""use_bn""]:
",4
"        bn_name = prefix + ""_bn""
        blob_out = fluid.layers.batch_norm(blob_out, \
                      # is_test = test_mode, \
                      momentum = nonlocal_params[""bn_momentum""], \
",4
"                      default_initializer = fluid.initializer.Constant(value = 0.))
        blob_out = fluid.layers.affine_channel(blob_out, scale = affine_scale, \
                      bias = affine_bias, name = prefix + '_affine')   # add affine

    return blob_out
",4
"from __future__ import division

import os
from collections import OrderedDict

",4
"

def test_reader(paths=None, images=None):
    """"""
    data generator
",4
"        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

    Yield:
",4
"    if paths:
        for img_path in paths:
            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"            img = cv2.imread(img_path).astype('float32')
            img_list.append(img)
    if images is not None:
",4
"        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        mean = np.array(mean)[np.newaxis, np.newaxis, :]
",4
"
        resize_w = np.round(im_scale * float(shape[1]))
",4
"        im_info = np.array([resize_h, resize_w, im_scale]).astype('float32')

        im = cv2.resize(
            im,
",4
"            fy=im_scale,
            interpolation=cv2.INTER_LINEAR)

",4
"        # HWC --> CHW
",4
"from __future__ import division
from __future__ import print_function

",4
"from paddle.fluid.regularizer import L2Decay
from paddle.fluid.initializer import Constant
",4
"                 norm_type='sync_bn',
                 freeze_norm=False,
",4
"                 feature_maps=[3, 4, 5],
                 dcn_v2_stages=[],
                 weight_prefix_name='',
                 nonlocal_stages=[],
                 get_prediction=False,
",4
"
        if isinstance(feature_maps, Integral):
            feature_maps = [feature_maps]

        assert depth in [34, 50], \
",4
"                     act=None,
                     name=None):
        out_channel = filter_size * filter_size * 3
        out = fluid.layers.conv2d(
            input,
",4
"                name=_name + '.conv2d.output.1')
",4
"                mask=mask,
                num_filters=num_filters,
                filter_size=filter_size,
                stride=stride,
",4
"                param_attr=ParamAttr(name=_name + ""_weights""),
                bias_attr=False,
                name=_name + "".conv2d.output.1"")
",4
"            if max_pooling_in_short_cut and not is_first:
                input = fluid.layers.pool2d(
                    input=input,
                    pool_size=2,
",4
"            expand = 1
        else:  # FIXME hard code for now, handles 32x4d, 64x4d and 32x8d
            num_filters = num_filters // 2
",4
"        for i, (c, k, s, act, g, _name) in enumerate(conv_def):
            residual = self._conv_norm(
                input=residual,
",4
"                name=_name,
                dcn_v2=(i == 1 and dcn_v2))
",4
"        short = self._shortcut(
            input,
            num_filters * expand,
            stride,
            is_first=is_first,
",4
"            name=shortcut_name)
        # Squeeze-and-Excitation
",4
"    def layer_warp(self, input, stage_num):
        """"""
",4
"            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2
",4
"
",4
"        for i in range(count):
            conv_name = self.na.fix_layer_warp_name(stage_num, count, i)
",4
"            dim_in = conv.shape[1]
            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
            if i % nonlocal_mod == nonlocal_mod - 1:
",4
"    def c1_stage(self, input):
        out_chan = self._c1_out_chan_num

",4
"        conv1_name = self.na.fix_c1_stage_name()

",4
"
        for i in feature_maps:
            res = self.layer_warp(res, i)
",4
"        if self.get_prediction:
            pool = fluid.layers.pool2d(
                input=res, pool_type='avg', global_pooling=True)
            stdv = 1.0 / math.sqrt(pool.shape[1] * 1.0)
",4
"                 depth=50,
                 freeze_at=2,
",4
"__all__ = [
    'base64_to_cv2',
",4
"    """"""
    image_name = os.path.split(image_path)[-1]
    name, ext = os.path.splitext(image_name)
    if ext == '':
        if img.format == 'PNG':
",4
"        else:
            if img.mode == ""RGB"" or img.mode == ""L"":
                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
",4
"                ext = '.png'
",4
"
    return os.path.join(output_dir, ""{}"".format(name)) + ext


",4
"            'top'], data['bottom']
        # draw bbox
        draw.line([(left, top), (left, bottom), (right, bottom), (right, top),
",4
"    if os.path.exists(save_name):
        os.remove(save_name)
    image.save(save_name)

    return save_name
",4
"

",4
"

",4
"            label_names.append(info.strip())
        return label_names
",4
"
def postprocess(paths, images, data_out, score_thresh, label_names, output_dir,
                handle_id, visualization):
    """"""
    postprocess the lod_tensor produced by fluid.Executor.run
",4
"    Returns:
        res (list[dict]): The result of vehicles detecion. keys include 'data', 'save_path', the corresponding value is:
            data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
",4
"                left (float): The X coordinate of the upper left corner of the bounding box;
                top (float): The Y coordinate of the upper left corner of the bounding box;
",4
"                right (float): The X coordinate of the lower right corner of the bounding box;
                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
",4
"            save_path (str): The path to save output images.
    """"""
    lod_tensor = data_out[0]
    lod = lod_tensor.lod[0]
",4
"
        output.append(output_i)

        if visualization:
",4
"from paddle.fluid.regularizer import L2Decay

",4
"
class AnchorGenerator(object):
    # __op__ = fluid.layers.anchor_generator
",4
"    def __init__(self,
                 stride=[16.0, 16.0],
                 anchor_sizes=[32, 64, 128, 256, 512],
                 aspect_ratios=[0.5, 1., 2.],
",4
"        target_assign (object): `RetinaTargetAssign` instance
        output_decoder (object): `RetinaOutputDecoder` instance
        num_convs_per_octave (int): Number of convolution layers in each octave
",4
"                 max_level=7,
                 min_level=3,
                 prior_prob=0.01,
                 base_scale=4,
",4
"                 num_scales_per_octave=3,
",4
"        self.sigma = sigma

    def _class_subnet(self, body_feats, spatial_scale):
        """"""
",4
"            cls_pred_input(list): Class prediction of all input fpn levels.
",4
"        cls_pred_list = []
",4
"                    i, self.min_level)
",4
"                subnet_blob_in = subnet_blob
                subnet_blob = fluid.layers.conv2d(
                    input=subnet_blob_in,
",4
"                    num_filters=self.num_chan,
                    filter_size=3,
                    stride=1,
                    padding=1,
                    act='relu',
",4
"
        return cls_pred_list

    def _bbox_subnet(self, body_feats, spatial_scale):
        """"""
",4
"            spatial_scale(list): A list of multiplicative spatial scale factor.

        Returns:
            bbox_pred_input(list): Bounding box prediction of all input fpn
                levels.
",4
"            # bbox prediction
            bbox_name = 'retnet_bbox_pred_fpn{}'.format(lvl)
            bbox_share_name = 'retnet_bbox_pred_fpn{}'.format(self.min_level)
",4
"                input=subnet_blob,
",4
"        Args:
            fpn_dict(dict): A dictionary represents the output of FPN with their name.
            spatial_scale(list): A list of multiplicative spatial scale factor.

        Return:
",4
"            anchor_var_input(list): Anchor variance of all input fpn levels with
                shape.
        """"""
",4
"    def get_prediction(self, body_feats, spatial_scale, im_info):
        """"""
        Get prediction bounding box in test stage.

        Args:
",4
"        Returns:
",4
"            pred_result(Variable): Prediction result with shape [N, 6]. Each
                row has 6 values: [label, confidence, xmin, ymin, xmax, ymax].
",4
"        bbox_pred_reshape_list = output['bbox_pred']
        anchor_reshape_list = output['anchor']
        for i in range(self.max_level - self.min_level + 1):
",4
"                cls_pred_reshape_list[i])
        pred_result = fluid.layers.retinanet_detection_output(
            bboxes=bbox_pred_reshape_list,
",4
"                shape [M, 1]. M is the number of groundtruth.
",4
"        loss_cls = fluid.layers.sigmoid_focal_loss(
            x=score_pred,
            label=score_tgt,
",4
"        self.class_dim = class_dim
        self.yolo_v3 = yolo_v3
",4
"                   num_filters,
                   stride,
                   padding,
                   num_groups=1,
                   act='relu',
",4
"            act=act,
",4
"                            num_groups,
                            stride,
                            scale,
",4
"        normal_conv = self._conv_norm(
            input=pointwise_conv,
            filter_size=3,
",4
"            num_filters=int(num_filters2),
            stride=2,
",4
"        blocks.append(out)
",4
"            out, 512, 1024, 512, 2, scale, name=self.prefix_name + ""conv5_6"")
        # 1/32
        out = self.depthwise_separable(
            out, 1024, 1024, 1024, 1, scale, name=self.prefix_name + ""conv6"")
        module13 = out
",4
"                size=self.class_dim,
                param_attr=ParamAttr(
                    initializer=fluid.initializer.MSRA(), name=""fc7_weights""),
                bias_attr=ParamAttr(name=""fc7_offset""))
            out = fluid.layers.softmax(out)
",4
"from ssd_mobilenet_v1_pascal.data_feed import reader


@moduleinfo(
",4
"        self.multi_box_head_config = self.model_config['MultiBoxHead']
        self.output_decoder_config = self.model_config['SSDOutputDecoder']
",4
"                }
                # names of outputs
                if get_prediction:
                    locs, confs, box, box_var = fluid.layers.multi_box_head(
                        inputs=body_feats,
",4
"                    outputs = {'bbox_out': [var_prefix + pred.name]}
                else:
                    outputs = {
                        'body_features':
                        [var_prefix + var.name for var in body_feats]
",4
"                outputs = {
                    out_key: [
                        context_prog.global_block().vars[varname]
                        for varname in out_value
                    ]
",4
"                if pretrained:

                    def _if_exist(var):
                        return os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
",4
"                    fluid.io.load_vars(
                        exe,
                        self.default_pretrained_model_path,
",4
"
    def object_detection(self,
                         paths=None,
                         images=None,
                         data=None,
",4
"                         batch_size=1,
                         use_gpu=False,
                         output_dir='detection_result',
                         score_thresh=0.5,
",4
"                    top (float): The Y coordinate of the upper left corner of the bounding box;
                    right (float): The X coordinate of the lower right corner of the bounding box;
",4
"                    bottom (float): The Y coordinate of the lower right corner of the bounding box;
                    label (str): The label of detection result;
",4
"        res = []
        for iter_id, feed_data in enumerate(batch_reader()):
",4
"            feed_data = np.array(feed_data)
            image_tensor = PaddleTensor(np.array(list(feed_data[:, 0])).copy())
            if use_gpu:
                data_out = self.gpu_predictor.run([image_tensor])
            else:
",4
"                data_out = self.cpu_predictor.run([image_tensor])

",4
"            params_filename=params_filename)

    @serving
    def serving_method(self, images, **kwargs):
",4
"            usage='%(prog)s',
            add_help=True)
        self.arg_input_group = self.parser.add_argument_group(
            title=""Input options"", description=""Input data. Required"")
",4
"        args = self.parser.parse_args(argvs)
        results = self.face_detection(
            paths=[args.input_path],
            batch_size=args.batch_size,
            use_gpu=args.use_gpu,
",4
"            default=False,
",4
"        """""" Transform the image data to numpy format.

        Args:
            to_rgb (bool): whether to convert BGR to RGB
",4
"    def __call__(self, im):
        if self.to_rgb:
",4
"        im_size_min = np.min(im_shape[0:2])
        im_size_max = np.max(im_shape[0:2])
        if isinstance(self.target_size, list):
            # Case for multi-scale training
            selected_size = random.choice(self.target_size)
",4
"        else:
            selected_size = self.target_size
        if float(im_size_min) == 0:
            raise ZeroDivisionError('{}: min size of image is 0'.format(self))
",4
"            im_scale = float(selected_size) / float(im_size_min)
            # Prevent the biggest axis from being more than max_size
",4
"                 mean=[0.485, 0.456, 0.406],
",4
"                 std=[1, 1, 1],
                 is_scale=True,
                 is_channel_first=True):
        """"""
",4
"
        Operators:
            1.(optional) Scale the image to [0,1]
            2. Each pixel minus mean and is divided by std
",4
"            im = im / 255.0
        im -= mean
",4
"            im = im[[2, 1, 0], :, :]
        return im
",4
"            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"            img = cv2.imread(img_path).astype('float32')
            img_list.append(img)
",4
"        std=[127.502231, 127.502231, 127.502231],
",4
"    elif img.format == 'BMP':
        ext = '.bmp'
    else:
        if img.mode == ""RGB"" or img.mode == ""L"":
",4
"        os.remove(save_name)

    image.save(save_name)

    return save_name
",4
"    return float(xmin), float(ymin), float(xmax), float(ymax)


def load_label_info(file_path):
    with open(file_path, 'r') as fr:
",4
"        text = fr.readlines()
        label_names = []
        for info in text:
            label_names.append(info.strip())
        return label_names
",4
"                score_thresh,
                label_names,
                output_dir,
                handle_id,
                visualization=True):
",4
"    """"""
",4
"        handle_id (int): The number of images that have been handled.
",4
"                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
    """"""
",4
"        unhandled_paths_num = len(unhandled_paths)
    else:
        unhandled_paths_num = 0

",4
"            output_i['data'].append(dt)

        output.append(output_i)
        if visualization:
",4
"        return getattr(self.model, 'variant', '')

    def fix_conv_norm_name(self, name):
",4
"            conv_name = str(stage_num + 2) + '_' + str(i + 1)
        return conv_name

    def fix_c1_stage_name(self):
        return ""res_conv1"" if self.model_type == 'ResNeXt' else ""conv1""
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"
import os
",4
"
from faster_rcnn_resnet50_fpn_venus.processor import load_label_info, postprocess, base64_to_cv2
from faster_rcnn_resnet50_fpn_venus.data_feed import test_reader, padding_minibatch
from faster_rcnn_resnet50_fpn_venus.fpn import FPN
from faster_rcnn_resnet50_fpn_venus.resnet import ResNet
",4
"                num_classes=708,
",4
"        Returns:
",4
"        startup_program = fluid.Program()
        with fluid.program_guard(context_prog, startup_program):
            with fluid.unique_name.guard():
                image = fluid.layers.data(
                    name='image', shape=[-1, 3, -1, -1], dtype='float32')
",4
"                # backbone
                backbone = ResNet(
                    norm_type='affine_channel',
                    depth=50,
                    feature_maps=[2, 3, 4, 5],
",4
"                # rpn_head: RPNHead
",4
"                        name='is_crowd', shape=[1], dtype='int32', lod_level=1)
                    gt_class = fluid.layers.data(
                        name='gt_class', shape=[1], dtype='int32', lod_level=1)
                    rpn_loss = rpn_head.get_loss(im_info, gt_bbox, is_crowd)
                    # bbox_assigner: BBoxAssigner
",4
"                        im_info=im_info,
                        batch_size_per_im=bbox_assigner.batch_size_per_im,
                        fg_fraction=bbox_assigner.fg_fraction,
                        fg_thresh=bbox_assigner.fg_thresh,
",4
"                        'image': var_prefix + image.name,
                        'im_info': var_prefix + im_info.name,
",4
"                add_vars_prefix(context_prog, var_prefix)
",4
"                        return os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
",4
"
                    fluid.io.load_vars(
                        exe,
                        self.default_pretrained_model_path,
",4
"                        predicate=_if_exist)
                return inputs, outputs, context_prog

    def rpn_head(self):
        return FPNRPNHead(
",4
"    def __init__(self,
                 batch_size_per_im=512,
                 fg_fraction=.25,
                 fg_thresh=.5,
",4
"__all__ = ['ConvNorm', 'FPN']


def ConvNorm(input,
             num_filters,
",4
"             filter_size,
",4
"             norm_groups=32,
             dilation=1,
             lr_scale=1,
",4
"        scale = fluid.framework._get_var(pattr.name)
        bias = fluid.framework._get_var(battr.name)
    elif norm_type == 'gn':
        out = fluid.layers.group_norm(
            input=conv,
",4
"            act=act,
            name=norm_name + '.output.1',
            groups=norm_groups,
            param_attr=pattr,
            bias_attr=battr)
",4
"            attr=battr,
            default_initializer=fluid.initializer.Constant(0.))
        out = fluid.layers.affine_channel(
",4
"        bias.stop_gradient = True
    return out


",4
"        num_chan (int): number of feature channels
        min_level (int): lowest level of the backbone feature map to use
        max_level (int): highest level of the backbone feature map to use
",4
"                 min_level=2,
                 max_level=6,
                 spatial_scale=[1. / 32., 1. / 16., 1. / 8., 1. / 4.],
",4
"                 norm_type=None,
                 freeze_norm=False):
        self.freeze_norm = freeze_norm
",4
"        self.max_level = max_level
        self.spatial_scale = spatial_scale
        self.has_extra_convs = has_extra_convs
        self.norm_type = norm_type
",4
"
    def _add_topdown_lateral(self, body_name, body_input, upper_output):
        lateral_name = 'fpn_inner_' + body_name + '_lateral'
",4
"        if self.norm_type:
",4
"                self.num_chan,
                1,
                initializer=initializer,
",4
"            lateral = fluid.layers.conv2d(
                body_input,
",4
"            spatial_scale(list): A list of multiplicative spatial scale factor.
        """"""
        spatial_scale = copy.deepcopy(self.spatial_scale)
        body_name_list = list(body_dict.keys())[::-1]
        num_backbone_stages = len(body_name_list)
",4
"        self.fpn_inner_output = [[] for _ in range(num_backbone_stages)]
        fpn_inner_name = 'fpn_inner_' + body_name_list[0]
        body_input = body_dict[body_name_list[0]]
        fan = body_input.shape[1]
        if self.norm_type:
",4
"                param_attr=ParamAttr(
",4
"            body_name = body_name_list[i]
",4
"            body_input = body_dict[body_name]
",4
"            top_output = self.fpn_inner_output[i - 1]
            fpn_inner_single = self._add_topdown_lateral(
                body_name, body_input, top_output)
            self.fpn_inner_output[i] = fpn_inner_single
",4
"                    self.fpn_inner_output[i],
",4
"                1,
                'max',
",4
"        if self.has_extra_convs and self.max_level > highest_backbone_level:
            fpn_blob = body_dict[body_name_list[0]]
            for i in range(highest_backbone_level + 1, self.max_level + 1):
",4
"                fpn_blob_in = fpn_blob
                fpn_name = 'fpn_' + str(i)
                if i > highest_backbone_level + 1:
",4
"                fpn_blob = fluid.layers.conv2d(
                    input=fpn_blob_in,
",4
"                    num_filters=self.num_chan,
                    filter_size=3,
                    stride=2,
                    padding=1,
",4
"                spatial_scale.insert(0, spatial_scale[0] * 0.5)
        res_dict = OrderedDict([(k, fpn_dict[k]) for k in fpn_name_list])
        return res_dict, spatial_scale
from __future__ import absolute_import
from __future__ import division
",4
"                                    initializer = fluid.initializer.Normal(loc = 0.0,
                                    scale = nonlocal_params[""conv_init_std""])), \
                                bias_attr = ParamAttr(name = prefix + '_theta' + ""_b"", \
",4
"    theta_shape_op.stop_gradient = True

    if nonlocal_params[""use_maxpool""]:
",4
"                                        pool_padding = [0, 0], \
                                        name = prefix + '_pool')
    else:
",4
"        max_pool = cur
",4
"                     initializer = fluid.initializer.Constant(value = 0.)) if (nonlocal_params[""no_bias""] == 0) else False, \
                 name = prefix + '_g')
    g_shape = g.shape
    # we have to use explicit batch size (to support arbitrary spacetime size)
",4
"                                  filter_size = [1, 1], stride = [1, 1], padding = [0, 0], \
                                  param_attr = ParamAttr(name = prefix + '_out' + ""_w"", \
                                      initializer = fluid.initializer.Constant(value = 0.) \
                                        if nonlocal_params[""use_zero_init_conv""] \
",4
"                                        else fluid.initializer.Normal(loc = 0.0,
                                            scale = nonlocal_params[""conv_init_std""])), \
                                  bias_attr = ParamAttr(name = prefix + '_out' + ""_b"", \
                                          initializer = fluid.initializer.Constant(value = 0.)) \
",4
"
    return blob_out


",4
"def add_space_nonlocal(input, dim_in, dim_out, prefix, dim_inner):
    '''
    add_space_nonlocal:
        Non-local Neural Networks: see https://arxiv.org/abs/1711.07971
    '''
",4
"from paddle import fluid
",4
"            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
",4
"        std = np.array(std)[np.newaxis, np.newaxis, :]
        im = im / 255.0
",4
"        im -= mean
        im /= std

        target_size = 800
        max_size = 1333
",4
"        max_shape[1] = int(
            np.ceil(max_shape_org[1] / coarsest_stride) * coarsest_stride)
        max_shape[2] = int(
",4
"        padding_im = np.zeros((im_c, max_shape[1], max_shape[2]),
                              dtype=np.float32)
        padding_im[:, 0:im_h, 0:im_w] = data['image']
        padding_image.append(padding_im)
",4
"    padding_shape = np.array(padding_shape).astype('float32')
    return padding_image, padding_info, padding_shape
",4
"from paddle.fluid.initializer import Normal
from paddle.fluid.regularizer import L2Decay
",4
"

class AnchorGenerator(object):
    # __op__ = fluid.layers.anchor_generator
    def __init__(self,
",4
"                 stride=[16.0, 16.0],
",4
"        self.anchor_sizes = anchor_sizes
        self.aspect_ratios = aspect_ratios
        self.variance = variance
        self.stride = stride

",4
"                 rpn_negative_overlap=0.3,
                 use_random=True):
        super(RPNTargetAssign, self).__init__()
        self.rpn_batch_size_per_im = rpn_batch_size_per_im
        self.rpn_straddle_thresh = rpn_straddle_thresh
",4
"                 nms_thresh=.5,
                 min_size=.1,
                 eta=1.):
        super(GenerateProposals, self).__init__()
",4
"        'anchor_generator', 'rpn_target_assign', 'train_proposal',
        'test_proposal'
    ]

",4
"        self.test_proposal = test_proposal
        self.num_classes = num_classes

    def _get_output(self, input):
",4
"        self.anchor, self.anchor_var = fluid.layers.anchor_generator(
            input=rpn_conv,
            anchor_sizes=self.anchor_generator.anchor_sizes,
",4
"            padding=0,
            act=None,
            name='rpn_cls_score',
            param_attr=ParamAttr(
",4
"                regularizer=L2Decay(0.)))
        # Proposal bbox regression deltas
        self.rpn_bbox_pred = fluid.layers.conv2d(
            rpn_conv,
            num_filters=4 * num_anchor,
",4
"            bias_attr=ParamAttr(
                name=""rpn_bbox_pred_b"",
                learning_rate=2.,
",4
"                regularizer=L2Decay(0.)))
        return self.rpn_cls_score, self.rpn_bbox_pred

    def get_proposals(self, body_feats, im_info, mode='train'):
",4
"        rpn_cls_score, rpn_bbox_pred = self._get_output(body_feat)

        if self.num_classes == 1:
            rpn_cls_prob = fluid.layers.sigmoid(
                rpn_cls_score, name='rpn_cls_prob')
",4
"                rpn_cls_score, perm=[0, 2, 3, 1])
            rpn_cls_score = fluid.layers.reshape(
                rpn_cls_score, shape=(0, 0, 0, -1, self.num_classes))
            rpn_cls_prob_tmp = fluid.layers.softmax(
",4
"        prop_op = self.train_proposal if mode == 'train' else self.test_proposal
        # prop_op
        rpn_rois, rpn_roi_probs = fluid.layers.generate_proposals(
",4
"            x=rpn_cls_score, shape=(0, -1, self.num_classes))
",4
"        Sample proposals and Calculate rpn loss.

        Args:
            im_info(Variable): The information of image with shape [N, 3] with
",4
"            is_crowd(Variable): Indicates groud-truth is crowd or not with
",4
"        Returns:
            Type: dict
                rpn_cls_loss(Variable): RPN classification loss.
",4
"                fluid.layers.rpn_target_assign(
                    bbox_pred=rpn_bbox,
",4
"                    is_crowd=is_crowd,
                    im_info=im_info,
                    rpn_batch_size_per_im=self.rpn_target_assign.rpn_batch_size_per_im,
",4
"                    rpn_straddle_thresh=self.rpn_target_assign.rpn_straddle_thresh,
                    rpn_fg_fraction=self.rpn_target_assign.rpn_fg_fraction,
                    rpn_positive_overlap=self.rpn_target_assign.rpn_positive_overlap,
",4
"            rpn_cls_loss = fluid.layers.sigmoid_cross_entropy_with_logits(
                x=score_pred, label=score_tgt)
",4
"        else:
            score_pred, loc_pred, score_tgt, loc_tgt, bbox_weight = \
                self.rpn_target_assign(
                    bbox_pred=rpn_bbox,
                    cls_logits=rpn_cls,
",4
"                    anchor_var=anchor_var,
                    gt_boxes=gt_box,
                    gt_labels=gt_label,
",4
"                logits=score_pred, label=labels_int64, numeric_stable_mode=True)

        rpn_cls_loss = fluid.layers.reduce_mean(
            rpn_cls_loss, name='loss_rpn_cls')

",4
"class FPNRPNHead(RPNHead):
    """"""
    RPN Head that supports FPN input
",4
"                 max_level=6,
                 num_classes=1):
        super(FPNRPNHead, self).__init__(anchor_generator, rpn_target_assign,
                                         train_proposal, test_proposal)
",4
"    def _get_output(self, input, feat_lvl):
        """"""
        Get anchor and FPN RPN head output at one level.

        Args:
",4
"        bbox_name = 'rpn_bbox_pred_fpn' + slvl
        conv_share_name = 'conv_rpn_fpn' + str(self.min_level)
",4
"
        cls_num_filters = num_anchors * self.num_classes
",4
"            input=conv_rpn_fpn,
            num_filters=cls_num_filters,
            filter_size=1,
            act=None,
            name=cls_name,
",4
"                learning_rate=2.,
                regularizer=L2Decay(0.)))
",4
"            filter_size=1,
            act=None,
            name=bbox_name,
            param_attr=ParamAttr(
                name=bbox_share_name + '_w',
",4
"                initializer=Normal(loc=0., scale=0.01)),
            bias_attr=ParamAttr(
                name=bbox_share_name + '_b',
                learning_rate=2.,
",4
"                regularizer=L2Decay(0.)))
        return self.rpn_cls_score, self.rpn_bbox_pred
",4
"
        prop_op = self.train_proposal if mode == 'train' else self.test_proposal
        if self.num_classes == 1:
            rpn_cls_prob_fpn = fluid.layers.sigmoid(
                rpn_cls_score_fpn, name='rpn_cls_prob_fpn' + str(feat_lvl))
",4
"            rpn_cls_score_fpn = fluid.layers.transpose(
",4
"            rpn_cls_prob_fpn, _ = fluid.layers.topk(rpn_cls_prob_fpn, 1)
            rpn_cls_prob_fpn = fluid.layers.reshape(
                rpn_cls_prob_fpn, shape=(0, 0, 0, -1))
            rpn_cls_prob_fpn = fluid.layers.transpose(
",4
"                rpn_cls_prob_fpn, perm=[0, 3, 1, 2])
        # prop_op
        rpn_rois_fpn, rpn_roi_prob_fpn = fluid.layers.generate_proposals(
            scores=rpn_cls_prob_fpn,
",4
"            bbox_deltas=rpn_bbox_pred_fpn,
",4
"            post_nms_top_n=prop_op.post_nms_top_n,
            nms_thresh=prop_op.nms_thresh,
",4
"        """"""
        Get proposals in multiple levels according to the output of fpn
",4
"            self.fpn_rpn_list.append((self.rpn_cls_score, self.rpn_bbox_pred))
            rois_list.append(rois_fpn)
            roi_probs_list.append(roi_probs_fpn)
            self.anchors_list.append(self.anchors)
            self.anchor_var_list.append(self.anchor_var)
",4
"                self.fpn_rpn_list[i][0], self.fpn_rpn_list[i][1],
                self.anchors_list[i], self.anchor_var_list[i])
            rpn_clses.append(single_input[0])
            rpn_bboxes.append(single_input[1])
            anchors.append(single_input[2])
",4
"    def __init__(self,
                 sampling_ratio=0,
                 min_level=2,
                 max_level=5,
",4
"                 canconical_level=4,
                 canonical_size=224,
",4
"                input=head_input,
                rois=rois_input,
                pooled_height=resolution,
",4
"
from .nonlocal_helper import add_space_nonlocal
from .name_adapter import NameAdapter

",4
"        norm_decay (float): weight decay for normalization layer weights
        variant (str): ResNet variant, supports 'a', 'b', 'c', 'd' currently
",4
"    __shared__ = ['norm_type', 'freeze_norm', 'weight_prefix_name']

    def __init__(self,
                 depth=50,
                 freeze_at=0,
",4
"                 variant='b',
                 feature_maps=[3, 4, 5],
                 dcn_v2_stages=[],
                 weight_prefix_name='',
",4
"        assert 0 <= freeze_at <= 4, ""freeze_at should be 0, 1, 2, 3 or 4""
",4
"            34: ([3, 4, 6, 3], self.basicblock),
            50: ([3, 4, 6, 3], self.bottleneck),
        }
        self.stage_filters = [64, 128, 256, 512]
",4
"        self.class_dim = class_dim

    def _conv_offset(self,
",4
"            bias_attr=ParamAttr(initializer=Constant(0.0), name=name + "".b_0""),
            act=act,
",4
"            conv = fluid.layers.deformable_conv(
                input=input,
",4
"        battr = ParamAttr(
            name=bn_name + '_offset',
",4
"            out = fluid.layers.batch_norm(
                input=conv,
",4
"                moving_variance_name=bn_name + '_variance',
                use_global_stats=global_stats)
            scale = fluid.framework._get_var(pattr.name)
            bias = fluid.framework._get_var(battr.name)
        elif self.norm_type == 'affine_channel':
",4
"            bias = fluid.layers.create_parameter(
                shape=[conv.shape[1]],
                dtype=conv.dtype,
",4
"            scale.stop_gradient = True
            bias.stop_gradient = True
        return out

    def _shortcut(self, input, ch_out, stride, is_first, name):
",4
"        max_pooling_in_short_cut = self.variant == 'd'
        ch_in = input.shape[1]
        # the naming rule is same as pretrained weight
        name = self.na.fix_shortcut_name(name)
        std_senet = getattr(self, 'std_senet', False)
",4
"            ], [num_filters, 3, stride2, 'relu', groups, conv_name2],
                        [num_filters * expand, 1, 1, None, 1, conv_name3]]
        else:
            conv_def = [[num_filters, 1, stride1, 'relu', 1, conv_name1],
",4
"                        [num_filters * expand, 1, 1, None, 1, conv_name3]]

        residual = input
",4
"                act=act,
                groups=g,
                name=_name,
                dcn_v2=(i == 1 and dcn_v2))
        short = self._shortcut(
",4
"    def basicblock(self,
                   input,
",4
"        conv0 = self._conv_norm(
            input=input,
            num_filters=num_filters,
            filter_size=3,
            act='relu',
",4
"        """"""
        assert stage_num in [2, 3, 4, 5]

",4
"                                          int(dim_in / 2))
        return conv

",4
"        if self.variant in ['c', 'd']:
            conv_def = [
                [out_chan // 2, 3, 2, ""conv1_1""],
                [out_chan // 2, 3, 1, ""conv1_2""],
                [out_chan, 3, 1, ""conv1_3""],
",4
"                stride=s,
                act='relu',
",4
"        return output

    def __call__(self, input):
        assert isinstance(input, Variable)
",4
"        res = input
",4
"        if not severed_head:
            res = self.c1_stage(res)
            feature_maps = range(2, max(self.feature_maps) + 1)

        for i in feature_maps:
",4
"                input=pool,
                size=self.class_dim,
                param_attr=fluid.param_attr.ParamAttr(
",4
"import base64
import os

import cv2
",4
"    """"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
",4
"            ext = '.png'
        elif img.format == 'JPEG':
            ext = '.jpg'
",4
"    draw = ImageDraw.Draw(image)
    for data in data_list:
        left, right, top, bottom = data['left'], data['right'], data[
            'top'], data['bottom']

",4
"    ymax = max(min(bbox[3], img_height), 0.)
",4
"                handle_id,
                visualization=True):
",4
"    """"""
    postprocess the lod_tensor produced by fluid.Executor.run

",4
"                top (float): The Y coordinate of the upper left corner of the bounding box;
                right (float): The X coordinate of the lower right corner of the bounding box;
                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
",4
"        unhandled_paths = paths[handle_id:]
        unhandled_paths_num = len(unhandled_paths)
    else:
        unhandled_paths_num = 0
",4
"
    output = []
    for index in range(len(lod) - 1):
        output_i = {'data': []}
",4
"                    org_img, output_dir, 'image_numpy_{}'.format(
                        (handle_id + index)))
                org_img.save(org_img_path)
        org_img_height = org_img.height
",4
"            output_i['save_path'] = draw_bounding_box_on_image(
                org_img_path, output_i['data'], output_dir)

    return output
",4
"from collections import OrderedDict

from paddle import fluid
",4
"from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.initializer import Normal, Xavier
from paddle.fluid.regularizer import L2Decay
",4
"                 nms_threshold=.5,
",4
"
",4
"    def __call__(self, x, y, inside_weight=None, outside_weight=None):
        return fluid.layers.smooth_l1(
            x,
",4
"            inside_weight=inside_weight,
",4
"class BoxCoder(object):
    def __init__(self,
",4
"        super(BoxCoder, self).__init__()
        self.prior_box_var = prior_box_var
",4
"        box_coder (object): `BoxCoder` instance
        nms (object): `MultiClassNMS` instance
",4
"        num_classes: number of output classes
    """"""
    __inject__ = ['head', 'box_coder', 'nms', 'bbox_loss']
",4
"    __shared__ = ['num_classes']

    def __init__(self,
                 head,
",4
"        Get the bbox head feature map.
",4
"            if isinstance(feat, OrderedDict):
",4
"
        Returns:
",4
"            cls_score(Variable): Output of rpn head with shape of
",4
"        head_feat = self.get_head_feat(roi_feat)
        # when ResNetC5 output a single feature map
        if not isinstance(self.head, TwoFCHead):
            head_feat = fluid.layers.pool2d(
",4
"                 bbox_inside_weights, bbox_outside_weights):
        """"""
        Get bbox_head loss.

",4
"            bbox_outside_weights(Variable): Indicates whether a box should
",4
"            Type: Dict
",4
"        cls_score, bbox_pred = self._get_output(roi_feat)

        labels_int64 = fluid.layers.cast(x=labels_int32, dtype='int64')
        labels_int64.stop_gradient = True
",4
"        loss_cls = fluid.layers.softmax_with_cross_entropy(
            logits=cls_score, label=labels_int64, numeric_stable_mode=True)
        loss_cls = fluid.layers.reduce_mean(loss_cls)
        loss_bbox = self.bbox_loss(
",4
"                       roi_feat,
                       rois,
                       im_info,
                       im_shape,
                       return_box_score=False):
",4
"        boxes = rois / im_scale
        cls_prob = fluid.layers.softmax(cls_score, use_cudnn=False)
        bbox_pred = fluid.layers.reshape(bbox_pred, (-1, self.num_classes, 4))
        # self.box_coder
        decoded_box = fluid.layers.box_coder(
",4
"            keep_top_k=self.nms.keep_top_k,
            nms_threshold=self.nms.nms_threshold,
            normalized=self.nms.normalized,
            nms_eta=self.nms.nms_eta,
            background_label=self.nms.background_label)
",4
"        """"""
        Distill the Head Features, so as to perform transfer learning.

",4
"                    outputs = {
                        'head_features':
                        [var_prefix + var.name for var in head_features],
",4
"                # trainable
                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
                # pretrained
                if pretrained:
",4
"
                    def _if_exist(var):
                        return os.path.exists(
                            os.path.join(self.default_pretrained_model_path,
                                         var.name))
",4
"            output_dir (str): The path to store output images.
            visualization (bool): Whether to save image or not.
            score_thresh (float): threshold for object detecion.

        Returns:
",4
"        paths = paths if paths else list()
        data_reader = partial(reader, paths, images)
",4
"            feed_data = np.array(feed_data)
            image_tensor = PaddleTensor(np.array(list(feed_data[:, 0])))
            im_size_tensor = PaddleTensor(np.array(list(feed_data[:, 1])))
",4
"            output = postprocess(
                paths=paths,
                images=images,
",4
"        fluid.io.save_inference_model(
            dirname=dirname,
            main_program=program,
            executor=exe,
            feeded_var_names=feeded_var_names,
",4
"            usage='%(prog)s',
            add_help=True)
",4
"            default=False,
            help=""whether use GPU or not"")
",4
"        self.arg_config_group.add_argument(
",4
"            default='yolov3_vehicles_detect_output',
            help=""The directory to save output images."")
",4
"            type=ast.literal_eval,
            default=0.2,
            help=""threshold for object detecion."")
",4
"        self.nms = nms
        self.prefix_name = weight_prefix_name

    def _conv_bn(self,
",4
"            padding=padding,
            act=None,
            param_attr=ParamAttr(name=name + "".conv.weights""),
",4
"            regularizer=L2Decay(self.norm_decay), name=bn_name + '.offset')
        out = fluid.layers.batch_norm(
",4
"    def _upsample(self, input, scale=2, name=None):
        out = fluid.layers.resize_nearest(
",4
"        Returns:
            outputs (list): Variables of each output layer
        """"""

",4
"                block = fluid.layers.concat(input=[route, block], axis=1)
            route, tip = self._detection_block(
",4
"            if i < len(blocks) - 1:
                # do not perform upsample in the last detection_block
                route = self._conv_bn(
                    input=route,
",4
"                    ch_out=256 // (2**i),
                    filter_size=1,
",4
"            outputs (list): list of Variables, return from _get_outputs
",4
"        downsample = 32
        for i, output in enumerate(outputs):
",4
"            keep_top_k=self.nms.keep_top_k,
            nms_threshold=self.nms.nms_threshold,
",4
"
",4
"            ext = '.jpg'
        elif img.format == 'BMP':
",4
"            ext = '.bmp'
",4
"        else:
            if img.mode == ""RGB"" or img.mode == ""L"":
                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
",4
"

def draw_bounding_box_on_image(image_path, data_list, save_dir):
    image = Image.open(image_path)
",4
"        return label_names


def postprocess(paths,
",4
"                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
    """"""
    lod_tensor = data_out[0]
",4
"    output = list()
    for index in range(len(lod) - 1):
",4
"from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay
",4
"
__all__ = ['DarkNet']


",4
"                 depth=53,
",4
"            num_filters=ch_out,
            filter_size=filter_size,
            stride=stride,
            padding=padding,
            act=None,
",4
"        bn_bias_attr = ParamAttr(
            regularizer=L2Decay(float(self.norm_decay)),
            name=bn_name + '.offset')

",4
"            moving_variance_name=bn_name + '.var')
",4
"    def _downsample(self,
                    input,
",4
"    def basicblock(self, input, ch_out, name=None):
",4
"            padding=1,
            name=name + "".1"")
        out = fluid.layers.elementwise_add(x=input, y=conv2, act=None)
",4
"        return out

    def __call__(self, input):
",4
"                bias_attr=ParamAttr(name='fc_offset'))
            out = fluid.layers.softmax(out)
            return out
        else:
",4
"        self.with_extra_blocks = with_extra_blocks
        self.extra_block_filters = extra_block_filters
        self.prefix_name = weight_prefix_name

    def _conv_norm(self,
",4
"            param_attr=parameter_attr,
            bias_attr=False)

        bn_name = name + ""_bn""
        norm_decay = self.norm_decay
",4
"            moving_variance_name=bn_name + '_variance')

    def depthwise_separable(self,
                            input,
",4
"                            name=None):
        depthwise_conv = self._conv_norm(
            input=input,
",4
"        pointwise_conv = self._conv_norm(
            input=input,
            filter_size=1,
            num_filters=int(num_filters1),
",4
"        return normal_conv

    def __call__(self, input):
        scale = self.conv_group_scale
",4
"        out = self.depthwise_separable(
            out, 256, 512, 256, 2, scale, name=self.prefix_name + ""conv4_2"")
        # 1/16
",4
"        blocks.append(out)
        for i in range(5):
            out = self.depthwise_separable(
                out,
                512,
",4
"                512,
                512,
                1,
                scale,
                name=self.prefix_name + ""conv5_"" + str(i + 1))
",4
"        module11 = out

",4
"import os
from functools import partial

import numpy as np
",4
"from yolov3_mobilenet_v1_coco2017.yolo_head import MultiClassNMS, YOLOv3Head


@moduleinfo(
    name=""yolov3_mobilenet_v1_coco2017"",
",4
"        cpu_config.disable_gpu()
        cpu_config.switch_ir_optim(False)
        self.cpu_predictor = create_paddle_predictor(cpu_config)

        try:
",4
"        Distill the Head Features, so as to perform transfer learning.

        Args:
            trainable (bool): whether to set parameters trainable.
            pretrained (bool): whether to load default pretrained model.
",4
"        startup_program = fluid.Program()
        with fluid.program_guard(context_prog, startup_program):
            with fluid.unique_name.guard():
",4
"                # image
                image = fluid.layers.data(
                    name='image', shape=[3, 608, 608], dtype='float32')
",4
"                # var_prefix
                var_prefix = '@HUB_{}@'.format(self.name)
                # name of inputs
                inputs = {
                    'image': var_prefix + image.name,
",4
"                    bbox_out = yolo_head.get_prediction(head_features, im_size)
                    outputs = {'bbox_out': [var_prefix + bbox_out.name]}
                else:
                    outputs = {
",4
"                # inputs
",4
"                    key: context_prog.global_block().vars[value]
                    for key, value in inputs.items()
                }
                # outputs
                outputs = {
",4
"                        for varname in value
                    ]
",4
"                        exe,
                        self.default_pretrained_model_path,
",4
"                         visualization=True):
        """"""API of Object Detection.

        Args:
",4
"                    confidence (float): The confidence of detection result.
",4
"        """"""
",4
"
        paths = paths if paths else list()
",4
"                visualization=visualization)
            res.extend(output)
        return res

",4
"        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
",4
"            executor=exe,
",4
"            prog='hub run {}'.format(self.name),
            usage='%(prog)s',
            add_help=True)
",4
"            paths=[args.input_path],
            batch_size=args.batch_size,
            use_gpu=args.use_gpu,
            output_dir=args.output_dir,
            visualization=args.visualization,
",4
"    def add_module_config_arg(self):
        """"""
        Add the command config options.
",4
"            '--input_path', type=str, help=""path to image."")
",4
"        self.arg_input_group.add_argument(
            '--score_thresh',
            type=ast.literal_eval,
            default=0.5,
            help=""threshold for object detecion."")
",4
"# coding=utf-8
from __future__ import absolute_import
from __future__ import print_function
",4
"    data generator

    Args:
        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]
",4
"        mean = [0.485, 0.456, 0.406]
",4
"        std = [0.229, 0.224, 0.225]
        im = im.astype(np.float32, copy=False)
        mean = np.array(mean)[np.newaxis, np.newaxis, :]
",4
"        std = np.array(std)[np.newaxis, np.newaxis, :]
",4
"        im = im / 255.0
        im -= mean
        im /= std
",4
"
from collections import OrderedDict

from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
",4
"        self.normalized = normalized
        self.score_threshold = score_threshold


class YOLOv3Head(object):
",4
"    """"""Head block for YOLOv3 network
",4
"
    Args:
        norm_decay (float): weight decay for normalization layer weights
        num_classes (int): number of output classes
        ignore_thresh (float): threshold to ignore confidence loss
",4
"                 num_classes=80,
                 ignore_thresh=0.7,
",4
"                          [59, 119], [116, 90], [156, 198], [373, 326]],
",4
"                 weight_prefix_name=''):
",4
"        self.norm_decay = norm_decay
        self.num_classes = num_classes
        self.ignore_thresh = ignore_thresh
",4
"                 ch_out,
                 filter_size,
",4
"            num_filters=ch_out,
            filter_size=filter_size,
            stride=stride,
",4
"            ""channel {} cannot be divided by 2 in detection block {}"" \
            .format(channel, name)

        conv = input
        for j in range(2):
",4
"                filter_size=3,
                stride=1,
                padding=1,
",4
"            channel * 2,
            filter_size=3,
            stride=1,
            padding=1,
",4
"    def _upsample(self, input, scale=2, name=None):
        out = fluid.layers.resize_nearest(
",4
"        """"""
        Check ANCHORS/ANCHOR_MASKS in config and parse mask_anchors
",4
"
        Returns:
            outputs (list): Variables of each output layer
        """"""

",4
"        outputs = []
",4
"
",4
"        # get last out_layer_num blocks in reverse order
        out_layer_num = len(self.anchor_masks)
        if isinstance(input, OrderedDict):
            blocks = list(input.values())[-1:-out_layer_num - 1:-1]
        else:
",4
"            blocks = input[-1:-out_layer_num - 1:-1]
",4
"                block = fluid.layers.concat(input=[route, block], axis=1)
            route, tip = self._detection_block(
                block,
",4
"            outputs.append(block_out)

",4
"                img_size=im_size,
                anchors=self.mask_anchors[i],
                class_num=self.num_classes,
                conf_thresh=self.nms.score_threshold,
                downsample_ratio=downsample,
",4
"
",4
"                ext = "".jpg""
",4
"            'top'], data['bottom']
        # draw bbox
",4
"    ymin = max(min(bbox[1], img_height), 0.)
    xmax = max(min(bbox[2], img_width), 0.)
    ymax = max(min(bbox[3], img_height), 0.)
",4
"        res (list[dict]): The result of vehicles detecion. keys include 'data', 'save_path', the corresponding value is:
            data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
                left (float): The X coordinate of the upper left corner of the bounding box;
                top (float): The Y coordinate of the upper left corner of the bounding box;
                right (float): The X coordinate of the lower right corner of the bounding box;
",4
"        result_i = results[lod[index]:lod[index + 1]]
        for row in result_i:
            if len(row) != 6:
                continue
",4
"
import numpy as np
import paddle.fluid as fluid
",4
"from paddlehub.common.paddle_helper import add_vars_prefix

",4
"        self.label_names = load_label_info(
            os.path.join(self.directory, ""label_file.txt""))
        self._set_config()
",4
"        Distill the Head Features, so as to perform transfer learning.

        Args:
            trainable (bool): whether to set parameters trainable.
",4
"                body_feats = backbone(image)
                # im_size
                im_size = fluid.layers.data(
",4
"                    anchors=[[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
                             [59, 119], [116, 90], [156, 198], [373, 326]],
                    norm_decay=0.,
                    num_classes=1,
                    ignore_thresh=0.7,
",4
"                    confidence (float): The confidence of detection result.
                save_path (str, optional): The path to save output images.
        """"""
",4
"                raise RuntimeError(
                    ""Attempt to use GPU for prediction, but environment variable CUDA_VISIBLE_DEVICES was not set correctly.""
                )

        paths = paths if paths else list()
",4
"                    [image_tensor, im_size_tensor])
            else:
                data_out = self.cpu_predictor.run(
",4
"                score_thresh=score_thresh,
",4
"        if combined:
            model_filename = ""__model__"" if not model_filename else model_filename
            params_filename = ""__params__"" if not params_filename else params_filename
",4
"            model_filename=model_filename,
            params_filename=params_filename)

    @serving
    def serving_method(self, images, **kwargs):
",4
"        images_decode = [base64_to_cv2(image) for image in images]
",4
"        return results
",4
"            title=""Config options"",
            description=
            ""Run configuration for controlling module behavior, not required."")
        self.add_module_config_arg()
",4
"            use_gpu=args.use_gpu,
            output_dir=args.output_dir,
            visualization=args.visualization,
",4
"            type=str,
            default='yolov3_pedestrian_detect_output',
            help=""The directory to save output images."")
        self.arg_config_group.add_argument(
",4
"            '--visualization',
            type=ast.literal_eval,
",4
"        self.arg_input_group.add_argument(
",4
"import numpy as np

",4
"            assert os.path.isfile(
",4
"            img_list.append(img)
    if images is not None:
",4
"        im_size = np.array([im_shape[0], im_shape[1]], dtype=np.int32)

        # decode image
        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
",4
"        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        im = im.astype(np.float32, copy=False)
",4
"        im = np.swapaxes(im, 1, 0)

        yield [im, im_size]
from __future__ import absolute_import
",4
"from __future__ import division
from __future__ import print_function

",4
"from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay

__all__ = ['MultiClassNMS', 'YOLOv3Head']
",4
"    def __init__(self, background_label, keep_top_k, nms_threshold, nms_top_k,
",4
"                 normalized, score_threshold):
        super(MultiClassNMS, self).__init__()
        self.background_label = background_label
",4
"    """"""Head block for YOLOv3 network

    Args:
        norm_decay (float): weight decay for normalization layer weights
",4
"        ignore_thresh (float): threshold to ignore confidence loss
",4
"    def __init__(self,
                 norm_decay=0.,
",4
"                 name=None):
        conv = fluid.layers.conv2d(
            input=input,
",4
"            name='{}.2'.format(name))
        tip = self._conv_bn(
            route,
            channel * 2,
            filter_size=3,
",4
"
    def _upsample(self, input, scale=2, name=None):
        out = fluid.layers.resize_nearest(
",4
"        self.anchors = []
        self.mask_anchors = []
",4
"
        assert len(anchors) > 0, ""ANCHORS not set.""
        assert len(self.anchor_masks) > 0, ""ANCHOR_MASKS not set.""
",4
"            for mask in masks:
                assert mask < anchor_num, ""anchor mask index overflow""
                self.mask_anchors[-1].extend(anchors[mask])

    def _get_outputs(self, input, is_train=True):
",4
"        Returns:
",4
"            if i > 0:  # perform concat in first 2 detection_block
                block = fluid.layers.concat(input=[route, block], axis=1)
            route, tip = self._detection_block(
                block,
                channel=512 // (2**i),
",4
"                name=self.prefix_name + ""yolo_block.{}"".format(i))
",4
"                                     ""yolo_output.{}.conv.weights"".format(i)),
                bias_attr=ParamAttr(
                    regularizer=L2Decay(0.),
",4
"    def get_prediction(self, outputs, im_size):
        """"""
        Get prediction result of YOLOv3 network

        Args:
",4
"        scores = []
        downsample = 32
",4
"
            downsample //= 2

",4
"        yolo_boxes = fluid.layers.concat(boxes, axis=1)
        yolo_scores = fluid.layers.concat(scores, axis=2)
        pred = fluid.layers.multiclass_nms(
",4
"    data = base64.b64decode(b64str.encode('utf8'))
",4
"def get_save_image_name(img, output_dir, image_path):
    """"""Get save image name from source image path.
    """"""
",4
"    name, ext = os.path.splitext(image_name)

",4
"
def clip_bbox(bbox, img_width, img_height):
    xmin = max(min(bbox[0], img_width), 0.)
    ymin = max(min(bbox[1], img_height), 0.)
",4
"                score_thresh,
                label_names,
                output_dir,
",4
"    Args:
        paths (list[str]): The paths of images.
",4
"        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
        data_out (lod_tensor): data output of predictor.
",4
"            data (dict): the result of object detection, keys include 'left', 'top', 'right', 'bottom', 'label', 'confidence', the corresponding value is:
                left (float): The X coordinate of the upper left corner of the bounding box;
                top (float): The Y coordinate of the upper left corner of the bounding box;
                right (float): The X coordinate of the lower right corner of the bounding box;
",4
"                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
",4
"
    assert type(paths) is list, ""type(paths) is not list.""
",4
"    if handle_id < len(paths):
        unhandled_paths = paths[handle_id:]
        unhandled_paths_num = len(unhandled_paths)
    else:
",4
"        unhandled_paths_num = 0

    output = list()
    for index in range(len(lod) - 1):
",4
"        org_img_height = org_img.height
        org_img_width = org_img.width
        result_i = results[lod[index]:lod[index + 1]]
        for row in result_i:
",4
"
        output.append(output_i)
",4
"from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay

",4
"
    def __init__(self,
                 depth=53,
",4
"
    def _conv_norm(self,
                   input,
                   ch_out,
                   filter_size,
",4
"                   stride,
                   padding,
                   act='leaky',
",4
"            regularizer=L2Decay(float(self.norm_decay)),
",4
"                    padding=1,
",4
"            name=name)

    def basicblock(self, input, ch_out, name=None):
        conv1 = self._conv_norm(
            input,
",4
"    def __call__(self, input):
        """"""Get the backbone of DarkNet, that is output for the 5 stages.

        :param input: Variable of input image
",4
"            stride=1,
            padding=1,
",4
"        blocks = []
        for i, stage in enumerate(stages):
            block = self.layer_warp(
                block_func=block_func,
                input=downsample_,
",4
"        if self.model_type == 'SEResNeXt':
            bn_name = name + ""_bn""
        return bn_name
",4
"        if count > 10 and stage_num == 4:
            if i == 0:
                conv_name = name + ""a""
            else:
",4
"    def fix_c1_stage_name(self):
        return ""res_conv1"" if self.model_type == 'ResNeXt' else ""conv1""
# coding=utf-8
from __future__ import absolute_import
from __future__ import division
",4
"
from faster_rcnn_resnet50_coco2017.processor import load_label_info, postprocess, base64_to_cv2
from faster_rcnn_resnet50_coco2017.data_feed import test_reader, padding_minibatch
from faster_rcnn_resnet50_coco2017.resnet import ResNet, ResNetC5
from faster_rcnn_resnet50_coco2017.rpn_head import AnchorGenerator, RPNTargetAssign, GenerateProposals, RPNHead
",4
"from faster_rcnn_resnet50_coco2017.bbox_head import MultiClassNMS, BBoxHead, SmoothL1Loss
",4
"from faster_rcnn_resnet50_coco2017.bbox_assigner import BBoxAssigner
from faster_rcnn_resnet50_coco2017.roi_extractor import RoIAlign


",4
"    type=""cv/object_detection"",
    summary=
    ""Baidu's Faster R-CNN model for object detection with backbone ResNet50, trained with dataset COCO2017"",
",4
"    def _initialize(self):
        # default pretrained model, Faster-RCNN with backbone ResNet50, shape of input tensor is [3, 800, 1333]
        self.default_pretrained_model_path = os.path.join(
            self.directory, ""faster_rcnn_resnet50_model"")
",4
"    def _set_config(self):
",4
"            trainable (bool): whether to set parameters trainable.
            pretrained (bool): whether to load default pretrained model.
            phase (str): optional choices are 'train' and 'predict'.

",4
"                im_info = fluid.layers.data(
                    name='im_info', shape=[3], dtype='float32', lod_level=0)
                im_shape = fluid.layers.data(
                    name='im_shape', shape=[3], dtype='float32', lod_level=0)
                body_feat_names = list(body_feats.keys())
",4
"                    sampling_ratio=roi_extractor.sampling_ratio)
                # head_feat
                bbox_head = self.bbox_head(num_classes)
                head_feat = bbox_head.head(roi_feat)
                if isinstance(head_feat, OrderedDict):
",4
"                        'im_shape': var_prefix + im_shape.name,
                        'gt_class': var_prefix + gt_class.name,
                        'gt_bbox': var_prefix + gt_bbox.name,
",4
"                        'generate_proposal_labels':
                        [var_prefix + var.name for var in outs]
                    }
",4
"                        if num_classes != 81:
                            if 'bbox_pred' in var.name or 'cls_score' in var.name:
                                return False
                        return os.path.exists(
",4
"
                    fluid.io.load_vars(
                        exe,
                        self.default_pretrained_model_path,
                        predicate=_if_exist)
",4
"            fg_fraction=0.25,
            fg_thresh=0.5,
            class_nums=num_classes)

",4
"            model_filename=model_filename,
            params_filename=params_filename)

    def object_detection(self,
",4
"                         paths=None,
                         images=None,
                         data=None,
                         use_gpu=False,
                         batch_size=1,
",4
"        Args:
            paths (list[str]): The paths of images.
            images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
            batch_size (int): batch size.
",4
"            use_gpu (bool): Whether to use gpu.
            output_dir (str): The path to store output images.
            visualization (bool): Whether to save image or not.
            score_thresh (float): threshold for object detecion.
",4
"            ]
            if use_gpu:
",4
"            else:
                data_out = self.cpu_predictor.run(feed_list)
",4
"                label_names=self.label_names,
                output_dir=output_dir,
                handle_id=handle_id,
",4
"
    @runnable
",4
"            prog=""hub run {}"".format(self.name),
",4
"            title=""Config options"",
            description=
",4
"                        ""File %s or %s is not exist."" % image_path)
        return self.object_detection(
            paths=input_data, use_gpu=args.use_gpu, batch_size=args.batch_size)
",4
"        super(BBoxAssigner, self).__init__()
        self.batch_size_per_im = batch_size_per_im
        self.fg_fraction = fg_fraction
",4
"    ""no_bias"": True,
    ""use_maxpool"": False,
    ""use_softmax"": True,
",4
"                                    initializer = fluid.initializer.Normal(loc = 0.0,
                                    scale = nonlocal_params[""conv_init_std""])), \
                                bias_attr = ParamAttr(name = prefix + '_theta' + ""_b"", \
",4
"                                        if not nonlocal_params[""no_bias""] else False, \
                                name = prefix + '_theta')
    theta_shape = theta.shape
",4
"                                        pool_size = [max_pool_stride, max_pool_stride], \
                                        pool_type = 'max', \
                                        pool_stride = [max_pool_stride, max_pool_stride], \
                                        pool_padding = [0, 0], \
",4
"    else:
        max_pool = cur

",4
"    # we have to use explicit batch size (to support arbitrary spacetime size)
    # e.g. (8, 1024, 4, 14, 14) => (8, 1024, 784)
    theta = fluid.layers.reshape(theta, shape=(0, 0, -1))
    theta = fluid.layers.transpose(theta, [0, 2, 1])
",4
"    phi = fluid.layers.reshape(phi, [0, 0, -1])
    theta_phi = fluid.layers.matmul(theta, phi, name=prefix + '_affinity')
",4
"    else:
        # not clear about what is doing in xlw's code
        p = None  # not implemented
        raise ""Not implemented when not use softmax""
",4
"from PIL import Image, ImageEnhance
from paddle import fluid

",4
"    Args:
        paths (list[str]): paths to images.
",4
"        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

",4
"    img_list = list()
    if paths:
        for img_path in paths:
            assert os.path.isfile(
",4
"        mean = np.array(mean)[np.newaxis, np.newaxis, :]
        std = np.array(std)[np.newaxis, np.newaxis, :]
        im = im / 255.0
        im -= mean
        im /= std
",4
"def padding_minibatch(batch_data, coarsest_stride=0, use_padded_im_info=True):
    max_shape_org = np.array(
        [data['image'].shape for data in batch_data]).max(axis=0)
",4
"        # image
        padding_im = np.zeros((im_c, max_shape[1], max_shape[2]),
                              dtype=np.float32)
",4
"        padding_info.append(data['im_info'])
        padding_shape.append(data['im_shape'])

    padding_image = np.array(padding_image).astype('float32')
",4
"        self.variance = variance
        self.stride = stride

",4
"                 rpn_batch_size_per_im=256,
                 rpn_straddle_thresh=0.,
                 rpn_fg_fraction=0.5,
                 rpn_positive_overlap=0.7,
                 rpn_negative_overlap=0.3,
",4
"        self.rpn_batch_size_per_im = rpn_batch_size_per_im
        self.rpn_straddle_thresh = rpn_straddle_thresh
",4
"        self.use_random = use_random
",4
"class GenerateProposals(object):
    # __op__ = fluid.layers.generate_proposals
    def __init__(self,
                 pre_nms_top_n=6000,
",4
"    RPN Head

",4
"        num_classes (int): number of classes in rpn output
    """"""
    __inject__ = [
",4
"        self.num_classes = num_classes
",4
"            input(Variable): feature map from backbone with shape of [N, C, H, W]

",4
"        num_anchor = self.anchor.shape[2]
",4
"            act=None,
            name='rpn_bbox_pred',
",4
"            im_info(Variable): The information of image with shape [N, 3] with
                shape (height, width, scale).
            body_feat_names(list): A list of names of feature maps from
                backbone.

",4
"        Returns:
            rpn_rois(Variable): Output proposals with shape of (rois_num, 4).
        """"""
        # In RPN Heads, only the last feature map of backbone is used.
",4
"            rpn_cls_prob = fluid.layers.transpose(
                rpn_cls_prob, perm=[0, 3, 1, 2])
        prop_op = self.train_proposal if mode == 'train' else self.test_proposal
        # prop_op
        rpn_rois, rpn_roi_probs = fluid.layers.generate_proposals(
",4
"            post_nms_top_n=prop_op.post_nms_top_n,
            nms_thresh=prop_op.nms_thresh,
",4
"        rpn_cls_score = fluid.layers.reshape(
            x=rpn_cls_score, shape=(0, -1, self.num_classes))
",4
"            if not getattr(self, attr, None):
",4
"                raise ValueError(""self.{} should not be None,"".format(attr),
                                 ""call RPNHead.get_proposals first"")
        return self._transform_input(self.rpn_cls_score, self.rpn_bbox_pred,
                                     self.anchor, self.anchor_var)
",4
"
",4
"        """"""
        rpn_cls, rpn_bbox, anchor, anchor_var = self._get_loss_input()
",4
"                    cls_logits=rpn_cls,
                    anchor_box=anchor,
",4
"                    is_crowd=is_crowd,
                    im_info=im_info,
                    rpn_batch_size_per_im=self.rpn_target_assign.rpn_batch_size_per_im,
",4
"                    rpn_straddle_thresh=self.rpn_target_assign.rpn_straddle_thresh,
                    rpn_fg_fraction=self.rpn_target_assign.rpn_fg_fraction,
                    rpn_positive_overlap=self.rpn_target_assign.rpn_positive_overlap,
                    rpn_negative_overlap=self.rpn_target_assign.rpn_negative_overlap,
",4
"                logits=score_pred, label=labels_int64, numeric_stable_mode=True)

        rpn_cls_loss = fluid.layers.reduce_mean(
            rpn_cls_loss, name='loss_rpn_cls')
",4
"        score_shape = fluid.layers.shape(score_tgt)
        score_shape = fluid.layers.cast(x=score_shape, dtype='float32')
",4
"
class RoIAlign(object):
    def __init__(self, resolution=7, spatial_scale=0.0625, sampling_ratio=0):
        super(RoIAlign, self).__init__()
",4
"        norm_decay (float): weight decay for normalization layer weights
        variant (str): ResNet variant, supports 'a', 'b', 'c', 'd' currently
        feature_maps (list): index of stages whose feature maps are returned
        dcn_v2_stages (list): index of stages who select deformable conv v2
        nonlocal_stages (list): index of stages who select nonlocal networks
",4
"                 variant='b',
                 feature_maps=[3, 4, 5],
                 dcn_v2_stages=[],
                 weight_prefix_name='',
",4
"
        if isinstance(feature_maps, Integral):
",4
"        self.norm_decay = norm_decay
        self.freeze_norm = freeze_norm
        self.variant = variant
",4
"        self._model_type = 'ResNet'
        self.feature_maps = feature_maps
        self.dcn_v2_stages = dcn_v2_stages
        self.depth_cfg = {
",4
"                     act=None,
",4
"            bias_attr=ParamAttr(initializer=Constant(0.0), name=name + "".b_0""),
            act=act,
",4
"        if self.freeze_norm:
",4
"        std_senet = getattr(self, 'std_senet', False)
        if ch_in != ch_out or stride != 1 or (self.depth < 50 and is_first):
            if std_senet:
                if is_first:
                    return self._conv_norm(input, ch_out, 1, stride, name=name)
",4
"                   name,
                   dcn_v2=False):
        if self.variant == 'a':
            stride1, stride2 = stride, 1
        else:
",4
"            residual = self._conv_norm(
                input=residual,
                num_filters=c,
                filter_size=k,
                stride=s,
",4
"            input,
            num_filters * expand,
",4
"        short = self._shortcut(
            input, num_filters, stride, is_first, name=name + ""_branch1"")
        return fluid.layers.elementwise_add(x=short, y=conv1, act='relu')

    def layer_warp(self, input, stage_num):
",4
"        stages, block_func = self.depth_cfg[self.depth]
        count = stages[stage_num - 2]
",4
"        conv = input
        for i in range(count):
",4
"            dim_in = conv.shape[1]
",4
"                                          nonlocal_name + '_{}'.format(i),
",4
"                                          int(dim_in / 2))
        return conv

",4
"        conv1_name = self.na.fix_c1_stage_name()

        if self.variant in ['c', 'd']:
",4
"
        for i in feature_maps:
            res = self.layer_warp(res, i)
            if i in self.feature_maps:
                res_endpoints.append(res)
",4
"            if self.freeze_at >= i:
                res.stop_gradient = True
        if self.get_prediction:
            pool = fluid.layers.pool2d(
",4
"    """"""
",4
"            if img.mode == ""RGB"" or img.mode == ""L"":
                ext = "".jpg""
            elif img.mode == ""RGBA"" or img.mode == ""P"":
                ext = '.png'
",4
"
",4
"def draw_bounding_box_on_image(image_path, data_list, save_dir):
    image = Image.open(image_path)
    draw = ImageDraw.Draw(image)
    for data in data_list:
",4
"        draw.line([(left, top), (left, bottom), (right, bottom), (right, top),
",4
"            draw.rectangle(
                xy=(left, top - (textsize_height + 5),
                    left + textsize_width + 10, top),
                fill=(255, 255, 255))
",4
"                bottom (float): The Y coordinate of the lower right corner of the bounding box;
                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
",4
"            org_img = Image.fromarray(org_img[:, :, ::-1])
            if visualization:
                org_img_path = get_save_image_name(
",4
"            confidence = row[1]
            bbox = row[2:]
            dt = {}
            dt['label'] = label_names[category_id]
            dt['confidence'] = float(confidence)
",4
"    return output
# coding=utf-8
",4
"from __future__ import absolute_import
",4
"from __future__ import division
",4
"from paddle.fluid.regularizer import L2Decay
from paddle.fluid.initializer import MSRA


",4
"class MultiClassNMS(object):
    # __op__ = fluid.layers.multiclass_nms
    def __init__(self,
",4
"                 score_threshold=.05,
                 nms_top_k=-1,
                 keep_top_k=100,
",4
"                 background_label=0):
        super(MultiClassNMS, self).__init__()
        self.score_threshold = score_threshold
",4
"        self.nms_threshold = nms_threshold
        self.normalized = normalized
        self.nms_eta = nms_eta
        self.background_label = background_label
",4
"
class BoxCoder(object):
",4
"
    Args:
        head (object): the head module instance, e.g., `ResNetC5`, `TwoFCHead`
        box_coder (object): `BoxCoder` instance
",4
"        nms (object): `MultiClassNMS` instance
        num_classes: number of output classes
    """"""
",4
"    __inject__ = ['head', 'box_coder', 'nms', 'bbox_loss']
    __shared__ = ['num_classes']

",4
"    def __init__(self,
                 head,
                 box_coder=BoxCoder(),
                 nms=MultiClassNMS(),
                 bbox_loss=SmoothL1Loss(),
",4
"        super(BBoxHead, self).__init__()
        self.head = head
",4
"        """"""
",4
"        Get the bbox head feature map.
        """"""

        if input is not None:
",4
"            roi_feat (Variable): RoI feature from RoIExtractor.
",4
"        """"""
        head_feat = self.get_head_feat(roi_feat)
        # when ResNetC5 output a single feature map
        if not isinstance(self.head, TwoFCHead):
",4
"                head_feat, pool_type='avg', global_pooling=True)
        cls_score = fluid.layers.fc(
            input=head_feat,
",4
"            name='cls_score',
            param_attr=ParamAttr(
",4
"            bias_attr=ParamAttr(
                name='bbox_pred_b', learning_rate=2., regularizer=L2Decay(0.)))
        return cls_score, bbox_pred

    def get_loss(self, roi_feat, labels_int32, bbox_targets,
",4
"        """"""

        cls_score, bbox_pred = self._get_output(roi_feat)

        labels_int64 = fluid.layers.cast(x=labels_int32, dtype='int64')
",4
"            rois (Variable): Output of generate_proposals in rpn head.
            im_info (Variable): A 2-D LoDTensor with shape [B, 3]. B is the
                number of input images, each element consists of im_height,
                im_width, im_scale.
",4
"            im_shape (Variable): Actual shape of original image with shape
                [B, 3]. B is the number of images, each element consists of
                original_height, original_width, 1

        Returns:
",4
"            pred_result(Variable): Prediction result with shape [N, 6]. Each
                row has 6 values: [label, confidence, xmin, ymin, xmax, ymax].
",4
"                N is the total number of prediction.
        """"""
",4
"import ast
",4
"
        Args:
            trainable (bool): whether to set parameters trainable.
",4
"                    name='im_size', shape=[2], dtype='int32')
                # yolo_head
                yolo_head = YOLOv3Head(num_classes=708)
",4
"                    outputs = {
                        'head_features':
                        [var_prefix + var.name for var in head_features],
                        'body_features':
                        [var_prefix + var.name for var in body_features]
",4
"                        context_prog.global_block().vars[varname]
                        for varname in value
                    ]
                    for key, value in outputs.items()
                }
",4
"                # trainable
                for param in context_prog.global_block().iter_parameters():
                    param.trainable = trainable
",4
"                # pretrained
                if pretrained:

                    def _if_exist(var):
                        return os.path.exists(
",4
"                        exe,
                        self.default_pretrained_model_path,
                        predicate=_if_exist)
                else:
",4
"                return inputs, outputs, context_prog
# coding=utf-8
",4
"from __future__ import division

import os

",4
"        paths (list[str]): paths to images.
        images (list(numpy.ndarray)): data of images, shape of each is [H, W, C]

    Yield:
",4
"            assert os.path.isfile(
                img_path), ""The {} isn't a valid file path."".format(img_path)
            img = cv2.imread(img_path).astype('float32')
            img_list.append(img)
    if images is not None:
",4
"        if float(im_size_min) == 0:
",4
"
        im_scale_x = float(target_size) / float(im_shape[1])
        im_scale_y = float(target_size) / float(im_shape[0])
        im = cv2.resize(
",4
"    Args:
        norm_decay (float): weight decay for normalization layer weights
        num_classes (int): number of output classes
        ignore_thresh (float): threshold to ignore confidence loss
        label_smooth (bool): whether to use label smoothing
",4
"        anchors (list): anchors
        anchor_masks (list): anchor masks
        nms (object): an instance of `MultiClassNMS`
    """"""
",4
"        self.label_smooth = label_smooth
        self.anchor_masks = anchor_masks
        self._parse_anchors(anchors)
        self.nms = nms
        self.prefix_name = weight_prefix_name
",4
"
    def _conv_bn(self,
                 input,
                 ch_out,
",4
"                 name=None):
        conv = fluid.layers.conv2d(
",4
"        bn_name = name + "".bn""
",4
"        bn_param_attr = ParamAttr(
            regularizer=L2Decay(self.norm_decay), name=bn_name + '.scale')
        bn_bias_attr = ParamAttr(
            regularizer=L2Decay(self.norm_decay), name=bn_name + '.offset')
        out = fluid.layers.batch_norm(
",4
"                conv,
",4
"                channel,
",4
"            is_test=is_test,
            name='{}.2'.format(name))
        tip = self._conv_bn(
",4
"            filter_size=3,
",4
"        out = fluid.layers.resize_nearest(
",4
"
        """"""
",4
"        assert len(anchors) > 0, ""ANCHORS not set.""
        assert len(self.anchor_masks) > 0, ""ANCHOR_MASKS not set.""

        for anchor in anchors:
",4
"            outputs (list): Variables of each output layer
        """"""

        outputs = []
",4
"
",4
"                num_filters=num_filters,
                filter_size=1,
                stride=1,
",4
"
        return outputs, blocks

    def get_prediction(self, outputs, im_size):
",4
"
        Returns:
            pred (Variable): The prediction result after non-max suppress.

        """"""
",4
"                img_size=im_size,
                anchors=self.mask_anchors[i],
                class_num=self.num_classes,
                conf_thresh=self.nms.score_threshold,
",4
"        pred = fluid.layers.multiclass_nms(
            bboxes=yolo_boxes,
            scores=yolo_scores,
",4
"            nms_top_k=self.nms.nms_top_k,
            keep_top_k=self.nms.keep_top_k,
            nms_threshold=self.nms.nms_threshold,
            background_label=self.nms.background_label,
",4
"    return data
",4
"
",4
"def get_save_image_name(img, output_dir, image_path):
    """"""Get save image name from source image path.
    """"""
    image_name = os.path.split(image_path)[-1]
",4
"            ext = '.jpg'
",4
"    image = Image.open(image_path)
    draw = ImageDraw.Draw(image)
    for data in data_list:
",4
"def load_label_info(file_path):
    with open(file_path, 'r') as fr:
",4
"    Args:
        paths (list[str]): The paths of images.
        images (list(numpy.ndarray)): images data, shape of each is [H, W, C]
",4
"        use_gpu (bool): Whether to use gpu.
",4
"
    Returns:
",4
"                label (str): The label of detection result;
                confidence (float): The confidence of detection result.
            save_path (str): The path to save output images.
",4
"    """"""
",4
"    if handle_id < len(paths):
",4
"
    output = list()
    for index in range(len(lod) - 1):
        output_i = {'data': []}
",4
"        if index < unhandled_paths_num:
            org_img_path = unhandled_paths[index]
            org_img = Image.open(org_img_path)
        else:
",4
"            org_img = Image.fromarray(org_img[:, :, ::-1])
",4
"            confidence = row[1]
",4
"
        output.append(output_i)
        if visualization:
            output_i['save_path'] = draw_bounding_box_on_image(
",4
"from paddle import fluid
from paddle.fluid.param_attr import ParamAttr
from paddle.fluid.regularizer import L2Decay

__all__ = ['DarkNet']
",4
"        get_prediction (bool): whether to get prediction
        class_dim (int): number of class while classification
",4
"        self.prefix_name = weight_prefix_name
        self.class_dim = class_dim
        self.get_prediction = get_prediction

    def _conv_norm(self,
",4
"            input=input,
            num_filters=ch_out,
            filter_size=filter_size,
            stride=stride,
",4
"        return out

    def _downsample(self,
                    input,
",4
"            stride=stride,
            padding=padding,
            name=name)

",4
"        stages, block_func = self.depth_cfg[self.depth]
        stages = stages[0:5]
",4
"        conv = self._conv_norm(
            input=input,
            ch_out=32,
            filter_size=3,
            stride=1,
",4
"            padding=1,
            name=self.prefix_name + ""yolo_input"")
        downsample_ = self._downsample(
            input=conv,
            ch_out=conv.shape[1] * 2,
",4
"                param_attr=ParamAttr(
                    initializer=fluid.initializer.Uniform(-stdv, stdv),
                    name='fc_weights'),
",4
"        else:
            return blocks
# coding=utf-8
",4
"        self._set_config()

    def _set_config(self):
",4
"            gpu_config_dec = AnalysisConfig(self.pretrained_decoder_net)
            gpu_config_dec.disable_glog_info()
            gpu_config_dec.enable_use_gpu(
                memory_pool_init_size_mb=1000, device_id=0)
            self.gpu_predictor_dec = create_paddle_predictor(gpu_config_dec)
",4
"                content(str): value is a numpy.ndarry with shape [H, W, C], content data.
                styles(str): value is a list of numpy.ndarray with shape [H, W, C], styles data.
                weights(str, optional): value is the interpolation weights correspond to styles.
",4
"            paths (list): list of dict objects, each dict contains key:
                content(str): value is the path to content.
",4
"            visualization (bool): whether to save image or not.

",4
"            im_output (list[dict()]): list of output images and save path of images.
        """"""
        if use_gpu:
",4
"            content = PaddleTensor(component['content_arr'].copy())
            content_feats = self.gpu_predictor_enc.run(
",4
"        decode_dirname = os.path.join(dirname, 'decoder')
",4
"        place = fluid.CPUPlace()
        exe = fluid.Executor(place)
",4
"
    def _save_decode_model(self,
",4
"            main_program=decode_program,
            executor=exe,
            feeded_var_names=decode_feeded_var_names,
            target_vars=decode_target_vars,
",4
"                'content': args.content,
                'styles': args.styles.split(','),
",4
"        """"""
        self.arg_config_group.add_argument(
",4
"            type=ast.literal_eval,
            default=False,
            help=""whether use GPU or not"")
        self.arg_config_group.add_argument(
",4
"            type=ast.literal_eval,
            default=True,
            help=""whether to save output as images."")
",4
"    def add_module_input_arg(self):
        """"""
        Add the command input options.
        """"""
",4
"            '--styles', type=str, help=""path to styles."")
        self.arg_input_group.add_argument(
            '--weights',
",4
"        pad_value=0.0,
        mode='reflect',
        paddings=[1, 1, 1, 1],
        name='x2paddle_22')
",4
"    x2paddle_23 = fluid.layers.conv2d(
        x2paddle_22,
        num_filters=64,
        filter_size=[3, 3],
",4
"    x2paddle_24 = fluid.layers.relu(x2paddle_23, name='x2paddle_24')
    x2paddle_25 = fluid.layers.pad2d(
        x2paddle_24,
        pad_value=0.0,
",4
"        dilation=[1, 1],
",4
"        ceil_mode=False,
        name='x2paddle_28',
        exclusive=False)
    x2paddle_29 = fluid.layers.pad2d(
",4
"    x2paddle_36 = fluid.layers.pad2d(
",4
"        stride=[1, 1],
",4
"    x2paddle_38 = fluid.layers.relu(x2paddle_37, name='x2paddle_38')
    x2paddle_39 = fluid.layers.pad2d(
        x2paddle_38,
        pad_value=0.0,
",4
"        filter_size=[3, 3],
        stride=[1, 1],
        padding=[0, 0],
",4
"        paddings=[1, 1, 1, 1],
        name='x2paddle_42')
    x2paddle_43 = fluid.layers.conv2d(
        x2paddle_42,
",4
"        num_filters=256,
        filter_size=[3, 3],
        stride=[1, 1],
        padding=[0, 0],
        dilation=[1, 1],
",4
"        groups=1,
        param_attr='x2paddle_17',
",4
"        name='x2paddle_46',
        bias_attr='x2paddle_18')
",4
"        paddings=[1, 1, 1, 1],
        name='x2paddle_49')
    x2paddle_50 = fluid.layers.conv2d(
",4
"        if data is not None:
            for component in data:
",4
"                ]
",4
"
",4
"
def _handle_single(im_path=None, im_arr=None):
    """"""
",4
"    if im_path is not None:
",4
"# coding=utf-8
",4
"import os

",4
"

",4
"    Writes all values from the Tensor src into dst at the indices specified in the index Tensor.

    :param dim: The axis along which to index
",4
"    if (index >= dst.shape[dim]).any() or (index < 0).any():
        raise IndexError(""The values of index must be between 0 and {}."".format(
            dst.shape[dim] - 1))
",4
"        slc = [slice(None)] * arr.ndim
",4
"    if not np.isscalar(src):
        if index.shape[dim] > src.shape[dim]:
            raise IndexError(""Dimension "" + str(dim) +
                             ""of index can not be bigger than that of src "")
",4
"        default_initializer=Constant(0.0))
    x2paddle_36 = fluid.layers.create_parameter(
        dtype='float32',
",4
"        name='x2paddle_36',
",4
"    x2paddle_19 = fluid.layers.pad2d(
        x2paddle_input_1,
",4
"        num_filters=256,
        filter_size=[3, 3],
        stride=[1, 1],
",4
"        name='x2paddle_24')
    x2paddle_25 = fluid.layers.conv2d(
        x2paddle_24,
        num_filters=256,
        filter_size=[3, 3],
",4
"        name='x2paddle_25',
        bias_attr='x2paddle_4')
    x2paddle_26 = fluid.layers.relu(x2paddle_25, name='x2paddle_26')
",4
"        name='x2paddle_34',
        bias_attr='x2paddle_10')
",4
"    x2paddle_39 = fluid.layers.conv2d(
        x2paddle_38,
        num_filters=128,
        filter_size=[3, 3],
        stride=[1, 1],
",4
"        padding=[0, 0],
        dilation=[1, 1],
        groups=1,
        param_attr='x2paddle_11',
        name='x2paddle_39',
",4
"    x2paddle_43 = fluid.layers.relu(x2paddle_42, name='x2paddle_43')
    x2paddle_45 = fluid.layers.resize_nearest(
",4
"        x2paddle_43, name='x2paddle_45', out_shape=[512, 512])
    x2paddle_46 = fluid.layers.pad2d(
        x2paddle_45,
        pad_value=0.0,
",4
"        param_attr='x2paddle_15',
        name='x2paddle_47',
",4
"        x2paddle_48,
        pad_value=0.0,
",4
"        padding=[0, 0],
        dilation=[1, 1],
        groups=1,
",4
"import videotag_tsn_lstm.resource.models as models
",4
"
",4
"            with fluid.program_guard(predictor_main_prog,
                                     predictor_startup_prog):
                # parse config
                predictor_config = parse_config(args.predictor_config)
",4
"                predictor_infer_config = merge_configs(predictor_config,
                                                       'infer', vars(args))

                predictor_model = models.get_model(
",4
"                    ""AttentionLSTM"", predictor_infer_config, mode='infer')
",4
"    @runnable
    def run_cmd(self, argsv):
        args = self.parser.parse_args(argsv)
",4
"        args.extractor_weights = os.path.join(self.directory, 'weights', 'tsn')
",4
"
        extractor_config = parse_config(args.extractor_config)
        extractor_infer_config = merge_configs(extractor_config, 'infer',
                                               vars(args))
        extractor_reader = get_reader(""TSN"", 'infer', extractor_infer_config)
",4
"            predictor_feed_list.append((predictor_feed_data, file_list[i]))

",4
"#distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"import sys
import signal
import logging

",4
"            self[key] = value
",4
"
",4
"def check_cuda(use_cuda, err = \
    ""\nYou can not set use_gpu = True in the model because you are using paddlepaddle-cpu.\n \
",4
"    """"""
",4
"#Licensed under the Apache License, Version 2.0 (the ""License"");
#you may not use this file except in compliance with the License.
",4
"
from .utility import AttrDict

logger = logging.getLogger(__name__)
",4
"]


",4
"
def create_attr_dict(yaml_config):
    from ast import literal_eval
    for key, value in yaml_config.items():
",4
"        if type(value) is dict:
            yaml_config[key] = value = AttrDict(value)
",4
"            continue
        try:
            if hasattr(sec_dict, k):
                setattr(sec_dict, k, v)
",4
"
",4
"    logger.info(
        ""---------------- {:>5} Arguments ----------------"".format(mode))
    for sec, sec_items in cfg.items():
",4
"def log_lr_and_step():
",4
"            lr_count = np.array(lr_count_var.get_tensor())
        logger.info(
            ""------- learning rate {}, learning rate counter {} -----"".format(
                np.array(lr), np.array(lr_count)))
",4
"    test_iter = 0
",4
"        train_iter = 0
        epoch_periods = []

        for data in train_dataloader():
            cur_time = time.time()
",4
"            train_iter += 1

            # NOTE: profiler tools, used for benchmark
",4
"                profiler.stop_profiler(""total"", profiler_path)
                return

",4
"        if len(epoch_periods) < 1:
            logger.info(
                'No iteration was executed, please check the data reader')
            sys.exit(1)
",4
"            exe,
",4
"                epoch + 1) % valid_interval == 0:
            test_with_dataloader(exe, compiled_test_prog, test_dataloader,
                                 test_fetch_list, test_metrics, log_interval,
                                 save_model_name)
",4
"
def save_model(exe,
               program,
",4
"        os.makedirs(save_dir)
    saved_model_name = model_name + postfix

    fluid.save(program, os.path.join(save_dir, saved_model_name))
",4
"
    return
",4
"

",4
"class NotImplementError(Exception):
    ""Error: model function not implement""

    def __init__(self, model, function):
",4
"        raise NotImplementError(self, self.optimizer)
",4
"
    def loss(self):
",4
"    def weights_info(self):
        ""get model weight default path and download url""
        raise NotImplementError(self, self.weights_info)

",4
"        return (None, None)

    def load_pretrain_params(self, exe, pretrain, prog, place):
",4
"        if sec.upper() not in self.cfg:
            return default
",4
"    def __init__(self):
        self.model_zoo = {}

    def regist(self, name, model):
        assert model.__base__ == ModelBase, ""Unknow model type {}"".format(
",4
"            type(model))
        self.model_zoo[name] = model

",4
"import json

depth = [3, 4, 23, 3]
",4
"params_list.append(bn_name + '_offset')
params_list.append(bn_name + '_mean')
params_list.append(bn_name + '_variance')

",4
"for block in range(len(depth)):
    for i in range(depth[block]):
        if block == 2:
",4
"            if i == 0:
                name = ""res"" + str(block + 2) + ""a""
            else:
                name = ""res"" + str(block + 2) + ""b"" + str(i)
        else:
",4
"            caffe_bn_name = 'BatchNormBackward' + str(layer_index) + '_bn'
            caffe_param_list.append(caffe_bn_name + '_scale')
            caffe_param_list.append(caffe_bn_name + '_offset')
            caffe_param_list.append(caffe_bn_name + '_mean')
            caffe_param_list.append(caffe_bn_name + '_variance')
",4
"#You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
",4
"import time
import sys
import paddle.fluid as fluid
",4
"                      stride=1,
                      groups=1,
                      act=None,
                      name=None):
        conv = fluid.layers.conv2d(
",4
"            bn_name = ""bn_"" + name
        else:
            bn_name = ""bn"" + name[3:]

",4
"            is_test=(not self.is_training),
            param_attr=fluid.param_attr.ParamAttr(name=bn_name + ""_scale""),
            bias_attr=fluid.param_attr.ParamAttr(bn_name + '_offset'),
            moving_mean_name=bn_name + ""_mean"",
",4
"            name=name + ""_branch2a"")
        conv1 = self.conv_bn_layer(
",4
"        short = self.shortcut(
            input, num_filters * 4, stride, name=name + ""_branch1"")

        return fluid.layers.elementwise_add(x=short, y=conv2, act='relu')
",4
"        supported_layers = [50, 101, 152]
",4
"            depth = [3, 8, 36, 3]
        num_filters = [64, 128, 256, 512]

        conv = self.conv_bn_layer(
            input=input,
",4
"                if layers in [101, 152] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
                        conv_name = ""res"" + str(block + 2) + ""b"" + str(i)
",4
"                else:
",4
"#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.
#
",4
"#    http://www.apache.org/licenses/LICENSE-2.0
",4
"#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"        self.num_epochs = self.get_config_from_sec('train', 'epoch')
        self.total_videos = self.get_config_from_sec('train', 'total_videos')
        self.base_learning_rate = self.get_config_from_sec(
",4
"        self.batch_size = self.get_config_from_sec(self.mode, 'batch_size')

    def build_input(self, use_dataloader=True):
",4
"        image_shape = [3, self.target_size, self.target_size]
",4
"        image_shape[0] = image_shape[0] * self.seglen
        image_shape = [None, self.seg_num] + image_shape
        self.use_dataloader = use_dataloader

",4
"        if self.mode != 'infer':
            label = fluid.data(name='label', shape=[None, 1], dtype='int64')
        else:
            label = None

",4
"            self.dataloader = fluid.io.DataLoader.from_generator(
                feed_list=[image, label], capacity=4, iterable=True)

        self.feature_input = [image]
",4
"            input=self.feature_input[0], class_dim=cfg['class_dim'])
",4
"        momentum = self.momentum
",4
"        self.loss_ = fluid.layers.mean(x=cost)
        return self.loss_

    def outputs(self):
",4
"        return self.network_outputs

",4
"        elif self.mode == 'test':
            #losses = self.loss()
",4
"            'https://paddlemodels.bj.bcebos.com/video_classification/ResNet50_pretrained.tar.gz'
        )

    def weights_info(self):
",4
"            'https://paddlemodels.bj.bcebos.com/video_classification/TSN.pdparams'
        )

",4
"    def load_pretrain_params(self, exe, pretrain, prog, place):
        def is_parameter(var):
            return isinstance(var, fluid.framework.Parameter)

        params_list = list(filter(is_parameter, prog.list_vars()))
",4
"        for param in params_list:
            print(param.name)

",4
"#        state_dict = np.load(weights)
",4
"#        for p in params_list:
#            if p.name in state_dict.keys():
#                print('########### load param {} from file'.format(p.name))
#            else:
",4
"#Licensed under the Apache License, Version 2.0 (the ""License"");
#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at
",4
"        self.feature_num = self.cfg.MODEL.feature_num
        self.feature_names = self.cfg.MODEL.feature_names
        self.feature_dims = self.cfg.MODEL.feature_dims
        self.num_classes = self.cfg.MODEL.num_classes
        self.embedding_size = self.cfg.MODEL.embedding_size
",4
"        self.batch_size = self.get_config_from_sec(self.mode, 'batch_size', 1)
        self.num_gpus = self.get_config_from_sec(self.mode, 'num_gpus', 1)

",4
"    def build_input(self, use_dataloader):
        self.feature_input = []
        for name, dim in zip(self.feature_names, self.feature_dims):
",4
"                feed_list=self.feature_input,  #+ [self.label_input],
                capacity=8,
                iterable=True)

",4
"        for i, (input_dim, feature) in enumerate(
                zip(self.feature_dims, self.feature_input)):
            att = LSTMAttentionModel(input_dim, self.embedding_size,
                                     self.lstm_size, self.drop_rate)
            att_out = att.forward(feature, is_training=(self.mode == 'train'))
",4
"            input=fc1,
            size=4096,
            act='tanh',
",4
"                              name = 'output')

        self.output = fluid.layers.sigmoid(self.logit)
",4
"
    def optimizer(self):
        assert self.mode == 'train', ""optimizer only can be get in train mode""
        values = [
            self.learning_rate * (self.decay_gamma**i)
",4
"
    def load_pretrain_params(self, exe, pretrain, prog, place):
        logger.info(
",4
"                    format(name))
",4
"
    def __init__(self,
                 bias_attr,
                 embedding_size=512,
                 lstm_size=1024,
",4
"        lstm_forward_fc = fluid.layers.fc(
            input=input_fc,
",4
"
",4
"            size=self.lstm_size * 4,
",4
"            name='rgb_lstm_backward')
",4
"
        return lstm_pool
from .attention_lstm import *
#  Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserve.
#
",4
"#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"
",4
"        self.seg_num = self.get_config_from_sec(mode, 'seg_num', self.seg_num)
        self.short_size = self.get_config_from_sec(mode, 'short_size')
        self.target_size = self.get_config_from_sec(mode, 'target_size')
        self.num_reader_threads = self.get_config_from_sec(
",4
"        self.filelist = cfg[mode.upper()]['filelist']

    def create_reader(self):
        _reader = self._reader_creator(self.filelist, self.mode, seg_num=self.seg_num, seglen = self.seglen, \
                         short_size = self.short_size, target_size = self.target_size, \
",4
"                         shuffle = (self.mode == 'train'), \
                         num_threads = self.num_reader_threads, \
                         buf_size = self.buf_size, format = self.format)

",4
"                        pickle_list,
                        mode,
                        seg_num,
                        seglen,
                        short_size,
",4
"                return None, None
",4
"                         short_size, target_size, img_mean, img_std, name = self.name), mp4_path

        def reader():
            lines = [line.strip() for line in pickle_list]
",4
"
",4
"                   short_size,
                   target_size,
                   img_mean,
                   img_std,
",4
"
    h_off = int(round((h - th) / 2.))
    w_off = int(round((w - tw) / 2.))

    img_crop = np_imgs[:, h_off:h_off + target_size, w_off:w_off +
",4
"    for i in range(len(imgs)):
        img = imgs[i]
        w, h = img.size
        if (w <= h and w == target_size) or (h <= w and h == target_size):
            resized_imgs.append(img)
",4
"            ow = int(target_size * 4.0 / 3.0)
            resized_imgs.append(img.resize((ow, oh), Image.BILINEAR))

    return resized_imgs
",4
"    sampledFrames = []
    for i in range(videolen):
        ret, frame = cap.read()
",4
"            idx = i

        for jj in range(idx, idx + seglen):
",4
"#
",4
"            self.reader_name)
        for reader in self.avail_readers:
",4
"    def create_reader(self):
        """"""Not implemented""""""
        pass

",4
"
# regist reader, sort by alphabet
",4
"
class Metrics(object):
",4
"        loss = np.mean(np.array(fetch_list[0]))
        pred = np.array(fetch_list[1])
        label = np.array(fetch_list[2])
        hit_at_one = youtube8m_metrics.calculate_hit_at_one(pred, label)
        perr = youtube8m_metrics.calculate_precision_at_equal_recall_rate(
",4
"            pred, label)
",4
"            video_id = fetch_list[1]
            for i in range(len(predictions)):
",4
"                topk_inds = predictions[i].argsort()[0 - self.topk:]
                topk_inds = topk_inds[::-1]
                preds = predictions[i][topk_inds]
                self.infer_results.append((video_id[i], topk_inds.tolist(),
",4
"            all_res_list = []
",4
"                    class_prob = item[2][i]
                    if class_prob < self.threshold:
                        continue
",4
"                    class_name = fl[class_id].split('\n')[0]
                    res[""prediction""][class_name] = class_prob
                if not res[""prediction""]:
                    logger.warning(
",4
"            epoch_info_dict = self.calculator.get()
",4
"            type(metrics))
        self.metrics_zoo[name] = metrics
",4
"        for k, v in self.metrics_zoo.items():
            if k == name:
                return v(name, mode, cfg)
        raise KeyError(name, self.metrics_zoo.keys())
",4
"
",4
"from . import mean_average_precision_calculator as map_calculator
",4
"
",4
"def calculate_hit_at_one(predictions, actuals):
    """"""Performs a local (numpy) calculation of the hit at one.

",4
"    aggregated_precision = 0.0
    num_videos = actuals.shape[0]
    for row in numpy.arange(num_videos):
",4
"                                         -num_labels)[-num_labels:]
        item_precision = 0.0
        for label_index in top_indices:
",4
"        aggregated_precision += item_precision
    aggregated_precision /= num_videos
",4
"

def calculate_gap(predictions, actuals, top_k=20):
",4
"        flatten(sparse_predictions), flatten(sparse_labels), sum(num_positives))
    return gap_calculator.peek_ap_at_n()
",4
"  Raises:
",4
"    m = len(predictions)
",4
"        self.sum_perr = 0.0
",4
"
    Args:
      predictions: A numpy matrix containing the outputs of the model.
",4
"      dictionary: A dictionary storing the metrics for the mini-batch.

",4
"        self.sum_hit_at_one += mean_hit_at_one * batch_size
        self.sum_perr += mean_perr * batch_size
        self.sum_loss += mean_loss * batch_size

        return {
",4
"        aps = self.map_calculator.peek_map_at_n()
        gap = self.global_ap_calculator.peek_ap_at_n()
",4
"
        epoch_info_dict = {}
        return {
            ""avg_hit_at_one"": avg_hit_at_one,
",4
"            ""gap"": gap
        }

    def clear(self):
",4
"        self.num_examples = 0
# Copyright 2016 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS-IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
",4
"list. After processing all the parts, we call peek_map_at_n
to calculate the mean average precision.

```
import random
",4
"    def __init__(self, num_class):
",4
"    Args:
      num_class: A positive Integer specifying the number of classes.
      top_n_array: A list of positive integers specifying the top n for each
",4
"      ValueError: An error occurred when the shape of predictions and actuals
      does not match.
    """"""
        if not num_positives:
            num_positives = [None for i in predictions.shape[1]]
",4
"                                      num_positives[i])

    def clear(self):
        for calculator in self._ap_calculators:
",4
"            calculator.clear()

    def is_empty(self):
        return ([calculator.heap_size for calculator in self._ap_calculators
                 ] == [0 for _ in range(self._num_class)])
",4
"```
",4
"
    Args:
",4
"        self._heap = []  # max heap of (prediction, actual)

    @property
    def heap_size(self):
",4
"    def accumulate(self, predictions, actuals, num_positives=None):
        """"""Accumulate the predictions and their ground truth labels.

",4
"        else:
            self._total_positives += numpy.size(numpy.where(actuals > 0))
        topk = self._top_n
        heap = self._heap

",4
"                if predictions[i] > heap[0][0]:  # heap[0] is the smallest
                    heapq.heappop(heap)
",4
"                    heapq.heappush(heap, (predictions[i], actuals[i]))

",4
"      If n is larger than the length of the ranked list,
      the average precision will be returned.
    """"""
        if self.heap_size <= 0:
",4
"      larger than 0 will be treated as positives, otherwise as negatives.
      n: the top n items to be considered in ap@n.
",4
"        predictions, actuals = AveragePrecisionCalculator._shuffle(
",4
"        if total_num_positives is None:
            numpos = numpy.size(numpy.where(actuals > 0))
        else:
",4
"            return 0
",4
"
        if n is not None:
            numpos = min(numpos, n)
        delta_recall = 1.0 / numpos
",4
"        poscount = 0.0

",4
"                ap += poscount / (i + 1) * delta_recall
",4
"    def _shuffle(predictions, actuals):
        random.seed(0)
        suffidx = random.sample(range(len(predictions)), len(predictions))
        predictions = predictions[suffidx]
        actuals = actuals[suffidx]
",4
"        return predictions, actuals

    @staticmethod
",4
"print(senta_test.sentiment_classify([""è¿é¨çµå½±å¤ªç³ç³äº"", ""è¿é¨çµå½±å¤ªæ£äº""]))
",4
"import argparse
import os
",4
"from paddlehub.module.module import runnable, moduleinfo

from senta_test.processor import load_vocab


",4
"    author_email="""",
    type=""nlp/sentiment_analysis"",
",4
")
class SentaTest(hub.Module):
    def _initialize(self):
        # add arg parser
",4
"                    break
            results.append({""text"": text, ""sentiment"": sentiment})

        return results

",4
"    @runnable
    def run_cmd(self, argvs):
        args = self.parser.parse_args(argvs)
        texts = [args.input_text]
",4
"parser = argparse.ArgumentParser()
",4
"
    def __init__(self):
",4
"    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count
",4
"
",4
"    if main_program is None:
        main_program = fluid.default_main_program()
",4
"            continue

        load_block.append_op(
            type='load',
",4
"def train():
    dataset = args.dataset
    image_shape = [3, 224, 224]
    pretrained_model = args.pretrained_model

",4
"                    strinfo.sub("""", l).replace(""\n"", """")
                    for l in item.split("", "")
                ]
                label_dict[key] = value[0]

",4
"
    # model ops
    image = fluid.data(
        name='image', shape=[None] + image_shape, dtype='float32')
    label = fluid.data(name='label', shape=[None, 1], dtype='int64')
",4
"    t_features, _ = t_model.net(input=image, class_dim=1000)
    for f in t_features.keys():
        t_features[f].stop_gradient = True

    # delta loss. hard code for the layer name, which is just before global pooling.
",4
"            else:
                print('\ttraining', param.name)
                parameters.append(param.name)
",4
"    optimizer = fluid.optimizer.Momentum(
        learning_rate=fluid.layers.piecewise_decay(
",4
"
    # running
",4
"    loading_parameters = {}
    t_loading_parameters = {}
    for p in main_program.all_parameters():
        if 'fc' not in p.name:
            if global_name in p.name:
",4
"                name = os.path.join(pretrained_model, p.name)
                loading_parameters[name] = p
                print(name, p.name)
        else:
",4
"    step = 0

    # test_data = reader_creator_all_in_memory('./datasets/PetImages', is_test=True)
    for e_id in range(args.num_epoch):
",4
"        avg_delta_loss = AverageMeter()
",4
"            # print(avg_loss_value[2])
",4
"                    f""\tEpoch {e_id}, Global_Step {step}, Batch_Time {batch_time.avg: .2f},""
                    f"" LR {wrapped_results[3][0]}, ""
                    f""Loss {avg_loss.avg: .4f}, Acc {avg_accuracy.avg: .4f}, Delta_Loss {avg_delta_loss.avg: .4f}""
                )
",4
"    model = ResNet101(is_test=True)
    _, logits = model.net(input=image, class_dim=reader_config.num_classes)
    out = fluid.layers.softmax(logits)

",4
"    start_program = fluid.default_startup_program()

",4
"        avg_loss_value = exe.run(
            main_program,
            feed=feeder.feed(data_train),
            fetch_list=[cost, accuracy])
        avg_loss.update(avg_loss_value[0], len(data_train))
",4
"        avg_accuracy.update(avg_loss_value[1], len(data_train))
",4
"    print(""test counts:"", avg_loss.count)
    print(""test_cost\t%f"" % avg_loss.avg)
",4
"#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at
#
",4
"#
#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an ""AS IS"" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#See the License for the specific language governing permissions and
",4
"    ""ResNet"", ""ResNet18"", ""ResNet34"", ""ResNet50"", ""ResNet101"", ""ResNet152""
]
",4
"        if layers >= 50:
            for block in range(len(depth)):
",4
"                        conv_name = ""res"" + str(block + 2) + chr(97 + i)
                    conv = self.bottleneck_block(
                        input=conv,
                        num_filters=num_filters[block],
                        stride=2 if i == 0 and block != 0 else 1,
",4
"                pool_type='avg',
                global_pooling=True,
                name=self.global_name + 'global_pooling',
",4
"                    name=self.global_name + 'fc_0.b_0'),
                param_attr=fluid.param_attr.ParamAttr(
",4
"                    name=self.global_name + 'fc_0.w_0',
                    initializer=fluid.initializer.Uniform(-stdv, stdv)))
",4
"            name=name + '.conv2d.output.1',
            data_format=data_format)

        if name == ""conv1"":
",4
"        return fluid.layers.batch_norm(
            input=conv,
            act=act,
            name=self.global_name + bn_name + '.output.1',
",4
"            param_attr=ParamAttr(self.global_name + bn_name + '_scale'),
",4
"            ch_in = input.shape[-1]
        if ch_in != ch_out or stride != 1 or is_first == True:
            return self.conv_bn_layer(
                input, ch_out, 1, stride, name=name, data_format=data_format)
        else:
",4
"            return input

    def bottleneck_block(self, input, num_filters, stride, name, data_format):
        conv0 = self.conv_bn_layer(
",4
"            input=input,
",4
"            data_format=data_format)
        conv2 = self.conv_bn_layer(
            input=conv1,
            num_filters=num_filters * 4,
",4
"
    def basic_block(self, input, num_filters, stride, is_first, name,
",4
"            num_filters=num_filters,
            filter_size=3,
",4
"            act='relu',
            stride=stride,
            name=name + ""_branch2a"",
            data_format=data_format)
",4
"        conv1 = self.conv_bn_layer(
",4
"def ResNet50(is_test=True, global_name=''):
    model = ResNet(layers=50, is_test=is_test, global_name=global_name)
    return model
",4
"

def ResNet101(is_test=True, global_name=''):
",4
"import paddle
import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr

",4
"        supported_layers = [50, 101, 152]
        assert layers in supported_layers, \
            ""supported layers are {} but input layer is {}"".format(supported_layers, layers)

",4
"        num_filters = [64, 128, 256, 512]

        conv = self.conv_bn_layer(
",4
"            act='relu',
            name='conv1_2')
        conv = self.conv_bn_layer(
",4
"            input=conv,
            pool_size=3,
            pool_stride=2,
            pool_padding=1,
",4
"                if layers in [101, 152] and block == 2:
                    if i == 0:
                        conv_name = ""res"" + str(block + 2) + ""a""
                    else:
",4
"                    conv_name = ""res"" + str(block + 2) + chr(97 + i)
                conv = self.bottleneck_block(
                    input=conv,
                    num_filters=num_filters[block],
",4
"                    stride=2 if i == 0 and block != 0 else 1,
                    name=conv_name)
                self.features[conv.name] = conv
",4
"
        pool = fluid.layers.pool2d(
            input=conv,
            pool_type='avg',
            global_pooling=True,
",4
"                name=self.global_name + 'fc_0.w_0',
                initializer=fluid.initializer.Uniform(-stdv, stdv)))
        return self.features, out

    def conv_bn_layer(self,
",4
"            act=act,
            name=self.global_name + bn_name + '.output.1',
",4
"        conv2 = self.conv_bn_layer(
            input=conv1,
            num_filters=num_filters * 4,
            filter_size=1,
",4
"
",4
"

def ResNet101_vc(is_test=True, global_name=''):
    model = ResNet(layers=101, is_test=is_test, global_name=global_name)
    return model
",4
"
",4
"    """"""resize image

",4
"    Args:
",4
"    Returns:
        img: cropped image data
",4
"        h_start = (height - size) // 2
    else:
        w_start = np.random.randint(0, width - size + 1)
        h_start = np.random.randint(0, height - size + 1)
",4
"    :return: np.array: shape: [ns, h, w, 3]
    """"""
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

",4
"        mirror = int(np.random.uniform(0, 2))
",4
"        if mirror == 1:
            img = img[:, :, ::-1, :]
",4
"
        root/train/dog/xxy.jpg
",4
"        ...

        root/test/dog/xxx.jpg
        ...
        root/test/cat/123.jpg
",4
"        ...
",4
"            dataset_dir, is_test)
        random_per = np.random.permutation(range(len(image_paths)))
",4
"                yield img, self.labels[i]

",4
"
        class_names, class_to_idx = _find_classes(datasubset_dir)
        # num_classes = len(class_names)
        image_paths = []
",4
"        return image_paths, labels, len(class_names)
# Configuration file for the Sphinx documentation builder.
#
",4
"#
from recommonmark.transform import AutoStructify
from recommonmark.parser import CommonMarkParser
",4
"# The suffix(es) of source filenames.
# You can specify multiple suffix as a list of string:
#
",4
"#
",4
"def setup(app):
    app.add_config_value('recommonmark_config', {
",4
"        'enable_eval_rst': True,
        'enable_auto_toc_tree': False,
    }, True)
    app.add_transform(AutoStructify)
#coding:utf-8
",4
"parser.add_argument(""--batch_size"",     type=int,                 default=1,    help=""Total examples' number in batch when the program predicts."")
args = parser.parse_args()
",4
"
if __name__ == '__main__':
    # loading Paddlehub senta pretrained model
    module = hub.Module(name=""senta_bilstm"")
",4
"    inputs, outputs, program = module.context(trainable=True)

",4
"    reader = hub.reader.LACClassifyReader(
        dataset=dataset, vocab_path=module.get_vocab_path())

",4
"    # Must feed all the tensor of senta's module need
    feed_list = [inputs[""words""].name]
",4
"
    # Setup RunConfig for PaddleHub Fine-tune API
    config = hub.RunConfig(
",4
"    print(cls_task.predict(data=data, return_result=True))
",4
"            print(
",4
"parser.add_argument(""--checkpoint_dir"", type=str, default=None, help=""Directory to model checkpoint"")
",4
"parser.add_argument(""--batch_size"", type=int, default=32, help=""Total examples' number in batch for training."")
args = parser.parse_args()
# yapf: enable.
",4
"    dataset = hub.dataset.ChnSentiCorp()
    reader = hub.reader.LACClassifyReader(
",4
"
    # Setup RunConfig for PaddleHub Fine-tune API
",4
"        use_cuda=args.use_gpu,
        use_pyreader=False,
",4
"        use_data_parallel=False,
        num_epoch=args.num_epoch,
        batch_size=args.batch_size,
        checkpoint_dir=args.checkpoint_dir,
",4
"import os
",4
"    # execute predict and print the result
    results = ssd.object_detection(images=[cv2.imread(test_img_path)])
    for result in results:
        print(result)
",4
"    ""--learning_rate"", type=float, default=5e-5, help=""learning_rate."")
parser.add_argument(
    ""--warmup_prop"", type=float, default=0.1, help=""warmup_prop."")
parser.add_argument(
",4
"    type=str,
    default="""",
    help=""Directory for saving model during "")
",4
"    if path == """":
        return False
    path = os.path.abspath(path)
    dirname = os.path.dirname(path)
    if not os.path.exists(dirname):
",4
"    # Download dataset and use ClassifyReader to read dataset
    dataset = hub.dataset.ChnSentiCorp()
",4
"    reader = hub.reader.ClassifyReader(
        dataset=dataset,
        vocab_path=module.get_vocab_path(),
        max_seq_len=args.max_seq_len)

",4
"    # Setup feed list for data feeder
",4
"    # Load model from the defined model path or not
    if args.model_path != """":
",4
"# See the License for the specific language governing permissions and
# limitations under the License.
",4
"""""""similarity between two sentences""""""

import numpy as np
",4
"from paddlehub.reader.tokenization import load_vocab
import paddle.fluid as fluid
import paddlehub as hub

",4
"    for token in tokens:
",4
"    vocab = load_vocab(module.get_vocab_path())
",4
"        [""æ°´æ æ¾ å°ç®± é å¨å­ å¥½ å"", ""ä¸­å½é¶è¡ çºªå¿µå¸ ç½ä¸ æä¹ é¢çº¦""],
        [""çµè ååº å¾ æ¢ æä¹ å"", ""ååº éåº¦ æ¢ , çµè æ»æ¯ å¡ æ¯ æä¹åäº""],
",4
"parser.add_argument(""--batch_size"",         type=int,               default=16,                         help=""Total examples' number in batch for training."")
parser.add_argument(""--module"",             type=str,               default=""resnet50"",                 help=""Module used as a feature extractor."")
",4
"    ""resnet152"": ""resnet_v2_152_imagenet"",
    ""mobilenet"": ""mobilenet_v2_imagenet"",
    ""nasnet"": ""nasnet_imagenet"",
    ""pnasnet"": ""pnasnet_imagenet""
",4
"

def predict(args):
    # Load Paddlehub  pretrained model
    module = hub.Module(name=args.module)
",4
"        dataset = hub.dataset.DogCat()
",4
"from paddle.fluid.dygraph.base import to_variable
from paddle.fluid.optimizer import AdamOptimizer

# yapf: disable
",4
"parser.add_argument(""--batch_size"",         type=int,               default=16,                                 help=""Total examples' number in batch for training."")
parser.add_argument(""--log_interval"",       type=int,               default=10,                                 help=""log interval."")
parser.add_argument(""--save_interval"",      type=int,               default=10,                                 help=""save interval."")
",4
"

class ResNet50(fluid.dygraph.Layer):
    def __init__(self, num_classes, backbone):
        super(ResNet50, self).__init__()
",4
"            for batch_id, data in enumerate(train_reader()):
                imgs = np.array(data[0][0])
",4
"                labels = np.array(data[0][1])
",4
"                cnt += imgs.shape[0]
                if batch_id % args.log_interval == 0:
",4
"

if __name__ == ""__main__"":
",4
"    ""resnet50"": ""resnet_v2_50_imagenet"",
    ""resnet101"": ""resnet_v2_101_imagenet"",
",4
"    if args.dataset.lower() == ""flowers"":
        dataset = hub.dataset.Flowers()
    elif args.dataset.lower() == ""dogcat"":
        dataset = hub.dataset.DogCat()
",4
"        dataset = hub.dataset.StanfordDogs()
",4
"    # Use ImageClassificationReader to read dataset
    data_reader = hub.reader.ImageClassificationReader(
        image_width=module.get_expected_image_width(),
        image_height=module.get_expected_image_height(),
",4
"        images_mean=module.get_pretrained_images_mean(),
        images_std=module.get_pretrained_images_std(),
        dataset=dataset)
",4
"    # Setup feed list for data feeder
    feed_list = [input_dict[""image""].name]
",4
"        use_data_parallel=args.use_data_parallel,
",4
"        data_reader=data_reader,
        feed_list=feed_list,
        feature=feature_map,
        num_classes=dataset.num_labels,
        config=config)
",4
"        exit(1)
    args.module = module_map[args.module]

    finetune(args)
",4
"    type=str,
    default=""mobilenet"",
    help=""Module used as feature extractor."")

",4
"# the name of hyper-parameters to be searched should keep with hparam.py
parser.add_argument(
    ""--batch_size"",
    type=int,
    default=16,
",4
"
# saved_params_dir and model_path are needed by auto fine-tune
parser.add_argument(
    ""--saved_params_dir"",
",4
"    type=str,
    default="""",
    help=""Directory for saving model"")
parser.add_argument(
    ""--model_path"", type=str, default="""", help=""load model path"")
",4
"    ""mobilenet"": ""mobilenet_v2_imagenet"",
    ""nasnet"": ""nasnet_imagenet"",
",4
"        num_classes=dataset.num_labels,
        config=config)

",4
"from __future__ import division
",4
"from __future__ import print_function

import argparse
import ast
",4
"parser.add_argument(""--batch_size"",     type=int,   default=1, help=""Total examples' number in batch for training."")
",4
"    # Load Paddlehub ERNIE Tiny pretrained model
    module = hub.Module(name=""ernie_tiny"")
    inputs, outputs, program = module.context(
",4
"
",4
"        checkpoint_dir=args.checkpoint_dir,
        strategy=hub.AdamWeightDecayStrategy())

    # Define a classfication fine-tune task by PaddleHub's API
",4
"# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
",4
"from __future__ import division
from __future__ import print_function

import argparse
import ast
",4
"parser.add_argument(""--checkpoint_dir"", type=str, default=None, help=""Directory to model checkpoint"")
parser.add_argument(""--batch_size"",     type=int,   default=1, help=""Total examples' number in batch for training."")
parser.add_argument(""--max_seq_len"", type=int, default=512, help=""Number of words of the longest seqence."")
parser.add_argument(""--use_gpu"", type=ast.literal_eval, default=False, help=""Whether use GPU for fine-tuning, input should be True or False"")
",4
"parser.add_argument(""--use_data_parallel"", type=ast.literal_eval, default=False, help=""Whether use data parallel."")
parser.add_argument(""--network"", type=str, default='bilstm', help=""Pre-defined network which was connected after Transformer model, such as ERNIE, BERT ,RoBERTa and ELECTRA."")
args = parser.parse_args()
# yapf: enable.
",4
"
    # Construct transfer learning network
",4
"        batch_size=args.batch_size,
        checkpoint_dir=args.checkpoint_dir,
        strategy=hub.AdamWeightDecayStrategy())
",4
"
    # Define a classfication fine-tune task by PaddleHub's API
    # network choice: bilstm, bow, cnn, dpcnn, gru, lstm (PaddleHub pre-defined network)
    # If you wanna add network after ERNIE/BERT/RoBERTa/ELECTRA module,
",4
"#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"
    # For ernie_tiny, it use sub-word to tokenize chinese sentence
    # If not ernie tiny, sp_model_path and word_dict_path should be set None
    reader = hub.reader.ClassifyReader(
",4
"        inputs[""position_ids""].name,
        inputs[""segment_ids""].name,
        inputs[""input_mask""].name,
    ]
",4
"
    # Select fine-tune strategy, setup config and fine-tune
    strategy = hub.AdamWeightDecayStrategy(
        warmup_proportion=args.warmup_proportion,
        weight_decay=args.weight_decay,
",4
"        num_epoch=args.num_epoch,
        batch_size=args.batch_size,
",4
"        checkpoint_dir=args.checkpoint_dir,
        strategy=strategy)
",4
"parser.add_argument(""--batch_size"", type=int, default=32, help=""Total examples' number in batch for training."")
",4
"
    # Load Paddlehub ERNIE Tiny pretrained model
    module = hub.Module(name=""ernie_tiny"")
    inputs, outputs, program = module.context(
",4
"    dataset = hub.dataset.ChnSentiCorp()
",4
"    # Construct transfer learning network
    # Use ""pooled_output"" for classification tasks on an entire sentence.
    # Use ""sequence_output"" for token-level output.
    pooled_output = outputs[""pooled_output""]

",4
"    # Setup RunConfig for PaddleHub Fine-tune API
",4
"    cls_task = hub.TextClassifierTask(
        data_reader=reader,
        feature=pooled_output,
        feed_list=feed_list,
        num_classes=dataset.num_labels,
",4
"from paddle.fluid.optimizer import AdamOptimizer

# yapf: disable
",4
"        self.transformer = transformer
        self.fc = Linear(input_dim=768, output_dim=num_classes)

",4
"            batch_size=args.batch_size, phase='train')

        loss_sum = acc_sum = cnt = 0
        # æ§è¡epoch_numæ¬¡è®­ç»
",4
"        for epoch in range(args.num_epoch):
            # è¯»åè®­ç»æ°æ®è¿è¡è®­ç»
            for batch_id, data in enumerate(train_reader()):
",4
"                input_ids = np.array(data[0][0]).astype(np.int64)
                position_ids = np.array(data[0][1]).astype(np.int64)
",4
"                segment_ids = np.array(data[0][2]).astype(np.int64)
                input_mask = np.array(data[0][3]).astype(np.float32)
                labels = np.array(data[0][4]).astype(np.int64)
",4
"                avg_loss = fluid.layers.mean(loss)
                avg_loss.backward()
                # åæ°æ´æ°
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
",4
"#
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
",4
"
import os

import numpy as np
from paddlehub.common.logger import logger
",4
"        # Choose dataset: GLUE/XNLI/ChinesesGLUE/NLPCC-DBQA/LCQMC
        # metric should be acc, f1 or matthews
        metrics_choices = [""acc""]

",4
"            inputs[""segment_ids""].name,
            inputs[""input_mask""].name,
        ]

        # Setup runing config for PaddleHub Finetune API
",4
"        self.cls_task = hub.TextClassifierTask(
            data_reader=reader,
            feature=pooled_output,
            feed_list=feed_list,
",4
"            # get predict index
            batch_result = np.argmax(batch_result, axis=2)[0]
",4
"    for index, text in enumerate(data):
        print(""%s\tpredict=%s"" % (data[index][0], predictions[index]))
import argparse
import os
",4
"    summary=""This is a PaddleHub Module. Just for test."",
",4
"        self.vocab = load_vocab(vocab_path)

",4
"        results = []
        for text in texts:
            sentiment = ""positive""
            for word in self.vocab:
",4
"        args = self.parser.parse_args(argvs)
        texts = [args.input_text]
        return self.sentiment_classify(texts)
def load_vocab(vocab_path):
    with open(vocab_path) as file:
",4
"# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
",4
"import argparse
import ast
",4
"    inputs, outputs, program = module.context(max_seq_len=args.max_seq_len)
",4
"        inputs[""segment_ids""].name,
        inputs[""input_mask""].name,
    ]

",4
"    cls_task = hub.TextClassifierTask(
        data_reader=reader,
        feature=pooled_output,
",4
"    print(cls_task.predict(data=data, return_result=True))
#coding:utf-8
#   Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
",4
"# yapf: disable
parser = argparse.ArgumentParser(__doc__)
parser.add_argument(""--num_epoch"", type=int, default=3, help=""Number of epoches for fine-tuning."")
parser.add_argument(""--use_gpu"", type=ast.literal_eval, default=False, help=""Whether use GPU for fine-tuning, input should be True or False"")
parser.add_argument(""--learning_rate"", type=float, default=5e-5, help=""Learning rate used to train with warmup."")
",4
"        trainable=True, max_seq_len=args.max_seq_len)
",4
"
    # Download dataset and use ClassifyReader to read dataset
    dataset = hub.dataset.NLPCC_DBQA()
    reader = hub.reader.ClassifyReader(
        dataset=dataset,
",4
"        vocab_path=module.get_vocab_path(),
        max_seq_len=args.max_seq_len)

    # Construct transfer learning network
",4
"
",4
"        max_query_length=64)

    seq_output = outputs[""sequence_output""]
",4
"    ]

",4
"        data_reader=reader,
        feature=seq_output,
        feed_list=feed_list,
        config=config,
",4
"
import argparse
import ast

",4
"parser.add_argument(""--max_seq_len"", type=int, default=384, help=""Number of words of the longest seqence."")
",4
"        trainable=True, max_seq_len=args.max_seq_len)

",4
"
    # Use ""sequence_output"" for token-level output.
    seq_output = outputs[""sequence_output""]

    # Setup feed list for data feeder
",4
"        strategy=hub.AdamWeightDecayStrategy())

    # Define a reading comprehension fine-tune task by PaddleHub's API
",4
"    reading_comprehension_task = hub.ReadingComprehensionTask(
        data_reader=reader,
",4
"
    # æå®æ£æµæ¹æ³ä¸ºpyramidbox_lite_server_maskå¹¶åépostè¯·æ±
    url = ""http://127.0.0.1:8866/predict/image/pyramidbox_lite_server_mask""
    r = requests.post(url=url, files=files, data={""visual_result"": ""True""})
",4
"    }
",4
"    data = {""texts"": text, ""batch_size"": 1}
",4
"    print(json.dumps(r.json(), indent=4, ensure_ascii=False))
# coding: utf8
",4
"import json

if __name__ == ""__main__"":
    # æå®ç¨äºé¢æµçææ¬å¹¶çæå­å¸{""text"": [text_1, text_2, ... ]}
",4
"import requests
",4
"
if __name__ == ""__main__"":
    # æå®è¦ä½¿ç¨çå¾çæä»¶å¹¶çæåè¡¨[(""image"", img_1), (""image"", img_2), ... ]
    file_list = [""../../../../docs/imgs/girl.jpg""]
    files = [(""image"", (open(item, ""rb""))) for item in file_list]
",4
"    if not os.path.exists(""output""):
        os.mkdir(""output"")

    results = eval(r.json()[""results""])
    for item in results:
",4
"            item.pop(""base64"")
    print(json.dumps(results, indent=4, ensure_ascii=False))
# coding: utf8
import requests
",4
"
",4
"import json

",4
"
if __name__ == ""__main__"":
    # æå®è¦é¢æµçå¾çå¹¶çæåè¡¨[(""image"", img_1), (""image"", img_2), ... ]
    file_list = [
",4
"# coding: utf8
from paddlehub.serving.bert_serving import bs_client

if __name__ == ""__main__"":
",4
"parser.add_argument(""--checkpoint_dir"",     type=str,               default=""paddlehub_finetune_ckpt"",  help=""Path to save log data."")
",4
"        predict_feature=pred_feature,
",4
"# -*- coding:utf8 -*-
import argparse
import os
import ast

",4
"parser.add_argument(""--batch_size"",         type=int,               default=8,                         help=""Total examples' number in batch for training."")
parser.add_argument(""--module"",             type=str,               default=""ssd"",                 help=""Module used as feature extractor."")
",4
"
def finetune(args):
",4
"    # base_path = '/home/local3/zhaopenghao/data/detect/paddle-job-84942-0'
",4
"        input_dict, output_dict, program = module.context(trainable=True)
        input_dict_pred = output_dict_pred = None

",4
"        num_epoch=args.num_epoch,
",4
"    task.finetune_and_eval()


",4
"#coding:utf-8
",4
"# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
",4
"if __name__ == '__main__':
    # Load Paddlehub ERNIE 2.0 pretrained model
    module = hub.Module(name=""ernie_v2_eng_base"")
    inputs, outputs, program = module.context(
        trainable=True, max_seq_len=args.max_seq_len)
",4
"# You may obtain a copy of the License at
#
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"""""""Fine-tuning on classification task """"""

import argparse
",4
"parser = argparse.ArgumentParser(__doc__)
parser.add_argument(""--num_epoch"", type=int, default=3, help=""Number of epoches for fine-tuning."")
",4
"    # Download dataset and use RegressionReader to read dataset
    dataset = hub.dataset.GLUE(""STS-B"")
",4
"        inputs[""segment_ids""].name,
        inputs[""input_mask""].name,
    ]
",4
"        config=config)

    # Fine-tune and evaluate by PaddleHub's API
    # will finish training, evaluation, testing, save model automatically
",4
"# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
",4
"    dataset = hub.dataset.Toxic()
    reader = hub.reader.MultiLabelClassifyReader(
        dataset=dataset,
        vocab_path=module.get_vocab_path(),
        max_seq_len=args.max_seq_len)
",4
"        num_classes=dataset.num_labels,
        config=config)

    # Fine-tune and evaluate by PaddleHub's API
    # will finish training, evaluation, testing, save model automatically
",4
"# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
",4
"from __future__ import division
",4
"from __future__ import print_function

",4
"        inputs[""input_ids""].name,
        inputs[""position_ids""].name,
        inputs[""segment_ids""].name,
        inputs[""input_mask""].name,
    ]
",4
"        strategy=hub.finetune.strategy.DefaultFinetuneStrategy())
",4
"        feature=pooled_output,
",4
"
",4
"                json.dumps(result['word'], encoding=""utf8"", ensure_ascii=False))
",4
"        'SourceHanSansSC-Medium.otf', fontsize, encoding=""utf-8"")
    #color = (255,0,0) # å­ä½é¢è²
    #position = (100,100)# æå­è¾åºä½ç½®
    color = color_bgr[::-1]
",4
"fourcc = cv2.VideoWriter_fourcc(*'vp90')
writer = cv2.VideoWriter(name, fourcc, fps, (width, height))
",4
"while True:
    frameData = {}
",4
"        maskFrameData['img'] = img_name

        maskFrameDatas.append(maskFrameData)

        maskIndex += 1
",4
"
",4
"            label_cn = ""æ å£ç½©""

        cv2.rectangle(frame_copy, (left, top), (right, bottom), color, 3)
        cv2.putText(frame_copy, label, (left, top - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
",4
"        break

",4
"return(!i||i!==r&&!b.contains(r,i))&&(e.type=o.origType,n=o.handler.apply(this,arguments),e.type=t),n}}}),b.support.submitBubbles||(b.event.special.submit={setup:function(){return b.nodeName(this,""form"")?!1:(b.event.add(this,""click._submit keypress._submit"",function(e){var n=e.target,r=b.nodeName(n,""input"")||b.nodeName(n,""button"")?n.form:t;r&&!b._data(r,""submitBubbles"")&&(b.event.add(r,""submit._submit"",function(e){e._submit_bubble=!0}),b._data(r,""submitBubbles"",!0))}),t)},postDispatch:function(e){e._submit_bubble&&(delete e._submit_bubble,this.parentNode&&!e.isTrigger&&b.event.simulate(""submit"",this.parentNode,e,!0))},teardown:function(){return b.nodeName(this,""form"")?!1:(b.event.remove(this,""._submit""),t)}}),b.support.changeBubbles||(b.event.special.change={setup:function(){return Z.test(this.nodeName)?((""checkbox""===this.type||""radio""===this.type)&&(b.event.add(this,""propertychange._change"",function(e){""checked""===e.originalEvent.propertyName&&(this._just_changed=!0)}),b.event.add(this,""click._change"",function(e){this._just_changed&&!e.isTrigger&&(this._just_changed=!1),b.event.simulate(""change"",this,e,!0)})),!1):(b.event.add(this,""beforeactivate._change"",function(e){var t=e.target;Z.test(t.nodeName)&&!b._data(t,""changeBubbles"")&&(b.event.add(t,""change._change"",function(e){!this.parentNode||e.isSimulated||e.isTrigger||b.event.simulate(""change"",this.parentNode,e,!0)}),b._data(t,""changeBubbles"",!0))}),t)},handle:function(e){var n=e.target;return this!==n||e.isSimulated||e.isTrigger||""radio""!==n.type&&""checkbox""!==n.type?e.handleObj.handler.apply(this,arguments):t},teardown:function(){return b.event.remove(this,""._change""),!Z.test(this.nodeName)}}),b.support.focusinBubbles||b.each({focus:""focusin"",blur:""focusout""},function(e,t){var n=0,r=function(e){b.event.simulate(t,e.target,b.event.fix(e),!0)};b.event.special[t]={setup:function(){0===n++&&o.addEventListener(e,r,!0)},teardown:function(){0===--n&&o.removeEventListener(e,r,!0)}}}),b.fn.extend({on:function(e,n,r,i,o){var a,s;if(""object""==typeof e){""string""!=typeof n&&(r=r||n,n=t);for(a in e)this.on(a,n,r,e[a],o);return this}if(null==r&&null==i?(i=n,r=n=t):null==i&&(""string""==typeof n?(i=r,r=t):(i=r,r=n,n=t)),i===!1)i=ot;else if(!i)return this;return 1===o&&(s=i,i=function(e){return b().off(e),s.apply(this,arguments)},i.guid=s.guid||(s.guid=b.guid++)),this.each(function(){b.event.add(this,e,i,r,n)})},one:function(e,t,n,r){return this.on(e,t,n,r,1)},off:function(e,n,r){var i,o;if(e&&e.preventDefault&&e.handleObj)return i=e.handleObj,b(e.delegateTarget).off(i.namespace?i.origType+"".""+i.namespace:i.origType,i.selector,i.handler),this;if(""object""==typeof e){for(o in e)this.off(o,n,e[o]);return this}return(n===!1||""function""==typeof n)&&(r=n,n=t),r===!1&&(r=ot),this.each(function(){b.event.remove(this,e,r,n)})},bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,""**""):this.off(t,e||""**"",n)},trigger:function(e,t){return this.each(function(){b.event.trigger(e,t,this)})},triggerHandler:function(e,n){var r=this[0];return r?b.event.trigger(e,n,r,!0):t}}),function(e,t){var n,r,i,o,a,s,u,l,c,p,f,d,h,g,m,y,v,x=""sizzle""+-new Date,w=e.document,T={},N=0,C=0,k=it(),E=it(),S=it(),A=typeof t,j=1<<31,D=[],L=D.pop,H=D.push,q=D.slice,M=D.indexOf||function(e){var t=0,n=this.length;for(;n>t;t++)if(this[t]===e)return t;return-1},_=""[\\x20\\t\\r\\n\\f]"",F=""(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+"",O=F.replace(""w"",""w#""),B=""([*^$|!~]?=)"",P=""\\[""+_+""*(""+F+"")""+_+""*(?:""+B+_+""*(?:(['\""])((?:\\\\.|[^\\\\])*?)\\3|(""+O+"")|)|)""+_+""*\\]"",R="":(""+F+"")(?:\\(((['\""])((?:\\\\.|[^\\\\])*?)\\3|((?:\\\\.|[^\\\\()[\\]]|""+P.replace(3,8)+"")*)|.*)\\)|)"",W=RegExp(""^""+_+""+|((?:^|[^\\\\])(?:\\\\.)*)""+_+""+$"",""g""),$=RegExp(""^""+_+""*,""+_+""*""),I=RegExp(""^""+_+""*([\\x20\\t\\r\\n\\f>+~])""+_+""*""),z=RegExp(R),X=RegExp(""^""+O+""$""),U={ID:RegExp(""^#(""+F+"")""),CLASS:RegExp(""^\\.(""+F+"")""),NAME:RegExp(""^\\[name=['\""]?(""+F+"")['\""]?\\]""),TAG:RegExp(""^(""+F.replace(""w"",""w*"")+"")""),ATTR:RegExp(""^""+P),PSEUDO:RegExp(""^""+R),CHILD:RegExp(""^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(""+_+""*(even|odd|(([+-]|)(\\d*)n|)""+_+""*(?:([+-]|)""+_+""*(\\d+)|))""+_+""*\\)|)"",""i""),needsContext:RegExp(""^""+_+""*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(""+_+""*((?:-\\d)?\\d*)""+_+""*\\)|)(?=[^-]|$)"",""i"")},V=/[\x20\t\r\n\f]*[+~]/,Y=/^[^{]+\{\s*\[native code/,J=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,G=/^(?:input|select|textarea|button)$/i,Q=/^h\d$/i,K=/'|\\/g,Z=/\=[\x20\t\r\n\f]*([^'""\]]*)[\x20\t\r\n\f]*\]/g,et=/\\([\da-fA-F]{1,6}[\x20\t\r\n\f]?|.)/g,tt=function(e,t){var n=""0x""+t-65536;return n!==n?t:0>n?String.fromCharCode(n+65536):String.fromCharCode(55296|n>>10,56320|1023&n)};try{q.call(w.documentElement.childNodes,0)[0].nodeType}catch(nt){q=function(e){var t,n=[];while(t=this[e++])n.push(t);return n}}function rt(e){return Y.test(e+"""")}function it(){var e,t=[];return e=function(n,r){return t.push(n+="" "")>i.cacheLength&&delete e[t.shift()],e[n]=r}}function ot(e){return e[x]=!0,e}function at(e){var t=p.createElement(""div"");try{return e(t)}catch(n){return!1}finally{t=null}}function st(e,t,n,r){var i,o,a,s,u,l,f,g,m,v;if((t?t.ownerDocument||t:w)!==p&&c(t),t=t||p,n=n||[],!e||""string""!=typeof e)return n;if(1!==(s=t.nodeType)&&9!==s)return[];if(!d&&!r){if(i=J.exec(e))if(a=i[1]){if(9===s){if(o=t.getElementById(a),!o||!o.parentNode)return n;if(o.id===a)return n.push(o),n}else if(t.ownerDocument&&(o=t.ownerDocument.getElementById(a))&&y(t,o)&&o.id===a)return n.push(o),n}else{if(i[2])return H.apply(n,q.call(t.getElementsByTagName(e),0)),n;if((a=i[3])&&T.getByClassName&&t.getElementsByClassName)return H.apply(n,q.call(t.getElementsByClassName(a),0)),n}if(T.qsa&&!h.test(e)){if(f=!0,g=x,m=t,v=9===s&&e,1===s&&""object""!==t.nodeName.toLowerCase()){l=ft(e),(f=t.getAttribute(""id""))?g=f.replace(K,""\\$&""):t.setAttribute(""id"",g),g=""[id='""+g+""'] "",u=l.length;while(u--)l[u]=g+dt(l[u]);m=V.test(e)&&t.parentNode||t,v=l.join("","")}if(v)try{return H.apply(n,q.call(m.querySelectorAll(v),0)),n}catch(b){}finally{f||t.removeAttribute(""id"")}}}return wt(e.replace(W,""$1""),t,n,r)}a=st.isXML=function(e){var t=e&&(e.ownerDocument||e).documentElement;return t?""HTML""!==t.nodeName:!1},c=st.setDocument=function(e){var n=e?e.ownerDocument||e:w;return n!==p&&9===n.nodeType&&n.documentElement?(p=n,f=n.documentElement,d=a(n),T.tagNameNoComments=at(function(e){return e.appendChild(n.createComment("""")),!e.getElementsByTagName(""*"").length}),T.attributes=at(function(e){e.innerHTML=""<select></select>"";var t=typeof e.lastChild.getAttribute(""multiple"");return""boolean""!==t&&""string""!==t}),T.getByClassName=at(function(e){return e.innerHTML=""<div class='hidden e'></div><div class='hidden'></div>"",e.getElementsByClassName&&e.getElementsByClassName(""e"").length?(e.lastChild.className=""e"",2===e.getElementsByClassName(""e"").length):!1}),T.getByName=at(function(e){e.id=x+0,e.innerHTML=""<a name='""+x+""'></a><div name='""+x+""'></div>"",f.insertBefore(e,f.firstChild);var t=n.getElementsByName&&n.getElementsByName(x).length===2+n.getElementsByName(x+0).length;return T.getIdNotName=!n.getElementById(x),f.removeChild(e),t}),i.attrHandle=at(function(e){return e.innerHTML=""<a href='#'></a>"",e.firstChild&&typeof e.firstChild.getAttribute!==A&&""#""===e.firstChild.getAttribute(""href"")})?{}:{href:function(e){return e.getAttribute(""href"",2)},type:function(e){return e.getAttribute(""type"")}},T.getIdNotName?(i.find.ID=function(e,t){if(typeof t.getElementById!==A&&!d){var n=t.getElementById(e);return n&&n.parentNode?[n]:[]}},i.filter.ID=function(e){var t=e.replace(et,tt);return function(e){return e.getAttribute(""id"")===t}}):(i.find.ID=function(e,n){if(typeof n.getElementById!==A&&!d){var r=n.getElementById(e);return r?r.id===e||typeof r.getAttributeNode!==A&&r.getAttributeNode(""id"").value===e?[r]:t:[]}},i.filter.ID=function(e){var t=e.replace(et,tt);return function(e){var n=typeof e.getAttributeNode!==A&&e.getAttributeNode(""id"");return n&&n.value===t}}),i.find.TAG=T.tagNameNoComments?function(e,n){return typeof n.getElementsByTagName!==A?n.getElementsByTagName(e):t}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if(""*""===e){while(n=o[i++])1===n.nodeType&&r.push(n);return r}return o},i.find.NAME=T.getByName&&function(e,n){return typeof n.getElementsByName!==A?n.getElementsByName(name):t},i.find.CLASS=T.getByClassName&&function(e,n){return typeof n.getElementsByClassName===A||d?t:n.getElementsByClassName(e)},g=[],h=["":focus""],(T.qsa=rt(n.querySelectorAll))&&(at(function(e){e.innerHTML=""<select><option selected=''></option></select>"",e.querySelectorAll(""[selected]"").length||h.push(""\\[""+_+""*(?:checked|disabled|ismap|multiple|readonly|selected|value)""),e.querySelectorAll("":checked"").length||h.push("":checked"")}),at(function(e){e.innerHTML=""<input type='hidden' i=''/>"",e.querySelectorAll(""[i^='']"").length&&h.push(""[*^$]=""+_+""*(?:\""\""|'')""),e.querySelectorAll("":enabled"").length||h.push("":enabled"","":disabled""),e.querySelectorAll(""*,:x""),h.push("",.*:"")})),(T.matchesSelector=rt(m=f.matchesSelector||f.mozMatchesSelector||f.webkitMatchesSelector||f.oMatchesSelector||f.msMatchesSelector))&&at(function(e){T.disconnectedMatch=m.call(e,""div""),m.call(e,""[s!='']:x""),g.push(""!="",R)}),h=RegExp(h.join(""|"")),g=RegExp(g.join(""|"")),y=rt(f.contains)||f.compareDocumentPosition?function(e,t){var n=9===e.nodeType?e.documentElement:e,r=t&&t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&&16&e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},v=f.compareDocumentPosition?function(e,t){var r;return e===t?(u=!0,0):(r=t.compareDocumentPosition&&e.compareDocumentPosition&&e.compareDocumentPosition(t))?1&r||e.parentNode&&11===e.parentNode.nodeType?e===n||y(w,e)?-1:t===n||y(w,t)?1:0:4&r?-1:1:e.compareDocumentPosition?-1:1}:function(e,t){var r,i=0,o=e.parentNode,a=t.parentNode,s=[e],l=[t];if(e===t)return u=!0,0;if(!o||!a)return e===n?-1:t===n?1:o?-1:a?1:0;if(o===a)return ut(e,t);r=e;while(r=r.parentNode)s.unshift(r);r=t;while(r=r.parentNode)l.unshift(r);while(s[i]===l[i])i++;return i?ut(s[i],l[i]):s[i]===w?-1:l[i]===w?1:0},u=!1,[0,0].sort(v),T.detectDuplicates=u,p):p},st.matches=function(e,t){return st(e,null,null,t)},st.matchesSelector=function(e,t){if((e.ownerDocument||e)!==p&&c(e),t=t.replace(Z,""='$1']""),!(!T.matchesSelector||d||g&&g.test(t)||h.test(t)))try{var n=m.call(e,t);if(n||T.disconnectedMatch||e.document&&11!==e.document.nodeType)return n}catch(r){}return st(t,p,null,[e]).length>0},st.contains=function(e,t){return(e.ownerDocument||e)!==p&&c(e),y(e,t)},st.attr=function(e,t){var n;return(e.ownerDocument||e)!==p&&c(e),d||(t=t.toLowerCase()),(n=i.attrHandle[t])?n(e):d||T.attributes?e.getAttribute(t):((n=e.getAttributeNode(t))||e.getAttribute(t))&&e[t]===!0?t:n&&n.specified?n.value:null},st.error=function(e){throw Error(""Syntax error, unrecognized expression: ""+e)},st.uniqueSort=function(e){var t,n=[],r=1,i=0;if(u=!T.detectDuplicates,e.sort(v),u){for(;t=e[r];r++)t===e[r-1]&&(i=n.push(r));while(i--)e.splice(n[i],1)}return e};function ut(e,t){var n=t&&e,r=n&&(~t.sourceIndex||j)-(~e.sourceIndex||j);if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function lt(e){return function(t){var n=t.nodeName.toLowerCase();return""input""===n&&t.type===e}}function ct(e){return function(t){var n=t.nodeName.toLowerCase();return(""input""===n||""button""===n)&&t.type===e}}function pt(e){return ot(function(t){return t=+t,ot(function(n,r){var i,o=e([],n.length,t),a=o.length;while(a--)n[i=o[a]]&&(n[i]=!(r[i]=n[i]))})})}o=st.getText=function(e){var t,n="""",r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if(""string""==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else for(;t=e[r];r++)n+=o(t);return n},i=st.selectors={cacheLength:50,createPseudo:ot,match:U,find:{},relative:{"">"":{dir:""parentNode"",first:!0},"" "":{dir:""parentNode""},""+"":{dir:""previousSibling"",first:!0},""~"":{dir:""previousSibling""}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(et,tt),e[3]=(e[4]||e[5]||"""").replace(et,tt),""~=""===e[2]&&(e[3]="" ""+e[3]+"" ""),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),""nth""===e[1].slice(0,3)?(e[3]||st.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*(""even""===e[3]||""odd""===e[3])),e[5]=+(e[7]+e[8]||""odd""===e[3])):e[3]&&st.error(e[0]),e},PSEUDO:function(e){var t,n=!e[5]&&e[2];return U.CHILD.test(e[0])?null:(e[4]?e[2]=e[4]:n&&z.test(n)&&(t=ft(n,!0))&&(t=n.indexOf("")"",n.length-t)-n.length)&&(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){return""*""===e?function(){return!0}:(e=e.replace(et,tt).toLowerCase(),function(t){return t.nodeName&&t.nodeName.toLowerCase()===e})},CLASS:function(e){var t=k[e+"" ""];return t||(t=RegExp(""(^|""+_+"")""+e+""(""+_+""|$)""))&&k(e,function(e){return t.test(e.className||typeof e.getAttribute!==A&&e.getAttribute(""class"")||"""")})},ATTR:function(e,t,n){return function(r){var i=st.attr(r,e);return null==i?""!=""===t:t?(i+="""",""=""===t?i===n:""!=""===t?i!==n:""^=""===t?n&&0===i.indexOf(n):""*=""===t?n&&i.indexOf(n)>-1:""$=""===t?n&&i.slice(-n.length)===n:""~=""===t?("" ""+i+"" "").indexOf(n)>-1:""|=""===t?i===n||i.slice(0,n.length+1)===n+""-"":!1):!0}},CHILD:function(e,t,n,r,i){var o=""nth""!==e.slice(0,3),a=""last""!==e.slice(-4),s=""of-type""===t;return 1===r&&0===i?function(e){return!!e.parentNode}:function(t,n,u){var l,c,p,f,d,h,g=o!==a?""nextSibling"":""previousSibling"",m=t.parentNode,y=s&&t.nodeName.toLowerCase(),v=!u&&!s;if(m){if(o){while(g){p=t;while(p=p[g])if(s?p.nodeName.toLowerCase()===y:1===p.nodeType)return!1;h=g=""only""===e&&!h&&""nextSibling""}return!0}if(h=[a?m.firstChild:m.lastChild],a&&v){c=m[x]||(m[x]={}),l=c[e]||[],d=l[0]===N&&l[1],f=l[0]===N&&l[2],p=d&&m.childNodes[d];while(p=++d&&p&&p[g]||(f=d=0)||h.pop())if(1===p.nodeType&&++f&&p===t){c[e]=[N,d,f];break}}else if(v&&(l=(t[x]||(t[x]={}))[e])&&l[0]===N)f=l[1];else while(p=++d&&p&&p[g]||(f=d=0)||h.pop())if((s?p.nodeName.toLowerCase()===y:1===p.nodeType)&&++f&&(v&&((p[x]||(p[x]={}))[e]=[N,f]),p===t))break;return f-=i,f===r||0===f%r&&f/r>=0}}},PSEUDO:function(e,t){var n,r=i.pseudos[e]||i.setFilters[e.toLowerCase()]||st.error(""unsupported pseudo: ""+e);return r[x]?r(t):r.length>1?(n=[e,e,"""",t],i.setFilters.hasOwnProperty(e.toLowerCase())?ot(function(e,n){var i,o=r(e,t),a=o.length;while(a--)i=M.call(e,o[a]),e[i]=!(n[i]=o[a])}):function(e){return r(e,0,n)}):r}},pseudos:{not:ot(function(e){var t=[],n=[],r=s(e.replace(W,""$1""));return r[x]?ot(function(e,t,n,i){var o,a=r(e,null,i,[]),s=e.length;while(s--)(o=a[s])&&(e[s]=!(t[s]=o))}):function(e,i,o){return t[0]=e,r(t,null,o,n),!n.pop()}}),has:ot(function(e){return function(t){return st(e,t).length>0}}),contains:ot(function(e){return function(t){return(t.textContent||t.innerText||o(t)).indexOf(e)>-1}}),lang:ot(function(e){return X.test(e||"""")||st.error(""unsupported lang: ""+e),e=e.replace(et,tt).toLowerCase(),function(t){var n;do if(n=d?t.getAttribute(""xml:lang"")||t.getAttribute(""lang""):t.lang)return n=n.toLowerCase(),n===e||0===n.indexOf(e+""-"");while((t=t.parentNode)&&1===t.nodeType);return!1}}),target:function(t){var n=e.location&&e.location.hash;return n&&n.slice(1)===t.id},root:function(e){return e===f},focus:function(e){return e===p.activeElement&&(!p.hasFocus||p.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:function(e){return e.disabled===!1},disabled:function(e){return e.disabled===!0},checked:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&!!e.checked||""option""===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,e.selected===!0},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeName>""@""||3===e.nodeType||4===e.nodeType)return!1;return!0},parent:function(e){return!i.pseudos.empty(e)},header:function(e){return Q.test(e.nodeName)},input:function(e){return G.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return""input""===t&&""button""===e.type||""button""===t},text:function(e){var t;return""input""===e.nodeName.toLowerCase()&&""text""===e.type&&(null==(t=e.getAttribute(""type""))||t.toLowerCase()===e.type)},first:pt(function(){return[0]}),last:pt(function(e,t){return[t-1]}),eq:pt(function(e,t,n){return[0>n?n+t:n]}),even:pt(function(e,t){var n=0;for(;t>n;n+=2)e.push(n);return e}),odd:pt(function(e,t){var n=1;for(;t>n;n+=2)e.push(n);return e}),lt:pt(function(e,t,n){var r=0>n?n+t:n;for(;--r>=0;)e.push(r);return e}),gt:pt(function(e,t,n){var r=0>n?n+t:n;for(;t>++r;)e.push(r);return e})}};for(n in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})i.pseudos[n]=lt(n);for(n in{submit:!0,reset:!0})i.pseudos[n]=ct(n);function ft(e,t){var n,r,o,a,s,u,l,c=E[e+"" ""];if(c)return t?0:c.slice(0);s=e,u=[],l=i.preFilter;while(s){(!n||(r=$.exec(s)))&&(r&&(s=s.slice(r[0].length)||s),u.push(o=[])),n=!1,(r=I.exec(s))&&(n=r.shift(),o.push({value:n,type:r[0].replace(W,"" "")}),s=s.slice(n.length));for(a in i.filter)!(r=U[a].exec(s))||l[a]&&!(r=l[a](r))||(n=r.shift(),o.push({value:n,type:a,matches:r}),s=s.slice(n.length));if(!n)break}return t?s.length:s?st.error(e):E(e,u).slice(0)}function dt(e){var t=0,n=e.length,r="""";for(;n>t;t++)r+=e[t].value;return r}function ht(e,t,n){var i=t.dir,o=n&&""parentNode""===i,a=C++;return t.first?function(t,n,r){while(t=t[i])if(1===t.nodeType||o)return e(t,n,r)}:function(t,n,s){var u,l,c,p=N+"" ""+a;if(s){while(t=t[i])if((1===t.nodeType||o)&&e(t,n,s))return!0}else while(t=t[i])if(1===t.nodeType||o)if(c=t[x]||(t[x]={}),(l=c[i])&&l[0]===p){if((u=l[1])===!0||u===r)return u===!0}else if(l=c[i]=[p],l[1]=e(t,n,s)||r,l[1]===!0)return!0}}function gt(e){return e.length>1?function(t,n,r){var i=e.length;while(i--)if(!e[i](t,n,r))return!1;return!0}:e[0]}function mt(e,t,n,r,i){var o,a=[],s=0,u=e.length,l=null!=t;for(;u>s;s++)(o=e[s])&&(!n||n(o,r,i))&&(a.push(o),l&&t.push(s));return a}function yt(e,t,n,r,i,o){return r&&!r[x]&&(r=yt(r)),i&&!i[x]&&(i=yt(i,o)),ot(function(o,a,s,u){var l,c,p,f=[],d=[],h=a.length,g=o||xt(t||""*"",s.nodeType?[s]:s,[]),m=!e||!o&&t?g:mt(g,f,e,s,u),y=n?i||(o?e:h||r)?[]:a:m;if(n&&n(m,y,s,u),r){l=mt(y,d),r(l,[],s,u),c=l.length;while(c--)(p=l[c])&&(y[d[c]]=!(m[d[c]]=p))}if(o){if(i||e){if(i){l=[],c=y.length;while(c--)(p=y[c])&&l.push(m[c]=p);i(null,y=[],l,u)}c=y.length;while(c--)(p=y[c])&&(l=i?M.call(o,p):f[c])>-1&&(o[l]=!(a[l]=p))}}else y=mt(y===a?y.splice(h,y.length):y),i?i(null,a,y,u):H.apply(a,y)})}function vt(e){var t,n,r,o=e.length,a=i.relative[e[0].type],s=a||i.relative["" ""],u=a?1:0,c=ht(function(e){return e===t},s,!0),p=ht(function(e){return M.call(t,e)>-1},s,!0),f=[function(e,n,r){return!a&&(r||n!==l)||((t=n).nodeType?c(e,n,r):p(e,n,r))}];for(;o>u;u++)if(n=i.relative[e[u].type])f=[ht(gt(f),n)];else{if(n=i.filter[e[u].type].apply(null,e[u].matches),n[x]){for(r=++u;o>r;r++)if(i.relative[e[r].type])break;return yt(u>1&&gt(f),u>1&&dt(e.slice(0,u-1)).replace(W,""$1""),n,r>u&&vt(e.slice(u,r)),o>r&&vt(e=e.slice(r)),o>r&&dt(e))}f.push(n)}return gt(f)}function bt(e,t){var n=0,o=t.length>0,a=e.length>0,s=function(s,u,c,f,d){var h,g,m,y=[],v=0,b=""0"",x=s&&[],w=null!=d,T=l,C=s||a&&i.find.TAG(""*"",d&&u.parentNode||u),k=N+=null==T?1:Math.random()||.1;for(w&&(l=u!==p&&u,r=n);null!=(h=C[b]);b++){if(a&&h){g=0;while(m=e[g++])if(m(h,u,c)){f.push(h);break}w&&(N=k,r=++n)}o&&((h=!m&&h)&&v--,s&&x.push(h))}if(v+=b,o&&b!==v){g=0;while(m=t[g++])m(x,y,u,c);if(s){if(v>0)while(b--)x[b]||y[b]||(y[b]=L.call(f));y=mt(y)}H.apply(f,y),w&&!s&&y.length>0&&v+t.length>1&&st.uniqueSort(f)}return w&&(N=k,l=T),x};return o?ot(s):s}s=st.compile=function(e,t){var n,r=[],i=[],o=S[e+"" ""];if(!o){t||(t=ft(e)),n=t.length;while(n--)o=vt(t[n]),o[x]?r.push(o):i.push(o);o=S(e,bt(i,r))}return o};function xt(e,t,n){var r=0,i=t.length;for(;i>r;r++)st(e,t[r],n);return n}function wt(e,t,n,r){var o,a,u,l,c,p=ft(e);if(!r&&1===p.length){if(a=p[0]=p[0].slice(0),a.length>2&&""ID""===(u=a[0]).type&&9===t.nodeType&&!d&&i.relative[a[1].type]){if(t=i.find.ID(u.matches[0].replace(et,tt),t)[0],!t)return n;e=e.slice(a.shift().value.length)}o=U.needsContext.test(e)?0:a.length;while(o--){if(u=a[o],i.relative[l=u.type])break;if((c=i.find[l])&&(r=c(u.matches[0].replace(et,tt),V.test(a[0].type)&&t.parentNode||t))){if(a.splice(o,1),e=r.length&&dt(a),!e)return H.apply(n,q.call(r,0)),n;break}}}return s(e,p)(r,t,d,n,V.test(e)),n}i.pseudos.nth=i.pseudos.eq;function Tt(){}i.filters=Tt.prototype=i.pseudos,i.setFilters=new Tt,c(),st.attr=b.attr,b.find=st,b.expr=st.selectors,b.expr["":""]=b.expr.pseudos,b.unique=st.uniqueSort,b.text=st.getText,b.isXMLDoc=st.isXML,b.contains=st.contains}(e);var at=/Until$/,st=/^(?:parents|prev(?:Until|All))/,ut=/^.[^:#\[\.,]*$/,lt=b.expr.match.needsContext,ct={children:!0,contents:!0,next:!0,prev:!0};b.fn.extend({find:function(e){var t,n,r,i=this.length;if(""string""!=typeof e)return r=this,this.pushStack(b(e).filter(function(){for(t=0;i>t;t++)if(b.contains(r[t],this))return!0}));for(n=[],t=0;i>t;t++)b.find(e,this[t],n);return n=this.pushStack(i>1?b.unique(n):n),n.selector=(this.selector?this.selector+"" "":"""")+e,n},has:function(e){var t,n=b(e,this),r=n.length;return this.filter(function(){for(t=0;r>t;t++)if(b.contains(this,n[t]))return!0})},not:function(e){return this.pushStack(ft(this,e,!1))},filter:function(e){return this.pushStack(ft(this,e,!0))},is:function(e){return!!e&&(""string""==typeof e?lt.test(e)?b(e,this.context).index(this[0])>=0:b.filter(e,this).length>0:this.filter(e).length>0)},closest:function(e,t){var n,r=0,i=this.length,o=[],a=lt.test(e)||""string""!=typeof e?b(e,t||this.context):0;for(;i>r;r++){n=this[r];while(n&&n.ownerDocument&&n!==t&&11!==n.nodeType){if(a?a.index(n)>-1:b.find.matchesSelector(n,e)){o.push(n);break}n=n.parentNode}}return this.pushStack(o.length>1?b.unique(o):o)},index:function(e){return e?""string""==typeof e?b.inArray(this[0],b(e)):b.inArray(e.jquery?e[0]:e,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){var n=""string""==typeof e?b(e,t):b.makeArray(e&&e.nodeType?[e]:e),r=b.merge(this.get(),n);return this.pushStack(b.unique(r))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),b.fn.andSelf=b.fn.addBack;function pt(e,t){do e=e[t];while(e&&1!==e.nodeType);return e}b.each({parent:function(e){var t=e.parentNode;return t&&11!==t.nodeType?t:null},parents:function(e){return b.dir(e,""parentNode"")},parentsUntil:function(e,t,n){return b.dir(e,""parentNode"",n)},next:function(e){return pt(e,""nextSibling"")},prev:function(e){return pt(e,""previousSibling"")},nextAll:function(e){return b.dir(e,""nextSibling"")},prevAll:function(e){return b.dir(e,""previousSibling"")},nextUntil:function(e,t,n){return b.dir(e,""nextSibling"",n)},prevUntil:function(e,t,n){return b.dir(e,""previousSibling"",n)},siblings:function(e){return b.sibling((e.parentNode||{}).firstChild,e)},children:function(e){return b.sibling(e.firstChild)},contents:function(e){return b.nodeName(e,""iframe"")?e.contentDocument||e.contentWindow.document:b.merge([],e.childNodes)}},function(e,t){b.fn[e]=function(n,r){var i=b.map(this,t,n);return at.test(e)||(r=n),r&&""string""==typeof r&&(i=b.filter(r,i)),i=this.length>1&&!ct[e]?b.unique(i):i,this.length>1&&st.test(e)&&(i=i.reverse()),this.pushStack(i)}}),b.extend({filter:function(e,t,n){return n&&(e="":not(""+e+"")""),1===t.length?b.find.matchesSelector(t[0],e)?[t[0]]:[]:b.find.matches(e,t)},dir:function(e,n,r){var i=[],o=e[n];while(o&&9!==o.nodeType&&(r===t||1!==o.nodeType||!b(o).is(r)))1===o.nodeType&&i.push(o),o=o[n];return i},sibling:function(e,t){var n=[];for(;e;e=e.nextSibling)1===e.nodeType&&e!==t&&n.push(e);return n}});function ft(e,t,n){if(t=t||0,b.isFunction(t))return b.grep(e,function(e,r){var i=!!t.call(e,r,e);return i===n});if(t.nodeType)return b.grep(e,function(e){return e===t===n});if(""string""==typeof t){var r=b.grep(e,function(e){return 1===e.nodeType});if(ut.test(t))return b.filter(t,r,!n);t=b.filter(t,r)}return b.grep(e,function(e){return b.inArray(e,t)>=0===n})}function dt(e){var t=ht.split(""|""),n=e.createDocumentFragment();if(n.createElement)while(t.length)n.createElement(t.pop());return n}var ht=""abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video"",gt=/ jQuery\d+=""(?:null|\d+)""/g,mt=RegExp(""<(?:""+ht+"")[\\s/>]"",""i""),yt=/^\s+/,vt=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/gi,bt=/<([\w:]+)/,xt=/<tbody/i,wt=/<|&#?\w+;/,Tt=/<(?:script|style|link)/i,Nt=/^(?:checkbox|radio)$/i,Ct=/checked\s*(?:[^=]|=\s*.checked.)/i,kt=/^$|\/(?:java|ecma)script/i,Et=/^true\/(.*)/,St=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,At={option:[1,""<select multiple='multiple'>"",""</select>""],legend:[1,""<fieldset>"",""</fieldset>""],area:[1,""<map>"",""</map>""],param:[1,""<object>"",""</object>""],thead:[1,""<table>"",""</table>""],tr:[2,""<table><tbody>"",""</tbody></table>""],col:[2,""<table><tbody></tbody><colgroup>"",""</colgroup></table>""],td:[3,""<table><tbody><tr>"",""</tr></tbody></table>""],_default:b.support.htmlSerialize?[0,"""",""""]:[1,""X<div>"",""</div>""]},jt=dt(o),Dt=jt.appendChild(o.createElement(""div""));At.optgroup=At.option,At.tbody=At.tfoot=At.colgroup=At.caption=At.thead,At.th=At.td,b.fn.extend({text:function(e){return b.access(this,function(e){return e===t?b.text(this):this.empty().append((this[0]&&this[0].ownerDocument||o).createTextNode(e))},null,e,arguments.length)},wrapAll:function(e){if(b.isFunction(e))return this.each(function(t){b(this).wrapAll(e.call(this,t))});if(this[0]){var t=b(e,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstChild&&1===e.firstChild.nodeType)e=e.firstChild;return e}).append(this)}return this},wrapInner:function(e){return b.isFunction(e)?this.each(function(t){b(this).wrapInner(e.call(this,t))}):this.each(function(){var t=b(this),n=t.contents();n.length?n.wrapAll(e):t.append(e)})},wrap:function(e){var t=b.isFunction(e);return this.each(function(n){b(this).wrapAll(t?e.call(this,n):e)})},unwrap:function(){return this.parent().each(function(){b.nodeName(this,""body"")||b(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,!0,function(e){(1===this.nodeType||11===this.nodeType||9===this.nodeType)&&this.appendChild(e)})},prepend:function(){return this.domManip(arguments,!0,function(e){(1===this.nodeType||11===this.nodeType||9===this.nodeType)&&this.insertBefore(e,this.firstChild)})},before:function(){return this.domManip(arguments,!1,function(e){this.parentNode&&this.parentNode.insertBefore(e,this)})},after:function(){return this.domManip(arguments,!1,function(e){this.parentNode&&this.parentNode.insertBefore(e,this.nextSibling)})},remove:function(e,t){var n,r=0;for(;null!=(n=this[r]);r++)(!e||b.filter(e,[n]).length>0)&&(t||1!==n.nodeType||b.cleanData(Ot(n)),n.parentNode&&(t&&b.contains(n.ownerDocument,n)&&Mt(Ot(n,""script"")),n.parentNode.removeChild(n)));return this},empty:function(){var e,t=0;for(;null!=(e=this[t]);t++){1===e.nodeType&&b.cleanData(Ot(e,!1));while(e.firstChild)e.removeChild(e.firstChild);e.options&&b.nodeName(e,""select"")&&(e.options.length=0)}return this},clone:function(e,t){return e=null==e?!1:e,t=null==t?e:t,this.map(function(){return b.clone(this,e,t)})},html:function(e){return b.access(this,function(e){var n=this[0]||{},r=0,i=this.length;if(e===t)return 1===n.nodeType?n.innerHTML.replace(gt,""""):t;if(!(""string""!=typeof e||Tt.test(e)||!b.support.htmlSerialize&&mt.test(e)||!b.support.leadingWhitespace&&yt.test(e)||At[(bt.exec(e)||["""",""""])[1].toLowerCase()])){e=e.replace(vt,""<$1></$2>"");try{for(;i>r;r++)n=this[r]||{},1===n.nodeType&&(b.cleanData(Ot(n,!1)),n.innerHTML=e);n=0}catch(o){}}n&&this.empty().append(e)},null,e,arguments.length)},replaceWith:function(e){var t=b.isFunction(e);return t||""string""==typeof e||(e=b(e).not(this).detach()),this.domManip([e],!0,function(e){var t=this.nextSibling,n=this.parentNode;n&&(b(this).remove(),n.insertBefore(e,t))})},detach:function(e){return this.remove(e,!0)},domManip:function(e,n,r){e=f.apply([],e);var i,o,a,s,u,l,c=0,p=this.length,d=this,h=p-1,g=e[0],m=b.isFunction(g);if(m||!(1>=p||""string""!=typeof g||b.support.checkClone)&&Ct.test(g))return this.each(function(i){var o=d.eq(i);m&&(e[0]=g.call(this,i,n?o.html():t)),o.domManip(e,n,r)});if(p&&(l=b.buildFragment(e,this[0].ownerDocument,!1,this),i=l.firstChild,1===l.childNodes.length&&(l=i),i)){for(n=n&&b.nodeName(i,""tr""),s=b.map(Ot(l,""script""),Ht),a=s.length;p>c;c++)o=l,c!==h&&(o=b.clone(o,!0,!0),a&&b.merge(s,Ot(o,""script""))),r.call(n&&b.nodeName(this[c],""table"")?Lt(this[c],""tbody""):this[c],o,c);if(a)for(u=s[s.length-1].ownerDocument,b.map(s,qt),c=0;a>c;c++)o=s[c],kt.test(o.type||"""")&&!b._data(o,""globalEval"")&&b.contains(u,o)&&(o.src?b.ajax({url:o.src,type:""GET"",dataType:""script"",async:!1,global:!1,""throws"":!0}):b.globalEval((o.text||o.textContent||o.innerHTML||"""").replace(St,"""")));l=i=null}return this}});function Lt(e,t){return e.getElementsByTagName(t)[0]||e.appendChild(e.ownerDocument.createElement(t))}function Ht(e){var t=e.getAttributeNode(""type"");return e.type=(t&&t.specified)+""/""+e.type,e}function qt(e){var t=Et.exec(e.type);return t?e.type=t[1]:e.removeAttribute(""type""),e}function Mt(e,t){var n,r=0;for(;null!=(n=e[r]);r++)b._data(n,""globalEval"",!t||b._data(t[r],""globalEval""))}function _t(e,t){if(1===t.nodeType&&b.hasData(e)){var n,r,i,o=b._data(e),a=b._data(t,o),s=o.events;if(s){delete a.handle,a.events={};for(n in s)for(r=0,i=s[n].length;i>r;r++)b.event.add(t,n,s[n][r])}a.data&&(a.data=b.extend({},a.data))}}function Ft(e,t){var n,r,i;if(1===t.nodeType){if(n=t.nodeName.toLowerCase(),!b.support.noCloneEvent&&t[b.expando]){i=b._data(t);for(r in i.events)b.removeEvent(t,r,i.handle);t.removeAttribute(b.expando)}""script""===n&&t.text!==e.text?(Ht(t).text=e.text,qt(t)):""object""===n?(t.parentNode&&(t.outerHTML=e.outerHTML),b.support.html5Clone&&e.innerHTML&&!b.trim(t.innerHTML)&&(t.innerHTML=e.innerHTML)):""input""===n&&Nt.test(e.type)?(t.defaultChecked=t.checked=e.checked,t.value!==e.value&&(t.value=e.value)):""option""===n?t.defaultSelected=t.selected=e.defaultSelected:(""input""===n||""textarea""===n)&&(t.defaultValue=e.defaultValue)}}b.each({appendTo:""append"",prependTo:""prepend"",insertBefore:""before"",insertAfter:""after"",replaceAll:""replaceWith""},function(e,t){b.fn[e]=function(e){var n,r=0,i=[],o=b(e),a=o.length-1;for(;a>=r;r++)n=r===a?this:this.clone(!0),b(o[r])[t](n),d.apply(i,n.get());return this.pushStack(i)}});function Ot(e,n){var r,o,a=0,s=typeof e.getElementsByTagName!==i?e.getElementsByTagName(n||""*""):typeof e.querySelectorAll!==i?e.querySelectorAll(n||""*""):t;if(!s)for(s=[],r=e.childNodes||e;null!=(o=r[a]);a++)!n||b.nodeName(o,n)?s.push(o):b.merge(s,Ot(o,n));return n===t||n&&b.nodeName(e,n)?b.merge([e],s):s}function Bt(e){Nt.test(e.type)&&(e.defaultChecked=e.checked)}b.extend({clone:function(e,t,n){var r,i,o,a,s,u=b.contains(e.ownerDocument,e);if(b.support.html5Clone||b.isXMLDoc(e)||!mt.test(""<""+e.nodeName+"">"")?o=e.cloneNode(!0):(Dt.innerHTML=e.outerHTML,Dt.removeChild(o=Dt.firstChild)),!(b.support.noCloneEvent&&b.support.noCloneChecked||1!==e.nodeType&&11!==e.nodeType||b.isXMLDoc(e)))for(r=Ot(o),s=Ot(e),a=0;null!=(i=s[a]);++a)r[a]&&Ft(i,r[a]);if(t)if(n)for(s=s||Ot(e),r=r||Ot(o),a=0;null!=(i=s[a]);a++)_t(i,r[a]);else _t(e,o);return r=Ot(o,""script""),r.length>0&&Mt(r,!u&&Ot(e,""script"")),r=s=i=null,o},buildFragment:function(e,t,n,r){var i,o,a,s,u,l,c,p=e.length,f=dt(t),d=[],h=0;for(;p>h;h++)if(o=e[h],o||0===o)if(""object""===b.type(o))b.merge(d,o.nodeType?[o]:o);else if(wt.test(o)){s=s||f.appendChild(t.createElement(""div"")),u=(bt.exec(o)||["""",""""])[1].toLowerCase(),c=At[u]||At._default,s.innerHTML=c[1]+o.replace(vt,""<$1></$2>"")+c[2],i=c[0];while(i--)s=s.lastChild;if(!b.support.leadingWhitespace&&yt.test(o)&&d.push(t.createTextNode(yt.exec(o)[0])),!b.support.tbody){o=""table""!==u||xt.test(o)?""<table>""!==c[1]||xt.test(o)?0:s:s.firstChild,i=o&&o.childNodes.length;while(i--)b.nodeName(l=o.childNodes[i],""tbody"")&&!l.childNodes.length&&o.removeChild(l)
}b.merge(d,s.childNodes),s.textContent="""";while(s.firstChild)s.removeChild(s.firstChild);s=f.lastChild}else d.push(t.createTextNode(o));s&&f.removeChild(s),b.support.appendChecked||b.grep(Ot(d,""input""),Bt),h=0;while(o=d[h++])if((!r||-1===b.inArray(o,r))&&(a=b.contains(o.ownerDocument,o),s=Ot(f.appendChild(o),""script""),a&&Mt(s),n)){i=0;while(o=s[i++])kt.test(o.type||"""")&&n.push(o)}return s=null,f},cleanData:function(e,t){var n,r,o,a,s=0,u=b.expando,l=b.cache,p=b.support.deleteExpando,f=b.event.special;for(;null!=(n=e[s]);s++)if((t||b.acceptData(n))&&(o=n[u],a=o&&l[o])){if(a.events)for(r in a.events)f[r]?b.event.remove(n,r):b.removeEvent(n,r,a.handle);l[o]&&(delete l[o],p?delete n[u]:typeof n.removeAttribute!==i?n.removeAttribute(u):n[u]=null,c.push(o))}}});var Pt,Rt,Wt,$t=/alpha\([^)]*\)/i,It=/opacity\s*=\s*([^)]*)/,zt=/^(top|right|bottom|left)$/,Xt=/^(none|table(?!-c[ea]).+)/,Ut=/^margin/,Vt=RegExp(""^(""+x+"")(.*)$"",""i""),Yt=RegExp(""^(""+x+"")(?!px)[a-z%]+$"",""i""),Jt=RegExp(""^([+-])=(""+x+"")"",""i""),Gt={BODY:""block""},Qt={position:""absolute"",visibility:""hidden"",display:""block""},Kt={letterSpacing:0,fontWeight:400},Zt=[""Top"",""Right"",""Bottom"",""Left""],en=[""Webkit"",""O"",""Moz"",""ms""];function tn(e,t){if(t in e)return t;var n=t.charAt(0).toUpperCase()+t.slice(1),r=t,i=en.length;while(i--)if(t=en[i]+n,t in e)return t;return r}function nn(e,t){return e=t||e,""none""===b.css(e,""display"")||!b.contains(e.ownerDocument,e)}function rn(e,t){var n,r,i,o=[],a=0,s=e.length;for(;s>a;a++)r=e[a],r.style&&(o[a]=b._data(r,""olddisplay""),n=r.style.display,t?(o[a]||""none""!==n||(r.style.display=""""),""""===r.style.display&&nn(r)&&(o[a]=b._data(r,""olddisplay"",un(r.nodeName)))):o[a]||(i=nn(r),(n&&""none""!==n||!i)&&b._data(r,""olddisplay"",i?n:b.css(r,""display""))));for(a=0;s>a;a++)r=e[a],r.style&&(t&&""none""!==r.style.display&&""""!==r.style.display||(r.style.display=t?o[a]||"""":""none""));return e}b.fn.extend({css:function(e,n){return b.access(this,function(e,n,r){var i,o,a={},s=0;if(b.isArray(n)){for(o=Rt(e),i=n.length;i>s;s++)a[n[s]]=b.css(e,n[s],!1,o);return a}return r!==t?b.style(e,n,r):b.css(e,n)},e,n,arguments.length>1)},show:function(){return rn(this,!0)},hide:function(){return rn(this)},toggle:function(e){var t=""boolean""==typeof e;return this.each(function(){(t?e:nn(this))?b(this).show():b(this).hide()})}}),b.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=Wt(e,""opacity"");return""""===n?""1"":n}}}},cssNumber:{columnCount:!0,fillOpacity:!0,fontWeight:!0,lineHeight:!0,opacity:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{""float"":b.support.cssFloat?""cssFloat"":""styleFloat""},style:function(e,n,r,i){if(e&&3!==e.nodeType&&8!==e.nodeType&&e.style){var o,a,s,u=b.camelCase(n),l=e.style;if(n=b.cssProps[u]||(b.cssProps[u]=tn(l,u)),s=b.cssHooks[n]||b.cssHooks[u],r===t)return s&&""get""in s&&(o=s.get(e,!1,i))!==t?o:l[n];if(a=typeof r,""string""===a&&(o=Jt.exec(r))&&(r=(o[1]+1)*o[2]+parseFloat(b.css(e,n)),a=""number""),!(null==r||""number""===a&&isNaN(r)||(""number""!==a||b.cssNumber[u]||(r+=""px""),b.support.clearCloneStyle||""""!==r||0!==n.indexOf(""background"")||(l[n]=""inherit""),s&&""set""in s&&(r=s.set(e,r,i))===t)))try{l[n]=r}catch(c){}}},css:function(e,n,r,i){var o,a,s,u=b.camelCase(n);return n=b.cssProps[u]||(b.cssProps[u]=tn(e.style,u)),s=b.cssHooks[n]||b.cssHooks[u],s&&""get""in s&&(a=s.get(e,!0,r)),a===t&&(a=Wt(e,n,i)),""normal""===a&&n in Kt&&(a=Kt[n]),""""===r||r?(o=parseFloat(a),r===!0||b.isNumeric(o)?o||0:a):a},swap:function(e,t,n,r){var i,o,a={};for(o in t)a[o]=e.style[o],e.style[o]=t[o];i=n.apply(e,r||[]);for(o in t)e.style[o]=a[o];return i}}),e.getComputedStyle?(Rt=function(t){return e.getComputedStyle(t,null)},Wt=function(e,n,r){var i,o,a,s=r||Rt(e),u=s?s.getPropertyValue(n)||s[n]:t,l=e.style;return s&&(""""!==u||b.contains(e.ownerDocument,e)||(u=b.style(e,n)),Yt.test(u)&&Ut.test(n)&&(i=l.width,o=l.minWidth,a=l.maxWidth,l.minWidth=l.maxWidth=l.width=u,u=s.width,l.width=i,l.minWidth=o,l.maxWidth=a)),u}):o.documentElement.currentStyle&&(Rt=function(e){return e.currentStyle},Wt=function(e,n,r){var i,o,a,s=r||Rt(e),u=s?s[n]:t,l=e.style;return null==u&&l&&l[n]&&(u=l[n]),Yt.test(u)&&!zt.test(n)&&(i=l.left,o=e.runtimeStyle,a=o&&o.left,a&&(o.left=e.currentStyle.left),l.left=""fontSize""===n?""1em"":u,u=l.pixelLeft+""px"",l.left=i,a&&(o.left=a)),""""===u?""auto"":u});function on(e,t,n){var r=Vt.exec(t);return r?Math.max(0,r[1]-(n||0))+(r[2]||""px""):t}function an(e,t,n,r,i){var o=n===(r?""border"":""content"")?4:""width""===t?1:0,a=0;for(;4>o;o+=2)""margin""===n&&(a+=b.css(e,n+Zt[o],!0,i)),r?(""content""===n&&(a-=b.css(e,""padding""+Zt[o],!0,i)),""margin""!==n&&(a-=b.css(e,""border""+Zt[o]+""Width"",!0,i))):(a+=b.css(e,""padding""+Zt[o],!0,i),""padding""!==n&&(a+=b.css(e,""border""+Zt[o]+""Width"",!0,i)));return a}function sn(e,t,n){var r=!0,i=""width""===t?e.offsetWidth:e.offsetHeight,o=Rt(e),a=b.support.boxSizing&&""border-box""===b.css(e,""boxSizing"",!1,o);if(0>=i||null==i){if(i=Wt(e,t,o),(0>i||null==i)&&(i=e.style[t]),Yt.test(i))return i;r=a&&(b.support.boxSizingReliable||i===e.style[t]),i=parseFloat(i)||0}return i+an(e,t,n||(a?""border"":""content""),r,o)+""px""}function un(e){var t=o,n=Gt[e];return n||(n=ln(e,t),""none""!==n&&n||(Pt=(Pt||b(""<iframe frameborder='0' width='0' height='0'/>"").css(""cssText"",""display:block !important"")).appendTo(t.documentElement),t=(Pt[0].contentWindow||Pt[0].contentDocument).document,t.write(""<!doctype html><html><body>""),t.close(),n=ln(e,t),Pt.detach()),Gt[e]=n),n}function ln(e,t){var n=b(t.createElement(e)).appendTo(t.body),r=b.css(n[0],""display"");return n.remove(),r}b.each([""height"",""width""],function(e,n){b.cssHooks[n]={get:function(e,r,i){return r?0===e.offsetWidth&&Xt.test(b.css(e,""display""))?b.swap(e,Qt,function(){return sn(e,n,i)}):sn(e,n,i):t},set:function(e,t,r){var i=r&&Rt(e);return on(e,t,r?an(e,n,r,b.support.boxSizing&&""border-box""===b.css(e,""boxSizing"",!1,i),i):0)}}}),b.support.opacity||(b.cssHooks.opacity={get:function(e,t){return It.test((t&&e.currentStyle?e.currentStyle.filter:e.style.filter)||"""")?.01*parseFloat(RegExp.$1)+"""":t?""1"":""""},set:function(e,t){var n=e.style,r=e.currentStyle,i=b.isNumeric(t)?""alpha(opacity=""+100*t+"")"":"""",o=r&&r.filter||n.filter||"""";n.zoom=1,(t>=1||""""===t)&&""""===b.trim(o.replace($t,""""))&&n.removeAttribute&&(n.removeAttribute(""filter""),""""===t||r&&!r.filter)||(n.filter=$t.test(o)?o.replace($t,i):o+"" ""+i)}}),b(function(){b.support.reliableMarginRight||(b.cssHooks.marginRight={get:function(e,n){return n?b.swap(e,{display:""inline-block""},Wt,[e,""marginRight""]):t}}),!b.support.pixelPosition&&b.fn.position&&b.each([""top"",""left""],function(e,n){b.cssHooks[n]={get:function(e,r){return r?(r=Wt(e,n),Yt.test(r)?b(e).position()[n]+""px"":r):t}}})}),b.expr&&b.expr.filters&&(b.expr.filters.hidden=function(e){return 0>=e.offsetWidth&&0>=e.offsetHeight||!b.support.reliableHiddenOffsets&&""none""===(e.style&&e.style.display||b.css(e,""display""))},b.expr.filters.visible=function(e){return!b.expr.filters.hidden(e)}),b.each({margin:"""",padding:"""",border:""Width""},function(e,t){b.cssHooks[e+t]={expand:function(n){var r=0,i={},o=""string""==typeof n?n.split("" ""):[n];for(;4>r;r++)i[e+Zt[r]+t]=o[r]||o[r-2]||o[0];return i}},Ut.test(e)||(b.cssHooks[e+t].set=on)});var cn=/%20/g,pn=/\[\]$/,fn=/\r?\n/g,dn=/^(?:submit|button|image|reset|file)$/i,hn=/^(?:input|select|textarea|keygen)/i;b.fn.extend({serialize:function(){return b.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=b.prop(this,""elements"");return e?b.makeArray(e):this}).filter(function(){var e=this.type;return this.name&&!b(this).is("":disabled"")&&hn.test(this.nodeName)&&!dn.test(e)&&(this.checked||!Nt.test(e))}).map(function(e,t){var n=b(this).val();return null==n?null:b.isArray(n)?b.map(n,function(e){return{name:t.name,value:e.replace(fn,""\r\n"")}}):{name:t.name,value:n.replace(fn,""\r\n"")}}).get()}}),b.param=function(e,n){var r,i=[],o=function(e,t){t=b.isFunction(t)?t():null==t?"""":t,i[i.length]=encodeURIComponent(e)+""=""+encodeURIComponent(t)};if(n===t&&(n=b.ajaxSettings&&b.ajaxSettings.traditional),b.isArray(e)||e.jquery&&!b.isPlainObject(e))b.each(e,function(){o(this.name,this.value)});else for(r in e)gn(r,e[r],n,o);return i.join(""&"").replace(cn,""+"")};function gn(e,t,n,r){var i;if(b.isArray(t))b.each(t,function(t,i){n||pn.test(e)?r(e,i):gn(e+""[""+(""object""==typeof i?t:"""")+""]"",i,n,r)});else if(n||""object""!==b.type(t))r(e,t);else for(i in t)gn(e+""[""+i+""]"",t[i],n,r)}b.each(""blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu"".split("" ""),function(e,t){b.fn[t]=function(e,n){return arguments.length>0?this.on(t,null,e,n):this.trigger(t)}}),b.fn.hover=function(e,t){return this.mouseenter(e).mouseleave(t||e)};var mn,yn,vn=b.now(),bn=/\?/,xn=/#.*$/,wn=/([?&])_=[^&]*/,Tn=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Nn=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Cn=/^(?:GET|HEAD)$/,kn=/^\/\//,En=/^([\w.+-]+:)(?:\/\/([^\/?#:]*)(?::(\d+)|)|)/,Sn=b.fn.load,An={},jn={},Dn=""*/"".concat(""*"");try{yn=a.href}catch(Ln){yn=o.createElement(""a""),yn.href="""",yn=yn.href}mn=En.exec(yn.toLowerCase())||[];function Hn(e){return function(t,n){""string""!=typeof t&&(n=t,t=""*"");var r,i=0,o=t.toLowerCase().match(w)||[];if(b.isFunction(n))while(r=o[i++])""+""===r[0]?(r=r.slice(1)||""*"",(e[r]=e[r]||[]).unshift(n)):(e[r]=e[r]||[]).push(n)}}function qn(e,n,r,i){var o={},a=e===jn;function s(u){var l;return o[u]=!0,b.each(e[u]||[],function(e,u){var c=u(n,r,i);return""string""!=typeof c||a||o[c]?a?!(l=c):t:(n.dataTypes.unshift(c),s(c),!1)}),l}return s(n.dataTypes[0])||!o[""*""]&&s(""*"")}function Mn(e,n){var r,i,o=b.ajaxSettings.flatOptions||{};for(i in n)n[i]!==t&&((o[i]?e:r||(r={}))[i]=n[i]);return r&&b.extend(!0,e,r),e}b.fn.load=function(e,n,r){if(""string""!=typeof e&&Sn)return Sn.apply(this,arguments);var i,o,a,s=this,u=e.indexOf("" "");return u>=0&&(i=e.slice(u,e.length),e=e.slice(0,u)),b.isFunction(n)?(r=n,n=t):n&&""object""==typeof n&&(a=""POST""),s.length>0&&b.ajax({url:e,type:a,dataType:""html"",data:n}).done(function(e){o=arguments,s.html(i?b(""<div>"").append(b.parseHTML(e)).find(i):e)}).complete(r&&function(e,t){s.each(r,o||[e.responseText,t,e])}),this},b.each([""ajaxStart"",""ajaxStop"",""ajaxComplete"",""ajaxError"",""ajaxSuccess"",""ajaxSend""],function(e,t){b.fn[t]=function(e){return this.on(t,e)}}),b.each([""get"",""post""],function(e,n){b[n]=function(e,r,i,o){return b.isFunction(r)&&(o=o||i,i=r,r=t),b.ajax({url:e,type:n,dataType:o,data:r,success:i})}}),b.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:yn,type:""GET"",isLocal:Nn.test(mn[1]),global:!0,processData:!0,async:!0,contentType:""application/x-www-form-urlencoded; charset=UTF-8"",accepts:{""*"":Dn,text:""text/plain"",html:""text/html"",xml:""application/xml, text/xml"",json:""application/json, text/javascript""},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:""responseXML"",text:""responseText""},converters:{""* text"":e.String,""text html"":!0,""text json"":b.parseJSON,""text xml"":b.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(e,t){return t?Mn(Mn(e,b.ajaxSettings),t):Mn(b.ajaxSettings,e)},ajaxPrefilter:Hn(An),ajaxTransport:Hn(jn),ajax:function(e,n){""object""==typeof e&&(n=e,e=t),n=n||{};var r,i,o,a,s,u,l,c,p=b.ajaxSetup({},n),f=p.context||p,d=p.context&&(f.nodeType||f.jquery)?b(f):b.event,h=b.Deferred(),g=b.Callbacks(""once memory""),m=p.statusCode||{},y={},v={},x=0,T=""canceled"",N={readyState:0,getResponseHeader:function(e){var t;if(2===x){if(!c){c={};while(t=Tn.exec(a))c[t[1].toLowerCase()]=t[2]}t=c[e.toLowerCase()]}return null==t?null:t},getAllResponseHeaders:function(){return 2===x?a:null},setRequestHeader:function(e,t){var n=e.toLowerCase();return x||(e=v[n]=v[n]||e,y[e]=t),this},overrideMimeType:function(e){return x||(p.mimeType=e),this},statusCode:function(e){var t;if(e)if(2>x)for(t in e)m[t]=[m[t],e[t]];else N.always(e[N.status]);return this},abort:function(e){var t=e||T;return l&&l.abort(t),k(0,t),this}};if(h.promise(N).complete=g.add,N.success=N.done,N.error=N.fail,p.url=((e||p.url||yn)+"""").replace(xn,"""").replace(kn,mn[1]+""//""),p.type=n.method||n.type||p.method||p.type,p.dataTypes=b.trim(p.dataType||""*"").toLowerCase().match(w)||[""""],null==p.crossDomain&&(r=En.exec(p.url.toLowerCase()),p.crossDomain=!(!r||r[1]===mn[1]&&r[2]===mn[2]&&(r[3]||(""http:""===r[1]?80:443))==(mn[3]||(""http:""===mn[1]?80:443)))),p.data&&p.processData&&""string""!=typeof p.data&&(p.data=b.param(p.data,p.traditional)),qn(An,p,n,N),2===x)return N;u=p.global,u&&0===b.active++&&b.event.trigger(""ajaxStart""),p.type=p.type.toUpperCase(),p.hasContent=!Cn.test(p.type),o=p.url,p.hasContent||(p.data&&(o=p.url+=(bn.test(o)?""&"":""?"")+p.data,delete p.data),p.cache===!1&&(p.url=wn.test(o)?o.replace(wn,""$1_=""+vn++):o+(bn.test(o)?""&"":""?"")+""_=""+vn++)),p.ifModified&&(b.lastModified[o]&&N.setRequestHeader(""If-Modified-Since"",b.lastModified[o]),b.etag[o]&&N.setRequestHeader(""If-None-Match"",b.etag[o])),(p.data&&p.hasContent&&p.contentType!==!1||n.contentType)&&N.setRequestHeader(""Content-Type"",p.contentType),N.setRequestHeader(""Accept"",p.dataTypes[0]&&p.accepts[p.dataTypes[0]]?p.accepts[p.dataTypes[0]]+(""*""!==p.dataTypes[0]?"", ""+Dn+""; q=0.01"":""""):p.accepts[""*""]);for(i in p.headers)N.setRequestHeader(i,p.headers[i]);if(p.beforeSend&&(p.beforeSend.call(f,N,p)===!1||2===x))return N.abort();T=""abort"";for(i in{success:1,error:1,complete:1})N[i](p[i]);if(l=qn(jn,p,n,N)){N.readyState=1,u&&d.trigger(""ajaxSend"",[N,p]),p.async&&p.timeout>0&&(s=setTimeout(function(){N.abort(""timeout"")},p.timeout));try{x=1,l.send(y,k)}catch(C){if(!(2>x))throw C;k(-1,C)}}else k(-1,""No Transport"");function k(e,n,r,i){var c,y,v,w,T,C=n;2!==x&&(x=2,s&&clearTimeout(s),l=t,a=i||"""",N.readyState=e>0?4:0,r&&(w=_n(p,N,r)),e>=200&&300>e||304===e?(p.ifModified&&(T=N.getResponseHeader(""Last-Modified""),T&&(b.lastModified[o]=T),T=N.getResponseHeader(""etag""),T&&(b.etag[o]=T)),204===e?(c=!0,C=""nocontent""):304===e?(c=!0,C=""notmodified""):(c=Fn(p,w),C=c.state,y=c.data,v=c.error,c=!v)):(v=C,(e||!C)&&(C=""error"",0>e&&(e=0))),N.status=e,N.statusText=(n||C)+"""",c?h.resolveWith(f,[y,C,N]):h.rejectWith(f,[N,C,v]),N.statusCode(m),m=t,u&&d.trigger(c?""ajaxSuccess"":""ajaxError"",[N,p,c?y:v]),g.fireWith(f,[N,C]),u&&(d.trigger(""ajaxComplete"",[N,p]),--b.active||b.event.trigger(""ajaxStop"")))}return N},getScript:function(e,n){return b.get(e,t,n,""script"")},getJSON:function(e,t,n){return b.get(e,t,n,""json"")}});function _n(e,n,r){var i,o,a,s,u=e.contents,l=e.dataTypes,c=e.responseFields;for(s in c)s in r&&(n[c[s]]=r[s]);while(""*""===l[0])l.shift(),o===t&&(o=e.mimeType||n.getResponseHeader(""Content-Type""));if(o)for(s in u)if(u[s]&&u[s].test(o)){l.unshift(s);break}if(l[0]in r)a=l[0];else{for(s in r){if(!l[0]||e.converters[s+"" ""+l[0]]){a=s;break}i||(i=s)}a=a||i}return a?(a!==l[0]&&l.unshift(a),r[a]):t}function Fn(e,t){var n,r,i,o,a={},s=0,u=e.dataTypes.slice(),l=u[0];if(e.dataFilter&&(t=e.dataFilter(t,e.dataType)),u[1])for(i in e.converters)a[i.toLowerCase()]=e.converters[i];for(;r=u[++s];)if(""*""!==r){if(""*""!==l&&l!==r){if(i=a[l+"" ""+r]||a[""* ""+r],!i)for(n in a)if(o=n.split("" ""),o[1]===r&&(i=a[l+"" ""+o[0]]||a[""* ""+o[0]])){i===!0?i=a[n]:a[n]!==!0&&(r=o[0],u.splice(s--,0,r));break}if(i!==!0)if(i&&e[""throws""])t=i(t);else try{t=i(t)}catch(c){return{state:""parsererror"",error:i?c:""No conversion from ""+l+"" to ""+r}}}l=r}return{state:""success"",data:t}}b.ajaxSetup({accepts:{script:""text/javascript, application/javascript, application/ecmascript, application/x-ecmascript""},contents:{script:/(?:java|ecma)script/},converters:{""text script"":function(e){return b.globalEval(e),e}}}),b.ajaxPrefilter(""script"",function(e){e.cache===t&&(e.cache=!1),e.crossDomain&&(e.type=""GET"",e.global=!1)}),b.ajaxTransport(""script"",function(e){if(e.crossDomain){var n,r=o.head||b(""head"")[0]||o.documentElement;return{send:function(t,i){n=o.createElement(""script""),n.async=!0,e.scriptCharset&&(n.charset=e.scriptCharset),n.src=e.url,n.onload=n.onreadystatechange=function(e,t){(t||!n.readyState||/loaded|complete/.test(n.readyState))&&(n.onload=n.onreadystatechange=null,n.parentNode&&n.parentNode.removeChild(n),n=null,t||i(200,""success""))},r.insertBefore(n,r.firstChild)},abort:function(){n&&n.onload(t,!0)}}}});var On=[],Bn=/(=)\?(?=&|$)|\?\?/;b.ajaxSetup({jsonp:""callback"",jsonpCallback:function(){var e=On.pop()||b.expando+""_""+vn++;return this[e]=!0,e}}),b.ajaxPrefilter(""json jsonp"",function(n,r,i){var o,a,s,u=n.jsonp!==!1&&(Bn.test(n.url)?""url"":""string""==typeof n.data&&!(n.contentType||"""").indexOf(""application/x-www-form-urlencoded"")&&Bn.test(n.data)&&""data"");return u||""jsonp""===n.dataTypes[0]?(o=n.jsonpCallback=b.isFunction(n.jsonpCallback)?n.jsonpCallback():n.jsonpCallback,u?n[u]=n[u].replace(Bn,""$1""+o):n.jsonp!==!1&&(n.url+=(bn.test(n.url)?""&"":""?"")+n.jsonp+""=""+o),n.converters[""script json""]=function(){return s||b.error(o+"" was not called""),s[0]},n.dataTypes[0]=""json"",a=e[o],e[o]=function(){s=arguments},i.always(function(){e[o]=a,n[o]&&(n.jsonpCallback=r.jsonpCallback,On.push(o)),s&&b.isFunction(a)&&a(s[0]),s=a=t}),""script""):t});var Pn,Rn,Wn=0,$n=e.ActiveXObject&&function(){var e;for(e in Pn)Pn[e](t,!0)};function In(){try{return new e.XMLHttpRequest}catch(t){}}function zn(){try{return new e.ActiveXObject(""Microsoft.XMLHTTP"")}catch(t){}}b.ajaxSettings.xhr=e.ActiveXObject?function(){return!this.isLocal&&In()||zn()}:In,Rn=b.ajaxSettings.xhr(),b.support.cors=!!Rn&&""withCredentials""in Rn,Rn=b.support.ajax=!!Rn,Rn&&b.ajaxTransport(function(n){if(!n.crossDomain||b.support.cors){var r;return{send:function(i,o){var a,s,u=n.xhr();if(n.username?u.open(n.type,n.url,n.async,n.username,n.password):u.open(n.type,n.url,n.async),n.xhrFields)for(s in n.xhrFields)u[s]=n.xhrFields[s];n.mimeType&&u.overrideMimeType&&u.overrideMimeType(n.mimeType),n.crossDomain||i[""X-Requested-With""]||(i[""X-Requested-With""]=""XMLHttpRequest"");try{for(s in i)u.setRequestHeader(s,i[s])}catch(l){}u.send(n.hasContent&&n.data||null),r=function(e,i){var s,l,c,p;try{if(r&&(i||4===u.readyState))if(r=t,a&&(u.onreadystatechange=b.noop,$n&&delete Pn[a]),i)4!==u.readyState&&u.abort();else{p={},s=u.status,l=u.getAllResponseHeaders(),""string""==typeof u.responseText&&(p.text=u.responseText);try{c=u.statusText}catch(f){c=""""}s||!n.isLocal||n.crossDomain?1223===s&&(s=204):s=p.text?200:404}}catch(d){i||o(-1,d)}p&&o(s,c,p,l)},n.async?4===u.readyState?setTimeout(r):(a=++Wn,$n&&(Pn||(Pn={},b(e).unload($n)),Pn[a]=r),u.onreadystatechange=r):r()},abort:function(){r&&r(t,!0)}}}});var Xn,Un,Vn=/^(?:toggle|show|hide)$/,Yn=RegExp(""^(?:([+-])=|)(""+x+"")([a-z%]*)$"",""i""),Jn=/queueHooks$/,Gn=[nr],Qn={""*"":[function(e,t){var n,r,i=this.createTween(e,t),o=Yn.exec(t),a=i.cur(),s=+a||0,u=1,l=20;if(o){if(n=+o[2],r=o[3]||(b.cssNumber[e]?"""":""px""),""px""!==r&&s){s=b.css(i.elem,e,!0)||n||1;do u=u||"".5"",s/=u,b.style(i.elem,e,s+r);while(u!==(u=i.cur()/a)&&1!==u&&--l)}i.unit=r,i.start=s,i.end=o[1]?s+(o[1]+1)*n:n}return i}]};function Kn(){return setTimeout(function(){Xn=t}),Xn=b.now()}function Zn(e,t){b.each(t,function(t,n){var r=(Qn[t]||[]).concat(Qn[""*""]),i=0,o=r.length;for(;o>i;i++)if(r[i].call(e,t,n))return})}function er(e,t,n){var r,i,o=0,a=Gn.length,s=b.Deferred().always(function(){delete u.elem}),u=function(){if(i)return!1;var t=Xn||Kn(),n=Math.max(0,l.startTime+l.duration-t),r=n/l.duration||0,o=1-r,a=0,u=l.tweens.length;for(;u>a;a++)l.tweens[a].run(o);return s.notifyWith(e,[l,o,n]),1>o&&u?n:(s.resolveWith(e,[l]),!1)},l=s.promise({elem:e,props:b.extend({},t),opts:b.extend(!0,{specialEasing:{}},n),originalProperties:t,originalOptions:n,startTime:Xn||Kn(),duration:n.duration,tweens:[],createTween:function(t,n){var r=b.Tween(e,l.opts,t,n,l.opts.specialEasing[t]||l.opts.easing);return l.tweens.push(r),r},stop:function(t){var n=0,r=t?l.tweens.length:0;if(i)return this;for(i=!0;r>n;n++)l.tweens[n].run(1);return t?s.resolveWith(e,[l,t]):s.rejectWith(e,[l,t]),this}}),c=l.props;for(tr(c,l.opts.specialEasing);a>o;o++)if(r=Gn[o].call(l,e,c,l.opts))return r;return Zn(l,c),b.isFunction(l.opts.start)&&l.opts.start.call(e,l),b.fx.timer(b.extend(u,{elem:e,anim:l,queue:l.opts.queue})),l.progress(l.opts.progress).done(l.opts.done,l.opts.complete).fail(l.opts.fail).always(l.opts.always)}function tr(e,t){var n,r,i,o,a;for(i in e)if(r=b.camelCase(i),o=t[r],n=e[i],b.isArray(n)&&(o=n[1],n=e[i]=n[0]),i!==r&&(e[r]=n,delete e[i]),a=b.cssHooks[r],a&&""expand""in a){n=a.expand(n),delete e[r];for(i in n)i in e||(e[i]=n[i],t[i]=o)}else t[r]=o}b.Animation=b.extend(er,{tweener:function(e,t){b.isFunction(e)?(t=e,e=[""*""]):e=e.split("" "");var n,r=0,i=e.length;for(;i>r;r++)n=e[r],Qn[n]=Qn[n]||[],Qn[n].unshift(t)},prefilter:function(e,t){t?Gn.unshift(e):Gn.push(e)}});function nr(e,t,n){var r,i,o,a,s,u,l,c,p,f=this,d=e.style,h={},g=[],m=e.nodeType&&nn(e);n.queue||(c=b._queueHooks(e,""fx""),null==c.unqueued&&(c.unqueued=0,p=c.empty.fire,c.empty.fire=function(){c.unqueued||p()}),c.unqueued++,f.always(function(){f.always(function(){c.unqueued--,b.queue(e,""fx"").length||c.empty.fire()})})),1===e.nodeType&&(""height""in t||""width""in t)&&(n.overflow=[d.overflow,d.overflowX,d.overflowY],""inline""===b.css(e,""display"")&&""none""===b.css(e,""float"")&&(b.support.inlineBlockNeedsLayout&&""inline""!==un(e.nodeName)?d.zoom=1:d.display=""inline-block"")),n.overflow&&(d.overflow=""hidden"",b.support.shrinkWrapBlocks||f.always(function(){d.overflow=n.overflow[0],d.overflowX=n.overflow[1],d.overflowY=n.overflow[2]}));for(i in t)if(a=t[i],Vn.exec(a)){if(delete t[i],u=u||""toggle""===a,a===(m?""hide"":""show""))continue;g.push(i)}if(o=g.length){s=b._data(e,""fxshow"")||b._data(e,""fxshow"",{}),""hidden""in s&&(m=s.hidden),u&&(s.hidden=!m),m?b(e).show():f.done(function(){b(e).hide()}),f.done(function(){var t;b._removeData(e,""fxshow"");for(t in h)b.style(e,t,h[t])});for(i=0;o>i;i++)r=g[i],l=f.createTween(r,m?s[r]:0),h[r]=s[r]||b.style(e,r),r in s||(s[r]=l.start,m&&(l.end=l.start,l.start=""width""===r||""height""===r?1:0))}}function rr(e,t,n,r,i){return new rr.prototype.init(e,t,n,r,i)}b.Tween=rr,rr.prototype={constructor:rr,init:function(e,t,n,r,i,o){this.elem=e,this.prop=n,this.easing=i||""swing"",this.options=t,this.start=this.now=this.cur(),this.end=r,this.unit=o||(b.cssNumber[n]?"""":""px"")},cur:function(){var e=rr.propHooks[this.prop];return e&&e.get?e.get(this):rr.propHooks._default.get(this)},run:function(e){var t,n=rr.propHooks[this.prop];return this.pos=t=this.options.duration?b.easing[this.easing](e,this.options.duration*e,0,1,this.options.duration):e,this.now=(this.end-this.start)*t+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),n&&n.set?n.set(this):rr.propHooks._default.set(this),this}},rr.prototype.init.prototype=rr.prototype,rr.propHooks={_default:{get:function(e){var t;return null==e.elem[e.prop]||e.elem.style&&null!=e.elem.style[e.prop]?(t=b.css(e.elem,e.prop,""""),t&&""auto""!==t?t:0):e.elem[e.prop]},set:function(e){b.fx.step[e.prop]?b.fx.step[e.prop](e):e.elem.style&&(null!=e.elem.style[b.cssProps[e.prop]]||b.cssHooks[e.prop])?b.style(e.elem,e.prop,e.now+e.unit):e.elem[e.prop]=e.now}}},rr.propHooks.scrollTop=rr.propHooks.scrollLeft={set:function(e){e.elem.nodeType&&e.elem.parentNode&&(e.elem[e.prop]=e.now)}},b.each([""toggle"",""show"",""hide""],function(e,t){var n=b.fn[t];b.fn[t]=function(e,r,i){return null==e||""boolean""==typeof e?n.apply(this,arguments):this.animate(ir(t,!0),e,r,i)}}),b.fn.extend({fadeTo:function(e,t,n,r){return this.filter(nn).css(""opacity"",0).show().end().animate({opacity:t},e,n,r)},animate:function(e,t,n,r){var i=b.isEmptyObject(e),o=b.speed(t,n,r),a=function(){var t=er(this,b.extend({},e),o);a.finish=function(){t.stop(!0)},(i||b._data(this,""finish""))&&t.stop(!0)};return a.finish=a,i||o.queue===!1?this.each(a):this.queue(o.queue,a)},stop:function(e,n,r){var i=function(e){var t=e.stop;delete e.stop,t(r)};return""string""!=typeof e&&(r=n,n=e,e=t),n&&e!==!1&&this.queue(e||""fx"",[]),this.each(function(){var t=!0,n=null!=e&&e+""queueHooks"",o=b.timers,a=b._data(this);if(n)a[n]&&a[n].stop&&i(a[n]);else for(n in a)a[n]&&a[n].stop&&Jn.test(n)&&i(a[n]);for(n=o.length;n--;)o[n].elem!==this||null!=e&&o[n].queue!==e||(o[n].anim.stop(r),t=!1,o.splice(n,1));(t||!r)&&b.dequeue(this,e)})},finish:function(e){return e!==!1&&(e=e||""fx""),this.each(function(){var t,n=b._data(this),r=n[e+""queue""],i=n[e+""queueHooks""],o=b.timers,a=r?r.length:0;for(n.finish=!0,b.queue(this,e,[]),i&&i.cur&&i.cur.finish&&i.cur.finish.call(this),t=o.length;t--;)o[t].elem===this&&o[t].queue===e&&(o[t].anim.stop(!0),o.splice(t,1));for(t=0;a>t;t++)r[t]&&r[t].finish&&r[t].finish.call(this);delete n.finish})}});function ir(e,t){var n,r={height:e},i=0;for(t=t?1:0;4>i;i+=2-t)n=Zt[i],r[""margin""+n]=r[""padding""+n]=e;return t&&(r.opacity=r.width=e),r}b.each({slideDown:ir(""show""),slideUp:ir(""hide""),slideToggle:ir(""toggle""),fadeIn:{opacity:""show""},fadeOut:{opacity:""hide""},fadeToggle:{opacity:""toggle""}},function(e,t){b.fn[e]=function(e,n,r){return this.animate(t,e,n,r)}}),b.speed=function(e,t,n){var r=e&&""object""==typeof e?b.extend({},e):{complete:n||!n&&t||b.isFunction(e)&&e,duration:e,easing:n&&t||t&&!b.isFunction(t)&&t};return r.duration=b.fx.off?0:""number""==typeof r.duration?r.duration:r.duration in b.fx.speeds?b.fx.speeds[r.duration]:b.fx.speeds._default,(null==r.queue||r.queue===!0)&&(r.queue=""fx""),r.old=r.complete,r.complete=function(){b.isFunction(r.old)&&r.old.call(this),r.queue&&b.dequeue(this,r.queue)},r},b.easing={linear:function(e){return e},swing:function(e){return.5-Math.cos(e*Math.PI)/2}},b.timers=[],b.fx=rr.prototype.init,b.fx.tick=function(){var e,n=b.timers,r=0;for(Xn=b.now();n.length>r;r++)e=n[r],e()||n[r]!==e||n.splice(r--,1);n.length||b.fx.stop(),Xn=t},b.fx.timer=function(e){e()&&b.timers.push(e)&&b.fx.start()},b.fx.interval=13,b.fx.start=function(){Un||(Un=setInterval(b.fx.tick,b.fx.interval))},b.fx.stop=function(){clearInterval(Un),Un=null},b.fx.speeds={slow:600,fast:200,_default:400},b.fx.step={},b.expr&&b.expr.filters&&(b.expr.filters.animated=function(e){return b.grep(b.timers,function(t){return e===t.elem}).length}),b.fn.offset=function(e){if(arguments.length)return e===t?this:this.each(function(t){b.offset.setOffset(this,e,t)});var n,r,o={top:0,left:0},a=this[0],s=a&&a.ownerDocument;if(s)return n=s.documentElement,b.contains(n,a)?(typeof a.getBoundingClientRect!==i&&(o=a.getBoundingClientRect()),r=or(s),{top:o.top+(r.pageYOffset||n.scrollTop)-(n.clientTop||0),left:o.left+(r.pageXOffset||n.scrollLeft)-(n.clientLeft||0)}):o},b.offset={setOffset:function(e,t,n){var r=b.css(e,""position"");""static""===r&&(e.style.position=""relative"");var i=b(e),o=i.offset(),a=b.css(e,""top""),s=b.css(e,""left""),u=(""absolute""===r||""fixed""===r)&&b.inArray(""auto"",[a,s])>-1,l={},c={},p,f;u?(c=i.position(),p=c.top,f=c.left):(p=parseFloat(a)||0,f=parseFloat(s)||0),b.isFunction(t)&&(t=t.call(e,n,o)),null!=t.top&&(l.top=t.top-o.top+p),null!=t.left&&(l.left=t.left-o.left+f),""using""in t?t.using.call(e,l):i.css(l)}},b.fn.extend({position:function(){if(this[0]){var e,t,n={top:0,left:0},r=this[0];return""fixed""===b.css(r,""position"")?t=r.getBoundingClientRect():(e=this.offsetParent(),t=this.offset(),b.nodeName(e[0],""html"")||(n=e.offset()),n.top+=b.css(e[0],""borderTopWidth"",!0),n.left+=b.css(e[0],""borderLeftWidth"",!0)),{top:t.top-n.top-b.css(r,""marginTop"",!0),left:t.left-n.left-b.css(r,""marginLeft"",!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent||o.documentElement;while(e&&!b.nodeName(e,""html"")&&""static""===b.css(e,""position""))e=e.offsetParent;return e||o.documentElement})}}),b.each({scrollLeft:""pageXOffset"",scrollTop:""pageYOffset""},function(e,n){var r=/Y/.test(n);b.fn[e]=function(i){return b.access(this,function(e,i,o){var a=or(e);return o===t?a?n in a?a[n]:a.document.documentElement[i]:e[i]:(a?a.scrollTo(r?b(a).scrollLeft():o,r?o:b(a).scrollTop()):e[i]=o,t)},e,i,arguments.length,null)}});function or(e){return b.isWindow(e)?e:9===e.nodeType?e.defaultView||e.parentWindow:!1}b.each({Height:""height"",Width:""width""},function(e,n){b.each({padding:""inner""+e,content:n,"""":""outer""+e},function(r,i){b.fn[i]=function(i,o){var a=arguments.length&&(r||""boolean""!=typeof i),s=r||(i===!0||o===!0?""margin"":""border"");return b.access(this,function(n,r,i){var o;return b.isWindow(n)?n.document.documentElement[""client""+e]:9===n.nodeType?(o=n.documentElement,Math.max(n.body[""scroll""+e],o[""scroll""+e],n.body[""offset""+e],o[""offset""+e],o[""client""+e])):i===t?b.css(n,r,s):b.style(n,r,i,s)},n,a?i:t,a,null)}})}),e.jQuery=e.$=b,""function""==typeof define&&define.amd&&define.amd.jQuery&&define(""jquery"",[],function(){return b})})(window);

/*! jQuery Migrate v1.2.2-pre | (c) 2005, 2013 jQuery Foundation, Inc. and other contributors | jquery.org/license */
",4
"	å¼åè¯´æï¼
	ä½¿ç¨çä¸»è¦ç¨åºè¯­è¨ï¼javascript(js)åactionscript3.0(as3.0)(as3.0ä¸»è¦ç¨äºflashplayeré¨åçå¼åï¼ä¸å¨è¯¥é¡µé¢åç°)
	åè½ï¼æ­æ¾è§é¢
",4
"			smartRemove: true,
",4
"				up: true,
				down: true
",4
"			},
			timeJump: 10,
",4
"				file: 'data:image/swf;base64,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',
",4
"				skipButtonShow: true,
				linkButtonShow: true,
				muteButtonShow: true,
				closeButtonShow: true,
				closeOtherButtonShow: true,
",4
"				frontStretched: 2,
",4
"				pauseStretched: 2,
				endStretched: 2
			},
",4
"}
!(function(){var javascriptPath='';!function(){var scriptList=document.scripts,thisPath=scriptList[scriptList.length-1].src;javascriptPath=thisPath.substring(0,thisPath.lastIndexOf('/')+1)}();var ckplayer=function(obj){this.config={videoDbClick:true,errorTime:100,videoDrawImage:false,adSkipClick:'javaScript->adjump'};this.varsConfig={playerID:'',container:'',variable:'ckplayer',volume:0.8,poster:'',autoplay:false,loop:false,live:false,duration:0,seek:0,drag:'',front:'',next:'',loaded:'',flashplayer:false,html5m3u8:false,track:null,cktrack:null,preview:null,prompt:null,video:null,config:'',type:'',crossorigin:'',crossdomain:'',unescape:false,mobileCkControls:false,mobileAutoFull:false,playbackrate:1,h5container:'',debug:false,adfront:'',adfronttime:'',adfrontlink:'',adpause:'',adpausetime:'',adpauselink:'',adinsert:'',adinserttime:'',adinsertlink:'',inserttime:'',adend:'',adendtime:'',adendlink:'',advertisements:''};this.vars={};this.language={volume:'é³éï¼',play:'ç¹å»æ­æ¾',pause:'ç¹å»æå',full:'ç¹å»å¨å±',escFull:'éåºå¨å±',mute:'ç¹å»éé³',escMute:'åæ¶éé³',front:'ä¸ä¸é',next:'ä¸ä¸é',definition:'ç¹å»éæ©æ¸æ°åº¦',playbackRate:'ç¹å»éæ©éåº¦',error:'å è½½åºé',adTime:'å¹¿å{$second}ç§',skipAd:'è·³è¿å¹¿å',skipAdTime:'{$second}ç§åå¯è·³è¿å¹¿å',adLink:'æ¥çè¯¦æ'};this.contextMenu=[['ckplayer','link','http://www.ckplayer.com','_blank'],['version:X','default','line']];this.errorList=[['000','Object does not exist'],['001','Variables type is not a object'],['002','Video object does not exist'],['003','Video object format error'],['004','Video object format error'],['005','Video object format error'],['006','[error] does not exist '],['007','Ajax error'],['008','Ajax error'],['009','Ajax object format error'],['010','Ajax.status:[error]']];this.playbackRateArr=[[0.5,'0.5å'],[1,'æ­£å¸¸'],[1.25,'1.25å'],[1.5,'1.5å'],[2,'2åé'],[4,'4åé']];this.playbackRateDefault=1;this.logo='';this.loaded=false;this.timerError=null;this.error=false;this.errorUrl=[];this.timerFull=null;this.full=false;this.timerTime=null;this.timerBuffer=null;this.isTimeButtonMove=true;this.isTimeButtonDown=false;this.isClick=false;this.timerClick=null;this.timerLoading=null;this.timerCBar=null;this.needSeek=0;this.volume=0;this.volumeTemp=0;this.time=0;this.isFirst=true;this.html5Video=true;this.pdCoor={x:0,y:0};this.playerType='';this.loadTime=0;this.body=document.body||document.documentElement;this.V=null;this.listenerJsArr=[];this.buttonLen=0;this.buttonArr=[];this.buttonWidth={};this.elementArr=[];this.elementTempArr=[];this.track=[];this.trackIndex=0;this.nowTrackShow={sn:''};this.trackElement=[];this.timerVCanvas=null;this.animateArray=[];this.animateElementArray=[];this.animatePauseArray=[];this.previewStart=0;this.previewDiv=null;this.previewTop=null;this.previewWidth=120;this.previewTween=null;this.isM3u8=false;this.promptArr=[];this.promptElement=null;this.ckplayerConfig={};this.showFace=true;this.errorAdd=false;this.errorSend=false;this.controlBarIsShow=true;this.videoScale=1;this.fontFamily='""Microsoft YaHei""; YaHei; ""\5FAE\8F6F\96C5\9ED1""; SimHei; ""\9ED1\4F53"";Arial';this.timeSliderLeftTemp=0;this.durationSendJS=false;this.adAnalysisEnd=false;this.advertisements={};this.isFirstTimePlay=true;this.adType='';this.adI=0;this.videoTemp={src:'',source:'',currentSrc:'',loop:false};this.adTimeAllTotal=0;this.adTimeTotal=0;this.adCountDownObj=null;this.adPlayStart=false;this.adPlayerPlay=false;this.adIsPause=false;this.adVideoMute=false;this.adIsVideoTime=false;this.endAdPlay=false;this.adPauseShow=false;this.adReset=false;this.adVideoPlay=false;if(obj){this.embed(obj)}};ckplayer.prototype={embed:function(c){if(window.location.href.substr(0,7)=='file://'){alert('Please use the HTTP protocol to open the page');return}if(c==undefined||!c){this.eject(this.errorList[0]);return}if(typeof(c)!='object'){this.eject(this.errorList[1])}this.vars=this.standardization(this.varsConfig,c);if(!this.vars['mobileCkControls']&&this.isMobile()){this.vars['flashplayer']=false;this.showFace=false}var videoString=this.vars['video'];if(!videoString){this.eject(this.errorList[2]);return}if(typeof(videoString)=='string'){if(videoString.substr(0,3)=='CK:'||videoString.substr(0,3)=='CE:'||videoString.substr(8,3)=='CK:'||videoString.substr(8,3)=='CE:'){this.vars['flashplayer']=true}}if(typeof(videoString)=='object'){if(videoString.length>1){if(videoString[0][0].substr(0,3)=='CK:'||videoString[0][0].substr(0,3)=='CE:'||videoString[0][0].substr(8,3)=='CK:'||videoString[0][0].substr(8,3)=='CE:'){this.vars['flashplayer']=true}}}if(this.vars['config']){this.ckplayerConfig=eval(this.vars['config']+'()')}else{this.ckplayerConfig=ckplayerConfig()}if((!this.supportVideo()&&this.vars['flashplayer']!='')||(this.vars['flashplayer']&&this.uploadFlash())||!this.isMsie()){this.html5Video=false;this.getVideo()}else if(videoString){this.analysedVideoUrl(videoString);return this}else{this.eject(this.errorList[2])}},analysedVideoUrl:function(video){var i=0,y=0;var thisTemp=this;this.VA=[];if(typeof(video)=='string'){if(video.substr(0,8)!='website:'){this.VA=[[video,'','',0]];var fileExt=this.getFileExt(video);switch(fileExt){case'.mp4':this.VA[0][1]='video/mp4';break;case'.ogg':this.VA[0][1]='video/ogg';break;case'.webm':this.VA[0][1]='video/webm';break;default:break}this.getVideo()}else{if(this.html5Video){var ajaxObj={url:video.substr(8),success:function(data){if(data){thisTemp.analysedUrl(data)}else{thisTemp.eject(thisTemp.errorList[5]);this.VA=video;thisTemp.getVideo()}}};this.ajax(ajaxObj)}else{this.VA=video;this.getVideo()}}}else if(typeof(video)=='object'){if(!this.isUndefined(typeof(video.length))){if(!this.isUndefined(typeof(video[0].length))){this.VA=video}this.getVideo()}else{if(!this.isUndefined(video['type'])){this.VA.push([video['file'],video['type'],'',0]);this.getVideo()}else{this.eject(this.errorList[5])}}}else{this.eject(this.errorList[4])}},analysedUrl:function(data){this.vars=this.standardization(this.vars,data);if(!this.isUndefined(data['video'])){this.vars['video']=data['video']}this.analysedVideoUrl(this.vars['video'])},getHtml5Video:function(){var va=this.VA;var nva=[];var mobile=false;var video=document.createElement('video');var codecs=function(type){var cod='';switch(type){case'video/mp4':cod='avc1.4D401E, mp4a.40.2';break;case'video/ogg':cod='theora, vorbis';break;case'video/webm':cod='vp8.0, vorbis';break;default:break}return cod};var supportType=function(vidType,codType){if(!video.canPlayType){this.html5Video=false;return}var isSupp=video.canPlayType(vidType+';codecs=""'+codType+'""');if(isSupp==''){return false}return true};if(this.vars['flashplayer']||!this.isMsie()){this.html5Video=false;return}if(this.isMobile()){mobile=true}for(var i=0;i<va.length;i++){var v=va[i];if(v){if(v[1]!=''&&!mobile&&supportType(v[1],codecs(v[1]))&&v[0].substr(0,4)!='rtmp'){nva.push(v)}if((this.getFileExt(v[0])=='.m3u8'||this.vars['type']=='video/m3u8'||this.vars['type']=='m3u8'||v[1]=='video/m3u8'||v[1]=='m3u8')&&this.vars['html5m3u8']){this.isM3u8=true;nva.push(v)}}}if(nva.length>0){this.VA=nva}else{if(!mobile){this.html5Video=false}}},getVideo:function(){var thisTemp=this;var v=this.vars;if(!this.adAnalysisEnd&&(v['adfront']!=''||v['adpause']!=''||v['adinsert']!=''||v['adend']!=''||v['advertisements']!='')){this.adAnalysisEnd=true;this.adAnalysis();return}if(this.V){this.changeVideo();return}if(this.vars['cktrack']){this.loadTrack()}if(this.supportVideo()&&!this.vars['flashplayer']){this.getHtml5Video()}var src='',source='',poster='',loop='',autoplay='',track='';var video=v['video'];var i=0;this.CD=this.getByElement(v['container']);volume=v['volume'];if(!this.CD){this.eject(this.errorList[6],v['container']);return false}this.V=undefined;var thisPd=null;if(v['h5container']!=''){thisPd=this.getByElement(v['h5container']);if(this.isUndefined(thisPd)){thisPd=null}}var isVideoH5=null;if(v['playerID']!=''){isVideoH5=this.getByElement('#'+v['playerID']);if(this.isUndefined(isVideoH5)){isVideoH5=null}}if(thisPd!=null&&isVideoH5!=null){this.PD=thisPd}else{var playerID='ckplayer'+this.randomString();var playerDiv=document.createElement('div');playerDiv.className=playerID;this.CD.innerHTML='';this.CD.appendChild(playerDiv);this.PD=this.getByElement(playerID)}this.css(this.CD,{backgroundColor:'#000000',overflow:'hidden',position:'relative'});this.css(this.PD,{backgroundColor:'#000000',width:'100%',height:'100%',fontFamily:this.fontFamily});if(this.html5Video){this.PD.onselectstart=this.PD.ondrag=function(){return false};if(this.VA.length==1){this.videoTemp['src']=decodeURIComponent(this.VA[0][0]);src=' src=""'+this.videoTemp['src']+'""'}else{var videoArr=this.VA.slice(0);videoArr=this.arrSort(videoArr);for(i=0;i<videoArr.length;i++){var type='';var va=videoArr[i];if(va[1]){type=' type=""'+va[1]+'""';if(type==' type=""video/m3u8""'||type==' type=""m3u8""'){type=''}}source+='<source src=""'+decodeURIComponent(va[0])+'""'+type+'>'}this.videoTemp['source']=source}if(v['autoplay']){autoplay=' autoplay=""autoplay""'}if(v['poster']){poster=' poster=""'+v['poster']+'""'}if(v['loop']){loop=' loop=""loop""'}if(v['seek']>0){this.needSeek=v['seek']}if(v['track']!=null&&v['cktrack']==null){var trackArr=v['track'];var trackDefault='';var defaultHave=false;for(i=0;i<trackArr.length;i++){var trackObj=trackArr[i];if(trackObj['default']&&!defaultHave){trackDefault=' default';defaultHave=true}else{trackDefault=''}track+='<track kind=""'+trackObj['kind']+'"" src=""'+trackObj['src']+'"" srclang=""'+trackObj['srclang']+'"" label=""'+trackObj['label']+'""'+trackDefault+'>'}}var autoLoad=this.ckplayerConfig['config']['autoLoad'];var preload='';if(!autoLoad){preload=' preload=""meta""'}var vid=this.randomString();var controls='';if(!this.showFace){controls=' controls=""controls""'}var mobileAutoFull=v['mobileAutoFull'];var mobileautofull='';if(!mobileAutoFull){mobileautofull=' x-webkit-airplay=""true"" playsinline  webkit-playsinline=""true""  x5-video-player-type=""h5""'}if(isVideoH5!=null&&thisPd!=null){this.V=isVideoH5;if(v['poster']){this.V.poster=v['poster']}}else{var html='';if(!this.isM3u8){html='<video id=""'+vid+'""'+src+' width=""100%"" height=""100%""'+autoplay+poster+loop+preload+controls+mobileautofull+track+'"">'+source+'</video>'}else{html='<video id=""'+vid+'"" width=""100%"" height=""100%""'+poster+loop+preload+controls+mobileautofull+track+'""></video>'}this.PD.innerHTML=html;this.V=this.getByElement('#'+vid)}if(this.vars['crossorigin']){this.V.crossOrigin=this.vars['crossorigin']}try{this.V.volume=volume;if(this.playbackRateArr&&this.vars['playbackrate']>-1){if(this.vars['playbackrate']<this.playbackRateArr.length){this.playbackRateDefault=this.vars['playbackrate']}this.V.playbackRate=this.playbackRateArr[this.playbackRateDefault][0]}}catch(error){}this.css(this.V,{width:'100%',height:'100%'});if(this.isM3u8){var loadJsHandler=function(){thisTemp.embedHls(thisTemp.VA[0][0],v['autoplay'])};this.loadJs(javascriptPath+'hls/hls.min.js',loadJsHandler)}this.css(this.V,'backgroundColor','#000000');if(this.config['videoDrawImage']){var canvasID='vcanvas'+this.randomString();var canvasDiv=document.createElement('div');canvasDiv.className=canvasID;this.PD.appendChild(canvasDiv);this.MD=this.getByElement(canvasID);this.css(this.MD,{backgroundColor:'#000000',width:'100%',height:'100%',position:'absolute',display:'none',cursor:'pointer',left:'0px',top:'0px',zIndex:'10'});var cvid='ccanvas'+this.randomString();this.MD.innerHTML=this.newCanvas(cvid,this.PD.offsetWidth,this.PD.offsetHeight);this.MDC=this.getByElement(cvid+'-canvas');this.MDCX=this.MDC.getContext('2d')}this.playerType='html5video';this.addVEvent();if(this.showFace){this.definition();if(!this.vars['live']&&this.playbackRateArr&&this.vars['playbackrate']>-1){this.playbackRate()}if(v['autoplay']){this.loadingStart(true)}}this.playerLoad()}else{this.embedSWF()}},arrayDel:function(arr){if(arr.length==0){return null}var newArr=[];for(var i=0;i<arr.length;i++){var type=arr[i]['type'];if(type=='mp4'||type=='mov'||this.isStrImage(type)){newArr.push(arr[i])}}if(newArr.length>0){return newArr}return null},adAnalysis:function(){var thisTemp=this;var v=this.vars;var isAdvShow=[];var i=0;if(v['advertisements']!=''&&v['advertisements'].substr(0,8)=='website:'){var ajaxObj={url:v['advertisements'].substr(8),success:function(data){if(data){var newData={};var val=null;try{if(!thisTemp.isUndefined(data['front'])){val=thisTemp.arrayDel(data['front']);if(!thisTemp.isUndefined(val)){newData['front']=val}val=thisTemp.arrayDel(data['pause']);if(!thisTemp.isUndefined(val)){newData['pause']=val}val=thisTemp.arrayDel(data['insert']);if(!thisTemp.isUndefined(val)){newData['insert']=val;if(!thisTemp.isUndefined(data['inserttime'])){newData['inserttime']=thisTemp.arrayInt(data['inserttime']);isAdvShow=[];for(i=0;i<newData['inserttime'].length;i++){isAdvShow.push(false)}newData['insertPlay']=isAdvShow}}val=thisTemp.arrayDel(data['end']);if(!thisTemp.isUndefined(val)){newData['end']=val}val=thisTemp.arrayDel(data['other']);if(!thisTemp.isUndefined(val)){newData['other']=val;isAdvShow=[];var arrTemp=[];for(i=0;i<val.length;i++){isAdvShow.push(false);arrTemp.push(parseInt('0'+val[i]['startTime']))}newData['othertime']=arrTemp;newData['otherPlay']=isAdvShow}}}catch(event){thisTemp.log(event)}thisTemp.advertisements=newData}thisTemp.getVideo()}};this.ajax(ajaxObj)}else{this.adAnalysisOne('front','adfront','adfronttime','adfrontlink','adfronttype');this.adAnalysisOne('pause','adpause','adpausetime','adpauselink','adpausetype');this.adAnalysisOne('insert','adinsert','adinserttime','adinsertlink','adinserttype');this.adAnalysisOne('end','adend','adendtime','adendlink','adendtype');if(!this.isUndefined(this.advertisements['insert'])){if(!this.isUndefined(v['inserttime'])){thisTemp.advertisements['inserttime']=v['inserttime']}}if(!this.isUndefined(thisTemp.advertisements['inserttime'])){thisTemp.advertisements['inserttime']=thisTemp.arrayInt(thisTemp.advertisements['inserttime']);isInsert=[];for(i=0;i<thisTemp.advertisements['inserttime'].length;i++){isInsert.push(false)}thisTemp.advertisements['insertPlay']=isInsert}thisTemp.getVideo()}},adAnalysisOne:function(adType,adName,adTime,adLink,adStype){var v=this.vars;if(this.isUndefined(v[adName])){v[adName]=''}if(this.isUndefined(v[adTime])){v[adTime]=''}if(this.isUndefined(v[adLink])){v[adLink]=''}if(this.isUndefined(v[adStype])){v[adStype]=''}if(v[adName]!=''){var adList=[];var ad=v[adName].split(',');var adtime=v[adTime].split(',');var adlink=v[adLink].split(',');var adstype=v[adStype].split(',');var i=0;if(ad.length>0){var adLinkLen=adlink.length,adTimeLen=adtime.length;if(v[adLink]==''){adLinkLen=0;adlink=[]}if(v[adTime]==''){adTimeLen=0;adtime=[]}if(adLinkLen<ad.length){for(i=adLinkLen;i<ad.length;i++){adlink.push('')}}if(adTimeLen<ad.length){for(i=adTimeLen;i<ad.length;i++){adtime.push('')}}var adstypeLen=adstype.length;if(v[adStype]==''){adstypeLen=0;adstype=[]}if(adstypeLen<ad.length){for(i=adstypeLen;i<ad.length;i++){adstype.push(this.getFileExt(ad[i]).replace('.',''))}}for(i=0;i<ad.length;i++){var type=adstype[i];if(type=='mp4'||type=='mov'||this.isStrImage(type)){var obj={file:ad[i],type:type,time:parseInt(adtime[i])>0?parseInt(adtime[i]):this.ckplayerConfig['style']['advertisement']['time'],link:adlink[i]};adList.push(obj)}}if(this.isUndefined(this.advertisements)){this.advertisements={}}if(adList.length>0){this.advertisements[adType]=adList}}}},playerLoad:function(){var thisTemp=this;if(this.isFirst){this.isFirst=false;setTimeout(function(){thisTemp.loadedHandler()},1)}},addVEvent:function(){var thisTemp=this;var eventVideoClick=function(event){thisTemp.videoClick()};this.addListenerInside('click',eventVideoClick);this.addListenerInside('click',eventVideoClick,this.MDC);this.timerErrorFun();var eventJudgeIsLive=function(event){thisTemp.sendJS('loadedmetadata');if(typeof(thisTemp.V.duration)=='number'&&thisTemp.V.duration>1){thisTemp.sendJS('duration',thisTemp.V.duration);thisTemp.formatInserttime(thisTemp.V.duration);if(thisTemp.adPlayerPlay){thisTemp.advertisementsTime(thisTemp.V.duration+1)}thisTemp.durationSendJS=true}thisTemp.judgeIsLive()};this.addListenerInside('loadedmetadata',eventJudgeIsLive);var eventPlaying=function(event){thisTemp.playingHandler();thisTemp.sendJS('play');thisTemp.sendJS('paused',false);if(!thisTemp.durationSendJS&&typeof(thisTemp.V.duration)=='number'&&thisTemp.V.duration>0){thisTemp.durationSendJS=true;thisTemp.sendJS('duration',thisTemp.V.duration);thisTemp.formatInserttime(thisTemp.V.duration)}};this.addListenerInside('playing',eventPlaying);var eventPause=function(event){thisTemp.pauseHandler();thisTemp.sendJS('pause');thisTemp.sendJS('paused',true)};this.addListenerInside('pause',eventPause);var eventEnded=function(event){thisTemp.endedHandler()};this.addListenerInside('ended',eventEnded);var eventTimeupdate=function(event){if(thisTemp.timerLoading!=null){thisTemp.loadingStart(false)}if(thisTemp.time){if(!thisTemp.adPlayerPlay){thisTemp.sendJS('time',thisTemp.time);if(!thisTemp.isUndefined(thisTemp.advertisements['insert'])){thisTemp.checkAdInsert(thisTemp.time)}if(!thisTemp.isUndefined(thisTemp.advertisements['other'])){thisTemp.checkAdOther(thisTemp.time)}if(thisTemp.time<3&&thisTemp.adReset){thisTemp.adReset=false;thisTemp.endedAdReset()}}else{thisTemp.adPlayerTimeHandler(thisTemp.time)}}};this.addListenerInside('timeupdate',eventTimeupdate);var eventWaiting=function(event){thisTemp.loadingStart(true)};this.addListenerInside('waiting',eventWaiting);var eventSeeking=function(event){thisTemp.sendJS('seek','start')};this.addListenerInside('seeking',eventSeeking);var eventSeeked=function(event){thisTemp.seekedHandler();thisTemp.sendJS('seek','ended')};this.addListenerInside('seeked',eventSeeked);var eventVolumeChange=function(event){try{thisTemp.volumechangeHandler();thisTemp.sendJS('volume',thisTemp.volume||thisTemp.V.volume)}catch(event){}};this.addListenerInside('volumechange',eventVolumeChange);var eventFullChange=function(event){var fullState=document.fullScreen||document.mozFullScreen||document.webkitIsFullScreen;thisTemp.sendJS('full',fullState)};this.addListenerInside('fullscreenchange',eventFullChange);this.addListenerInside('webkitfullscreenchange',eventFullChange);this.addListenerInside('mozfullscreenchange',eventFullChange);if(this.showFace){this.interFace()}},resetPlayer:function(){this.timeTextHandler();if(this.showFace){this.timeProgress(0,1);this.changeLoad(0);this.initPlayPause();this.definition();this.showFrontNext();this.deletePrompt();this.deletePreview();this.trackHide();this.resetTrack();this.trackElement=[];this.track=[]}},interFace:function(){this.showFace=true;var thisTemp=this;var html='';var i=0;var bWidth=38,bHeight=38;var bBgColor='#FFFFFF',bOverColor='#0782F5';var timeInto=this.formatTime(0)+' / '+this.formatTime(this.vars['duration']);var randomS=this.randomString(10);var controlBarBgID='controlbgbar'+randomS,controlBarID='controlbar'+randomS,timeProgressBgID='timeprogressbg'+randomS,loadProgressID='loadprogress'+randomS,timeProgressID='timeprogress'+randomS,timeBOBGID='timebobg'+randomS,timeBOID='timebo'+randomS,timeBWID='timebw'+randomS,timeTextID='timetext'+randomS,playID='play'+randomS,pauseID='pause'+randomS,frontID='front'+randomS,nextID='next'+randomS,fullID='full'+randomS,escFullID='escfull'+randomS,muteID='mute'+randomS,escMuteID='escmute'+randomS,volumeID='volume'+randomS,volumeDbgID='volumedbg'+randomS,volumeBgID='volumebg'+randomS,volumeUpID='volumeup'+randomS,volumeBOID='volumebo'+randomS,volumeBWID='volumebw'+randomS,definitionID='definition'+randomS,definitionPID='definitionp'+randomS,playbackRateID='playbackrate'+randomS,playbackRatePID='playbackratep'+randomS,promptBgID='promptbg'+randomS,promptID='prompt'+randomS,dlineID='dline'+randomS,menuID='menu'+randomS,pauseCenterID='pausecenter'+randomS,loadingID='loading'+randomS,errorTextID='errortext'+randomS,logoID='logo'+randomS,adBackgroundID='background'+randomS,adElementID='adelement'+randomS,adBarID='adBar'+randomS,adSkipID='adskip'+randomS,adTimeID='adtime'+randomS,adLinkID='adlink'+randomS,adMuteID='admute'+randomS,adEscMuteID='adescmute'+randomS,adPauseCloseID='adpauseclose'+randomS;var controlBarBg=document.createElement('div'),controlBar=document.createElement('div'),timeProgressBg=document.createElement('div'),timeBoBg=document.createElement('div'),pauseCenter=document.createElement('div'),errorText=document.createElement('div'),promptBg=document.createElement('div'),prompt=document.createElement('div'),menuDiv=document.createElement('div'),definitionP=document.createElement('div'),playbackrateP=document.createElement('div'),loading=document.createElement('div'),logo=document.createElement('div'),adBackground=document.createElement('div'),adElement=document.createElement('div'),adBar=document.createElement('div'),adLink=document.createElement('div'),adPauseClose=document.createElement('div');controlBarBg.className=controlBarBgID;controlBar.className=controlBarID;timeProgressBg.className=timeProgressBgID;timeBoBg.className=timeBOBGID;promptBg.className=promptBgID;prompt.className=promptID;menuDiv.className=menuID;definitionP.className=definitionPID;playbackrateP.className=playbackRatePID;pauseCenter.className=pauseCenterID;loading.className=loadingID;logo.className=logoID;errorText.className=errorTextID;adBackground.className=adBackgroundID;adElement.className=adElementID;adBar.className=adBarID;adLink.className=adLinkID;adPauseClose.className=adPauseCloseID;this.PD.appendChild(controlBarBg);this.PD.appendChild(controlBar);this.PD.appendChild(timeProgressBg);this.PD.appendChild(timeBoBg);this.PD.appendChild(promptBg);this.PD.appendChild(prompt);this.PD.appendChild(definitionP);this.PD.appendChild(playbackrateP);this.PD.appendChild(pauseCenter);this.PD.appendChild(loading);this.PD.appendChild(errorText);this.PD.appendChild(logo);this.PD.appendChild(adBackground);this.PD.appendChild(adElement);this.PD.appendChild(adBar);this.PD.appendChild(adLink);this.PD.appendChild(adPauseClose);this.body.appendChild(menuDiv);if(this.vars['live']){timeInto=this.getNowDate()}html+='<div class=""'+playID+'"" data-title=""'+thisTemp.language['play']+'"">'+this.newCanvas(playID,bWidth,bHeight)+'</div>';html+='<div class=""'+pauseID+'"" data-title=""'+thisTemp.language['pause']+'"">'+this.newCanvas(pauseID,bWidth,bHeight)+'</div>';html+='<div class=""'+dlineID+'-la""></div>';html+='<div class=""'+frontID+'"" data-title=""'+thisTemp.language['front']+'"">'+this.newCanvas(frontID,bWidth,bHeight)+'</div>';html+='<div class=""'+dlineID+'-lb""></div>';html+='<div class=""'+nextID+'"" data-title=""'+thisTemp.language['next']+'"">'+this.newCanvas(nextID,bWidth,bHeight)+'</div>';html+='<div class=""'+dlineID+'-lc""></div>';html+='<div class=""'+timeTextID+'"">'+timeInto+'</div>';html+='<div class=""'+fullID+'"" data-title=""'+thisTemp.language['full']+'"">'+this.newCanvas(fullID,bWidth,bHeight)+'</div>';html+='<div class=""'+escFullID+'"" data-title=""'+thisTemp.language['escFull']+'"">'+this.newCanvas(escFullID,bWidth,bHeight)+'</div>';html+='<div class=""'+dlineID+'-ra""></div>';html+='<div class=""'+definitionID+'"" data-title=""'+thisTemp.language['definition']+'""></div>';html+='<div class=""'+dlineID+'-rb""></div>';html+='<div class=""'+playbackRateID+'"" data-title=""'+thisTemp.language['playbackRate']+'""></div>';html+='<div class=""'+dlineID+'-rc""></div>';html+='<div class=""'+volumeID+'""><div class=""'+volumeDbgID+'""><div class=""'+volumeBgID+'""><div class=""'+volumeUpID+'""></div></div><div class=""'+volumeBOID+'""><div class=""'+volumeBWID+'""></div></div></div></div>';html+='<div class=""'+muteID+'"" data-title=""'+thisTemp.language['mute']+'"">'+this.newCanvas(muteID,bWidth,bHeight)+'</div>';html+='<div class=""'+escMuteID+'"" data-title=""'+thisTemp.language['escMute']+'"">'+this.newCanvas(escMuteID,bWidth,bHeight)+'</div>';html+='<div class=""'+dlineID+'-rd""></div>';this.getByElement(controlBarID).innerHTML=html;this.getByElement(timeProgressBgID).innerHTML='<div class=""'+loadProgressID+'""></div><div class=""'+timeProgressID+'""></div>';this.getByElement(timeBOBGID).innerHTML='<div class=""'+timeBOID+'""><div class=""'+timeBWID+'""></div></div>';this.getByElement(pauseCenterID).innerHTML=this.newCanvas(pauseCenterID,80,80);this.getByElement(loadingID).innerHTML=this.newCanvas(loadingID,60,60);this.getByElement(errorTextID).innerHTML=this.language['error'];html='<div class=""'+adTimeID+'"">'+this.language['adTime'].replace('{$second}',0)+'</div>';html+='<div class=""'+adMuteID+'"">'+this.newCanvas(adMuteID,30,30)+'</div>';html+='<div class=""'+adEscMuteID+'"">'+this.newCanvas(adEscMuteID,30,30)+'</div>';html+='<div class=""'+adSkipID+'""></div>';this.getByElement(adBarID).innerHTML=html;this.getByElement(adLinkID).innerHTML=this.language['adLink'];this.getByElement(adPauseCloseID).innerHTML=this.newCanvas(adPauseCloseID,20,20);if(this.ckplayerConfig['style']['logo']){if(this.ckplayerConfig['style']['logo']['file']){var logoFile=this.ckplayerConfig['style']['logo']['file'];if(logoFile.substr(0,15)=='data:image/png;'||logoFile.substr(0,15)=='data:image/jpg;'||logoFile.substr(0,16)=='data:image/jpeg;'){this.getByElement(logoID).innerHTML='<img src=""'+logoFile+'"" border=""0"">'}}}else{this.getByElement(logoID).innerHTML=this.vars['logo']||this.logo||''}var pd=this.PD;this.CB={controlBarBg:this.getByElement(controlBarBgID,pd),controlBar:this.getByElement(controlBarID,pd),promptBg:this.getByElement(promptBgID,pd),prompt:this.getByElement(promptID,pd),timeProgressBg:this.getByElement(timeProgressBgID,pd),loadProgress:this.getByElement(loadProgressID,pd),timeProgress:this.getByElement(timeProgressID,pd),timeBoBg:this.getByElement(timeBOBGID,pd),timeButton:this.getByElement(timeBOID,pd),timeText:this.getByElement(timeTextID,pd),play:this.getByElement(playID,pd),front:this.getByElement(frontID,pd),next:this.getByElement(nextID,pd),pause:this.getByElement(pauseID,pd),definition:this.getByElement(definitionID,pd),definitionP:this.getByElement(definitionPID,pd),definitionLine:this.getByElement(dlineID+'-rb',pd),playbackrate:this.getByElement(playbackRateID,pd),playbackrateP:this.getByElement(playbackRatePID,pd),playbackrateLine:this.getByElement(dlineID+'-rc',pd),full:this.getByElement(fullID,pd),escFull:this.getByElement(escFullID,pd),mute:this.getByElement(muteID,pd),escMute:this.getByElement(escMuteID,pd),volume:this.getByElement(volumeID,pd),volumeBg:this.getByElement(volumeBgID,pd),volumeUp:this.getByElement(volumeUpID,pd),volumeBO:this.getByElement(volumeBOID,pd),pauseCenter:this.getByElement(pauseCenterID,pd),menu:this.getByElement(menuID),loading:this.getByElement(loadingID,pd),loadingCanvas:this.getByElement(loadingID+'-canvas',pd),errorText:this.getByElement(errorTextID,pd),logo:this.getByElement(logoID,pd),playLine:this.getByElement(dlineID+'-la',pd),frontLine:this.getByElement(dlineID+'-lb',pd),nextLine:this.getByElement(dlineID+'-lc',pd),fullLine:this.getByElement(dlineID+'-ra'),definitionLine:this.getByElement(dlineID+'-rb',pd),muteLine:this.getByElement(dlineID+'-rd',pd),adBackground:this.getByElement(adBackgroundID,pd),adElement:this.getByElement(adElementID,pd),adBar:this.getByElement(adBarID,pd),adSkip:this.getByElement(adSkipID,pd),adTime:this.getByElement(adTimeID,pd),adLink:this.getByElement(adLinkID,pd),adMute:this.getByElement(adMuteID,pd),adEscMute:this.getByElement(adEscMuteID,pd),adPauseClose:this.getByElement(adPauseCloseID,pd)};this.buttonWidth={play:bWidth,full:bWidth,front:bWidth,next:bWidth,mute:bWidth};this.css(controlBarBgID,{width:'100%',height:bHeight+'px',backgroundColor:'#000000',position:'absolute',bottom:'0px',filter:'alpha(opacity:0.8)',opacity:'0.8',zIndex:'990'});this.css(controlBarID,{width:'100%',height:bHeight+'px',position:'absolute',bottom:'0px',zIndex:'990'});this.css(pauseCenterID,{width:'80px',height:'80px',borderRadius:'50%',position:'absolute',display:'none',cursor:'pointer',zIndex:'996'});this.css(loadingID,{width:'60px',height:'60px',position:'absolute',display:'none',zIndex:'996'});this.css(errorTextID,{width:'120px',height:'30px',lineHeight:'30px',color:'#FFFFFF',fontSize:'14px',textAlign:'center',position:'absolute',display:'none',zIndex:'101',cursor:'default',zIndex:'996'});this.css(logoID,{height:'30px',lineHeight:'30px',color:'#FFFFFF',fontFamily:'Arial',fontSize:'28px',textAlign:'center',position:'absolute',float:'left',left:'-1000px',top:'20px',zIndex:'996',filter:'alpha(opacity:0.8)',opacity:'0.8',cursor:'default'});this.css(this.CB['loadingCanvas'],{transform:'rotate(0deg)',msTransform:'rotate(0deg)',mozTransform:'rotate(0deg)',webkitTransform:'rotate(0deg)',oTransform:'rotate(0deg)'});this.css([promptBgID,promptID],{height:'30px',lineHeight:'30px',color:'#FFFFFF',fontSize:'14px',textAlign:'center',position:'absolute',borderRadius:'5px',paddingLeft:'5px',paddingRight:'5px',bottom:'0px',display:'none',zIndex:'995'});this.css(promptBgID,{backgroundColor:'#000000',filter:'alpha(opacity:0.5)',opacity:'0.5'});this.css(timeProgressBgID,{width:'100%',height:'6px',backgroundColor:'#3F3F3F',overflow:'hidden',position:'absolute',bottom:'38px',zIndex:'888'});this.css([loadProgressID,timeProgressID],{width:'1px',height:'6px',position:'absolute',bottom:'38px',top:'0px',zIndex:'991'});this.css(loadProgressID,'backgroundColor','#6F6F6F');this.css(timeProgressID,'backgroundColor',bOverColor);this.css(timeBOBGID,{width:'100%',height:'14px',overflow:'hidden',position:'absolute',bottom:'34px',cursor:'pointer',zIndex:'992'});this.css(timeBOID,{width:'14px',height:'14px',overflow:'hidden',borderRadius:'50%',backgroundColor:bBgColor,cursor:'pointer',position:'absolute',top:'0px',zIndex:'200'});this.css(timeBWID,{width:'8px',height:'8px',overflow:'hidden',borderRadius:'50%',position:'absolute',backgroundColor:bOverColor,left:'3px',top:'3px'});this.css(timeTextID,{lineHeight:bHeight+'px',color:'#FFFFFF',fontFamily:'arial',fontSize:'16px',paddingLeft:'10px',float:'left',overflow:'hidden',cursor:'default'});this.css([dlineID+'-la',dlineID+'-lb',dlineID+'-lc',dlineID+'-ra',dlineID+'-rb',dlineID+'-rc',dlineID+'-rd'],{width:'0px',height:bHeight+'px',overflow:'hidden',borderLeft:'1px solid #303030',borderRight:'1px solid #151515',filter:'alpha(opacity:0.9)',opacity:'0.9'});this.css([dlineID+'-la',dlineID+'-lb',dlineID+'-lc'],'float','left');this.css([dlineID+'-ra',dlineID+'-rb',dlineID+'-rc',dlineID+'-rd'],'float','right');this.css([dlineID+'-lb',dlineID+'-lc',dlineID+'-rb',dlineID+'-rc'],'display','none');this.css([playID,pauseID,frontID,nextID],{width:bWidth+'px',height:bHeight+'px',float:'left',overflow:'hidden',cursor:'pointer'});this.css([frontID,nextID],'display','none');this.initPlayPause();this.css([muteID,escMuteID],{width:bWidth+'px',height:bHeight+'px',float:'right',overflow:'hidden',cursor:'pointer'});if(this.vars['volume']>0){this.css(escMuteID,'display','none')}else{this.css(muteID,'display','none')}if(!this.ckplayerConfig['config']['mobileVolumeBarShow']&&this.isMobile()){this.css([muteID,escMuteID,volumeID,volumeDbgID,dlineID+'-rd'],{display:'none'})}this.css([volumeID,volumeDbgID],{width:'110px',height:bHeight+'px',overflow:'hidden',float:'right'});this.css(volumeDbgID,{position:'absolute'});this.css([volumeBgID,volumeUpID],{width:'100px',height:'6px',overflow:'hidden',borderRadius:'5px',cursor:'pointer'});this.css(volumeBgID,{position:'absolute',top:'16px'});this.css(volumeBgID,'backgroundColor','#666666');this.css(volumeUpID,'backgroundColor',bOverColor);this.buttonWidth['volume']=100;this.css(volumeBOID,{width:'12px',height:'12px',overflow:'hidden',borderRadius:'50%',position:'absolute',backgroundColor:bBgColor,top:'13px',left:'0px',cursor:'pointer'});this.css(volumeBWID,{width:'6px',height:'6px',overflow:'hidden',borderRadius:'50%',position:'absolute',backgroundColor:bOverColor,left:'3px',top:'3px'});this.css(definitionID,{lineHeight:bHeight+'px',color:'#FFFFFF',float:'right',fontSize:'14px',textAlign:'center',overflow:'hidden',display:'none',cursor:'pointer'});this.css(definitionPID,{lineHeight:(bHeight-8)+'px',color:'#FFFFFF',overflow:'hidden',position:'absolute',bottom:'4px',backgroundColor:'#000000',textAlign:'center',zIndex:'995',cursor:'pointer',display:'none'});this.css(playbackRateID,{lineHeight:bHeight+'px',color:'#FFFFFF',float:'right',fontSize:'14px',textAlign:'center',overflow:'hidden',display:'none',cursor:'pointer'});this.css(playbackRatePID,{lineHeight:(bHeight-8)+'px',color:'#FFFFFF',overflow:'hidden',position:'absolute',bottom:'4px',backgroundColor:'#000000',textAlign:'center',zIndex:'995',cursor:'pointer',display:'none'});this.css([fullID,escFullID],{width:bWidth+'px',height:bHeight+'px',float:'right',overflow:'hidden',cursor:'pointer'});this.css(escFullID,'display','none');this.css(adBackgroundID,{width:'100%',height:'100%',backgroundColor:'#000000',position:'absolute',top:'0px',zIndex:'997',display:'none'});this.css(adElementID,{position:'absolute',overflow:'hidden',top:'0px',zIndex:'998',float:'center',display:'none'});this.css(adBarID,{position:'absolute',overflow:'hidden',top:'10px',right:'10px',zIndex:'999',textAlign:'right',display:'none'});this.css(adTimeID,{backgroundColor:'#000000',color:'#FF0000',paddingLeft:'10px',paddingRight:'10px',lineHeight:(bHeight-8)+'px',marginLeft:'5px',float:'right',cursor:'pointer'});this.css([adMuteID,adEscMuteID],{backgroundColor:'#000000',width:'30px',height:'30px',marginLeft:'5px',float:'right',display:'none',cursor:'pointer'});this.css(adSkipID,{backgroundColor:'#000000',lineHeight:(bHeight-8)+'px',color:'#FFFFFF',paddingLeft:'10px',paddingRight:'10px',float:'right',display:'none',cursor:'pointer'});this.css(adLinkID,{backgroundColor:'#ea5503',lineHeight:(bHeight-8)+'px',color:'#FFFFFF',paddingLeft:'10px',paddingRight:'10px',position:'absolute',overflow:'hidden',bottom:'10px',right:'10px',zIndex:'999',display:'none'});this.css(adPauseCloseID,{backgroundColor:'#f7f7f7',widht:'20px',height:'20px',position:'absolute',overflow:'hidden',zIndex:'999',top:'60px',left:'30px',borderRadius:'20px',display:'none',cursor:'pointer'});var cPlay=this.getByElement(playID+'-canvas').getContext('2d');var cPlayFillRect=function(){thisTemp.canvasFill(cPlay,[[12,10],[29,19],[12,28]])};cPlay.fillStyle=bBgColor;cPlayFillRect();var cPlayOver=function(event){cPlay.clearRect(0,0,bWidth,bHeight);cPlay.fillStyle=bOverColor;cPlayFillRect()};var cPlayOut=function(event){cPlay.clearRect(0,0,bWidth,bHeight);cPlay.fillStyle=bBgColor;cPlayFillRect()};this.addListenerInside('mouseover',cPlayOver,this.getByElement(playID+'-canvas'));this.addListenerInside('mouseout',cPlayOut,this.getByElement(playID+'-canvas'));var cPause=this.getByElement(pauseID+'-canvas').getContext('2d');var cPauseFillRect=function(){thisTemp.canvasFillRect(cPause,[[10,10,5,18],[22,10,5,18]])};cPause.fillStyle=bBgColor;cPauseFillRect();var cPauseOver=function(event){cPause.clearRect(0,0,bWidth,bHeight);cPause.fillStyle=bOverColor;cPauseFillRect()};var cPauseOut=function(event){cPause.clearRect(0,0,bWidth,bHeight);cPause.fillStyle=bBgColor;cPauseFillRect()};this.addListenerInside('mouseover',cPauseOver,this.getByElement(pauseID+'-canvas'));this.addListenerInside('mouseout',cPauseOut,this.getByElement(pauseID+'-canvas'));var cFront=this.getByElement(frontID+'-canvas').getContext('2d');var cFrontFillRect=function(){thisTemp.canvasFill(cFront,[[16,19],[30,10],[30,28]]);thisTemp.canvasFillRect(cFront,[[8,10,5,18]])};cFront.fillStyle=bBgColor;cFrontFillRect();var cFrontOver=function(event){cFront.clearRect(0,0,bWidth,bHeight);cFront.fillStyle=bOverColor;cFrontFillRect()};var cFrontOut=function(event){cFront.clearRect(0,0,bWidth,bHeight);cFront.fillStyle=bBgColor;cFrontFillRect()};this.addListenerInside('mouseover',cFrontOver,this.getByElement(frontID+'-canvas'));this.addListenerInside('mouseout',cFrontOut,this.getByElement(frontID+'-canvas'));var cNext=this.getByElement(nextID+'-canvas').getContext('2d');var cNextFillRect=function(){thisTemp.canvasFill(cNext,[[8,10],[22,19],[8,28]]);thisTemp.canvasFillRect(cNext,[[25,10,5,18]])};cNext.fillStyle=bBgColor;cNextFillRect();var cNextOver=function(event){cNext.clearRect(0,0,bWidth,bHeight);cNext.fillStyle=bOverColor;cNextFillRect()};var cNextOut=function(event){cNext.clearRect(0,0,bWidth,bHeight);cNext.fillStyle=bBgColor;cNextFillRect()};this.addListenerInside('mouseover',cNextOver,this.getByElement(nextID+'-canvas'));this.addListenerInside('mouseout',cNextOut,this.getByElement(nextID+'-canvas'));var cFull=this.getByElement(fullID+'-canvas').getContext('2d');var cFullFillRect=function(){thisTemp.canvasFillRect(cFull,[[19,10,9,3],[25,13,3,6],[10,19,3,9],[13,25,6,3]])};cFull.fillStyle=bBgColor;cFullFillRect();var cFullOver=function(){cFull.clearRect(0,0,bWidth,bHeight);cFull.fillStyle=bOverColor;cFullFillRect()};var cFullOut=function(){cFull.clearRect(0,0,bWidth,bHeight);cFull.fillStyle=bBgColor;cFullFillRect()};this.addListenerInside('mouseover',cFullOver,this.getByElement(fullID+'-canvas'));this.addListenerInside('mouseout',cFullOut,this.getByElement(fullID+'-canvas'));var cEscFull=this.getByElement(escFullID+'-canvas').getContext('2d');var cEscFullFillRect=function(){thisTemp.canvasFillRect(cEscFull,[[20,9,3,9],[23,15,6,3],[9,20,9,3],[15,23,3,6]])};cEscFull.fillStyle=bBgColor;cEscFullFillRect();var cEscFullOver=function(){cEscFull.clearRect(0,0,bWidth,bHeight);cEscFull.fillStyle=bOverColor;cEscFullFillRect()};var cEscFullOut=function(){cEscFull.clearRect(0,0,bWidth,bHeight);cEscFull.fillStyle=bBgColor;cEscFullFillRect()};this.addListenerInside('mouseover',cEscFullOver,this.getByElement(escFullID+'-canvas'));this.addListenerInside('mouseout',cEscFullOut,this.getByElement(escFullID+'-canvas'));var cMute=this.getByElement(muteID+'-canvas').getContext('2d');var cMuteFillRect=function(){thisTemp.canvasFill(cMute,[[10,15],[15,15],[21,10],[21,28],[15,23],[10,23]]);thisTemp.canvasFillRect(cMute,[[23,15,2,8],[27,10,2,18]])};cMute.fillStyle=bBgColor;cMuteFillRect();var cMuteOver=function(){cMute.clearRect(0,0,bWidth,bHeight);cMute.fillStyle=bOverColor;cMuteFillRect()};var cMuteOut=function(){cMute.clearRect(0,0,bWidth,bHeight);cMute.fillStyle=bBgColor;cMuteFillRect()};this.addListenerInside('mouseover',cMuteOver,this.getByElement(muteID+'-canvas'));this.addListenerInside('mouseout',cMuteOut,this.getByElement(muteID+'-canvas'));var cEscMute=this.getByElement(escMuteID+'-canvas').getContext('2d');var cEscMuteFillRect=function(){thisTemp.canvasFill(cEscMute,[[10,15],[15,15],[21,10],[21,28],[15,23],[10,23]]);thisTemp.canvasFill(cEscMute,[[23,13],[24,13],[33,25],[32,25]]);thisTemp.canvasFill(cEscMute,[[32,13],[33,13],[24,25],[23,25]])};cEscMute.fillStyle=bBgColor;cEscMuteFillRect();var cEscMuteOver=function(){cEscMute.clearRect(0,0,bWidth,bHeight);cEscMute.fillStyle=bOverColor;cEscMuteFillRect()};var cEscMuteOut=function(){cEscMute.clearRect(0,0,bWidth,bHeight);cEscMute.fillStyle=bBgColor;cEscMuteFillRect()};this.addListenerInside('mouseover',cEscMuteOver,this.getByElement(escMuteID+'-canvas'));this.addListenerInside('mouseout',cEscMuteOut,this.getByElement(escMuteID+'-canvas'));var cAdMute=this.getByElement(adMuteID+'-canvas').getContext('2d');var cAdMuteFillRect=function(){thisTemp.canvasFill(cAdMute,[[8,12],[12,12],[16,8],[16,21],[12,18],[8,18]]);thisTemp.canvasFillRect(cAdMute,[[18,12,2,6],[21,8,2,14]])};cAdMute.fillStyle=bBgColor;cAdMuteFillRect();var cAdMuteOver=function(){cAdMute.clearRect(0,0,bWidth,bHeight);cAdMute.fillStyle=bOverColor;cAdMuteFillRect()};var cAdMuteOut=function(){cAdMute.clearRect(0,0,bWidth,bHeight);cAdMute.fillStyle=bBgColor;cAdMuteFillRect()};this.addListenerInside('mouseover',cAdMuteOver,this.getByElement(adMuteID+'-canvas'));this.addListenerInside('mouseout',cAdMuteOut,this.getByElement(adMuteID+'-canvas'));var cAdEscMute=this.getByElement(adEscMuteID+'-canvas').getContext('2d');var cAdEscMuteFillRect=function(){thisTemp.canvasFill(cAdEscMute,[[8,12],[12,12],[16,8],[16,21],[12,18],[8,18]]);thisTemp.canvasFill(cAdEscMute,[[18,10],[20,10],[26,20],[24,20]]);thisTemp.canvasFill(cAdEscMute,[[25,10],[27,10],[20,20],[18,20]])};cAdEscMute.fillStyle=bBgColor;cAdEscMuteFillRect();var cAdEscMuteOver=function(){cAdEscMute.clearRect(0,0,bWidth,bHeight);cAdEscMute.fillStyle=bOverColor;cAdEscMuteFillRect()};var cAdEscMuteOut=function(){cAdEscMute.clearRect(0,0,bWidth,bHeight);cAdEscMute.fillStyle=bBgColor;cAdEscMuteFillRect()};this.addListenerInside('mouseover',cAdEscMuteOver,this.getByElement(adEscMuteID+'-canvas'));this.addListenerInside('mouseout',cAdEscMuteOut,this.getByElement(adEscMuteID+'-canvas'));var adPauseClose=this.getByElement(adPauseCloseID+'-canvas').getContext('2d');var adPauseCloseFillRect=function(){thisTemp.canvasFill(adPauseClose,[[4,6],[6,6],[16,15],[14,15]]);thisTemp.canvasFill(adPauseClose,[[14,6],[16,6],[6,15],[4,15]])};adPauseClose.fillStyle='#404856';adPauseCloseFillRect();var adPauseCloseOver=function(){adPauseClose.clearRect(0,0,bWidth,bHeight);adPauseClose.fillStyle=bOverColor;adPauseCloseFillRect()};var adPauseCloseOut=function(){adPauseClose.clearRect(0,0,bWidth,bHeight);adPauseClose.fillStyle='#404856';adPauseCloseFillRect()};this.addListenerInside('mouseover',adPauseCloseOver,this.getByElement(adPauseCloseID+'-canvas'));this.addListenerInside('mouseout',adPauseCloseOut,this.getByElement(adPauseCloseID+'-canvas'));var cLoading=this.getByElement(loadingID+'-canvas').getContext('2d');var cLoadingFillRect=function(){cLoading.save();var grad=cLoading.createLinearGradient(0,0,60,60);grad.addColorStop(0,bBgColor);var grad2=cLoading.createLinearGradient(0,0,80,60);grad2.addColorStop(1,bOverColor);var grad3=cLoading.createLinearGradient(0,0,80,60);grad3.addColorStop(1,'#FF9900');var grad4=cLoading.createLinearGradient(0,0,80,60);grad4.addColorStop(1,'#CC3300');cLoading.strokeStyle=grad;cLoading.lineWidth=8;cLoading.beginPath();cLoading.arc(30,30,25,0,0.4*Math.PI,false);cLoading.stroke();cLoading.closePath();cLoading.beginPath();cLoading.strokeStyle=grad2;cLoading.arc(30,30,25,0.5*Math.PI,0.9*Math.PI,false);cLoading.stroke();cLoading.beginPath();cLoading.strokeStyle=grad3;cLoading.arc(30,30,25,Math.PI,1.4*Math.PI,false);cLoading.stroke();cLoading.beginPath();cLoading.strokeStyle=grad4;cLoading.arc(30,30,25,1.5*Math.PI,1.9*Math.PI,false);cLoading.stroke();cLoading.closePath();cLoading.restore()};cLoading.fillStyle=bBgColor;cLoadingFillRect();var cPauseCenter=this.getByElement(pauseCenterID+'-canvas').getContext('2d');var cPauseCenterFillRect=function(){thisTemp.canvasFill(cPauseCenter,[[28,22],[59,38],[28,58]]);cPauseCenter.save();cPauseCenter.lineWidth=5;cPauseCenter.beginPath();cPauseCenter.arc(40,40,35,0,2*Math.PI,false);cPauseCenter.stroke();cPauseCenter.closePath();cPauseCenter.restore()};cPauseCenter.fillStyle=bBgColor;cPauseCenter.strokeStyle=bBgColor;cPauseCenterFillRect();var cPauseCenterOver=function(){cPauseCenter.clearRect(0,0,80,80);cPauseCenter.fillStyle=bOverColor;cPauseCenter.strokeStyle=bOverColor;cPauseCenterFillRect()};var cPauseCenterOut=function(){cPauseCenter.clearRect(0,0,80,80);cPauseCenter.fillStyle=bBgColor;cPauseCenter.strokeStyle=bBgColor;cPauseCenterFillRect()};this.addListenerInside('mouseover',cPauseCenterOver,this.getByElement(pauseCenterID+'-canvas'));this.addListenerInside('mouseout',cPauseCenterOut,this.getByElement(pauseCenterID+'-canvas'));var volumeBOOver=function(){thisTemp.css(volumeBOID,'backgroundColor',bOverColor);thisTemp.css(volumeBWID,'backgroundColor',bBgColor)};var volumeBOOut=function(){thisTemp.css(volumeBOID,'backgroundColor',bBgColor);thisTemp.css(volumeBWID,'backgroundColor',bOverColor)};this.addListenerInside('mouseover',volumeBOOver,this.getByElement(volumeBOID));this.addListenerInside('mouseout',volumeBOOut,this.getByElement(volumeBOID));var timeBOOver=function(){thisTemp.css(timeBOID,'backgroundColor',bOverColor);thisTemp.css(timeBWID,'backgroundColor',bBgColor)};var timeBOOut=function(){thisTemp.css(timeBOID,'backgroundColor',bBgColor);thisTemp.css(timeBWID,'backgroundColor',bOverColor)};this.addListenerInside('mouseover',timeBOOver,this.getByElement(timeBOID));this.addListenerInside('mouseout',timeBOOut,this.getByElement(timeBOID));this.addButtonEvent();this.newMenu();this.controlBarHide();this.keypress();this.changeVolume(this.vars['volume']);this.showFrontNext();setTimeout(function(){thisTemp.elementCoordinate()},100);this.checkBarWidth();var resize=function(){thisTemp.elementCoordinate();thisTemp.timeUpdateHandler();thisTemp.changeLoad();thisTemp.checkBarWidth();thisTemp.changeElementCoor();thisTemp.changePrompt();thisTemp.adPauseCoor();thisTemp.adOtherCoor()};this.addListenerInside('resize',resize,window)},newCanvas:function(id,width,height){return'<canvas class=""'+id+'-canvas"" width=""'+width+'"" height=""'+height+'""></canvas>'},addButtonEvent:function(){var thisTemp=this;var playClick=function(event){thisTemp.videoPlay();thisTemp.sendJS('clickEvent','actionScript->videoPlay')};this.addListenerInside('click',playClick,this.CB['play']);this.addListenerInside('click',playClick,this.CB['pauseCenter']);var pauseClick=function(event){thisTemp.videoPause();thisTemp.sendJS('clickEvent','actionScript->videoPause')};this.addListenerInside('click',pauseClick,this.CB['pause']);var frontClick=function(event){if(thisTemp.vars['front']){eval(thisTemp.vars['front']+'()');thisTemp.sendJS('clickEvent','actionScript->'+thisTemp.vars['front'])}};this.addListenerInside('click',frontClick,this.CB['front']);var nextClick=function(event){if(thisTemp.vars['next']){eval(thisTemp.vars['next']+'()');thisTemp.sendJS('clickEvent','actionScript->'+thisTemp.vars['next'])}};this.addListenerInside('click',nextClick,this.CB['next']);var muteClick=function(event){thisTemp.videoMute();thisTemp.sendJS('clickEvent','actionScript->videoMute')};this.addListenerInside('click',muteClick,this.CB['mute']);var escMuteClick=function(event){thisTemp.videoEscMute();thisTemp.sendJS('clickEvent','actionScript->videoEscMute')};this.addListenerInside('click',escMuteClick,this.CB['escMute']);var fullClick=function(event){thisTemp.fullScreen();thisTemp.sendJS('clickEvent','actionScript->fullScreen')};this.addListenerInside('click',fullClick,this.CB['full']);var escFullClick=function(event){thisTemp.quitFullScreen();thisTemp.sendJS('clickEvent','actionScript->quitFullScreen')};this.addListenerInside('click',escFullClick,this.CB['escFull']);var adSkipClick=function(event){if(thisTemp.CB['adSkip'].innerHTML==thisTemp.language['skipAd']){thisTemp.runFunction(thisTemp.config['adSkipClick'])}};this.addListenerInside('click',adSkipClick,this.CB['adSkip']);var adMuteClick=function(event){thisTemp.adMuteFunction()};this.addListenerInside('click',adMuteClick,this.CB['adMute']);var adEscMuteClick=function(event){thisTemp.adEscMuteFunction()};this.addListenerInside('click',adEscMuteClick,this.CB['adEscMute']);var adPauseCloseClick=function(event){thisTemp.adPauseCloseFunction()};this.addListenerInside('click',adPauseCloseClick,this.CB['adPauseClose']);var promptHide=function(event){thisTemp.promptShow(false)};var playOver=function(event){thisTemp.promptShow(thisTemp.CB['play'])};this.addListenerInside('mouseover',playOver,this.CB['play']);this.addListenerInside('mouseout',promptHide,this.CB['play']);var pauseOver=function(event){thisTemp.promptShow(thisTemp.CB['pause'])};this.addListenerInside('mouseover',pauseOver,this.CB['pause']);this.addListenerInside('mouseout',promptHide,this.CB['pause']);var frontOver=function(event){thisTemp.promptShow(thisTemp.CB['front'])};this.addListenerInside('mouseover',frontOver,this.CB['front']);this.addListenerInside('mouseout',promptHide,this.CB['front']);var nextOver=function(event){thisTemp.promptShow(thisTemp.CB['next'])};this.addListenerInside('mouseover',nextOver,this.CB['next']);this.addListenerInside('mouseout',promptHide,this.CB['next']);var muteOver=function(event){thisTemp.promptShow(thisTemp.CB['mute'])};this.addListenerInside('mouseover',muteOver,this.CB['mute']);this.addListenerInside('mouseout',promptHide,this.CB['mute']);var escMuteOver=function(event){thisTemp.promptShow(thisTemp.CB['escMute'])};this.addListenerInside('mouseover',escMuteOver,this.CB['escMute']);this.addListenerInside('mouseout',promptHide,this.CB['escMute']);var fullOver=function(event){thisTemp.promptShow(thisTemp.CB['full'])};this.addListenerInside('mouseover',fullOver,this.CB['full']);this.addListenerInside('mouseout',promptHide,this.CB['full']);var escFullOver=function(event){thisTemp.promptShow(thisTemp.CB['escFull'])};this.addListenerInside('mouseover',escFullOver,this.CB['escFull']);this.addListenerInside('mouseout',promptHide,this.CB['escFull']);var definitionOver=function(event){thisTemp.promptShow(thisTemp.CB['definition'])};this.addListenerInside('mouseover',definitionOver,this.CB['definition']);this.addListenerInside('mouseout',promptHide,this.CB['definition']);var playbackrateOver=function(event){thisTemp.promptShow(thisTemp.CB['playbackrate'])};this.addListenerInside('mouseover',playbackrateOver,this.CB['playbackrate']);this.addListenerInside('mouseout',promptHide,this.CB['playbackrate']);var volumePrompt=function(vol){var volumeBOXY=thisTemp.getCoor(thisTemp.CB['volumeBO']);var promptObj={title:thisTemp.language['volume']+vol+'%',x:volumeBOXY['x']+thisTemp.CB['volumeBO'].offsetWidth*0.5,y:volumeBOXY['y']};thisTemp.promptShow(false,promptObj)};var volumeObj={slider:this.CB['volumeBO'],follow:this.CB['volumeUp'],refer:this.CB['volumeBg'],grossValue:'volume',pd:true,startFun:function(vol){},monitorFun:function(vol){thisTemp.changeVolume(vol*0.01,false,false);volumePrompt(vol)},endFun:function(vol){},overFun:function(vol){volumePrompt(vol)}};this.slider(volumeObj);var volumeClickObj={refer:this.CB['volumeBg'],grossValue:'volume',fun:function(vol){thisTemp.changeVolume(vol*0.01,true,true)}};this.progressClick(volumeClickObj);this.timeButtonMouseDown();var volumeBgMove=function(event){var volumeBgXY=thisTemp.getCoor(thisTemp.CB['volumeBg']);var eventX=thisTemp.client(event)['x'];var eventVolume=parseInt((eventX-volumeBgXY['x'])*100/thisTemp.CB['volumeBg'].offsetWidth);var buttonPromptObj={title:thisTemp.language['volume']+eventVolume+'%',x:eventX,y:volumeBgXY['y']};thisTemp.promptShow(false,buttonPromptObj)};this.addListenerInside('mousemove',volumeBgMove,this.CB['volumeBg']);this.addListenerInside('mouseout',promptHide,this.CB['volumeBg']);this.addListenerInside('mouseout',promptHide,this.CB['volumeBO']);this.addDefListener();this.addPlaybackrate()},videoClick:function(){var thisTemp=this;var clearTimerClick=function(){if(thisTemp.timerClick!=null){if(thisTemp.timerClick.runing){thisTemp.timerClick.stop()}thisTemp.timerClick=null}};var timerClickFun=function(){clearTimerClick();thisTemp.isClick=false;if(thisTemp.adPlayerPlay){var ad=thisTemp.getNowAdvertisements();try{if(ad['link']!=''){window.open(ad['link'])}thisTemp.ajaxSuccessNull(ad['clickMonitor'])}catch(event){}}else{if(thisTemp.ckplayerConfig['config']['click']){thisTemp.playOrPause()}}};clearTimerClick();if(this.isClick){this.isClick=false;if(thisTemp.ckplayerConfig['config']['doubleClick']){if(!this.full){thisTemp.fullScreen()}else{thisTemp.quitFullScreen()}}}else{this.isClick=true;this.timerClick=new this.timer(300,timerClickFun,1)}},timeButtonMouseDown:function(){var thisTemp=this;var timePrompt=function(time){if(isNaN(time)){time=0}var timeButtonXY=thisTemp.getCoor(thisTemp.CB['timeButton']);var promptObj={title:thisTemp.formatTime(time),x:timeButtonXY['x']-thisTemp.pdCoor['x']+thisTemp.CB['timeButton'].offsetWidth*0.5,y:timeButtonXY['y']-thisTemp.pdCoor['y']};thisTemp.promptShow(false,promptObj)};var timeObj={slider:this.CB['timeButton'],follow:this.CB['timeProgress'],refer:this.CB['timeBoBg'],grossValue:'time',pd:false,startFun:function(time){thisTemp.isTimeButtonMove=false},monitorFun:function(time){},endFun:function(time){if(thisTemp.V){if(thisTemp.V.duration>0){thisTemp.needSeek=0;thisTemp.videoSeek(parseInt(time))}}},overFun:function(time){timePrompt(time)}};var timeClickObj={refer:this.CB['timeBoBg'],grossValue:'time',fun:function(time){if(thisTemp.V){if(thisTemp.V.duration>0){thisTemp.needSeek=0;thisTemp.videoSeek(parseInt(time))}}}};var timeBoBgmousemove=function(event){var timeBoBgXY=thisTemp.getCoor(thisTemp.CB['timeBoBg']);var eventX=thisTemp.client(event)['x'];var eventTime=parseInt((eventX-timeBoBgXY['x'])*thisTemp.V.duration/thisTemp.CB['timeBoBg'].offsetWidth);var buttonPromptObj={title:thisTemp.formatTime(eventTime),x:eventX,y:timeBoBgXY['y']};thisTemp.promptShow(false,buttonPromptObj);var def=false;if(!thisTemp.isUndefined(thisTemp.CB['definitionP'])){if(thisTemp.css(thisTemp.CB['definitionP'],'display')!='block'){def=true}}if(thisTemp.vars['preview']!=null&&def){buttonPromptObj['time']=eventTime;thisTemp.preview(buttonPromptObj)}};var promptHide=function(event){thisTemp.promptShow(false);if(thisTemp.previewDiv!=null){thisTemp.css([thisTemp.previewDiv,thisTemp.previewTop],'display','none')}};if(!this.vars['live']){this.isTimeButtonDown=true;this.addListenerInside('mousemove',timeBoBgmousemove,this.CB['timeBoBg']);this.addListenerInside('mouseout',promptHide,this.CB['timeBoBg'])}else{this.isTimeButtonDown=false;timeObj['removeListenerInside']=true;timeClickObj['removeListenerInside']=true}this.slider(timeObj);this.progressClick(timeClickObj)},progressClick:function(obj){var thisTemp=this;var referMouseClick=function(event){var referX=thisTemp.client(event)['x']-thisTemp.getCoor(obj['refer'])['x'];var rWidth=obj['refer'].offsetWidth;var grossValue=0;if(obj['grossValue']=='volume'){grossValue=100}else{if(thisTemp.V){grossValue=thisTemp.V.duration}}var nowZ=parseInt(referX*grossValue/rWidth);if(obj['fun']){if(obj['grossValue']==='time'){var sliderXY=thisTemp.getCoor(thisTemp.CB['timeButton']);sliderLeft=sliderXY['x'];if(!thisTemp.checkSlideLeft(referX,sliderLeft,rWidth)){return}var bimeButtonWB=thisTemp.CB['timeButton'].offsetWidth*0.5;thisTemp.css(thisTemp.CB['timeButton'],'left',(referX-bimeButtonWB)+'px');thisTemp.css(thisTemp.CB['timeProgress'],'width',(referX)+'px')}obj['fun'](nowZ)}};if(this.isUndefined(obj['removeListenerInside'])){this.addListenerInside('click',referMouseClick,obj['refer'])}else{this.removeListenerInside('click',referMouseClick,obj['refer'])}},slider:function(obj){var thisTemp=this;var clientX=0,criterionWidth=0,sliderLeft=0,referLeft=0;var value=0;var calculation=function(){var sLeft=parseInt(thisTemp.css(obj['slider'],'left'));var rWidth=obj['refer'].offsetWidth-obj['slider'].offsetWidth;var grossValue=0;if(thisTemp.isUndefined(sLeft)||isNaN(sLeft)){sLeft=0}if(obj['grossValue']=='volume'){grossValue=100}else{if(thisTemp.V){grossValue=thisTemp.V.duration}}return parseInt(sLeft*grossValue/rWidth)};var mDown=function(event){thisTemp.addListenerInside('mousemove',mMove,document);thisTemp.addListenerInside('mouseup',mUp,document);var referXY=thisTemp.getCoor(obj['refer']);var sliderXY=thisTemp.getCoor(obj['slider']);clientX=thisTemp.client(event)['x'];referLeft=referXY['x'];sliderLeft=sliderXY['x'];criterionWidth=clientX-sliderLeft;if(obj['startFun']){obj['startFun'](calculation())}};var mMove=function(event){clientX=thisTemp.client(event)['x'];var newX=clientX-criterionWidth-referLeft;if(newX<0){newX=0}if(newX>obj['refer'].offsetWidth-obj['slider'].offsetWidth){newX=obj['refer'].offsetWidth-obj['slider'].offsetWidth}if(obj['slider']===thisTemp.CB['timeButton']){if(!thisTemp.checkSlideLeft(newX,sliderLeft,obj['refer'].offsetWidth)){return}}thisTemp.css(obj['slider'],'left',newX+'px');thisTemp.css(obj['follow'],'width',(newX+obj['slider'].offsetWidth*0.5)+'px');var nowZ=calculation();if(obj['monitorFun']){obj['monitorFun'](nowZ)}};var mUp=function(event){thisTemp.removeListenerInside('mousemove',mMove,document);thisTemp.removeListenerInside('mouseup',mUp,document);if(obj['endFun']){obj['endFun'](calculation())}};var mOver=function(event){if(obj['overFun']){obj['overFun'](calculation())}};if(this.isUndefined(obj['removeListenerInside'])){this.addListenerInside('mousedown',mDown,obj['slider']);this.addListenerInside('mouseover',mOver,obj['slider'])}else{this.removeListenerInside('mousedown',mDown,obj['slider']);this.removeListenerInside('mouseover',mOver,obj['slider'])}},checkSlideLeft:function(newX,sliderLeft,refer){var timeSA=this.ckplayerConfig['config']['timeScheduleAdjust'];switch(timeSA){case 0:return false;break;case 2:if(newX<sliderLeft){return false}break;case 3:if(newX>sliderLeft){return false}break;case 4:if(!this.timeSliderLeftTemp){this.timeSliderLeftTemp=sliderLeft/refer}if(newX<this.timeSliderLeftTemp*refer){return false}break;case 5:if(!this.timeSliderLeftTemp){this.timeSliderLeftTemp=sliderLeft/refer}else{var timeSliderMax=sliderLeft/refer;if(timeSliderMax>this.timeSliderLeftTemp){this.timeSliderLeftTemp=timeSliderMax}}if(newX>this.timeSliderLeftTemp*refer){return false}break;default:return true;break}return true},loadingStart:function(rot){var thisTemp=this;if(this.isUndefined(rot)){rot=true}if(this.showFace){this.css(thisTemp.CB['loading'],'display','none')}if(this.timerLoading!=null){if(this.timerLoading.runing){this.timerLoading.stop()}this.timerLoading=null}var buffer=0;var loadingFun=function(){var nowRotate='0';try{nowRotate=thisTemp.css(thisTemp.CB['loadingCanvas'],'transform')||thisTemp.css(thisTemp.CB['loadingCanvas'],'-ms-transform')||thisTemp.css(thisTemp.CB['loadingCanvas'],'-moz-transform')||thisTemp.css(thisTemp.CB['loadingCanvas'],'-webkit-transform')||thisTemp.css(thisTemp.CB['loadingCanvas'],'-o-transform')||'0'}catch(event){}nowRotate=parseInt(nowRotate.replace('rotate(','').replace('deg);',''));nowRotate+=4;if(nowRotate>360){nowRotate=0}if(thisTemp.showFace){thisTemp.css(thisTemp.CB['loadingCanvas'],{transform:'rotate('+nowRotate+'deg)',msTransform:'rotate('+nowRotate+'deg)',mozTransform:'rotate('+nowRotate+'deg)',webkitTransform:'rotate('+nowRotate+'deg)',oTransform:'rotate('+nowRotate+'deg)'})}buffer++;if(buffer>=99){buffer=99}thisTemp.sendJS('buffer',buffer)};if(rot){this.timerLoading=new this.timer(10,loadingFun);if(this.showFace){this.css(thisTemp.CB['loading'],'display','block')}}else{thisTemp.sendJS('buffer',100)}},showFrontNext:function(){if(!this.showFace){return}if(this.vars['front']){this.css([this.CB['front'],this.CB['frontLine']],'display','block')}else{this.css([this.CB['front'],this.CB['frontLine']],'display','none')}if(this.vars['next']){this.css([this.CB['next'],this.CB['nextLine']],'display','block')}else{this.css([this.CB['next'],this.CB['nextLine']],'display','none')}},promptShow:function(ele,data){if(!this.showFace){return}var obj={};if(ele||data){if(!this.isUndefined(data)){obj=data}else{var offsetCoor=this.getCoor(ele);obj={title:this.getDataset(ele,'title'),x:offsetCoor['x']+ele.offsetWidth*0.5,y:offsetCoor['y']}}this.CB['prompt'].innerHTML=obj['title'];this.css(this.CB['prompt'],'display','block');var promoptWidth=this.getStringLen(obj['title'])*10;this.css(this.CB['promptBg'],'width',promoptWidth+'px');this.css(this.CB['prompt'],'width',promoptWidth+'px');promoptWidth+=10;var x=obj['x']-(promoptWidth*0.5);var y=this.PD.offsetHeight-obj['y']+8;if(x<0){x=0}if(x>this.PD.offsetWidth-promoptWidth){x=this.PD.offsetWidth-promoptWidth}this.css([this.CB['promptBg'],this.CB['prompt']],{display:'block',left:x+'px',bottom:y+'px'})}else{this.css([this.CB['promptBg'],this.CB['prompt']],{display:'none'})}},timerErrorFun:function(){var thisTemp=this;this.errorSend=false;var clearIntervalError=function(event){if(thisTemp.timerError!=null){if(thisTemp.timerError.runing){thisTemp.timerError.stop()}thisTemp.timerError=null}};var errorFun=function(event){clearIntervalError();thisTemp.error=true;thisTemp.errorUrl=thisTemp.getVideoUrl();if(!thisTemp.errorSend){thisTemp.errorSend=true;thisTemp.sendJS('error')}if(thisTemp.showFace){thisTemp.css(thisTemp.CB['errorText'],'display','block');thisTemp.css(thisTemp.CB['pauseCenter'],'display','none');thisTemp.css(thisTemp.CB['loading'],'display','none')}thisTemp.V.removeAttribute('poster');thisTemp.resetPlayer()};var errorListenerFun=function(event){setTimeout(function(){if(isNaN(thisTemp.V.duration)){errorFun(event)}},500)};if(!this.errorAdd){this.errorAdd=true;this.addListenerInside('error',errorListenerFun,this.V)}clearIntervalError();var timerErrorFun=function(){if(thisTemp.V&&parseInt(thisTemp.V.networkState)==3){errorFun()}};this.timerError=new this.timer(this.config['errorTime'],timerErrorFun)},judgeFullScreen:function(){var thisTemp=this;if(this.timerFull!=null){if(this.timerFull.runing){this.timerFull.stop()}this.timerFull=null}var fullFun=function(){thisTemp.isFullScreen()};this.timerFull=new this.timer(20,fullFun)},isFullScreen:function(){if(!this.showFace){return}var fullState=document.fullScreen||document.mozFullScreen||document.webkitIsFullScreen||document.msFullscreenElement;if(fullState&&!this.full){this.full=true;this.sendJS('full',true);this.elementCoordinate();this.css(this.CB['full'],'display','none');this.css(this.CB['escFull'],'display','block');if(this.vars['live']==0){this.timeUpdateHandler()}this.PD.appendChild(this.CB['menu'])}if(!fullState&&this.full){this.full=false;this.sendJS('full',false);this.elementCoordinate();this.css(this.CB['full'],'display','block');this.css(this.CB['escFull'],'display','none');if(this.timerFull!=null){if(this.timerFull.runing){this.timerFull.stop()}this.timerFull=null}if(this.vars['live']==0){this.timeUpdateHandler()}this.body.appendChild(this.CB['menu'])}},newMenu:function(){var thisTemp=this;var i=0;this.css(this.CB['menu'],{backgroundColor:'#FFFFFF',padding:'5px',position:'absolute',left:'10px',top:'20px',display:'none',zIndex:'999',color:'#A1A9BE',boxShadow:'2px 2px 3px #AAAAAA'});var mArr=this.contextMenu;var cMenu=this.ckplayerConfig['menu'];if(cMenu['name']){if(cMenu['link']){mArr[0]=[cMenu['name'],'link',cMenu['link']]}else{mArr[0]=[cMenu['name'],'default']}}if(cMenu['version']){mArr[1]=[cMenu['version'],'default','line']}if(cMenu['more']){if(typeof(cMenu['more'])=='object'){if(cMenu['more'].length>0){var moreArr=cMenu['more'];for(i=0;i<moreArr.length;i++){var mTemp=moreArr[i];var arrTemp=[];if(mTemp['name']){arrTemp.push(mTemp['name'])}if(mTemp['clickEvent']&&mTemp['clickEvent']!='none'){var eveObj=this.clickEvent(mTemp['clickEvent']);arrTemp.push(eveObj['type']);if(eveObj['fun']){arrTemp.push(eveObj['fun'])}if(eveObj['link']){arrTemp.push(eveObj['link'])}if(eveObj['target']){arrTemp.push(' target=""'+eveObj['target']+'""')}}if(mTemp['separatorBefore']){arrTemp.push('line')}mArr.push(arrTemp)}}}}var html='';for(i=0;i<mArr.length;i++){var me=mArr[i];switch(me[1]){case'default':html+='<p>'+me[0]+'</p>';break;case'link':if(me[3]){me[3]='target=""'+me[3]+'""'}html+='<p><a href=""'+me[2]+'""'+me[3]+'>'+me[0]+'</a></p>';break;case'javaScript':html+='<p><a href=""javascript:'+me[2]+'"">'+me[0]+'</a></p>';break;case'actionScript':html+='<p><a href=""javascript:'+this.vars['variable']+me[2].replace('thisTemp','')+'"">'+me[0]+'</a></p>';break;default:break}}this.CB['menu'].innerHTML=html;var pArr=this.CB['menu'].childNodes;for(i=0;i<pArr.length;i++){this.css(pArr[i],{height:'30px',lineHeight:'30px',margin:'0px',fontFamily:this.fontFamily,fontSize:'12px',paddingLeft:'10px',paddingRight:'30px'});if(mArr[i][mArr[i].length-1]=='line'){this.css(pArr[i],'borderBottom','1px solid #e9e9e9')}var aArr=pArr[i].childNodes;for(var n=0;n<aArr.length;n++){if(aArr[n].localName=='a'){this.css(aArr[n],{color:'#000000',textDecoration:'none'})}}}this.PD.oncontextmenu=function(event){var eve=event||window.event;var client=thisTemp.client(event);if(eve.button==2){eve.returnvalue=false;var x=client['x']+thisTemp.pdCoor['x']-2;var y=client['y']+thisTemp.pdCoor['y']-2;thisTemp.css(thisTemp.CB['menu'],{display:'block',left:x+'px',top:y+'px'});return false}return true};var setTimeOutPClose=function(){if(setTimeOutP){window.clearTimeout(setTimeOutP);setTimeOutP=null}};var setTimeOutP=null;var mouseOut=function(event){setTimeOutPClose();setTimeOutP=setTimeout(function(event){thisTemp.css(thisTemp.CB['menu'],'display','none')},500)};this.addListenerInside('mouseout',mouseOut,thisTemp.CB['menu']);var mouseOver=function(event){setTimeOutPClose()};this.addListenerInside('mouseover',mouseOver,thisTemp.CB['menu'])},controlBarHide:function(hide){var thisTemp=this;var client={x:0,y:0},oldClient={x:0,y:0};var cShow=true,force=false;var oldCoor=[0,0];var controlBarShow=function(show){if(show&&!cShow&&thisTemp.controlBarIsShow){cShow=true;thisTemp.sendJS('controlBar',true);thisTemp.css(thisTemp.CB['controlBarBg'],'display','block');thisTemp.css(thisTemp.CB['controlBar'],'display','block');thisTemp.css(thisTemp.CB['timeProgressBg'],'display','block');thisTemp.css(thisTemp.CB['timeBoBg'],'display','block');thisTemp.changeVolume(thisTemp.volume);thisTemp.changeLoad();if(!thisTemp.timerBuffer){thisTemp.bufferEdHandler()}}else{if(cShow){cShow=false;var paused=thisTemp.getMetaDate()['paused'];if(force){paused=false}if(!paused){thisTemp.sendJS('controlBar',false);thisTemp.css(thisTemp.CB['controlBarBg'],'display','none');thisTemp.css(thisTemp.CB['controlBar'],'display','none');thisTemp.css(thisTemp.CB['timeProgressBg'],'display','none');thisTemp.css(thisTemp.CB['timeBoBg'],'display','none');thisTemp.promptShow(false)}}}};var cbarFun=function(event){if(client['x']==oldClient['x']&&client['y']==oldClient['y']){var cdH=parseInt(thisTemp.CD.offsetHeight);if((client['y']<cdH-50||client['y']>cdH-2)&&cShow&&!thisTemp.getMetaDate()['paused']){controlBarShow(false)}}else{if(!cShow){controlBarShow(true)}}oldClient={x:client['x'],y:client['y']}};this.timerCBar=new this.timer(2000,cbarFun);var cdMove=function(event){var getClient=thisTemp.client(event);client['x']=getClient['x'];client['y']=getClient['y'];if(!cShow){controlBarShow(true)}};this.addListenerInside('mousemove',cdMove,thisTemp.CD);this.addListenerInside('ended',cdMove);this.addListenerInside('resize',cdMove,window);if(hide===true){cShow=true;force=true;controlBarShow(false)}if(hide===false){cShow=false;force=true;controlBarShow(true)}},keypress:function(){var thisTemp=this;var keyDown=function(eve){var keycode=eve.keyCode||eve.which;if(this.adPlayerPlay){return}switch(keycode){case 32:thisTemp.playOrPause();break;case 37:thisTemp.fastBack();break;case 39:thisTemp.fastNext();break;case 38:now=thisTemp.volume+thisTemp.ckplayerConfig['config']['volumeJump'];thisTemp.changeVolume(now>1?1:now);break;case 40:now=thisTemp.volume-thisTemp.ckplayerConfig['config']['volumeJump'];thisTemp.changeVolume(now<0?0:now);break;default:break}};this.addListenerInside('keydown',keyDown,window||document)},playbackRate:function(){if(!this.showFace){return}var thisTemp=this;var vArr=this.playbackRateArr;var html='';var nowD='';var i=0;if(!nowD){nowD=vArr[this.playbackRateDefault][1]}if(vArr.length>1){var zlen=0;for(i=0;i<vArr.length;i++){html='<p>'+vArr[i][1]+'</p>'+html;var dlen=this.getStringLen(vArr[i][1]);if(dlen>zlen){zlen=dlen}}if(html){html+='<p>'+nowD+'</p>'}this.CB['playbackrate'].innerHTML=nowD;this.CB['playbackrateP'].innerHTML=html;this.css([this.CB['playbackrate'],this.CB['playbackrateLine']],'display','block');var pArr=this.CB['playbackrateP'].childNodes;for(var i=0;i<pArr.length;i++){var fontColor='#FFFFFF';if(pArr[i].innerHTML==nowD){fontColor='#0782F5'}this.css(pArr[i],{color:fontColor,margin:'0px',padding:'0px',fontSize:'14px'});if(i<pArr.length-1){this.css(pArr[i],'borderBottom','1px solid #282828')}var defClick=function(event){if(nowD!=this.innerHTML){thisTemp.css(thisTemp.CB['playbackrateP'],'display','none');thisTemp.newPlaybackrate(this.innerHTML);thisTemp.sendJS('clickEvent','actionScript->newPlaybackrate')}};this.addListenerInside('click',defClick,pArr[i])}var pW=(zlen*10)+20;this.css(this.CB['playbackrateP'],{width:pW+'px'});this.css(this.CB['playbackrate'],{width:pW+'px'});this.buttonWidth['playbackrate']=this.CB['playbackrate'].offsetWidth}else{this.CB['playbackrate'].innerHTML='';this.CB['playbackrateP'].innerHTML='';this.css([this.CB['playbackrate'],this.CB['playbackrateLine']],'display','none')}},addPlaybackrate:function(){var thisTemp=this;var setTimeOutP=null;var defClick=function(event){thisTemp.css(thisTemp.CB['playbackrateP'],{left:thisTemp.getCoor(thisTemp.CB['playbackrate'])['x']+'px',display:'block'})};this.addListenerInside('click',defClick,this.CB['playbackrate']);var defMouseOut=function(event){if(setTimeOutP){window.clearTimeout(setTimeOutP);setTimeOutP=null}setTimeOutP=setTimeout(function(event){thisTemp.css(thisTemp.CB['playbackrateP'],'display','none')},500)};this.addListenerInside('mouseout',defMouseOut,thisTemp.CB['playbackrateP']);var defMouseOver=function(event){if(setTimeOutP){window.clearTimeout(setTimeOutP);setTimeOutP=null}};this.addListenerInside('mouseover',defMouseOver,thisTemp.CB['playbackrateP'])},newPlaybackrate:function(title){var vArr=this.playbackRateArr;var nVArr=[];var i=0;for(i=0;i<vArr.length;i++){var v=vArr[i];if(v[1]==title){this.playbackRateDefault=i;this.V.playbackRate=v[0];if(this.showFace){this.CB['playbackrate'].innerHTML=v[1];this.playbackRate()}this.sendJS('playbackRate',v)}}},definition:function(){if(!this.showFace){return}var thisTemp=this;var vArr=this.VA;var dArr=[];var html='';var nowD='';var i=0;for(i=0;i<vArr.length;i++){var d=vArr[i][2];if(dArr.indexOf(d)==-1){dArr.push(d)}if(this.V){if(vArr[i][0]==this.V.currentSrc){nowD=d}}}if(!nowD){nowD=dArr[0]}if(dArr.length>1){var zlen=0;for(i=dArr.length-1;i>-1;i--){html='<p>'+dArr[i]+'</p>'+html;var dlen=this.getStringLen(dArr[i]);if(dlen>zlen){zlen=dlen}}if(html){html+='<p>'+nowD+'</p>'}this.CB['definition'].innerHTML=nowD;this.CB['definitionP'].innerHTML=html;this.css([this.CB['definition'],this.CB['definitionLine']],'display','block');var pArr=this.CB['definitionP'].childNodes;for(var i=0;i<pArr.length;i++){var fontColor='#FFFFFF';if(pArr[i].innerHTML==nowD){fontColor='#0782F5'}this.css(pArr[i],{color:fontColor,margin:'0px',padding:'0px',fontSize:'14px'});if(i<pArr.length-1){this.css(pArr[i],'borderBottom','1px solid #282828')}var defClick=function(){if(nowD!=this.innerHTML){thisTemp.css(thisTemp.CB['definitionP'],'display','none');thisTemp.newDefinition(this.innerHTML)}};this.addListenerInside('click',defClick,pArr[i])}var pW=(zlen*10)+20;this.css(this.CB['definitionP'],{width:pW+'px'});this.css(this.CB['definition'],{width:pW+'px'});this.buttonWidth['definition']=this.CB['definition'].offsetWidth}else{this.CB['definition'].innerHTML='';this.CB['definitionP'].innerHTML='';this.css([this.CB['definition'],this.CB['definitionLine']],'display','none')}},addDefListener:function(){var thisTemp=this;var setTimeOutP=null;var defClick=function(event){thisTemp.css(thisTemp.CB['definitionP'],{left:thisTemp.getCoor(thisTemp.CB['definition'])['x']+'px',display:'block'})};this.addListenerInside('click',defClick,this.CB['definition']);var defMouseOut=function(event){if(setTimeOutP){window.clearTimeout(setTimeOutP);setTimeOutP=null}setTimeOutP=setTimeout(function(event){thisTemp.css(thisTemp.CB['definitionP'],'display','none')},500)};this.addListenerInside('mouseout',defMouseOut,thisTemp.CB['definitionP']);var defMouseOver=function(event){if(setTimeOutP){window.clearTimeout(setTimeOutP);setTimeOutP=null}};this.addListenerInside('mouseover',defMouseOver,thisTemp.CB['definitionP'])},changeDefinition:function(n){if(!this.loaded||n<0){return}if(this.playerType=='flashplayer'){this.V.changeDefinition(n);return}if(this.VA.length>n){var arr=this.VA[n];if(arr.length>3){var title=arr[2];if(title){this.newDefinition(title)}}}},newDefinition:function(title){var vArr=this.VA;var nVArr=[];var i=0;for(i=0;i<vArr.length;i++){var v=vArr[i];if(v[2]==title){nVArr.push(v);this.sendJS('definitionChange',i+'')}}if(nVArr.length<1){return}if(this.V!=null&&this.needSeek==0){this.needSeek=this.V.currentTime}if(this.getFileExt(nVArr[0][0])!='.m3u8'){this.isM3u8=false}if(!this.isM3u8){if(nVArr.length==1){this.V.innerHTML='';this.V.src=nVArr[0][0];this.V.currentSrc=nVArr[0][0]}else{var source='';nVArr=this.arrSort(nVArr);for(i=0;i<nVArr.length;i++){var type='';var va=nVArr[i];if(va[1]){type=' type=""'+va[1]+'""'}source+='<source src=""'+va[0]+'""'+type+'>'}this.V.removeAttribute('src');this.V.innerHTML=source;this.V.currentSrc=nVArr[0][0]}}else{this.embedHls(vArr[0][0],this.vars['autoplay'])}this.V.autoplay='autoplay';this.V.load();this.timerErrorFun()},embedHls:function(url,autoplay){var thisTemp=this;if(Hls.isSupported()){var hls=new Hls();hls.loadSource(url);hls.attachMedia(this.V);hls.on(Hls.Events.MANIFEST_PARSED,function(){thisTemp.playerLoad();if(autoplay){thisTemp.videoPlay()}})}},prompt:function(){if(!this.showFace){return}var thisTemp=this;var prompt=this.vars['promptSpot'];if(prompt==null||this.promptArr.length>0){return}var showPrompt=function(event){if(thisTemp.promptElement==null){var random2='prompte'+thisTemp.randomString(5);var ele2=document.createElement('div');ele2.className=random2;thisTemp.PD.appendChild(ele2);thisTemp.promptElement=thisTemp.getByElement(random2);thisTemp.css(thisTemp.promptElement,{overflowX:'hidden',lineHeight:'22px',fontSize:'14px',color:'#FFFFFF',position:'absolute',display:'block',zIndex:'90'})}var pcon=thisTemp.getPromptTest();var pW=pcon['pW'],pT=pcon['pT'],pL=parseInt(thisTemp.css(this,'left'))-parseInt(pW*0.5);if(pcon['pL']>10){pL=pcon['pL']}if(pL<0){pL=0}thisTemp.css(thisTemp.promptElement,{width:pW+'px',left:(-pW-10)+'px',display:'block'});thisTemp.promptElement.innerHTML=thisTemp.getDataset(this,'words');thisTemp.css(thisTemp.promptElement,{left:pL+'px',top:(pT-thisTemp.promptElement.offsetHeight-10)+'px'})};var hidePrompt=function(event){if(thisTemp.promptElement!=null){thisTemp.css(thisTemp.promptElement,{display:'none'})}};var i=0;for(i=0;i<prompt.length;i++){var pr=prompt[i];var words=pr['words'];var time=pr['time'];var random='prompt'+this.randomString(5);var ele=document.createElement('div');ele.className=random;this.CB['timeBoBg'].appendChild(ele);var div=this.getByElement(random);div.setAttribute('data-time',time);div.setAttribute('data-words',words);this.css(div,{width:'6px',height:'6px',backgroundColor:'#FFFFFF',position:'absolute',top:'4px',left:'-100px',display:'none',zIndex:'1',borderRadius:'6px'});this.addListenerInside('mouseover',showPrompt,div);this.addListenerInside('mouseout',hidePrompt,div);this.promptArr.push(div)}this.changePrompt()},getPromptTest:function(){var pW=this.previewWidth,pT=this.getCoor(this.CB['timeButton'])['y'],pL=0;if(this.previewTop!=null){pT-=parseInt(this.css(this.previewTop,'height'));pL=parseInt(this.css(this.previewTop,'left'))}else{pT-=35}pL+=2;if(pL<0){pL=0}if(pL>this.PD.offsetWidth-pW){pL=this.PD.offsetWidth-pW}return{pW:pW,pT:pT,pL:pL}},deletePrompt:function(){var arr=this.promptArr;if(arr.length>0){for(var i=0;i<arr.length;i++){if(arr[i]){this.deleteChild(arr[i])}}}this.promptArr=[]},changePrompt:function(){if(this.promptArr.length==0){return}var arr=this.promptArr;var duration=this.getMetaDate()['duration'];var bw=this.CB['timeBoBg'].offsetWidth;for(var i=0;i<arr.length;i++){var time=parseInt(this.getDataset(arr[i],'time'));var left=parseInt(time*bw/duration)-parseInt(arr[i].offsetWidth*0.5);if(left<0){left=0}if(left>bw-parseInt(arr[i].offsetWidth*0.5)){left=bw-parseInt(arr[i].offsetWidth*0.5)}this.css(arr[i],{left:left+'px',display:'block'})}},preview:function(obj){var thisTemp=this;var preview={file:null,scale:0};preview=this.standardization(preview,this.vars['preview']);if(preview['file']==null||preview['scale']<=0){return}var srcArr=preview['file'];if(this.previewStart==0){this.previewStart=1;if(srcArr.length>0){var i=0;var imgW=0,imgH=0;var random=thisTemp.randomString(10);var loadNum=0;var loadImg=function(i){srcArr[i]=thisTemp.getNewUrl(srcArr[i]);var n=0;var img=new Image();img.src=srcArr[i];img.className=random+i;img.onload=function(event){loadNum++;if(thisTemp.previewDiv==null){imgW=img.width;imgH=img.height;thisTemp.previewWidth=parseInt(imgW*0.1);var ele=document.createElement('div');ele.className=random;thisTemp.PD.appendChild(ele);thisTemp.previewDiv=thisTemp.getByElement(random);var eleTop=(obj['y']-parseInt(imgH*0.1)+2);thisTemp.css(thisTemp.previewDiv,{width:srcArr.length*imgW*10+'px',height:parseInt(imgH*0.1)+'px',backgroundColor:'#000000',position:'absolute',left:'0px',top:eleTop+'px',display:'none',zIndex:'80'});ele.setAttribute('data-x','0');ele.setAttribute('data-y',eleTop);var ele2=document.createElement('div');ele2.className=random+'d2';thisTemp.PD.appendChild(ele2);thisTemp.previewTop=thisTemp.getByElement(ele2.className);thisTemp.css(thisTemp.previewTop,{width:parseInt(imgW*0.1)+'px',height:parseInt(imgH*0.1)+'px',position:'absolute',border:'5px solid '+thisTemp.css(thisTemp.CB['timeProgress'],'backgroundColor'),left:'0px',top:(obj['y']-parseInt(imgH*0.1)+2)+'px',display:'none',zIndex:'81'});var html='';for(n=0;n<srcArr.length;n++){html+=thisTemp.newCanvas(random+n,imgW*10,parseInt(imgH*0.1))}thisTemp.previewDiv.innerHTML=html}thisTemp.previewDiv.appendChild(img);var cimg=thisTemp.getByElement(img.className);var canvas=thisTemp.getByElement(img.className+'-canvas');var context=canvas.getContext('2d');var sx=0,sy=0,x=0,h=parseInt(imgH*0.1);for(n=0;n<100;n++){x=parseInt(n*imgW*0.1);context.drawImage(cimg,sx,sy,parseInt(imgW*0.1),h,x,0,parseInt(imgW*0.1),h);sx+=parseInt(imgW*0.1);if(sx>=imgW){sx=0;sy+=h}thisTemp.css(cimg,'display','none')}if(loadNum==srcArr.length){thisTemp.previewStart=2}else{i++;loadImg(i)}}}}loadImg(i);return}if(this.previewStart==2){var isTween=true;var nowNum=parseInt(obj['time']/this.vars['preview']['scale']);var numTotal=parseInt(thisTemp.getMetaDate()['duration']/this.vars['preview']['scale']);if(thisTemp.css(thisTemp.previewDiv,'display')=='none'){isTween=false}thisTemp.css(thisTemp.previewDiv,'display','block');var imgWidth=thisTemp.previewDiv.offsetWidth*0.01/srcArr.length;var left=(imgWidth*nowNum)-obj['x']+parseInt(imgWidth*0.5),top=obj['y']-thisTemp.previewDiv.offsetHeight;thisTemp.css(thisTemp.previewDiv,'top',top+2+'px');var topLeft=obj['x']-parseInt(imgWidth*0.5);var timepieces=0;if(topLeft<0){topLeft=0;timepieces=obj['x']-topLeft-imgWidth*0.5}if(topLeft>thisTemp.PD.offsetWidth-imgWidth){topLeft=thisTemp.PD.offsetWidth-imgWidth;timepieces=obj['x']-topLeft-imgWidth*0.5}if(left<0){left=0}if(left>numTotal*imgWidth-thisTemp.PD.offsetWidth){left=numTotal*imgWidth-thisTemp.PD.offsetWidth}thisTemp.css(thisTemp.previewTop,{left:topLeft+'px',top:top+2+'px',display:'block'});if(thisTemp.previewTop.offsetHeight>thisTemp.previewDiv.offsetHeight){thisTemp.css(thisTemp.previewTop,{height:thisTemp.previewDiv.offsetHeight-(thisTemp.previewTop.offsetHeight-thisTemp.previewDiv.offsetHeight)+'px'})}if(this.previewTween!=null){this.animatePause(this.previewTween);this.previewTween=null}var nowLeft=parseInt(thisTemp.css(thisTemp.previewDiv,'left'));var leftC=nowLeft+left;if(nowLeft==-(left+timepieces)){return}if(isTween){var obj={element:thisTemp.previewDiv,start:null,end:-(left+timepieces),speed:0.3};this.previewTween=this.animate(obj)}else{thisTemp.css(thisTemp.previewDiv,'left',-(left+timepieces)+'px')}}},deletePreview:function(){if(this.previewDiv!=null){this.deleteChild(this.previewDiv);this.previewDiv=null;this.previewStart=0}},changeVideo:function(){if(!this.html5Video){this.getVarsObject();this.V.newVideo(this.vars);return}var vArr=this.VA;var v=this.vars;var i=0;if(vArr.length<1){return}if(this.V!=null&&this.needSeek==0){this.needSeek=this.V.currentTime}if(v['poster']){this.V.poster=v['poster']}else{this.V.removeAttribute('poster')}if(v['loop']){this.V.loop='loop'}else{this.V.removeAttribute('loop')}if(v['seek']>0){this.needSeek=v['seek']}else{this.needSeek=0}if(this.getFileExt(vArr[0][0])!='.m3u8'){this.isM3u8=false}if(!this.isM3u8){if(vArr.length==1){this.V.innerHTML='';this.V.src=vArr[0][0]}else{var source='';vArr=this.arrSort(vArr);for(i=0;i<vArr.length;i++){var type='';var va=vArr[i];if(va[1]){type=' type=""'+va[1]+'""'}source+='<source src=""'+va[0]+'""'+type+'>'}this.V.removeAttribute('src');this.V.innerHTML=source}if(v['autoplay']){this.V.autoplay='autoplay'}else{this.V.removeAttribute('autoplay')}this.V.load()}else{this.embedHls(vArr[0][0],v['autoplay'])}if(!this.isUndefined(v['volume'])){this.changeVolume(v['volume'])}this.resetPlayer();this.timerErrorFun();if(this.vars['cktrack']){this.loadTrack()}},elementCoordinate:function(){this.pdCoor=this.getXY(this.PD);try{this.css(this.CB['pauseCenter'],{left:parseInt((this.PD.offsetWidth-80)*0.5)+'px',top:parseInt((this.PD.offsetHeight-80)*0.5)+'px'})}catch(event){}try{this.css(this.CB['loading'],{left:parseInt((this.PD.offsetWidth-60)*0.5)+'px',top:parseInt((this.PD.offsetHeight-60)*0.5)+'px'})}catch(event){}try{this.css(this.CB['errorText'],{left:parseInt((this.PD.offsetWidth-120)*0.5)+'px',top:parseInt((this.PD.offsetHeight-30)*0.5)+'px'})}catch(event){}try{this.css(this.CB['logo'],{left:parseInt(this.PD.offsetWidth-this.CB['logo'].offsetWidth-20)+'px',top:'20px'})}catch(event){}this.checkBarWidth()},checkBarWidth:function(){if(!this.showFace){return}var controlBarW=this.CB['controlBar'].offsetWidth;var ele=[];ele.push([[this.CB['full'],this.CB['escFull'],this.CB['fullLine']],this.buttonWidth['full']+2,'full']);if(this.vars['front']!=''){ele.push([[this.CB['front'],this.CB['frontLine']],this.buttonWidth['front']+2])}if(this.vars['next']!=''){ele.push([[this.CB['next'],this.CB['nextLine']],this.buttonWidth['next']+2])}if(this.CB['definition'].innerHTML!=''){ele.push([[this.CB['definition'],this.CB['definitionLine']],this.buttonWidth['definition']+2])}if((this.ckplayerConfig['config']['mobileVolumeBarShow']||!this.isMobile())&&this.css(this.CB['volume'],'display')=='block'){ele.push([[this.CB['volume']],this.buttonWidth['volume']]);ele.push([[this.CB['mute'],this.CB['escMute'],this.CB['muteLine']],this.buttonWidth['mute']+2,'mute'])}ele.push([[this.CB['timeText']],this.buttonWidth['timeText']]);ele.push([[this.CB['play'],this.CB['pause'],this.CB['playLine']],this.buttonWidth['play']+2,'play']);var i=0;var len=0;var isc=true;for(var i=0;i<ele.length;i++){var nlen=ele[i][1];if(nlen>2){len+=nlen}else{isc=false}}if(isc){this.buttonLen=len;this.buttonArr=ele}len=this.buttonLen;ele=this.buttonArr;for(var i=0;i<ele.length;i++){if(len>controlBarW){len-=ele[i][1];this.css(ele[i][0],'display','none')}else{this.css(ele[i][0],'display','block');if(ele[i].length==3){var name=ele[i][2];switch(name){case'mute':if(this.volume==0){this.css(this.CB['mute'],'display','none')}else{this.css(this.CB['escMute'],'display','none')}break;case'play':this.playShow(this.V.paused?false:true);break;case'full':if(this.full){this.css(this.CB['full'],'display','none')}else{this.css(this.CB['escFull'],'display','none')}break}}}}},initPlayPause:function(){if(!this.showFace){return}if(this.vars['autoplay']){this.css([this.CB['play'],this.CB['pauseCenter']],'display','none');this.css(this.CB['pause'],'display','block')}else{this.css(this.CB['play'],'display','block');if(this.css(this.CB['errorText'],'display')=='none'){this.css(this.CB['pauseCenter'],'display','block')}this.css(this.CB['pause'],'display','none')}},loadedHandler:function(){this.loaded=true;if(this.vars['loaded']!=''){try{eval(this.vars['loaded']+'()')}catch(event){this.log(event)}}},playingHandler:function(){this.playShow(true);if(this.isFirstTimePlay&&!this.isUndefined(this.advertisements['front'])){this.isFirstTimePlay=false;this.adI=0;this.adType='front';this.adMuteInto();this.adIsVideoTime=true;this.adPlayStart=true;this.adVideoPlay=false;this.videoPause();this.advertisementsTime();this.advertisementsPlay();this.adSkipButtonShow();return}if(this.adPlayerPlay){return}if(this.needSeek>0){this.videoSeek(this.needSeek);this.needSeek=0}if(this.animatePauseArray.length>0){this.animateResume('pause')}if(this.playerType=='html5video'&&this.V!=null&&this.config['videoDrawImage']){this.sendVCanvas()}if(!this.isUndefined(this.advertisements['pause'])&&!this.adPlayStart){this.adPauseCloseFunction()}},adPausePlayer:function(){this.adI=0;this.adType='pause';this.adPauseShow=true;this.loadAdPause()},loadAdPause:function(){var ad=this.getNowAdvertisements();var type=ad['type'];var thisTemp=this;var width=this.PD.offsetWidth,height=this.PD.offsetHeight;if(this.isStrImage(type)&&this.adPauseShow){this.css(this.CB['adElement'],'display','block');var imgClass='adimg'+this.randomString(10);var imgHtml='<img src=""'+ad['file']+'"" class=""'+imgClass+'"">';if(ad['link']){imgHtml='<a href=""'+ad['link']+'"" target=""_blank"">'+imgHtml+'</a>'}this.CB['adElement'].innerHTML=imgHtml;this.addListenerInside('load',function(){var imgObj=new Image();imgObj.src=this.src;var imgWH=thisTemp.adjustmentWH(imgObj.width,imgObj.height);thisTemp.css([thisTemp.getByElement(imgClass),thisTemp.CB['adElement']],{width:imgWH['width']+'px',height:imgWH['height']+'px',border:'0px'});if(thisTemp.ckplayerConfig['style']['advertisement']['closeButtonShow']&&thisTemp.adPauseShow){thisTemp.css(thisTemp.CB['adPauseClose'],{display:'block'})}thisTemp.ajaxSuccessNull(ad['exhibitionMonitor']);thisTemp.adPauseCoor()},this.getByElement(imgClass));this.addListenerInside('click',function(){thisTemp.ajaxSuccessNull(ad['clickMonitor'])},this.CB['adElement']);var newI=this.adI;if(this.adI<this.advertisements['pause'].length-1){newI++}else{newI=0}if(ad['time']>0){setTimeout(function(){if(thisTemp.adPauseShow){thisTemp.adI=newI;thisTemp.loadAdPause()}},ad['time']*1000)}}},adPauseCoor:function(){if(this.css(this.CB['adElement'],'display')=='block'){var w=this.CB['adElement'].offsetWidth,h=this.CB['adElement'].offsetHeight;var pw=this.PD.offsetWidth,ph=this.PD.offsetHeight;this.css(this.CB['adElement'],{top:(ph-h)*0.5+'px',left:(pw-w)*0.5+'px'});if(this.css(this.CB['adPauseClose'],'display')=='block'){this.css(this.CB['adPauseClose'],{top:(ph-h)*0.5-10+'px',left:(pw-w)*0.5+w-10+'px',})}}},adPauseCloseFunction:function(){this.CB['adElement'].innerHTML='';this.css([this.CB['adElement'],this.CB['adPauseClose']],'display','none');this.adPauseShow=false},advertisementsTime:function(nt){if(this.isUndefined(nt)){nt=0}var ad=this.advertisements[this.adType];if(nt>0){ad[this.adI]['time']=Math.ceil(nt)}this.adTimeAllTotal=0;for(var i=this.adI;i<ad.length;i++){if(!this.isUndefined(ad[i]['time'])){this.adTimeAllTotal+=Math.ceil(ad[i]['time'])}}if(this.adTimeAllTotal>0){this.CB['adTime'].innerHTML=this.language['adTime'].replace('{$second}',this.adTimeAllTotal>9?this.adTimeAllTotal:'0'+this.adTimeAllTotal)}if(this.adPauseShow){this.adPauseCloseFunction()}this.adOtherCloseAll();this.adTimeTotal=-1},adSkipButtonShow:function(){var thisTemp=this;var skipConfig=this.ckplayerConfig['style']['advertisement'];var delayTimeTemp=skipConfig[this.adType+'SkipButtonDelay'];var timeFun=function(){if(delayTimeTemp>=0){thisTemp.CB['adSkip'].innerHTML=thisTemp.language['skipAdTime'].replace('{$second}',delayTimeTemp>9?delayTimeTemp:'0'+delayTimeTemp);setTimeout(timeFun,1000)}else{thisTemp.CB['adSkip'].innerHTML=thisTemp.language['skipAd']}delayTimeTemp--};if(skipConfig['skipButtonShow']){this.css(thisTemp.CB['adSkip'],'display','block');if(skipConfig[this.adType+'SkipButtonDelay']>0&&this.isUndefined(this.adSkipButtonTime)){timeFun()}else{thisTemp.css(thisTemp.CB['adSkip'],'display','block');thisTemp.CB['adSkip'].innerHTML=this.language['skipAd']}}},advertisementsPlay:function(){this.css([this.CB['adBackground'],this.CB['adElement'],this.CB['adBar'],this.CB['adLink']],'display','none');this.adPlayerPlay=false;var ad=this.advertisements[this.adType];if(this.adI==0&&(this.adType=='front'||this.adType=='insert'||this.adType=='end')){this.sendJS('process',this.adType+' ad play')}this.trackHide();if(this.adI<ad.length){if(!this.isUndefined(ad[this.adI]['time'])){this.adTimeTotal=parseInt(ad[this.adI]['time'])}this.loadAdvertisements()}else{this.adEnded()}},eliminateAd:function(){if(this.adType){var ad=this.advertisements[this.adType];this.adI=ad.length;this.advertisementsPlay()}},adEnded:function(){var thisTemp=this;this.adPlayStart=false;this.adPlayerPlay=false;if(this.adVideoPlay){if(this.videoTemp['src']!=''){this.V.src=this.videoTemp['src']}else{if(this.V.src){this.V.removeAttribute('src')}}if(this.videoTemp['source']!=''){this.V.innerHTML=this.videoTemp['source']}if(this.videoTemp['currentSrc']!=''){this.V.src=this.videoTemp['currentSrc'];this.V.currentSrc=this.videoTemp['currentSrc']}if(this.videoTemp['loop']){this.V.loop=true;this.videoTemp['loop']=false}if(this.adType=='end'){this.endedHandler()}else{this.videoPlay()}}else{this.videoPlay()}this.changeVolume(this.vars['volume']);this.sendJS('process',this.adType+' ad ended');this.changeControlBarShow(true)},loadAdvertisements:function(){var ad=this.getNowAdvertisements();var type=ad['type'];var thisTemp=this;var width=this.PD.offsetWidth,height=this.PD.offsetHeight;this.changeControlBarShow(false);this.adPlayerPlay=true;if(this.isStrImage(type)){this.css([this.CB['adBackground'],this.CB['adElement'],this.CB['adBar']],'display','block');this.css([this.CB['adMute'],this.CB['adEscMute']],'display','none');var imgClass='adimg'+this.randomString(10);var imgHtml='<img src=""'+ad['file']+'"" class=""'+imgClass+'"">';if(ad['link']){imgHtml='<a href=""'+ad['link']+'"" target=""_blank"">'+imgHtml+'</a>'}this.CB['adElement'].innerHTML=imgHtml;this.addListenerInside('load',function(){var imgObj=new Image();imgObj.src=this.src;var imgWH=thisTemp.adjustmentWH(imgObj.width,imgObj.height);thisTemp.css(thisTemp.getByElement(imgClass),{width:imgWH['width']+'px',height:imgWH['height']+'px',border:'0px'});thisTemp.css(thisTemp.CB['adElement'],{width:imgWH['width']+'px',height:imgWH['height']+'px',top:(height-imgWH['height'])*0.5+'px',left:(width-imgWH['width'])*0.5+'px',});thisTemp.ajaxSuccessNull(ad['exhibitionMonitor'])},this.getByElement(imgClass));this.addListenerInside('click',function(){thisTemp.ajaxSuccessNull(ad['clickMonitor'])},this.CB['adElement']);if(!this.isUndefined(ad['time'])){this.adCountDown()}}else{this.css(this.CB['adBar'],'display','block');if(this.adVideoMute){this.css(this.CB['adEscMute'],'display','block');this.css(this.CB['adMute'],'display','none')}else{this.css(this.CB['adEscMute'],'display','none');this.css(this.CB['adMute'],'display','block')}this.CB['adElement'].innerHTML='';if(this.videoTemp['currentSrc']==''){this.videoTemp['currentSrc']=this.getCurrentSrc()}if(this.V.loop){this.videoTemp['loop']=true;this.V.loop=false}if(this.V!=null&&this.V.currentTime>0&&this.adIsVideoTime){this.adIsVideoTime=false;this.needSeek=this.V.currentTime}this.V.src=ad['file'];this.V.currentSrc=ad['file'];this.V.innerHTML='';this.V.play();this.adVideoPlay=true;this.ajaxSuccessNull(ad['exhibitionMonitor']);if(!this.adVideoMute){this.adEscMuteFunction()}}if(ad['link']){this.css(this.CB['adLink'],'display','block');var link='<a href=""'+ad['link']+'"" target=""_blank"" class=""ckadmorelink"">'+this.language['adLink']+'</a>';this.CB['adLink'].innerHTML=link;this.css(this.getByElement('ckadmorelink'),{color:'#FFFFFF',textDecoration:'none'});this.addListenerInside('click',function(){thisTemp.ajaxSuccessNull(ad['clickMonitor'])},this.CB['adLink'])}else{this.css(this.CB['adLink'],'display','none')}},adCountDown:function(){var thisTemp=this;if(this.adTimeTotal>0){if(!this.adIsPause){this.adTimeTotal--;this.showAdTime();this.adCountDownObj=null;this.adCountDownObj=setTimeout(function(){thisTemp.adCountDown()},1000)}}else{this.adI++;this.advertisementsPlay()}},adPlayerTimeHandler:function(time){var ad=this.getNowAdvertisements();var type=ad['type'];if(this.isStrImage(type)){return}if(this.adTimeTotal!=parseInt(time)){this.adTimeTotal=parseInt(time);this.showAdTime()}},showAdTime:function(){this.adTimeAllTotal--;var n=this.adTimeAllTotal;if(n<0){n=0}this.CB['adTime'].innerHTML=this.language['adTime'].replace('{$second}',n<10?'0'+n:n)},checkAdOther:function(t){if(this.adPlayerPlay){return}var adTime=this.advertisements['othertime'];var adPlay=this.advertisements['otherPlay'];for(var i=0;i<adTime.length;i++){if(t>=adTime[i]&&!adPlay[i]){adPlay[i]=true;this.newAdOther(i)}}},newAdOther:function(i){var thisTemp=this;var ad=this.advertisements['other'][i];var randomS=this.randomString(10);var adDivID='adother'+randomS;imgClassName='adimgother'+randomS;var adDiv=document.createElement('div');adDiv.className=adDivID;this.PD.appendChild(adDiv);ad['div']=adDivID;ad['element']=imgClassName;this.getByElement(adDivID).innerHTML='<a href="""" target=""blank""><img src=""'+ad['file']+'"" class=""'+imgClassName+'""></a>';this.css(adDivID,{position:'absolute',overflow:'hidden',zIndex:'996',top:'60px',left:'30px',cursor:'pointer'});if(this.ckplayerConfig['style']['advertisement']['closeOtherButtonShow']){var closeAdDivID='adotherclose'+randomS;var closeAdDiv=document.createElement('div');closeAdDiv.className=closeAdDivID;this.PD.appendChild(closeAdDiv);this.getByElement(closeAdDivID).innerHTML=this.newCanvas(closeAdDivID,20,20);ad['closeDiv']=closeAdDivID;ad['close']=false;this.css(closeAdDivID,{backgroundColor:'#f7f7f7',widht:'20px',height:'20px',position:'absolute',overflow:'hidden',zIndex:'997',top:'60px',left:'30px',borderRadius:'20px',cursor:'pointer'});var adOtherClose=this.getByElement(closeAdDivID+'-canvas').getContext('2d');var adOtherCloseFillRect=function(){thisTemp.canvasFill(adOtherClose,[[4,6],[6,6],[16,15],[14,15]]);thisTemp.canvasFill(adOtherClose,[[14,6],[16,6],[6,15],[4,15]])};adOtherClose.fillStyle='#404856';adOtherCloseFillRect();var adOtherCloseOver=function(){adOtherClose.clearRect(0,0,20,20);adOtherClose.fillStyle='#0782F5';adOtherCloseFillRect()};var adOtherCloseOut=function(){adOtherClose.clearRect(0,0,20,20);adOtherClose.fillStyle='#404856';adOtherCloseFillRect()};this.addListenerInside('mouseover',adOtherCloseOver,this.getByElement(closeAdDivID+'-canvas'));this.addListenerInside('mouseout',adOtherCloseOut,this.getByElement(closeAdDivID+'-canvas'))}this.addListenerInside('load',function(){var imgObj=new Image();imgObj.src=this.src;var imgWH=thisTemp.adjustmentWH(imgObj.width,imgObj.height);thisTemp.css([thisTemp.getByElement(imgClassName),thisTemp.getByElement(adDivID)],{width:imgWH['width']+'px',height:imgWH['height']+'px',border:'0px'});thisTemp.advertisements['other'][i]=ad;thisTemp.ajaxSuccessNull(ad['exhibitionMonitor']);thisTemp.adOtherCoor()},this.getByElement(imgClassName));this.addListenerInside('click',function(){thisTemp.adOtherClose(i)},this.getByElement(closeAdDivID));this.addListenerInside('click',function(){thisTemp.ajaxSuccessNull(ad['clickMonitor'])},this.getByElement(imgClassName));if(ad['time']>0){setTimeout(function(){thisTemp.adOtherClose(i)},ad['time']*1000)}},adOtherClose:function(i){var ad=this.advertisements['other'][i];if(!this.isUndefined(ad['close'])){if(!ad['close']){ad['close']=true;this.PD.removeChild(this.getByElement(ad['div']));this.PD.removeChild(this.getByElement(ad['closeDiv']))}}},adOtherCloseAll:function(){if(!this.isUndefined(this.advertisements['other'])){var ad=this.advertisements['other'];for(var i=0;i<ad.length;i++){this.adOtherClose(i)}}},adOtherCoor:function(){if(!this.isUndefined(this.advertisements['other'])){var arr=this.advertisements['other'];for(var i=0;i<arr.length;i++){var ad=arr[i];if(!this.isUndefined(ad['close'])){if(!ad['close']){var coor=this.getPosition(ad);var x=coor['x'],y=coor['y'],cx=x+this.getByElement(ad['div']).offsetWidth-10,cy=y-10;this.css(this.getByElement(ad['div']),{left:x+'px',top:y+'px'});if(!this.isUndefined(ad['closeDiv'])){this.css(this.getByElement(ad['closeDiv']),{left:cx+'px',top:cy+'px'})}}}}}},checkAdInsert:function(t){if(this.adPlayerPlay){return}var adTime=this.advertisements['inserttime'];var adPlay=this.advertisements['insertPlay'];var duration=this.getMetaDate()['duration'];for(var i=adTime.length-1;i>-1;i--){if(t>=adTime[i]&&t<duration-2&&t>1&&!adPlay[i]){this.adI=0;this.adType='insert';this.adMuteInto();this.adIsVideoTime=true;this.adPlayStart=true;this.adVideoPlay=false;this.videoPause();this.advertisementsTime();this.advertisementsPlay();this.adSkipButtonShow();adPlay[i]=true;for(var n=0;n<i+1;n++){adPlay[n]=true}break}}},formatInserttime:function(duration){if(!this.isUndefined(this.advertisements['inserttime'])){var arr=this.advertisements['inserttime'];var newArr=[];for(var i=0;i<arr.length;i++){if(arr[i].toString().substr(-1)=='%'){newArr.push(parseInt(duration*parseInt(arr[i])*0.01))}else{newArr.push(parseInt(arr[i]))}}this.advertisements['inserttime']=newArr}},getNowAdvertisements:function(){if(this.adI==-1){return{file:'',time:0,link:''}}return this.advertisements[this.adType][this.adI]},adjustmentWH:function(w,h){var width=this.PD.offsetWidth,height=this.PD.offsetHeight;var nw=0,nh=0;if(w>=width||h>=height){if(width/w>height/h){nh=height-20;nw=w*nh/h}else{nw=width-20;nh=h*nw/w}}else{nw=w;nh=h}return{width:nw,height:nh}},ajaxSuccessNull:function(url){if(!this.isUndefined(url)){var ajaxObj={url:url,success:function(data){}};this.ajax(ajaxObj)}},runFunction:function(s){try{var arr=s.split('->');switch(arr[0]){case'javaScript':eval(arr[1]+'()');break;case'actionScript':eval('this.'+arr[1]+'()');break}}catch(event){}},sendVCanvas:function(){if(this.timerVCanvas==null){this.css(this.V,'display','none');this.css(this.MD,'display','block');var thisTemp=this;var videoCanvas=function(){if(thisTemp.MDCX.width!=thisTemp.PD.offsetWidth){thisTemp.MDC.width=thisTemp.PD.offsetWidth}if(thisTemp.MDCX.height!=thisTemp.PD.offsetHeight){thisTemp.MDC.height=thisTemp.PD.offsetHeight}thisTemp.MDCX.clearRect(0,0,thisTemp.MDCX.width,thisTemp.MDCX.height);var coor=thisTemp.getProportionCoor(thisTemp.PD.offsetWidth,thisTemp.PD.offsetHeight,thisTemp.V.videoWidth,thisTemp.V.videoHeight);thisTemp.MDCX.drawImage(thisTemp.V,0,0,thisTemp.V.videoWidth,thisTemp.V.videoHeight,coor['x'],coor['y'],coor['width'],coor['height'])};this.timerVCanvas=new this.timer(0,videoCanvas)}},pauseHandler:function(){var thisTemp=this;this.playShow(false);if(this.animatePauseArray.length>0){this.animatePause('pause')}if(this.playerType=='html5video'&&this.V!=null&&this.config['videoDrawImage']){this.stopVCanvas()}if(!this.isUndefined(this.advertisements['pause'])&&!this.adPlayStart&&!this.adPauseShow){setTimeout(function(){if(!thisTemp.isUndefined(thisTemp.advertisements['pause'])&&!thisTemp.adPlayStart&&!thisTemp.adPauseShow&&thisTemp.time>1){thisTemp.adPausePlayer()}},300)}},stopVCanvas:function(){if(this.timerVCanvas!=null){this.css(this.V,'display','block');this.css(this.MD,'display','none');if(this.timerVCanvas.runing){this.timerVCanvas.stop()}this.timerVCanvas=null}},playShow:function(b){if(!this.showFace){return}if(b){this.css(this.CB['play'],'display','none');this.css(this.CB['pauseCenter'],'display','none');this.css(this.CB['pause'],'display','block')}else{this.css(this.CB['play'],'display','block');if(this.css(this.CB['errorText'],'display')=='none'){if(!this.adPlayerPlay){this.css(this.CB['pauseCenter'],'display','block')}}else{this.css(this.CB['pauseCenter'],'display','none')}this.css(this.CB['pause'],'display','none')}},seekedHandler:function(){this.resetTrack();this.isTimeButtonMove=true;if(this.V.paused){this.videoPlay()}},endedHandler:function(){if(this.adPlayerPlay){this.adI++;this.advertisementsPlay();return}if(!this.endAdPlay&&!this.isUndefined(this.advertisements['end'])){this.endAdPlay=true;this.adI=0;this.adType='end';this.adMuteInto();this.adIsVideoTime=true;this.adPlayStart=true;this.adVideoPlay=false;this.videoPause();this.advertisementsTime();this.advertisementsPlay();this.adSkipButtonShow();this.adReset=true;return}this.sendJS('ended');this.endedAdReset();if(!this.vars['loop']){this.videoSeek(0)}},endedAdReset:function(){var arr=[];var i=0;if(!this.isUndefined(this.advertisements['insertPlay'])){arr=this.advertisements['insertPlay'];for(i=0;i<arr.length;i++){this.advertisements['insertPlay'][i]=false}}if(!this.isUndefined(this.advertisements['otherPlay'])){arr=this.advertisements['otherPlay'];for(i=0;i<arr.length;i++){this.advertisements['otherPlay'][i]=false}}},volumechangeHandler:function(){if(!this.showFace){return}if((this.ckplayerConfig['config']['mobileVolumeBarShow']||!this.isMobile())&&this.css(this.CB['volume'],'display')=='block'){try{if(this.V.volume>0){this.css(this.CB['mute'],'display','block');this.css(this.CB['escMute'],'display','none')}else{this.css(this.CB['mute'],'display','none');this.css(this.CB['escMute'],'display','block')}}catch(event){}}},timeUpdateHandler:function(){var duration=0;if(this.playerType=='html5video'){try{duration=this.V.duration}catch(event){}}if(duration>0){this.time=this.V.currentTime;this.timeTextHandler();this.trackShowHandler();if(this.isTimeButtonMove){this.timeProgress(this.time,duration)}}},timeProgress:function(time,duration){if(!this.showFace){return}var timeProgressBgW=this.CB['timeProgressBg'].offsetWidth;var timeBOW=parseInt((time*timeProgressBgW/duration)-(this.CB['timeButton'].offsetWidth*0.5));if(timeBOW>timeProgressBgW-this.CB['timeButton'].offsetWidth){timeBOW=timeProgressBgW-this.CB['timeButton'].offsetWidth}if(timeBOW<0){timeBOW=0}this.css(this.CB['timeProgress'],'width',timeBOW+'px');this.css(this.CB['timeButton'],'left',parseInt(timeBOW)+'px')},timeTextHandler:function(){if(!this.showFace){return}var duration=this.V.duration;var time=this.V.currentTime;if(isNaN(duration)||parseInt(duration)<0.2){duration=this.vars['duration']}this.CB['timeText'].innerHTML=this.formatTime(time)+' / '+this.formatTime(duration);if(this.CB['timeText'].offsetWidth>0){this.buttonWidth['timeText']=this.CB['timeText'].offsetWidth}},bufferEdHandler:function(){if(!this.showFace||this.playerType=='flashplayer'){return}var thisTemp=this;var clearTimerBuffer=function(){if(thisTemp.timerBuffer!=null){if(thisTemp.timerBuffer.runing){thisTemp.sendJS('buffer',100);thisTemp.timerBuffer.stop()}thisTemp.timerBuffer=null}};clearTimerBuffer();var bufferFun=function(){if(thisTemp.V.buffered.length>0){var duration=thisTemp.V.duration;var len=thisTemp.V.buffered.length;var bufferStart=thisTemp.V.buffered.start(len-1);var bufferEnd=thisTemp.V.buffered.end(len-1);var loadTime=bufferStart+bufferEnd;var loadProgressBgW=thisTemp.CB['timeProgressBg'].offsetWidth;var timeButtonW=thisTemp.CB['timeButton'].offsetWidth;var loadW=parseInt((loadTime*loadProgressBgW/duration)+timeButtonW);if(loadW>=loadProgressBgW){loadW=loadProgressBgW;clearTimerBuffer()}thisTemp.changeLoad(loadTime)}};this.timerBuffer=new this.timer(200,bufferFun)},changeLoad:function(loadTime){if(this.V==null){return}if(!this.showFace){return}var loadProgressBgW=this.CB['timeProgressBg'].offsetWidth;var timeButtonW=this.CB['timeButton'].offsetWidth;var duration=this.V.duration;if(this.isUndefined(loadTime)){loadTime=this.loadTime}else{this.loadTime=loadTime}var loadW=parseInt((loadTime*loadProgressBgW/duration)+timeButtonW);this.css(this.CB['loadProgress'],'width',loadW+'px')},judgeIsLive:function(){var thisTemp=this;if(this.timerError!=null){if(this.timerError.runing){this.timerError.stop()}this.timerError=null}this.error=false;if(this.showFace){this.css(this.CB['errorText'],'display','none')}var timeupdate=function(event){thisTemp.timeUpdateHandler()};if(!this.vars['live']){if(this.V!=null&&this.playerType=='html5video'){this.addListenerInside('timeupdate',timeupdate);thisTemp.timeTextHandler();thisTemp.prompt();setTimeout(function(){thisTemp.bufferEdHandler()},200)}}else{this.removeListenerInside('timeupdate',timeupdate);if(this.timerTime!=null){window.clearInterval(this.timerTime);timerTime=null}if(this.timerTime!=null){if(this.timerTime.runing){this.timerTime.stop()}this.timerTime=null}var timeFun=function(){if(thisTemp.V!=null&&!thisTemp.V.paused&&thisTemp.showFace){thisTemp.CB['timeText'].innerHTML=thisTemp.getNowDate()}};this.timerTime=new this.timer(1000,timeFun)}this.definition()},loadTrack:function(){if(this.playerType=='flashplayer'||this.vars['flashplayer']==true){return}var thisTemp=this;var track=this.vars['cktrack'];var obj={method:'get',dataType:'text',url:track,charset:'utf-8',success:function(data){thisTemp.track=thisTemp.parseSrtSubtitles(data);thisTemp.trackIndex=0;thisTemp.nowTrackShow={sn:''}}};this.ajax(obj)},resetTrack:function(){this.trackIndex=0;this.nowTrackShow={sn:''}},trackShowHandler:function(){if(!this.showFace||this.adPlayerPlay){return}if(this.track.length<1){return}if(this.trackIndex>=this.track.length){this.trackIndex=0}var nowTrack=this.track[this.trackIndex];if(this.time>=nowTrack['startTime']&&this.time<=nowTrack['endTime']){var nowShow=this.nowTrackShow;if(nowShow['sn']!=nowTrack['sn']){this.trackHide();this.trackShow(nowTrack)}}else{this.trackHide();this.checkTrack()}},trackShow:function(track){this.nowTrackShow=track;var arr=track['content'];for(var i=0;i<arr.length;i++){var obj={list:[{type:'text',text:arr[i],color:'#FFFFFF',size:16,font:this.fontFamily,lineHeight:30}],position:[1,2,null,-(arr.length-i)*30-50]};var ele=this.addElement(obj);this.trackElement.push(ele)}},trackHide:function(){for(var i=0;i<this.trackElement.length;i++){this.deleteElement(this.trackElement[i])}this.trackElement=[]},checkTrack:function(){var num=this.trackIndex;var arr=this.track;var i=0;for(i=num;i<arr.length;i++){if(this.time>=arr[i]['startTime']&&this.time<=arr[i]['endTime']){this.trackIndex=i;break}}},playOrPause:function(){if(!this.loaded){return}if(this.V==null){return}if(this.playerType=='flashplayer'){this.V.playOrPause();return}if(this.V.paused){this.videoPlay()}else{this.videoPause()}},videoPlay:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoPlay();return}if(this.adPlayerPlay){this.eliminateAd();return}try{if(this.V.currentSrc){this.V.play()}}catch(event){}},videoPause:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoPause();return}try{this.V.pause()}catch(event){}},videoSeek:function(time){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoSeek(time);return}var duration=this.getMetaDate()['duration'];if(duration>0&&time>duration){time=duration}if(time>=0){this.V.currentTime=time;this.sendJS('seekTime',time)}},changeVolume:function(vol,bg,button){if(this.loaded){if(this.playerType=='flashplayer'){this.V.changeVolume(time);return}}if(isNaN(vol)||this.isUndefined(vol)){vol=0}if(!this.loaded){this.vars['volume']=vol}if(!this.html5Video){this.V.changeVolume(vol);return}try{if(this.isUndefined(bg)){bg=true}}catch(e){}try{if(this.isUndefined(button)){button=true}}catch(e){}if(!vol){vol=0}if(vol<0){vol=0}if(vol>1){vol=1}try{this.V.volume=vol}catch(error){}this.volume=vol;if(bg&&this.showFace){var bgW=vol*this.CB['volumeBg'].offsetWidth;if(bgW<0){bgW=0}if(bgW>this.CB['volumeBg'].offsetWidth){bgW=this.CB['volumeBg'].offsetWidth}this.css(this.CB['volumeUp'],'width',bgW+'px')}if(button&&this.showFace){var buLeft=parseInt(this.CB['volumeUp'].offsetWidth-(this.CB['volumeBO'].offsetWidth*0.5));if(buLeft>this.CB['volumeBg'].offsetWidth-this.CB['volumeBO'].offsetWidth){buLeft=this.CB['volumeBg'].offsetWidth-this.CB['volumeBO'].offsetWidth}if(buLeft<0){buLeft=0}this.css(this.CB['volumeBO'],'left',buLeft+'px')}},videoMute:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoMute();return}this.volumeTemp=this.V?(this.V.volume>0?this.V.volume:this.vars['volume']):this.vars['volume'];this.changeVolume(0)},videoEscMute:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoEscMute();return}this.changeVolume(this.volumeTemp>0?this.volumeTemp:this.vars['volume'])},adMuteFunction:function(){if(!this.loaded){return}this.changeVolume(0);this.adVideoMute=true;this.css(this.CB['adEscMute'],'display','block');this.css(this.CB['adMute'],'display','none')},adEscMuteFunction:function(){if(!this.loaded){return}var v=this.ckplayerConfig['style']['advertisement']['videoVolume'];this.changeVolume(v);this.adMuteInto()},adMuteInto:function(){this.adVideoMute=false;this.css(this.CB['adEscMute'],'display','none');this.css(this.CB['adMute'],'display','block')},fastBack:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.fastBack();return}var time=this.time-this.ckplayerConfig['config']['timeJump'];if(time<0){time=0}this.videoSeek(time)},fastNext:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.fastNext();return}var time=this.time+this.ckplayerConfig['config']['timeJump'];if(time>this.V.duration){time=this.V.duration}this.videoSeek(time)},getCurrentSrc:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){return this.V.getCurrentSrc()}return this.V.currentSrc},switchFull:function(){if(this.full){this.quitFullScreen()}else{this.fullScreen()}},fullScreen:function(){if(this.html5Video&&this.playerType=='html5video'){var element=this.PD;if(element.requestFullscreen){element.requestFullscreen()}else if(element.mozRequestFullScreen){element.mozRequestFullScreen()}else if(element.webkitRequestFullscreen){element.webkitRequestFullscreen()}else if(element.msRequestFullscreen){element.msRequestFullscreen()}else if(element.oRequestFullscreen){element.oRequestFullscreen()}this.judgeFullScreen()}else{}},quitFullScreen:function(){if(this.html5Video&&this.playerType=='html5video'){if(document.exitFullscreen){document.exitFullscreen()}else if(document.msExitFullscreen){document.msExitFullscreen()}else if(document.mozCancelFullScreen){document.mozCancelFullScreen()}else if(document.oRequestFullscreen){document.oCancelFullScreen()}else if(document.requestFullscreen){document.requestFullscreen()}else if(document.webkitExitFullscreen){document.webkitExitFullscreen()}else{this.css(document.documentElement,'cssText','');this.css(document.document.body,'cssText','');this.css(this.PD,'cssText','')}this.judgeFullScreen()}},videoRotation:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoRotation(n);return}if(this.isUndefined(n)){n=0}var tf=this.css(this.V,'transform');if(this.isUndefined(tf)&&!tf){tf='rotate(0deg)'}var reg=tf.match(/rotate\([^)]+\)/);reg=reg?reg[0].replace('rotate(','').replace('deg)',''):'';if(reg==''){reg=0}else{reg=parseInt(reg)}if(n==-1){reg-=90}else if(n==1){reg+=90}else{if(n!=90&&n!=180&&n!=270&&n!=-90&&n!=-180&&n!=-270){reg=0}else{reg=n}}n=reg;var y90=n%90,y180=n%180,y270=n%270;var ys=false;if(y90==0&&y180==90&&y270==90){ys=true}if(y90==0&&y180==90&&y270==0){ys=true}if(y90==-0&&y180==-90&&y270==-90){ys=true}if(y90==-0&&y180==-90&&y270==-0){ys=true}tf=tf.replace(/rotate\([^)]+\)/,'').replace(/scale\([^)]+\)/,'')+' rotate('+n+'deg)';var cdW=this.CD.offsetWidth,cdH=this.CD.offsetHeight,vW=this.V.videoWidth,vH=this.V.videoHeight;if(vW>0&&vH>0){if(ys){if(cdW/cdH>vH/vW){nH=cdH;nW=vH*nH/vW}else{nW=cdW;nH=vW*nW/vH}this.css(this.V,'transform','rotate(0deg)');this.css(this.V,'transform','scale('+nH/cdW+','+nW/cdH+')'+tf)}else{this.css(this.V,'transform',tf)}}else{this.css(this.V,'transform',tf)}return},videoBrightness:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoBrightness(n);return}},videoContrast:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoContrast(n);return}},videoSaturation:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoSaturation(n);return}},videoHue:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoHue(n);return}},videoZoom:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoZoom(n);return}if(this.isUndefined(n)){n=1}if(n<0){n=0}if(n>2){n=2}var tf=this.css(this.V,'transform');tf=tf.replace(/scale\([^)]+\)/,'')+' scale('+n+')';this.videoScale=n;this.css(this.V,'transform',tf);return},videoProportion:function(w,h){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoProportion(w,h);return}},adPlay:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.adPlay();return}if(this.adPlayerPlay){this.adIsPause=false;if(this.adPlayerPlay){var ad=this.getNowAdvertisements();var type=ad['type'];if(this.isStrImage(type)){this.adCountDown()}else{this.V.play()}}}},adPause:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.adPause();return}if(this.adPlayerPlay){this.adIsPause=true;var ad=this.getNowAdvertisements();var type=ad['type'];if(type!='jpg'&&type!='jpeg'&&type!='png'&&type!='svg'&&type!='gif'){this.videoPause()}}},videoError:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoError(n);return}},changeConfig:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.changeConfig(arguments);return}var obj=this.ckplayerConfig;var arg=arguments;for(var i=0;i<arg.length-1;i++){if(obj.hasOwnProperty(arg[i])){obj=obj[arg[i]]}else{return}}var val=arg[arg.length-1];switch(arg.length){case 2:this.ckplayerConfig[arg[0]]=val;break;case 3:this.ckplayerConfig[arg[0]][arg[1]]=val;break;case 4:this.ckplayerConfig[arg[0]][arg[1]][arg[2]]=val;break;case 5:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]]=val;break;case 6:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]][arg[4]]=val;break;case 7:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]][arg[4]][arg[5]]=val;break;case 8:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]][arg[4]][arg[5]][arg[6]]=val;break;case 9:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]][arg[4]][arg[5]][arg[6]][arg[7]]=val;break;case 10:this.ckplayerConfig[arg[0]][arg[1]][arg[2]][arg[3]][arg[4]][arg[5]][arg[6]][arg[7]][arg[8]]=val;break;default:return;break}this.sendJS('configChange',this.ckplayerConfig)},custom:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.custom(arguments);return}},getConfig:function(){if(!this.loaded){return null}if(this.playerType=='flashplayer'){return this.V.getConfig(arguments)}},openUrl:function(n){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.openUrl(n);return}},videoClear:function(){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.videoClear();return}},newVideo:function(c){if(this.playerType=='flashplayer'){this.V.newVideo(c);return}else{this.embed(c)}},screenshot:function(obj,save,name){if(!this.loaded){return}if(this.playerType=='flashplayer'){try{this.V.screenshot(obj,save,name)}catch(error){this.log(error)}return}if(obj=='video'){var newCanvas=document.createElement('canvas');newCanvas.width=this.V.videoWidth;newCanvas.height=this.V.videoHeight;newCanvas.getContext('2d').drawImage(this.V,0,0,this.V.videoWidth,this.V.videoHeight);try{var base64=newCanvas.toDataURL('image/jpeg');this.sendJS('screenshot',{object:obj,save:save,name:name,base64:base64})}catch(error){this.log(error)}}},changeSize:function(w,h){if(this.isUndefined(w)){w=0}if(this.isUndefined(h)){h=0}if(w>0){this.css(this.CD,'width',w+'px')}if(h>0){this.css(this.CD,'height',h+'px')}if(this.html5Video){this.elementCoordinate()}},changePlaybackRate:function(n){if(this.html5Video){var arr=this.playbackRateArr;n=parseInt(n);if(n<arr.length){this.newPlaybackrate(arr[n][1])}}},changeControlBarShow:function(show){if(!this.loaded){return}if(this.playerType=='flashplayer'){this.V.changeControlBarShow(show);return}if(show){this.controlBarIsShow=true;this.controlBarHide(false)}else{this.controlBarIsShow=false;this.controlBarHide(true)}},embedSWF:function(){var vid=this.randomString();var flashvars=this.getFlashVars();var param=this.getFlashplayerParam();var flashplayerUrl='http://www.macromedia.com/go/getflashplayer';var html='',src=javascriptPath+'ckplayer.swf';id='id=""'+vid+'"" name=""'+vid+'"" ';html+='<object pluginspage=""'+flashplayerUrl+'"" classid=""clsid:d27cdb6e-ae6d-11cf-96b8-444553540000""  codebase=""http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=11,3,0,0"" width=""100%"" height=""100%"" '+id+' align=""middle"">';html+=param['v'];html+='<param name=""movie"" value=""'+src+'"">';html+='<param name=""flashvars"" value=""'+flashvars+'"">';html+=' <param name=""wmode"" value=""transparent"">';html+='<embed wmode=""transparent"" '+param['w']+' src=""'+src+'"" flashvars=""'+flashvars+'"" width=""100%"" height=""100%"" '+id+' align=""middle"" type=""application/x-shockwave-flash"" pluginspage=""'+flashplayerUrl+'"" />';html+='</object>';this.PD.innerHTML=html;this.V=this.getObjectById(vid);this.playerType='flashplayer'},getFlashVars:function(){this.getVarsObject();var v=this.vars;var z='';for(k in v){if(k!='flashplayer'&&k!='container'&&v[k]!=''){if(z!=''){z+='&'}var vk=v[k];if(vk==true){vk=1}if(vk==false){vk=0}z+=k+'='+vk}}if(!v.hasOwnProperty('volume')||!v['volume']){if(z!=''){z+='&'}z+='volume=0'}return z},isStrImage:function(s){if(s=='jpg'||s=='jpeg'||s=='png'||s=='svg'||s=='gif'){return true}return false},getVarsObject:function(){var v=this.vars;var f='',d='',w='';var arr=this.VA;var prompt=v['promptSpot'];var i=0;var video=this.vars['video'];if(typeof(video)=='object'){if(!this.isUndefined(typeof(video.length))){var arr=video;for(i=0;i<arr.length;i++){var arr2=arr[i];if(arr2){if(f!=''){f+=this.ckplayerConfig['config']['split'];d+=',';w+=',';v['type']+=this.ckplayerConfig['config']['split']}f+=encodeURIComponent(decodeURIComponent(arr2[0]));d+=arr2[2];w+=arr2[3];v['type']+=arr2[1].replace('video/','')}}}else{f=encodeURIComponent(decodeURIComponent(video['file']));if(!this.isUndefined(video['type'])){v['type']=video['type']}d='';w=''}}else{f=encodeURIComponent(decodeURIComponent(video))}if(v['preview']!=null){v['previewscale']=v['preview']['scale'];v['preview']=v['preview']['file'].join(',')}if(prompt!=null){v['promptspot']='';v['promptspottime']='';for(i=0;i<prompt.length;i++){if(v['promptspot']!=''){v['promptspot']+=',';v['promptspottime']+=','}v['promptspot']+=prompt[i]['words'];v['promptspottime']+=prompt[i]['time']}}if(f!=''){v['video']=f;v['definition']=d;v['weight']=w}if(!v['volume']){v['volume']=0}var newV={};for(var k in v){if(v[k]!=null){newV[k]=v[k]}if(k=='type'){newV[k]=v[k].replace('video/m3u8','m3u8')}}this.vars=newV},getFlashplayerParam:function(){var w='',v='',o={allowScriptAccess:'always',allowFullScreen:true,quality:'high',bgcolor:'#000'};for(var e in o){w+=e+'=""'+o[e]+'"" ';v+='<param name=""'+e+'"" value=""'+o[e]+'"" />'}w=w.replace('movie=','src=');return{w:w,v:v}},getMetaDate:function(){if(!this.loaded||this.V==null){return false}if(this.playerType=='html5video'){var duration=0;try{duration=!isNaN(this.V.duration)?this.V.duration:0}catch(event){this.log(event)}var data={duration:duration,volume:this.V.volume,playbackRate:this.V.playbackRate,width:this.PD.offsetWidth||this.V.offsetWidth||this.V.width,height:this.PD.offsetHeight||this.V.offsetHeight||this.V.height,streamWidth:this.V.videoWidth,streamHeight:this.V.videoHeight,videoWidth:this.V.offsetWidth,videoHeight:this.V.offsetHeight,paused:this.V.paused};return data}else{try{return this.V.getMetaDate()}catch(event){this.log(event)}}return false},getVideoUrl:function(){if(this.playerType=='flashplayer'){return this.V.getVideoUrl()}var arr=[];if(this.V.src){arr.push(this.V.src)}else{var uArr=this.V.childNodes;for(var i=0;i<uArr.length;i++){arr.push(uArr[i].src)}}return arr},clickEvent:function(call){if(call=='none'||call==''||call==null){return{type:'none'}}var callArr=call.split('->');var type='',fun='',link='',target='';if(callArr.length==2){var callM=callArr[0];var callE=callArr[1];if(!callE){return{type:'none'}}var val='';var eArr=[];type=callM;switch(callM){case'actionScript':if(callE.indexOf('(')>-1){eArr=callE.split('(');callE=eArr[0];val=eArr[1].replace(')','')}if(val==''){fun='thisTemp.'+callE+'()'}else{fun='thisTemp.'+callE+'('+val+')'}break;case'javaScript':if(callE.substr(0,11)=='[flashvars]'){callE=callE.substr(11);if(this.vars.hasOwnProperty(callE)){callE=this.vars[callE]}else{break}}if(callE.indexOf('(')>-1){eArr=callE.split('(');callE=eArr[0];val=eArr[1].replace(')','')}if(val==''){fun=callE+'()'}else{fun=callE+'('+val+')'}break;case""link"":var callLink=(callE+',').split(',');if(callLink[0].substr(0,11)=='[flashvars]'){var fl=callLink[0].replace('[flashvars]','');if(this.vars.hasOwnProperty(fl)){callLink[0]=this.vars[fl]}else{break}}if(!callLink[1]){callLink[1]='_blank'}link=callLink[0];target=callLink[1];break}}return{type:type,fun:fun,link:link,target:target}},getPosition:function(obj){var pw=this.PD.offsetWidth,ph=this.PD.offsetHeight;var x=0,y=0;switch(obj['align']){case'left':x=obj['offsetX'];break;case'center':x=pw*0.5+obj['offsetX'];break;case'right':x=pw+obj['offsetX'];break}switch(obj['vAlign']){case'top':y=obj['offsetY'];break;case'middle':y=ph*0.5+obj['offsetY'];break;case'bottom':y=ph+obj['offsetY'];break}return{x:x,y:y}},addElement:function(attribute){var thisTemp=this;if(this.playerType=='flashplayer'){return this.V.addElement(attribute)}var i=0;var obj={list:null,x:'100%',y:""50%"",position:null,alpha:1,backgroundColor:'',backAlpha:1,backRadius:0,clickEvent:''};obj=this.standardization(obj,attribute);var list=obj['list'];if(list==null){return''}var id='element'+this.randomString(10);var ele=document.createElement('div');ele.className=id;if(obj['x']){ele.setAttribute('data-x',obj['x'])}if(obj['y']){ele.setAttribute('data-y',obj['y'])}if(obj['position']!=null){ele.setAttribute('data-position',obj['position'].join(','))}this.PD.appendChild(ele);var eid=this.getByElement(id);this.css(eid,{position:'absolute',filter:'alpha(opacity:'+obj['alpha']+')',opacity:obj['alpha'].toString(),width:'800px',zIndex:'20'});var bgid='elementbg'+this.randomString(10);var bgAlpha=obj['alpha'].toString();var bgColor=obj['backgroundColor'].replace('0x','#');var html='';var idArr=[];var clickArr=[];if(!this.isUndefined(list)&&list.length>0){var textObj,returnObj,clickEvent;for(i=0;i<list.length;i++){var newEleid='elementnew'+this.randomString(10);switch(list[i]['type']){case'image':case'png':case'jpg':case'jpeg':case'gif':textObj={type:'image',file:'',radius:0,width:30,height:30,alpha:1,paddingLeft:0,paddingRight:0,paddingTop:0,paddingBottom:0,marginLeft:0,marginRight:0,marginTop:0,marginBottom:0,backgroundColor:'',clickEvent:''};list[i]=this.standardization(textObj,list[i]);clickEvent=this.clickEvent(list[i]['clickEvent']);clickArr.push(clickEvent);if(clickEvent['type']=='link'){html+='<div class=""'+newEleid+'"" data-i=""'+i+'""><a href=""'+clickEvent['link']+'"" target=""'+clickEvent['target']+'""><img class=""'+newEleid+'_image"" src=""'+list[i]['file']+'"" style=""border:0;""></a></div>'}else{html+='<div class=""'+newEleid+'"" data-i=""'+i+'""><img class=""'+newEleid+'_image"" src=""'+list[i]['file']+'"" style=""border:0;""></div>'}break;case'text':textObj={type:'text',text:'',color:'0xFFFFFF',size:14,font:this.fontFamily,leading:0,alpha:1,paddingLeft:0,paddingRight:0,paddingTop:0,paddingBottom:0,marginLeft:0,marginRight:0,marginTop:0,marginBottom:0,backgroundColor:'',backAlpha:1,backRadius:0,clickEvent:''};list[i]=this.standardization(textObj,list[i]);clickEvent=this.clickEvent(list[i]['clickEvent']);clickArr.push(clickEvent);if(clickEvent['type']=='link'){html+='<div class=""'+newEleid+'"" data-i=""'+i+'""><div class=""'+newEleid+'_bg""></div><div class=""'+newEleid+'_text""><a href=""'+clickEvent['link']+'"" target=""'+clickEvent['target']+'"">'+list[i]['text']+'</a></div></div>'}else{html+='<div  class=""'+newEleid+'"" data-i=""'+i+'""><div class=""'+newEleid+'_bg""></div><div class=""'+newEleid+'_text"">'+list[i]['text']+'</div></div>'}break;default:break}idArr.push(newEleid)}}var objClickEvent=this.clickEvent(obj['clickEvent']);eid.innerHTML='<div class=""'+bgid+'""></div><div class=""'+bgid+'_c"">'+html+'</div>';if(objClickEvent['type']=='javaScript'||objClickEvent['type']=='actionScript'){var objClickHandler=function(){eval(objClickEvent['fun']);thisTemp.sendJS('clickEvent',clk['type']+'->'+clk['fun'].replace('thisTemp.','').replace('()',''))};this.addListenerInside('click',objClickHandler,this.getByElement(bgid+'_c'))}this.css(bgid+'_c',{position:'absolute',zIndex:'2'});for(i=0;i<idArr.length;i++){var clk=clickArr[i];if(clk['type']=='javaScript'||clk['type']=='actionScript'){var clickHandler=function(){clk=clickArr[this.getAttribute('data-i')];eval(clk['fun']);thisTemp.sendJS('clickEvent',clk['type']+'->'+clk['fun'].replace('thisTemp.','').replace('()',''))};this.addListenerInside('click',clickHandler,this.getByElement(idArr[i]))}switch(list[i]['type']){case'image':case'png':case'jpg':case'jpeg':case'gif':this.css(idArr[i],{float:'left',width:list[i]['width']+'px',height:list[i]['height']+'px',filter:'alpha(opacity:'+list[i]['alpha']+')',opacity:list[i]['alpha'].toString(),marginLeft:list[i]['marginLeft']+'px',marginRight:list[i]['marginRight']+'px',marginTop:list[i]['marginTop']+'px',marginBottom:list[i]['marginBottom']+'px',borderRadius:list[i]['radius']+'px',cursor:'pointer'});this.css(idArr[i]+'_image',{width:list[i]['width']+'px',height:list[i]['height']+'px',borderRadius:list[i]['radius']+'px'});break;case'text':this.css(idArr[i]+'_text',{filter:'alpha(opacity:'+list[i]['alpha']+')',opacity:list[i]['alpha'].toString(),borderRadius:list[i]['radius']+'px',fontFamily:list[i]['font'],fontSize:list[i]['size']+'px',color:list[i]['color'].replace('0x','#'),lineHeight:list[i]['leading']>0?list[i]['leading']+'px':'',paddingLeft:list[i]['paddingLeft']+'px',paddingRight:list[i]['paddingRight']+'px',paddingTop:list[i]['paddingTop']+'px',paddingBottom:list[i]['paddingBottom']+'px',whiteSpace:'nowrap',position:'absolute',zIndex:'3',cursor:'pointer'});this.css(idArr[i],{float:'left',width:this.getByElement(idArr[i]+'_text').offsetWidth+'px',height:this.getByElement(idArr[i]+'_text').offsetHeight+'px',marginLeft:list[i]['marginLeft']+'px',marginRight:list[i]['marginRight']+'px',marginTop:list[i]['marginTop']+'px',marginBottom:list[i]['marginBottom']+'px'});this.css(idArr[i]+'_bg',{width:this.getByElement(idArr[i]+'_text').offsetWidth+'px',height:this.getByElement(idArr[i]+'_text').offsetHeight+'px',filter:'alpha(opacity:'+list[i]['backAlpha']+')',opacity:list[i]['backAlpha'].toString(),borderRadius:list[i]['backRadius']+'px',backgroundColor:list[i]['backgroundColor'].replace('0x','#'),position:'absolute',zIndex:'2'});break;default:break}}this.css(bgid,{width:this.getByElement(bgid+'_c').offsetWidth+'px',height:this.getByElement(bgid+'_c').offsetHeight+'px',position:'absolute',filter:'alpha(opacity:'+bgAlpha+')',opacity:bgAlpha,backgroundColor:bgColor.replace('0x','#'),borderRadius:obj['backRadius']+'px',zIndex:'1'});this.css(eid,{width:this.getByElement(bgid).offsetWidth+'px',height:this.getByElement(bgid).offsetHeight+'px'});var eidCoor=this.calculationCoor(eid);this.css(eid,{left:eidCoor['x']+'px',top:eidCoor['y']+'px'});this.elementArr.push(eid.className);return eid},getElement:function(element){if(this.playerType=='flashplayer'){return this.V.getElement(element)}var ele=element;if(typeof(element)=='string'){ele=this.getByElement(element)}var coor=this.getCoor(ele);return{x:coor['x'],y:coor['y'],width:ele.offsetWidth,height:ele.offsetHeight,alpha:!this.isUndefined(this.css(ele,'opacity'))?parseFloat(this.css(ele,'opacity')):1,show:this.css(ele,'display')=='none'?false:true}},elementShow:function(element,show){if(this.playerType=='flashplayer'){this.V.elementShow(element,show);return}if(typeof(element)=='string'){if(element){this.css(ele,'display',show==true?'block':'none')}else{var arr=this.elementTempArr;for(var i=0;i<arr.length;i++){this.css(arr[i],'display',show==true?'block':'none')}}}},calculationCoor:function(ele){if(this.playerType=='flashplayer'){return this.V.calculationCoor(ele)}if(ele==[]){return}var x,y,position=[];var w=this.PD.offsetWidth,h=this.PD.offsetHeight;var ew=ele.offsetWidth,eh=ele.offsetHeight;if(!this.isUndefined(this.getDataset(ele,'x'))){x=this.getDataset(ele,'x')}if(!this.isUndefined(this.getDataset(ele,'y'))){y=this.getDataset(ele,'y')}if(!this.isUndefined(this.getDataset(ele,'position'))){try{position=this.getDataset(ele,'position').toString().split(',')}catch(event){}}if(position.length>0){position.push(null,null,null,null);var i=0;for(i=0;i<position.length;i++){if(this.isUndefined(position[i])||position[i]==null||position[i]=='null'||position[i]==''){position[i]=null}else{position[i]=parseFloat(position[i])}}if(position[2]==null){switch(position[0]){case 0:x=0;break;case 1:x=parseInt((w-ew)*0.5);break;default:x=w-ew;break}}else{switch(position[0]){case 0:x=position[2];break;case 1:x=parseInt(w*0.5)+position[2];break;default:x=w+position[2];break}}if(position[3]==null){switch(position[1]){case 0:y=0;break;case 1:y=parseInt((h-eh)*0.5);break;default:y=h-eh;break}}else{switch(position[1]){case 0:y=position[3];break;case 1:y=parseInt(h*0.5)+position[3];break;default:y=h+position[3];break}}}else{if(x.substring(x.length-1,x.length)=='%'){x=Math.floor(parseInt(x.substring(0,x.length-1))*w*0.01)}if(y.substring(y.length-1,y.length)=='%'){y=Math.floor(parseInt(y.substring(0,y.length-1))*h*0.01)}}return{x:x,y:y}},changeElementCoor:function(){for(var i=0;i<this.elementArr.length;i++){if(this.getByElement(this.elementArr[i])!=[]){var c=this.calculationCoor(this.getByElement(this.elementArr[i]));if(c['x']&&c['y']){this.css(this.elementArr[i],{top:c['y']+'px',left:c['x']+'px'})}}}},tween:function(){var Tween={None:{easeIn:function(t,b,c,d){return c*t/d+b},easeOut:function(t,b,c,d){return c*t/d+b},easeInOut:function(t,b,c,d){return c*t/d+b}},Quadratic:{easeIn:function(t,b,c,d){return c*(t/=d)*t+b},easeOut:function(t,b,c,d){return-c*(t/=d)*(t-2)+b},easeInOut:function(t,b,c,d){if((t/=d/2)<1)return c/2*t*t+b;return-c/2*((--t)*(t-2)-1)+b}},Cubic:{easeIn:function(t,b,c,d){return c*(t/=d)*t*t+b},easeOut:function(t,b,c,d){return c*((t=t/d-1)*t*t+1)+b},easeInOut:function(t,b,c,d){if((t/=d/2)<1)return c/2*t*t*t+b;return c/2*((t-=2)*t*t+2)+b}},Quartic:{easeIn:function(t,b,c,d){return c*(t/=d)*t*t*t+b},easeOut:function(t,b,c,d){return-c*((t=t/d-1)*t*t*t-1)+b},easeInOut:function(t,b,c,d){if((t/=d/2)<1)return c/2*t*t*t*t+b;return-c/2*((t-=2)*t*t*t-2)+b}},Quintic:{easeIn:function(t,b,c,d){return c*(t/=d)*t*t*t*t+b},easeOut:function(t,b,c,d){return c*((t=t/d-1)*t*t*t*t+1)+b},easeInOut:function(t,b,c,d){if((t/=d/2)<1)return c/2*t*t*t*t*t+b;return c/2*((t-=2)*t*t*t*t+2)+b}},Sine:{easeIn:function(t,b,c,d){return-c*Math.cos(t/d*(Math.PI/2))+c+b},easeOut:function(t,b,c,d){return c*Math.sin(t/d*(Math.PI/2))+b},easeInOut:function(t,b,c,d){return-c/2*(Math.cos(Math.PI*t/d)-1)+b}},Exponential:{easeIn:function(t,b,c,d){return(t==0)?b:c*Math.pow(2,10*(t/d-1))+b},easeOut:function(t,b,c,d){return(t==d)?b+c:c*(-Math.pow(2,-10*t/d)+1)+b},easeInOut:function(t,b,c,d){if(t==0)return b;if(t==d)return b+c;if((t/=d/2)<1)return c/2*Math.pow(2,10*(t-1))+b;return c/2*(-Math.pow(2,-10*--t)+2)+b}},Circular:{easeIn:function(t,b,c,d){return-c*(Math.sqrt(1-(t/=d)*t)-1)+b},easeOut:function(t,b,c,d){return c*Math.sqrt(1-(t=t/d-1)*t)+b},easeInOut:function(t,b,c,d){if((t/=d/2)<1)return-c/2*(Math.sqrt(1-t*t)-1)+b;return c/2*(Math.sqrt(1-(t-=2)*t)+1)+b}},Elastic:{easeIn:function(t,b,c,d,a,p){if(t==0)return b;if((t/=d)==1)return b+c;if(!p)p=d*.3;if(!a||a<Math.abs(c)){a=c;var s=p/4}else var s=p/(2*Math.PI)*Math.asin(c/a);return-(a*Math.pow(2,10*(t-=1))*Math.sin((t*d-s)*(2*Math.PI)/p))+b},easeOut:function(t,b,c,d,a,p){if(t==0)return b;if((t/=d)==1)return b+c;if(!p)p=d*.3;if(!a||a<Math.abs(c)){a=c;var s=p/4}else var s=p/(2*Math.PI)*Math.asin(c/a);return(a*Math.pow(2,-10*t)*Math.sin((t*d-s)*(2*Math.PI)/p)+c+b)},easeInOut:function(t,b,c,d,a,p){if(t==0)return b;if((t/=d/2)==2)return b+c;if(!p)p=d*(.3*1.5);if(!a||a<Math.abs(c)){a=c;var s=p/4}else var s=p/(2*Math.PI)*Math.asin(c/a);if(t<1)return-.5*(a*Math.pow(2,10*(t-=1))*Math.sin((t*d-s)*(2*Math.PI)/p))+b;return a*Math.pow(2,-10*(t-=1))*Math.sin((t*d-s)*(2*Math.PI)/p)*.5+c+b}},Back:{easeIn:function(t,b,c,d,s){if(s==undefined)s=1.70158;return c*(t/=d)*t*((s+1)*t-s)+b},easeOut:function(t,b,c,d,s){if(s==undefined)s=1.70158;return c*((t=t/d-1)*t*((s+1)*t+s)+1)+b},easeInOut:function(t,b,c,d,s){if(s==undefined)s=1.70158;if((t/=d/2)<1)return c/2*(t*t*(((s*=(1.525))+1)*t-s))+b;return c/2*((t-=2)*t*(((s*=(1.525))+1)*t+s)+2)+b}},Bounce:{easeIn:function(t,b,c,d){return c-Tween.Bounce.easeOut(d-t,0,c,d)+b},easeOut:function(t,b,c,d){if((t/=d)<(1/2.75)){return c*(7.5625*t*t)+b}else if(t<(2/2.75)){return c*(7.5625*(t-=(1.5/2.75))*t+.75)+b}else if(t<(2.5/2.75)){return c*(7.5625*(t-=(2.25/2.75))*t+.9375)+b}else{return c*(7.5625*(t-=(2.625/2.75))*t+.984375)+b}},easeInOut:function(t,b,c,d){if(t<d/2)return Tween.Bounce.easeIn(t*2,0,c,d)*.5+b;else return Tween.Bounce.easeOut(t*2-d,0,c,d)*.5+c*.5+b}}};return Tween},animate:function(attribute){if(this.playerType=='flashplayer'){return this.V.animate(attribute)}var thisTemp=this;var animateId='animate_'+this.randomString();var obj={element:null,parameter:'x',static:false,effect:'None.easeIn',start:null,end:null,speed:0,overStop:false,pauseStop:false,callBack:null};obj=this.standardization(obj,attribute);if(obj['element']==null||obj['speed']==0){return false}var w=this.PD.offsetWidth,h=this.PD.offsetHeight;var effArr=(obj['effect']+'.').split('.');var tweenFun=this.tween()[effArr[0]][effArr[1]];var eleCoor={x:0,y:0};if(this.isUndefined(tweenFun)){return false}var def=this.arrIndexOf(this.elementArr,obj['element'].className);if(def>-1){this.elementTempArr.push(obj['element'].className);this.elementArr.splice(def,1)}var css={};var pm=this.getElement(obj['element']);var t=0;var b=0;var c=0;var d=obj['speed']*1000;var timerTween=null;var tweenObj=null;var start=obj['start']==null?'':obj['start'].toString();var end=obj['end']==null?'':obj['end'].toString();switch(obj['parameter']){case'x':if(obj['start']==null){b=pm['x']}else{if(start.substring(start.length-1,start.length)=='%'){b=parseInt(start)*w*0.01}else{b=parseInt(start)}}if(obj['end']==null){c=pm['x']-b}else{if(end.substring(end.length-1,end.length)=='%'){c=parseInt(end)*w*0.01-b}else if(end.substring(0,1)=='-'||end.substring(0,1)=='+'){if(typeof(obj['end'])=='number'){c=parseInt(obj['end'])-b}else{c=parseInt(end)}}else{c=parseInt(end)-b}}break;case'y':if(obj['start']==null){b=pm['y']}else{if(start.substring(start.length-1,start.length)=='%'){b=parseInt(start)*h*0.01}else{b=parseInt(start)}}if(obj['end']==null){c=pm['y']-b}else{if(end.substring(end.length-1,end.length)=='%'){c=parseInt(end)*h*0.01-b}else if(end.substring(0,1)=='-'||end.substring(0,1)=='+'){if(typeof(obj['end'])=='number'){c=parseInt(obj['end'])-b}else{c=parseInt(end)}}else{c=parseInt(end)-b}}break;case'alpha':if(obj['start']==null){b=pm['alpha']*100}else{if(start.substring(start.length-1,start.length)=='%'){b=parseInt(obj['start'])}else{b=parseInt(obj['start']*100)}}if(obj['end']==null){c=pm['alpha']*100-b}else{if(end.substring(end.length-1,end.length)=='%'){c=parseInt(end)-b}else if(end.substring(0,1)=='-'||end.substring(0,1)=='+'){if(typeof(obj['end'])=='number'){c=parseInt(obj['end'])*100-b}else{c=parseInt(obj['end'])*100}}else{c=parseInt(obj['end'])*100-b}}break}var callBack=function(){var index=thisTemp.arrIndexOf(thisTemp.animateElementArray,animateId);if(index>-1){thisTemp.animateArray.splice(index,1);thisTemp.animateElementArray.splice(index,1)}index=thisTemp.arrIndexOf(thisTemp.animatePauseArray,animateId);if(index>-1){thisTemp.animatePauseArray.splice(index,1)}if(obj['callBack']!=null&&obj['element']&&obj['callBack']!='callBack'&&obj['callBack']!='tweenX'&&obj['tweenY']!='callBack'&&obj['callBack']!='tweenAlpha'){var cb=eval(obj['callBack']);cb(obj['element']);obj['callBack']=null}};var stopTween=function(){if(timerTween!=null){if(timerTween.runing){timerTween.stop()}timerTween=null}};var tweenX=function(){if(t<d){t+=10;css={left:Math.ceil(tweenFun(t,b,c,d))+'px'};if(obj['static']){eleCoor=thisTemp.calculationCoor(obj['element']);css['top']=eleCoor['y']+'px'}thisTemp.css(obj['element'],css)}else{stopTween();try{var defX=this.arrIndexOf(this.elementTempArr,obj['element'].className);if(defX>-1){this.elementTempArr.splice(defX,1)}}catch(event){}thisTemp.elementArr.push(obj['element'].className);callBack()}};var tweenY=function(){if(t<d){t+=10;css={top:Math.ceil(tweenFun(t,b,c,d))+'px'};if(obj['static']){eleCoor=thisTemp.calculationCoor(obj['element']);css['left']=eleCoor['x']+'px'}thisTemp.css(obj['element'],css)}else{stopTween();try{var defY=this.arrIndexOf(this.elementTempArr,obj['element'].className);if(defY>-1){this.elementTempArr.splice(defY,1)}}catch(event){}thisTemp.elementArr.push(obj['element'].className);callBack()}};var tweenAlpha=function(){if(t<d){t+=10;eleCoor=thisTemp.calculationCoor(obj['element']);var ap=Math.ceil(tweenFun(t,b,c,d))*0.01;css={filter:'alpha(opacity:'+ap+')',opacity:ap.toString()};if(obj['static']){eleCoor=thisTemp.calculationCoor(obj['element']);css['top']=eleCoor['y']+'px';css['left']=eleCoor['x']+'px'}thisTemp.css(obj['element'],css)}else{stopTween();try{var defA=this.arrIndexOf(this.elementTempArr,obj['element'].className);if(defA>-1){this.elementTempArr.splice(defA,1)}}catch(event){}thisTemp.elementArr.push(obj['element'].className);callBack()}};switch(obj['parameter']){case'x':tweenObj=tweenX;break;case'y':tweenObj=tweenY;break;case'alpha':tweenObj=tweenAlpha;break;default:break}timerTween=new thisTemp.timer(10,tweenObj);timerTween.callBackFunction=callBack;if(obj['overStop']){var mouseOver=function(){if(timerTween!=null&&timerTween.runing){timerTween.stop()}};this.addListenerInside('mouseover',mouseOver,obj['element']);var mouseOut=function(){var start=true;if(obj['pauseStop']&&thisTemp.getMetaDate()['paused']){start=false}if(timerTween!=null&&!timerTween.runing&&start){timerTween.start()}};this.addListenerInside('mouseout',mouseOut,obj['element'])}this.animateArray.push(timerTween);this.animateElementArray.push(animateId);if(obj['pauseStop']){this.animatePauseArray.push(animateId)}return animateId},animateResume:function(id){if(this.playerType=='flashplayer'){this.V.animateResume(this.isUndefined(id)?'':id);return}var arr=[];if(id!=''&&!this.isUndefined(id)&&id!='pause'){arr.push(id)}else{if(id==='pause'){arr=this.animatePauseArray}else{arr=this.animateElementArray}}for(var i=0;i<arr.length;i++){var index=this.arrIndexOf(this.animateElementArray,arr[i]);if(index>-1){this.animateArray[index].start()}}},animatePause:function(id){if(this.playerType=='flashplayer'){this.V.animatePause(this.isUndefined(id)?'':id);return}var arr=[];if(id!=''&&!this.isUndefined(id)&&id!='pause'){arr.push(id)}else{if(id==='pause'){arr=this.animatePauseArray}else{arr=this.animateElementArray}}for(var i=0;i<arr.length;i++){var index=this.arrIndexOf(this.animateElementArray,arr[i]);if(index>-1){this.animateArray[index].stop()}}},deleteAnimate:function(id){if(this.playerType=='flashplayer'&&this.V){try{this.V.deleteAnimate(id)}catch(event){this.log(event)}return}var index=this.arrIndexOf(this.animateElementArray,id);if(index>-1){this.animateArray[index].callBackFunction();this.animateArray.splice(index,1);this.animateElementArray.splice(index,1)}},deleteElement:function(ele){if(this.playerType=='flashplayer'&&this.V){try{this.V.deleteElement(ele)}catch(event){}return}var def=this.arrIndexOf(this.elementArr,ele.className);if(def>-1){this.elementArr.splice(def,1)}try{def=this.arrIndexOf(this.elementTempArr,ele.className);if(def>-1){this.elementTempArr.splice(def,1)}}catch(event){}this.deleteAnimate(ele);this.deleteChild(ele)},getByElement:function(obj,parent){if(this.isUndefined(parent)){parent=document}var num=obj.substr(0,1);var res=[];if(num!='#'){if(num=='.'){obj=obj.substr(1,obj.length)}if(parent.getElementsByClassName){res=parent.getElementsByClassName(obj)}else{var reg=new RegExp(' '+obj+' ','i');var ele=parent.getElementsByTagName('*');for(var i=0;i<ele.length;i++){if(reg.test(' '+ele[i].className+' ')){res.push(ele[i])}}}if(res.length>0){return res[0]}else{return res}}else{if(num=='#'){obj=obj.substr(1,obj.length)}return document.getElementById(obj)}},css:function(elem,attribute,value){var i=0;var k='';if(typeof(elem)=='object'){if(!this.isUndefined(typeof(elem.length))){for(i=0;i<elem.length;i++){var el;if(typeof(elem[i])=='string'){el=this.getByElement(elem[i])}else{el=elem[i]}if(typeof(attribute)!='object'){if(!this.isUndefined(value)){el.style[attribute]=value}}else{for(k in attribute){if(!this.isUndefined(attribute[k])){try{el.style[k]=attribute[k]}catch(event){this.log(event)}}}}}return}}if(typeof(elem)=='string'){elem=this.getByElement(elem)}if(typeof(attribute)!='object'){if(!this.isUndefined(value)){elem.style[attribute]=value}else{if(!this.isUndefined(this.getStyle(elem,attribute))){return this.getStyle(elem,attribute)}else{return false}}}else{for(k in attribute){if(!this.isUndefined(attribute[k])){elem.style[k]=attribute[k]}}}},getStyle:function(obj,attr){if(!this.isUndefined(obj.style[attr])){return obj.style[attr]}else{if(obj.currentStyle){return obj.currentStyle[attr]}else{return getComputedStyle(obj,false)[attr]}}},isUndefined:function(value){try{if(value=='undefined'||value==undefined||value==null){return true}}catch(event){this.log(event)}return false},addListener:function(name,funName){if(name&&funName){if(this.playerType=='flashplayer'){var ff='';if(typeof(funName)=='function'){ff=this.getParameterNames(funName)}this.V.addListener(name,ff);return}var have=false;for(var i=0;i<this.listenerJsArr.length;i++){var arr=this.listenerJsArr[i];if(arr[0]==name&&arr[1]==funName){have=true;break}}if(!have){this.listenerJsArr.push([name,funName])}}},removeListener:function(name,funName){if(name&&funName){if(this.playerType=='flashplayer'){var ff='';if(typeof(funName)=='function'){ff=this.getParameterNames(funName)}this.V.removeListener(name,ff);return}for(var i=0;i<this.listenerJsArr.length;i++){var arr=this.listenerJsArr[i];if(arr[0]==name&&arr[1]==funName){this.listenerJsArr.splice(i,1);break}}}},addListenerInside:function(e,f,d,t){if(this.isUndefined(t)){t=false}var o=this.V;if(!this.isUndefined(d)){o=d}if(o.addEventListener){try{o.addEventListener(e,f,t)}catch(event){}}else if(o.attachEvent){try{o.attachEvent('on'+e,f)}catch(event){}}else{o['on'+e]=f}},removeListenerInside:function(e,f,d,t){if(this.isUndefined(t)){t=false}var o=this.V;if(!this.isUndefined(d)){o=d}if(o.removeEventListener){try{this.addNum--;o.removeEventListener(e,f,t)}catch(e){}}else if(o.detachEvent){try{o.detachEvent('on'+e,f)}catch(e){}}else{o['on'+e]=null}},sendJS:function(name,val){if(this.adPlayerPlay&&name.substr(-2)!='Ad'){return}var list=this.listenerJsArr;var obj={variable:this.vars['variable']};if(this.vars['playerID']){obj['playerID']=this.vars['playerID']}for(var i=0;i<list.length;i++){var arr=list[i];if(arr[0]==name){if(val){switch(arr[1].length){case 1:arr[1](val);break;case 2:arr[1](val,obj);break;default:arr[1]();break}}else{switch(arr[1].length){case 1:if(typeof(val)=='boolean'){arr[1](false)}else{arr[1](obj)}break;default:arr[1]();break}}}}},getParameterNames:function(fn){if(typeof(fn)!=='function'){return false}var COMMENTS=/((\/\/.*$)|(\/\*[\s\S]*?\*\/))/mg;var code=fn.toString().replace(COMMENTS,'');var result=code.slice(code.indexOf(' ')+1,code.indexOf('('));return result===null?false:result},getNowDate:function(){var nowDate=new Date();var month=nowDate.getMonth()+1;var date=nowDate.getDate();var hours=nowDate.getHours();var minutes=nowDate.getMinutes();var seconds=nowDate.getSeconds();var tMonth='',tDate='',tHours='',tMinutes='',tSeconds='',tSeconds=(seconds<10)?'0'+seconds:seconds+'',tMinutes=(minutes<10)?'0'+minutes:minutes+'',tHours=(hours<10)?'0'+hours:hours+'',tDate=(date<10)?'0'+date:date+'',tMonth=(month<10)?'0'+month:month+'';return tMonth+'/'+tDate+' '+tHours+':'+tMinutes+':'+tSeconds},formatTime:function(seconds,ishours){var tSeconds='',tMinutes='',tHours='';if(isNaN(seconds)){seconds=0}var s=Math.floor(seconds%60),m=0,h=0;if(ishours){m=Math.floor(seconds/60)%60;h=Math.floor(seconds/3600)}else{m=Math.floor(seconds/60)}tSeconds=(s<10)?'0'+s:s+'';tMinutes=(m>0)?((m<10)?'0'+m+':':m+':'):'00:';tHours=(h>0)?((h<10)?'0'+h+':':h+':'):'';if(ishours){return tHours+tMinutes+tSeconds}else{return tMinutes+tSeconds}},randomString:function(len){len=len||16;var chars='abcdefghijklmnopqrstuvwxyz';var maxPos=chars.length;var val='';for(i=0;i<len;i++){val+=chars.charAt(Math.floor(Math.random()*maxPos))}return'ch'+val},getStringLen:function(str){var len=0;for(var i=0;i<str.length;i++){if(str.charCodeAt(i)>127||str.charCodeAt(i)==94){len+=2}else{len++}}return len},createXHR:function(){if(window.XMLHttpRequest){return new XMLHttpRequest()}else if(window.ActiveXObject){try{return new ActiveXObject('Microsoft.XMLHTTP')}catch(event){try{return new ActiveXObject('Msxml2.XMLHTTP')}catch(event){this.eject(this.errorList[7])}}}else{this.eject(this.errorList[8])}},ajax:function(cObj){var thisTemp=this;var callback=null;var obj={method:'get',dataType:'json',charset:'utf-8',async:false,url:'',data:null,success:null};if(typeof(cObj)!='object'){this.eject(this.errorList[9]);return}obj=this.standardization(obj,cObj);if(obj.dataType==='json'||obj.dataType==='text'||obj.dataType==='html'){var xhr=this.createXHR();callback=function(){if(xhr.status==200){if(thisTemp.isUndefined(obj.success)){return}if(obj.dataType==='json'){try{obj.success(eval('('+xhr.responseText+')'))}catch(event){obj.success(null)}}else{obj.success(xhr.responseText)}}else{thisTemp.eject(thisTemp.errorList[10],'Ajax.status:'+xhr.status)}};obj.url=obj.url.indexOf('?')==-1?obj.url+'?rand='+this.randomString(6):obj.url;obj.data=this.formatParams(obj.data);if(obj.method==='get'&&!this.isUndefined(obj.data)){if(obj.data!=''){if(obj.url.indexOf('?')==-1){obj.url+='?'+obj.data}else{obj.url+='&'+obj.data}}}if(obj.async===true){xhr.onreadystatechange=function(){if(xhr.readyState==4&&callback!=null){callback()}}}xhr.open(obj.method,obj.url,obj.async);if(obj.method==='post'){xhr.setRequestHeader('Content-Type','application/x-www-form-urlencoded');xhr.setRequestHeader('charset',obj['charset']);xhr.send(obj.data)}else{xhr.send(null)}if(obj.async===false){callback()}}else if(obj.dataType==='jsonp'){var oHead=document.getElementsByTagName('head')[0];var oScript=document.createElement('script');var callbackName='callback'+new Date().getTime();var params=this.formatParams(obj.data)+'&callback='+callbackName;callback=obj.success;oScript.src=obj.url.split('?')+'?'+params;oHead.insertBefore(oScript,oHead.firstChild);window[callbackName]=function(json){callback(json);oHead.removeChild(oScript)}}},loadJs:function(path,success){var oHead=document.getElementsByTagName('HEAD').item(0);var oScript=document.createElement('script');oScript.type='text/javascript';oScript.src=this.getNewUrl(path);oHead.appendChild(oScript);oScript.onload=function(){success()}},isMsie:function(){var browser=navigator.appName;var b_version=navigator.appVersion;var version=b_version.split(';');var trim_Version='';if(version.length>1){trim_Version=version[1].replace(/[ ]/g,'')}if(browser=='Microsoft Internet Explorer'&&(trim_Version=='MSIE6.0'||trim_Version=='MSIE7.0'||trim_Version=='MSIE8.0'||trim_Version=='MSIE9.0'||trim_Version=='MSIE10.0')){return false}return true},uploadFlash:function(){var swf;if(navigator.userAgent.indexOf('MSIE')>0){try{var swf=new ActiveXObject('ShockwaveFlash.ShockwaveFlash');return true}catch(e){return false}}if(navigator.userAgent.indexOf('Firefox')>0){swf=navigator.plugins['Shockwave Flash'];if(swf){return true}else{return false}}return true},supportVideo:function(){if(!this.isMsie()){return false}if(!!document.createElement('video').canPlayType){var vidTest=document.createElement('video');var oggTest;try{oggTest=vidTest.canPlayType('video/ogg; codecs=""theora, vorbis""')}catch(error){oggTest=false}if(!oggTest){var h264Test;try{h264Test=vidTest.canPlayType('video/mp4; codecs=""avc1.42E01E, mp4a.40.2""')}catch(error){h264Test=false}if(!h264Test){return false}else{if(h264Test==""probably""){return true}else{return false}}}else{if(oggTest==""probably""){return true}else{return false}}}else{return false}},getDataset:function(ele,z){try{return ele.dataset[z]}catch(error){try{return ele.getAttribute('data-'+z)}catch(error){return false}}},getObjectById:function(id){var x=null;var y=this.getByElement('#'+id);var r='embed';if(y&&y.nodeName=='OBJECT'){if(typeof(y.SetVariable)!='undefined'){x=y}else{var z=y.getElementsByTagName(r)[0];if(z){x=z}}}return x},formatParams:function(data){var arr=[];for(var i in data){arr.push(encodeURIComponent(i)+'='+encodeURIComponent(data[i]))}return arr.join('&')},arrSort:function(arr){var temp=[];for(var i=0;i<arr.length;i++){for(var j=0;j<arr.length-i;j++){if(!this.isUndefined(arr[j+1])&&arr[j][3]<arr[j+1][3]){temp=arr[j+1];arr[j+1]=arr[j];arr[j]=temp}}}return arr},getFileExt:function(filepath){if(filepath!=''&&!this.isUndefined(filepath)){if(filepath.indexOf('?')>-1){filepath=filepath.split('?')[0]}var pos='.'+filepath.replace(/.+\./,'');return pos.toLowerCase()}return''},isMobile:function(){if(navigator.userAgent.match(/(iPhone|iPad|iPod|Android|ios)/i)){return true}return false},isContains:function(str,key){return str.indexOf(key)>-1},getNewUrl:function(url){if(this.isContains(url,'?')){return url+='&'+this.randomString(8)+'='+this.randomString(8)}else{return url+='?'+this.randomString(8)+'='+this.randomString(8)}},client:function(event){var eve=event||window.event;if(this.isUndefined(eve)){eve={clientX:0,clientY:0}}return{x:eve.clientX+(document.documentElement.scrollLeft||this.body.scrollLeft)-this.pdCoor['x'],y:eve.clientY+(document.documentElement.scrollTop||this.body.scrollTop)-this.pdCoor['y']}},getCoor:function(obj){var coor=this.getXY(obj);return{x:coor['x']-this.pdCoor['x'],y:coor['y']-this.pdCoor['y']}},getXY:function(obj){var parObj=obj;var left=obj.offsetLeft;var top=obj.offsetTop;while(parObj=parObj.offsetParent){left+=parObj.offsetLeft;top+=parObj.offsetTop}return{x:left,y:top}},removeChild:function(){if(this.playerType=='html5video'){var i=0;var timerArr=[this.timerError,this.timerFull,this.timerTime,this.timerBuffer,this.timerClick,this.timerLoading,this.timerCBar,this.timerVCanvas];for(i=0;i<timerArr.length;i++){if(timerArr[i]!=null){if(timerArr[i].runing){timerArr[i].stop()}timerArr[i]=null}}var ltArr=this.listenerJsArr;for(i=0;i<ltArr.length;i++){this.removeListener(ltArr[i][0],ltArr[i][1])}}this.playerType=='';this.V=null;if(this.showFace){this.deleteChild(this.CB['menu'])}this.deleteChild(this.PD);this.CD.innerHTML=''},canvasFill:function(name,path){name.beginPath();for(var i=0;i<path.length;i++){var d=path[i];if(i>0){name.lineTo(d[0],d[1])}else{name.moveTo(d[0],d[1])}}name.closePath();name.fill()},canvasFillRect:function(name,path){for(var i=0;i<path.length;i++){var d=path[i];name.fillRect(d[0],d[1],d[2],d[3])}},deleteChild:function(f){var def=this.arrIndexOf(this.elementArr,f.className);if(def>-1){this.elementArr.splice(def,1)}var childs=f.childNodes;for(var i=childs.length-1;i>=0;i--){f.removeChild(childs[i])}if(f&&f!=null&&f.parentNode){try{if(f.parentNode){f.parentNode.removeChild(f)}}catch(event){}}},getProportionCoor:function(stageW,stageH,vw,vh){var w=0,h=0,x=0,y=0;if(stageW/stageH<vw/vh){w=stageW;h=w*vh/vw}else{h=stageH;w=h*vw/vh}x=(stageW-w)*0.5;y=(stageH-h)*0.5;return{width:parseInt(w),height:parseInt(h),x:parseInt(x),y:parseInt(y)}},parseSrtSubtitles:function(srt){var subtitles=[];var textSubtitles=[];var i=0;var arrs=srt.split('\n');var arr=[];var delHtmlTag=function(str){return str.replace(/<[^>]+>/g,'')};for(i=0;i<arrs.length;i++){if(arrs[i].replace(/\s/g,'').length>0){arr.push(arrs[i])}else{if(arr.length>0){textSubtitles.push(arr)}arr=[]}}for(i=0;i<textSubtitles.length;++i){var textSubtitle=textSubtitles[i];if(textSubtitle.length>=2){var sn=textSubtitle[0];var startTime=this.toSeconds(this.trim(textSubtitle[1].split(' --> ')[0]));var endTime=this.toSeconds(this.trim(textSubtitle[1].split(' --> ')[1]));var content=[delHtmlTag(textSubtitle[2])];if(textSubtitle.length>2){for(var j=3;j<textSubtitle.length;j++){content.push(delHtmlTag(textSubtitle[j]))}}var subtitle={sn:sn,startTime:startTime,endTime:endTime,content:content};subtitles.push(subtitle)}}return subtitles},timer:function(time,fun,number){var thisTemp=this;this.time=10;this.fun=null;this.timeObj=null;this.number=0;this.numberTotal=null;this.runing=false;this.startFun=function(){thisTemp.number++;thisTemp.fun();if(thisTemp.numberTotal!=null&&thisTemp.number>=thisTemp.numberTotal){thisTemp.stop()}};this.start=function(){if(!thisTemp.runing){thisTemp.runing=true;thisTemp.timeObj=window.setInterval(thisTemp.startFun,time)}};this.stop=function(){if(thisTemp.runing){thisTemp.runing=false;window.clearInterval(thisTemp.timeObj);thisTemp.timeObj=null}};if(time){this.time=time}if(fun){this.fun=fun}if(number){this.numberTotal=number}this.start()},toSeconds:function(t){var s=0.0;if(t){var p=t.split(':');for(i=0;i<p.length;i++){s=s*60+parseFloat(p[i].replace(',','.'))}}return s},arrayInt:function(str){var a=str.split(',');var b=[];for(var i=0;i<a.length;i++){if(this.isUndefined(a[i])){a[i]=0}if(a[i].substr(-1)!='%'){a[i]=parseInt(a[i])}b.push(a[i])}return b},standardization:function(o,n){var h={};var k;for(k in o){h[k]=o[k]}for(k in n){var type=typeof(h[k]);switch(type){case'number':h[k]=parseFloat(n[k]);break;default:h[k]=n[k];break}}return h},arrIndexOf:function(arr,key){var re=new RegExp(key,['']);return(arr.toString().replace(re,'â¢').replace(/[^,â¢]/g,'')).indexOf('â¢')},trim:function(str){if(str!=''){return str.replace(/(^\s*)|(\s*$)/g,'')}return''},log:function(val){try{console.log(val)}catch(e){}},eject:function(er,val){if(!this.vars['debug']){return}var errorVal=er[1];if(!this.isUndefined(val)){errorVal=errorVal.replace('[error]',val)}var value='error '+er[0]+':'+errorVal;try{this.log(value)}catch(e){}}};window.ckplayer=ckplayer})();
",4
"	è½¯ä»¶åç§°ï¼ckplayer
	è½¯ä»¶çæ¬ï¼X1
",4
"	return {
",4
"			definition: true,//æ¯å¦ä½¿ç¨æ¸æ°åº¦ç»ä»¶
			smartRemove: true,//æ¯å¦ä½¿ç¨æºè½æ¸çï¼ä½¿ç¨è¯¥åè½åå¨å¤æ®µæ¶å½åæ­æ¾æ®µä¹åçæ®µé½ä¼è¢«æ¸é¤åºåå­ï¼åå°å¯¹åå­çä½¿ç¨
			bufferTime: 200,//ç¼å­åºçé¿åº¦ï¼åä½ï¼æ¯«ç§,ä¸è¦å°äº10
			click: true,//æ¯å¦æ¯æå±å¹åå»æå
			doubleClick: true,//æ¯å¦æ¯æå±å¹åå»å¨å±
",4
"				space: true,//æ¯å¦å¯ç¨ç©ºæ ¼é®åæ¢æ­æ¾/æå
				left: true,//æ¯å¦å¯ç¨å·¦æ¹åé®å¿«é
				right: true,//æ¯å¦å¯ç¨å³æ¹åé®å¿«è¿
				up: true,//æ¯å¦æ¯æä¸æ¹åé®å¢å é³é
				down: true //æ¯å¦æ¯æä¸æ¹åé®åå°é³é
",4
"				endStretched: 2 //ç»æå¹¿åæä¼¸æ¹å¼ï¼0=åå§å¤§å°ï¼1=èªå¨ç¼©æ¾ï¼2=åªæå½å¹¿åçå®½æé«å¤§äºæ­æ¾å¨å®½é«æ¶æè¿è¡ç¼©æ¾ï¼3=åèæ­æ¾å¨å®½é«ï¼4=å®½åº¦åèæ­æ¾å¨å®½ãé«åº¦èªå¨ï¼5=é«åº¦åèæ­æ¾å¨é«ãå®½åº¦èªå¨
",4
"		javascriptPath = thisPath.substring(0, thisPath.lastIndexOf('/') + 1);
	} ();
	var ckplayer = function(obj) {
		/*
			javascripté¨åå¼åæç¨çæ³¨éè¯´æï¼
",4
"		//å¨å±åéï¼æ­æ¾å¨é»è®¤éç½®ï¼å¨å¤é¨ä¼ éè¿æ¥ç¸åºéç½®åï¼åè¿è¡ç¸å³æ¿æ¢
",4
"		this.varsConfig = {
",4
"			drag: '',//æå¨æ¶æ¯æçåç½®åæ°
			front: '',//åä¸éæé®å¨ä½
",4
"			next: '',//ä¸ä¸éæé®å¨ä½
			loaded: '',//å è½½æ­æ¾å¨åè°ç¨çå½æ°
			flashplayer: false,//è®¾ç½®ætrueåå¼ºå¶ä½¿ç¨flashplayer
",4
"			prompt: null,//æç¤ºç¹åè½
",4
"			debug: false,//æ¯å¦å¼å¯è°è¯æ¨¡å¼
			//ä»¥ä¸ä¸ºå¹¿åç¸å³éç½®
			adfront: '',
",4
"			adpause: '',
			adpausetime: '',
			adpauselink: '',
			adinsert: '',
",4
"			adendlink: '',
			advertisements: ''
",4
"			escMute: 'åæ¶éé³',
			front: 'ä¸ä¸é',
			next: 'ä¸ä¸é',
			definition: 'ç¹å»éæ©æ¸æ°åº¦',
			playbackRate: 'ç¹å»éæ©éåº¦',
",4
"			error: 'å è½½åºé',
",4
"		//å¨å±åéï¼æ¯å¦å è½½äºæ­æ¾å¨
		this.loaded = false;
		//å¨å±åéï¼è®¡æ¶å¨ï¼çå¬è§é¢å è½½åºéçç¶æ
",4
"		//å¨å±åéï¼æ¯å¦åºé
		this.error = false;
		//å¨å±åéï¼åºéå°åçæ°ç»
		this.errorUrl = [];
",4
"		//å¨å±åéï¼è®¡æ¶å¨ï¼çå¬è§é¢å è½½
		this.timerBuffer = null;
",4
"		//å¨å±åéï¼è®¾ç½®è¿åº¦æé®åè¿åº¦æ¡æ¯å¦è·çæ¶é´ååï¼è¯¥å±æ§ä¸»è¦ç¨æ¥å¨æä¸è¿åº¦æé®æ¶æåè¿åº¦æé®ç§»å¨åè¿åº¦æ¡çé¿åº¦åå
",4
"		this.isTimeButtonMove = true;
		//å¨å±åéï¼è¿åº¦æ æ¯å¦ææï¼å¦ææ¯ç´æ­ï¼åä¸éè¦çå¬æ¶é´è®©è¿åº¦æé®åè¿åº¦æ¡åå
",4
"		//å¨å±åéï¼ç¨æ¥æ¨¡æåå»åè½çå¤æ­
		this.isClick = false;
		//å¨å±åéï¼è®¡æ¶å¨ï¼ç¨æ¥æ¨¡æåå»åè½çè®¡æ¶å¨
",4
"		this.volume = 0;
		//å¨å±åéï¼éé³æ¶ä¿å­ä¸´æ¶é³é
		this.volumeTemp = 0;
		//å¨å±åé/åéç±»åï¼Number/åè½ï¼å½åæ­æ¾æ¶é´
",4
"			x: 0,
			y: 0
		};
",4
"		this.loadTime = 0;
",4
"		this.trackIndex = 0;
		//å¨å±åéï¼å½åæ¾ç¤ºçå­å¹åå®¹
		this.nowTrackShow = {
",4
"			sn: ''
		};
		//å¨å±åéï¼ä¿å­å­å¹åä»¶æ°ç»
",4
"		this.videoScale = 1;
",4
"		this.adI = 0;
		//å¨å±åéï¼è¦æ­æ¾çä¸´æ¶å°å
		this.videoTemp = {
",4
"			}
			if (typeof(c) != 'object') {
				this.eject(this.errorList[1]);
			}
			this.vars = this.standardization(this.varsConfig, c);
",4
"					if (videoString[0][0].substr(0, 3) == 'CK:' || videoString[0][0].substr(0, 3) == 'CE:' || videoString[0][0].substr(8, 3) == 'CK:' || videoString[0][0].substr(8, 3) == 'CE:') {
",4
"					default:
						break;
					}
",4
"									thisTemp.analysedUrl(data);
								} else {
									thisTemp.eject(thisTemp.errorList[5]);
									this.VA = video;
",4
"				this.html5Video = false;
				return;
",4
"			}
			for (var i = 0; i < va.length; i++) {
				var v = va[i];
				if (v) {
					if (v[1] != '' && !mobile && supportType(v[1], codecs(v[1])) && v[0].substr(0, 4) != 'rtmp') {
",4
"						nva.push(v);
					}
",4
"			if (nva.length > 0) {
				this.VA = nva;
			} else {
				if (!mobile) {
",4
"			}
			if (this.vars['cktrack']) {
				this.loadTrack();
",4
"			source = '',
			poster = '',
			loop = '',
",4
"			autoplay = '',
			track = '';
			var video = v['video'];
",4
"				this.PD = thisPd; //PD:å®ä¹æ­æ¾å¨å®¹å¨å¯¹è±¡å¨å±åé
			} else {
				var playerID = 'ckplayer' + this.randomString();
				var playerDiv = document.createElement('div');
				playerDiv.className = playerID;
",4
"				this.CD.innerHTML = '';
				this.CD.appendChild(playerDiv);
				this.PD = this.getByElement(playerID); //PD:å®ä¹æ­æ¾å¨å®¹å¨å¯¹è±¡å¨å±åé
",4
"				if (this.VA.length == 1) {
					this.videoTemp['src'] = decodeURIComponent(this.VA[0][0]);
					src = ' src=""' + this.videoTemp['src'] + '""';

",4
"						if (va[1]) {
							type = ' type=""' + va[1] + '""';
							if (type == ' type=""video/m3u8""' || type == ' type=""m3u8""') {
",4
"								type = '';
							}
						}
",4
"						var trackObj = trackArr[i];
						if (trackObj['default'] && !defaultHave) {
							trackDefault = ' default';
							defaultHave = true;
",4
"					}
",4
"				}
				var vid = this.randomString();
				var controls = '';
				if (!this.showFace) {
",4
"					}
				} else {
					var html = '';
					if (!this.isM3u8) {
",4
"						if (this.vars['playbackrate'] < this.playbackRateArr.length) {
",4
"				} catch(error) {}
				this.css(this.V, {
					width: '100%',
",4
"					this.loadJs(javascriptPath + 'hls/hls.min.js', loadJsHandler);
				}
",4
"				this.css(this.V, 'backgroundColor', '#000000');
				//åå»ºä¸ä¸ªç»å¸å®¹å¨
				if (this.config['videoDrawImage']) {
					var canvasID = 'vcanvas' + this.randomString();
",4
"					}
",4
"			}
		},
		/*
",4
"			åæå¹¿åæ°æ®
",4
"												isAdvShow.push(false);
",4
"										for (i = 0; i < val.length; i++) {
",4
"						isInsert.push(false);
					}
					thisTemp.advertisements['insertPlay'] = isInsert;
				}
				thisTemp.getVideo();
",4
"			if (arr.length == 0) {
				return null;
",4
"			for (var i = 0; i < arr.length; i++) {
				var type = arr[i]['type'];
				if (type == 'mp4' || type == 'mov' || this.isStrImage(type)) {
					newArr.push(arr[i]);
",4
"				}
",4
"		adAnalysisOne: function(adType, adName, adTime, adLink, adStype) {
			var v = this.vars;
			if (this.isUndefined(v[adName])) {
				v[adName] = '';
",4
"					var adLinkLen = adlink.length,
					adTimeLen = adtime.length;
",4
"					if (adTimeLen < ad.length) {
						for (i = adTimeLen; i < ad.length; i++) {
",4
"					}
",4
"						adstypeLen = 0;
						adstype = [];
					}
					if (adstypeLen < ad.length) {
",4
"				}
",4
"					thisTemp.formatInserttime(thisTemp.V.duration);
					if (thisTemp.adPlayerPlay) {
						thisTemp.advertisementsTime(thisTemp.V.duration + 1);
",4
"			//çå¬è§é¢æ­æ¾äºä»¶
			var eventPlaying = function(event) {
",4
"					thisTemp.formatInserttime(thisTemp.V.duration);
",4
"						//çå¬ä¸­é´æå¥å¹¿åæ¯å¦éè¦æ­æ¾
						if (!thisTemp.isUndefined(thisTemp.advertisements['insert'])) {
							thisTemp.checkAdInsert(thisTemp.time);
						}
",4
"					}

				}
",4
"			};
			this.addListenerInside('timeupdate', eventTimeupdate);
			//çå¬è§é¢ç¼å²äºä»¶
			var eventWaiting = function(event) {
				thisTemp.loadingStart(true);
",4
"			};
			this.addListenerInside('volumechange', eventVolumeChange);
			//çå¬å¨å±äºä»¶
			var eventFullChange = function(event) {
",4
"		},
",4
"		resetPlayer: function() {
			this.timeTextHandler();
			if (this.showFace) {
",4
"				this.deletePrompt(); //å é¤æç¤ºç¹
				this.deletePreview(); //å é¤é¢è§å¾
				this.trackHide(); //éç½®å­å¹
				this.resetTrack();
",4
"			volumeDbgID = 'volumedbg' + randomS,//é³éè°èæ¡å®¹å¨èæ¯
",4
"			volumeBgID = 'volumebg' + randomS,//é³éè°èæ¡èæ¯å±
",4
"			errorTextID = 'errortext' + randomS,//éè¯¯ææ¬æ¡
			logoID = 'logo' + randomS,//logo
",4
"			adBackgroundID = 'background' + randomS,//å¹¿åèæ¯å¾ç
			adElementID = 'adelement' + randomS,//å¹¿åå®¹å¨
			adBarID = 'adBar' + randomS,//å¹¿åé¡¶é¨åè®¡æ¶ï¼è·³è¿å¹¿åï¼éé³æé®å®¹å¨
			adSkipID = 'adskip' + randomS,//è·³è¿å¹¿åæé®
			adTimeID = 'adtime' + randomS,//åè®¡æ¶æé®
",4
"			adLinkID = 'adlink' + randomS,//å¹¿åé¾æ¥æé®
",4
"			adLink = document.createElement('div'),
			adPauseClose = document.createElement('div');
			/*
",4
"			this.PD.appendChild(timeProgressBg);
			this.PD.appendChild(timeBoBg);
			this.PD.appendChild(promptBg);
			this.PD.appendChild(prompt);
			this.PD.appendChild(definitionP);
",4
"			html += '<div class=""' + escMuteID + '"" data-title=""' + thisTemp.language['escMute'] + '"">' + this.newCanvas(escMuteID, bWidth, bHeight) + '</div>'; //éåºéé³æé®
			html += '<div class=""' + dlineID + '-rd""></div>'; //åéçº¿
			this.getByElement(controlBarID).innerHTML = html;
			//æå»ºè¿åº¦æ¡åå®¹
			this.getByElement(timeProgressBgID).innerHTML = '<div class=""' + loadProgressID + '""></div><div class=""' + timeProgressID + '""></div>';
",4
"			this.getByElement(timeBOBGID).innerHTML = '<div class=""' + timeBOID + '""><div class=""' + timeBWID + '""></div></div>';
			//æå»ºè¿åº¦æ¡åå®¹ç»æ
			this.getByElement(pauseCenterID).innerHTML = this.newCanvas(pauseCenterID, 80, 80); //æå»ºä¸­é´æåæé®
			this.getByElement(loadingID).innerHTML = this.newCanvas(loadingID, 60, 60); //æå»ºä¸­é´ç¼å²æ¶æ¾ç¤ºçå¾æ 
			this.getByElement(errorTextID).innerHTML = this.language['error']; //æå»ºéè¯¯æ¶æ¾ç¤ºçææ¬æ¡
",4
"			//æå»ºå¹¿åç¸å³
			html = '<div class=""' + adTimeID + '"">' + this.language['adTime'].replace('{$second}', 0) + '</div>';
",4
"			html += '<div class=""' + adMuteID + '"">' + this.newCanvas(adMuteID, 30, 30) + '</div>';
			html += '<div class=""' + adEscMuteID + '"">' + this.newCanvas(adEscMuteID, 30, 30) + '</div>';
			html += '<div class=""' + adSkipID + '""></div>';
			this.getByElement(adBarID).innerHTML = html;
			this.getByElement(adLinkID).innerHTML = this.language['adLink'];
",4
"					if (logoFile.substr(0, 15) == 'data:image/png;' || logoFile.substr(0, 15) == 'data:image/jpg;' || logoFile.substr(0, 16) == 'data:image/jpeg;') {
						this.getByElement(logoID).innerHTML = '<img src=""' + logoFile + '"" border=""0"">'; //æå»ºlogo
					}
",4
"				prompt: this.getByElement(promptID, pd),
",4
"				timeProgressBg: this.getByElement(timeProgressBgID, pd),
				loadProgress: this.getByElement(loadProgressID, pd),
				timeProgress: this.getByElement(timeProgressID, pd),
				timeBoBg: this.getByElement(timeBOBGID, pd),
				timeButton: this.getByElement(timeBOID, pd),
",4
"				play: bWidth,
				full: bWidth,
				front: bWidth,
",4
"				backgroundColor: '#000000',
				position: 'absolute',
",4
"			this.css(controlBarID, {
				width: '100%',
				height: bHeight + 'px',
",4
"				position: 'absolute',
				bottom: '0px',
				zIndex: '990'
			});
			//ä¸­é´æåæé®
",4
"				display: 'none',
",4
"				textAlign: 'center',
				position: 'absolute',
				display: 'none',
				zIndex: '101',
",4
"				msTransform: 'rotate(0deg)',
				mozTransform: 'rotate(0deg)',
				webkitTransform: 'rotate(0deg)',
				oTransform: 'rotate(0deg)'
",4
"			});
",4
"				paddingLeft: '5px',
				paddingRight: '5px',
				bottom: '0px',
",4
"				top: '0px',
				zIndex: '991'
			});
",4
"			this.css(loadProgressID, 'backgroundColor', '#6F6F6F');
			this.css(timeProgressID, 'backgroundColor', bOverColor);
			//æ¶é´è¿åº¦æé®
",4
"				bottom: '34px',
				cursor: 'pointer',
				zIndex: '992'
			});
",4
"			});
			this.css(timeBWID, {
",4
"				opacity: '0.9'
			});
			this.css([dlineID + '-la', dlineID + '-lb', dlineID + '-lc'], 'float', 'left');
",4
"			//æ­æ¾/æå/ä¸ä¸é/ä¸ä¸éæé®
			this.css([playID, pauseID, frontID, nextID], {
				width: bWidth + 'px',
				height: bHeight + 'px',
				float: 'left',
",4
"				overflow: 'hidden',
				cursor: 'pointer'
",4
"				height: bHeight + 'px',
",4
"				width: '100px',
",4
"				cursor: 'pointer'
			});
			this.css(volumeBWID, {
				width: '6px',
				height: '6px',
",4
"				bottom: '4px',
				backgroundColor: '#000000',
",4
"				cursor: 'pointer',
",4
"				position: 'absolute',
				bottom: '4px',
",4
"				textAlign: 'center',
				zIndex: '995',
",4
"			this.css(adBackgroundID, {
				width: '100%',
",4
"				height: '100%',
",4
"				backgroundColor: '#000000',
",4
"				position: 'absolute',
				top: '0px',
				zIndex: '997',
				display: 'none'
			});
",4
"				overflow: 'hidden',
				top: '10px',
",4
"				cursor: 'pointer'
			});
",4
"				cursor: 'pointer'
			});
			this.css(adSkipID, {
				backgroundColor: '#000000',
",4
"				zIndex: '999',
",4
"				cPlayFillRect();
			};

			this.addListenerInside('mouseover', cPlayOver, this.getByElement(playID + '-canvas'));
",4
"			};
			cPause.fillStyle = bBgColor;
			cPauseFillRect();
			var cPauseOver = function(event) {
",4
"				cFull.clearRect(0, 0, bWidth, bHeight);
				cFull.fillStyle = bOverColor;
				cFullFillRect();
			};
",4
"			//å®ä¹éåºå¨å±æé®æ ·å¼
",4
"				cEscFull.fillStyle = bOverColor;
				cEscFullFillRect();
",4
"				thisTemp.canvasFillRect(cMute, [[23, 15, 2, 8], [27, 10, 2, 18]]);
			};
			cMute.fillStyle = bBgColor;
			cMuteFillRect();
",4
"				cMute.clearRect(0, 0, bWidth, bHeight);
				cMute.fillStyle = bBgColor;
				cMuteFillRect();
			};
			this.addListenerInside('mouseover', cMuteOver, this.getByElement(muteID + '-canvas'));
",4
"			var cAdMute = this.getByElement(adMuteID + '-canvas').getContext('2d');
",4
"			var cAdMuteFillRect = function() {
				thisTemp.canvasFill(cAdMute, [[8, 12], [12, 12], [16, 8], [16, 21], [12, 18], [8, 18]]);
				thisTemp.canvasFillRect(cAdMute, [[18, 12, 2, 6], [21, 8, 2, 14]]);
			};
",4
"			};
			this.addListenerInside('mouseover', cAdEscMuteOver, this.getByElement(adEscMuteID + '-canvas'));
",4
"			this.addListenerInside('mouseout', cAdEscMuteOut, this.getByElement(adEscMuteID + '-canvas'));
			//å®ä¹æåå¹¿åå³é­æé®
			var adPauseClose = this.getByElement(adPauseCloseID + '-canvas').getContext('2d');
",4
"			this.addListenerInside('mouseover', adPauseCloseOver, this.getByElement(adPauseCloseID + '-canvas'));
			this.addListenerInside('mouseout', adPauseCloseOut, this.getByElement(adPauseCloseID + '-canvas'));
			//å®ä¹loadingæ ·å¼
			var cLoading = this.getByElement(loadingID + '-canvas').getContext('2d');
			var cLoadingFillRect = function() {
",4
"				cLoading.stroke(); //ç»å¶
				cLoading.beginPath(); //è·¯å¾å¼å§
",4
"				cPauseCenter.fillStyle = bOverColor;
				cPauseCenter.strokeStyle = bOverColor;
",4
"			//é¼ æ ç»è¿/ç¦»å¼é³éè°èæé®
			var volumeBOOver = function() {
				thisTemp.css(volumeBOID, 'backgroundColor', bOverColor);
				thisTemp.css(volumeBWID, 'backgroundColor', bBgColor);
",4
"				thisTemp.elementCoordinate();
				thisTemp.timeUpdateHandler();
				thisTemp.changeLoad();
				thisTemp.checkBarWidth();
				thisTemp.changeElementCoor(); //ä¿®æ¹æ°å åä»¶çåæ 
",4
"				thisTemp.adPauseCoor();
",4
"					eval(thisTemp.vars['front'] + '()');
					thisTemp.sendJS('clickEvent', 'actionScript->' + thisTemp.vars['front']);
				}
			};
",4
"			this.addListenerInside('click', frontClick, this.CB['front']);
			var nextClick = function(event) {
				if (thisTemp.vars['next']) {
					eval(thisTemp.vars['next'] + '()');
					thisTemp.sendJS('clickEvent', 'actionScript->' + thisTemp.vars['next']);
",4
"				thisTemp.videoMute();
				thisTemp.sendJS('clickEvent', 'actionScript->videoMute');
			};
",4
"				thisTemp.quitFullScreen();
				thisTemp.sendJS('clickEvent', 'actionScript->quitFullScreen');
			};
			this.addListenerInside('click', escFullClick, this.CB['escFull']);
			var adSkipClick = function(event) {
",4
"			var adPauseCloseClick = function(event) {
				thisTemp.adPauseCloseFunction();
			};
			this.addListenerInside('click', adPauseCloseClick, this.CB['adPauseClose']);
			//å®ä¹åä¸ªæé®çé¼ æ ç»è¿/ç¦»å¼äºä»¶
",4
"			var promptHide = function(event) {
",4
"				thisTemp.promptShow(false);
			};
			var playOver = function(event) {
",4
"			this.addListenerInside('mouseover', nextOver, this.CB['next']);
			this.addListenerInside('mouseout', promptHide, this.CB['next']);
			var muteOver = function(event) {
",4
"			};
			this.addListenerInside('mouseover', escMuteOver, this.CB['escMute']);
			this.addListenerInside('mouseout', promptHide, this.CB['escMute']);
			var fullOver = function(event) {
",4
"				thisTemp.promptShow(thisTemp.CB['definition']);
			};
			this.addListenerInside('mouseover', definitionOver, this.CB['definition']);
			this.addListenerInside('mouseout', promptHide, this.CB['definition']);
			var playbackrateOver = function(event) {
",4
"				}
			};
			this.slider(volumeObj);
			var volumeClickObj = {
				refer: this.CB['volumeBg'],
",4
"					var ad = thisTemp.getNowAdvertisements();
					try {
						if (ad['link'] != '') {
							window.open(ad['link']);
",4
"					}
				}
",4
"
			};
			clearTimerClick();
			if (this.isClick) {
",4
"				this.isClick = false;
				if (thisTemp.ckplayerConfig['config']['doubleClick']) {
					if (!this.full) {
",4
"				}

",4
"				endFun: function(time) {
					if (thisTemp.V) {
						if (thisTemp.V.duration > 0) {
							thisTemp.needSeek = 0;
							thisTemp.videoSeek(parseInt(time));
",4
"			var timeClickObj = {
",4
"						if (thisTemp.V.duration > 0) {
							thisTemp.needSeek = 0;
							thisTemp.videoSeek(parseInt(time));
",4
"					y: timeBoBgXY['y']
",4
"			};
			var promptHide = function(event) {
				thisTemp.promptShow(false);
				if (thisTemp.previewDiv != null) {
",4
"					startFun:å¼å§è°ç¨çåç´ 
					monitorFun:çå¬å½æ°
					endFun:ç»æè°ç¨çå½æ°
",4
"			var mDown = function(event) {
				thisTemp.addListenerInside('mousemove', mMove, document);
				thisTemp.addListenerInside('mouseup', mUp, document);
",4
"				var referXY = thisTemp.getCoor(obj['refer']);
",4
"				thisTemp.css(obj['slider'], 'left', newX + 'px');
				thisTemp.css(obj['follow'], 'width', (newX + obj['slider'].offsetWidth * 0.5) + 'px');
				var nowZ = calculation();
				if (obj['monitorFun']) {
",4
"			var mOver = function(event) {
				if (obj['overFun']) {
",4
"			}
",4
"		/*
			åé¨å½æ°
			æ¾ç¤ºloading
		*/
		loadingStart: function(rot) {
",4
"				this.css(thisTemp.CB['loading'], 'display', 'none');
			}
			if (this.timerLoading != null) {
				if (this.timerLoading.runing) {
					this.timerLoading.stop();
",4
"				var nowRotate = '0';
				try {
					nowRotate = thisTemp.css(thisTemp.CB['loadingCanvas'], 'transform') || thisTemp.css(thisTemp.CB['loadingCanvas'], '-ms-transform') || thisTemp.css(thisTemp.CB['loadingCanvas'], '-moz-transform') || thisTemp.css(thisTemp.CB['loadingCanvas'], '-webkit-transform') || thisTemp.css(thisTemp.CB['loadingCanvas'], '-o-transform') || '0';
",4
"				if (thisTemp.showFace) {
					thisTemp.css(thisTemp.CB['loadingCanvas'], {
						transform: 'rotate(' + nowRotate + 'deg)',
",4
"				thisTemp.sendJS('buffer', buffer);
			};
",4
"			} else {
				thisTemp.sendJS('buffer', 100);
			}
		},
",4
"				}
				this.CB['prompt'].innerHTML = obj['title'];
				this.css(this.CB['prompt'], 'display', 'block');
				var promoptWidth = this.getStringLen(obj['title']) * 10;
				this.css(this.CB['promptBg'], 'width', promoptWidth + 'px');
",4
"					x = 0;
				}
",4
"				}
				this.css([this.CB['promptBg'], this.CB['prompt']], {
					display: 'block',
					left: x + 'px',
",4
"					bottom: y + 'px'
				});
			} else {
				this.css([this.CB['promptBg'], this.CB['prompt']], {
					display: 'none'
",4
"			}
		},
		/*
			åé¨å½æ°
",4
"				thisTemp.V.removeAttribute('poster');
				thisTemp.resetPlayer();
			};
			var errorListenerFun = function(event) {
				setTimeout(function() {
",4
"			clearIntervalError();
			var timerErrorFun = function() {
				if (thisTemp.V && parseInt(thisTemp.V.networkState) == 3) {
					errorFun();
				}
",4
"			}
",4
"			var fullFun = function() {
				thisTemp.isFullScreen();
			};
",4
"		/*
			åé¨å½æ°
",4
"			å¤æ­æ¯å¦æ¯å¨å±
",4
"				this.css(this.CB['full'], 'display', 'none');
				this.css(this.CB['escFull'], 'display', 'block');
				if (this.vars['live'] == 0) {
",4
"			if (!fullState && this.full) {
				this.full = false;
",4
"					if (this.timerFull.runing) {
						this.timerFull.stop();
					}
					this.timerFull = null;
",4
"			}
		},
		/*
			åé¨å½æ°
",4
"			this.css(this.CB['menu'], {
",4
"				zIndex: '999',
				color: '#A1A9BE',
",4
"								arrTemp.push(eveObj['type']);
",4
"								if (eveObj['fun']) {
									arrTemp.push(eveObj['fun']);
								}
",4
"								if (eveObj['link']) {
",4
"									arrTemp.push(eveObj['link']);
								}
								if (eveObj['target']) {
									arrTemp.push(' target=""' + eveObj['target'] + '""');
								}
",4
"					}
				}
			}
			var html = '';
",4
"			for (i = 0; i < mArr.length; i++) {
",4
"				}
			}
			this.CB['menu'].innerHTML = html;
			var pArr = this.CB['menu'].childNodes;
			for (i = 0; i < pArr.length; i++) {
",4
"					paddingRight: '30px'
",4
"					}
				}
			}
			this.PD.oncontextmenu = function(event) {
",4
"					thisTemp.css(thisTemp.CB['menu'], {
						display: 'block',
						left: x + 'px',
",4
"				if (setTimeOutP) {
					window.clearTimeout(setTimeOutP);
					setTimeOutP = null;
				}
			};
",4
"							thisTemp.sendJS('controlBar', false);
							thisTemp.css(thisTemp.CB['controlBarBg'], 'display', 'none');
							thisTemp.css(thisTemp.CB['controlBar'], 'display', 'none');
",4
"				oldClient = {
					x: client['x'],
",4
"				client['x'] = getClient['x'];
				client['y'] = getClient['y'];
				if (!cShow) {
					controlBarShow(true);
				}
",4
"				cShow = false;
",4
"					break;
				case 37:
					thisTemp.fastBack();
					break;
",4
"		playbackRate: function() {
			if (!this.showFace) {
",4
"				return;
			}
			var thisTemp = this;
			var vArr = this.playbackRateArr;
",4
"				nowD = vArr[this.playbackRateDefault][1];
			}
",4
"					var dlen = this.getStringLen(vArr[i][1]);
",4
"					}
					var defClick = function(event) {
						if (nowD != this.innerHTML) {
							thisTemp.css(thisTemp.CB['playbackrateP'], 'display', 'none');
							thisTemp.newPlaybackrate(this.innerHTML);
",4
"							thisTemp.sendJS('clickEvent', 'actionScript->newPlaybackrate');
						}
					};
",4
"				this.css([this.CB['playbackrate'], this.CB['playbackrateLine']], 'display', 'none');
			}
		},
",4
"		/*
			åé¨å½æ°
",4
"				}
			};
",4
"			var i = 0;
			for (i = 0; i < vArr.length; i++) {
				var v = vArr[i];
				if (v[1] == title) {
					this.playbackRateDefault = i;
",4
"			if (!this.showFace) {
				return;
			}
			var thisTemp = this;
			var vArr = this.VA;
",4
"			if (dArr.length > 1) {
				var zlen = 0;
				for (i = dArr.length - 1; i > -1; i--) {
					html = '<p>' + dArr[i] + '</p>' + html;
",4
"					var defClick = function() {
						if (nowD != this.innerHTML) {
							thisTemp.css(thisTemp.CB['definitionP'], 'display', 'none');
							thisTemp.newDefinition(this.innerHTML);
						}
",4
"				var pW = (zlen * 10) + 20;
				this.css(this.CB['definitionP'], {
					width: pW + 'px'
				});
				this.css(this.CB['definition'], {
",4
"					width: pW + 'px'
",4
"		*/
",4
"		addDefListener: function() {
			var thisTemp = this;
			var setTimeOutP = null;
			var defClick = function(event) {
",4
"				thisTemp.css(thisTemp.CB['definitionP'], {
					left: thisTemp.getCoor(thisTemp.CB['definition'])['x'] + 'px',
",4
"			this.addListenerInside('mouseout', defMouseOut, thisTemp.CB['definitionP']);
			var defMouseOver = function(event) {
				if (setTimeOutP) {
					window.clearTimeout(setTimeOutP);
",4
"		/*
			æ¥å£å½æ°
",4
"		*/
		newDefinition: function(title) {
			var vArr = this.VA;
			var nVArr = [];
			var i = 0;
",4
"			if (nVArr.length < 1) {
",4
"			}
			if (!this.isM3u8) {
",4
"				} else {
					var source = '';
					nVArr = this.arrSort(nVArr);
					for (i = 0; i < nVArr.length; i++) {
						var type = '';
",4
"			}
			this.V.autoplay = 'autoplay';
			this.V.load();
",4
"			this.timerErrorFun();
		},
		/*
			åç½®å½æ°
",4
"		prompt: function() {
			if (!this.showFace) {
",4
"				return;
			}
			var thisTemp = this;
			var prompt = this.vars['promptSpot'];
			if (prompt == null || this.promptArr.length > 0) {
",4
"				pL = parseInt(thisTemp.css(this, 'left')) - parseInt(pW * 0.5);
				if (pcon['pL'] > 10) {
					pL = pcon['pL'];
				}
				if (pL < 0) {
",4
"				var ele = document.createElement('div');
				ele.className = random;
",4
"				pL = 0;
			}
			if (pL > this.PD.offsetWidth - pW) {
",4
"				return;
",4
"			}
			var arr = this.promptArr;
",4
"								var eleTop = (obj['y'] - parseInt(imgH * 0.1) + 2);
								thisTemp.css(thisTemp.previewDiv, {
",4
"								});
								ele.setAttribute('data-x', '0');
								ele.setAttribute('data-y', eleTop);
								var ele2 = document.createElement('div');
								ele2.className = random + 'd2';
",4
"								thisTemp.PD.appendChild(ele2);
								thisTemp.previewTop = thisTemp.getByElement(ele2.className);
								thisTemp.css(thisTemp.previewTop, {
									width: parseInt(imgW * 0.1) + 'px',
",4
"							var context = canvas.getContext('2d');
							var sx = 0,
",4
"								i++;
								loadImg(i);
							}
						};
					};
",4
"				this.previewStart = 0;
			}
		},
		/*
			åé¨å½æ°
",4
"			var i = 0;
			if (vArr.length < 1) {
				return;
			}
			if (this.V != null && this.needSeek == 0) {
",4
"				this.needSeek = 0;
			}
			if (this.getFileExt(vArr[0][0]) != '.m3u8') {
",4
"						var va = vArr[i];
						if (va[1]) {
",4
"			è°æ´ä¸­é´æåæé®,ç¼å²loadingï¼éè¯¯æç¤ºææ¬æ¡çä½ç½®
		*/
		elementCoordinate: function() {
			this.pdCoor = this.getXY(this.PD);
			try {
",4
"		},
		/*
",4
"			var controlBarW = this.CB['controlBar'].offsetWidth;
			var ele = [];
			ele.push([[this.CB['full'], this.CB['escFull'], this.CB['fullLine']], this.buttonWidth['full'] + 2, 'full']);
			if (this.vars['front'] != '') {
",4
"			}
",4
"				ele.push([[this.CB['volume']], this.buttonWidth['volume']]);
				ele.push([[this.CB['mute'], this.CB['escMute'], this.CB['muteLine']], this.buttonWidth['mute'] + 2, 'mute']);
			}
			ele.push([[this.CB['timeText']], this.buttonWidth['timeText']]);
			ele.push([[this.CB['play'], this.CB['pause'], this.CB['playLine']], this.buttonWidth['play'] + 2, 'play']);
",4
"			if (isc) {
				this.buttonLen = len;
				this.buttonArr = ele;
			}
",4
"					this.css(ele[i][0], 'display', 'block');
					if (ele[i].length == 3) {
						var name = ele[i][2];
						switch (name) {
",4
"						case 'mute':
",4
"							break;
",4
"					}
				}
",4
"			åå§åæåææ­æ¾æé®
",4
"			} else {
				this.css(this.CB['play'], 'display', 'block');
				if (this.css(this.CB['errorText'], 'display') == 'none') {
",4
"				} catch(event) {
					this.log(event);
				}
			}
",4
"			this.playShow(true);
			//å¦ææ¯ç¬¬ä¸æ¬¡æ­æ¾
			if (this.isFirstTimePlay && !this.isUndefined(this.advertisements['front'])) {
",4
"				this.adPlayStart = true;
				this.adVideoPlay = false;
				this.videoPause();
",4
"			if (this.playerType == 'html5video' && this.V != null && this.config['videoDrawImage']) {
				this.sendVCanvas();
			}
			if (!this.isUndefined(this.advertisements['pause']) && !this.adPlayStart) { //å¦æå­å¨æåå¹¿å
				this.adPauseCloseFunction();
",4
"			}
		},
		/*æåæ¶æ­æ¾æåå¹¿å*/
		adPausePlayer: function() {
			this.adI = 0;
",4
"		},
		/*è°æ´æåå¹¿åçä½ç½®*/
",4
"				ph = this.PD.offsetHeight;
				this.css(this.CB['adElement'], {
					top: (ph - h) * 0.5 + 'px',
					left: (pw - w) * 0.5 + 'px'
				});
",4
"		},
",4
"		},
",4
"				}
			}
			if (this.adTimeAllTotal > 0) {
",4
"			this.adOtherCloseAll();
			this.adTimeTotal = -1;
		},
		/*å¤æ­æ¯å¦éè¦æ¾ç¤ºè·³è¿å¹¿åæé®*/
",4
"			var delayTimeTemp = skipConfig[this.adType + 'SkipButtonDelay'];
			var timeFun = function() {
				if (delayTimeTemp >= 0) {
					thisTemp.CB['adSkip'].innerHTML = thisTemp.language['skipAdTime'].replace('{$second}', delayTimeTemp > 9 ? delayTimeTemp: '0' + delayTimeTemp);
",4
"					setTimeout(timeFun, 1000);
",4
"				}
				delayTimeTemp--;
			};
",4
"			if (skipConfig['skipButtonShow']) {
				this.css(thisTemp.CB['adSkip'], 'display', 'block');
				if (skipConfig[this.adType + 'SkipButtonDelay'] > 0 && this.isUndefined(this.adSkipButtonTime)) {
					timeFun();
",4
"				if (!this.isUndefined(ad[this.adI]['time'])) {
",4
"		/*å è½½å¹¿å*/
		loadAdvertisements: function() {
			//this.videoTemp
			var ad = this.getNowAdvertisements();
",4
"			var width = this.PD.offsetWidth,
			height = this.PD.offsetHeight;
			this.changeControlBarShow(false);
			this.adPlayerPlay = true;
			if (this.isStrImage(type)) {
",4
"				var imgClass = 'adimg' + this.randomString(10);
				var imgHtml = '<img src=""' + ad['file'] + '"" class=""' + imgClass + '"">';
				if (ad['link']) {
					imgHtml = '<a href=""' + ad['link'] + '"" target=""_blank"">' + imgHtml + '</a>';
				}
",4
"				//å¤æ­æ¯å¦éé³
				if (this.adVideoMute) {
					this.css(this.CB['adEscMute'], 'display', 'block');
					this.css(this.CB['adMute'], 'display', 'none');
",4
"				}
				if (this.V.loop) {
					this.videoTemp['loop'] = true;
",4
"					this.needSeek = this.V.currentTime;
				}
",4
"				if (!this.adVideoMute) {
",4
"					color: '#FFFFFF',
					textDecoration: 'none'
				});
",4
"					1000);
",4
"			this.adTimeAllTotal--;
			var n = this.adTimeAllTotal;
			if (n < 0) {
",4
"			this.CB['adTime'].innerHTML = this.language['adTime'].replace('{$second}', n < 10 ? '0' + n: n);
		},
",4
"			var ad = this.advertisements['other'][i];
			var randomS = this.randomString(10); //è·åä¸ä¸ªéæºå­ç¬¦ä¸²
			var adDivID = 'adother' + randomS; //å¹¿åå®¹å¨
			imgClassName = 'adimgother' + randomS;
			var adDiv = document.createElement('div');
",4
"			this.PD.appendChild(adDiv);
			ad['div'] = adDivID;
			ad['element'] = imgClassName;
",4
"				zIndex: '996',
				top: '60px',
				left: '30px',
				cursor: 'pointer'
			});
",4
"				ad['close'] = false;
				this.css(closeAdDivID, {
",4
"					backgroundColor: '#f7f7f7',
",4
"					height: '20px',
",4
"					adOtherClose.fillStyle = '#404856';
					adOtherCloseFillRect();
				};
				this.addListenerInside('mouseover', adOtherCloseOver, this.getByElement(closeAdDivID + '-canvas'));
",4
"				this.addListenerInside('mouseout', adOtherCloseOut, this.getByElement(closeAdDivID + '-canvas'));
			}
			this.addListenerInside('load',
",4
"				thisTemp.adOtherCoor();
			},
			this.getByElement(imgClassName));
			this.addListenerInside('click',
",4
"			function() {
",4
"		/*
			è®¡ç®å¶å®å¹¿åçåæ 
		*/
",4
"			if (!this.isUndefined(this.advertisements['inserttime'])) {
				var arr = this.advertisements['inserttime'];
				var newArr = [];
",4
"						newArr.push(parseInt(arr[i]));
					}
",4
"		getNowAdvertisements: function() {
			if (this.adI == -1) {
				return {
",4
"			height = this.PD.offsetHeight;
			var nw = 0,
			nh = 0;
			if (w >= width || h >= height) {
",4
"					url: url,
",4
"		runFunction: function(s) {
",4
"			ä½¿ç¨ç»å¸éå è§é¢
		*/
",4
"		sendVCanvas: function() {
			if (this.timerVCanvas == null) {
				this.css(this.V, 'display', 'none');
				this.css(this.MD, 'display', 'block');
",4
"				this.timerVCanvas = new this.timer(0, videoCanvas);
			}
		},
		/*
",4
"			}
",4
"				this.css(this.CB['play'], 'display', 'none');
				this.css(this.CB['pauseCenter'], 'display', 'none');
				this.css(this.CB['pause'], 'display', 'block');
			} else {
				this.css(this.CB['play'], 'display', 'block');
",4
"				if (this.css(this.CB['errorText'], 'display') == 'none') {
					if (!this.adPlayerPlay) {
						this.css(this.CB['pauseCenter'], 'display', 'block');
					}

",4
"				this.css(this.CB['pause'], 'display', 'none');
			}
",4
"			åé¨å½æ°
			çå¬æ­æ¾ç»æ
		*/
		endedHandler: function() {
",4
"			if (this.adPlayerPlay) {
				this.adI++;
",4
"			}
			if ((this.ckplayerConfig['config']['mobileVolumeBarShow'] || !this.isMobile()) && this.css(this.CB['volume'], 'display') == 'block') {
",4
"					if (this.V.volume > 0) {
						this.css(this.CB['mute'], 'display', 'block');
						this.css(this.CB['escMute'], 'display', 'none');
",4
"					} else {
						this.css(this.CB['mute'], 'display', 'none');
						this.css(this.CB['escMute'], 'display', 'block');
",4
"			this.css(this.CB['timeButton'], 'left', parseInt(timeBOW) + 'px');
		},
",4
"		},
		/*
			åé¨å½æ°
			çå¬æ¯å¦æ¯ç¼å²ç¶æ
		*/
",4
"			}
			var thisTemp = this;
			var clearTimerBuffer = function() {
				if (thisTemp.timerBuffer != null) {
",4
"					thisTemp.timerBuffer = null;
				}
			};
			clearTimerBuffer();
",4
"				}
			};
			this.timerBuffer = new this.timer(200, bufferFun);
",4
"		},
",4
"		/*
			åé¨å½æ°
			åç¬è®¡ç®å è½½è¿åº¦
		*/
		changeLoad: function(loadTime) {
",4
"				if (this.timerError.runing) {
					this.timerError.stop();
				}
				this.timerError = null;
",4
"					thisTemp.prompt(); //æ·»å æç¤ºç¹
					setTimeout(function() {
",4
"					if (this.timerTime.runing) {
						this.timerTime.stop();
					}
					this.timerTime = null;
",4
"				}
				var timeFun = function() {
					if (thisTemp.V != null && !thisTemp.V.paused && thisTemp.showFace) {
						thisTemp.CB['timeText'].innerHTML = thisTemp.getNowDate();
					}
",4
"		*/
		loadTrack: function() {
			if (this.playerType == 'flashplayer' || this.vars['flashplayer'] == true) {
				return;
			}
",4
"					thisTemp.track = thisTemp.parseSrtSubtitles(data);
					thisTemp.trackIndex = 0;
",4
"				return;
			}
			if (this.trackIndex >= this.track.length) {
",4
"				var nowShow = this.nowTrackShow;
				if (nowShow['sn'] != nowTrack['sn']) {
					this.trackHide();
",4
"			for (var i = 0; i < this.trackElement.length; i++) {
				this.deleteElement(this.trackElement[i]);
			}
			this.trackElement = [];
",4
"		checkTrack: function() {
			var num = this.trackIndex;
			var arr = this.track;
			var i = 0;
",4
"		*/
		playOrPause: function() {
			if (!this.loaded) {
				return;
",4
"				return;
			}
			if (this.playerType == 'flashplayer') {
				this.V.playOrPause();
				return;
",4
"			}
			if (this.adPlayerPlay) {
",4
"				this.eliminateAd(); //æ¸é¤å¹¿å
				return;
			}
",4
"			try {
				if (this.V.currentSrc) {
",4
"			}
",4
"			if (this.playerType == 'flashplayer') {
				this.V.videoSeek(time);
				return;
",4
"				if (this.isUndefined(bg)) {
					bg = true;
				}
",4
"				if (this.isUndefined(button)) {
					button = true;
				}
			} catch(e) {}
",4
"				if (buLeft < 0) {
					buLeft = 0;
				}
",4
"		adEscMuteFunction: function() {
			if (!this.loaded) {
				return;
",4
"		fastBack: function() {
			if (!this.loaded) {
				return;
",4
"				return;
",4
"			æ¥å£å½æ°
			å¿«è¿
		*/
",4
"				this.V.fastNext();
				return;
",4
"		*/
		getCurrentSrc: function() {
			if (!this.loaded) {
",4
"			return this.V.currentSrc;
		},
		/*
			åç½®å½æ°
",4
"			reg = reg ? reg[0].replace('rotate(', '').replace('deg)', '') : '';
			if (reg == '') {
				reg = 0;
			} else {
				reg = parseInt(reg);
",4
"					reg = 0;
				} else {
					reg = n;
",4
"			y270 = n % 270;
			var ys = false;
",4
"			if (y90 == -0 && y180 == -90 && y270 == -0) {
				ys = true;
",4
"					this.css(this.V, 'transform', 'rotate(0deg)');
					this.css(this.V, 'transform', 'scale(' + nH / cdW + ',' + nW / cdH + ')' + tf);
				} else {
					this.css(this.V, 'transform', tf);
				}
",4
"				return;
			}
			if (this.playerType == 'flashplayer') {
",4
"				this.V.videoContrast(n);
",4
"				return;
			}
		},
		videoSaturation: function(n) {
			if (!this.loaded) {
",4
"			if (this.playerType == 'flashplayer') {
				this.V.videoZoom(n);
",4
"			}
",4
"			}
		},
",4
"				this.adIsPause = false;
				if (this.adPlayerPlay) {
",4
"					} else {
						this.V.play();
					}
				}
			}
",4
"				return;
			}
			if (this.playerType == 'flashplayer') {
",4
"				this.V.videoError(n);
				return;
			}
",4
"					obj = obj[arg[i]];
				} else {
					return;
",4
"			if (this.playerType == 'flashplayer') {
				this.V.custom(arguments);
				return;
",4
"			if (!this.loaded) {
",4
"				return null;
",4
"		*/
		newVideo: function(c) {
			if (this.playerType == 'flashplayer') {
				this.V.newVideo(c);
				return;
",4
"			æªå¾
",4
"			if (this.playerType == 'flashplayer') {
				try {
					this.V.screenshot(obj, save, name);
				} catch(error) {
					this.log(error);
",4
"				newCanvas.width = this.V.videoWidth;
",4
"				newCanvas.height = this.V.videoHeight;
				newCanvas.getContext('2d').drawImage(this.V, 0, 0, this.V.videoWidth, this.V.videoHeight);
",4
"		},
		/*
			æ¥å£å½æ°
",4
"			}
			if (this.isUndefined(h)) {
",4
"			if (this.html5Video) {
				var arr = this.playbackRateArr;
				n = parseInt(n);
				if (n < arr.length) {
",4
"		},
		/*
			åé¨å½æ°
			æ³¨åæ§å¶æ§å¶æ æ¾ç¤ºä¸éèå½æ°
		*/
",4
"				this.controlBarIsShow = true;
				this.controlBarHide(false);
			} else {
				this.controlBarIsShow = false;
				this.controlBarHide(true);
",4
"			this.playerType = 'flashplayer';
			//this.loaded=true;
		},
",4
"					if (vk == false) {
						vk = 0;
					}
					z += k + '=' + vk;
				}
",4
"			åç½®å½æ°
			å°varsæ ¼å¼åæflashè½æ¥åçå¯¹è±¡ãåç±getFlashVarså½æ°è½¬åæå­ç¬¦ä¸²æç±newVideoç´æ¥ä½¿ç¨
",4
"			}
			if (v['preview'] != null) {
				v['previewscale'] = v['preview']['scale'];
				v['preview'] = v['preview']['file'].join(',');
",4
"				quality: 'high',
",4
"				bgcolor: '#000'
			};
			for (var e in o) {
				w += e + '=""' + o[e] + '"" ';
				v += '<param name=""' + e + '"" value=""' + o[e] + '"" />';
",4
"				}
				var data = {
					duration: duration,
",4
"					paused: this.V.paused
",4
"		*/
		clickEvent: function(call) {
			if (call == 'none' || call == '' || call == null) {
",4
"			link = '',
",4
"						fun = 'thisTemp.' + callE + '(' + val + ')';
					}
					break;
",4
"
					}
",4
"				}
			}
			return {
				type: type,
",4
"		},
",4
"		/*
			åç½®å½æ°
			æ ¹æ®æå®çalign,valign,offsetX,offsetYè®¡ç®åæ 
",4
"				x = obj['offsetX'];
				break;
			case 'center':
				x = pw * 0.5 + obj['offsetX'];
",4
"				break;
			case 'right':
				x = pw + obj['offsetX'];
				break;
			}
",4
"			switch (obj['vAlign']) {
			case 'top':
				y = obj['offsetY'];
				break;
",4
"			åç½®å½æ°
",4
"			åæ­æ¾å¨çé¢æ·»å ä¸ä¸ªææ¬
		*/
		addElement: function(attribute) {
			var thisTemp = this;
",4
"			if (this.playerType == 'flashplayer') {
				return this.V.addElement(attribute);
			}
			var i = 0;
			var obj = {
",4
"				return '';
			}
",4
"			}

",4
"						}
						break;
					case 'text':
",4
"						textObj = {
							type: 'text',
							//è¯´ææ¯ææ¬
							text: '',
							//ææ¬åå®¹
",4
"							color: '0xFFFFFF',
							size: 14,
							font: this.fontFamily,
							leading: 0,
",4
"							clickEvent: ''
						};
						list[i] = this.standardization(textObj, list[i]);
",4
"						}
						break;
					default:
						break;
					}
",4
"			var objClickEvent = this.clickEvent(obj['clickEvent']);
			/*if(objClickEvent['type']=='link'){
				html = '<a href=""'+objClickEvent['link']+'"" target=""'+objClickEvent['target']+'"">' + html + '</a>';
",4
"			}*/
			eid.innerHTML = '<div class=""' + bgid + '""></div><div class=""' + bgid + '_c"">' + html + '</div>';
			if (objClickEvent['type'] == 'javaScript' || objClickEvent['type'] == 'actionScript') {
				var objClickHandler = function() {
					eval(objClickEvent['fun']);
",4
"					this.addListenerInside('click', clickHandler, this.getByElement(idArr[i]))
",4
"				}
				switch (list[i]['type']) {
				case 'image':
				case 'png':
				case 'jpg':
",4
"						marginTop: list[i]['marginTop'] + 'px',
						marginBottom: list[i]['marginBottom'] + 'px',
",4
"					});
",4
"					this.css(idArr[i] + '_image', {
						width: list[i]['width'] + 'px',
						height: list[i]['height'] + 'px',
						borderRadius: list[i]['radius'] + 'px'
",4
"					});
					break;
				case 'text':
					this.css(idArr[i] + '_text', {
",4
"						zIndex: '3',
						cursor: 'pointer'
					});
					this.css(idArr[i], {
						float: 'left',
",4
"						marginRight: list[i]['marginRight'] + 'px',
						marginTop: list[i]['marginTop'] + 'px',
						marginBottom: list[i]['marginBottom'] + 'px'
",4
"					});
",4
"			}
			this.css(bgid, {
				width: this.getByElement(bgid + '_c').offsetWidth + 'px',
",4
"			});
			this.css(eid, {
				width: this.getByElement(bgid).offsetWidth + 'px',
				height: this.getByElement(bgid).offsetHeight + 'px'
			});
",4
"				left: eidCoor['x'] + 'px',
				top: eidCoor['y'] + 'px'
",4
"			return eid;
		},
		/*
			åç½®å½æ°
			è·ååä»¶çå±æ§ï¼åæ¬x,y,width,height,alpha
",4
"				return this.V.getElement(element);
			}
			var ele = element;
",4
"			if (typeof(element) == 'string') {
				ele = this.getByElement(element);
			}
			var coor = this.getCoor(ele);
",4
"					for (var i = 0; i < arr.length; i++) {
						this.css(arr[i], 'display', show == true ? 'block': 'none');
					}
				}
			}
",4
"		*/
		calculationCoor: function(ele) {
			if (this.playerType == 'flashplayer') {
				return this.V.calculationCoor(ele);
			}
",4
"					if (this.isUndefined(position[i]) || position[i] == null || position[i] == 'null' || position[i] == '') {
						position[i] = null;
					} else {
						position[i] = parseFloat(position[i]);
",4
"					case 0:
						x = 0;
",4
"					switch (position[1]) {
",4
"						break;
					default:
						y = h + position[3];
",4
"		tween: function() {
			var Tween = {
",4
"					easeOut: function(t, b, c, d) {
						return c * t / d + b;
					},
",4
"					easeInOut: function(t, b, c, d) {
						return c * t / d + b;
					}
				},
				Quadratic: {
",4
"					},
					easeInOut: function(t, b, c, d) {
						if ((t /= d / 2) < 1) return c / 2 * t * t + b;
						return - c / 2 * ((--t) * (t - 2) - 1) + b;
					}
",4
"						return - c * ((t = t / d - 1) * t * t * t - 1) + b;
",4
"				Quintic: {
",4
"					easeInOut: function(t, b, c, d) {
						if (t == 0) return b;
						if (t == d) return b + c;
						if ((t /= d / 2) < 1) return c / 2 * Math.pow(2, 10 * (t - 1)) + b;
						return c / 2 * ( - Math.pow(2, -10 * --t) + 2) + b;
",4
"					easeInOut: function(t, b, c, d) {
						if ((t /= d / 2) < 1) return - c / 2 * (Math.sqrt(1 - t * t) - 1) + b;
						return c / 2 * (Math.sqrt(1 - (t -= 2) * t) + 1) + b;
					}
				},
",4
"							var s = p / 4;
						} else var s = p / (2 * Math.PI) * Math.asin(c / a);
						return - (a * Math.pow(2, 10 * (t -= 1)) * Math.sin((t * d - s) * (2 * Math.PI) / p)) + b;
					},
					easeOut: function(t, b, c, d, a, p) {
",4
"							var s = p / 4;
						} else var s = p / (2 * Math.PI) * Math.asin(c / a);
						return (a * Math.pow(2, -10 * t) * Math.sin((t * d - s) * (2 * Math.PI) / p) + c + b);
",4
"			parameter:String=éè¦æ¹åçå±æ§ï¼x,y,width,height,alpha,
			effect:String=ææåç§°,
",4
"				y: 0
			};
			if (this.isUndefined(tweenFun)) {
				return false;
			}
",4
"			//åå°è¯¥åä»¶ä»åä»¶æ°ç»éå é¤ï¼è®©å¶ä¸åè·éæ­æ¾å¨çå°ºå¯¸æ¹åèæ¹åä½ç½®
			var def = this.arrIndexOf(this.elementArr, obj['element'].className);
",4
"			var tweenObj = null;
			var start = obj['start'] == null ? '': obj['start'].toString();
			var end = obj['end'] == null ? '': obj['end'].toString();
			switch (obj['parameter']) {
			case 'x':
",4
"						b = parseInt(start) * w * 0.01;
					} else {
						b = parseInt(start);
					}
",4
"						c = parseInt(end) * w * 0.01 - b;
					} else if (end.substring(0, 1) == '-' || end.substring(0, 1) == '+') {
						if (typeof(obj['end']) == 'number') {
							c = parseInt(obj['end']) - b;
						} else {
",4
"					} else if (end.substring(0, 1) == '-' || end.substring(0, 1) == '+') {
						if (typeof(obj['end']) == 'number') {
							c = parseInt(obj['end']) - b;
						} else {
",4
"				} else {
",4
"			};
",4
"					css = {
						left: Math.ceil(tweenFun(t, b, c, d)) + 'px'
					};
					if (obj['static']) {
						eleCoor = thisTemp.calculationCoor(obj['element']);
",4
"
				} else {
					stopTween();
					try {
						var defX = this.arrIndexOf(this.elementTempArr, obj['element'].className);
",4
"						if (defX > -1) {
							this.elementTempArr.splice(defX, 1);
						}
					} catch(event) {}
",4
"				}
",4
"			};
",4
"						if (defY > -1) {
							this.elementTempArr.splice(defY, 1);
						}
					} catch(event) {}
					thisTemp.elementArr.push(obj['element'].className);
",4
"					callBack();
				}
			};
			var tweenAlpha = function() {
				if (t < d) {
",4
"			return animateId;
		},
		/*
",4
"				this.V.animateResume(this.isUndefined(id) ? '': id);
				return;
			}
			var arr = [];
			if (id != '' && !this.isUndefined(id) && id != 'pause') {
",4
"					this.animateArray[index].start();
",4
"			æ¥å£å½æ°
			æåè¿è¡animate
		*/
		animatePause: function(id) {
",4
"			for (var i = 0; i < arr.length; i++) {
",4
"				var index = this.arrIndexOf(this.animateElementArray, arr[i]);
				if (index > -1) {
",4
"		*/
		deleteAnimate: function(id) {
			if (this.playerType == 'flashplayer' && this.V) {
				try {
					this.V.deleteAnimate(id);
",4
"				} catch(event) {
					this.log(event);
				}
",4
"			if (index > -1) {
				this.animateArray[index].callBackFunction();
				this.animateArray.splice(index, 1);
",4
"			if (def > -1) {
				this.elementArr.splice(def, 1);
			}
			try {
",4
"				if (def > -1) {
					this.elementTempArr.splice(def, 1);
",4
"			this.deleteChild(ele);
		},
		/*
			--------------------------------------------------------------
",4
"			å±ç¨å½æ°é¨å
			ä»¥ä¸å½æ°å¹¶éåªè½å¨æ¬ç¨åºä¸­ä½¿ç¨ï¼ä¹å¯ä»¥å¨é¡µé¢å¶å®é¡¹ç®ä¸­ä½¿ç¨
",4
"					obj = obj.substr(1, obj.length);
				}
				if (parent.getElementsByClassName) {
					res = parent.getElementsByClassName(obj);
",4
"				if (res.length > 0) {
					return res[0];
				} else {
",4
"			var i = 0;
			var k = '';
			if (typeof(elem) == 'object') { //å¯¹è±¡ææ°ç»
				if (!this.isUndefined(typeof(elem.length))) { //è¯´ææ¯æ°ç»
					for (i = 0; i < elem.length; i++) {
",4
"				for (k in attribute) {
					if (!this.isUndefined(attribute[k])) {
",4
"				if (obj.currentStyle) {
					return obj.currentStyle[attr];
				} else {
					return getComputedStyle(obj, false)[attr];
",4
"				this.log(event);
			}
			return false;
",4
"				if (this.playerType == 'flashplayer') {
",4
"				var have = false;
",4
"				for (var i = 0; i < this.listenerJsArr.length; i++) {
					var arr = this.listenerJsArr[i];
",4
"				if (!have) {
					this.listenerJsArr.push([name, funName]);
				}
			}
		},
",4
"					if (typeof(funName) == 'function') {
						ff = this.getParameterNames(funName);
					}
					this.V.removeListener(name, ff);
",4
"		*/
		addListenerInside: function(e, f, d, t) {
			if (this.isUndefined(t)) {
",4
"				t = false;
			}
			var o = this.V;
			if (!this.isUndefined(d)) {
",4
"			}
",4
"					this.addNum--;
					o.removeEventListener(e, f, t);
				} catch(e) {}
",4
"				o['on' + e] = null;
",4
"			}
",4
"			};
			if (this.vars['playerID']) {
				obj['playerID'] = this.vars['playerID'];
			}
			for (var i = 0; i < list.length; i++) {
",4
"							arr[1]();
							break;
						}
",4
"					}
				}
",4
"			}
		},
		/*
			å±ç¨å½æ°
			è·åå½æ°åç§°ï¼å¦ function ckplayer(){} var fun=ckplayerï¼ågetParameterNames(fun)=ckplayer
",4
"		*/
		getParameterNames: function(fn) {
			if (typeof(fn) !== 'function') {
				return false;
			}
",4
"			tMinutes = '',
			tSeconds = '',
			tSeconds = (seconds < 10) ? '0' + seconds: seconds + '',
			tMinutes = (minutes < 10) ? '0' + minutes: minutes + '',
",4
"		/*
			å±ç¨å½æ°
			æ ¼å¼åæ¶åç§
",4
"			å±ç¨å½æ°
			è·åä¸ä¸ªéæºå­ç¬¦
			lenï¼éæºå­ç¬¦é¿åº¦
		*/
",4
"			len = len || 16;
			var chars = 'abcdefghijklmnopqrstuvwxyz';
			var maxPos = chars.length;
			var val = '';
",4
"			ç¨æ¥ä¸ºajaxæä¾æ¯æ
		*/
		createXHR: function() {
",4
"			} else {
				this.eject(this.errorList[8]);
",4
"			}
		},
		/*
			å±ç¨å½æ°
			ajaxè°ç¨
",4
"				dataType: 'json',
				//è¯·æ±çæ°æ®ç±»å
				charset: 'utf-8',
				async: false,
				//trueè¡¨ç¤ºå¼æ­¥ï¼falseè¡¨ç¤ºåæ­¥
",4
"							obj.success(xhr.responseText); //åè°ä¼ éåæ°
						}
",4
"					}
				};
",4
"							obj.url += '&' + obj.data;
						}
					}
				}
				if (obj.async === true) { //trueè¡¨ç¤ºå¼æ­¥ï¼falseè¡¨ç¤ºåæ­¥
",4
"				var callbackName = 'callback' + new Date().getTime();
				var params = this.formatParams(obj.data) + '&callback=' + callbackName; //ææ¶é´æ³æ¼æ¥å­ç¬¦ä¸²
				callback = obj.success;
				//æ¼æ¥å¥½src
				oScript.src = obj.url.split('?') + '?' + params;
",4
"				//æå¥scriptæ ç­¾
",4
"				};
			}
",4
"		},
		/*
			å±ç¨å½æ°
			æé¤IE6-9
		*/
",4
"			if (navigator.userAgent.indexOf('MSIE') > 0) {
				try {
					var swf = new ActiveXObject('ShockwaveFlash.ShockwaveFlash');
					return true;
",4
"				if (!oggTest) {
					var h264Test;
					try {
						h264Test = vidTest.canPlayType('video/mp4; codecs=""avc1.42E01E, mp4a.40.2""');
					} catch(error) {
",4
"					x = y;
				} else {
					var z = y.getElementsByTagName(r)[0];
					if (z) {
",4
"		/*
			å±ç¨å½æ°
			å¯¹è±¡è½¬å°åå­ç¬¦ä¸²
",4
"		*/
		formatParams: function(data) {
			var arr = [];
			for (var i in data) {
				arr.push(encodeURIComponent(i) + '=' + encodeURIComponent(data[i]));
",4
"			var temp = [];
			for (var i = 0; i < arr.length; i++) {
				for (var j = 0; j < arr.length - i; j++) {
					if (!this.isUndefined(arr[j + 1]) && arr[j][3] < arr[j + 1][3]) {
						temp = arr[j + 1];
",4
"		isContains: function(str, key) {
			return str.indexOf(key) > -1;
		},
",4
"		/*
			åç½®å½æ°
			ç»å°åæ·»å éæºæ°
		*/
		getNewUrl: function(url) {
",4
"				};
",4
"			}
			return {
				x: eve.clientX + (document.documentElement.scrollLeft || this.body.scrollLeft) - this.pdCoor['x'],
",4
"		getXY: function(obj) {
			var parObj = obj;
			var left = obj.offsetLeft;
			var top = obj.offsetTop;
",4
"		removeChild: function() {
			if (this.playerType == 'html5video') {
				//å é¤è®¡æ¶å¨
				var i = 0;
				var timerArr = [this.timerError, this.timerFull, this.timerTime, this.timerBuffer, this.timerClick, this.timerLoading, this.timerCBar, this.timerVCanvas];
",4
"			ç»ç©å½¢
		*/
		canvasFillRect: function(name, path) {
",4
"		},
		/*
			åç½®å½æ°
		 	æ ¹æ®å®¹å¨çå®½é«,åé¨èç¹çå®½é«è®¡ç®åºåé¨èç¹çå®½é«ååæ 
",4
"		parseSrtSubtitles: function(srt) {
			var subtitles = [];
",4
"			var i = 0;
",4
"				} else {
					if (arr.length > 0) {
						textSubtitles.push(arr);
",4
"			}
			for (i = 0; i < textSubtitles.length; ++i) {
				var textSubtitle = textSubtitles[i];
",4
"					var subtitle = {
						sn: sn,
						startTime: startTime,
						endTime: endTime,
",4
"				if (thisTemp.numberTotal != null && thisTemp.number >= thisTemp.numberTotal) {
					thisTemp.stop();
",4
"					thisTemp.runing = false;
					window.clearInterval(thisTemp.timeObj);
					thisTemp.timeObj = null;
",4
"				this.numberTotal = number;
			}
			this.start();
",4
"			}
			return h;
",4
"		},
",4
"		}
	};
	window.ckplayer = ckplayer;
})();
",4
"//
",4
"
#include ""mask_detector.h"" // NOLINT

",4
"int main(int argc, char* argv[]) {
  if (argc < 3 || argc > 4) {
    std::cout << ""Usage:""
              << ""./mask_detector ./models/ ./images/test.png""
              << std::endl;
",4
"
  // Load image
",4
"  // Prediction result
  std::vector<FaceResult> results;
  // Stage1: Face detection
  detector.Predict(img, &results, det_shrink);
  // Stage2: Mask wearing classification
",4
"  for (const FaceResult& item : results) {
    printf(""{left=%d, right=%d, top=%d, bottom=%d},""
           "" class_id=%d, confidence=%.5f\n"",
           item.rect[0],
           item.rect[1],
",4
"           item.class_id,
           item.confidence);
  }
",4
"
",4
"  cv::Mat roi_rect;
  // Classification result: confidence
  float confidence;
  // Classification result : class id
  int class_id;
",4
"
class FaceDetector {
 public:
",4
"                      const std::vector<float>& scale,
                      bool use_gpu = false) :
  mean_(mean),
  scale_(scale) {
",4
"    LoadModel(model_dir, use_gpu, &predictor_);
  }
",4
"  void Predict(std::vector<FaceResult>* faces);

",4
" private:
",4
"// Licensed under the Apache License, Version 2.0 (the ""License"");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
",4
"// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an ""AS IS"" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
",4
"      int base = h * width + w;
      input_buffer[base + 0 * stride] =
          (im.at<cv::Vec3f>(h, w)[0] - mean[0]) * scale[0];
",4
"  config.SwitchUseFeedFetchOps(false);
  config.SwitchSpecifyInputNames(true);
  // Memory optimization
",4
"  *predictor = std::move(CreatePaddlePredictor(config));
",4
"    cv::Point origin;
    origin.x = roi.x;
    origin.y = roi.y;

",4
"    // Configure text background
    cv::Rect text_back = cv::Rect(results[i].rect[0],
    results[i].rect[2] - text_size.height,
    text_size.width,
",4
"                cv::Scalar(0, 0, 0),
                thickness);
  }
}

",4
"  int rh = input_shape_[2];
  int rw = input_shape_[3];
  int total_size = output_data_.size() / 6;
  for (int j = 0; j < total_size; ++j) {
    // Class id
",4
"    int ymax = (output_data_[5 + j * 6] * rh) / shrink;
    int wd = xmax - xmin;
    int hd = ymax - ymin;
",4
"    if (score > threshold_) {
      auto roi = cv::Rect(xmin, ymin, wd, hd) &
",4
"      result_item.rect = {xmin, xmax, ymin, ymax};
      result_item.roi_rect = roi_ref;
      result->push_back(result_item);
",4
"  std::vector<int> output_shape = out_tensor->shape();
  // Calculate output length
  int output_size = 1;
  for (int j = 0; j < output_shape.size(); ++j) {
",4
"  input_shape_ = {
      batch_size,
      EVAL_CROP_SIZE_[0],
",4
"    }
    im.convertTo(im, CV_32FC3, 1.0 / 256.0);
    rc = im.channels();
    rw = im.cols;
",4
"  float* data = output_data_.data();
  int batch_size = faces->size();
",4
"  auto in_tensor = predictor_->GetInputTensor(input_names[0]);
  in_tensor->Reshape(input_shape_);
  in_tensor->copy_from_cpu(input_data_.data());
",4
"module.processor.save_inference_model(""./pyramidbox_lite_server_mask"")
print(""pyramidbox_lite_server_mask module export done!"")

# Load mask detector (mobile version) module from PaddleHub
",4
"
def parse_args():
    parser = argparse.ArgumentParser('mask detection.')
    parser.add_argument(
",4
"        '--models_dir', type=str, default='', help='path of models.')
    parser.add_argument(
        '--img_paths', type=str, default='', help='path of images')
    parser.add_argument(
        '--video_path', type=str, default='', help='path of video.')
",4
"        self.rect_info = rect_info
",4
"        config.enable_use_gpu(100, 0)
        config.switch_ir_optim(True)
",4
"        self.scale = np.array(scale).reshape((3, 1, 1))
",4
"    def Preprocess(self, faces):
        h, w = self.EVAL_SIZE[1], self.EVAL_SIZE[0]
",4
"
",4
"            input_data = np.concatenate(inputs)
            im_tensor = fluid.core.PaddleTensor(
",4
"                input_data.copy().astype('float32'))
            output_data = self.predictor.run([im_tensor])[0]
            output_data = output_data.as_ndarray()
",4
"            self.Postprocess(output_data, faces)


class FaceDetector:
    def __init__(self, model_dir, mean, scale, use_gpu=False, threshold=0.7):
",4
"        self.scale = np.array(scale).reshape((3, 1, 1))
        self.threshold = threshold
        self.predictor = LoadModel(model_dir, use_gpu)
",4
"        scale=[0.007843, 0.007843, 0.007843],
        use_gpu=args.use_gpu,
",4
"        scale=[1.0, 1.0, 1.0],
",4
"            names.append(name)
",4
"    path = './result'
    isExists = os.path.exists(path)
",4
"    if not isExists:
        os.makedirs(path)
    fps = 30
    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))
",4
"        classifier.Predict(det_out)
        end_pre = time.time()
        im = VisualizeResult(frame, det_out)
        writer.write(im)
",4
"    writer.release()


if __name__ == ""__main__"":
    args = parse_args()
",4
"#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"# Export inference model for deployment
module.processor.save_inference_model(""./pyramidbox_lite_server_mask"")
print(""pyramidbox_lite_server_mask module export done!"")
",4
"#coding:utf-8
",4
"#   Copyright (c) 2019 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
",4
"#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
",4
"
",4
"        dataset=dataset,
        vocab_path=module.get_vocab_path(),
        max_seq_len=args.max_seq_len,
        sp_model_path=module.get_spm_path(),
        word_dict_path=module.get_word_dict_path())
",4
"    # Must feed all the tensor of ERNIE's module need
",4
"    def forward(self, input_ids, position_ids, segment_ids, input_mask):
        result = self.transformer(input_ids, position_ids, segment_ids,
",4
"                loss_sum += avg_loss.numpy() * labels.shape[0]
                label_num, infer_num, correct_num = chunk_eval(
                    labels, ret_infers.numpy(), seq_len, dataset.num_labels, 1)
                cnt += labels.shape[0]

",4
"                total_infer += infer_num
",4
"

if __name__ == ""__main__"":
",4
"# You may obtain a copy of the License at
#
",4
"    # Load Paddlehub ERNIE Tiny pretrained model
    module = hub.Module(name=""ernie_tiny"")
    inputs, outputs, program = module.context(
        trainable=True, max_seq_len=args.max_seq_len)

",4
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# import pychecker.checker
import sys
",5
"
# Initialise basics and read command line and settings.
",5
"
import os
import shutil
import sys
",5
"from pysollib.settings import PACKAGE, VERSION
",5
"    shutil.copytree('html-src/images', 'html-src/html/images')
    try:
        shutil.rmtree('data/html')
    except OSError:
        pass
",5
"
",5
"# Use Freecell Solver, if it is installed.
# http://fc-solve.berlios.de/
SOLVER_LIB_PATH = ""/usr/local/lib/libfreecell-solver.0.dylib""
SOLVER = [""/usr/local/bin/fc-solve""]
if not os.path.exists(SOLVER_LIB_PATH):
",5
"    CFBundleVersion='%s' % VERSION,
    CFBundleShortVersionString='%s' % VERSION,
    NSHumanReadableCopyright=""Copyright (C) 1998-2003 Markus F.X.J. Oberhumer"",
",5
"               iconfile=ICON_FILE,
               resources=RESOURCES,
               frameworks=FRAMEWORKS,
               excludes=['pysollib.pysolgtk']
",5
"#
top = os.getcwd()
# Modify the fc-solve binary with install_name_tool to use the dependent
",5
"# libfreecell-solver dynamic library in the app bundle.
if SOLVER and ""py2app"" in sys.argv:
    os.chdir('dist/%s.app/Contents/Resources' % PACKAGE)
    call(""install_name_tool -change \
",5
"         /usr/local/lib/libfreecell-solver.0.dylib \
         @executable_path/../Frameworks/libfreecell-solver.0.dylib fc-solve"",
         shell=True
",5
"import os

from pysollib.settings import PACKAGE_URL
from pysollib.settings import VERSION
",5
"    data_dir = 'share/PySolFC'
    locale_dir = 'share/locale'
else:
    data_dir = 'data'
    locale_dir = 'locale'
",5
"
",5
"    if s.startswith('graft data/cardset-'):
        ddirs.append(s[11:].strip())
",5
"    data_files += get_data_files(os.path.join('data', d),
                                 os.path.join(data_dir, d))

data_files += get_data_files('locale', locale_dir)

",5
"
",5
"    'url': PACKAGE_URL,
    'author': 'Skomoroh',
    'author_email': 'skomoroh@gmail.com',
",5
"                 'pysollib.kivy',
                 'pysollib.game',
",5
"                 'pysollib.games.mahjongg'],
    'data_files': data_files,
    }
",5
"                      'icon_resources': [(1, 'data/pysol.ico')], }]
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"# ************************************************************************
",5
"        obj = self.app.sample_manager.getByName(name)
        if not obj or not obj.absname:
            return 0
        try:
            if self._playSample(obj.absname, priority, loop, volume):
",5
"        self.sample_loop = 0

    def stopSamplesLoop(self):
",5
"    #

    def _connectServer(self):
",5
"class PysolSoundServerModuleClient(AbstractAudioClient):

    CAN_PLAY_SOUND = True
    CAN_PLAY_MUSIC = True

",5
"        return 1
",5
"
    def _stopSamples(self):
        self.cmd(""stopwav"")

    def _stopSamplesLoop(self):
",5
"    def updateSettings(self):
        if self.audiodev is None or not self.app:
            return
        s, m = 0, 0
",5
"
class KivyAudioClient(AbstractAudioClient):

",5
"    CAN_PLAY_MUSIC = False
",5
"
        if self.sound:
",5
"                if self.sound:
",5
"    def _endSample(self, a):
        print('Sound: stopped, %s' % self.sound)
        self.sound = None
        self._condPlaySample()

",5
"# ************************************************************************
# * Win32 winsound audio
# ************************************************************************
",5
"        self.pipe = pipe
        # import ossaudiodev
        # self.audiodev = ossaudiodev.open('w')
        self.sound_priority = -1
",5
"        self._busy = False

    def mainLoop(self):
        while True:
            s = os.read(self.pipe, 256)
",5
"                continue
",5
"                th = Thread(target=self.playLoop, args=(filename,))
",5
"        try:
",5
"                traceback.print_exc()
            self._busy = False
            return 0


",5
"
# ************************************************************************
",5
"        self.mixer = pygame.mixer
        self.time = pygame.time
        self.music = self.mixer.music
",5
"
",5
"    def _playSample(self, filename, priority, loop, volume):
        # print '_playSample:', filename, priority, loop, volume
        if self.sound_channel and self.sound_channel.get_busy():
            if self.sound_priority >= priority:
",5
"                self.sound.stop()
        vol = self.app.opt.sound_sample_volume/128.0
        try:
            self.sound = self.mixer.Sound(filename)
            self.sound.set_volume(vol)
",5
"            pass
        self.sound_priority = priority
        return 1

",5
"            return
",5
"                    while self.music and self.music.get_busy():
                        self._wait(200)
",5
"                    self._wait(300)
                except Exception:
                    # if traceback: traceback.print_exc()
                    self._wait(1000)

",5
"    def _wait(self, s):
        # sometime time or time.wait is None (threading)
",5
"        if self.time and self.time.wait:
            self.time.wait(s)

    def playContinuousMusic(self, music_list):
        # print 'playContinuousMusic'
",5
"                self.music.stop()
                self.music = None
",5
"        else:
",5
"        else:
            t = gettext.translation(
",5
"
    It supports all entity names required by the XHTML 1.0 Recommendation.
    It also defines handlers for all HTML 2.0 and many HTML 3.0 and 3.2
",5
"    elements.

    """"""

",5
"        self.savedata = None
        self.isindex = 0
        self.title = None
        self.base = None
        self.anchor = None
",5
"    # ------ Methods used internally; some may be overridden

    # --- Formatter interface, taking care of 'savedata' mode;
    # shouldn't need to be overridden

",5
"
    def anchor_bgn(self, href, name, type):
        """"""This method is called at the start of an anchor region.

",5
"        The arguments correspond to the attributes of the <A> tag with
        the same names.  The default implementation maintains a list of
        hyperlinks (defined by the HREF attribute for <A> tags) within
",5
"    def handle_image(self, src, alt, *args):
        """"""This method is called to handle images.

        The default implementation simply passes the alt value to the
        handle_data() method.
",5
"
    def start_html(self, attrs): pass

    def end_html(self): pass
",5
"
    def do_base(self, attrs):
",5
"        self.formatter.push_font(('h1', 0, 1, 0))

",5
"    def start_h2(self, attrs):
        self.formatter.end_paragraph(1)
        self.formatter.push_font(('h2', 0, 1, 0))

",5
"    def end_h4(self):
        self.formatter.end_paragraph(1)
",5
"
    def start_h6(self, attrs):
        self.formatter.end_paragraph(1)
        self.formatter.push_font(('h6', 0, 1, 0))

",5
"    def do_p(self, attrs):
        self.formatter.end_paragraph(1)

    def start_pre(self, attrs):
        self.formatter.end_paragraph(1)
",5
"        self.list_stack.append(['ul', '*', 0])

    def end_ul(self):
",5
"            if a == 'type':
",5
"        self.formatter.pop_margin()
",5
"    def start_em(self, attrs): self.start_i(attrs)

    def end_em(self): self.end_i()

    def start_kbd(self, attrs): self.start_tt(attrs)
",5
"    def start_samp(self, attrs): self.start_tt(attrs)

    def end_samp(self): self.end_tt()

",5
"    def start_strong(self, attrs): self.start_b(attrs)

",5
"    def end_strong(self): self.end_b()
",5
"
    def start_tt(self, attrs):
",5
"        self.formatter.push_font((AS_IS, AS_IS, AS_IS, 1))
",5
"            value = value.strip()
            if attrname == 'href':
",5
"                href = value
            if attrname == 'name':
                name = value
            if attrname == 'type':
                type = value.lower()
",5
"
    # --- Horizontal Rule

    def do_hr(self, attrs):
",5
"                align = value
            if attrname == 'alt':
                alt = value
            if attrname == 'ismap':
                ismap = value
",5
"            sys.exit(1)

    data = f.read()

    if f is not sys.stdin:
",5
"
    if silent:
        f = formatter.NullFormatter()
    else:
        f = formatter.AbstractFormatter(formatter.DumbWriter())
",5
"
if __name__ == '__main__':
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"autodrop = boolean
",5
"gameperfect = boolean
deal = boolean
gamelost = boolean
",5
"flip = boolean
undo = boolean
gamefinished = boolean
",5
"autopilotlost = boolean
turnwaste = boolean
gamewon = boolean
",5
"small = list
",5
"fixed = list
",5
"[timeouts]
highlight_samerank = float(0.2, 9.9)
raise_card = float(0.2, 9.9)
demo = float(0.2, 9.9)
highlight_cards = float(0.2, 9.9)
",5
"[cardsets]
0 = string_list(min=2, max=2)
1 = string_list(min=2, max=2)
2 = string_list(min=2, max=2)
",5
"        ('mahjongg_show_removed', 'bool'),
",5
"        ('shisen_show_hint', 'bool'),
        ('shisen_show_matching', 'bool'),
",5
"        ('animations', 'int'),
        ('redeal_animation', 'bool'),
",5
"        ('compact_stacks', 'bool'),
        ('shadow', 'bool'),
        ('shade', 'bool'),
",5
"        ('toolbar_relief', 'str'),
        ('toolbar_compound', 'str'),
",5
"        ('game_holded', 'int'),
        ('wm_maximized', 'bool'),
",5
"        self.update_player_stats = True
        self.autofaceup = True
        self.autodrop = False
",5
"            self.mahjongg_create_solvable = 1  # 0 - none, 1 - easy, 2 - hard
        self.shisen_show_hint = True
        self.shisen_show_matching = False
        self.animations = 3             # default to Medium
        self.redeal_animation = True
",5
"        if TOOLKIT == 'kivy':
            self.redeal_animation = False
            self.win_animation = False
",5
"            'gamefinished': False,
            'gamelost': False,
",5
"            'gameperfect': False,
            'gamewon': False,
            }
",5
"            ""default"": None,
            # ""default"": (""helvetica"", 12),
",5
"            ""sans"": (""times"",     12),  # for html
            ""fixed"": (""courier"",   12),  # for html & log
",5
"            'text':         '#ffffff',
",5
"        self.favorite_gameid = []
        if TOOLKIT == 'kivy':
            self.favorite_gameid = [2, 7, 8, 19, 140, 116, 152, 176, 181,
                                    194, 207, 706, 721, 756, 903, 5034,
",5
"            'looking-glass',
            'one-big-family',
            'rin-tin-tin',
            'slick-rock',
            'the-last-mohican',
",5
"            self.fonts[""fixed""] = (""courier new"", 10)
",5
"            CSI.TYPE_MUGHAL_GANJIFA: (""Mughal Ganjifa"", """"),
            # CSI.TYPE_NAVAGRAHA_GANJIFA: (""Navagraha Ganjifa"", """"),
",5
"            CSI.TYPE_NAVAGRAHA_GANJIFA: (""Dashavatara Ganjifa"", """"),
            CSI.TYPE_DASHAVATARA_GANJIFA: (""Dashavatara Ganjifa"", """"),
            CSI.TYPE_TRUMP_ONLY: (""Matrix"", """"),
        }

",5
"        # colors
        config['colors'] = self.colors
",5
"            config = configobj.ConfigObj(configspec=configspec,
                                         encoding=self._config_encoding)
",5
"
        # add initial comment
        if not os.path.exists(filename):
            config.initial_comment = ['-*- coding: %s -*-' %
                                      self._config_encoding]
",5
"                    continue
                for key, value in data.items():
                    if value is False:
                        print_err('config file: validation error: '
                                  'section: ""%s"", key: ""%s""' % (section, key))
",5
"        recent_gameid = self._getOption('general', 'recent_gameid', 'list')
",5
"                self.toolbar_vars[key] = (key in visible_buttons)

        myGettext.language = self.language

",5
"        # solver
        solver_presets = self._getOption('general', 'solver_presets', 'list')
        if solver_presets is not None:
",5
"                self.sound_samples[key] = val

        # fonts
        for key in self.fonts:
",5
"            if val is not None:
",5
"                try:
",5
"                       ('preserve_aspect_ratio', 'bool')):
            val = self._getOption('cardsets', key, t)
            if val is not None:
                setattr(self, key, val)

",5
"#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
",5
"# *
# * The whole hint system is exclusively used by Game.getHints().
",5
"    # level == 1: show hint and display score value (key `Ctrl-H')
    # level == 2: demo
",5
"    def __init__(self, game, level):
        pass
",5
"    # Subclass responsibility.
    #
    # Returns a list of ""atomic hints"" - an atomic hint is a 7-tuple
",5
"    # (score, pos, ncards, from_stack, to_stack, text_color, forced_move).
    #
    #    if ncards == 0: deal cards
",5
"    #    elif from_stack == to_stack: flip card
    #    else: move cards from from_stack to to_stack
    #
    #    score, pos and text_color are only for debugging.
    #    A forced_move is the next move that must be taken after this move
",5
"    #    in order to avoid endless loops during demo play.
    #
    # Deal and flip may only happen if self.level >= 2 (i.e. demo).
    #
    # See Game.showHint() for more information.
",5
"    def getHints(self, taken_hint=None):
        return []
",5
"        if self.level == 0:
            self.score_flatten_value = 10000
        # temporaries within getHints()
",5
"        self.reset()
",5
"    # stack cloning
    #

",5
"        for s in self.__clones:
            s.__class__ = self.AClonedStack     # restore orignal class
            destruct(s)
        self.__clones = []

",5
"                    self.score_flatten_value
        if text_color is None:
            text_color = self.BLACK
        assert forced_move is None or len(forced_move) == 7
",5
"    #   - clean up and return hints sorted by score
    #

    # Default scores for flip and deal moves.
    SCORE_FLIP = 100000         # 0..100000
",5
"                if r.canFlipCard():
                    self.addHint(self.SCORE_FLIP, 1, r, r)
",5
"                        return self._returnHints()
        # 3) ask subclass to do something useful
",5
"    # utility shallMovePile()
    #

    # we move the pile if it is accepted by the target stack
",5
"    def _defaultShallMovePile(self, from_stack, to_stack, pile, rpile):
",5
"        if from_stack is to_stack or not \
                to_stack.acceptsCards(from_stack, pile):
            return 0
        return 1

",5
"        if len(rpile) == 0:
            return 1
        # now check for loops
        rr = self.ClonedStack(from_stack, stackcards=rpile)
",5
"    # other utility methods
    #
",5
"    # The DefaultHint is optimized for Klondike type games
    # and also deals quite ok with other simple variants.
    #
    # But it completely lacks any specific strategy about game
",5
"
    # Basic bonus for moving a card.
",5
"
    def _getMoveCardBonus(self, r, t, pile, rpile):
",5
"        assert pile
        bonus = 0
        if rpile:
            rr = self.ClonedStack(r, stackcards=rpile)
",5
"            # simple heuristics - prefer low-rank cards in rpile
",5
"
    BONUS_FLIP_CARD = 1500        # 0..9000

    def _getFlipSpecialBonus(self, r, t, pile, rpile):
",5
"        # 1) check Tableau piles
        self.step010(game.sg.dropstacks, game.s.rows)

        # 2) try if we can move part of a pile within the RowStacks
",5
"        if not self.hints and self.level >= 1:
            self.step030(game.s.foundations, game.s.rows, game.sg.dropstacks)

        # 4) try if we can move a card from a RowStack to a ReserveStack
        if not self.hints or self.level == 0:
",5
"
    # 1) check Tableau piles

",5
"                self.addHint(score, ncards, r, t, color)
                if score >= 90000 and self.level >= 1:
",5
"                    break
",5
"            # 1b) try if we can move cards to one of the RowStacks
            for pile in self.step010b_getPiles(r):
",5
"        return (stack.getPile(), )

    def step010_movePile(self, r, pile, rows):
        lp = len(pile)
",5
"        lr = len(r.cards)
",5
"                    empty_row_seen = 1
",5
"
    # 2) try if we can move part of a pile within the RowStacks
    #    so that we can drop a card afterwards
    #    score: 40000 .. 59999
",5
"                for c in pile:
                    rr = self.ClonedStack(r, stackcards=[c])
                    stack, ncards = rr.canDropCards(foundations)
",5
"                    i += 1
                # now try to make a move so that the drop-card will get free
                for di in drop_info:
",5
"                    c = di[0]
                    sub_pile = pile[di[3]+1:]
                    # print ""trying drop move"", c, pile, sub_pile
                    # assert r.canMoveCards(sub_pile)
                    if not r.canMoveCards(sub_pile):
",5
"                        score = 40000
                        score += 1000 + (self.K - r.getCard().rank)
                        # force the drop (to avoid loops)
                        force = (999999, 0, di[2], r, di[1], self.BLUE, None)
",5
"            card = r.getCard()
            if not card or not r.canMoveCards([card]):
",5
"            for t in reservestacks:
",5
"                score, color = self._getMovePileScore(
                    score, None, r, t, pile, rpile)
                self.addHint(score, len(pile), r, t, color)
                break
",5
"            return
",5
"        piles = []
        while p:
            piles.append(p)
            p = p[1:]       # note: we need a fresh shallow copy
",5
"        return piles


class Yukon_Hint(YukonType_Hint):
    BONUS_FLIP_CARD = 9000
",5
"    #        for Russian Solitaire
    def _getMovePileScore(self, score, color, r, t, pile, rpile):
        s, color = YukonType_Hint._getMovePileScore(
            self, score, color, r, t, pile, rpile)
        bonus = s - score
",5
"        # for a card in stack t.
        tpile = t.getPile()
",5
"                        bonus = (d * 1000) + bonus % 100
                        break
",5
"            self.base_rank = game_type['base_rank']
",5
"        else:
            self.base_rank = game.s.foundations[0].cap.base_rank
        # print 'game_type:', game_type
",5
"
    def card2str1_(self, rank, suit):
        # row and reserves
",5
"        return self._card2str_format('%(R)s%(S)s', rank, suit)
",5
"            else:
",5
"                for f in self.game.s.foundations:
                    if f.acceptsCards(src, cards):
                        dest = f
",5
"            print(command)
        kw = {'shell': True,
              'stdin': subprocess.PIPE,
              'stdout': subprocess.PIPE,
              'stderr': subprocess.PIPE}
",5
"        if os.name != 'nt':
            kw['close_fds'] = True
        p = subprocess.Popen(command, **kw)
        bytes_board = six.binary_type(board, 'utf-8')
",5
"        pout, perr = p.communicate(bytes_board)
        if p.returncode in (127, 1):
            # Linux and Windows return codes for ""command not found"" error
            raise RuntimeError('Solver exited with {}'.format(p.returncode))
        return BytesIO(pout), BytesIO(perr)
",5
"        return

    def _addPrefixLine(self, prefix, b):
        if b:
            self._addBoardLine(prefix + b)
",5
"        s_game.random = constructRandom('Custom')
",5
"        s_game.newGame(
            shuffle=True,
            random=constructRandom('Custom'),
",5
"            dealer=lambda: solver.importFileHelper(fh, s_game))
        s_game.random = constructRandom('Custom')

",5
"        CARD_RE = r'(?:' + RANKS_RE + SUITS_RE + ')'
",5
"                raise PySolHintLayoutImportError(
                    ""Duplicate cards in input"",
                    [solver.card2str1_(rank, suit)],
                    line_num
",5
"                try:
                    return s.decode(encoding)
                except UnicodeDecodeError:
                    continue
            return s.decode(""latin-1"")  # will always work
",5
"        for line_p in mytext.splitlines():
            line_num += 1
            line = line_p.rstrip('\r\n')
",5
"                        r'(' + SUITS_RE + r')-([' + RANKS0_S + r'])', m,
                        ""Invalid Foundations line""):
                    for foundat in game.foundations:
                        suit = foundat.cap.suit
",5
"                                   ""Invalid column text""):
                put_str(game.rows[stack_idx], str_)
",5
"        for s in game.s.foundations:
            if s.cards:
                b += ' ' + self.card2str2(
                    s.cards[0 if is_simple_simon else -1])
        self._addPrefixLine('Founds:', b)
",5
"                FCS_VERSION = (int(m.group(1)), int(m.group(2)),
                               int(m.group(3)))
            else:
                FCS_VERSION = (0, 0, 0)
",5
"        board = self.calcBoardString()
        #
",5
"                args += ['-s']
        if self.options['preset'] and self.options['preset'] != 'none':
            args += ['--load-config', self.options['preset']]
",5
"                 '--decks-num', game.gameinfo.decks,
                 '--stacks-num', len(game.s.rows),
",5
"            'the': game.s.foundations,
            'stack': game.s.rows,
            'freecell': game.s.reserves,
            }
        if DEBUG:
",5
"                else:
",5
"
        #
        if DEBUG:
            print('time:', time.time()-start_time)
",5
"        if len(hints) > 0:
            if self.solver_state != 'intractable':
",5
"                self.solver_state = 'solved'
",5
"        self.hints.append(None)         # XXX

        # print self.hints
",5
"        if (len(cards) > 0):
            board += ' '.join(['Talon:'] +
",5
"                if not c.face_up:
                    cs = '<%s>' % cs
                b += cs + ' '
",5
"        if 'queens_on_kings' in game_type:
            args += ['--queens-on-kings']
        if 'wrap_ranks' in game_type:
",5
"                result = m.group(1)
                break

        self.dialog.setText(iter=iter_, depth=depth, states=states)
        self.solver_state = result.lower()
",5
"        for sbytes in pout:
            s = six.text_type(sbytes, encoding='utf-8')
            if DEBUG:
                print(s)

",5
"            if s.strip() == 'Deal talon':
                hints.append([1, game.s.talon, None])
                continue

",5
"                continue

            m = re.match(
                'Move a card from stack ([0-9]+) to the foundations', s)
            if not m:
",5
"        pout.close()
        perr.close()
",5
"

",5
"#  This program is free software: you can redistribute it and/or modify
",5
"#  it under the terms of the GNU General Public License as published by
",5
"#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
",5
"#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"
",5
"
class Images:
    def __init__(self, dataloader, cs, r=1):
        self.d = dataloader
",5
"        self._card = []
        self._back = []
        # bottom of stack (link to _bottom_negative/_bottom_positive)
        self._bottom = []
        self._bottom_negative = []      # negative bottom of stack (white)
",5
"            self.CARDW, self.CARDH = w, h
        else:
            if ((check_w and w != self.CARDW) or
",5
"        except Exception:
            pass
",5
"        if (not USE_PIL and TOOLKIT != 'kivy') or imagedir is None:
",5
"            fn = None
        img = createBottom(self._card[0], color, fn)
        return img

",5
"            self.__addBack(im, name)
",5
"        # bottoms / letters
        bottom = None
        neg_bottom = None
",5
"        # load bottoms
        for i in range(self.cs.nbottoms):
            name = ""bottom%02d"" % (i + 1)
            bottom = self.__loadBottom(name, color='black')
",5
"                name = ""shadow%02d.%s"" % (i, ext)
                im = self.__loadCard(name, check_w=0, check_h=0)
                self._shadow.append(im)
                if i > 0:  # skip 0
                    name = ""xshadow%02d.%s"" % (i, ext)
",5
"                    progress.update(step=pstep)
        # shade
        if USE_PIL:
            self._highlight.append(
",5
"            return self._shadow[ncards]
",5
"            ncards = abs(ncards)-2
            if ncards >= len(self._xshadow):
                return None
            return self._xshadow[ncards]
",5
"        y0, y1 = min(y1, y0), max(y1, y0)
        cw, ch = self.getSize()
        x1 += cw
        y1 += ch
",5
"        w, h = x1-x0, y1-y0
        if (w, h) in self._pil_shadow:
",5
"            else:
",5
"                self._highlighted_images[card] = shade
        if not shade:
            # we have not PIL
            return self.getShade()
        return shade
",5
"    def setNegative(self, flag=0):
        if flag:
            self._bottom = self._bottom_negative
            self._letter = self._letter_negative
",5
"        else:
",5
"        cs = self.cs
        if cs is None:
",5
"    def getDelta(self):
        return (int(self.CARD_DX * self._xfactor),
                int(self.CARD_DY * self._yfactor))

",5
"    def resize(self, xf, yf):
        # print 'Images.resize:', xf, yf, self._card[0].width(), self.CARDW
",5
"        for b in self._back:
            b.image = b.image.resize(xf, yf)
        # stack bottom image
        neg = self._bottom is self._bottom_negative
        self._bottom_negative = []
",5
"# *
# ************************************************************************

class SubsampledImages(Images):
",5
"#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    def __init__(self, x, y, suit=None):
        self.x = int(round(x))
        self.y = int(round(y))
",5
"            layout_card_y_space = 14

        self.CW = images.CARDW
        self.CH = images.CARDH
",5
"        self.YOFFSET = images.CARD_YOFFSET
        self.XM = layout_x_margin       # XMARGIN
        self.YM = layout_y_margin       # YMARGIN

",5
"        else:
",5
"        stack.setText(tx, ty, ta, tf)

",5
"                   reserve_class=None,
                   **kw
",5
"            else:
",5
"                for r in self.s.foundations:
                    s.foundations.append(foundation_class(r.x, r.y, game,
                                                          suit=r.suit))
",5
"                s1 = game.s.reserves[i]
                s2 = self.s.reserves[i]
                s1.texts.ncards = self.defaultText(s2)

",5
"            }
        return d[anchor]
",5
"
    def createText(self, stack, anchor, dx=0, dy=0, text_format=""""):
        if self.canvas.preview > 1:
",5
"        if self.canvas.preview > 1:
",5
"            return
        assert stack.texts.rounds is None
        delta_x, delta_y = 0, 0
",5
"            anchor = 'ss'
            delta_y = self.TEXT_MARGIN
        tx, ty, ta, tf = self.getTextAttr(stack, anchor)
        tx += delta_x + dx
        ty += delta_y + dy
",5
"        font = self.game.app.getFont(""canvas_default"")
        stack.texts.rounds = MfxCanvasText(self.canvas, tx, ty,
                                           anchor=ta, font=font)

",5
"    def setRegion(self, stacks, rects):
        self.regions.append((stacks, rects))

",5
"
    def defaultText(self, layout_stack):
        if self.canvas.preview > 1:
            return None
",5
"        layout_stack.text_args[""font""] = \
            self.game.app.getFont(""canvas_default"")
        t = MfxCanvasText(self.game.canvas, **layout_stack.text_args)
        t.text_format = layout_stack.text_format
        return t
",5
"
",5
"        x, y = XM, YM
        for i in range(halfrows):
            self.s.rows.append(S(x+i*XS, y))
",5
"    #  - below: rows
    #  - left bottom: talon, waste
    #

    def freeCellLayout(self, rows=0, reserves=0, waste=0,
",5
"
        # set size so that at least 2//3 of a card is visible with 18 cards
        h = CH*2//3 + (playcards-1)*self.YOFFSET
",5
"        x, y = (w - (toprows*XS - XM))//2, YM
        if reserves:
            for i in range(reserves):
",5
"
        # create talon
        x, y = XM, h - YS
",5
"        if waste:
            x += XS
            self.s.waste = s = S(x, y)
            if texts:
",5
"            h = YS+(playcards-1)*self.YOFFSET+YS
",5
"            self.s.rows.append(S(x, y))
            x += XS
",5
"            yy = h - YS - CH//2
        else:
            yy = 999999
        self.setRegion(self.s.rows, (-999, -999, x - CW // 2, yy))
",5
"                self.s.foundations.append(S(x+i*XS, y, suit=suit))
            y += YS

        # create talon and waste
        x, y = x + (decks-1)*XS, h - YS
",5
"    def harpLayout(self, rows, waste, reserves=0,
                   texts=1, reserve_texts=False, playcards=19):
",5
"        XM, YM = self.XM, self.YM
        XS, YS = self.XS, self.YS

",5
"
        w = max(reserves*XS, rows*XS, (suits*decks+waste+1)*XS,
",5
"            h += self.TEXT_HEIGHT
",5
"        for suit in range(suits):
            for i in range(decks):
                self.s.foundations.append(S(x, y, suit=suit))
",5
"            yy = -999
        self.setRegion(self.s.rows, (-999, yy, 999999, y - YS // 2))
        if waste:
            x = w - 2*XS
            self.s.waste = s = S(x, y)
",5
"        suits = len(self.game.gameinfo.suits) + bool(self.game.gameinfo.trumps)
        foundrows = 1 + (suits > 5)
        frows = decks * suits // foundrows
",5
"
        w = XM + maxrows * XS
        # set size so that at least 2//3 of a card is visible with 16 cards
        h = CH * 2 // 3 + (playcards - 1) * self.YOFFSET
        h = max(h, 2 * YS)
",5
"                # place text right of stack
                self._setText(s, 'ne')
        if waste:
            x += XS
",5
"
        # below
",5
"            self.s.rows.append(S(x, y))
            x += XS
        if reserves:
",5
"        # bottom
",5
"                x += XS
                if reserve_texts:
                    self._setText(s, anchor=""n"")

        # set window
",5
"
    #
    # Yukon layout
    #  - left: rows
",5
"        XM, YM = self.XM, self.YM
        XS, YS = self.XS, self.YS

",5
"        # set window
        self.size = (XM + (rows+decks)*XS,  h)

    #
",5
"        yextra = 0

",5
"        # set size so that at least 2//3 of a card is visible with 10 cards
        h = CH * 2 // 3 + (playcards - 1) * self.YOFFSET
        h = max(h, 2 * YS)

        # top
",5
"
        # set window
        self.size = (XM + maxrows * XS, YM + YS + yextra + h)

",5
"    #
    # Samuri layout
    #  - top center: rows
    #  - left & right: foundations
    #  - bottom center: talon
",5
"        # set size so that at least 2//3 of a card is visible with 20 cards
        h = CH * 2 // 3 + (playcards - 1) * self.YOFFSET
        h = max(h, 2 * YS)

        # bottom center
",5
"                x0, y0 = x + XS * i, y + YS * d
                self.s.foundations.append(S(x0, y0, suit=suit))
",5
"            d += 1
",5
"        S = self.__createStack
        CH = self.CH
        XM, YM = self.XM, self.YM
        XS, YS = self.XS, self.YS

",5
"            y += YS
        x, y = w - XS, YM + YS * decks
        for i in range(reserves // 2):
            self.s.reserves.append(S(x, y))
            y += YS
",5
"        if texts:
",5
"        XM, YM = self.XM, self.YM
        XS, YS = self.XS, self.YS

",5
"        self.setRegion(self.s.rows, (0, 0, XS * rows // 2 + XM // 2, 999999))

        # create reserves
        x, y = w - XS * decks, YM + YS * 4
        for i in range(decks):
",5
"        # set size so that at least 2//3 of a card is visible with 12 cards
        h = CH * 2 // 3 + (playcards - 1) * self.YOFFSET
        h = max(h, 2 * YS)

        # create talon
",5
"            x += XS + XM
",5
"            self.s.rows.append(S(x, y))
",5
"            x += XS + XM
        self.setRegion(self.s.rows, (XS + XM, -999, 999999, 999999))
",5
"    #  - center: two groups of rows
    #  - lower right: talon
    #
",5
"
        # Talon
",5
"            for i in range(decks):
                self.s.foundations.append(S(x, y, suit=(suit + suits // 20)))
                x += XS
",5
"#  the Free Software Foundation, either version 3 of the License, or
",5
"#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
",5
"#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"# - flip the top card of a stack
# - turn a whole stack onto another stack
# - update the model or complete view a stack
",5
"        self.redo(game)

    def __repr__(self):
        return str(self.__dict__)
",5
"    def cmpForRedo(self, other):
        return -1
",5
"# * Move the top N cards from a stack to another stack.
# ************************************************************************

",5
"class AMoveMove(AtomicMove):
",5
"        if frames == -2 and game.moves.state not in (game.S_UNDO, game.S_REDO):
            # don't use animation for drag-move
            frames = 0
        cards = from_stack.cards[-ncards:]
        if frames != 0:
",5
"        to_stack.updatePositions()

    def redo(self, game):
        self._doMove(game, self.ncards, game.allstacks[self.from_stack_id],
",5
"    def _doMove(self, game, stack):
",5
"

",5
"        to_stack = game.allstacks[self.to_stack_id]
        assert len(from_stack.cards) > 0
        assert len(to_stack.cards) == 0
        mylen = len(from_stack.cards)
        for i in range(mylen):
",5
"            to_stack.round = to_stack.round + 1
        self._doMove(from_stack, to_stack, 0)

    def undo(self, game):
        from_stack = game.allstacks[self.from_stack_id]
",5
"
# ************************************************************************
",5
"            # model
            stack.updateModel(undo, self.flags)
        else:
",5
"# ************************************************************************
",5
"
class ASaveSeedMove(AtomicMove):
    def __init__(self, game):
        self.state = game.random.getstate()

",5
"    def redo(self, game):
        game.random.setstate(self.state)

    def undo(self, game):
",5
"
class ASaveStateMove(AtomicMove):
    def __init__(self, game, flags):
        self.state = game.getState()
",5
"    def undo(self, game):
        if (self.flags & 3) in (2, 3):
",5
"        return cmp(self.state, other.state)


# ************************************************************************
# * Shuffle all cards of a stack. Saves the seed. Does not flip any cards.
",5
"class AShuffleStackMove(AtomicMove):
    def __init__(self, stack, game):
        self.stack_id = stack.id
        # save cards and state
        self.card_ids = tuple([c.id for c in stack.cards])
",5
"        game.random.setstate(self.state)
        seq = stack.cards
        n = len(seq) - 1
        while n > 0:
",5
"
    def undo(self, game):
",5
"
",5
"        if game.moves.state == game.S_PLAY:
            assert to_stack.acceptsCards(
                from_stack, [from_stack.cards[from_pos]])
        card = from_stack.cards[from_pos]
",5
"
",5
"        card = to_stack.removeCard()
        # if self.frames != 0:
        #  x, y = to_stack.getPositionFor(card)
",5
"
    def undo(self, game):
        # stack = game.allstacks[self.stack_id]
        pass
",5
"
    def cmpForRedo(self, other):
        return cmp((self.stack_id, self.from_pos, self.to_pos),
                   (other.stack_id, other.from_pos, other.to_pos))
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"#
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"from pysollib.gamedb import GI, loadGame
from pysollib.layout import Layout
from pysollib.mygettext import _, n_
from pysollib.stack import AC_FoundationStack, \
        AC_RowStack, \
",5
"        Spider_AC_Foundation, \
",5
"import six

# ************************************************************************
# *
",5
"# ************************************************************************

",5
"    def __init__(self, values_map, default, var_name,
",5
"        else:
            self.values = self.values_map
        self.var_name = var_name
",5
"        self.label = label
        self.widget = widget
        self.variable = None            # Tk variable
        self.current_value = None

",5
"    var_name='decks',
    )
LayoutType = WizSetting(
    values_map=((n_('FreeCell'), Layout.freeCellLayout),
",5
"    label=_('Layout:'),
",5
"                (n_('Deal to waste'),         WasteTalonStack),
                (n_('Deal to tableau'),       DealRowRedealTalonStack),
                (n_('Deal to reserves'),      DealReserveRedealTalonStack),
                (n_('Spider'),                SpiderTalonStack),
                (n_('Grounds for a Divorce'), GroundsForADivorceTalonStack),
",5
"    values_map=((n_('No redeals'), 0),
                (n_('One redeal'), 1),
                (n_('Two redeals'), 2),
",5
"                (n_('Unlimited redeals'), -1),
                ),
    default=n_('No redeals'),
",5
"    values_map=(1, 5),
    default=1,
    widget='spin',
    label=_('# of cards dealt to the waste:'),
    var_name='deal_to_waste',
",5
"                (n_('Rank'),                   RK_FoundationStack),
                (n_('Spider same suit'),       Spider_SS_Foundation),
                (n_('Spider alternate color'), Spider_AC_Foundation),
                (n_('Spider rank'),            Spider_RK_Foundation),
                ),
",5
"    )
FoundBaseCard = WizSetting(
",5
"    default=n_('Ace'),
    label=_('Base card:'),
",5
"    var_name='rows_num',
    )
RowsType = WizSetting(
    values_map=((n_('Same suit'),                     SS_RowStack),
                (n_('Alternate color'),               AC_RowStack),
",5
"    label=_('Type:'),
    var_name='rows_type',
",5
"                (n_('King'), KING),
",5
"    values_map=((n_('Up'), 1), (n_('Down'), -1)),
    default=n_('Down'),
    label=_('Direction:'),
    var_name='rows_dir',
",5
"    values_map=(0, 1),
",5
"    default=0,
    label=_('Use ""Super Move"" feature:'),
    var_name='rows_super_move',
    widget='check',
",5
"    widget='spin',
    label=_('Number of reserves:'),
    var_name='reserves_num',
    )
ReservesMaxAccept = WizSetting(
",5
"    values_map=(0, 20),
    default=1,
",5
"    )
DealType = WizSetting(
    values_map=((n_('Triangle'),  'triangle'),
                (n_('Rectangle'), 'rectangle'),
",5
"    RowsType,
    RowsBaseCard,
    RowsDir,
    RowsMaxMove,
    RowsWrap,
",5
"    DealMaxCards,
    DealToFound,
",5
"    )


def write_game(app, game=None):
    import pysollib.customgame                   # for py2exe
",5
"## THIS FILE WAS GENERATED AUTOMATICALLY BY THE SOLITAIRE WIZARD
## DO NOT EDIT

",5
"                fd.write(""        '%s': %i,\n"" % (w.var_name, v))
",5
"

def reset_wizard(game):
    for w in WizardWidgets:
        if isinstance(w, six.string_types):
",5
"    t = _(""A Python Solitaire Game Collection"")
    if app.miscrandom.random() < 0.8:
        t = _(""A World Domination Project"")
    strings = (_(""&Nice""), _(""&Credits...""))
",5
"Copyright (C) 1998 - 2003 Markus F.X.J. Oberhumer.
Copyright (C) 2003 Mt. Hood Playing Card Co.
Copyright (C) 2005 - 2009 Skomoroh.
All Rights Reserved.
",5
"    elif TOOLKIT == ""wx"":
        t = ""wxPython""
    elif TOOLKIT == ""kivy"":
        t = ""kivy""
",5
"Guido van Rossum for the initial example program
T. Kirk for lots of contributed games and cardsets
",5
"
The Python, %(gui_library)s, SDL & Linux crews
for making this program possible''') % {'app': TITLE, 'gui_library': t},
        image=app.gimages.logos[3], image_side=""right"",
        separator=True)
",5
"def help_html(app, document, dir_, top=None):
    global help_html_viewer, help_html_index
    if not document:
        return None
",5
"    if top is None:
",5
"    # print doc, help_html_index
    try:
        viewer = help_html_viewer
        # if viewer.parent.winfo_parent() != top._w:
",5
"            top.wm_minsize(400, 200)
        viewer = HTMLViewer(top, app, help_html_index)
        viewer.display(doc)
    # wm_map(top, maximized=maximized)
    viewer.parent.wm_deiconify()
",5
"from pysollib.hint import Yukon_Hint
from pysollib.layout import Layout
",5
"        GroundsForADivorceTalonStack, \
",5
"        Spider_RK_Foundation, \
        Spider_SS_Foundation, \
",5
"        Spider_SS_RowStack, \
        StackWrapper, \
        SuperMoveAC_RowStack, \
        SuperMoveBO_RowStack, \
        SuperMoveRK_RowStack, \
",5
"        WasteTalonStack, \
        Yukon_AC_RowStack, \
        Yukon_RK_RowStack, \
        Yukon_SS_RowStack
",5
"
import six

",5
"        if isinstance(w, six.string_types):
            continue
        if w.var_name in ss:
            v = ss[w.var_name]
        else:
",5
"                               Spider_RK_Foundation,):
            kw['suit'] = ANY_SUIT
        # fix dir and base_rank for Spider foundations
",5
"        if s['found_type'] in (Spider_SS_Foundation,
                               Spider_AC_Foundation,
                               Spider_RK_Foundation,):
            kw['dir'] = -kw['dir']
            if s['found_base_card'] == KING:
",5
"                ((BO_RowStack, SuperMoveBO_RowStack),
",5
"                ):
",5
"            if s['rows_type'] in c:
                if s['rows_wrap']:
                    self.shallHighlightMatch = f[1]
                else:
                    self.shallHighlightMatch = f[0]
",5
"        if not s['deal_found']:
            return cards
        if s['found_type'] in (Spider_SS_Foundation,
",5
"        if base_card == ANY_RANK:
            base_card = cards[0].rank
        # move base_card to top of the Talon (i.e. first cards to be dealt)
        return self._shuffleHookMoveToTop(
",5
"            max_cards -= self.s.talon.dealRowAvail(rows=rows, flip=flip,
                                                   frames=frames)
            return frames, max_cards

",5
"
",5
"        min_cards = max(len(self.s.rows), 8)
        max_rows = s['deal_face_down'] + s['deal_face_up'] \
            + s['deal_to_reserves']
",5
"        if max_rows <= 1:
            min_cards = max_cards

",5
"        # deal to foundations
        if s['deal_found']:
            frames, max_cards = deal(self.s.foundations,
",5
"                                     True, frames, max_cards)

",5
"        # deal to reserves
",5
"            frames, max_cards = deal(self.s.reserves[:max_cards],
                                     True, frames, max_cards)

        # deal to rows
",5
"        if s['deal_type'] == 'triangle':
            # triangle
            for i in range(1, len(self.s.rows)):
                if max_rows <= 1:
",5
"                mc = max_cards - len(self.s.rows)
                frames, max_cards = deal(self.s.rows[i:i+mc],
                                         flip, frames, max_cards)
                face_down -= 1
",5
"            while self.s.talon.cards:
                frames, max_cards = deal(self.s.rows, True, frames, max_cards)
",5
"            self.s.talon.dealCards()


def registerCustomGame(gameclass):
",5
"                          GI.GT_CUSTOM | GI.GT_ORIGINAL,
                          s['decks'], s['redeals'], s['skill_level']))


",5
"    # A card doesn't record to which stack it belongs; only the stack
",5
"    #
    # Semi-public read-only instance variables:
",5
"    #

    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
        # The card is created at position (x, y), with its face down.
",5
"        return self.hide_stack is not None
",5
"        # Raise the card above all other objects in its group (i.e. stack).
        if unhide:
            self.unhide()
        self.item.tkraise()
",5
"
    def setSelected(self, s, group=None):
        pass
",5
"#
",5
"from pysollib.pysoltk import TimeoutsDialog
from pysollib.pysoltk import create_find_card_dialog
from pysollib.pysoltk import create_solver_dialog
from pysollib.settings import DEBUG
",5
"# ************************************************************************
",5
"            hint=0,
            autofaceup=0,
            autodrop=0,
",5
"            shuffle=0,
            autodeal=0,
            quickplay=0,
            demo=0,
",5
"            ms.save = 1
        if opt.undo:
            if game.canUndo() and game.moves.index > 0:
                ms.undo = 1
",5
"        # File menu
        self.setMenuState(ms.save, ""file.save"")
        self.setMenuState(ms.save_as, ""file.saveas"")
        self.setMenuState(ms.hold_and_quit, ""file.holdandquit"")
",5
"        self.setMenuState(ms.redo, ""edit.redo"")
        self.setMenuState(ms.redo, ""edit.redoall"")
        self.updateBookmarkMenuState()
",5
"        self.setMenuState(ms.find_card, ""assist.findcard"")
        self.setMenuState(ms.demo, ""assist.demo"")
        self.setMenuState(ms.demo, ""assist.demoallgames"")
",5
"        self.setToolbarState(ms.undo, ""undo"")
        self.setToolbarState(ms.redo, ""redo"")
        self.setToolbarState(ms.autodrop, ""autodrop"")
        self.setToolbarState(ms.shuffle, ""shuffle"")
        self.setToolbarState(ms.pause, ""pause"")
",5
"    # disable menu items and toolbar
    def disableMenus(self):
        if self.game is None:
",5
"                return
        if self.game.nextGameFlags(self.game.id) == 0:
            self.game.endGame()
            self.game.newGame()
        else:
",5
"    def _mSelectGame(self, id, random=None, force=False):
",5
"                             bitmap=""error"")
",5
"            self.game.newGame(random=random)
        else:
            self.game.endGame()
            self.game.quitGame(id, random=random)
",5
"        if self.changed():
",5
"                return
        r = self.game.random
        seed = r.increaseSeed(r.initial_seed)
",5
"                           default=0, e_width=25)
        if d.status != 0:
",5
"            return
        if d.button == 2:
",5
"        if self._cancelDrag():
            return
        if self.changed():
",5
"            gi = self.app.getGameInfo(g)
",5
"                games.append(gi.id)
",5
"            elif type == 'not won' and won == 0 and lost > 0:
                games.append(gi.id)
            elif type == 'not played' and won+lost == 0:
",5
"        gl = list(gl)
        if len(gl) < 2 or (id not in gl):
            return
        if self.changed():
",5
"
    def mSelectNextGameByName(self, *args):
        self._mSelectNextGameFromList(self.app.gdb.getGamesIdSortedByName(), 1)
",5
"    def mSave(self, *args):
",5
"            return
        if self.changed():
            if not self.game.areYouSure(_(""Quit %s"") % TITLE):
                return
        self.game.endGame()
",5
"        if self._cancelDrag():
            return
",5
"            self.game.playSample(""redo"")
",5
"            return
        self.game.gsaveinfo.bookmarks = {}
        self.game.updateMenus()

    def mRestart(self, *args):
",5
"                # save to file
                fn = os.path.join(self.app.dn.config, ""comments.txt"")
",5
"        self._setCommentMenu(bool(game.gsaveinfo.comment))

    #
",5
"        if player is None:
            text = _(""Demo statistics were appended to\n\n%(filename)s"")
",5
"    def mPlayerStats(self, *args, **kw):
        wasPaused = False
        if not self.game.pause:
            self.game.doPause()
            wasPaused = True
",5
"        gameid = None
        while mode > 0:
",5
"                player = self.app.opt.player
            n = self.game.gameinfo.name
            # translation keywords
",5
"                d = FullLog_StatsDialog(self.top, header, self.app, player)
",5
"                d = SessionLog_StatsDialog(self.top, header, self.app, player)
            elif mode == 105:
                # TRANSLATORS: eg. top 10 or top 5 results for a certain game
",5
"                # print full log to file
                write_method = FileStatsFormatter.writeFullLog
                self._mStatsSave(player, ""log"", write_method)
            elif mode == 204:
                # print session log to file
",5
"                ):
                    self.app.stats.resetStats(player, self.game.id)
                    self.game.updateStatus(stats=self.app.stats.getStats(
",5
"                    self.game.quitGame(gameid)
            elif mode == 402:
                # start a new game with a gameid / gamenumber
                # TODO
",5
"                print_err(""stats problem: %s %s %s"" % (mode, demo, player))
                pass
            if d.status != 0:
",5
"                break
            mode = d.button
        if self.game.pause:
            if wasPaused:
",5
"    #

    def mHint(self, *args):
        if self._cancelDrag():
",5
"                self.app.opt.player = n
                self.game.updateStatus(player=self.app.opt.player)
                self.game.updateStatus(stats=self.app.stats.getStats(
                    self.app.opt.player, self.game.id))

",5
"
    def mOptFonts(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"                d.highlight_samerank_timeout

",5
"
    def mHelpLicense(self, *args):
",5
"    #

    def mScreenshot(self, *args):
        if self._cancelDrag():
",5
"            i = i + 1
",5
"            if i >= 10000:      # give up
",5
"                return
        self.top.screenshot(fn)
",5
"
    def mPlayNextMusic(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"# ************************************************************************
",5
"# * toolbar
# ************************************************************************

class PysolToolbar(PysolToolbarTk):
",5
"            self.menubar.mNewGame()
        return 1

    def mOpen(self, *args):
",5
"        return 1
",5
"    def mPlayerStats(self, *args):
        if not self._busy():
            self.menubar.mPlayerStats()
        return 1
",5
"        return 1

    def mQuit(self, *args):
",5
"
def n_(x):                        # for gettext
",5
"DATA_DIRS = []
# you can add your extra directories here
if os.name == 'posix':
    DATA_DIRS = [
        '/usr/share/PySolFC',
",5
"# i18n, see also options.py
TRANSLATE_GAME_NAMES = True

",5
"
",5
"from pysollib.mfxutil import print_err
from pysollib.mygettext import _
from pysollib.pysolaudio import AbstractAudioClient
from pysollib.pysolaudio import KivyAudioClient, OSSAudioClient
",5
"from pysollib.pysoltk import PysolProgressBar
from pysollib.pysoltk import loadImage
from pysollib.resource import Tile
from pysollib.settings import SOUND_MOD, TITLE, TOOLKIT
from pysollib.util import DataLoader
",5
"# *
# ************************************************************************

def parse_option(argv):
",5
"            opts[""help""] = True
        elif i[0] in (""--deal""):
            opts[""deal""] = i[1]
",5
"
    if opts[""help""]:
",5
"        # os.path.join(app.dn.config, ""screenshots""),
",5
"        os.path.join(app.dn.config, ""plugins""),
            ):
        if not os.path.exists(d):
            try:
                os.makedirs(d)
",5
"    top = MfxRoot(className=TITLE)
    app.top = top
    app.top_bg = top.cget(""bg"")
    app.top_cursor = top.cget(""cursor"")

",5
"
    # init games database
    def progressCallback(*args):
        app.intro.progress.update(step=1)
",5
"    if opts[""nosound""] or SOUND_MOD == 'none':
        app.audio = AbstractAudioClient()
    elif opts['sound-mod']:
",5
"        snd = []
",5
"                app.tabletile_index = tile.index
                break

",5
"            # that the music order is not random.
",5
"    # prepare other images
",5
"    # load cardset
    progress = app.intro.progress
    if not app.loadCardset(cardset, progress=progress, update=1):
        for cardset in app.cardset_manager.getAll():
            progress.reset()
",5
"                break
        else:
            fatal_no_cardsets(app)
            return 3

",5
"            self.args = args

        def build(self):
            logging.info(""KivyApp: build"")
",5
"    def main(args=None):
        # create the application
        app = Application()
        r = pysol_init(app, args)
",5
"#  Copyright (C) 2005-2009 Skomoroh
",5
"        self.total_moves_result = GameStatResult()
        self.score_result = GameStatResult()
        self.score_casino_result = GameStatResult()

    def update(self, game, status):
",5
"        game_number = game.getGameNumber(format=0)
        game_start_time = game.gstats.start_time
        # update number of games
",5
"        if status == 0:
",5
"            self.num_won += 1
        else:  # status == 2
",5
"            score_p = self.score_result.update(
",5
"            return

        game.updateTime()
",5
"        return time_p, moves_p, total_moves_p, score_p, score_casino_p
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
",5
"    # return n
    n = n.encode('iso8859-1', 'replace')
    # FIXME: rewrite this for better speed
",5
"        from pysollib.kivy.LApp import get_platform
        plat = get_platform()
        if plat == 'android':
            os.environ['HOME'] = '/sdcard'
",5
"

def win32_getprefdir(package):
",5
"
    def copy(self):
        c = self.__class__()
        c.__dict__.update(self.__dict__)
        return c
",5
"

",5
"            kw = kw.__dict__
        if isinstance(defaults, KwStruct):
            defaults = defaults.__dict__
",5
"            kw = kw.copy()
            for k, v in defaults.items():
                if k not in kw:
                    kw[k] = v
        self.__dict__.update(kw)
",5
"        return self.__dict__.get(key, default)

    def getKw(self):
        return self.__dict__

",5
"
# ************************************************************************
# * pickling support
",5
"# ************************************************************************

def pickle(obj, filename, protocol=0):
    f = None
",5
"    finally:
",5
"# ************************************************************************
# *
# ************************************************************************
",5
"        webbrowser.open(url)
    except OSError:                  # raised on windows if link is unreadable
        pass
    except Exception:
        return False
",5
"
class Resource(Struct):
    def __init__(self, **kw):
",5
"            return self._objects[index]
        return None

",5
"    def getSearchDirs(self, app, search, env=None):
",5
"                        globdirs = glob.glob(d + ""-*"")
",5
"
# CardsetInfo constants
class CSI:
",5
"    # cardset size
",5
"        7:  _(""Navagraha Ganjifa type (108 cards)""),
        8:  _(""Dashavatara Ganjifa type (120 cards)""),
        9:  _(""Trumps only type (variable cards)""),
    }
",5
"    }

",5
"    # cardset styles
    STYLE = {
        1:  _(""Adult""),                #
        2:  _(""Animals""),              #
        3:  _(""Anime""),                #
",5
"        1012:  _(""Czech Republic""),    #
        1013:  _(""Denmark""),           #
        1003:  _(""England""),           #
        1004:  _(""France""),            #
        1006:  _(""Germany""),           #
",5
"    DATE = {
",5
"        10:  ""1000 - 1099"",
        11:  ""1100 - 1199"",
        12:  ""1200 - 1299"",
        13:  ""1300 - 1399"",
        14:  ""1400 - 1499"",
",5
"            styles=[],
            year=0,
            # line[1]
            ident="""",
",5
"            CARD_YOFFSET=0,
            SHADOW_XOFFSET=0,
",5
"            backnames=(),
            # other
",5
"            dir="""",
",5
"        )
        Resource.__init__(self, **kw.getKw())

",5
"    def getFaceCardNames(self):
        names = []
",5
"
    def getPreviewCardNames(self):
        names = self.getFaceCardNames()
        pnames = []
        ranks, suits = self.ranks, self.suits
",5
"        self.registered_types = {}
        self.registered_sizes = {}
        self.registered_styles = {}
        self.registered_nationalities = {}
        self.registered_dates = {}
",5
"
    def _check(self, cs):
        s = cs.type
        if s not in CSI.TYPE:
            return 0
",5
"        elif s == CSI.TYPE_TAROCK:
",5
"            cs.trumps = list(range(22))
        elif s == CSI.TYPE_MAHJONGG:
            cs.ranks = list(range(10))
            cs.suits = ""abc""
",5
"            cs.ranks = list(range(16))
",5
"            cs.suits = ""cshd""
            cs.trumps = list(range(4))
        elif s == CSI.TYPE_MUGHAL_GANJIFA:
",5
"            cs.nbottoms = 12
            cs.ranks = list(range(12))
            cs.suits = ""abcdefghi""
        elif s == CSI.TYPE_DASHAVATARA_GANJIFA:
            cs.nbottoms = 13
",5
"
    def register(self, cs):
",5
"            elif CW <= 60 and CH <= 85:
                cs.si.size = CSI.SIZE_SMALL
            elif CW <= 75 and CH <= 105:
                cs.si.size = CSI.SIZE_MEDIUM
            elif CW <= 90 and CH <= 125:
",5
"        s = cs.si.size
        self.registered_sizes[s] = self.registered_sizes.get(s, 0) + 1
        cs.updateCardback()
        ResourceManager.register(self, cs)

",5
"
# ************************************************************************
# * Tile
# ************************************************************************

",5
"

",5
"# ************************************************************************
",5
"#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"from pysollib.pysoltk import MfxCanvasRectangle, MfxCanvasText
from pysollib.pysoltk import after_cancel, after_idle
",5
"from pysollib.pysoltk import get_text_width
from pysollib.pysoltk import markImage
",5
"from pysollib.settings import DEBUG
from pysollib.settings import TOOLKIT
from pysollib.util import ACE, KING
from pysollib.util import ANY_RANK, ANY_SUIT, NO_RANK
",5
"        if not c.face_up:
",5
"
# check that all cards are face-down
def cardsFaceDown(cards):
    if not cards:
",5
"    return True

",5
"
# check that cards are face-up and build down by rank
def isRankSequence(cards, mod=8192, dir=-1):
",5
"        if (c1.rank + dir) % mod != c2.rank:
            return False
        c1 = c2
",5
"            return False
",5
"        if (c1.rank + dir) % mod != c2.rank or c1.suit != c2.suit:
",5
"    def __init__(self, x, y, game, cap={}):
",5
"        #
",5
"        # model
",5
"        #
        model.id = id
",5
"            min_cards=0,
",5
"        view.group = MfxCanvasGroup(view.canvas)
",5
"
",5
"            shade_img=None,
        )
        # other canvas items
",5
"        # text items
        view.texts = Struct(
",5
"        dx, dy = cardw+view.canvas.xmargin, cardh+view.canvas.ymargin
        view.is_visible = view.x >= -dx and view.y >= -dy
        view.is_open = -1
",5
"        # help breaking circular references
        unbind_destroy(self.group)

    def prepareStack(self):
",5
"        self.prepareView()
        if self.is_visible:
            self.initBindings()
",5
"        # bind(group, ""<B1-Motion>"", self.__motionEventHandler)
",5
"        bind(group, ""<ButtonRelease-1>"", self.__releaseEventHandler)
        bind(group, ""<Control-1>"", self.__controlclickEventHandler)
",5
"        bind(group, ""<Enter>"", self.__enterEventHandler)
        bind(group, ""<Leave>"", self.__leaveEventHandler)

",5
"            self.CARD_YOFFSET = (oy,)
",5
"                                                group=self.group)
            self.top_bottom = self.images.bottom

    # invisible stack bottom
",5
"
    # Add a card add the top of a stack. Also update display. {model -> view}
    def addCard(self, card, unhide=1, update=1):
        model, view = self, self
        model.cards.append(card)
",5
"        card.tkraise(unhide=unhide)
        if view.can_hide_cards and len(model.cards) >= 3:
",5
"            # we only need to display the 2 top cards
            model.cards[-3].hide(self)
        card.item.addtag(view.group)
        for c in model.cards[position:]:
            view._position(c)
",5
"
",5
"    # Remove a card from the stack. Also update display. {model -> view}
    def removeCard(self, card=None, unhide=1, update=1, update_positions=0):
",5
"        assert len(model.cards) > 0
        if card is None:
            card = model.cards[-1]
",5
"                    model.cards[-3].unhide()
            del model.cards[-1]
        else:
            card.item.dtag(view.group)
",5
"                for c in model.cards[card_index:]:
                    view._position(c)
",5
"
        if update:
            view.updateText()
        self.unshadeStack()
",5
"        self.is_filled = False
        return card

",5
"        return None

    # get the largest moveable pile {model} - uses canMoveCards()
",5
"                    return cards
                del cards[0]
        return None

",5
"    # Position the card on the canvas {view}
    def _position(self, card):
        x, y = self.getPositionFor(card)
        card.moveTo(x, y)

",5
"        images = self.game.app.images
        cw, ch = images.getSize()
        index = -1
        for i in range(len(cards)):
            c = cards[i]
",5
"            return dir - self.cap.mod
",5
"        mylen = len(cards)
",5
"        def _check(c, suit, color, rank):
            return ((suit >= 0 and c.suit != suit) or
                    (color >= 0 and c.color != color) or
                    (rank >= 0 and c.rank != rank))
",5
"        for c in cards:
            if not c.face_up or _check(c, cap.suit, cap.color, cap.rank):
                return False
        if self.cards:
",5
"        if mylen < cap.min_move or mylen > cap.max_move:
            return False
        mylen = len(self.cards) - mylen
",5
"            return False
        return cardsFaceUp(cards)

    #
    # Capabilities - important for game logic {model}
",5
"        # Do we accept receiving `cards' from `from_stack' ?
        return False
",5
"
    def canFlipCard(self):
        # Can we flip our top card ?
",5
"    def resetGame(self):
        # Called when starting a new game.
",5
"        # self.images.bottom = None

    def __repr__(self):
        # Return a string for debug print statements.
",5
"        return ""%s(%d)"" % (self.__class__.__name__, self.id)

    #
    # Atomic move actions {model -> view}
    #
",5
"    def playMoveMove(self, ncards, to_stack, frames=-1, shadow=-1, sound=True):
        if sound:
",5
"            else:
                self.game.playSample(""move"", priority=10)
",5
"
    #
    # Appearance {view}
    #
",5
"
",5
"            return x, y
        ix, iy, lx, ly = 0, 0, len(view.CARD_XOFFSET), len(view.CARD_YOFFSET)
        d = self.shrink_face_down
        for c in model.cards:
",5
"            else:
                x += self.CARD_XOFFSET[ix]//d
",5
"            item = c.item
            if not view.can_hide_cards:
                d = self.shrink_face_down
                if c.face_up:
                    x += self.CARD_XOFFSET[ix]
",5
"            #     for c in self.cards:
",5
"            #         if c.isHidden():
            #             assert c.hide_stack is not None
            #         else:
",5
"
    def reallocateCards(self):
",5
"        # change CARD_YOFFSET if a cards is off-screen
        # returned False if CARD_YOFFSET is not changed, otherwise True
        if not self.game.app.opt.compact_stacks:
            return False
",5
"                return False
            n = num_face_down // self.shrink_face_down + num_face_up
",5
"        # resize and move stack
        # xf, yf - a multiplicative factor (from the original values)
        # print 'Stack.resize:', self, self.is_visible, xf, yf
        x0, y0 = self.init_coord
        x, y = int(round(x0*xf)), int(round(y0*yf))
",5
"                    continue
                # check the rank
                if c.rank != card.rank:
",5
"                # ask the target stack
                if s.basicShallHighlightSameRank(c):
",5
"                    info.append((s, c, c, col_2))
        self.game.stats.highlight_samerank += 1
",5
"    def highlightMatchingCards(self, event):
        i = self._findCard(event)
        if i < 0:
            return 0
",5
"        if not self.basicShallHighlightMatch(card):
",5
"        if i < 0 or positions <= 0 or not self.cards[i].face_up:
            return 0
        # print self.cards[i]
        self.cards[i].item.tkraise()
        self.canvas.update_idletasks()
",5
"        elif TOOLKIT == 'gtk':
            for c in self.cards[i+1:]:
",5
"        if not self.is_open:
            return 0
        i = self._findCard(event)
        positions = len(self.cards) - i - 1
",5
"        self.cards[i].item.tkraise()
        self.canvas.update_idletasks()
        self.game.sleep(self.game.app.opt.timeouts['raise_card'])
        if not face_up:
            self.cards[i].showBack()
",5
"    def rightclickHandler(self, event):
        return 0

    def doubleclickHandler(self, event):
        return self.clickHandler(event)
",5
"        if self.game.app.opt.highlight_samerank:
            return self.highlightSameRank(event)
        return 0

",5
"        # default action: move cards back to their origin position
        if drag.cards:
            if sound:
",5
"            if self.game.app.opt.mouse_type == 'point-n-click':
",5
"                drag.stack.moveCardsBackHandler(event, drag)
            else:
                self.moveCardsBackHandler(event, drag)

",5
"    def moveCardsBackHandler(self, event, drag):
        if self.game.app.opt.animations:
            if drag.cards:
                c = drag.cards[0]
",5
"    def __defaultClickEventHandler(self, event, handler,
                                   start_drag=0, cancel_drag=1):
        self.game.event_handled = True  # for Game.undoHandler
        if self.game.demo:
",5
"            self.game.stopDemo(event)
            return EVENT_HANDLED
        self.game.interruptSleep()
",5
"                self.startDrag(event, sound=sound)
        else:
            handler(event)
        return EVENT_HANDLED

",5
"    if (TOOLKIT == 'kivy'):
",5
"        #      # this allows us to skip redraws on slow machines
        #      drag = self.game.drag
        #      if drag.timer is None:
        #          drag.timer = after_idle(self.canvas, self.keepDragTimer)
",5
"        #      drag.event = event
        #  else:
        #      # update now
        #      self.keepDrag(event)
",5
"            return EVENT_HANDLED
        if self.game.app.opt.mouse_type == 'drag-n-drop':
",5
"    def __enterEventHandler(self, event):
        if self.game.drag.stack:
",5
"                return EVENT_HANDLED
            else:
",5
"
    def getDragCards(self, index):
",5
"    def startDrag(self, event, sound=True):
        # print event.x, event.y
        assert self.game.drag.stack is None
",5
"        x_offset, y_offset = self.cards[i].x, self.cards[i].y
",5
"        images = game.app.images
        drag.shadows = self.createShadows(drag.cards)
",5
"        # sx, sy = 0, 0
        sx, sy = -images.SHADOW_XOFFSET, -images.SHADOW_YOFFSET
        dx, dy = 0, 0
        cw, ch = images.getSize()
",5
"            dx = event.x - (x_offset+cw+sx) - game.canvas.xmargin
            dy = event.y - (y_offset+ch+sy) - game.canvas.ymargin
            if dx < 0:
                dx = 0
            if dy < 0:
",5
"    # continue a drag operation
    def keepDrag(self, event):
        drag = self.game.drag
",5
"                self._updateShade()
            for s in drag.shadows:
                s.move(dx, dy)
            for card in drag.cards:
",5
"                card.moveBy(dx, dy)
        drag.event = None

    def keepDragTimer(self):
        drag = self.game.drag
",5
"        drag.timer = None
        if drag.event:
            self.keepDrag(drag.event)
            self.canvas.update_idletasks()
",5
"
    # create shadows, return a tuple of MfxCanvasImages
    def createShadows(self, cards, dx=0, dy=0):
",5
"            s = MfxCanvasImage(self.canvas, cx, cy,
                               image=img, anchor=ANCHOR_SE)
",5
"
",5
"            return (s1, s2)
        return ()

    # handle shade within a drag operation
",5
"        game = self.game
        images = game.app.images
        CW, CH = images.CARDW, images.CARDH
        drag = game.drag
        # stacks = game.allstacks
",5
"        c = drag.cards[0]
        stacks = (game.getClosestStack(c, drag.stack), )
        r1_0, r1_1, r1_2, r1_3 = c.x, c.y, c.x + CW, c.y + CH
        sstack, sdiff, sx, sy = None, 999999999, 0, 0
",5
"                r2 = (s.x, s.y, s.x + CW, s.y + CH)
            if (r1_2 <= r2[0] or r1_3 <= r2[1] or
                    r2[2] <= r1_0 or r2[3] <= r1_1):
                # rectangles do not intersect
                continue
",5
"            diff = (r1_0 - r2[0])**2 + (r1_1 - r2[1])**2
            if diff < sdiff:
                sstack, sdiff, sx, sy = s, diff, r2[0], r2[1]
        if sstack is drag.shade_stack:
            return
",5
"                img = images.getHighlightedCard(
                    card.deck, card.suit, card.rank)
",5
"        img = MfxCanvasImage(game.canvas, sx, sy, image=img, anchor=ANCHOR_NW)
        drag.shade_img = img
        # raise/lower the shade image to the correct stacking order
        if TOOLKIT == 'tk':
            if drag.shadows:
",5
"                img.lower(drag.shadows[0])
            else:
                img.lower(drag.cards[0].item)
        elif TOOLKIT == 'gtk':
",5
"
    # for closeStack
",5
"        y1 += ch
        xx0, yy0 = x0, y0
        w, h = x1-x0, y1-y0
        #
        if TOOLKIT == 'gtk' or not Image:
",5
"        shade = markImage(shade)
        tkshade = ImageTk.PhotoImage(shade)
        im = MfxCanvasImage(self.canvas, xx0, yy0,
",5
"            s.delete()
        drag.shadows = []
",5
"            else:
                assert drag.stack is self
",5
"        if self.game.app.opt.dragcursor:
            self.canvas.config(cursor='')
        drag = self.game.drag.copy()
",5
"            self._stopDrag()
",5
"        return str(self)  # debug

    def getBaseCard(self):
",5
"        return ''

    def _getBaseCard(self, rank=None):
        # FIXME: no-french games
        if self.cap.max_accept == 0:
",5
"        elif br == 10:
            s = s % _('Jack')
        elif br == 11:
",5
"            s = s % _('Ace')
        else:
            s = s % str(br+1)
        return s

",5
"            return _('No cards')
        else:
            return ungettext('%d card', '%d cards', n) % n


",5
"            self.game.stopSamples()
        return n

    # Same, but no error if not enough cards are available.
    def dealRowAvail(self, rows=None, flip=1,
",5
"                self.game.flipMove(self)
            self.game.moveMove(1, self, r, frames=frames)
        self.game.leaveState(old_state)
",5
"            rank = self.game.s.foundations[0].cap.base_rank
",5
"        n = 0
        for r in stacks:
            assert r is not self
            while self.cards:
                n += 1
",5
"            self.game.top.waitAnimation()
        return n


",5
"class DealBaseCard_StackMethods:
    def dealSingleBaseCard(self, frames=-1, update_saveinfo=1):
        c = self.cards[-1]
",5
"        self.dealBaseCards(ncards=1, frames=frames, update_saveinfo=0)
        for s in self.game.s.foundations:
            s.cap.base_rank = c.rank
            if update_saveinfo:
",5
"                cap = Struct(base_rank=c.rank)
                self.game.saveinfo.stack_caps.append((s.id, cap))
",5
"        return c
",5
"        assert not self.base_cards
        while ncards > 0:
            assert self.cards
            c = self.cards[-1]
            for s in self.game.s.foundations:
",5
"        num_cards = self._redeal(rows=rows, reverse=reverse, frames=frames)
        if num_cards == 0:          # game already finished
            return 0
        if shuffle:
            # shuffle
",5
"            assert self.max_rounds == n + 1

",5
"        return self.game.dealCards(sound=True)

    def rightclickHandler(self, event):
        return self.clickHandler(event)
",5
"    # Actual dealing, usually called by Game.dealCards().
    # Either deal all cards in Game.startGame(), or subclass responsibility.
",5
"            if self.texts.rounds is not None:
                t = _(""Round %d"") % self.round
                self.texts.rounds.config(text=t)
        if update_redeal:
",5
"                t = (_(""Stop""), _(""Redeal""))[deal]
            if self.texts.redeal is not None and self.game.preview <= 1:
                if t != self.texts.redeal_str:
                    self.texts.redeal.config(text=t)
                    self.texts.redeal_str = t
",5
"        if self.images.redeal:
            self.canvas.delete(self.images.redeal)
",5
"        if cw >= 60 and ch >= 60:
            # add a redeal image above the bottom image
",5
"        # round = _('Round #%d.') % self.round
        return _('Talon.')+' '+nredeals  # +' '+round
",5
"        self._addRedealImage()
",5
"    def dealCards(self, sound=False):
        return self.dealRowAvail(sound=sound)
",5
"
",5
"            return False
        return not self.game.isGameWon()

",5
"    def dealCards(self, sound=False, rows=None, shuffle=False):
        num_cards = 0
        if rows is None:
",5
"            # move all cards to talon
            num_cards = self._redeal(rows=rows, frames=4)
            if shuffle:
                # shuffle
",5
"class DealReserveRedealTalonStack(DealRowRedealTalonStack):

    def canDealCards(self, rows=None):
        return DealRowRedealTalonStack.canDealCards(
            self, rows=self.game.s.reserves)
",5
"    def canDealCards(self):
        if not DealRowRedealTalonStack.canDealCards(self):
            return False
",5
"# * An OpenStack is a stack where cards can be placed and dragged
# * (i.e. FoundationStack, RowStack, ReserveStack, ...)
",5
"        # (max_move defaults to 1)
",5
"        return self.basicCanMoveCards(cards)
",5
"
    def canFlipCard(self):
",5
"        return (None, 0)
",5
"    def clickHandler(self, event):
        flipstacks, dropstacks, quickstacks = self.game.getAutoStacks(event)
        if self in flipstacks and self.canFlipCard():
            self.playFlipMove(animation=True)
",5
"            # return -1                   # continue this event (start a drag)
",5
"    def controlclickHandler(self, event):
        # highlight matching cards
        if self.game.app.opt.highlight_cards:
",5
"            return self.highlightMatchingCards(event)
        return 0

    def dragMove(self, drag, stack, sound=True):
        if self.game.app.opt.mouse_type == 'point-n-click':
",5
"
",5
"            dx, dy = event.x - drag.start_x, event.y - drag.start_y
",5
"                return
            # print dx, dy
        # get destination stack
        if self.game.app.opt.mouse_type == 'point-n-click':
",5
"                if s is not self and s.cards:
",5
"        else:
",5
"                for s in to_stacks:
                    if s is not self and s.acceptsCards(self, pile):
                        score = self.game.getQuickPlayScore(len(pile), self, s)
",5
"                  dir=1, max_accept=1, max_cards=13)
",5
"        if self.game.app.opt.quickplay:
            n = self.quickPlayHandler(event)
            self.game.stats.quickplay_moves += n
",5
"            return n
        return 0

",5
"        for s in self.game.s.foundations:
",5
"
    def varyGetBaseCard(self):
        rank = None
        for s in self.game.s.foundations:
",5
"        else:
            return _('Foundation. Build by same rank.')


",5
"class SC_FoundationStack(SS_FoundationStack):
    def __init__(self, x, y, game, suit, **cap):
        kwdefault(cap, base_suit=suit)
        SS_FoundationStack.__init__(self, x, y, game, ANY_SUIT, **cap)
",5
"                return False
        return True

",5
"            return False
        # now check the cards
",5
"    def _isSequence(self, cards):
",5
"        # cards must be an acceptable sequence
        if not self._isAcceptableSequence(cards):
            return False
",5
"
# Abstract class.
",5
"class BasicRowStack(OpenStack):
    def __init__(self, x, y, game, **cap):
        kwdefault(cap, dir=-1, base_rank=ANY_RANK)
        OpenStack.__init__(self, x, y, game, **cap)
        self.CARD_YOFFSET = game.app.images.CARD_YOFFSET
",5
"        return ''

    # def getBaseCard(self):
    #    return self._getBaseCard()
",5
"
",5
"    def __init__(self, x, y, game, **cap):
        kwdefault(cap, max_move=999999, max_accept=999999)
        BasicRowStack.__init__(self, x, y, game, **cap)
",5
"
    def getBaseCard(self):
        return self._getBaseCard()
",5
"            return _('Tableau. Build down regardless of suit.')
        else:
",5
"        elif self.cap.dir < 0:
",5
"        return len(cards) <= max_move and AC_RowStack.canMoveCards(self, cards)


# A Freecell_SameSuit_RowStack (i.e. Baker's Game)
",5
"        elif self.cap.dir < 0:
            return _('Tableau. Build down regardless of suit. '
",5
"
# A Spider_SameSuit_RowStack builds down by rank and suit,
# but accepts sequences that match by rank only.
",5
"class Yukon_AC_RowStack(BasicRowStack):
    def __init__(self, x, y, game, **cap):
        kwdefault(cap, max_move=999999, max_accept=999999)
        BasicRowStack.__init__(self, x, y, game, **cap)
",5
"
    def _isSequence(self, c1, c2):
        return ((c1.rank + self.cap.dir) % self.cap.mod == c2.rank and
                c1.color != c2.color)
",5
"
    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
            return False
        # [topcard + card[0]] must be acceptable
",5
"
    def getHelp(self):
        if self.cap.dir > 0:
",5
"                     'any face-up cards regardless of sequence.')

    def getBaseCard(self):
        return self._getBaseCard()
",5
"class Yukon_RK_RowStack(Yukon_AC_RowStack):
    def _isSequence(self, c1, c2):
        return (c1.rank + self.cap.dir) % self.cap.mod == c2.rank

",5
"    def __init__(self, x, y, game, **cap):
        kwdefault(cap, base_rank=KING)
        AC_RowStack.__init__(self, x, y, game, **cap)


",5
"

# up or down by color
class UD_SC_RowStack(SequenceRowStack):
",5
"        return (isSameColorSequence(cards, self.cap.mod, 1) or
                isSameColorSequence(cards, self.cap.mod, -1))

    def getHelp(self):
        return _('Tableau. Build up or down by color.')
",5
"

# up or down by alternate color
class UD_AC_RowStack(SequenceRowStack):
    def __init__(self, x, y, game, **cap):
",5
"        return n

",5
"

",5
"
    def acceptsCards(self, from_stack, cards):
",5
"        if not SC_RowStack.acceptsCards(self, from_stack, cards):
            return False
        return len(cards) <= self._getMaxMove(len(self.cards))


",5
"        return _('Waste.')

",5
"                self.game.playSample(""dealwaste"")
            num_cards = min(len(self.cards), self.num_deal)
            assert len(waste.cards) + num_cards <= waste.cap.max_cards
            for i in range(num_cards):
                if not self.cards[-1].face_up:
",5
"        elif waste.cards and self.round != self.max_rounds:
            if sound:
                self.game.playSample(""turnwaste"", priority=20)
            num_cards = len(waste.cards)
            self.game.turnStackMove(waste, self)
",5
"
    def shuffleAndDealCards(self, sound=False):
        WasteTalonStack.dealCards(self, sound=sound, shuffle=True)

",5
"
class FaceUpWasteTalonStack(WasteTalonStack):
    def canFlipCard(self):
        return len(self.cards) > 0 and not self.cards[-1].face_up
",5
"        return retval

",5
"        self.game.fillStack(self)

    def clickHandler(self, event):
        if self.canDealCards():
",5
"# * ReserveStack (free cell)
",5
"        x, y = game.getInvisibleCoords()
        kwdefault(cap, max_move=0, max_accept=0)
        Stack.__init__(self, x, y, game, cap=cap)

",5
"    # no bottom
    getBottomImage = Stack._getNoneBottomImage


# ************************************************************************
",5
"# * NB: this stack only for CARD_XOFFSET == 0
# ************************************************************************
",5
"    def startDrag(self, event, sound=True):
        OpenStack.startDrag(self, event, sound=sound)
        if self.game.app.opt.mouse_type == 'point-n-click':
            self.cards[self.game.drag.index].tkraise()
            self.game.drag.shadows[0].tkraise()
",5
"        else:
            for c in self.cards[self.game.drag.index+1:]:
                c.moveBy(0, -self.CARD_YOFFSET[0])
",5
"            return -1               # continue this event (start a drag)
        if self in dropstacks:
            i = self._findCard(event)
            if i < 0:
",5
"            cards = [self.cards[i]]
",5
"        return 0

",5
"            card.tkraise()

    def singleCardMove(self, index, to_stack, frames=-1, shadow=-1):
        self.game.singleCardMove(
            self, to_stack, index, frames=frames, shadow=shadow)
",5
"        self.fillStack()

    def dragMove(self, drag, to_stack, sound=True):
        self.playSingleCardMove(drag.index, to_stack, frames=0, sound=sound)
",5
"                self.game.playSample(""move"", priority=10)
        self.singleCardMove(index, to_stack, frames=frames, shadow=shadow)
",5
"            return 0
",5
"        pile = [self.cards[i]]
        for s in to_stacks:
            if s is not self and s.acceptsCards(self, pile):
                score = self.game.getQuickPlayScore(1, self, s)
                moves.append((score, -len(moves), i, s))
",5
"        self.cap = cap

",5
"    # return a new stack (an instance of the stack class)
    def __call__(self, x, y, game, **cap):
        # must preserve self.cap, so create a shallow copy
",5
"# self.cap only, call-time cap is completely ignored
class FullStackWrapper(StackWrapper):
    def __call__(self, x, y, game, **cap):
",5
"#
#  You should have received a copy of the GNU General Public License
",5
"    GC_MAHJONGG = CSI.TYPE_MAHJONGG
",5
"    GT_3DECK_TYPE = 2
    GT_4DECK_TYPE = 3
",5
"    GT_FORTY_THIEVES = 9
",5
"    GT_FREECELL = 10
",5
"    GT_GOLF = 11
    GT_GYPSY = 12
    GT_HANAFUDA = 13
",5
"    TYPE_NAMES = {
        GT_BAKERS_DOZEN:        n_(""Baker's Dozen""),
",5
"        GT_FAN_TYPE:            n_(""Fan""),
        GT_FORTY_THIEVES:       n_(""Forty Thieves""),
        GT_FREECELL:            n_(""FreeCell""),
        GT_GOLF:                n_(""Golf""),
",5
"        GT_MONTANA:             n_(""Montana""),
        GT_NAPOLEON:            n_(""Napoleon""),
        GT_NUMERICA:            n_(""Numerica""),
        GT_PAIRING_TYPE:        n_(""Pairing""),
        GT_RAGLAN:              n_(""Raglan""),
",5
"        GT_SPIDER:              n_(""Spider""),
        GT_TERRACE:             n_(""Terrace""),
        GT_YUKON:               n_(""Yukon""),
",5
"    }
",5
"        (n_(""Canfield type""),
            lambda gi, gt=GT_CANFIELD: gi.si.game_type == gt),
        (n_(""Fan type""), lambda gi, gt=GT_FAN_TYPE: gi.si.game_type == gt),
        (n_(""Forty Thieves type""),
            lambda gi, gt=GT_FORTY_THIEVES: gi.si.game_type == gt),
",5
"            lambda gi, gt=GT_SIMPLE_TYPE: gi.si.game_type == gt),
",5
"        (n_(""Three-Deck games""),
            lambda gi, gt=GT_3DECK_TYPE: gi.si.game_type == gt),
",5
"    )

    SELECT_ORIGINAL_GAME_BY_TYPE = (
",5
"    )

    SELECT_CONTRIB_GAME_BY_TYPE = (
        (n_(""French type""), lambda gi, gf=GT_CONTRIB,
",5
"    SELECT_SPECIAL_GAME_BY_TYPE = (
        (n_(""Shisen-Sho""), lambda gi, gt=GT_SHISEN_SHO: gi.si.game_type == gt),
        (n_(""Hex A Deck type""),
            lambda gi, gt=GT_HEXADECK: gi.si.game_type == gt),
        (n_(""Matrix type""), lambda gi, gt=GT_MATRIX: gi.si.game_type == gt),
",5
"        (n_(""Memory type""), lambda gi, gt=GT_MEMORY: gi.si.game_type == gt),
        (n_(""Poker type""), lambda gi, gt=GT_POKER_TYPE: gi.si.game_type == gt),
        (n_(""Puzzle type""),
            lambda gi, gt=GT_PUZZLE_TYPE: gi.si.game_type == gt),
",5
"        #         Gay gordons, Helsinki,
",5
"            100, 105, 111, 112, 113, 130, 139, 144, 146, 147, 148, 200,
            201, 206, 224, 225, 229, 230, 233, 257, 258, 280, 281, 282,
",5
"        )),

        #  KDE Patience 0.7.3 from KDE 1.1.2 (we have 6 out of 9 games)
",5
"        (""Fred Lunde"", (459,)),
        (""Albert Morehead and Geoffrey Mott-Smith"", (25, 42, 48, 173, 282,
                                                     303, 362, 547, 738)),
        (""David Parlett"", (64, 98, 294, 338, 654, 674,)),
        (""Randy Rasa"", (187, 190, 191, 192,)),
",5
"        (""3.30"", (145, 146, 147, 148, 149, 150, 151)),
        (""3.40"", (152, 153, 154)),
        (""4.00"", (157, 158, 159, 160, 161, 162, 163, 164)),
        (""4.20"", (165, 166, 167, 168, 169, 170, 171, 172, 173, 174,
",5
"                  175, 176, 177, 178)),
        (""4.30"", (179, 180, 181, 182, 183, 184)),
        (""4.41"", (185, 186, 187, 188, 189, 190, 191, 192, 193, 194,
",5
"                  195, 196, 197, 198, 199)),
        (""4.60"", (200, 201, 202, 203, 204, 205,
                  206, 207, 208, 209,
                  210, 211, 212, 213, 214, 215, 216, 217, 218, 219,
",5
"                      15420, 15421, 15422, 16000, 16001, 16002, 16003, 16004,
",5
"        ('fc-0.9.0', tuple(range(323, 421))),
        ('fc-0.9.1', tuple(range(421, 441))),
        ('fc-0.9.2', tuple(range(441, 466))),
        ('fc-0.9.3', tuple(range(466, 661))),
",5
"    _CHILDREN_GAMES = [16, 33, 55, 90, 91, 96, 97, 176, 903, ]
",5
"
    _OPEN_GAMES = []
",5
"        12,    # Braid
",5
"        158,   # Imperial Trumps
        279,   # Kings
",5
"            try:
                s = six.text_type(s, 'utf-8')
",5
"            if pysollib.settings.TRANSLATE_GAME_NAMES:
",5
"        #
",5
"        if not (1 <= category <= 9):
            if game_type == GI.GT_HANAFUDA:
                category = GI.GC_HANAFUDA
",5
"            elif game_type == GI.GT_TAROCK:
",5
"                category = GI.GC_NAVAGRAHA_GANJIFA
",5
"                     (GI.GT_OPEN, GI._OPEN_GAMES),
                     (GI.GT_POPULAR, GI._POPULAR_GAMES)):
            if (game_flags & f) and (id not in l):
                l.append(id)
",5
"        gi_si.update(si)
        #
        Struct.__init__(self, id=id, gameclass=gameclass,
                        name=name, short_name=short_name,
",5
"                        category=category, skill_level=skill_level,
                        suits=tuple(suits), ranks=tuple(ranks),
                        trumps=tuple(trumps),
",5
"    def setCallback(self, func):
        self.callback = func

    def getSelected(self):
",5
"        return self.__selected_key

",5
"        return self.__all_games.get(key)

    def _check_game(self, gi):
        # print 'check game:', gi.id, gi.short_name.encode('utf-8')
        if gi.id in self.__all_games:
",5
"        for n in gi.altnames:
",5
"                self.__gamenames[n] = gi
            # invalidate sorted lists
",5
"#                  else:
#                      print gi.id
            if hasattr(gi.gameclass, 'Solver_Class') and \
               gi.gameclass.Solver_Class is not None:
                self.__games_for_solver.append(gi.id)
",5
"        if self.callback and self._num_games % 10 == 0:
            self.callback()
",5
"
    def getAllGames(self):
        # return self.__all_games
        return list(self.__games.values())
",5
"    def getGamesIdSortedByName(self):
        if self.__games_by_name is None:
",5
"                l2.append((name, id))
                for n in gi.altnames:
                    name = n  # .lower()
                    l3.append((name, id, n))
",5
"            l1.sort()
",5
"            self.__games_by_altname = tuple([i[1:] for i in l3])
",5
"
    def getGamesForSolver(self):
        return self.__games_for_solver

",5
"def loadGame(modname, filename, check_game=False):
    # print ""load game"", modname, filename
    GAME_DB.check_game = check_game
    GAME_DB.current_filename = filename
",5
"""""""

",5
"                raise AttributeError(k)
        self.__dict__.update(kw)
#!/usr/bin/env python
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"from pysol_cards.random import LCRandom31, match_ms_deal_prefix  # noqa: I100
from pysol_cards.random import CUSTOM_BIT, MS_LONG_BIT  # noqa: I100

",5
"    ret = pysol_cards.random.MTRandom(seed)
    return ret


",5
"#  Copyright (C) 2003 Mt. Hood Playing Card Co.
#  Copyright (C) 2005-2009 Skomoroh
#
",5
"
import os
import re
",5
"from pysollib.mfxutil import Struct, destruct
from pysollib.mfxutil import USE_PIL
from pysollib.mfxutil import getprefdir, getusername
from pysollib.mfxutil import latin1_normalize, print_err
from pysollib.mfxutil import pickle, unpickle
",5
"from pysollib.mygettext import _
from pysollib.options import Options
from pysollib.pysolrandom import PysolRandom, constructRandom
from pysollib.pysoltk import HTMLViewer
",5
"from pysollib.resource import Tile, TileManager
",5
"        # visual components
",5
"        self.top_bg = None              # default background
        self.top_cursor = None          # default cursor
        self.menubar = None
        self.toolbar = None
",5
"            demo=[],                  # demo logos
            pause=[],                 # pause logos
",5
"        self.cardset = None             # current cardset
        self.cardsets_cache = {}
        self.tabletile_manager = TileManager()
        self.tabletile_index = 0        # current table tile
        self.sample_manager = SampleManager()
",5
"        self.music_manager = MusicManager()
        self.music_playlist = []
        self.intro = Struct(
            progress=None,            # progress bar
        )
",5
"        # directory names
        config = os.path.normpath(getprefdir(PACKAGE))
",5
"            opt_cfg=os.path.join(self.dn.config, ""options.cfg""),
            stats=os.path.join(self.dn.config, ""statistics.dat""),
",5
"            holdgame=os.path.join(self.dn.config, ""holdgame.dat""),
            comments=os.path.join(self.dn.config, ""comments.dat""),
        )
",5
"        # random generators
",5
"        self.gamerandom = PysolRandom()
        self.miscrandom = PysolRandom()
        # player
        player = getusername()
        if not player:
",5
"            deal=None,
        )
",5
"        except StopIteration:
            pass

",5
"                game = None
            if game:
                if game.id == self.opt.game_holded and game.gstats.holded:
                    game.gstats.loaded = game.gstats.loaded - 1
",5
"                    continue
                if self.nextgame.holdgame:
                    assert self.nextgame.id <= 0
",5
"            except Exception:
                traceback.print_exc()
",5
"
    def mainproc(self):
        # copy startup options
        self.startup_opt = self.opt.copy()
",5
"                except Exception:
",5
"                    print_err(_(""can't find game: %(game)s"") % {
                        'game': self.commandline.game})
                    sys.exit(-1)
                else:
                    self.nextgame.id = gameid
",5
"                    deal = self.commandline.deal
                    self.nextgame.random = \
                        None if deal is None else constructRandom(deal)
            elif self.commandline.gameid is not None:
",5
"        self.top.grid_columnconfigure(1, weight=1)
        self.top.grid_rowconfigure(1, weight=1)
",5
"                                    size=self.opt.toolbar_size,
                                    relief=self.opt.toolbar_relief,
                                    compound=self.opt.toolbar_compound)
        self.toolbar.show(self.opt.toolbar)
",5
"
    def runGame(self, id_, random=None):
",5
"            g = self.getGameClass(id_)
            if g is None:
                # start first available game
",5
"        # create stacks and layout
",5
"        self.toolbar.config(
            'shuffle',
",5
"            self.opt.toolbar_vars['shuffle'] and self.game.canShuffle())
        # delete intro progress bar
        if self.intro.progress:
            self.intro.progress.destroy()
            destruct(self.intro.progress)
",5
"            self.stats.gameid_balance = 0
            self.game.newGame(random=random, autoplay=0)
            autoplay = 1
        self.nextgame.loadedgame = None
        self.nextgame.bookmark = None
",5
"        if self.opt.splashscreen and self.splashscreen > 0:
            status = help_about(self, timeout=20000, sound=0)
",5
"                    self.nextgame.startdemo = 1
        self.splashscreen = 0
        # start demo/autoplay
        if self.nextgame.startdemo:
            self.nextgame.startdemo = 0
",5
"    # free game
    def freeGame(self):
",5
"        self.top.connectApp(None)

    #
",5
"                  ""joker10_100"",):
            self.gimages.logos.append(self.dataloader.findImage(f, dirname))
",5
"        else:
            dirname = os.path.join('images', 'dialog', 'bluecurve')
        for f in ('error', 'info', 'question', 'warning'):
",5
"                (_('&OK'), 'ok'),
                (_('&Cancel'), 'cancel'),
                (_('&New game'), 'new'),
            ):
",5
"                fn = self.dataloader.findImage(f, dirname)
                im = loadImage(fn)
                MfxDialog.button_img[n] = im

    def loadImages2(self):
",5
"        # load canvas images
        dirname = ""images""
        # for f in (""noredeal"", ""redeal"",):
        for f in (""stopsign"", ""redeal"",):
",5
"            fn = self.dataloader.findImage(f, dirname)
            im = loadImage(fn)
",5
"            SelectDialogTreeData.img.append(im)
",5
"        # load htmlviewer images
        dirname = os.path.join('images', 'htmlviewer')
        fn = self.dataloader.findImage('disk', dirname)
        HTMLViewer.symbols_fn['disk'] = fn

",5
"            if os.path.exists(d):
                return d
            return None
        return d
",5
"        return self._getImagesDir('cards')
",5
"                self.opt.colors['table'] = tile.color
                self.opt.tabletile_name = None
",5
"        gi = self.getGameInfo(id)
        if gi:
            if update & 256:
",5
"        if c and c[0] == cs.ident:
            # print 'load from cache', c
            self.images, self.subsampled_images = c[1], c[2]
            self.updateCardset(id, update=update)
",5
"            color = self.opt.colors['table']
            if self.tabletile_index > 0:
                color = ""#008200""
",5
"            progress = PysolProgressBar(self, self.top, title=title,
                                        color=color,
                                        images=self.progress_images)
        images = Images(self.dataloader, cs)
        try:
",5
"            self.nextgame.cardset = self.cardset
            if self.cardset:
                self.cardset_manager.setSelected(self.cardset.index)
",5
"            # images.destruct()
            destruct(images)
",5
"    def checkCompatibleCardsetType(self, gi, cs):
",5
"            t0 = ""Dashavatara Ganjifa""
            if cs_type not in (CSI.TYPE_DASHAVATARA_GANJIFA,):
",5
"                return cs, 1
        # try by gameid / category
        for key, flag in (((1, gi.id), 8), (gi.category, 4)):
",5
"                return cs, flag
        # ask
        return None, 0

    def requestCompatibleCardsetType(self, id):
",5
"        cs, cs_update_flag = self.getCompatibleCardset(gi, self.cardset)
        if cs is self.cardset:
            return 0
        if cs is not None:
",5
"            self.top, title=_(""Incompatible cardset""),
            bitmap=""warning"",
            text=_('''The currently selected cardset %(cardset)s
is not compatible with the game
%(game)s
",5
"        self.loadCardset(cs, id=id)
        return 1

",5
"             self.opt.preserve_aspect_ratio) = d.scale_values
            if not self.opt.auto_scale:
                self.images.resize(self.opt.scale_x, self.opt.scale_y)
            if d.cardset_values:
                cs.CARD_XOFFSET, cs.CARD_YOFFSET = d.cardset_values
",5
"    #
    # load & save options, and statistics
    #
",5
"            # for backwards compatibility
            opt = unpickle(self.fn.opt)
",5
"
    def saveStatistics(self):
",5
"        return self.gdb.getGamesIdSortedByName()

    ##
    def getGamesIdSortedByPlayed(self, player=''):
        if player == '':
",5
"        if player == '':
            player = self.opt.player

",5
"        games.sort(key=_key)
        return games[::-1]

    def getGamesIdSortedByPercent(self, player=''):
",5
"
        def _key(a):
            wa, la, ta, ma = self.stats.getFullStats(player, a)
",5
"        gi = self.gdb.get(id)
        if gi is None:
            return None
        return gi.gameclass
",5
"
    def _choice(self, lst):
        return self.miscrandom.choice(lst)

    def chooseRandomOutOfGames(self, games):
",5
"        return self._choice(games)

    def getRandomGameId(self):
        return self._choice(self.gdb.getGamesIdSortedById())

",5
"    def getAllUserNames(self):
        names = []
",5
"        config = CardsetConfig()
        if not self._parseCardsetConfig(config, lines):
            # print filename, 'invalid config'
",5
"            return None
",5
"        if config.CARDD > self.top.winfo_screendepth():
            return None
        cs = Cardset()
        cs.dir = dirname
        cs.update(config.__dict__)
",5
"            if len(fields) < 5:
                perr(1, msg='number of fields')
",5
"            cs.year = int(m.group(1))
        if len(cs.ext) < 2 or cs.ext[0] != ""."":
            perr(1, msg='invalid extention')
            return 0
",5
"            return 0
        cs.ident = line[1]
        m = re.search(r""^(.*;)?([^;]+)$"", cs.ident)
        if not m:
            perr(2, msg='invalid format')
",5
"        if not m:
            perr(4, msg='invalid format')
",5
"            cs.backnames.insert(0, back)
            cs.backindex = 0
        # set offsets from options.cfg
",5
"        if cs.ident in self.opt.offsets:
            cs.CARD_XOFFSET, cs.CARD_YOFFSET = self.opt.offsets[cs.ident]
        # if cs.type != 1: print cs.type, cs.name
",5
"
    def initCardsets(self):
        manager = self.cardset_manager
",5
"                    f = os.path.join(d, ""config.txt"")
                    if os.path.isfile(f):
",5
"                                          % (d, f))
                                pass
                        except Exception:
                            # traceback.print_exc()
                            pass
",5
"    # init tiles
    #
    def _init_tiles_process_dir(self, dirname, found, t):
        """"""docstring for _init_tiles_process_die""""""
",5
"            f = os.path.join(dirname, name)
",5
"    def initTiles(self):
        manager = self.tabletile_manager
        # find all available tiles
",5
"        dirs = manager.getSearchDirs(
            self,
            (""tiles-*"",
                os.path.join(""tiles"", ""stretch""),
                os.path.join(""tiles"", ""save-aspect"")),
",5
"        # register tiles
        found.sort()
        for f in found:
            obj = f[1]
",5
"        """"""docstring for _my_list_dir""""""
        if dirname and os.path.isdir(dirname):
            names = os.listdir(dirname)
            names = list(map(os.path.normcase, names))
            names.sort()
",5
"    # init samples / music
    #

    def initResource(self, manager, dirs, ext_re, Resource_Class):
",5
"                    if not os.path.isfile(f):
",5
"        dirs = manager.getSearchDirs(self, ""music-*"", ""PYSOL_MUSIC"")
",5
"# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"
from pysollib.mygettext import n_

",5
"        'preset': 'None',
        'name': n_('My Game'),
        },

",5
"        'redeals': 'Unlimited redeals',
        'rows_num': 7,
        'rows_base_card': 'King',
        'reserves_num': 0,
        'deal_type': 'Triangle',
",5
"        'skill_level': 'Mostly skill',
",5
"        'rows_max_move': 'Top card',
        'rows_super_move': 1,
        'deal_face_up': 6,
        },
",5
"
    'Spider': {
        'preset': 'Spider',
        'name': n_('My Spider'),
        'skill_level': 'Mostly skill',
",5
"        'talon': 'Deal to tableau',
",5
"        'deal_type': 'Triangle',
        'deal_face_down': 8,
        'deal_face_up': 1,
        },
",5
"
    'Simple Simon': {
        'preset': 'Simple Simon',
        'name': n_('My Simple Simon'),
        'skill_level': 'Mostly skill',
",5
"#
",5
"#  Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
#  Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"#  Copyright (C) 2005-2009 Skomoroh
#
",5
"#
# ---------------------------------------------------------------------------##
",5
"from pysollib.settings import VERSION_TUPLE

",5
"
class Statistics:
    def __init__(self):
",5
"        # returned (won, lost)
",5
"    def getFullStats(self, player, gameid):
        # returned (won, lost, playing time, moves)
",5
"            return (s.num_won+s.num_perfect,
                    s.num_lost,
                    s.time_result.average,
                    s.moves_result.average,)
",5
"    def updateGameStat(self, player, game, status):
        #
        if player not in self.games_stats:
            self.games_stats[player] = {}
        if game.id not in self.games_stats[player]:
",5
"            all_games_stat = GameStat('all')
            self.games_stats[player]['all'] = all_games_stat
",5
"            all_games_stat = self.games_stats[player]['all']
",5
"# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"#
# ---------------------------------------------------------------------------##
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    from pysollib.ui.tktile.card import *  # noqa: F401,F403
    from pysollib.ui.tktile.tkcanvas import *  # noqa: F401,F403
    from pysollib.ui.tktile.tkwrap import *  # noqa: F401,F403
    from pysollib.ui.tktile.findcarddialog import *  # noqa: F401,F403
    if USE_TILE:
",5
"        from pysollib.tk.playeroptionsdialog import *  # noqa: F401,F403
        from pysollib.tk.soundoptionsdialog import *  # noqa: F401,F403
        from pysollib.tk.timeoutsdialog import *  # noqa: F401,F403
        from pysollib.tk.colorsdialog import *  # noqa: F401,F403
",5
"        from pysollib.tk.fontsdialog import *  # noqa: F401,F403
        from pysollib.tk.solverdialog import *  # noqa: F401,F403
        from pysollib.tk.gameinfodialog import *  # noqa: F401,F403
        from pysollib.tk.toolbar import *  # noqa: F401,F403
        from pysollib.tk.statusbar import *  # noqa: F401,F403
",5
"        from pysollib.tk.progressbar import *  # noqa: F401,F403
        from pysollib.tk.menubar import *  # noqa: F401,F403
        from pysollib.tk.selectcardset import *  # noqa: F401,F403
        from pysollib.tk.selecttree import *  # noqa: F401,F403
",5
"    from pysollib.pysolgtk.selectcardset import *  # noqa: F401,F403
",5
"# the Free Software Foundation, either version 3 of the License, or
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"            self.PREFIXES = []
",5
"RANKS = (_(""Ace""), ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"",
         _(""Jack""), _(""Queen""), _(""King""))
",5
"NO_SUIT = 999999            # no card can ever match this suit
NO_COLOR = 999999           # no card can ever match this color
NO_RANK = 999999            # no card can ever match this rank
UNLIMITED_MOVES = 999999    # for max_move
",5
"#
",5
"
",5
"        for p in self.path:
            if all(os.path.isfile(os.path.join(p, fn)) for fn in filenames):
                self.dir = p
                break
",5
"            raise OSError(str(argv0)+"": DataLoader could not find "" +
                          str(filenames))
",5
"            subdirs = (subdirs,)
",5
"        raise OSError(""DataLoader could not find image ""+filename +
                      "" in ""+self.dir+"" ""+str(subdirs))

    def findAllIconSizes(self, filename='pysol.png'):
        try:
",5
"                         if f not in icon_blacklist]
            except OSError:
                icons = []
        return filter(os.path.isfile, icons)
",5
"#!/usr/bin/env python
",5
"# -*- mode: python; coding: utf-8; -*-
",5
"#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
",5
"        if os.name == 'nt':
            lang, enc = locale.getdefaultlocale()
",5
"    locale.setlocale(locale.LC_ALL, '')

    # install gettext
    locale_locations = (
",5
"
    for par in locale_locations:
",5
"    # debug
",5
"            # bundles, so we hide it here.
            from pysollib.macosx.appSupport import hideTkConsole
            hideTkConsole(root)
        #
",5
"            except tkinter.TclError:
                pass
            else:
",5
"            pysollib.settings.FCS_COMMAND = fcs_command
            f = os.path.join('freecell-solver', 'presetrc')
            os.environ['FREECELL_SOLVER_PRESETRC'] = f
    if os.name in ('posix', 'nt'):
",5
"        try:
            kw = {'shell': True,
                  'stdout': subprocess.PIPE,
",5
"# -*- mode: python; coding: utf-8; -*-
",5
"#
# This program is distributed in the hope that it will be useful,
",5
"from pysollib.mygettext import _

from six.moves import range

",5
"

class PysolStatsFormatter:

    def getStatHeader(self):
",5
"    def getStatResults(self, player, sort_by='name'):
",5
"        if won + lost > 0:
            if won > 0:
                time = format_time(ttime/tgames)
",5
"        self.avrg_moves = moves
        self.percent = perc
        # yield (_(""Total (%d out of %d games)"") % (tgames, len(g)),
        #       won+lost, won, lost, time, moves, perc, '')
",5
"        return self.total_games, \
               self.played_games, \
               self.won_games, \
",5
"    def getLogResults(self, player, prev_games):
        t_won, tlost = 0, 0
",5
"            if len(pg) == 5:
",5
"            if pg[2] >= 0:
                won = pg[2] > 0
                t_won, tlost = t_won + won, tlost + (1 - won)
            status = ""*error*""
            if -2 <= pg[2] <= 2:
",5
"                status = (_(""Loaded""), _(""Not won""), _(""Lost""),
                          _(""Won""), _(""Perfect""))[pg[2]+2]
            # writer.plog(name, gamenumber, date, status, gameid=gameid,
            #   won=pg[2])
            yield [name, gamenumber, date, status, pg[2], gameid]
",5
"
class FileStatsFormatter(PysolStatsFormatter):

    def __init__(self, app, file):
        self.app = app
",5
"    def nl(self, count=1):
        self.p(""\n"" * count)

",5
"        self.p(s)

    def plog(self, gamename, gamenumber, date, status, gameid=-1, won=-1):
        self.p(""%-25s %-20s  %17s  %s\n"" %
",5
"        self.writeHeader(header, 62)
        header = self.getStatHeader()
",5
"
    def writeLog(self, player, header, prev_games):
        if not player or not prev_games:
",5
"        return self.writeLog(player, header, prev_games)
",5
"
",5
"
# ************************************************************************
# *
# ************************************************************************
",5
"class ProgressionFormatter:

    def __init__(self, app, player, gameid):
",5
"            return
        for g in games:
            id = g[0]
",5
"            status = g[2]
            start_time = g[3]
",5
"            t[0] -= 1
            lt = self.norm_time(t)
",5
"            marks = [lt[:3], t[:3]]
            while t > lt:
                t[1] -= d
                t = self.norm_time(t)
                marks.append(t[:3])
",5
"            delta = 7
            format = '%d.%m.%y'

        res = []
",5
"                    won += results[t][1]
                ct[2] -= 1
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"
",5
"# ************************************************************************
# *
# ************************************************************************

",5
"solver_dialog = solver_dialog


",5
"        if name in self.gamenames:
            self.start_button.config(state='normal')
",5
"            self.games_var.set(name)
",5
"

",5
"def create_solver_dialog(parent, game):
",5
"        # traceback.print_exc()
",5
"
",5
"# *
",5
"        self._label_column = 0
        #
        self.padx = 1
",5
"        label = getattr(self, name + '_label')
        label.config(**kw)
",5
"
",5
"            ('stats',       _('Games played: won/lost'),  12),
                ):
            self._createLabel(n, tooltip=t, width=w)
",5
"
# ************************************************************************
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"
from .tkwidget import MfxDialog

",5
"
class SelectUserNameDialog(MfxDialog):
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
",5
"        self.createBitmaps(top_frame, kw)
",5
"        self.update_stats_var = tkinter.BooleanVar()
        self.update_stats_var.set(app.opt.update_player_stats != 0)
",5
"        frame.pack(expand=True, fill='both', padx=5, pady=10)
        widget = tkinter.Label(frame, text=_(""\nPlease enter your name""),
                               # justify='left', anchor='w',
",5
"                                command=self.selectUserName)
        widget.grid(row=1, column=1, padx=5, pady=5)
",5
"        frame.columnconfigure(0, weight=1)
        #
        self.player = self.player_var.get()
        self.confirm = self.confirm_var.get()
",5
"        #
        focus = self.createButtons(bottom_frame, kw)
        self.mainloop(focus, kw.timeout)
",5
"        self.win_animation = self.win_animation_var.get()
        raise SystemExit

    def initKw(self, kw):
",5
"import os

from pysollib.mfxutil import Image, ImageTk
from pysollib.mygettext import _, n_
from pysollib.settings import TITLE
",5
"from pysollib.ui.tktile.menubar import MfxMenu, createToolbarMenu
from pysollib.ui.tktile.tkconst import EVENT_HANDLED
from pysollib.util import IMAGE_EXTENSIONS
from pysollib.winsystems import TkSettings
",5
"                      column=self.position,
",5
"            self.grid(row=self.position,
                      column=0,
                      ipadx=padx, ipady=pady,
                      sticky='nsew')

",5
"        tkinter.Checkbutton.__init__(self, parent, kwargs)
        AbstractToolbarButton.__init__(
            self, parent, toolbar, toolbar_name, position)


",5
"        self.toolbar = toolbar
        self.position = position
        self.visible = False

    def show(self, orient, force=False):
",5
"                      column=self.position,
                      padx=padx, pady=pady,
",5
"        tkinter.Message.__init__(self, parent, **kwargs)
        self.toolbar = toolbar
",5
"        self.visible = False
",5
"# * Note: Applications should call show/hide after constructor.
",5
"class PysolToolbarTk:
",5
"        self.top = top
        self.menubar = menubar
",5
"        self.frame = tkinter.Frame(top, relief=TkSettings.toolbar_relief,
                                   bd=TkSettings.toolbar_borderwidth)
        #
",5
"        sep.bind(""<1>"", self.clickHandler)
        sep.bind(""<3>"", self.rightclickHandler)
",5
"        self._createLabel(""player"", label=n_('Player'),
",5
"        self.popup = MfxMenu(master=None, label=n_('Toolbar'), tearoff=0)
        createToolbarMenu(menubar, self.popup)
        self.frame.bind(""<1>"", self.clickHandler)
",5
"                else:
                    w.show(orient=self.orient)
            elif isinstance(w, ToolbarFlatSeparator):
",5
"                               relief=TkSettings.toolbar_separator_relief)
        sep.show(orient=self.orient)
        self._widgets.append(sep)
",5
"        return sep

    def _createFlatSeparator(self):
        position = len(self._widgets)
        sep = ToolbarFlatSeparator(self.frame,
",5
"        button_relief = TkSettings.toolbar_button_relief
",5
"        if image:
            kw['image'] = image
        if check:
",5
"        if tooltip:
            b = MfxTooltip(button)
            self._tooltips.append(b)
            b.setText(tooltip)
",5
"        return button

    def _createLabel(self, name, label=None, tooltip=None):
",5
"        aspect = (400, 300)[self.getSize() != 0]
        position = len(self._widgets)
",5
"        self._tooltips = []
        for w in self._widgets:
",5
"    def updateText(self, **kw):
        for name in kw.keys():
            label = getattr(self, name + ""_label"")
",5
"                name = w.toolbar_name
                image = self._loadImage(name)
                data.append((name, w, image))
        except Exception:
",5
"
",5
"    def _setOrient(self, orient='horizontal', force=False):
        if not force and self.orient == orient:
",5
"            return False
        for w in self._widgets:
            if w.visible:
",5
"    # Mouse event handlers
    #

    def clickHandler(self, event):
",5
"        if self._busy():
            return EVENT_HANDLED
",5
"    def middleclickHandler(self, event):
        if self._busy():
            return EVENT_HANDLED
        if 1 <= self.side <= 2:
            self.menubar.setToolbarSide(3 - self.side)
",5
"        return EVENT_HANDLED

",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"# ************************************************************************
",5
"
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------

",5
"from pysollib.mfxutil import KwStruct
from pysollib.mygettext import _
",5
"        self.highlight_cards_sleep_var.set(app.opt.timeouts['highlight_cards'])
        self.highlight_samerank_sleep_var = tkinter.DoubleVar()
        self.highlight_samerank_sleep_var.set(
",5
"                               self.highlight_cards_sleep_var),
                           (_('Highlight same rank:'),
",5
"        #
        focus = self.createButtons(bottom_frame, kw)
        self.mainloop(focus, kw.timeout)
        #
        self.demo_timeout = self.demo_sleep_var.get()
",5
"                      )
",5
"        return MfxDialog.initKw(self, kw)
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"# *
# ************************************************************************


",5
"    def __init__(self, parent, title, app, **kw):
        self.app = app
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
",5
"        self.sound_mode = tkinter.BooleanVar()
        self.sound_mode.set(app.opt.sound_mode != 0)
",5
"        #
        row = 0
        w = tkinter.Checkbutton(frame, variable=self.sound,
                                text=_(""Sound enabled""), anchor='w')
        w.grid(row=row, column=0, columnspan=2, sticky='ew')
",5
"            w = tkinter.Scale(frame, from_=0, to=128, resolution=1,
",5
"        frame = tkinter.LabelFrame(top_frame, text=_('Enable samles'),
",5
"        frame.columnconfigure(0, weight=1)
        frame.columnconfigure(1, weight=1)
        #
        row = 0
",5
"        col = 0
",5
"            w.grid(row=row, column=col, sticky='ew')
            if col == 1:
                col = 0
                row += 1
",5
"            self.app.opt.sound_sample_volume = self.sample_volume.get()
            self.app.opt.sound_music_volume = self.music_volume.get()
            for n, t, v in self.samples:
                self.app.opt.sound_samples[n] = v.get()
",5
"        elif button == 2:
            self.app.opt = self.saved_opt
        if self.app.audio:
",5
"Changing DirectX settings will take effect
the next time you restart """""")+TITLE,
            bitmap=""warning"",
",5
"from pysollib.tk.basetkmfxdialog import BaseTkMfxDialog
from pysollib.ui.tktile.colorsdialog import BaseColorsDialog
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"import os
",5
"class SingleGame_StatsDialog(MfxDialog):
    def __init__(self, parent, title, app, player, gameid, **kw):
        self.app = app
",5
"    #

    def _calc_tabs(self):
        #
",5
"        #           font.measure(_(""Lost:"")),
        #           font.measure(_(""Total:"")))
        t1 += 10
",5
"            pwon = float(won) / (won + lost)
            pwon = min(max(pwon, 0.00001), 0.99999)
            plost = 1.0 - pwon
",5
"        return pwon, plost

    def _createChartInit(self, text):
",5
"        #
",5
"            x, ty[0]-dy, text=""%d"" % won, anchor=""ne"", font=tfont, fill=fg)
",5
"            c.create_text(
                x, ty[1]-dy, text=""%d%%"" % (100-pw), anchor=""ne"", font=tfont,
                fill=fg)

",5
"#          p = list(p[:])
",5
"#              dx = int(round(p[j][0] * perc))
#              dy = int(round(p[j][1] * perc))
#              p[j] = (p[i][0] + dx, p[i][1] + dy)
#          # draw rects
#          def draw_rect(a, b, c, d, col, canvas=canvas, p=p):
",5
"#          #  draw_line(3, 7)     # test
#          draw_line(4, 5)
#          draw_line(5, 6)
#          draw_line(6, 7)
#          draw_line(7, 4)
",5
"#          image = app.gimages.stats[0]
#          iw, ih = image.width(), image.height()
#          #c, tfont, fg = self._createChartInit(frame, iw+160, ih, text)
#          self._createChartInit(iw+160, ih, text)
",5
"#          self._createChartTexts(tx, ty, won, lost)
#          c.create_text(tx[0], ty[0]-48, text=self.player, anchor=""nw"",
#          font=tfont, fill=fg)

",5
"        kw = KwStruct(
            kw,
",5
"        self.canvas.dialog.nodes[id] = (self.gameid, self.gamenumber)

    def _calc_tabs(self, arg):
",5
"        header = self.getLogHeader()
        t1, t2, t3, t4 = header
        s = ""%-25s %-20s  %-17s  %s"" % header
        id = self.canvas.create_text(1, y, text=s, anchor=""nw"",
",5
"    def writeFullLog(self, player):
        prev_games = self.app.stats.prev_games.get(player)
        return self.writeLog(player, prev_games)

",5
"    def writeSessionLog(self, player):
        prev_games = self.app.stats.session_games.get(player)
        return self.writeLog(player, prev_games)
",5
"

",5
"# ************************************************************************
# *
# ************************************************************************

",5
"        # if parent and parent.winfo_screenheight() < 600:
        #    lines = 20
        #
",5
"        #
        self.player = player
        self.title = title
",5
"            top_frame, width=kw.width, height=kw.height)
        self.sc.pack(fill='both', expand=True, padx=kw.padx, pady=kw.pady)
        #
        self.nodes = {}
",5
"        dx, dy = 4, 0
        self.canvas.config(scrollregion=(-dx, -dy, bbox[2]+dx, bbox[3]+dy))
",5
"        self.canvas.xview_moveto(-dx)
",5
"        self.mainloop(focus, kw.timeout)

    def initKw(self, kw):
        kw = KwStruct(
            kw,
",5
"        return MfxDialog.initKw(self, kw)

    def destroy(self):
        self.app = None
",5
"
    def singleClick(self, event=None):
",5
"        writer.writeStats(player, self.sort_by)
",5
"
    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(_(""&OK""), (_(""Session &log...""), 104),
",5
"
    def initKw(self, kw):
        kw = KwStruct(
            kw,
",5
"            strings=(_(""&OK""), (_(""&Full log...""), 103),
                     (_(""&Save to file""), 204)),
            default=0,)
        return FullLog_StatsDialog.initKw(self, kw)
",5
"        for s in game.s.foundations:
            n = n + len(s.cards)
        w1 = (_(""Highlight piles: "") + str(stats.highlight_piles) + ""\n"" +
",5
"                w2 = w2 + _(""\nRedeals: "") + str(game.s.talon.round - 1)
            w2 = w2 + _(""\nCards in Talon: "") + str(len(game.s.talon.cards))
",5
"            w2 = w2 + _(""\nCards in Foundations: "") + str(n)
",5
"            self, parent, title=_(""Game status""),
            text=game.getTitleName() + ""\n"" +
            game.getGameNumber(format=1) + ""\n"" +
            _(""Playing time: "") + game.getTime() + ""\n"" +
",5
"            _(""Started at: "") + date + ""\n\n"" +
            _(""Moves: "") + str(game.moves.index) + ""\n"" +
            _(""Undo moves: "") + str(stats.undo_moves) + ""\n"" +
",5
"            _(""Bookmark moves: "") + str(gstats.goto_bookmark_moves) + ""\n"" +
            _(""Demo moves: "") + str(stats.demo_moves) + ""\n"" +
",5
"class _TopDialog(MfxDialog):
    def __init__(self, parent, title, top, **kw):
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
",5
"        frame = tkinter.Frame(**cnf)
",5
"        cnf['text'] = _('Result')
        label = tkinter.Label(**cnf)
        label.grid(row=0, column=3, sticky='ew')
",5
"            # Game number
            cnf['text'] = '#'+str(i.game_number)
",5
"class Top_StatsDialog(MfxDialog):
    def __init__(self, parent, title, app, player, gameid, **kw):
        self.app = app
",5
"        self.createBitmaps(top_frame, kw)

        frame = tkinter.Frame(top_frame)
",5
"            gameid in app.stats.games_stats[player] and
",5
"                 ),
                (_('Moves:'),
                 s.moves_result.min,
",5
"                 s.moves_result.max,
",5
"                 round(s.moves_result.average, 2),
                 s.moves_result.total,
                 s.moves_result.top,
                 ),
",5
"            #                 round(s.score_result.average, 2),
            #                 s.score_result.top,
            #                 ))
            #  if s.score_casino_result.min:
            #      ll.append(('Casino Score:',
",5
"            #                 s.score_casino_result.min,
            #                 s.score_casino_result.max,
            #                 round(s.score_casino_result.average, 2), ))
",5
"
        focus = self.createButtons(bottom_frame, kw)
",5
"        self.mainloop(focus, kw.timeout)

    def showTop(self, top):
",5
"                      strings=(_('&OK'),),
                      default=0,
                      image=self.app.gimages.logos[4],
",5
"        frame = tkinter.Frame(top_frame)
        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

",5
"        self.top_margin = 15+self.text_height
        self.bottom_margin = 15+self.text_height+10+self.text_height
",5
"        canvas.create_text(x1+4, y1-4, anchor='s', text=_('% won'))

        # caption
        d = self.text_height
        x, y = self.xmargin, self.canvas_height-self.ymargin
",5
"        canvas.create_rectangle(x, y, x+d, y-d, outline='black',
                                fill=self.played_color)
        x += d+5
        canvas.create_text(x, y, anchor='sw', text=_('Played'))
",5
"        x += measure(_('Played'))+20
        canvas.create_rectangle(x, y, x+d, y-d, outline='black',
                                fill=self.won_color)
",5
"        var.set('all')
        b = tkinter.Radiobutton(right_frame, text=_('All games'),
                                variable=var, value='all',
                                command=self.updateGraph,
",5
"        b = tkinter.Radiobutton(right_frame, text=_('Current game'),
                                variable=var, value='current',
",5
"                                command=self.updateGraph,
                                variable=self.played_graph_var,
                                justify='left', anchor='w'
                                )
",5
"        b.pack(fill='x', expand=True, padx=3, pady=1)
        self.percent_graph_var = tkinter.BooleanVar()
        self.percent_graph_var.set(True)
        b = tkinter.Checkbutton(label_frame, text=_('% won'),
",5
"        return MfxDialog.initKw(self, kw)

    def updateGraph(self, *args):
        interval = self.variable.get()
        canvas = self.canvas
",5
"        x0, y0 = self.left_margin, self.canvas_height-self.bottom_margin
        x1, y1 = self.canvas_width-self.right_margin, self.top_margin
",5
"        for res in result:
            if res[0] is not None and x > xx+self.text_width+4:
                # id = canvas.create_line(x, y0, x, y0-5, width=3)
                # self.items.append(id)
                id = canvas.create_line(x, y0, x, y1, stipple='gray50')
",5
"            else:
                id = canvas.create_line(x, y0, x, y0-3, width=1)
                self.items.append(id)
",5
"            x += dx

        # horizontal scale
        max_games = max([i[1] for i in result])
",5
"        if self.won_graph_var.get():
            id = canvas.create_line(fill=self.won_color, width=3,
",5
"                                    *won_coords)
            self.items.append(id)
",5
"        if self.percent_graph_var.get():
            id = canvas.create_line(fill=self.percent_color, width=3,
                                    *percent_coords)
            self.items.append(id)
#!/usr/bin/env python
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"
import os
import sys

",5
"if __name__ == '__main__':
    d = os.path.abspath(os.path.join(sys.path[0], '..', '..'))
",5
"        return MfxMessageDialog

    def __init__(self, parent, app=None, home=None):
        self.parent = parent
        self.app = app
",5
"            index=0,
",5
"        self.backButton = tkinter.Button(parent, text=_(""Back""),
",5
"        text_frame.grid(row=1, column=0, columnspan=4, sticky='nsew')
        text_frame.grid_propagate(False)
        vbar = tkinter.Scrollbar(text_frame)
        vbar.pack(side='right', fill='y')
        self.text = tkinter.Text(text_frame,
",5
"        self.text[""yscrollcommand""] = vbar.set
",5
"    return 0


",5
"# * - menu actions
# ************************************************************************

",5
"        return connect_game_find_card_dialog(game)

    def _destroy_find_card_dialog(self):
        return destroy_find_card_dialog()

",5
"        return SelectGameDialog

    def _calcSelectGameDialogWithPreview(self):
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"
import os
",5
"
from .tkwidget import MfxScrolledCanvas
",5
"    def __init__(self, tree, parent_node, text, key):
        self.tree = tree
        self.parent_node = parent_node
        self.text = text
",5
"        self.subnodes = None
        # canvas item ids
        self.symbol_id = None
        self.text_id = None
",5
"            self.tree.keys[self.key] = lst

    def whoami(self):
        if self.parent_node is None:
            return (self.text, )
",5
"        self.drawSymbol(topleftx, toplefty)
        linestart = style.distx + style.width + 5
        self.text_id = -1
        self.drawText(x + linestart, y)
        return x, y, x, y + style.disty
",5
"        elif self.selected:
            b = canvas.bbox(self.text_id)
            self.textrect_id = canvas.create_rectangle(
",5
"
    #
    #
    #

",5
"        lx, ly, nx, ny = MfxTreeBaseNode.draw(self, x, y, ilastx, ilasty)
        if self.expanded:
            style = self.tree.style
            childx = nx + style.distx + style.width // 2
            childy = ny
",5
"    def drawSymbol(self, x, y, **kw):
        color = kw.get(""color"")
        if color is None:
            if self.expanded:
",5
"                color = ""red""
            else:
                color = ""pink""
",5
"        for node in self.keys.get(self.selection_key, []):
            node.selected = 0
        MfxScrolledCanvas.destroy(self)

    def findNode(self, event=None):
",5
"    #

    def draw(self):
",5
"        # and the yscrollincrement works nicely.
",5
"        nx = nx - self.style.distx
        ny = ny + self.style.height // 2
        for node in self.rootnodes:
            # update tree
            node.tree = self
",5
"        bbox = self.canvas.bbox(""all"")
        # self.canvas.config(scrollregion=bbox)
",5
"        oldcur = self.canvas[""cursor""]
        self.canvas[""cursor""] = ""watch""
        self.canvas.update_idletasks()
        self.clear()
",5
"    #
",5
"    def getContents(self, node):
        # Overload this, supposed to return a list of subnodes of node.
        pass

",5
"    #

",5
"    def updateSelection(self, key):
        l1 = self.keys.get(self.selection_key, [])
        l2 = self.keys.get(key, [])
        for node in l1:
            if node.selected and node not in l2:
",5
"                node.updateSymbol()
                node.updateText()
        self.selection_key = key
",5
"        if isinstance(dirs, str):
            dirs = (dirs,)
        for dir in dirs:
",5
"    def singleClick(self, event=None):
",5
"        if not node:
            return
        print(""Clicked node %s %s"" % (node.text, node.key))
        if isinstance(node, MfxTreeLeaf):
",5
"            node.expanded = not node.expanded
            self.redraw()
        return ""break""


",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"
from pysollib.mfxutil import KwStruct
from pysollib.mygettext import _
from pysollib.tk.tkwidget import MfxDialog
",5
"
        self.font_family = 'Helvetica'
        self.font_size = 12
",5
"        self.font_weight = 'normal'
        self.font_slant = 'roman'

",5
"                    if init_font[3] in ['bold', 'normal']:
                        self.font_weight = init_font[3]
                    elif init_font[2] in ['italic', 'roman']:
                        self.font_slant = init_font[3]
                    else:
",5
"        self.weight_var = tkinter.BooleanVar()
        self.slant_var = tkinter.BooleanVar()
        self.size_var = tkinter.IntVar()

",5
"                                  variable=self.slant_var)
        cb2.grid(row=3, column=0, columnspan=2, sticky='we')
",5
"
        sc = tkinter.Scale(frame, from_=6, to=40, resolution=1,
                           # label='Size',
",5
"        font_families = list(tkinter_font.families())
        font_families.sort()
        selected = -1
",5
"        self.font = (self.font_family, self.font_size,
                     self.font_slant, self.font_weight)

    def fontupdate(self, *args):
",5
"        if self.list_box.curselection():
            self.font_family = self.list_box.get(self.list_box.curselection())
",5
"        self.createBitmaps(top_frame, kw)

        frame = tkinter.Frame(top_frame)
        frame.pack(expand=True, fill='both', padx=5, pady=10)
",5
"                          ('small',          _('Small: ')),
",5
"    """"""
",5
"    def __init__(self, parent, pageNames=[], **kw):
        """"""
",5
"
",5
"            return
",5
"    tkinter.Label(tabPage.pages['Foobar']['page'], text='Bar', pady=20).pack()
    tkinter.Label(tabPage.pages['Baz']['page'], text='Baz').pack()
",5
"    buttonRemove.pack(padx=5, pady=5)
    labelPgName.pack(padx=5)
    entryPgName.pack(padx=5)
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"from .selecttree import SelectDialogTreeLeaf, SelectDialogTreeNode
from .tkwidget import MfxDialog, MfxScrolledCanvas
",5
"    def _getContents(self):
        contents = []
        for obj in self.tree.data.all_objects:
            if self.select_func(obj):
",5
"                SelectTileLeaf(None, None, _(""Navy""), key=""#000086""),
                SelectTileLeaf(None, None, _(""Olive""), key=""#868200""),
                SelectTileLeaf(None, None, _(""Orange""), key=""#f79600""),
                SelectTileLeaf(None, None, _(""Teal""), key=""#008286""),
            ), expanded=e1),
",5
"    def __init__(self, parent, title, app, manager, key=None, **kw):
        kw = self.initKw(kw)
",5
"        frame.pack(fill='both', expand=True,
                   padx=kw.padx-padx, pady=kw.pady-pady)
        self.tree = self.Tree_Class(self, frame, key=key,
                                    default=kw.default,
                                    font=font, width=w1)
",5
"        if button == 1:        # ""Solid color...""
            try:
                c = tkinter_colorchooser.askcolor(
                    master=self.top,
",5
"                if c and c[1]:
                    color = str(c[1])
",5
"                    self.key = color.lower()
                    self.table_color = self.key
                    self.tree.updateSelection(self.key)
                    self.updatePreview(self.key)
            return
",5
"            # solid color
            canvas.config(bg=key)
            canvas.setTile(None)
            canvas.setTextColor(None)
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"#
# You should have received a copy of the GNU General Public License
",5
"# ---------------------------------------------------------------------------##

",5
"        self.cframe = tkinter.Frame(self.frame, relief='sunken', bd=1,
                                    takefocus=0)
        self.canvas = tkinter.Canvas(self.cframe, width=width, height=height,
                                     takefocus=0, bd=0, highlightthickness=0)
        self.scale = self.canvas.create_rectangle(-10, -10, 0, height,
",5
"        else:
            self.update(percent=0)
        self.norm = norm
",5
"        self.top.destroy()
        self.top = None
",5
"
",5
"        if self.text >= 0:
",5
"
def progressbar_main(args):
    from pysollib.ui.tktile.tkutil import wm_withdraw
",5
"    import sys
    sys.exit(progressbar_main(sys.argv))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"#
# ---------------------------------------------------------------------------
",5
"
",5
"from pysollib.ui.tktile.tkutil import makeToplevel, setTransient
",5
"# * abstract base class for the dialogs in this module
# ************************************************************************
",5
"    def destroy(self):
        after_cancel(self.timer)
        unbind_destroy(self.top)
        try:
",5
"        sep = len(kw.strings) > 1
        kwdefault(kw.__dict__, separator=sep)
        return kw

",5
"            separator.pack(side='bottom', fill='x')
        top_frame = tkinter.Frame(self.top)
",5
"        elif kw.image:
            b = tkinter.Label(frame, image=kw.image)
            b.pack(side=kw.image_side, padx=kw.image_padx, pady=kw.image_pady)
",5
"
    def createButtons(self, frame, kw):
        button = -1
",5
"        elif max_len > 6:
            button_width = max_len+2
        else:
            button_width = 8
        # print 'button_width =', button_width
",5
"            if s is None:
",5
"
# ************************************************************************
# * replacement for the tk_dialog script
# ************************************************************************
",5
"        self._url = kw['url']
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
",5
"                            width=kw.width)
        msg.pack(fill='both', expand=True)

",5
"
",5
"        kw = KwStruct(kw,
                      strings=(_(""&OK""), _(""&Cancel"")), default=0,
                      separator=False,
                      )
",5
"
# ************************************************************************
# * a simple tooltip
",5
"        self.xoffset = 0
        self.yoffset = 4

",5
"        after_cancel(self.cancel_timer)
        self.cancel_timer = None
        if time.time() - MfxTooltip.last_leave_time < self.leave_timeout/1000.:
",5
"        #          return
        # x = self.widget.winfo_rootx()
",5
"        x = self.widget.winfo_pointerx()
        y = self.widget.winfo_rooty() + self.widget.winfo_height()
",5
"        x += self.xoffset
        y += self.yoffset
        self.tooltip = tkinter.Toplevel()
",5
"        self.tooltip.wm_iconify()
        self.tooltip.wm_overrideredirect(1)
",5
"                                   relief=self.relief, justify=self.justify,
",5
"# * A canvas widget with scrollbars and some useful bindings.
# ************************************************************************

",5
"            return False
        # print i, tile
        if i == 0:
            assert tile.color
",5
"            assert tile.filename is None
",5
"        else:
            assert tile.color is None
",5
"                return False
        #
",5
"            self.canvas.config(bg=tile.color)
",5
"            # app.top.config(bg=tile.color)
        else:
",5
"        return True

",5
"
",5
"
",5
"        if w is None:
            w = self.canvas
        bind(w, ""<KeyPress-Prior>"", self.page_up)
        bind(w, ""<KeyPress-Next>"", self.page_down)
        bind(w, ""<KeyPress-Up>"", self.unit_up)
",5
"            bind(w, '<5>', self.mouse_wheel_down)
        # don't work on Linux
        # bind(w, '<MouseWheel>', self.mouse_wheel)
",5
"
    def _setHbar(self, first, last):
        if self.canvas.busy:
",5
"        return 'break'
",5
"        return self._yview('moveto', 1)
",5
"        self.game = game
        self.stack = stack
        self.canvas = game.canvas
        self.bindings = []

",5
"            self.frame = frame
            label = tkinter.Message(frame, font=font, text=text,
",5
"            self.bindings.append(
                label.bind('<ButtonPress>', self._buttonPressEvent))
",5
"        if self.id:
            self.canvas.delete(self.id)
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"
                def callback(v, w=w):
                    return self.presetSelected(v, w)
                om = tkinter.OptionMenu(frame, w.variable,
                                        command=callback, *values)
",5
"                values = [_(v) for v in w.values]
                om = tkinter.OptionMenu(frame, w.variable, *values)
",5
"                    w.variable = tkinter.IntVar()
",5
"
        notebook.ChangePage()
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"#
# ---------------------------------------------------------------------------##

import os
",5
"from pysollib.resource import CSI
from pysollib.ui.tktile.selecttree import SelectDialogTreeData
from pysollib.ui.tktile.tkcanvas import MfxCanvasImage
from pysollib.ui.tktile.tkutil import loadImage
from pysollib.util import CARDSET
",5
"
",5
"# * Nodes
# ************************************************************************
",5
"class SelectCardsetData(SelectDialogTreeData):
    def __init__(self, manager, key):
        SelectDialogTreeData.__init__(self)
",5
"        self.all_objects = [obj for obj in self.all_objects if not obj.error]
        self.no_contents = [SelectCardsetLeaf(
            None, None, _(""(no cardsets)""), key=None), ]
",5
"        nodes = []
        for key, name in items:
            if manager.registered_styles.get(key):
                nodes.append(
                    SelectCardsetNode(
",5
"        #
        self.rootnodes = [_f for _f in (
            SelectCardsetNode(
                None, _(""All Cardsets""),
",5
"                    None, _(""Large cardsets""),
",5
"            ), expanded=1),
            select_by_type,
            select_by_style,
",5
"

# ************************************************************************
# * Dialog
",5
"    TreeDataHolder_Class = SelectCardsetTree
    TreeData_Class = SelectCardsetData

",5
"            var = tkinter.DoubleVar()
            var.set(app.opt.scale_y)
            self.scale_y = tkinter.Scale(
                left_frame, label=_('Scale Y:'),
                from_=0.5, to=4.0, resolution=0.1,
",5
"                variable=self.auto_scale,
                takefocus=False,
                command=self._updateAutoScale
                )
",5
"
    def destroy(self):
        self.tree.updateNodesWithTree(self.tree.rootnodes, None)
",5
"        return MfxDialog.initKw(self, kw)

    def mDone(self, button):
        if button in (0, 1):            # Load/Cancel
",5
"
    def _updateAutoScale(self, v=None):
        if self.auto_scale.get():
            self.aspect_check.config(state='normal')
",5
"        self.preview_images = []
        cs = self.manager.get(key)
        if not cs:
            self.preview_key = -1
",5
"            return
        names, columns = cs.getPreviewCardNames()
",5
"        for image in self.preview_images:
            if USE_PIL:
",5
"            if i % columns == 0:
                x, y = 10, y + dy
            else:
                x = x + dx
        canvas.config(scrollregion=(0, 0, sx+dx, sy+dy),
",5
"        frame = tkinter.Frame(top_frame)
        frame.pack(fill=""both"", expand=True, padx=5, pady=10)
        #
        #
        info_frame = tkinter.LabelFrame(frame, text=_('About cardset'))
",5
"        info_frame.grid(row=0, column=0, columnspan=2, sticky='ew',
                        padx=0, pady=5, ipadx=5, ipady=5)
",5
"                                       for i in cardset.si.nationalities])
        if cardset.year:
            year = str(cardset.year)
        row = 0
",5
"        for n, t in (
",5
"            # ('Version:', str(cardset.version)),
",5
"            (_('Nationality:'),   nationalities),
            (_('Year:'),          year),
            # (_('Number of cards:'), str(cardset.ncards)),
",5
"                label.grid(row=row, column=0, sticky='nw')
                label = tkinter.Label(info_frame, text=t,
                                      anchor='w', justify='left')
                label.grid(row=row, column=1, sticky='nw')
",5
"            try:
                from random import choice
                im = choice(images)
                f = os.path.join(cardset.dir, cardset.backname)
                self.back_image = loadImage(file=f)
",5
"        return MfxDialog.initKw(self, kw)
from pysollib.tk.tkwidget import MfxDialog

from six.moves import tkinter

",5
"    def _calcToolkit(self):
        return tkinter

",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"

",5
"class SelectGameNode(SelectDialogTreeNode):
",5
"        else:
",5
"        return contents or self.tree.data.no_games
",5
"        self.no_games = [SelectGameLeaf(None, None, _(""(no games)""), None), ]
        #
        s_by_type = s_oriental = s_special = s_original = s_contrib = \
            s_mahjongg = None
",5
"                     GI.SELECT_SPECIAL_GAME_BY_TYPE,
                     GI.SELECT_ORIGINAL_GAME_BY_TYPE,
                     GI.SELECT_CONTRIB_GAME_BY_TYPE,
",5
"        if list(filter(select_mahjongg_game, self.all_games_gi)):
            gg = SelectGameNode(None, _(""Mahjongg Games""),
                                select_mahjongg_game)
        g.append(gg)
",5
"        for name, games in GI.GAMES_BY_COMPATIBILITY:
            def select_func(gi, games=games):
                return gi.id in games
            if name is None or not list(filter(
                    select_func, self.all_games_gi)):
",5
"        for name, games in GI.GAMES_BY_PYSOL_VERSION:
",5
"            s_by_pysol_version = SelectGameNode(None, _(""by PySol version""),
                                                tuple(gg))
        s_by_inventors, gg = None, []
",5
"                               lambda gi: gi.skill_level == GI.SL_SKILL),
                )),
            SelectGameNode(None, _(""by Game Feature""), (
                SelectGameNode(None, _(""by Number of Cards""), (
                    SelectGameNode(None, _(""32 cards""),
",5
"                                   lambda gi: gi.si.ncards == 32),
                    SelectGameNode(None, _(""48 cards""),
",5
"                                   lambda gi: gi.si.ncards == 64),
                    SelectGameNode(None, _(""78 cards""),
                                   lambda gi: gi.si.ncards == 78),
",5
"                    SelectGameNode(None, _(""No redeal""),
                                   lambda gi: gi.si.redeals == 0),
",5
"                    SelectGameNode(None, _(""1 redeal""),
                                   lambda gi: gi.si.redeals == 1),
                    SelectGameNode(None, _(""2 redeals""),
                                   lambda gi: gi.si.redeals == 2),
                    SelectGameNode(None, _(""3 redeals""),
",5
"                s_by_compatibility,
            )),
            s_by_pysol_version,
            s_by_inventors,
",5
"                               lambda gi: gi.si.game_flags & GI.GT_SCORE),
                SelectGameNode(
                    None, _(""Games with Separate Decks""),
                    lambda gi: gi.si.game_flags & GI.GT_SEPARATE_DECKS),
                SelectGameNode(None, _(""Open Games (all cards visible)""),
",5
"            )),
            s_original,
            s_contrib,
",5
"        #
        self.app = app
",5
"                                    font=font, default=kw.default)
",5
"        self.mainloop(focus, kw.timeout)
",5
"
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(None, None, _(""&Cancel""),), default=0,
                      resizable=True,
",5
"            doc = self.app.getGameRulesFilename(self.tree.selection_key)
            if not doc:
",5
"        self.gameid = gameid
        self.bookmark = bookmark
        self.random = None
        if self.TreeDataHolder_Class.data is None:
            self.TreeDataHolder_Class.data = self.TreeData_Class(app)
",5
"                         ipadx=padx, ipady=pady, sticky='nws')
        # Info
        self.info_labels = {}
        for n, t, f, row in (
",5
"            text_label.grid(row=row, column=1, sticky='nw')
            self.info_labels[n] = (title_label, text_label)
        # info_frame.columnconfigure(1, weight=1)
        info_frame.rowconfigure(6, weight=1)
",5
"        self.preview.setTile(app, app.tabletile_index, force=True)
",5
"        right_frame.columnconfigure(1, weight=1)
        right_frame.rowconfigure(1, weight=1)
",5
"        # focus = self.tree.frame
        self.mainloop(focus, kw.timeout)

    def initKw(self, kw):
",5
"                top_cursor=self.app.top_cursor,
                toolbar=None,
",5
"            self.preview_app.opt.shadow = 0
            self.preview_app.opt.shade = 0
        #
        self.preview_app.audio = None    # turn off audio for initial dealing
        if animations >= 0:
",5
"        # self.top.wm_title(""Select Game - "" +
        #   self.app.getGameTitleName(gameid))
        title = self.app.getGameTitleName(gameid)
",5
"        canvas.xview_moveto(0)
        canvas.yview_moveto(0)
",5
"        if self.app.opt.animations:
            self.preview_app.opt.animations = 10
        else:
            self.preview_app.opt.animations = 0
",5
"            rules_button.config(state=""disabled"")

    def updateInfo(self, gameid):
",5
"            GI.SL_SKILL:        _('Skill only'),
            }
        skill_level = sl.get(gi.skill_level)
",5
"        elif gi.redeals == -1:
            redeals = _('unlimited')
        else:
            redeals = str(gi.redeals)
        # stats
",5
"            percent = ""0.0""
",5
"            ('played',      won+lost),
            ('won',         won),
",5
"                text_label.grid_remove()
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"    pass
",5
"    pass
#!/usr/bin/env python
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"class BasicStatusbar:
    def __init__(self, top, row, column, columnspan):
        self.top = top
",5
"

# ************************************************************************
",5
"        for n, t, w in (
            (""time"",        _(""Playing time""),            10),
",5
"                ):
",5
"from tkwidget import MfxDialog
",5
"class PlayerOptionsDialog(MfxDialog):
",5
"    def __init__(self, parent, title, app, **kw):
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, **kw)
",5
"        self.confirm_quit_check = gtk.CheckButton(_('Confirm quit'))
        self.confirm_quit_check.show()
        top_box.pack_start(self.confirm_quit_check)
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"
",5
"        self.dir = dir
",5
"    #
    # wrappers
    #

    def _busy(self):
",5
"        # set orient
        if side in (1, 2):
            orient = gtk.ORIENTATION_HORIZONTAL
",5
"        else:
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# ---------------------------------------------------------------------------##

import gtk
import gtk.glade

",5
"from pysollib.mygettext import _

# ************************************************************************
# *
# ************************************************************************
",5
"            'highlight_cards',
",5
"            def callback(w, n=n):
                sp = self.widgets_tree.get_widget(n+'_spinbutton')
                sc = self.widgets_tree.get_widget(n+'_scale')
",5
"                sp.set_value(sc.get_value())
",5
"                sc.set_value(sp.get_value())
            dic[n+'_spinbutton_value_changed'] = callback
",5
"
        for n in keys:
",5
"            v = app.opt.timeouts[n]
            w = self.widgets_tree.get_widget(n+'_spinbutton')
",5
"            setattr(self, n+'_timeout', w.get_value())

        dialog.destroy()

    def _translateLabels(self):
",5
"            'label29',
            'label30',
                ):
            w = self.widgets_tree.get_widget(n)
",5
"    _selected_row = None
",5
"        sw.add(treeview)
        treeview.set_rules_hint(True)
        treeview.set_headers_visible(False)
        renderer = gtk.CellRendererText()
        renderer.set_property('xalign', 0.0)
",5
"        selection = treeview.get_selection()
        selection.connect('changed', parent.showSelected)
        treeview.connect('unrealize', self._unrealizeEvent)

",5
"
    def _restoreSettings(self):
",5
"            selection = self.treeview.get_selection()
            # selection.select_path(self._selected_row)
",5
"    def _loadExpandedRows(self):
        for path in self._expanded_rows:
            self.treeview.expand_to_path(path)

",5
"        index = model.get_value(iter, 1)
        return index

    def unselectAll(self):
",5
"        selection = self.treeview.get_selection()
        selection.unselect_all()
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"        table = self.widgets_tree.get_widget('samples_table')
        samples_checkbuttons = {}
        row = 0
        col = 0
",5
"        w.set_value(app.opt.sound_music_volume)

",5
"        dialog.set_title(title)
        dialog.set_transient_for(parent)
",5
"                app.opt.sound_music_volume = w.get_value()
                for n, t in keys:
                    w = samples_checkbuttons[n]
                    app.opt.sound_samples[n] = w.get_active()
",5
"                    app.audio.playSample('drop', priority=1000)
            if response != gtk.RESPONSE_APPLY:
                dialog.destroy()
",5
"        for n in (
            'label76',
            'label77',
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"import gtk.glade
from gtk import gdk

",5
"
class ColorsDialog:
",5
"
    def __init__(self, parent, title, app, **kw):

",5
"
        self.status = -1
        self.button = -1
",5
"        label = self.widgets_tree.get_widget(name+'_label')
",5
"        dialog.set_transient_for(self.dialog)
        dialog.set_position(gtk.WIN_POS_CENTER_ON_PARENT)
        dialog.colorsel.set_current_color(gdk.color_parse(color))
        response = dialog.run()
",5
"            self._setColor(name, c)
",5
"        dialog.destroy()

",5
"            'label31',
            'label32',
",5
"            'label52',
            'label53',
            'label79',
               ):
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"# ************************************************************************


class StatsFormatter(PysolStatsFormatter):
",5
"        return 1


class LogFormatter(PysolStatsFormatter):
    MAX_ROWS = 10000
",5
"            iter = self.store.append(None)
",5
"                           3, result[3],
",5
"        return 1

",5
"class Game_StatsDialog:

",5
"        self.gameid = gameid
        self.games = {}
",5
"                gi = app.gdb.get(id)
                self.games[n] = gi
                self.games_id.append(id)
",5
"        # current session
",5
"        self._createGameCombo(table, 1, 0, self._top10ComboChanged)
        self._createTop()
        self._updateTop(gameid)
",5
"        dialog.set_position(gtk.WIN_POS_CENTER_ON_PARENT)
        dialog.set_transient_for(parent)
        dialog.resize(500, 340)
",5
"            'label12',
",5
"        table.attach(combo,
                     x, x+1,                y, y+1,
                     gtk.FILL | gtk.EXPAND,   0,
                     4,                     4)
        #
",5
"            if id == self.gameid:
                current = n
",5
"        y -= dy//2

",5
"            win.draw_arc(gc, False, x, y+dy, w, h, s*64, ewon*64)
",5
"            gc.set_foreground(colormap.alloc_color('#800000'))
            win.draw_arc(gc, True, x, y+dy, w, h, (s+ewon)*64, elost*64)
            gc.set_foreground(colormap.alloc_color('black'))
",5
"            win.draw_arc(gc, False, x, y+dy, w, h, (s+ewon)*64, elost*64)
",5
"
    def _createTop(self):
        for n in ('top_10_time_treeview',
                  'top_10_moves_treeview',
                  'top_10_total_moves_treeview'):
",5
"                gameid not in s[self.player] or
                not s[self.player][gameid].time_result.top)
        if cond:
",5
"            return

        s = s[self.player][gameid]

",5
"        label.set_text(str(s.moves_result.max))
        label = self.widgets_tree.get_widget('moves_average_label')
        label.set_text(str(round(s.moves_result.average, 2)))

",5
"                              gobject.TYPE_STRING,  # result
                              )
        treeview.set_model(store)
        n = 0
",5
"        for i in top:
            t = time.strftime('%Y-%m-%d %H:%M',
                              time.localtime(i.game_start_time))
            if isinstance(i.value, float):
                # time
",5
"            else:
",5
"            row += 1
",5
"        for label in (
            _('Game'),
            _('Played'),
            _('Won'),
",5
"            column = gtk.TreeViewColumn(label, gtk.CellRendererText(),
                                        text=n)
            column.set_resizable(True)
",5
"            column.set_sort_column_id(n)
            treeview.append_column(column)
            n += 1
        #
",5
"                                        text=n)
",5
"                              gobject.TYPE_INT,     # gameid
                              )
        treeview.set_model(store)
",5
"        t2 = map(int, val2.split(':'))
        return cmp(len(t1), len(t2)) or cmp(t1, t2)
",5
"
    def _cmpMoves(self, store, iter1, iter2):
        val1 = store.get_value(iter1, 5)
        val2 = store.get_value(iter2, 5)
        return cmp(float(val1), float(val2))
",5
"
",5
"        date = time.strftime('%Y-%m-%d %H:%M',
                             time.localtime(game.gstats.start_time))
        MfxMessageDialog.__init__(
            self, parent, title=_('Game status'),
            text=game.getTitleName() + '\n' +
",5
"            game.getGameNumber(format=1) + '\n' +
            _('Playing time: ') + game.getTime() + '\n' +
            _('Started at: ') + date + '\n\n' +
            _('Moves: ') + str(game.moves.index) + '\n' +
",5
"            _('Undo moves: ') + str(stats.undo_moves) + '\n' +
            _('Bookmark moves: ') + str(gstats.goto_bookmark_moves) + '\n' +
",5
"import htmllib
import os
import sys
",5
"import traceback
",5
"import pango

",5
"
",5
"# ************************************************************************
# *
# ************************************************************************
",5
"    def anchor_end(self):
",5
"            self.text.apply_tag(tag, start, end)

            self.anchor = None

",5
"        # ~ width = int(int(self.text['width']) * 0.9)
        width = 70
",5
"        self.write('\n')
",5
"
class tkHTMLParser(htmllib.HTMLParser):
",5
"            self.anchor = None
        self.formatter.writer.anchor_end()

",5
"        self.textview.connect('leave-notify-event', self.leave_event)
        self.textview.connect('enter-notify-event', self.motion_notify_event)

        self._changed_cursor = False
",5
"
        # cursor
        self.defcursor = gdk.XTERM
        self.handcursor = gdk.HAND2
",5
"        parent.show_all()
        gobject.idle_add(gtk.main)
",5
"            self.statusbar.pop(0)
        return False
",5
"            traceback.print_exc()
            default_font = ('times new roman', 12)
            fixed_font = ('courier', 12)
        size = default_font[1]
        sign = 1
",5
"            'h3': (default_font[0], size + 6*sign, 'bold'),
            'h4': (default_font[0], size + 4*sign, 'bold'),
            'h5': (default_font[0], size + 2*sign, 'bold'),
",5
"            'h6': (default_font[0], size + 1*sign, 'bold'),
",5
"            font = self.fontmap[tag_name]
",5
"        # set default font
        fd = pango.FontDescription(default_font[0]+' '+str(default_font[1]))
        if 'bold' in default_font:
",5
"    def basejoin(self, url, baseurl=None, relpath=1):
        if baseurl is None:
",5
"                break
",5
"        # ftp: and http: would work if we use urllib, but this widget is
        # far too limited to display anything but our documentation...
        for p in REMOTE_PROTOCOLS:
",5
"        # locate the file relative to the current url
",5
"        url = self.basejoin(url, relpath=relpath)

        # read the file
        try:
            file = None
",5
"            if 0:
                import urllib
                file = urllib.urlopen(url)
            else:
",5
"
        writer = tkHTMLWriter(self.textbuffer, self, self.app)
        fmt = formatter.AbstractFormatter(writer)
",5
"            u, pos = self.history.list[self.history.index-1]
            if u == url:
                self.updateHistoryXYView()
                return
",5
"
    def goForward(self, *event):
        if self.history.index < len(self.history.list):
",5
"        if self.home and self.home != self.url:
            self.updateHistoryXYView()
            self.display(self.home, relpath=0)

    def errorDialog(self, msg):
",5
"        self.images[fn] = img
        return img

",5
"    viewer.display(url)
    top.connect('destroy', lambda w: gtk.main_quit())
    gtk.main()
    return 0
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"import os
import re

",5
"import gtk
from gtk import gdk
",5
"# * - create menubar
",5
"    # create menubar
    #

    def m(self, *args):
",5
"            ('file',           None, ltk2gtk('&File')),
            ('recentgames',    None, ltk2gtk('R&ecent games')),
            ('favoritegames',  None, ltk2gtk('Fa&vorite games')),
            ('select',         None, ltk2gtk('&Select')),
            ('edit',           None, ltk2gtk('&Edit')),
",5
"            ('game',           None, ltk2gtk('&Game')),
            ('assist',         None, ltk2gtk('&Assist')),
            ('options',        None, ltk2gtk('&Options')),
",5
"            ('cardview',       None, ltk2gtk('Card &view')),
            ('toolbar',        None, ltk2gtk('&Toolbar')),
            ('statusbar',      None, ltk2gtk('Stat&usbar')),
",5
"            # menuitems
            ('playablepreview', None,
",5
"            ('addtofavorites', None,
             ltk2gtk('A&dd to favorites'), None,
             None, self.mAddFavor),
",5
"            ('status', None,
             ltk2gtk('S&tatus...'),  'T',
             None, self.mStatus),
            ('hint', None,
",5
"            ('tabletile', None,
             ltk2gtk('Table t&ile...'), None,
             None, self.mOptTableTile),
            ('fonts', None,
",5
"            ('aboutpysol', None,
             ltk2gtk('&About ')+TITLE+'...',
",5
"            ('pause', gtk.STOCK_STOP,            # action, stock
             ltk2gtk('&Pause'), 'P',             # label, accelerator
             ltk2gtk('Pause game'),              # tooltip
             self.mPause,                        # callback
             False,                              # initial value
",5
"            ]
",5
"            ('Startup splash sc&reen',  '', 'splashscreen',           False),
            ('&Show removed tiles (in Mahjongg games)', '',
",5
"            if not action:
                action = re.sub(r'[^0-9a-zA-Z]', '', label).lower()
",5
"                 None, None,
                 lambda w, o=opt_name, u=update_game: self.mOptToggle(w, o, u),
",5
"          ('animationmedium',   None, ltk2gtk('&Medium'),      None, None, 3),
          ('animationslow',     None, ltk2gtk('&Slow'),        None, None, 4),
          ('animationveryslow', None, ltk2gtk('V&ery slow'),   None, None, 5),
",5
"          )
        mouse_entries = (
          ('draganddrop',   None, ltk2gtk('&Drag-and-Drop'),   None, None, 0),
          ('pointandclick', None, ltk2gtk('&Point-and-Click'), None, None, 1),
",5
"        action_group.add_radio_actions(animations_entries,
                                       self.app.opt.animations,
                                       self.mOptAnimations)
        t = ['drag-n-drop', 'point-n-click', 'sticky-mouse'].index(
",5
"                                       self.mOptMouseType)
        action_group.add_radio_actions(toolbar_side_entries,
",5
"        self._createSelectMenu(games, menu)

        if not self.app.audio.CAN_PLAY_SOUND:
            item = ui_manager.get_widget('/menubar/options/sound')
",5
"
    def _getNumGames(self, games, select_data):
        ngames = 0
        for label, select_func in select_data:
",5
"            label = gi.name
        menu_item = gtk.MenuItem(label)
        menu_item.set_data('user_data', gi.id)
        menu_item.connect('activate', self.mSelectGame)
",5
"        for gi in games:
",5
"        n, d = 0, self._cb_max
",5
"        i = 0
        while True:
",5
"                break
            m = min(n+d-1, len(games)-1)
            n1, n2 = games[n].name, games[m].name
            label = n1[:3]+' - '+n2[:3]
",5
"
    def _addPopularGamesMenu(self, games, menu):
        def select_func(gi):
            return gi.si.game_flags & GI.GT_POPULAR
",5
"        mahjongg_games = filter(select_func, games)
        if len(mahjongg_games) == 0:
            return
",5
"            if not games:
                return
",5
"            submenu = self._createSubMenu(menu, label=label)
            self._addGamesSubMenu(games, submenu, short_name=True)
        #
",5
"        path_map = {
            'help.rulesforthisgame': '/menubar/help/rules',
            'options.automaticplay.autodrop':
                '/menubar/options/automaticplay/optautodrop'
",5
"        if path in path_map:
            path = path_map[path]
        else:
            path = '/menubar/'+path.replace('.', '/')
        menuitem = self.top.ui_manager.get_widget(path)
",5
"    #
    # menu actions
    #

    def mAddFavor(self, w):
",5
"        gameid = self.app.game.id
        if gameid in self.app.opt.favorite_gameid:
            self.app.opt.favorite_gameid.remove(gameid)
",5
"        item = self.top.ui_manager.get_widget(
",5
"        menu.foreach(checkFavor)
        #
        for gameid in games:
            if gameid not in menu_games:
",5
"            item = gtk.MenuItem(_('Empty'))
            item.show()
            item.set_sensitive(False)
",5
"            filename = None
        d.destroy()
",5
"        if self._cancelDrag(break_pause=False):
            return
",5
"                filename += '-01'
            filename += '.pso'
        idir, ifile = os.path.split(os.path.normpath(filename))
        if not idir:
",5
"    def mSelectGameDialogWithPreview(self, *event):
        if self._cancelDrag(break_pause=False):
            return
",5
"                                        manager=self.app.tabletile_manager,
                                        key=key)
",5
"        key = self.app.nextgame.cardset.index
        d = SelectCardsetDialogWithPreview(
            self.top, title=_('Select cardset'),
            app=self.app, manager=self.app.cardset_manager, key=key)
        cs = self.app.cardset_manager.get(d.key)
",5
"                self.game.quitGame(bookmark=1)

    def mOptToggle(self, w, opt_name, update_game):
",5
"        self.app.opt.__dict__[opt_name] = w.get_active()
        if update_game:
            self.game.endGame(bookmark=1)
            self.game.quitGame(bookmark=1)

",5
"    def mOptNegativeBottom(self, w):
        if self._cancelDrag():
",5
"        self.app.opt.animations = w1.get_current_value()

",5
"        self.app.opt.mouse_type = t
",5
"        if self._cancelDrag(break_pause=False):
",5
"        # FIXME
        pass

    def _setPauseMenu(self, v):
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"find_card_dialog = None


def create_find_card_dialog(parent, game, dir):
",5
"

def connect_game_find_card_dialog(game):
",5
"def destroy_find_card_dialog():
    pass
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"# ---------------------------------------------------------------------------
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"import gtk
import gtk.glade

import pango
",5
"            'fixed',
            'canvas_default',
            'canvas_fixed',
            'canvas_large',
            'canvas_small',
",5
"            )
",5
"            button.connect('clicked', self._changeFont, n)

        self._translateLabels()

        dialog = self.widgets_tree.get_widget('fonts_dialog')
",5
"        self.dialog = dialog
        dialog.set_title(title)
",5
"        dialog.set_transient_for(parent)

        self.status = -1
        self.button = -1
",5
"        self.fonts = {}
",5
"    def _setFont(self, name, font):
        label = self.widgets_tree.get_widget(name+'_label')
",5
"        label.set_data('user_data', font)
",5
"
    def _changeFont(self, w, name):
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"
",5
"        if stack is self.hide_stack:
            return
        self.item.hide()
",5
"
class _OneImageCard(_HideableCard):
    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
        _HideableCard.__init__(self, id, deck, suit, rank, game, x=x, y=y)
",5
"        images = game.app.images
",5
"        if self.face_up:
            self.__image.config(image=self.__back_image)
            self.tkraise(unhide)
            self.face_up = 0
",5
"
    def updateCardBackground(self, image):
        self.__back.config(image=image)
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"        self.table_color = app.opt.colors['table']
        # paned
",5
"        #
        self.preview = MfxCanvas(top_box)  # width=w2
",5
"        self.show_all()
        gtk.main()

    def rowActivated(self, w, row, col):
        # FIXME
",5
"            return None
        return self.all_keys[index]

    def showSelected(self, w):
",5
"            child_iter = model.append(iter)
            model.set(child_iter, 0, _('(no tiles)'), 1, -1)

",5
"                  padx=10, pady=10,
                  width=600, height=400,
",5
"                  )
        return MfxDialog.initKw(self, kw)

    def _colorselOkClicked(self, w, d):
        c = d.colorsel.get_current_color()
",5
"        setTransient(win, self)
        win.show()
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"        self.top = makeToplevel(parent, title=title)
        self.top.set_position(gtk.WIN_POS_CENTER)
        self.top.set_resizable(False)
        self.top.connect(""delete_event"", self.wmDeleteWindow)

",5
"        # hbox
        hbox = gtk.HBox(spacing=5)
        hbox.set_border_width(10)
        hbox.show()
        self.top.table.attach(hbox,
",5
"        # hbox-1: image
        if images and images[0]:
            im = gtk.Image()
            im.set_from_pixbuf(images[0].pixbuf)
",5
"        w, h = self.pbar.size_request()
        self.pbar.set_size_request(max(w, 300), max(h, height))
",5
"        # self.steps_sum += step
        # print self.steps_sum, self.norm
",5
"        self.pbar.set_text(str(percent)+'%')
",5
"    def update_idletasks(self):
        while gtk.events_pending():
",5
"            gtk.main_iteration()

    def wmDeleteWindow(self, *args):
        return True
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"        self.status = 0
        self.hide()
        self.destroy()
        gtk.main_quit()

",5
"
class MfxDialog(_MyDialog):
    img = {}
",5
"            im.set_property('xpad', kw['bitmap_padx'])
            im.set_property('ypad', kw['bitmap_pady'])
",5
"
    def createButtons(self, box, kw):
        strings, default = kw['strings'], kw['default']
",5
"                  image=None, image_side=""left"",
",5
"        self.status = 0
        self.button = button.get_data(""user_data"")
",5
"
",5
"        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, **kw)
",5
"
# ************************************************************************
# *
# ************************************************************************

",5
"    def __init__(self, app, parent, title, **kw):
        self._url = kw['url']
",5
"            '<span foreground=""blue"" underline=""single"">%s</span>' % kw['url'])

        event_box = gtk.EventBox()
        box.pack_start(event_box)
",5
"        event_box.window.set_cursor(gdk.Cursor(gdk.HAND2))
        gtk.main()

    def initKw(self, kw):
",5
"        if isinstance(ex, EnvironmentError) and ex.filename is not None:
            t = '[Errno %s] %s:\n%s' % \
                (ex.errno, ex.strerror, repr(ex.filename))
        else:
",5
"# ************************************************************************
",5
"        button.set_flags(gtk.CAN_DEFAULT)
        self.action_area.pack_start(button)
        button.show()
        button.grab_default()
        button = gtk.Button(""Cancel"")
",5
"        button.connect(""clicked"", self.quit)
        button.set_flags(gtk.CAN_DEFAULT)
        self.action_area.pack_start(button)
        button.show()

",5
"
",5
"# ---------------------------------------------------------------------------##

# imports

",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"        # self.add(self.vbox)
        self.table = gtk.Table(3, 6, False)
        self.add(self.table)
",5
"            if k in (""background"", ""bg""):
                # print ""Toplevel configure: bg""
                pass
            elif k == ""cursor"":
",5
"
    def winfo_screenheight(self):
",5
"        return gdk.screen_height()

    def winfo_screendepth(self):
        # print 'winfo_screendepth', self.window.get_geometry()
",5
"        return self.window.get_geometry()[-1]

    def wm_command(self, *args):
        # FIXME
",5
"    def wm_iconname(self, name):
        pass
        # ~ self.set_icon_name(name)

    def wm_minsize(self, width, height):
",5
"
    def option_add(self, *args):
        # print self, 'option_add'
        pass
",5
"# * The root toplevel window of an application.
",5
"        sw, sh = self.winfo_screenwidth(), self.winfo_screenheight()
        # self.wm_group(self)
        self.wm_title(TITLE + ' ' + VERSION)
        # self.wm_iconname(TITLE + ' ' + VERSION)
        if sw < 640 or sh < 480:
",5
"            pass
        return True
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"
class SelectCardsetDialogWithPreview(MfxDialog):
    _cardset_store = None

    def __init__(self, parent, title, app, manager, key=None, **kw):
",5
"        hpaned.pack1(treeview.scrolledwindow, True, True)
        # treeview.treeview.expand_all()
        # right
",5
"        # self.scrolledwindow = sw
        #
        self.preview = MfxCanvas(self)
        self.preview.show()
",5
"        store.set(iter, 0, root_label, 1, -1)
        for index, name in cardsets:
",5
"            child_iter = store.append(iter)
            # ~ name = _(name)
            store.set(child_iter, 0, name, 1, index)

    def _addCardsetsByType(self, store, root_label, all_cardsets,
",5
"            cardsets = []
            for cs in all_cardsets:
                si = getattr(cs.si, selecter_type)
                if isinstance(si, int):  # type
",5
"                    if key == si:
                        cardsets.append((cs.index, cs.name))
                else:  # style, nationality, date
",5
"                              gobject.TYPE_INT)
        manager = self.manager
        all_cardsets = manager.getAllSortedByName()
        all_cardsets = [obj for obj in all_cardsets if not obj.error]

",5
"        store.set(root_iter, 0, _('by Size'), 1, -1)
        for label, selecter in (
",5
"                f = os.path.join(cs.dir, n + cs.ext)
                self.preview_images.append(loadImage(file=f))
        except Exception:
            self.preview_key = -1
            self.preview_images = []
",5
"        self.preview_key = key
",5
"    def done(self, button):
        b = button.get_data('user_data')
        if b == 2:
            self.createInfo()
            return
",5
"from gtk import gdk

# ************************************************************************
# * constants
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"
import gtk
from gtk import gdk

",5
"
def wm_withdraw(window):
    window.hide()
",5
"    window.show()


def makeToplevel(parent, title=None, class_=None, gtkclass=gtk.Window):
    window = gtkclass()
",5
"
def setTransient(window, parent, relx=0.5, rely=0.3, expose=1):
    window.realize()
    # ~ grab_add(window)
    if parent:
",5
"            self.pixbuf = gdk.Pixbuf(gdk.COLORSPACE_RGB,
                                     True, 8, width, height)
            if fill:
                c = gdk.color_parse(fill)
                c = '%02x%02x%02xffL' % (c.red, c.green, c.blue)
",5
"        pixbuf = self.pixbuf.scale_simple(w, h, gdk.INTERP_BILINEAR)
",5
"def copyImage(image, x, y, width, height):
    # FIXME
    return image.clone()


",5
"    # FIXME
    return None
",5
"    return e.type == gdk.BUTTON_PRESS and e.button == 2


def _wrap_b3_press(e):
    return (e.type == gdk.BUTTON_PRESS and e.button == 3 and
",5
"
def _wrap_b1_motion(e):
    return e.type == gdk.MOTION_NOTIFY and (e.state & gdk.BUTTON_PRESS_MASK)

",5
"

def _wrap_leave(e):
    return e.type == gdk.LEAVE_NOTIFY

",5
"#      if not _wrap_handlers.has_key(seq):
#          _wrap_handlers[seq] = lambda e, key=c: _wrap_key_press(e, key)
#  import pprint; pprint.pprint(_wrap_handlers)
",5
"        lst = [(wrap, func)]
",5
"def unbind_destroy(widget):
    k = id(widget)
    if k in __bindings:
        #  FIXME
",5
"# Some background information:
",5
"#
#   - Each card is a canvas group consisting of a background and foreground
#     image. Turning a card raises the respective image within that group.
#
",5
"gdk = gtk.gdk

# ************************************************************************
# * canvas items
# *
",5
"
    def bbox(self):
        #  FIXME
",5
"        return (0, 0, 0, 0)

    def delete(self):
        if self._item is not None:
            self._item.destroy()
",5
"    def lower(self, positions=None):
",5
"    def tkraise(self, positions=None):
        # print 'tkraise', positions
        if positions is None:
            self._item.raise_to_top()
            self._item.get_property('parent').raise_to_top()
",5
"        else:
            # print self, 'tkraise', positions
            # self._item.raise_to_top()
            self._item.raise_to_top()  # positions)
",5
"
    def move(self, x, y):
        self._item.move(x, y)
",5
"
    def show(self):
        if self._item:
            self._item.show()
",5
"
    def hide(self):
        if self._item:
            self._item.hide()
        self._is_hidden = True
",5
"
    def connect(self, signal, func, args):
        # print '_CanvasItem.connect:', self, signal
        self._item.connect('event', func, args)
",5
"
",5
"                               anchor=anchor)
        self._item.show()

    def config(self, image):
        # ~ assert isinstance(image.im, GdkImlib.Image)
",5
"        self._item.set(pixbuf=image.pixbuf)


class MfxCanvasLine(_CanvasItem):
",5
"    def __init__(self, canvas, *points, **kw):
",5
"        _CanvasItem.__init__(self, canvas)
        kwargs = {}
",5
"        if 'arrowshape' in kw:
            kwargs['arrow_shape_a'] = kw['arrowshape'][0]
            kwargs['arrow_shape_b'] = kw['arrowshape'][1]
            kwargs['arrow_shape_c'] = kw['arrowshape'][2]
        if 'group' in kw:
",5
"        else:
            group = canvas.root()
        self._item = group.add(gnomecanvas.CanvasLine,
                               points=points, **kwargs)
        self._item.show()
",5
"
",5
"            kw['width_pixels'] = width
        if fill:
",5
"        _CanvasItem.__init__(self, canvas)
        self._x, self._y = x, y
        if preview < 0:
            preview = canvas.preview
        if preview > 1:
",5
"            self._item = None
            return
        anchor = anchor_tk2gtk(anchor)
",5
"        canvas._text_items.append(self)
        self._item.show()

",5
"    def __setitem__(self, key, value):
        if key == 'fill':
            self._item.set(fill_color=value)
        elif key == 'font':
",5
"    def config(self, **kw):
        for k, v in kw.items():
            self[k] = v

",5
"        # self.connect('destroy', self.destroyEvent)

",5
"        # print '_sizeAllocate', rect.x, rect.y, rect.width, rect.height
        if self._width > 0:
            w = self._width
            h = min(self._height, rect.height)
",5
"        print('TkCanvas bind:', sequence)
        return

    def cget(self, attr):
",5
"        if attr == 'cursor':
            # FIXME
            return gdk.LEFT_PTR
            # return self.get_window().get_cursor(v)
        elif attr == 'width':
",5
"    def winfo_height(self):
",5
"        return self.get_size()[1]

    def configure(self, **kw):
        height, width = -1, -1
        for k, v in kw.items():
",5
"
",5
"
    def pack(self, **kw):
        self.show()

    # PySol extension
",5
"            if (i == app.tabletile_index and
",5
"                    tile.color == app.opt.colors['table']):
                return False
",5
"
        return True
",5
"            self.realize()
            # return False
",5
"        # print 'setBackgroundImage', filename
        if filename is None:
            if self.__tileimage:
",5
"            bg_pixbuf = gdk.Pixbuf(pixbuf.get_colorspace(),
",5
"                                   pixbuf.get_has_alpha(),
                                   pixbuf.get_bits_per_sample(),
",5
"                    x += w
                y += h

        w = self.root().add(gnomecanvas.CanvasPixbuf,
",5
"        else:
            pixbuf = image.pixbuf
        w, h = self.get_size()
        iw, ih = pixbuf.get_width(), pixbuf.get_height()
",5
"    def update_idletasks(self):
        # print 'MfxCanvas.update_idletasks'
        # gdk.window_process_all_updates()
",5
"    def updateAll(self):
        print('Canvas - updateAll')
        for i in self._all_items:
            i._item.hide()
        self.update_now()
",5
"        self.top.table.attach(
            self,
            1, 2,                   2, 3,
            gtk.EXPAND | gtk.FILL,  gtk.EXPAND | gtk.FILL | gtk.SHRINK,
",5
"        self._width, self._height = width, height
        self.set_size_request(width, height)
        # self.set_size(width, height)
",5
"        # self.queue_resize()
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"
# imports
import os

import gobject
",5
"from pysollib.gamedb import GI
from pysollib.help import help_html
from pysollib.mfxutil import Struct, destruct
",5
"from pysoltree import PysolTreeView

from tkcanvas import MfxCanvas

from tkutil import unbind_destroy
",5
"            ('time',        _('Playing time:'),     stats_frame,  3),
            ('moves',       _('Moves:'),            stats_frame,  4),
            ('percent',     _('% won:'),            stats_frame,  5),
",5
"        # canvas
        self.preview = MfxCanvas(self)
        self.preview.show()
",5
"        self.preview.setTile(app, app.tabletile_index, force=True)

        # set the scale factor
",5
"        self.preview.preview = 2
        # create a preview of the current game
        self.preview_key = -1
        self.preview_game = None
",5
"        self.preview_app = None
",5
"
    def _selectGames(self, all_games, selecter):
        # return list of tuples (gameid, gamename)
        if selecter is None:
            return [(gi.id, gi.name) for gi in all_games]
",5
"        # by type
",5
"            (_(""64 cards""), lambda gi: gi.si.ncards == 64),
            (_(""78 cards""), lambda gi: gi.si.ncards == 78),
            (_(""104 cards""), lambda gi: gi.si.ncards == 104),
            (_(""144 cards""), lambda gi: gi.si.ncards == 144),
",5
"            (_(""Other number""),
",5
"
        data = []
        for label, vg in GI.GAMES_BY_COMPATIBILITY:
",5
"                lambda gi: gi.si.game_flags & GI.GT_SEPARATE_DECKS),
            (_(""Open Games (all cards visible)""),
                lambda gi: gi.si.game_flags & GI.GT_OPEN),
            (_(""Relaxed Variants""),
                lambda gi: gi.si.game_flags & GI.GT_RELAXED),)
",5
"                  strings=(_(""&Select""), _(""&Rules""), _(""&Cancel""),),
",5
"        self.preview_game = None
        # destruct the app
",5
"        if destroy:
            if self.preview_app:
",5
"                toolbar=None,
                # methods
                constructGame=self.app.constructGame,
                getFont=self.app.getFont,
            )
",5
"            self.preview_app.opt.animations = animations
",5
"            }
        skill_level = sl.get(gi.skill_level)
        if gi.redeals == -2:
            redeals = _('variable')
",5
"            percent = ""%.1f"" % (100.0*won/(won+lost))
        else:
",5
"            percent = ""0.0""
",5
"        time = format_time(time)
",5
"        moves = str(round(moves, 1))
",5
"            ('name',        name),
            ('altnames',    altnames),
            ('category',    category),
            ('type',        type),
            ('skill_level', skill_level),
",5
"            ('lost',        lost),
            ('time',        time),
            ('moves',       moves),
            ('percent',     percent),
                ):
",5
"                self.gameid = id
            # ~ self.tree.n_expansions = 1  # save xyview in any case
        if button == 1:                    # Rules
            id = self.getSelected()
",5
"            if id:
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
",5
"

import math
import time
",5
"import traceback
from pickle import Pickler, Unpickler, UnpicklingError
",5
"from pysol_cards.cards import ms_rearrange
from pysol_cards.random import random__int2str

from pysollib.game.dump import pysolDumpGame
from pysollib.gamedb import GI
",5
"from pysollib.help import help_about
from pysollib.hint import DefaultHint
",5
"from pysollib.mfxutil import Image, ImageTk, USE_PIL
from pysollib.mfxutil import Struct, SubclassResponsibility, destruct
",5
"from pysollib.pysoltk import Card
from pysollib.pysoltk import EVENT_HANDLED, EVENT_PROPAGATE
from pysollib.pysoltk import MfxCanvasLine, MfxCanvasRectangle, MfxCanvasText
from pysollib.pysoltk import MfxExceptionDialog, MfxMessageDialog
from pysollib.pysoltk import after, after_cancel, after_idle
",5
"# 'factory=' is absent from older versions.
assert getattr(attr, '__version_info__', (0, 0, 0)) >= (18, 2, 0), (
        ""Newer version of https://pypi.org/project/attrs/ is required."")

",5
"# *   undo/redo (using a move history)
# *   hints/demo
",5
"        if v is None:
            if sb:
                sb.updateText(gamenumber="""")
            # self.top.wm_title(""%s - %s""
",5
"            # self.top.wm_title(""%s - %s %s"" % (TITLE,
            # self.getTitleName(), v))
            return
    if k == ""info"":
",5
"            if sb:
                sb.updateText(moves=""%d"" % v)
            return
        if isinstance(v, str):
            # if tb: tb.updateText(moves=v)
",5
"                sb.updateText(time=v)
",5
"            stats.shuffle_moves == 0)


def _highlightCards__calc_item(canvas, delta, cw, ch, s, c1, c2, color):
    assert c1 in s.cards and c2 in s.cards
",5
"        else:
            if sx0 > 0:
                # left to right
                x2 += sx0
",5
"        # vertical stack
",5
"                y2 = y2 + sy0
            else:
",5
"    elif TOOLKIT == 'gtk':
        r = MfxCanvasRectangle(canvas, x1, y1, x2, y2,
                               width=4, fill=None, outline=color,
                               group=s.group)
        if tkraise:
",5
"    return r
",5
"    def calc_info(self, xf, yf):
        """"""docstring for calc_info""""""
",5
"@attr.s
class GameStacks(NewStruct):
    talon = attr.ib(default=None)
    waste = attr.ib(default=None)
",5
"        self.rows = tuple(self.rows)
        self.reserves = tuple(self.reserves)
        self.internals = tuple(self.internals)
",5
"    shade_img = attr.ib(default=None)
",5
"@attr.s
class GameTexts(NewStruct):
    info = attr.ib(default=None)
    help = attr.ib(default=None)
",5
"    player_moves = attr.ib(default=0)           # number of moves
    # number of moves while in demo mode
    demo_moves = attr.ib(default=0)
",5
"    autoplay_moves = attr.ib(default=0)         # number of moves
    quickplay_moves = attr.ib(default=0)        # number of quickplay moves
    goto_bookmark_moves = attr.ib(default=0)    # number of goto bookmark
    shuffle_moves = attr.ib(default=0)          # number of shuffles (Mahjongg)
    # did this game already update the demo stats ?
",5
"    elapsed_time = attr.ib(default=0.0)
    pause_start_time = attr.ib(default=0.0)

    def _reset_statistics(self):
",5
"        self.total_moves = 0
        self.quickplay_moves = 0
        self.goto_bookmark_moves = 0
",5
"    # number of times this game was restarted
",5
"
@attr.s
class GameMoves(NewStruct):
",5
"    talon_round = attr.ib(default=1)
",5
"class GameGlobalSaveInfo(NewStruct):
    bookmarks = attr.ib(factory=dict)
    comment = attr.ib(default="""")


",5
"# Needed for saving a game
",5
"
",5
"        self.version = VERSION
        self.version_tuple = VERSION_TUPLE
        self.cards = []
",5
"        self.regions = StackRegions()
",5
"        self.event_handled = False      # if click event handled by Stack (???)
",5
"        # init the stack view
        for stack in self.allstacks:
",5
"            stack.assertStack()
        if self.s.talon:
            assert hasattr(self.s.talon, ""round"")
",5
"            assert hasattr(self.s.talon, ""max_rounds"")
        if DEBUG:
            self._checkGame()
        self.optimizeRegions()
",5
"            if self.app.opt.auto_scale:
",5
"        self.canvas.busy = False
        if DEBUG >= 4:
",5
"        if self.s.foundations:
            ncards = 0
            for stack in self.s.foundations:
                ncards += stack.cap.max_cards
            if ncards != self.gameinfo.ncards:
",5
"            for c, f in (
                ((Spider_AC_RowStack, Spider_SS_RowStack),
",5
"                 (self._shallHighlightMatch_SS,
                  self._shallHighlightMatch_SSW)),
",5
"                ((RK_RowStack, UD_RK_RowStack),
                 (self._shallHighlightMatch_RK,
",5
"                      '%s' % class_name, 2)

    def initBindings(self):
        # note: a Game is only allowed to bind self.canvas and not to self.top
        # bind(self.canvas, ""<Double-1>"", self.undoHandler)
",5
"        self.canvas = app.canvas
        self.filename = """"
        self.drag = GameDrag()
",5
"        for obj in self.cards:
            destruct(obj)
        for obj in self.allstacks:
            obj.destruct()
            destruct(obj)
",5
"    # Do not destroy game structure (like stacks and cards) here !
    def reset(self, restart=0):
        self.filename = """"
        self.demo = None
        self.solver = None
",5
"        self.failed_snapshots = []
        # local statistics are reset on each game restart
        self.stats = GameStatsStruct()
        self.startMoves()
        if restart:
",5
"        # some vars for win animation
        self.win_animation = GameWinAnimation()

    def getTitleName(self):
",5
"        return self.app.getGameTitleName(self.id)

    def getGameNumber(self, format):
",5
"    def newGame(self, random=None, restart=0, autoplay=1, shuffle=True,
",5
"        self.startMoves()
        for stack in self.allstacks:
            stack.updateText()
        self.updateSnapshots()
        self.updateText()
",5
"        self.stopSamples()
",5
"        if autoplay:
            self.autoPlay()
            self.stats.player_moves = 0
        self.setCursor(cursor=self.app.top_cursor)
        self.stats.update_time = time.time()
",5
"        if reset:
            self.reset()
        self.resetGame()
",5
"        self.version = game.version
        self.version_tuple = game.version_tuple
",5
"        self.saveinfo = game.saveinfo
",5
"            self.allstacks[stack_id].cap.update(cap.__dict__)
        # 5) subclass settings
        self._restoreGameHook(game)
",5
"        for stack in self.allstacks:
",5
"                stack.group.tkraise()
        if self.preview <= 1:
            for t in (self.texts.score, self.texts.base_rank,):
",5
"        if random is not None:
            if ((random.__class__ is not self.random.__class__) or
                    random.initial_seed != self.random.initial_seed):
                f |= 16
        return f
",5
"    # This should be called directly before newGame(),
    # restoreGame(), restoreGameFromBookmark() and quitGame().
",5
"    def endGame(self, restart=0, bookmark=0, holdgame=0):
        if self.preview:
",5
"            self.doPause()
        if holdgame:
            return
        if bookmark:
",5
"            return
        if restart:
            if self.moves.index > 0 and self.getPlayerMoves() > 0:
",5
"                self.gstats.restarted += 1
            return
        self.updateStats()
        stats = self.app.stats
",5
"    def resizeImages(self):
        # resizing images and cards
",5
"        if self.app.opt.auto_scale:
",5
"                # apparent size of canvas
                vw = self.canvas.winfo_width()
                vh = self.canvas.winfo_height()
            else:
",5
"            # calculate factor of resizing
            xf = float(vw)/iw
",5
"            x0, y0 = stack.init_coord
            x, y = int(round(x0*xf)), int(round(y0*yf))
            stack.resize(xf, yf)
            stack.updatePositions()
        self.regions.calc_info(xf, yf)
",5
"            self.canvas.coords(item, x, y)

    def createRandom(self, random):
",5
"            self.moves.state = state
        return old_state
",5
"
    def getSnapshot(self):
        # generate hash (unique string) of current move
        sn = []
",5
"        # optimisation
        sn = hash(sn)
        return sn
",5
"            for k in sg:
                if s.__class__ is k.__class__ and \
                       s.cap.__dict__ == k.cap.__dict__:
",5
"        if progress:
            pstep = (100.0 - progress.percent) / gi.ncards
        cards = []
",5
"            progress.update(percent=100)
",5
"            cards = ms_rearrange(cards)
",5
"        cards = self._shuffleHook(cards)
        # finally add the shuffled cards to the Talon
",5
"    # subclass overrideable (must use self.random)
    def _shuffleHook(self, cards):
",5
"            # delete piles descriptions
            return True
        if self.demo:
            self.stopDemo()
",5
"
    _resizeHandlerID = None

    def _resizeHandler(self):
",5
"            return 0
        if self.app.audio:
            return self.app.audio.playSample(
                name,
",5
"        a = self.app.opt.animations
        if a and not self.preview:
",5
"        if confirm:
            if not title:
",5
"                       tkraise=1, frames=-1, shadow=-1):
        # available values of app.opt.animations:
        # 0 - without animations
",5
"        clock, delay, skip = None, 1, 1
        if self.app.opt.animations >= 2:
            clock = uclock
        SPF = 0.15 / 8          # animation speed - seconds per frame
",5
"        elif self.app.opt.animations == 4:      # slow
            frames *= 8
",5
"            SPF /= 2
        elif self.app.opt.animations == 10:
            # this is used internally in game preview to speed up
            # the initial dealing
",5
"        dx, dy = (x - c0.x) / float(frames), (y - c0.y) / float(frames)
",5
"            tx, ty = tx + mx, ty + my
            if i == 1 and shadow and from_stack:
",5
"                shadows = from_stack.createShadows(cards, sx, sy)
",5
"            for s in shadows:
",5
"            if clock:
                endtime = starttime + i*SPF
",5
"        dx, dy = x - c0.x, y - c0.y
        for card in cards:
            card.moveBy(dx, dy)
        self.canvas.update_idletasks()
",5
"        if not Image:
",5
"        canvas = self.canvas
        card = from_stack.cards[-1]
        im1 = card._active_image._pil_image
        if card.face_up:
",5
"        elif self.app.opt.animations == 5:  # very slow
            SPF = 0.1/8
            frames = 24.0

        if to_stack is None:
",5
"                min_size = h/10
                shrink_dx = 0
                shrink_dy = (h-min_size) / (frames-1)
            else:
",5
"                return False
",5
"        move_dy = dest_y / frames / 2
        xpos, ypos = float(x0), float(y0)

        card.tkraise()
",5
"
        # step 1
        d_x = shrink_dx/2+move_dx-ascent_dx
        d_y = shrink_dy/2+move_dy-ascent_dy
        nframe = 0
",5
"                usleep(t/1000)
                # else:
                # nframe += 1
",5
"            canvas.update_idletasks()
",5
"
        card.moveTo(x1, y1)
        # canvas.update_idletasks()
",5
"        canvas = self.canvas
        canvas.delete(*self.win_animation.canvas_images)
        self.win_animation.canvas_images = []

",5
"        x0 -= (width-cw)/2
        y0 -= (height-ch)/2
",5
"                saved_images[img_index] = {}
            if round_k in saved_images[img_index]:
",5
"                new_size = (int(iw*k), int(ih*k))
",5
"
        for id in raised_images:
            canvas.tag_raise(id)
",5
"            self.saved_images = {}
            self.canvas.showAllItems()
            return True
        return False

",5
"        for c in scards:
            self.win_animation.images.append(c._face_image._pil_image)
        # compute visible geometry
        self.win_animation.width = self.canvas.winfo_width()
",5
"        self.win_animation.height = self.canvas.winfo_height()
        # run win animation in background
        # after_idle(self.canvas, self.winAnimationEvent)
",5
"
    def redealAnimation(self):
",5
"        if not self.app.opt.animations or not self.app.opt.redeal_animation:
            return
        cards = []
",5
"            return
        self.setCursor(cursor=CURSOR_WATCH)
        self.top.busyUpdate()
        self.canvas.update_idletasks()
        old_a = self.app.opt.animations
",5
"                self.animatedMoveTo(
",5
"                self.animatedMoveTo(s, None, [c], sx, sy, tkraise=0, shadow=0)
            else:
                c.moveTo(sx, sy)
",5
"        if seconds > 0:
",5
"            if self.top:
                self.top.interruptSleep()
",5
"        # add to regions
        self.regions.data.append(
            (priority, -len(self.regions.data), tuple(stacks), tuple(rect)))

    # as getClosestStack() is called within the mouse motion handler
",5
"        # for InvisibleStack, etc
        # x, y = -500, -500 - len(game.allstacks)
        cardw, cardh = self.app.images.CARDW, self.app.images.CARDH
        x, y = cardw + self.canvas.xmargin, cardh + self.canvas.ymargin
        return -x-10, -y-10
",5
"                self.autoPlay()
            return n
        return 0

    # fill a stack if rules require it (e.g. Picture Gallery)
",5
"        return self.Hint_Class

",5
"        return self.canSaveGame()

    def canUndo(self):
",5
"        return True

    def canRedo(self):
        return self.canUndo()

",5
"            return ''
",5
"        if demo and self.getPlayerMoves() == 0:
            if not self.stats.demo_updated:
                # a pure demo game - update demo stats
",5
"                ret = self.app.stats.updateStats(
                    self.app.opt.player, self, status)
",5
"                    if ret[0] and ret[1]:
                        top_msg = _(
",5
"                        top_msg = _(
                            '\nYou have reached\n# %(timerank)d in the top ' +
",5
"                            '%(tops)d of playing time.') % {
                                'timerank': ret[0],
                                'tops': TOP_SIZE}
                    elif ret[1]:        # moves
",5
"    def checkForWin(self):
",5
"        if self.demo:
            return status
        if TOOLKIT == 'kivy':
",5
"        if status == 2:
",5
"            top_msg = self.updateStats()
            time = self.getTime()
            self.finished = True
            self.playSample(""gameperfect"", priority=1000)
",5
"                self.top, title=_(""Game finished""), bitmap=""info"",
                text=_(""\nGame finished\n""),
",5
"                text=_(""\nGame finished, but not without my help...\n""),
                strings=(_(""&New game""), _(""&Restart""), _(""&Cancel"")))
",5
"        # default: all Foundations must be filled
",5
"
",5
"
    def getAutoStacks(self, event=None):
        # returns (flipstacks, dropstacks, quickplaystacks)
        # default: sg.dropstacks
        return (self.sg.dropstacks, self.sg.dropstacks, self.sg.dropstacks)
",5
"            done_something = 0
            # a) flip top cards face-up
            if autofaceup and flipstacks:
                for s in flipstacks:
                    if s.canFlipCard():
",5
"                        # each single flip is undo-able unless opt.autofaceup
                        self.finishMove()
                        if self.checkForWin():
",5
"                            return 1
            # b) drop cards
            if autodrop and dropstacks:
                for s in dropstacks:
                    to_stack, ncards = s.canDropCards(self.s.foundations)
",5
"                    if to_stack:
",5
"            return self.dealCards(sound=sound)
",5
"        if not self.app:
            return None
        col = self.app.opt.colors['samerank_1']
        info = []
",5
"        for s in self.allstacks:
            for c in s.cards:
                if c.suit == suit and c.rank == rank:
                    if s.basicShallHighlightSameRank(c):
                        info.append((s, c, c, col))
",5
"    def getHighlightPilesStacks(self):
        # default: dropstacks with min pile length = 2
        if self.sg.hp_stacks:
",5
"        if self.pause:
            return 0
        self.stopWinAnimation()
",5
"        if not items:
            return 0
        self.canvas.update_idletasks()
        if sleep:
",5
"            self.sleep(sleep)
            items.reverse()
            for r in items:
                r.delete()
",5
"    def highlightNotMatching(self):
        if self.demo:
            return
",5
"        y = int(int(self.canvas.cget('height'))*(self.canvas.yview()[0]))
        w, h = self.canvas.winfo_width(), self.canvas.winfo_height()

        color = self.app.opt.colors['not_matching']
",5
"        x0, y0 = x+width//2-xmargin, y+width//2-ymargin
        x1, y1 = x+w-width//2-xmargin, y+h-width//2-ymargin
        r = MfxCanvasRectangle(self.canvas, x0, y0, x1, y1,
                               width=width, fill=None, outline=color)

",5
"            r.delete_deferred(self.app.opt.timeouts['highlight_cards'])
            return

        self.canvas.update_idletasks()
        self.sleep(self.app.opt.timeouts['highlight_cards'])
",5
"                pile = s.getPile()
                if pile and len(pile) >= si[1]:
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return False

    def _shallHighlightMatch_AC(self, stack1, card1, stack2, card2):
        # by alternate color
",5
"        return card1.color != card2.color and abs(card1.rank-card2.rank) == 1

    def _shallHighlightMatch_ACW(self, stack1, card1, stack2, card2):
        # by alternate color with wrapping (only for french games)
",5
"                 (card2.rank + 1) % 13 == card1.rank))

    def _shallHighlightMatch_SC(self, stack1, card1, stack2, card2):
",5
"
    def getQuickPlayScore(self, ncards, from_stack, to_stack):
        if to_stack in self.s.reserves:
",5
"        if to_stack.cards:
",5
"    # update game-related canvas texts (i.e. self.texts)
    def updateText(self):
",5
"    # casino type scoring
    def getGameScoreCasino(self):
        v = -len(self.cards)
        for s in self.s.foundations:
",5
"            v = v + 5 * len(s.cards)
        return v
",5
"
    def shallUpdateBalance(self):
        # Update the balance unless this is a loaded game or
",5
"            # if self.solver is None:
            # return None
            return self.solver.getHints(taken_hint)
        hint_class = self.getHintClass()
        if hint_class is None:
",5
"    # give a hint
",5
"        h = self.hints.list[self.hints.index]
        self.hints.index = self.hints.index + 1
        if self.hints.index >= len(self.hints.list):
            self.hints.index = 0
        # paranoia - verify hint
",5
"            assert 1 <= ncards <= len(from_stack.cards)
            if DEBUG:
",5
"                        from_stack, from_stack.cards[-ncards:]):
                    print('*fail accepts cards*', from_stack, to_stack, ncards)
                if not from_stack.canMoveCards(from_stack.cards[-ncards:]):
                    print('*fail move cards*', from_stack, ncards)
",5
"        x2, y2 = x2 + dx, y2 + dy
        if ncards == 1:
            x1 += cw // 2
            y1 += ch // 2
",5
"        self.sleep(sleep)
        # delete the hint
",5
"        if not self.demo:
            return
        self.canvas.setTopImage(None)
        self.demo_logo = None
        self.demo = None
",5
"        if not self.demo or self.demo.keypress:
            self.stopDemo()
            # self.updateMenus()
",5
"        self.hints.list = None
        player_moves = self.getPlayerMoves()
        d, status = None, 0
        bitmap = ""info""
",5
"        timeout = 10000
",5
"        if 1 and player_moves == 0:
            timeout = 5000
        if self.demo and self.demo.level == 3:
",5
"                text = _(""\nGame finished\n"")
                if DEBUG:
",5
"                d = MfxMessageDialog(self.top,
                                     title=_(""%s Autopilot"") % TITLE,
",5
"                    # we only increase the splash-screen counter if the last
                    # demo actually made a move
                    self.app.demo_counter += 1
",5
"                    self.newGame()
        else:
            # game not finished yet
            self.top.busyUpdate()
            if self.demo:
",5
"        score, pos, ncards, from_stack, to_stack, text_color, forced_move = h
        if ncards == 0:
            # a deal-move
",5
"            # do not let games like Klondike and Canfield deal forever
            if self.dealCards() == 0:
                return 1
",5
"                demo.last_deal.append(c)
            else:                       # new version, based on snapshots
                # check snapshot
                sn = self.getSnapshot()
",5
"            # a flip-move
",5
"            from_stack.flipMove(animation=True)
",5
"            (""se"", self.width - 8, self.height - 8),
",5
"        if ta:
            # font = self.app.getFont(""canvas_large"")
            font = self.app.getFont(""default"")
            self.demo.info_text = MfxCanvasText(self.canvas, ta[1], ta[2],
                                                anchor=ta[0], font=font,
",5
"    def getDemoInfoText(self):
        h = self.Hint_Class is None and 'None' or self.Hint_Class.__name__
        return '%s (%s)' % (self.gameinfo.short_name, h)
",5
"                items1.extend(list(s.cards))
",5
"        for c in items:
            cx, cy = c.x, c.y
            if cy >= y2:
                if cx <= x1:
",5
"        if self.width <= 100 or self.height <= 100:
            return
        # self.demo_logo = self.app.miscrandom.choice(self.app.gimages.demo)
        n = self.random.initial_seed % len(self.app.gimages.demo)
        self.demo_logo = self.app.gimages.demo[int(n)]
",5
"            return
        if self.getStuck():
            text = ''
        else:
            text = 'x'
",5
"    #

    def startMoves(self):
        self.moves = GameMoves()
",5
"        self.stats._reset_statistics()

    def __storeMove(self, am):
        if self.S_DEAL <= self.moves.state <= self.S_PLAY:
            self.moves.current.append(am)
",5
"
    # move type 1
    def moveMove(self, ncards, from_stack, to_stack, frames=-1, shadow=-1):
        assert from_stack and to_stack and from_stack is not to_stack
        assert 0 < ncards <= len(from_stack.cards)
",5
"        assert stack
        am = AFlipMove(stack)
        self.__storeMove(am)
        am.do(self)
",5
"        self.__storeMove(am)
",5
"        self.__storeMove(am)
        am.do(self)
        self.hints.list = None

    # move type 3
",5
"    def turnStackMove(self, from_stack, to_stack):
        assert from_stack and to_stack and (from_stack is not to_stack)
        assert len(to_stack.cards) == 0
",5
"
",5
"                    redo = 1
        # add current move to history (which is a list of lists)
        if redo:
            # print ""detected redo:"", current
",5
"        self.updateSnapshots()
",5
"        # update view
        self.updateText()
",5
"    #
    # subclass hooks
",5
"    def getState(self):
        # save vars (for undo/redo)
        return []

    #
",5
"                    _(""Replace existing bookmark %d?"") % (n+1)):
                return 0
        f = BytesIO()
        try:
",5
"
    def gotoBookmark(self, n, confirm=-1, update_stats=1):
        self.finishMove()       # just in case
        bm = self.gsaveinfo.bookmarks.get(n)
        if not bm:
",5
"            self.setBookmark(-1, confirm=0)
        except Exception:
",5
"            del self.gsaveinfo.bookmarks[n]
            self.setCursor(cursor=self.app.top_cursor)
        else:
",5
"    def loadGame(self, filename):
        if self.changed():
            if not self.areYouSure(_(""Open game"")):
                return
",5
"            traceback.print_exc()
",5
"            self.setCursor(cursor=self.app.top_cursor)
            MfxMessageDialog(
",5
"
        def pload(t=None, p=p):
            obj = p.load()
",5
"                'app': PACKAGE,
                'ver': version})
        game_version = 1
",5
"        initial_seed = random__int2str(pload(int))
        game.random = constructRandom(initial_seed)
        state = pload()
        if not (isinstance(game.random, random2.Random) and
",5
"                isinstance(state, int)):
            game.random.setstate(state)
        # if not hasattr(game.random, ""origin""):
",5
"        # game.random.origin = game.random.ORIGIN_UNKNOWN
        game.loadinfo.stacks = []
        game.loadinfo.ncards = 0
        nstacks = pload(int)
        validate(1 <= nstacks, err_txt)
",5
"        game.loadinfo.talon_round = pload()
",5
"            game.gsaveinfo = self.gsaveinfo
        return game
",5
"        if not self.top:
            return
",5
"            self.app.statusbar.updateText(info=kw['info'])
        if 'help' in kw and self.app.opt.helpbar:
            self.app.helpbar.updateText(info=kw['help'])
",5
"    #
    # Piles descriptions
    #

    def showStackDesc(self):
",5
"        for s in self.allstacks:
            sd = (s.__class__.__name__, s.cap.base_rank, s.cap.dir)
",5
"    #
",5
"    def _startDealNumRows(self, n):
        self._dealNumRows(n)
        self.startDealSample()

    def _startDealNumRowsAndDealSingleRow(self, n):
",5
"from pysollib.settings import VERSION, VERSION_TUPLE


def pysolDumpGame(game_, p, bookmark=0):
",5
"    p.dump(len(game_.allstacks))
    for stack in game_.allstacks:
        p.dump(len(stack.cards))
        for card in stack.cards:
            p.dump(card.id)
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"# You should have received a copy of the GNU General Public License
",5
"        FullStackWrapper, \
        InitialDealTalonStack, \
        InvisibleStack, \
        KingAC_RowStack, \
        KingSS_RowStack, \
",5
"# * Fan
# ************************************************************************
",5
"    #
    # game layout
    #

",5
"                   texts=False):
        # create layout
        l, s = Layout(self), self.s
",5
"        decks = self.gameinfo.decks
        if reserves:
            x, y = l.XM, l.YM
",5
"        for fnd_cls in self.Foundation_Classes:
            for i in range(4):
                s.foundations.append(fnd_cls(x, y, self, suit=i))
                x += dx
        for i in range(len(rows)):
",5
"                s.rows.append(stack)
                x += w
        x, y = self.width - l.XS, self.height - l.YS
        s.talon = self.Talon_Class(x, y, self)
        if texts:
",5
"    def getHighlightPilesStacks(self):
        return ()


",5
"# ************************************************************************

class ScotchPatience(Fan):
    Foundation_Classes = [AC_FoundationStack]
    RowStack_Class = StackWrapper(RK_RowStack, base_rank=NO_RANK)
",5
"
    def createGame(self):
        Fan.createGame(self, playcards=8)
    shallHighlightMatch = Game._shallHighlightMatch_RK
",5
"

# ************************************************************************
# * Shamrocks
",5
"    RowStack_Class = StackWrapper(
",5
"        i, n = 0, 17
        kings = []
        for c in cards:
            if c.rank == KING:
",5
"                j += n
        cards.reverse()
",5
"
    def dealCards(self, sound=False):
        n = self.redealCards1()
        if n == 0:
",5
"            return 0
        self.redealCards2()
        if sound:
            self.game.startDealSample()
",5
"        self.redealCards3()
        if sound:
            self.game.stopSamples()
        return n
",5
"    def redealCards2(self):
",5
"    # redeal step 3) - redeal cards to stacks
    def redealCards3(self, face_up=1):
        # deal 3 cards to each row, and 1-3 cards to last row
        to_stacks = self.game.s.rows
",5
"            return False
        return True

    def updateModel(self, undo, flags):
        assert undo == self.game.draw_done
",5
"        images = self.game.app.images
",5
"            font=self.game.app.getFont(""canvas_default""))


",5
"        lay.defaultStackGroups()
        # extra settings
        self.draw_done = 0

    def startGame(self):
",5
"        self.s.reserves[0].updateText()
        LaBelleLucie.startGame(self)

    def _restoreGameHook(self, game):
",5
"        self.loadinfo.addattr(draw_done=p.load())

    def _saveGameHook(self, p):
",5
"    Foundation_Classes = [StackWrapper(SS_FoundationStack, min_cards=1)]

",5
"        return num_cards

",5
"    def redealCards3(self, face_up=1):
        for r in self.game.s.rows:
            while len(r.cards) < 3:
                self.dealToStacks([r], frames=4)
                if not self.cards:
",5
"    def startGame(self):
",5
"
# ************************************************************************
# * House in the Wood
# * House on the Hill
",5
"        self.s.talon.dealRow(rows=self.s.rows[:34], frames=0)
        self.s.talon.dealRow(rows=self.s.rows[:35], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:35])
",5
"    def acceptsCards(self, from_stack, cards):
",5
"
    def _getBaseCard(self):
        return _('Base card - Ace or King.')

",5
"
    def createGame(self):
        # create layout
",5
"        # create stacks
        x, y = l.XM, l.YM
        for i in range(2):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
",5
"
    #
",5
"
",5
"
class FreeFan(Fan):
    RowStack_Class = FullStackWrapper(SuperMoveSS_RowStack, base_rank=KING)
    Solver_Class = FreeCellSolverWrapper(esf='kings', sbb='suit')
",5
"    RowStack_Class = StackWrapper(RK_RowStack, dir=0,
",5
"        for r in self.s.rows:
            for i in range(ncards):
                if not self.s.talon.cards:
",5
"                    break
                c = self.s.talon.cards[-1]
                t = r
                if c.rank == ACE:
",5
"    RowStack_Class = FullStackWrapper(
",5
"# ************************************************************************
# * Fascination Fan
",5
"    RowStack_Class = StackWrapper(AC_RowStack, base_rank=NO_RANK)

",5
"            self.s.talon.dealRow(rows=self.s.rows[:17], flip=0, frames=0)
        self._startAndDealRow()

",5
"    def redealCards(self):
        r0 = r1 = len(self.s.talon.cards)//3
        m = len(self.s.talon.cards) % 3
        if m >= 1:
",5
"        self.s.talon.dealRowAvail(frames=4)

    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"        playcards = 10
        w0 = l.XS+(playcards-1)*l.XOFFSET
",5
"        x, y = l.XM, l.YM
",5
"        s.talon = Crescent_Talon(x, y, self, max_rounds=4)
",5
"            for j in range(4):
                stack = UD_SS_RowStack(x, y, self, base_rank=NO_RANK, mod=13)
                s.rows.append(stack)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
                x += w0
",5
"
    def createGame(self):
        Fan.createGame(self, rows=(4, 4, 4, 4), playcards=10, texts=True)

",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank == card2.rank


",5
"# ************************************************************************
",5
"
    def _redeal(self, rows=None, frames=0):
        # move all cards to the talon
        num_cards = 0
        if rows is None:
",5
"            self.game.nextRoundMove(self)
            if sound:
",5
"            return ncards
        #
",5
"        if sound and self.game.app.opt.animations:
            self.game.startDealSample()
",5
"        x1, x2 = l.XM, self.width - 2*l.XS
        for i in range(2):
            y = l.YM
",5
"            x1 += l.XS
            x2 += l.XS

        x, y = l.XM + 3*l.XS, l.YM
",5
"            y += l.YS
        x, y = l.XM + 3*l.XS, l.YM + 5*l.YS
        for i in (0, 1):
            stack = SS_RowStack(x, y, self, max_move=1, base_rank=KING)
",5
"# register the game
registerGame(GameInfo(56, FanGame, ""Fan"",
                      GI.GT_FAN_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(87, ScotchPatience, ""Scotch Patience"",
",5
"registerGame(GameInfo(317, HouseOnTheHill, ""House on the Hill"",
",5
"registerGame(GameInfo(385, BoxFan, ""Box Fan"",
                      GI.GT_FAN_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(516, Troika, ""Troika"",
                      GI.GT_FAN_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(625, FascinationFan, ""Fascination Fan"",
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# the Free Software Foundation, either version 3 of the License, or
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"        l, s = Layout(self), self.s

        # set window
",5
"        for i in range(4):
",5
"            stack = self.Foundation_Class(x, y, self, suit=ANY_SUIT,
                                          base_rank=ANY_RANK)
",5
"        l.defaultAll()

    #
    # game overrides
    #
",5
"        rows = self.s.rows[:4]
",5
"        for s in self.s.rows:
            if s.cards:
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"
class Striptease_RowStack(UD_RK_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
",5
"                (r2 == JACK and r1 == KING)):
            return True
        return ((r1+1) % 13 == r2 or (r2+1) % 13 == r1)

",5
"
class Striptease_Reserve(OpenStack):
",5
"    def canFlipCard(self):
",5
"    def isGameWon(self):
        for r in self.s.reserves:
            if len(r.cards) != 1:
                return False
        return True
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        r1, r2 = card1.rank, card2.rank
        if r1 == QUEEN or r2 == QUEEN:
            return False
",5
"#
# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# GNU General Public License for more details.
#
",5
"from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.hint import CautiousDefaultHint
",5
"
class Doublets(Game):
    Hint_Class = CautiousDefaultHint

",5
"        # set window
",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, ""s"")
        l.createRoundText(s.talon, 'nn')
",5
"        self.startDealSample()
",5
"        self.s.talon.dealRow()
",5
"        if self.s.talon.cards or self.s.waste.cards:
            return False
",5
"                      GI.GT_1DECK_TYPE, 1, 2, GI.SL_MOSTLY_LUCK,
                      altnames=('Double or Quits',)))
",5
"        DealReserveRedealTalonStack, \
        DealRowTalonStack, \
        FaceUpWasteTalonStack, \
",5
"        InitialDealTalonStack, \
        OpenStack, \
        ReserveStack, \
",5
"        Stack, \
        StackWrapper, \
",5
"    # consider moving card to the Talon as well
    def step010(self, dropstacks, rows):
        rows = rows + (self.game.s.talon,)
",5
"        return DefaultHint.step010(self, dropstacks, rows)
",5
"        if self.basicIsBlocked():
            return False
        if from_stack is self or not self.cards or len(cards) != 1:
            return False
",5
"            return 1
        return 0

    def _dropPairMove(self, n, other_stack, frames=-1, shadow=-1):
        if not self.game.demo:
",5
"            return
        old_state = self.game.enterState(self.game.S_FILL)
        f = self.game.s.foundations[0]
        self.game.moveMove(n, self, f, frames=frames, shadow=shadow)
        self.game.moveMove(n, other_stack, f, frames=frames, shadow=shadow)
",5
"        other_stack.fillStack()

    def moveMove(self, ncards, to_stack, frames=-1, shadow=-1):
        if to_stack in self.game.s.foundations:
            self.game.moveMove(
",5
"    def canDealCards(self):
        if not FaceUpWasteTalonStack.canDealCards(self):
            return False
        return not self.game.isGameWon()
",5
"
",5
"    Hint_Class = Pyramid_Hint
    Foundation_Class = Pyramid_Foundation
",5
"    #
    # game layout
    #
",5
"
    def _createPyramid(self, l, x0, y0, size):
        rows = []
",5
"            for j in range(i+1):
",5
"            for j in range(i+1):
                k = n+i+1
                rows[n].blockmap = [rows[k], rows[k+1]]
                n += 1
",5
"                rows.append(stack)
                x = x + l.XS
        # compute blocking
        n = 0
        for i in range(size-1):
",5
"                    rows[n].blockmap = [rows[k-1]]
                else:
                    rows[n].blockmap = [rows[k-1], rows[k]]
",5
"                n += 1
        return rows

",5
"        # create stacks
",5
"            if s.talon.max_rounds > 1:
                l.createRoundText(s.talon, 'ne')
        if waste:
            y = y + l.YS
",5
"                             suit=ANY_SUIT, dir=0, base_rank=ANY_RANK,
                             max_move=0, max_cards=52*decks))
",5
"                x += l.XS

        # define stack-groups
",5
"    # game overrides
    #

",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(frames=4)
        self.s.talon.dealCards()          # deal first card to WasteStack

",5
"# * Giza
# ************************************************************************

class Giza_Reserve(Pyramid_StackMethods, OpenStack):
",5
"    def clickHandler(self, event):
        if self._dropKingClickHandler(event):
",5
"        return OpenStack.clickHandler(self, event)


",5
"        self.s.talon.dealRow(frames=4)

",5
"# ************************************************************************

class Thirteen(Pyramid):

    #
",5
"    def createGame(self):
        # create layout
",5
"        # create stacks
        for i in range(7):
",5
"        x, y = l.XM, l.YM
        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, ""s"")
",5
"        x = x + l.XS
        s.waste = Pyramid_Waste(x, y, self, max_accept=1)
        l.createText(s.waste, ""s"")
        s.waste.CARD_XOFFSET = 14
        x, y = self.width - l.XS, l.YM
",5
"        s.foundations.append(Pyramid_Foundation(x, y, self,
                             suit=ANY_SUIT, dir=0, base_rank=ANY_RANK,
",5
"        l, s = Layout(self), self.s

",5
"            x = l.XM
            for j in range(5):
                s.rows.append(Giza_Reserve(x, y, self, max_accept=1))
                x += l.XS
",5
"        x, y = self.width-l.XS, self.height-l.YS
        s.foundations.append(Pyramid_Foundation(x, y, self,
                             suit=ANY_SUIT, dir=0, base_rank=ANY_RANK,
                             max_move=0, max_cards=52))
",5
"        l.defaultStackGroups()
",5
"
class Elevens_RowStack(Giza_Reserve):
    ACCEPTED_SUM = 9

",5
"        if from_stack is self or not self.cards or len(cards) != 1:
            return False
        c = self.cards[-1]
        return (c.face_up and cards[0].face_up and
",5
"                cards[0].rank + c.rank == self.ACCEPTED_SUM)

    def clickHandler(self, event):
        return OpenStack.clickHandler(self, event)

",5
"
class Elevens(Pyramid):
",5
"
",5
"                             max_move=0, max_cards=52))
",5
"            x += l.XS

        if texts:
            stack = s.reserves[0]
            tx, ty, ta, tf = l.getTextAttr(stack, ""n"")
",5
"            font = self.app.getFont(""canvas_default"")
            stack.texts.misc = MfxCanvasText(self.canvas, tx, ty,
                                             anchor=ta, font=font)
",5
"    def startGame(self):
",5
"        self._startAndDealRow()

    def fillStack(self, stack):
        old_state = self.enterState(self.S_FILL)
        if stack in self.s.rows:
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        # FIXME
        return False

",5
"        reserves_ncards = 0
        for s in self.s.reserves:
            if s.cards:
                reserves_ncards += 1
",5
"            if not self.demo:
                self.playSample(""droppair"", priority=200)
",5
"            for s in self.s.reserves:
                s.moveMove(1, self.s.foundations[0], frames=4)
",5
"            self.fillStack(stack)
        self.leaveState(old_state)


",5
"        return cards[0].suit == self.cards[0].suit


class SuitElevens_Reserve(Elevens_Reserve):
",5
"
# ************************************************************************
# * Fifteens
# ************************************************************************

",5
"class Fifteens_RowStack(Elevens_RowStack):
    ACCEPTED_SUM = 13
",5
"        if self.game.preview > 1 or self.texts.misc is None:
            return
        t = ''
        if self.cards:
            ranks = [c.rank for c in self.cards]
",5
"            for r in (9, JACK, QUEEN, KING):
                if r in ranks:
",5
"                n = sum([i+1 for i in ranks])
                t = str(n)
        self.texts.misc.config(text=t)

",5
"        self.fillStack()

    def fillStack(self, stack=None):
        old_state = self.enterState(self.S_FILL)
",5
"            if (9 in reserve_ranks or JACK in reserve_ranks or
                    QUEEN in reserve_ranks or KING in reserve_ranks):
                if reserve_ranks == [9, JACK, QUEEN, KING]:
                    self._dropReserve()
            else:
",5
"                reserve_sum = sum([c.rank+1 for c in reserve.cards])
                if reserve_sum == 15:
                    self._dropReserve()
",5
"        for r in self.game.s.reserves:
            if r.cards:
                r_ranks.append(r.cards[0].rank)
        if not r_ranks:
",5
"        for i in range(3):
            j, k = (i+1) % 3, (i+2) % 3
            if ((r_ranks[i]+1) % 13 == r_ranks[j] and
                    (r_ranks[j]+1) % 13 == r_ranks[k]):
",5
"
class TripleAlliance(Game):

    def createGame(self):
",5
"            r.moveMove(1, self.s.foundations[0])
        self.leaveState(old_state)

    def isGameWon(self):
        return len(self.s.foundations[0].cards) == 51
",5
"class Pharaohs(Pyramid):
",5
"
    Talon_Class = InitialDealTalonStack
",5
"
    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

",5
"        s.rows += self._createPyramid(l, x, y, 2)
        x, y = l.XM+2*l.XS, l.YM
        s.rows += self._createPyramid(l, x, y, 7)
        x, y = l.XM+2.5*l.XS, l.YM+3*l.YS
",5
"        s.rows += self._createPyramid(l, x, y, 6)

        x, y = l.XM, self.height-l.YS
        s.talon = self.Talon_Class(x, y, self)
",5
"        self.s.talon.dealRow(frames=4)

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.rank + card2.rank == 11 or
                card1.rank == card2.rank)
",5
"
        # create stacks
        x, y = l.XM, l.YM
",5
"# ************************************************************************
# * Apophis
# ************************************************************************

",5
"    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
            return False
",5
"    PYRAMID_Y_FACTOR = 2

",5
"        x, y = l.XM+1.5*l.XS, l.YM
        s.rows = self._createPyramid(l, x, y, 7)
",5
"        x, y = l.XM, l.YM
        s.talon = DealReserveRedealTalonStack(x, y, self, max_rounds=3)
",5
"        y += l.YS
        for i in range(3):
",5
"
",5
"        self.startDealSample()
        self.s.talon.dealRow(frames=4)
        self.s.talon.dealCards()

",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank + card2.rank == 11

# ************************************************************************
# * Cheops
",5
"# ************************************************************************
# * Exit
# ************************************************************************
",5
"class Exit_RowStack(Elevens_RowStack):
    def acceptsCards(self, from_stack, cards):
",5
"        c1 = self.cards[-1]
        c2 = cards[0]
",5
"        s.reserves.append(stack)
",5
"        stack.CARD_YOFFSET = l.YOFFSET
        x, y = self.width-l.XS, self.height-l.YS
        s.foundations.append(AbstractFoundationStack(x, y, self, suit=ANY_SUIT,
                             max_accept=0, max_move=0, max_cards=52))
        l.createText(s.foundations[0], ""n"")
",5
"        x, y = l.XM, self.height-l.YS
        s.talon = InitialDealTalonStack(x, y, self)

",5
"            for j in range(5):
                k = i*5+j
",5
"        return cards

    def startGame(self):
        self.startDealSample()
",5
"
",5
"        l.defaultStackGroups()
        self.sg.openstacks.append(s.talon)
        self.sg.dropstacks.append(s.talon)
        self.sg.openstacks.append(s.waste)

",5
"
",5
"
        x, y = l.XM, self.height-l.YS
",5
"        s.waste.CARD_XOFFSET = l.XOFFSET
        l.createText(s.waste, ""n"")

",5
"        l.createText(s.foundations[0], 'nw')

",5
"
# ************************************************************************
# * Triangle
",5
"        self.sg.openstacks.append(s.waste)

",5
"
        y += l.YS
",5
"class Hurricane_Hint(DefaultHint):
    def step010(self, dropstacks, rows):
        rows = rows + self.game.s.reserves
",5
"                               frames=frames, shadow=shadow)
            self.fillStack()

",5
"
        # set window
        ww = l.XS + max(2*l.XOFFSET, l.XS//2)
        w = l.XM + 1.5*l.XS + 4*ww
",5
"        x = l.XM + 1.5*l.XS + l.XS+2*l.XOFFSET + d//2
        y = l.YM+l.YS
        for i in range(3):
",5
"

",5
"                      GI.GT_PAIRING_TYPE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(657, Baroness, ""Baroness"",
",5
"                      GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(681, KingTut, ""King Tut"",
                      GI.GT_PAIRING_TYPE, 1, -1, GI.SL_MOSTLY_LUCK))
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"#
# ---------------------------------------------------------------------------##

from pysollib.game import Game
",5
"        SS_RowStack
from pysollib.util import KING

",5
"# ************************************************************************
# * Heads and Tails
",5
"    # game layout
",5
"        self.setSize(l.XM+10*l.XS, l.YM+l.YS+2*h)

",5
"        # create stacks
        x, y = self.width - l.XS, self.height - l.YS
        s.talon = InitialDealTalonStack(x, y, self)

        x, y = l.XM+l.XS, l.YM
",5
"        x, y = l.XM+l.XS, l.YM+l.YS+h
        for i in range(8):
",5
"            x += l.XS

",5
"    # game overrides
    #

    def startGame(self):
",5
"# ************************************************************************
# * Barrier
",5
"
    def createGame(self):
        reserves = 8
        rows = 10
        max_rows = max(8, rows, reserves)
",5
"        for i in range(8):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
            x += l.XS
        x, y = l.XM, self.height-l.YS
",5
"    def startGame(self):
        rows = len(self.s.rows)
        reserves = len(self.s.reserves)
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealRow()

    def fillStack(self, stack):
",5
"                return
            old_state = self.enterState(self.S_FILL)
            from_stack.flipMove()
",5
"# register the game

registerGame(GameInfo(307, HeadsAndTails, ""Heads and Tails"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(708, Barrier, ""Barrier"",
",5
"from pysollib.hint import CautiousDefaultHint
from pysollib.layout import Layout
from pysollib.stack import \
        AC_FoundationStack, \
        AbstractFoundationStack, \
",5
"        StackWrapper, \
        TalonStack, \
",5
"        UNLIMITED_REDEALS
",5
"# * Sultan
# ************************************************************************

class Sultan(Game):

",5
"
    def createGame(self, reserves=6):
        # create layout
        l, s = Layout(self), self.s
",5
"
        # set window
        w, h = 3*l.XM+5*l.XS, l.YM+4*l.YS+l.TEXT_HEIGHT+l.TEXT_MARGIN
",5
"               (2, 2, 3, 1, 13),
               (1, 0, 2, 1, 12),
               )
",5
"        for i in range(reserves//2):
            s.rows.append(ReserveStack(x, y, self))
            y += l.YS
",5
"
        x, y = 3*l.XM+4*l.XS, l.YM
        for i in range(reserves//2):
            s.rows.append(ReserveStack(x, y, self))
",5
"        x += l.XS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, ""s"")

        # define stack-groups
",5
"        x, y = l.XM, l.YM+l.YS
",5
"                          max_cards=1, max_move=0, base_rank=QUEEN))
            x += l.XS
",5
"        x = l.XM+1.5*l.XS
        y += l.YS
        for i in range(4):
",5
"            x += l.XS

        l.defaultStackGroups()
",5
"
",5
"        l.createRoundText(s.talon, 'nn')
",5
"        x, y = l.XM+1.5*l.XS, l.YM
        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
                                 mod=13, max_cards=6, base_rank=4, dir=-1))
",5
"
        l.defaultStackGroups()

    def startGame(self):
",5
"        l, s = Layout(self), self.s
        self.setSize(l.XM+8*l.XS, l.YM+4*l.YS)
",5
"            x += l.XS
",5
"        # move 5's and 6's to top of the Talon (i.e. first cards to be dealt)
        return self._shuffleHookMoveToTop(
            cards,
            lambda c: (c.rank in (4, 5), (c.rank, c.suit)))
",5
"
    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
        self.s.talon.dealCards()          # deal first card to WasteStack
",5
"# * Idle Aces
# ************************************************************************
",5
"
",5
"        x, y = l.XM, l.YM
        s.talon = WasteTalonStack(x, y, self, max_rounds=3)
",5
"                RK_FoundationStack(
                    x, y, self,
                    # suit=ANY_SUIT,
                    base_rank=KING, dir=-1, max_move=0))
            k += 1
",5
"        k = 0
        for i, j in((1, 0.2), (3, 0.2), (1, 2.8), (3, 2.8)):
            x, y = x0+i*l.XS, y0+j*l.YS
            s.foundations.append(IdleAces_AceFoundation(x, y, self,
                                 suit=k, max_cards=1, max_move=0))
",5
"
",5
"            x += l.XS
        for i, j in ((0, 2), (0, 1), (0, 0),
                     (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0),
                     (7, 0), (7, 1), (7, 2), ):
",5
"        return self._shuffleHookMoveToTop(
            cards,
",5
"        if self.round == 1:
",5
"
",5
"        self._startAndDealRow()
",5
"        l, s = Layout(self), self.s
",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
                                                    base_rank=KING, dir=-1))
            y += l.YS
        y = l.YM
",5
"            for j in range(3):
                s.rows.append(BasicRowStack(x, y, self,
",5
"            l.createText(s.waste, 'se')

        l.defaultStackGroups()

",5
"class Patriarchs(PicturePatience):
    def createGame(self):
        PicturePatience.createGame(self, max_rounds=2)

    def _shuffleHook(self, cards):
",5
"
# ************************************************************************
# * Sixes and Sevens
# * Two Rings
# ************************************************************************
",5
"            x = l.XM
            for j in range(4):
                s.foundations.append(SS_FoundationStack(x, y, self,
",5
"        self.startDealSample()
        self.s.talon.dealRow()
",5
"class TwoRings(Game):

    def createGame(self, max_rounds=2):
",5
"
        suit = 0
",5
"        x0, y0 = l.XM+5*l.XS, l.YM
        for xx, yy in lay:
            x, y = x0+xx*l.XS, y0+yy*l.YS
",5
"        x, y = l.XM, l.YM+4*l.YS
        for i in range(8):
            stack = BasicRowStack(x, y, self)
            stack.CARD_YOFFSET = 0
",5
"# ************************************************************************
# * Corner Suite
# ************************************************************************
",5
"
class CornerSuite(Game):
    Hint_Class = CautiousDefaultHint
",5
"
    def createGame(self):
        l, s = Layout(self), self.s
",5
"        self.setSize(l.XM+5*l.XS, l.YM+5*l.YS)

        suit = 0
        for x, y in ((0, 0), (4, 0), (0, 4), (4, 4)):
            x, y = l.XM+x*l.XS, l.YM+y*l.YS
",5
"            suit += 1

",5
"        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, 'nw')
        x += l.XS
        s.waste = WasteStack(x, y, self)
",5
"            for j in range(3):
                stack = CornerSuite_RowStack(x, y, self, max_move=1)
",5
"                x += l.XS
            y += l.YS

        l.defaultStackGroups()

",5
"class Marshal_Hint(CautiousDefaultHint):
    def _getDropCardScore(self, score, color, r, t, ncards):
",5
"        return 93000, color


",5
"class Marshal(Game):
",5
"                stack = UD_SS_RowStack(x, y, self, base_rank=NO_RANK)
",5
"                self.moveMove(1, self.s.talon, stack)
                self.leaveState(old_state)
",5
"
",5
"
class RoyalAids(Game):
",5
"            s.rows.append(stack)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, 0
",5
"            x += l.XS
        x, y = l.XM+2.75*l.XS, l.YM+3*l.YS
",5
"    shallHighlightMatch = Game._shallHighlightMatch_AC


",5
"                     (3, 0),
                     (4, 1.5),
                     (3, 3),
                     (2, 3),
                     (1, 3),
",5
"                     (0, 1.5),
                     ):
            x, y = l.XM+i*l.XS, l.YM+j*l.YS
            stack = RK_RowStack(x, y, self, dir=1, mod=13, max_move=0)
",5
"
        l.defaultStackGroups()

",5
"
class Adela_Foundation(SS_FoundationStack):
",5
"        return len(self.game.s.foundations[index].cards) > 0
",5
"        l, s = Layout(self), self.s
",5
"

# ************************************************************************
# * Toni
",5
"        suit = 0
",5
"
class Khedive(Game):

    def createGame(self):

",5
"        x, y = l.XM+4*l.XS, l.YM
        r = list(range(11))
        for i in range(5, 0, -1):
            for j in r[i:-i]:
",5
"
",5
"            for j in range(i+1):
",5
"
        suit = 0
        for xx, yy in ((1.5, 1.5),
                       (1,   2.5),
                       (6.5, 1.5),
",5
"        self.s.talon.dealCards()
",5
"# * Grandee
# * Turncoats
# * Voracious
# ************************************************************************

",5
"                stack.CARD_YOFFSET = 0
                s.rows.append(stack)
                x += l.XS
",5
"        if waste:
            l.createText(s.talon, 'n')
",5
"            x -= l.XS
",5
"    def startGame(self):
        self._startAndDealRow()

    shallHighlightMatch = Game._shallHighlightMatch_SS
",5
"

",5
"class Turncoats(Grandee):
    Talon_Class = TalonStack
",5
"    RowStack_Class = StackWrapper(UD_AC_RowStack, base_rank=NO_RANK)

    def createGame(self):
",5
"        Grandee.createGame(self, rows=12)

    def fillStack(self, stack):
        if not stack.cards:
",5
"        self.s.talon.dealCards()

",5
"# * Desert Island
",5
"    def createGame(self):

        # create layout
",5
"        for i in range(3):
            x = l.XM
            for j in range(8):
                # stack = SS_RowStack(x, y, self, max_move=1)
",5
"
        l, s = Layout(self), self.s
        w, h = 3*l.XM+5*l.XS, l.YM+5*l.YS
        self.setSize(w, h)

",5
"               (2, 1, 3, QUEEN, -1),
               (2, 2, 3, QUEEN, -1),
               (1, 1, 2, KING, 1),
               )
        for xx, yy, suit, base_rank, dir in lay:
",5
"            x, y = 2*l.XM+l.XS+xx*l.XS, l.YM+yy*l.YS
",5
"            stack = SS_FoundationStack(x, y, self, suit=suit,
",5
"
    def fillStack(self, stack):
        if stack in self.s.rows and not stack.cards:
",5
"                self.s.waste.moveMove(1, stack)
            self.leaveState(old_state)

",5
"                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(410, CaptiveQueens, ""Captive Queens"",
                      GI.GT_1DECK_TYPE, 1, 2, GI.SL_MOSTLY_LUCK,
                      altnames=(""Quadrille"",)))
registerGame(GameInfo(418, Contradance, ""Contradance"",
",5
"registerGame(GameInfo(423, LadyOfTheManor, ""Lady of the Manor"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_LUCK,
                      altnames=(""Vassal"", ""La Chatelaine"")))
",5
"                      GI.GT_2DECK_TYPE, 2, 1, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(438, SixesAndSevens, ""Sixes and Sevens"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(477, CornerSuite, ""Corner Suite"",
",5
"registerGame(GameInfo(660, Toni, ""Toni"",
                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_MOSTLY_LUCK))
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(743, Turncoats, ""Turncoats"",
                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(744, Voracious, ""Voracious"",
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"        InitialDealTalonStack, \
",5
"class StHelena_Talon(TalonStack):

    def canDealCards(self):
        if self.round == self.max_rounds:
",5
"            for i in range(len(r.cards)):
                num_cards = num_cards + 1
                self.game.moveMove(1, r, self, frames=0)
        assert len(self.cards) == num_cards
",5
"        if num_cards == 0:          # game already finished
",5
"class StHelena_FoundationStack(SS_FoundationStack):
",5
"                return False
",5
"
class StHelena(Game):

    Hint_Class = CautiousDefaultHint
    Talon_Class = StackWrapper(StHelena_Talon, max_rounds=3)
",5
"
    #
",5
"        # set window
        w, h = 3*l.XM+6*l.XS, 3*l.YM+4*l.YS
        self.setSize(w, h)

        # create stacks
",5
"            x, y = xm*l.XM+xs*l.XS, ym*l.YM+ys*l.YS
            stack = self.RowStack_Class(x, y, self, max_move=1, max_accept=1)
",5
"                                                       base_rank=KING, dir=-1))
            x = x + l.XS
",5
"            x = x + l.XS

",5
"
    #
    # game overrides
    #

",5
"    def startGame(self):
        self._startDealNumRows(7)
        self.s.talon.dealRow()
",5
"    Talon_Class = InitialDealTalonStack
",5
"class LesQuatreCoins_RowStack(UD_RK_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not UD_RK_RowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        return len(self.game.s.talon.cards) == 0


class LesQuatreCoins_Talon(RedealTalonStack):
",5
"

",5
"            return True
        if self.game.s.talon.cards:
            if from_stack in self.game.s.rows[4:]:
                i = list(self.game.s.foundations).index(self)
",5
"                j = list(self.game.s.rows).index(from_stack)
                return i == j-4
        return True


",5
"
        for i, j in ((0, 0), (5, 0), (0, 4), (5, 4)):
            x, y = l.XM+l.XS+i*l.XS, l.YM+j*l.YS
",5
"        self.s.talon.dealCards()

",5
"        self.setSize(l.XM+8*l.XS, l.YM+5*l.YS)

        for i, j in ((0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0),
",5
"
        x, y = l.XM+3*l.XS, l.YM+l.YS
        for i in range(3):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
                                 base_rank=9, mod=13, dir=-1))
",5
"        s.foundations.append(SS_FoundationStack(x, y, self, suit=3,
                             base_rank=JACK, mod=13, dir=-1))
",5
"
",5
"        x, y = l.XM, l.YM+2*l.YS
",5
"registerGame(GameInfo(620, LesQuatreCoins, ""Les Quatre Coins"",
                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_MOSTLY_SKILL))
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"        UD_AC_RowStack, \
        UD_RK_RowStack, \
        WasteStack, \
        WasteTalonStack, \
",5
"    def closeStack(self):
        if len(self.cards) == 4 and isRankSequence(self.cards, dir=0):
            if not self.game.moves.state == self.game.S_REDO:
                self.game.flipAllMove(self)
",5
"            for j in range(twidth):
                if i*twidth+j >= self.NSTACKS:
",5
"        self.sg.talonstacks = [s.talon]
",5
"            self.s.talon.dealRow(rows=r, frames=0)
        self.startDealSample()
",5
"
",5
"#  registerGame(GameInfo(341, PileOn2Decks, ""PileOn (2 decks)"",
#                        GI.GT_2DECK_TYPE | GI.GT_OPEN,, 2, 0))
",5
"

# ************************************************************************
",5
"        for i in range(rows):
            s.rows.append(UD_AC_RowStack(x, y, self, mod=13))
            x += l.XS
",5
"
    def startGame(self):
",5
"

class FourByFour_Foundation(AbstractFoundationStack):

    def _getNumSameCards(self):
",5
"        decks = self.game.gameinfo.decks
        rank = self.cards[-1].rank
",5
"        return _('Foundation. Build up regardless of suit.')


class FourByFour(Game):
    Hint_Class = FourByFour_Hint
",5
"        l.createText(s.talon, 's')
        x += l.XS
",5
"        x += 3.5*l.XS
",5
"        s.foundations.append(FourByFour_Foundation(x, y, self,
",5
"                             suit=ANY_SUIT, base_rank=ANY_RANK, max_cards=52,
                             max_accept=1, max_move=0, mod=13))
        stack = s.foundations[0]
        tx, ty, ta, tf = l.getTextAttr(stack, 'ne')
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
        self.s.talon.dealCards()
",5
"
    def updateText(self):
        decks = self.gameinfo.decks
",5
"            r = r % 13
            r = RANKS[r]
            t = '%s (%d)' % (r, n)
        f.texts.misc.config(text=t)
",5
"        self.setSize(l.XM+rows*l.XS, l.YM+2*l.YS+playcards*l.YOFFSET)

        x, y = l.XM, l.YM
        for i in range(reserves):
            s.reserves.append(ReserveStack(x, y, self))
",5
"        tx, ty, ta, tf = l.getTextAttr(stack, 'ne')
        font = self.app.getFont('canvas_default')
        stack.texts.misc = MfxCanvasText(self.canvas, tx, ty,
                                         anchor=ta, font=font)

",5
"
        x, y = l.XM, self.height-l.YS
",5
"                      ranks=(0, 5, 6, 7, 8, 9, 10, 11, 12),
                      rules_filename=""pileon.html""))
registerGame(GameInfo(554, Foursome, ""Foursome"",
",5
"# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"from pysollib.hint import CautiousDefaultHint
",5
"# ************************************************************************
",5
"
    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

",5
"        l.createText(s.waste, ""s"")

        # define stack-groups
        l.defaultStackGroups()
",5
"        c = self.s.talon.getCard()
",5
"    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
        self.loadinfo.base_card_id = p.load()

    def _saveGameHook(self, p):
",5
"        foundations = decks*4
        max_rows = max(foundations, rows)
        w, h = l.XM+(max_rows+1)*l.XS, l.YM+3*l.YS+playcards*l.YOFFSET
        self.setSize(w, h)
",5
"        # create stacks
        x, y = l.XM+l.XS+(max_rows-foundations)*l.XS//2, l.YM
",5
"        x, y = l.XM+l.XS+(max_rows-rows)*l.XS//2, l.YM+l.YS
        for i in range(rows):
            s.rows.append(self.RowStack_Class(x, y, self,
                                              max_move=1, max_accept=1))
",5
"# ************************************************************************
",5
"        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == KING and c.deck == 0, c.suit))
",5
"class AlgerianPatience3(Carthage):
    Foundation_Classes = (SS_FoundationStack,
",5
"            cards, lambda c: (c.rank == ACE, (c.deck, c.suit)))
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
",5
"    #
",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            x += l.XS
",5
"            stack = BasicRowStack(x, y, self, max_move=1, max_accept=0)
            stack.CARD_YOFFSET = l.YOFFSET
",5
"        x, y = l.XM+dx, l.YM+l.YS
        s.reserves.append(GrandDuchess_Reserve(x, y, self))
        x, y = self.width-dx-l.XS, l.YM+l.YS
",5
"        pass

    def getAutoStacks(self, event=None):
        return ((), (), self.sg.dropstacks)

",5
"# ************************************************************************
# * Parisienne
# ************************************************************************

class Parisienne(GrandDuchess):
",5
"
class GrandDuchessPlus(GrandDuchess):
",5
"                      altnames=('La Parisienne', 'Parisian')))
",5
"registerGame(GameInfo(618, GrandDuchessPlus, ""Grand Duchess +"",
",5
"                      GI.GT_2DECK_TYPE, 2, 3))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
",5
"        WasteTalonStack
",5
"        if c0.rank != c.rank:
",5
"            return (None, 0)
",5
"        self.setSize(w, h)

        # create stacks
",5
"        for i in range(9):
            s.rows.append(Simplex_RowStack(x, y, self))
",5
"                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_MOSTLY_LUCK))
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"#
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.games.golf import Golf_Hint, Golf_Waste
from pysollib.layout import Layout
",5
"from pysollib.util import ANY_RANK

# ************************************************************************
# * Three Peaks Row Stack
# ************************************************************************
",5
"

",5
"                if not self.cards[-1].face_up:
                    game.flipMove(self)
                game.moveMove(1, self, waste, frames=4, shadow=0)
                self.fillStack()
",5
"            i = i + step[i]
",5
"    def clickHandler(self, event):
        result = OpenStack.doubleclickHandler(self, event)
        if result == 1 and not self.game.score_counted:
",5
"
",5
"            s.rows.append(ThreePeaks_RowStack(x, y, self))
            x = x + l.XS
",5
"                l.XM + l.XS * 3, h - l.YM,
                anchor=""sw"",
                font=self.app.getFont(""canvas_default""))

",5
"        t = _('Score:\011This hand:  ') + str(self.hand_score)
        t = t + _('\011This game:  ') + str(self.game_score)
        self.texts.info.config(text=t)

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        # First count the empty peaks
        for r in self.s.rows[:3]:
            if not r.cards:
                i = i * 2
",5
"            if not r.cards and not self.peaks[r.id]:
                score, self.peaks[r.id] = score + 5 * i, 1
        # Now give credit for the sequence length
",5
"
class ThreePeaksNoScore(ThreePeaks):
    SCORING = 0
",5
"
class UnionSquare_Foundation(AbstractFoundationStack):
",5
"        # self.CARD_YOFFSET = 1

    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
            return False
",5
"            stack_dir = (self.cards[1].rank - self.cards[0].rank) % \
                self.cap.mod
",5
"    RowStack_Class = UnionSquare_RowStack
",5
"    #
    # game overrides
",5
"                                  max_accept=1,  max_move=1, mod=13)

    def createGame(self):
        UnionSquare.createGame(self, rows=20)

",5
"        return self._shuffleHookMoveToTop(
            cards,
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_SSW


",5
"# ************************************************************************
# * Boomerang
# ************************************************************************

class Boomerang_Foundation(AbstractFoundationStack):
",5
"        if not AbstractFoundationStack.acceptsCards(self, from_stack, cards):
            return False
        # check the rank
        # 7, 8, 9, 10, J, Q, K, A, K, Q, J, 10, 9, 8, 7, A
        if len(self.cards) < 7:
",5
"            return cards[0].rank - 6 == len(self.cards)
        elif len(self.cards) == 7:
            return cards[0].rank == ACE
        elif len(self.cards) < 15:
            return cards[0].rank == 20 - len(self.cards)
",5
"        UnionSquare.createGame(self, rows=12)
",5
"
    def fillStack(self, stack):
",5
"# register the game
registerGame(GameInfo(35, UnionSquare, ""Union Square"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_SKILL,
                      altnames=('British Square',),
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"#
# ---------------------------------------------------------------------------##
",5
"from pysollib.stack import \
        OpenStack, \
        SS_FoundationStack, \
        Stack, \
        WasteTalonStack
",5
"# *
",5
"            game.flipMove(self)
",5
"        else:  # not self.cards
            if self.round < self.max_rounds:
                ncards = 0
                rows = list(game.s.rows)[:game.MAX_ROW]
                rows.reverse()
",5
"                            game.flipMove(r)
",5
"

# ************************************************************************
# * Lara's Game
# ************************************************************************
",5
"            x = x + l.XS
            if i == ROW_LENGTH or i == ROW_LENGTH * 2 + 1 \
                    or i == ROW_LENGTH * 3 + 2:
",5
"        # Create reserves
        x, y = l.XM + l.XS * (ROW_LENGTH == 6), \
            l.YM + l.YS * (ROW_LENGTH - (ROW_LENGTH == 6))
",5
"        for i in range(20):
            s.reserves.append(LarasGame_ReserveStack(x, y, self, max_cards=2))
            x += l.XS * (i < (ROW_LENGTH + 4)) - l.XS * (i == (ROW_LENGTH + 9))
",5
"
    #
    # Game extras
    #
",5
"    # game overrides
",5
"            frames=0)
        self.active_row = None
",5
"    def getHighlightPilesStacks(self):
        return ()

    # Finish the current move.
    # Append current active_row to moves.current.
",5
"            stats.player_moves = stats.player_moves + 1
            if moves.index == 0:
                stats.demo_moves = 0    # clear all demo moves
        stats.total_moves = stats.total_moves + 1
        # add current move to history (which is a list of lists)
",5
"        m = m[:len(m) - 1]
        self.moves.state = self.S_REDO
        for atomic_move in m:
            atomic_move.redo(self)
",5
"        self.moves.state = self.S_PLAY
        self.stats.redo_moves = self.stats.redo_moves + 1
        self.stats.total_moves = self.stats.total_moves + 1
        self.hints.list = None
",5
"        p.dump(self.active_row)

",5
"
# ************************************************************************
# * Relaxed Lara's Game
# ************************************************************************
",5
"    Reserve_Cards = 2
",5
"# * Osmosis
# ************************************************************************

",5
"
class Osmosis_Foundation(AbstractFoundationStack):
",5
"        return True

    def getHelp(self):
        return _('Foundation. Build in suit regardless of rank.')

",5
"
class Osmosis(Game):
",5
"    #

    def createGame(self, max_rounds=-1, num_deal=1):
        # create layout
        l, s = Layout(self), self.s
",5
"            stack = BasicRowStack(x, y, self, max_move=1, max_accept=0)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
            s.rows.append(stack)
",5
"            y = y + l.YS
        x, y, = self.width - l.XS, l.YM + l.YS
        s.talon = WasteTalonStack(x, y, self,
",5
"                                  max_rounds=max_rounds, num_deal=num_deal)
        l.createText(s.talon, ""sw"")
        y = y + l.YS
        s.waste = WasteStack(x, y, self)
",5
"        base_card = self.s.talon.getCard()
        n = base_card.suit * self.gameinfo.decks
        to_stack = self.s.foundations[n]
        self.startDealSample()
",5
"        self.flipMove(self.s.talon)
",5
"        self.moveMove(1, self.s.talon, to_stack)
        # deal cards
        for i in range(3):
            self.s.talon.dealRow(flip=flip)
        self.s.talon.dealRow()
",5
"
class Peek(Osmosis):
    def startGame(self):
",5
"        for c1 in below_found.cards:
            if c0.rank == c1.rank:
                return True
        return False

",5
"        self.s.talon.dealRow()
        # deal one card to foundation
        self.s.talon.dealRow(rows=self.s.foundations[:1])
        # deal cards to WasteStack
",5
"        l, s = Layout(self), self.s
",5
"
        # set window
        w, h = max(2*l.XM+2*l.XS+(5+13)*l.XOFFSET, l.XM + 8*l.XS), l.YM+8*l.YS
",5
"# ************************************************************************
# * Genesis
# ************************************************************************

class Genesis(Game):
",5
"        # create layout
",5
"        l, s = Layout(self), self.s
",5
"        x, y, = l.XM, h-2*l.YS-3*l.YOFFSET
",5
"
        # define stack-groups
        l.defaultStackGroups()
",5
"
    def startGame(self):
        for i in range(3):
            self.s.talon.dealRow(rows=self.s.rows[13:], frames=0)
",5
"
# ************************************************************************
# * Bridesmaids
# ************************************************************************

",5
"        l, s = Layout(self), self.s

        # set window
        w, h = l.XM+3*l.XS+12*l.XOFFSET, l.YM+4*l.YS
",5
"        self.setSize(w, h)
",5
"                                  num_deal=3)
        l.createText(s.talon, 'se')
",5
"        y += l.YS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 'se')

",5
"            y += l.YS

        # define stack-groups
",5
"    def startGame(self, flip=0):
",5
"        self.startDealSample()
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.hint import CautiousDefaultHint
",5
"        stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"            self.s.talon.dealRow(rows=self.s.rows[-i:])
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC

",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"        # set window
        max_rows = max(rows, reserves)
        w, h = l.XM + max_rows*l.XS, l.YM + 2*l.YS + (12+playcards)*l.YOFFSET
        self.setSize(w, h)

",5
"
",5
"
",5
"
# ************************************************************************
# * Flourish
# ************************************************************************
",5
"
class Flourish(WaveMotion):
    RowStack_Class = AC_RowStack
",5
"                      GI.GT_1DECK_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(753, Flourish, ""Flourish"",
",5
"                      GI.GT_1DECK_TYPE | GI.GT_OPEN | GI.GT_ORIGINAL, 1, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.games.spider import Spider_SS_Foundation
",5
"from pysollib.mygettext import _
from pysollib.pysoltk import MfxCanvasText
from pysollib.stack import \
    DealRowTalonStack, \
    InitialDealTalonStack, \
",5
"class Yukon(Game):
    Layout_Method = staticmethod(Layout.yukonLayout)
    Talon_Class = InitialDealTalonStack
    Foundation_Class = SS_FoundationStack
    RowStack_Class = StackWrapper(Yukon_AC_RowStack, base_rank=KING)
",5
"        for r in l.s.foundations:
",5
"            s.foundations.append(
                self.Foundation_Class(
                    r.x, r.y, self, suit=r.suit, max_move=0))
        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self))
",5
"# * Russian Solitaire (like Yukon, but build down by suit)
# ************************************************************************

class RussianSolitaire(Yukon):
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit != card2.suit and
                abs(card1.rank-card2.rank) == 1)

",5
"
# ************************************************************************
",5
"
class Grandfather_Talon(RedealTalonStack):
",5
"
",5
"class Alaska_RowStack(Yukon_SS_RowStack):
    def _isSequence(self, c1, c2):
        return (c1.suit == c2.suit and
                ((c1.rank + self.cap.dir) % self.cap.mod == c2.rank or
                 (c2.rank + self.cap.dir) % self.cap.mod == c1.rank))
",5
"

# ************************************************************************
",5
"                 'any face-up cards regardless of sequence.')
",5
"

class Roslin(Yukon):
    RowStack_Class = StackWrapper(Roslin_RowStack, base_rank=KING)

",5
"        return Yukon.createGame(self, waste=0, texts=1)

    def startGame(self):
        for i in (3, 3, 3, 4, 5, 6):
",5
"    Layout_Method = staticmethod(Layout.klondikeLayout)
    Talon_Class = DealRowTalonStack
",5
"class Rushdike(RussianSolitaire):
    Layout_Method = staticmethod(Layout.klondikeLayout)
    Talon_Class = DealRowTalonStack

",5
"        return RussianSolitaire.createGame(self, waste=0, texts=1)
",5
"    def startGame(self, flip=0, reverse=1):
",5
"        r = self.s.rows
        for i in (1, 1, 2, 2, 3, 3):
            self.s.talon.dealRow(rows=r[i:len(r)-i], flip=0, frames=0)
",5
"
    def createGame(self):
        layout = Rushdike.createGame(self)
        help = (_('''\
",5
"                ((card1.rank + dir) % mod == card2.rank or
",5
"# ************************************************************************
# * Double Yukon
# * Double Russian Solitaire
# ************************************************************************
",5
"    shallHighlightMatch = Game._shallHighlightMatch_SS


",5
"            self.s.talon.dealRow(rows=self.s.rows[i:], flip=0, frames=0)
        for i in range(5):
            self.s.talon.dealRow(rows=self.s.rows, flip=1, frames=0)
        self._startAndDealRow()
",5
"# ************************************************************************
",5
"    RowStack_Class = StackWrapper(Yukon_SS_RowStack, base_rank=KING)
    Layout_Method = staticmethod(Layout.freeCellLayout)

    #
    # game layout
",5
"    #

",5
"        lay, s = Layout(self), self.s
        kwdefault(layout, rows=10, reserves=2, texts=0)
        self.Layout_Method(lay, **layout)
        self.setSize(lay.size[0], lay.size[1])
",5
"    #

    def startGame(self):
        n = 1
        for i in range(4):
",5
"

# ************************************************************************
",5
"            s.foundations.append(
                SS_FoundationStack(r.x, r.y, self, suit=r.suit))
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self))
",5
"        self._startDealNumRowsAndDealRowAndCards(3)

",5
"
class RawPrawn(AustralianPatience):
",5
"    RowStack_Class = Yukon_SS_RowStack


class BimBom(AustralianPatience):
    RowStack_Class = Yukon_SS_RowStack
",5
"
",5
"
",5
"        for i in (4, 4, 4, 4, 8):
            self.s.talon.dealRow(rows=self.s.rows[:i], flip=1, frames=0)
            self.s.talon.dealRow(rows=self.s.rows[i:], flip=0, frames=0)
",5
"    def createGame(self):
        Yukon.createGame(self, waste=0)
",5
"

class RussianSpider(RussianSolitaire):
    RowStack_Class = StackWrapper(RussianSpider_RowStack, base_rank=KING)
",5
"    Foundation_Class = Spider_SS_Foundation

",5
"    def createGame(self, rows=7):
        # create layout
        l, s = Layout(self), self.s
        l.yukonLayout(rows=rows, texts=0, playcards=25)
        self.setSize(l.size[0], l.size[1])
",5
"# ************************************************************************

class Brisbane_RowStack(Yukon_AC_RowStack):
    def _isSequence(self, c1, c2):
        return (c1.rank + self.cap.dir) % self.cap.mod == c2.rank
",5
"
    def startGame(self):
        for i in range(1, len(self.s.rows)):
",5
"        self.s.talon.dealRow()
        self.s.talon.dealRowAvail()
",5
"
    def getHighlightPilesStacks(self):
        return ()

    shallHighlightMatch = Game._shallHighlightMatch_RK
",5
"

",5
"# ************************************************************************
# * Hawaiian
# ************************************************************************

",5
"class Hawaiian(Game):
    Hint_Class = Yukon_Hint

    def createGame(self, rows=10, playcards=20):
        l, s = Layout(self), self.s
",5
"        self.setSize(l.XM+max(rows, 8)*l.XS,
                     l.YM+2*l.YS+playcards*l.YOFFSET)
        x, y = l.XM, l.YM
",5
"            x += l.XS
        x, y = self.width-rows*l.XS, l.YM+l.YS
        for i in range(rows):
",5
"    def getHighlightPilesStacks(self):
",5
"        l.klondikeLayout(rows=rows, waste=0, playcards=25)
        self.setSize(l.size[0], l.size[1])
        s.talon = WaveTalon(l.s.talon.x, l.s.talon.y, self)
",5
"                      GI.GT_YUKON | GI.GT_XORIGINAL, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(189, Queenie, ""Queenie"",
",5
"registerGame(GameInfo(525, Queensland, ""Queensland"",
                      GI.GT_YUKON, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(530, RussianSpider, ""Russian Spider"",
                      GI.GT_SPIDER, 1, 0, GI.SL_BALANCED,
                      altnames=('Ukrainian Solitaire',)))
",5
"registerGame(GameInfo(732, Wave, ""Wave"",
                      GI.GT_2DECK_TYPE | GI.GT_ORIGINAL, 2, 0, GI.SL_BALANCED))
#!/usr/bin/env python
",5
"    def canDealCards(self):
        return len(self.cards) or self.round != self.max_rounds
",5
"        if sound:
            game.startDealSample()
        # shuffle
        game.shuffleStackMove(self)
        # redeal
",5
"                      altnames=(""Die boese Sieben"",)))
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"        BasicRowStack, \
        DealRowTalonStack, \
        InitialDealTalonStack, \
        OpenStack, \
",5
"        OpenTalonStack, \
        RK_RowStack, \
        SS_FoundationStack, \
        SS_RowStack, \
        StackWrapper, \
",5
"        # default
        l.defaultAll()

    #
    # game overrides
",5
"        return True

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        self.startDealSample()
        self.s.talon.dealRow()
",5
"        self.s.talon.fillStack()

",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.color != card2.color and \
            abs(card1.rank-card2.rank) in (0, 1)


",5
"# * Harvestman
# ************************************************************************
",5
"
",5
"            return True
        c1, c2 = self.cards[-1], cards[0]
        if c1.rank == c2.rank+1:
            return True
        return c1.rank == c2.rank
",5
"        return isSameSuitSequence(cards) or isRankSequence(cards, dir=0)
",5
"        for i in range(10):
",5
"                max_accept=0, max_cards=104))
        l.createText(s.foundations[0], ""s"")

        # define stack-groups
",5
"
    def startGame(self):
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank == card2.rank or abs(card1.rank-card2.rank) == 1

",5
"
    def createGame(self, rows=8):

        l, s = Layout(self), self.s
",5
"
        w, h = l.XM+rows*l.XS, l.YM+2*l.YS+14*l.YOFFSET
        self.setSize(w, h)

        x, y = l.XM, l.YM
",5
"        for i in range(rows):
            s.rows.append(
                RK_RowStack(
                    x, y, self, max_cards=13, mod=13, dir=1, max_move=1))
",5
"                card = r.cards[-1]
                if len(r.cards) == 1 and t.acceptsCards(r, [card]):
                    if len(t.cards) > 1:
",5
"                        self.addHint(6000+card.rank, 1, r, t)
                    else:
                        self.addHint(5000+card.rank, 1, r, t)

",5
"        x, y = l.XM, l.YM
        s.talon = TalonStack(x, y, self)
        l.createText(s.talon, ""s"")
        x += l.XS
",5
"                self.s.talon.flipMove()
                self.s.talon.moveMove(1, stack)
",5
"                self.leaveState(old_state)
",5
"            x = l.XM+l.XS
            for j in range(8):
",5
"# ************************************************************************
# * Eight Packs (ex. Four Packs)
# * Four Packs
# ************************************************************************
",5
"
",5
"        x, y = l.XM, l.YM
        for i in range(10):
            s.rows.append(self.RowStack_Class(x, y, self, dir=1))
",5
"        l.createText(s.talon, 'n')
",5
"
",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 'n')

        l.defaultStackGroups()

",5
"        return True
",5
"
",5
"                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(312, Galloway, ""Galloway"",
                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(313, Robin, ""Robin"",
                      GI.GT_2DECK_TYPE | GI.GT_ORIGINAL, 2, 0,
",5
"                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(481, KnottyNines, ""Knotty Nines"",
                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(482, SweetSixteen, ""Sweet Sixteen"",
                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_BALANCED))
",5
"                      GI.GT_2DECK_TYPE | GI.GT_ORIGINAL, 2, 2,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(762, FourPacks, ""Four Packs"",
                      GI.GT_2DECK_TYPE, 2, 1, GI.SL_MOSTLY_SKILL))
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"        WasteTalonStack
from pysollib.util import ACE, ANY_SUIT, KING, UNLIMITED_CARDS

",5
"
        # set window
        max_x = max([i[0] for i in self.FOUNDATIONS_LAYOUT+self.ROWS_LAYOUT])
",5
"        l.createText(s.talon, ""s"")
        x = x + l.XS
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=(self.s.foundations[0],))
",5
"        self.s.talon.dealRow()
        self.s.talon.dealCards()          # deal first card to WasteStack
",5
"

class DutchSolitaire(Windmill):
",5
"        StackWrapper(BlackHole_Foundation, suit=ANY_SUIT, mod=13,
                     max_cards=UNLIMITED_CARDS, min_cards=1),
        ]
    RowStack_Class = DutchSolitaire_RowStack
",5
"        def select_cards(c):
            if c.rank == ACE:
                if c.suit in (0, 1):
                    return True, c.suit
",5
"                if c.suit == 3 and c.deck == 0:
",5
"                    return True, c.suit
            return False, None
",5
"        return self._shuffleHookMoveToTop(cards, select_cards)

",5
"
class NapoleonsTomb(pysollib.game.StartDealRowAndCards, Game):

    #
    # game layout
",5
"    #

",5
"                             mod=13, max_cards=24, dir=-1))
        for d in ((0.1, 0.1), (1.9, 0.1), (0.1, 1.9), (1.9, 1.9)):
",5
"            x, y = x0 + d[0] * l.XS, y0 + d[1] * l.YS
            s.foundations.append(Windmill_Foundation(x, y, self,
                                 max_cards=7, base_rank=6, mod=13))

",5
"            x, y = x0+d[0]*l.XS, y0+d[1]*l.YS
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
",5
"        for d in ((2, 0), (1, 1), (2, 1), (3, 1), (2, 2)):
            x, y = x0+d[0]*l.XS, y0+d[1]*l.YS
",5
"        # define stack-groups
",5
"        self.s.talon.dealCards()          # deal first card to WasteStack


",5
"            s.cap.base_rank = self.base_card.rank
",5
"        self.flipMove(self.s.talon)
        self.moveMove(1, self.s.talon, self.s.foundations[self.base_card.suit])
        self.s.talon.dealRow()
        self.s.talon.dealCards()          # deal first 3 cards to WasteStack

",5
"
    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
",5
"
class Simplicity(Game):
    Hint_Class = CautiousDefaultHint

    def createGame(self, max_rounds=2):
",5
"
        i = 0
        for x, y in ((l.XM,        l.YM),
",5
"        self.moveMove(1, self.s.talon, self.s.foundations[self.base_card.suit])
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_ACW

",5
"    def _restoreGameHook(self, game):
        self.base_card = self.cards[game.loadinfo.base_card_id]
        for s in self.s.foundations:
            s.cap.base_rank = self.base_card.rank
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"#
# ---------------------------------------------------------------------------##

from pysollib.game import Game
",5
"        RK_FoundationStack, \
        RedealTalonStack, \
        SS_FoundationStack, \
        StackWrapper, \
",5
"    Hint_Class = CautiousDefaultHint
    Talon_Class = StackWrapper(RedealTalonStack, max_rounds=3)
    RowStack_Class = UD_SS_RowStack
",5
"
    def createGame(self, rows=12, round_text=True):
",5
"        s.talon = self.Talon_Class(l.XM, l.YM, self)
        if round_text:
",5
"        # define stack-groups
        l.defaultStackGroups()

    #
    # game overrides
",5
"# ************************************************************************

",5
"    def createGame(self):

        # create layout
        l, s = Layout(self), self.s
",5
"
        # create stacks
",5
"        x, y, = l.XM+l.XS, l.YM
",5
"        for i in range(8):
            s.foundations.append(DieRussische_Foundation(x, y, self,
                                 suit=i % 4, max_cards=8))
            x += l.XS
",5
"        l.defaultStackGroups()

    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(7)
",5
"
    def startGame(self):
        self._startDealNumRows(6)
        self.s.talon.dealRowAvail()

",5
"        for f in self.game.s.foundations:
            if len(f.cards) > num_cards:
                suit = f.cards[num_cards].suit
                break
        else:
",5
"        for i in range(rows):
",5
"
        # define stack-groups
",5
"    shallHighlightMatch = Game._shallHighlightMatch_AC

",5
"registerGame(GameInfo(293, Nationale, ""Nationale"",
                      GI.GT_BAKERS_DOZEN | GI.GT_OPEN, 2, 0,
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"    getBottomImage = Stack._getReserveBottomImage


",5
"        #             return False
        return ReserveStack.acceptsCards(self, from_stack, cards)
",5
"            return False
        return ReserveStack.canMoveCards(self, cards)


",5
"
    #
",5
"        x0 = l.XM + 24 + 4*l.XS
        x1 = x0 + l.XS + l.XM
        x2 = x1 + l.XS + l.XM
",5
"
        # create stacks
        y = l.YM
        for i in range(4):
            s.rows.append(self.RowStack_Class(x0, y, self))
",5
"            y = y + l.YS
        # talon
        if cells == 1:
            # x, y = l.XM, self.height - l.YS
            y = self.height + l.YS
",5
"        else:
            y = self.height - l.YS
        s.talon = InitialDealTalonStack(x, y, self)

        # update stack building direction
",5
"    def _shuffleHook(self, cards):
",5
"        rank = cards[-1].rank
        return self._shuffleHookMoveToBottom(
            cards, lambda c, rank=rank: (c.rank == rank, c.suit))
",5
"    def startGame(self):
        for i in range(4):
            self.s.talon.dealRow(rows=self.s.rows[:8], frames=0)
        self.startDealSample()
",5
"    #
    # game extras
    #

",5
"    def updateText(self):
        if self.preview > 1 or not self.texts.info:
            return
        t = """"
",5
"

# ************************************************************************
# * Der freie Napoleon (completely equivalent to Der kleine Napoleon,
",5
"# * just a different layout)
# ************************************************************************

class DerFreieNapoleon(DerKleineNapoleon):
",5
"        l, s = Layout(self), self.s

",5
"        for j in range(8):
            x = l.XM + j*l.XS
            s.rows.append(self.RowStack_Class(x, y, self))
        for j in range(reserves):
",5
"        y = l.YM
        x = x1+(max(cells, reserves)-cells)*l.XS//2
        for i in range(cells):
            s.reserves.append(self.FreeCell_Class(x, y, self))
",5
"            x += l.XS
        # foundations
        x = l.XM + 2*l.XS
        for i in range(4):
",5
"            font = self.app.getFont(""canvas_default"")
",5
"        DerFreieNapoleon.createGame(self, cells=2, texts=False)

    def _shuffleHook(self, cards):
",5
"        return self._shuffleHookMoveToBottom(cards,
                                             lambda c: (c.rank == ACE, c.suit))

",5
"    def acceptsCards(self, from_stack, cards):
",5
"            s.foundations.append(Braid_Foundation(x, y, self, suit=i))
            x += l.XS
        tx, ty, ta, tf = l.getTextAttr(s.foundations[-1], ""se"")
",5
"    def startGame(self):
        for i in range(4):
            self.s.talon.dealRow(rows=self.s.rows, frames=0)
        self.startDealSample()
",5
"
    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"

class Bonaparte(TheLittleCorporal):

    def createGame(self):
",5
"        TheLittleCorporal.createGame(self, rows=8)

    def startGame(self):
",5
"        self._startDealNumRows(5)
        self.s.talon.dealRow()
",5
"# ************************************************************************

class BusyCards_FreeCell(ReserveStack):
",5
"
",5
"        l.defaultStackGroups()

",5
"    def _shuffleHook(self, cards):
        return self._shuffleHookMoveToTop(
",5
"registerGame(GameInfo(705, BusyCards, ""Busy Cards"",
                      GI.GT_NAPOLEON | GI.GT_OPEN | GI.GT_ORIGINAL, 2, 0,
                      GI.SL_MOSTLY_SKILL))
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
",5
"        AC_RowStack, \
        KingAC_RowStack, \
        OpenStack, \
",5
"

",5
"            if len(cards) != 1 and len(cards) != len(from_stack.cards):
",5
"

class Canfield_RK_RowStack(RK_RowStack):
    def basicAcceptsCards(self, from_stack, cards):
",5
"            if self.INITIAL_RESERVE_CARDS > 30:
                yoffset = 5
        # (piles up to 20 cards are playable in default window size)
        h = max(3*lay.YS, lay.YS+self.INITIAL_RESERVE_CARDS*yoffset)
        if round_text:
",5
"            self.texts.info = MfxCanvasText(self.canvas, tx, ty,
                                            anchor=ta, font=font)
        x, y = lay.XM, lay.YM + lay.YS + lay.TEXT_HEIGHT
        if round_text:
            y += lay.TEXT_HEIGHT
",5
"        if text:
",5
"            y += lay.TEXT_HEIGHT
        for i in range(rows):
            s.rows.append(self.RowStack_Class(x, y, self))
",5
"
    #
    # game extras
    #
",5
"            return
        if not self.texts.info:
",5
"            return
        if not self.base_card:
            t = """"
        else:
            t = RANKS[self.base_card.rank]
",5
"            s.cap.base_rank = self.base_card.rank
        n = self.base_card.suit * self.gameinfo.decks
        if self.s.foundations[n].cards:
",5
"            self.moveMove(
                1, self.s.talon, self.s.reserves[0], frames=4, shadow=0)
        if self.s.reserves[0].canFlipCard():
            self.flipMove(self.s.reserves[0])
        self.s.talon.dealRow(reverse=1)
",5
"

# ************************************************************************
# * Rainbow
",5
"# ************************************************************************

",5
"    RowStack_Class = StackWrapper(Canfield_RK_RowStack, mod=13)
",5
"
    def createGame(self):
        Canfield.createGame(self, max_rounds=1, num_deal=1)

    shallHighlightMatch = Game._shallHighlightMatch_RKW
",5
"# ************************************************************************
# * Storehouse (aka Straight Up)
# ************************************************************************


",5
"        self.s.talon.dealRow(rows=self.s.foundations[:3])
        Canfield.startGame(self)
",5
"
",5
"
",5
"    shallHighlightMatch = Game._shallHighlightMatch_SSW

",5
"
    def startGame(self):
        self.startDealSample()
",5
"        lay, s = Layout(self), self.s

",5
"        # set window
        self.setSize(lay.XM + 9*lay.XS + lay.XM, lay.YM + 4*lay.YS)

        # extra settings
        self.base_card = None
",5
"            s.foundations.append(
                self.Foundation_Class(x, y, self, i, mod=13, max_move=0))
        tx, ty, ta, tf = lay.getTextAttr(None, ""se"")
",5
"        tx, ty = x + tx + lay.XM, y + ty
        font = self.app.getFont(""canvas_default"")
        self.texts.info = MfxCanvasText(
",5
"        for i in range(8):
            x = lay.XM + (i + (i >= 4))*lay.XS
",5
"    #

    def createGame(self):
        # create layout
        lay, s = Layout(self), self.s
",5
"        s.talon = WasteTalonStack(lay.XM, h-lay.YS, self, max_rounds=1)
        lay.createText(s.talon, ""n"")
        s.waste = WasteStack(lay.XM+lay.XS, h-lay.YS, self)
        lay.createText(s.waste, ""n"")
",5
"    #
    # game overrides
    #
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"                    from_stack = r2
            elif self.s.waste.cards:
                from_stack = self.s.waste
            if from_stack:
                from_stack.moveMove(1, stack)
",5
"    #
",5
"        x, y = lay.XM+(max_rows-rows)*lay.XS//2, lay.YM+lay.YS+lay.TEXT_HEIGHT
        for i in range(rows):
            s.rows.append(self.RowStack_Class(x, y, self))
",5
"
",5
"        queen_stack.cap.base_rank = QUEEN

",5
"    def startGame(self):
        self.startDealSample()
",5
"# * Mystique
# ************************************************************************

class Minerva(Canfield):
    RowStack_Class = KingAC_RowStack
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"# ************************************************************************
# * Triple Canfield
",5
"    Hint_Class = Canfield_Hint

    def createGame(self):
        Canfield.createGame(self, max_rounds=2, num_deal=1, round_text=True)
",5
"            self.moveMove(
                1, self.s.talon, self.s.reserves[0], frames=4, shadow=0)
        self.flipMove(self.s.reserves[0])
        self.s.talon.dealRow(reverse=1)
        self.s.talon.dealCards()
",5
"        lay.createRoundText(s.talon, 'ne', dx=lay.XS)
        x += lay.XS
        s.waste = WasteStack(x, y, self)
        lay.createText(s.waste, 's')
",5
"        for i in range(4):
            s.foundations.append(self.Foundation_Class(x, y, self, suit=i))
            x += lay.XS
        x0, y0, w = lay.XM, lay.YM+lay.YS+2*lay.TEXT_HEIGHT,\
            lay.XS+2*lay.XOFFSET
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()

    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"

# ************************************************************************
# * Demon
# ************************************************************************
",5
"    def dealCards(self, sound=False):
        self.num_deal = 4-self.round
        return WasteTalonStack.dealCards(self, sound=sound)
",5
"

",5
"class CanfieldRush(Canfield):
    Talon_Class = CanfieldRush_Talon
    # RowStack_Class = StackWrapper(AC_RowStack, mod=13)
",5
"# ************************************************************************

class Skippy(Canfield):
    FILL_EMPTY_ROWS = 0
",5
"        lay.createText(s.talon, 's')
        x += lay.XS
",5
"                stack = RK_RowStack(x, y, self, max_move=1, mod=13)
                s.rows.append(stack)
",5
"        self.moveMove(1, self.s.talon, self.s.foundations[n], frames=0)
        self.updateText()
        # update rows cap.base_rank
        row_base_rank = (self.base_card.rank-1) % 13
        for s in self.s.rows:
",5
"        self._startDealNumRowsAndDealRowAndCards(3)

",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            s.foundations.append(SS_FoundationStack(x+4*lay.XS, y, self,
",5
"        lay.createText(s.talon, 'ne')
        y += lay.YS
",5
"        s.waste = WasteStack(x, y, self)
        lay.createText(s.waste, 'ne')
        x, y = lay.XM+2*lay.XS, lay.YM+lay.YS
        for i in range(4):
",5
"registerGame(GameInfo(108, Rainbow, ""Rainbow"",
                      GI.GT_CANFIELD, 1, 0, GI.SL_BALANCED))
",5
"registerGame(GameInfo(315, Gate, ""Gate"",
",5
"registerGame(GameInfo(527, Doorway, ""Doorway"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_BALANCED,
                      altnames=('Solstice',)))
",5
"# ---------------------------------------------------------------------------##
#
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"# * Castles in Spain
",5
"# ************************************************************************
",5
"        self.Layout_Method(l, **layout)
        self.setSize(l.size[0], l.size[1])
",5
"        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self)
        for r in l.s.foundations:
            s.foundations.append(
                self.Foundation_Class(r.x, r.y, self, suit=r.suit))
        for r in l.s.rows:
",5
"
# ************************************************************************
",5
"            return False
        # when empty, only accept a single card
        return self.cards or len(cards) == 1
",5
"
",5
"    def createGame(self):
",5
"
    def _shuffleHook(self, cards):
",5
"            cards, lambda c: (c.rank == 0, c.suit))

    def startGame(self):
",5
"        for i in kings:
            j = i % n
            while j < i:
                if cards[j].rank != KING:
",5
"                    cards[i], cards[j] = cards[j], cards[i]
                    break
                j = j + n
        cards.reverse()
        return cards
",5
"
",5
"# ************************************************************************
# * Spanish Patience
# * Portuguese Solitaire
# ************************************************************************

",5
"    Foundation_Class = AC_FoundationStack
    Solver_Class = None
",5
"
class PortugueseSolitaire(BakersDozen):
    RowStack_Class = StackWrapper(RK_RowStack, base_rank=KING, max_move=1)
    Solver_Class = FreeCellSolverWrapper(sbb='rank', esf='kings')
",5
"
",5
"class GoodMeasure(BakersDozen):
    Solver_Class = FreeCellSolverWrapper(preset='good_measure')

    def createGame(self):
        CastlesInSpain.createGame(self, rows=10)
",5
"        cards = BakersDozen._shuffleHook(self, cards)
        # move 2 Aces to bottom of the Talon (i.e. last cards to be dealt)
        return self._shuffleHookMoveToBottom(
            cards, lambda c: (c.rank == 0, c.suit), 2)

",5
"
class Cruel(CastlesInSpain):
    Talon_Class = StackWrapper(Cruel_Talon, max_rounds=-1)
    RowStack_Class = StackWrapper(SS_RowStack, base_rank=NO_RANK)
    # Solver_Class = FreeCellSolverWrapper(preset='cruel')
",5
"        lay = Cruel.createGame(self)
",5
"        cards = Cruel._shuffleHook(self, cards)
        return cards

",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s
        Layout.bakersDozenLayout(l, rows=13)
",5
"        s.talon = Cruel_Talon(l.s.talon.x, l.s.talon.y, self, max_rounds=-1)
        for r in l.s.foundations:
            s.foundations.append(
                SS_FoundationStack(r.x, r.y, self, suit=r.suit))
        for r in l.s.rows:
",5
"registerGame(GameInfo(86, GoodMeasure, ""Good Measure"",
                      GI.GT_BAKERS_DOZEN | GI.GT_OPEN, 1, 0,
",5
"                      GI.GT_BAKERS_DOZEN | GI.GT_OPEN, 1, 1,
                      GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(664, SpanishPatienceII, ""Spanish Patience II"",
                      GI.GT_BAKERS_DOZEN | GI.GT_OPEN, 1, 0,
",5
"# *
# ************************************************************************
",5
"
# ************************************************************************
# * Montana
# ************************************************************************

",5
"                if in_sequence:
                    if (not r.cards or
                            not self._inSequence(r.cards[-1], suit, RBASE+j)):
",5
"                    if r.cards:
                        game.moveMove(1, r, self, frames=0)
",5
"        # the spaces are directly after the sorted sequence in each row
        return gaps


",5
"                    x += l.XS
",5
"            s.talon = self.Talon_Class(x, y, self)
        if self.RBASE:
            # create an invisible stack to hold the four Aces
",5
"
    #
    # game overrides
    #
",5
"        rows = self.s.rows
        for i in range(0, self.RLEN, self.RSTEP):
            if not rows[i].cards:
                return False
            suit = rows[i].cards[-1].suit
",5
"    shallHighlightMatch = Game._shallHighlightMatch_SS

    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"        spaces = []
        while len(spaces) != 4:
            r = self.game.random.choice(stacks)
",5
"
# ************************************************************************
# * Blue Moon
",5
"    RLEN, RSTEP, RBASE = 56, 14, 0
",5
"class RedMoon(BlueMoon):
    def _shuffleHook(self, cards):
        # move Aces to top of the Talon (i.e. first cards to be dealt)
",5
"        return False


",5
"class Jungle(BlueMoon):
    Talon_Class = StackWrapper(Montana_Talon, max_rounds=2)
    RowStack_Class = Jungle_RowStack
",5
"
class Paganini_Talon(Montana_Talon):
    def _inSequence(self, card, suit, rank):
        card_rank = card.rank
        if card_rank >= 5:
",5
"        return left.cards[-1].rank+1 == cards[0].rank

",5
"class Paganini(BlueMoon):
    RLEN, RSTEP, RBASE = 40, 10, 0

    Talon_Class = StackWrapper(Paganini_Talon, max_rounds=2)
",5
"    RowStack_Class = Paganini_RowStack
",5
"                    return False
        return True
",5
"    def acceptsCards(self, from_stack, cards):
        # if not BasicRowStack.acceptsCards(self, from_stack, cards):
",5
"        row, col = divmod(self.id, RSTEP)
",5
"            if col != RSTEP-1:
                return False
        else:
            if card.rank - RBASE != col:
                return False
",5
"        if suit is not None:
            return card.suit == suit
        for r in self.game.s.rows:      # check other rows
            if r.cards and r.cards[0].face_up and r.cards[0].suit == card.suit:
",5
"        game.moveMove(n, swap, other_stack, frames=0)
        game.leaveState(old_state)

",5
"
class Spoilt(Game):
    RSTEP, RBASE = 8, 6
",5
"            if not r.cards:
                return False
",5
"            if not r.cards[0].face_up:
",5
"
class DoubleBlueMoon(DoubleMontana, BlueMoon):
    Talon_Class = StackWrapper(Montana_Talon, max_rounds=3)
",5
"    startGame = RedMoon.startGame


",5
"                      GI.GT_MONTANA, 1, 0, GI.SL_MOSTLY_LUCK,
",5
"from pysollib.layout import Layout
",5
"from pysollib.stack import \
        AC_RowStack, \
        FreeCell_SS_RowStack, \
",5
"# ************************************************************************
",5
"
    def createGame(self, rows=8, reserves=8):
        # create layout
        l, s = Layout(self), self.s

",5
"        self.setSize(l.XM + maxrows*l.XS, l.YM + l.YS + h + l.YS)

",5
"            s.reserves.append(ReserveStack(x, y, self))
            x = x + l.XS
        self.setRegion(s.reserves, (-999, y - l.CH // 2, 999999, 999999))
        s.talon = InitialDealTalonStack(l.XM, l.YM, self)
",5
"    #
    # game layout
    #

    def createGame(self):
",5
"        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.rows + s.reserves
        self.sg.reservestacks = s.reserves
",5
"            s.rows.append(self.RowStack_Class(x, y, self))
            x = x + l.XS
        x, y = l.XM + (maxrows-reserves)*l.XS//2, self.height - l.YS
",5
"        s.talon = InitialDealTalonStack(l.XM+1, y, self)

        # define stack-groups
        l.defaultStackGroups()
",5
"
    def startGame(self):
        self._startDealNumRows(6)
        self.s.talon.dealRow()
",5
"        self.s.talon.dealRow(rows=self.s.rows[::3])

    shallHighlightMatch = Game._shallHighlightMatch_SSW
",5
"        for s in self.s.foundations:
            s.cap.base_rank = self.base_card.rank
        for s in self.s.rows:
            s.cap.base_rank = (self.base_card.rank - 1) % 13

",5
"            to_stack = self.s.foundations[c.suit * self.gameinfo.decks]
            self.flipMove(self.s.talon)
            self.moveMove(1, self.s.talon, to_stack, frames=0)
",5
"

# ************************************************************************
# * Flipper
",5
"# ************************************************************************
",5
"            return False
        i = list(self.game.s.rows).index(self)
        return len(self.game.s.reserves[i].cards) == 0


",5
"            i += 1
",5
"registerGame(GameInfo(6, RelaxedSeahavenTowers, ""Relaxed Seahaven Towers"",
                      GI.GT_FREECELL | GI.GT_RELAXED | GI.GT_OPEN, 1, 0,
                      GI.SL_SKILL))
",5
"registerGame(GameInfo(64, Penguin, ""Penguin"",
",5
"                      GI.GT_FREECELL | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"from pysollib.layout import Layout
from pysollib.mfxutil import kwdefault
from pysollib.mygettext import _
from pysollib.pysoltk import MfxCanvasText
",5
"        AbstractFoundationStack, \
        BasicRowStack, \
        DealRowTalonStack, \
",5
"                continue
            # this assertion must hold for Golf
",5
"                    continue
                if t is r:
",5
"            self.addHint(score, ncards, r, w, color)
",5
"
class Golf(Game):
    Solver_Class = BlackHoleSolverWrapper(preset='golf', base_rank=0,
",5
"
        # set window
        playcards = 5
",5
"        w1, w2 = 8*l.XS+l.XM, 2*l.XS
        if w2 + 52*l.XOFFSET > w1:
",5
"        if event is None:
            # disable auto drop - this would ruin the whole gameplay
            return (self.sg.dropstacks, (), ())
        else:
",5
"            # rightclickHandler
",5
"            return (self.sg.dropstacks, self.sg.dropstacks, ())


# ************************************************************************
# *
",5
"
class Elevator_RowStack(Golf_RowStack):
    STEP = (1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6)

",5
"        # define stack-groups (non default)
",5
"
    #
    # game overrides
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:21], flip=0)
        self.s.talon.dealRow(rows=self.s.rows[21:])
        self.s.talon.dealCards()          # deal first card to WasteStack
",5
"                x = l.XM + j*w
                s.rows.append(self.RowStack_Class(x, y, self))
        y = y + l.YS
",5
"    #

    def _shuffleHook(self, cards):
        # move Ace to bottom of the Talon (i.e. last cards to be dealt)
        return self._shuffleHookMoveToBottom(
",5
"        if self.cards:
            r1, r2 = self.cards[-1].rank, cards[0].rank
            return (r1 + 1) % self.cap.mod == r2
        return True

",5
"        l, s = Layout(self), self.s
",5
"        l, s = Layout(self), self.s
",5
"            x += l.XS
",5
"        for r in s.rows:
            r.CARD_XOFFSET, r.CARD_YOFFSET = 0, l.YOFFSET

",5
"
    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(3)

",5
"
# ************************************************************************
# * Robert
# * Wasatch
# ************************************************************************
",5
"
",5
"        Robert.createGame(self, max_rounds=UNLIMITED_REDEALS, num_deal=3)
",5
"            return False
        if cards[0].suit == DIAMOND:
            return False
",5
"    def isGameWon(self):
        if len(self.s.foundations[0].cards) != 13:
            return False
        for s in self.s.rows:
            if len(s.cards) == 0:
",5
"
        dx = (self.width-l.XM-(reserves+1)*l.XS)//3
        x, y = l.XM+dx, l.YM
        for i in range(reserves):
            s.reserves.append(ReserveStack(x, y, self))
",5
"        x += dx
        max_cards = 52*self.gameinfo.decks
        s.foundations.append(RK_FoundationStack(x, y, self,
                             base_rank=ANY_RANK, mod=13, max_cards=max_cards))
",5
"            return c1.rank == ACE and c1.suit == 0
        c2 = self.cards[-1]
        if c2.rank == KING:
            suit = (c2.suit+1) % 4
",5
"        tx, ty, ta, tf = l.getTextAttr(stack, 'se')
        font = self.app.getFont('canvas_default')
        stack.texts.misc = MfxCanvasText(self.canvas, tx, ty,
                                         anchor=ta, font=font)
        x, y = self.width-l.XS, self.height-l.YS
",5
"    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(3)
",5
"            t = ''
",5
"        else:
            c = f.cards[-1]
            if c.rank == KING:
                suit = (c.suit+1) % 4
",5
"# ************************************************************************
",5
"
class Vague(Game):
    Foundation_Classes = [StackWrapper(SS_FoundationStack,
",5
"        maxrows = max(columns, 2+decks*4)
        self.setSize(l.XM+maxrows*l.XS, l.YM+(rows+1)*l.YS)

",5
"                s.foundations.append(found(x, y, self, suit=i))
                x += l.XS

        y = l.YM+l.YS
        for i in range(rows):
",5
"
        l.defaultStackGroups()

",5
"        if event is None:
            # disable auto drop - this would ruin the whole gameplay
            return ((), (), self.sg.dropstacks)
",5
"
class ThirtyTwoCards(Vague):
",5
"    def acceptsCards(self, from_stack, cards):
        if not RK_FoundationStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        self.setSize(l.XM+9*l.XS, l.YM+3*l.YS+7*l.YOFFSET+2*l.TEXT_HEIGHT)
",5
"
        x, y = l.XM+4*l.XS, l.YM
        stack = DevilsSolitaire_Foundation(
            x, y, self, suit=ANY_SUIT, base_rank=ANY_RANK, mod=13)
        tx, ty, ta, tf = l.getTextAttr(stack, 'nw')
",5
"        font = self.app.getFont('canvas_default')
",5
"        s.foundations.append(stack)

        x, y = l.XM, l.YM+l.YS
",5
"
        x, y = l.XM+4*l.XS, l.YM+l.YS
        stack = OpenStack(x, y, self)
        stack.CARD_YOFFSET = l.YOFFSET
",5
"
    def fillStack(self, stack):
        old_state = self.enterState(self.S_FILL)
        if stack in self.s.rows and not stack.cards:
            if not self.s.waste.cards:
",5
"
# ************************************************************************
# * Three Fir-trees
# ************************************************************************
",5
"class ThreeFirTrees_RowStack(Golf_RowStack):
    def __init__(self, x, y, game):
        Golf_RowStack.__init__(self, x, y, game, max_accept=0, max_cards=1)
",5
"        self.CARD_YOFFSET = 0
        self.blockmap = []
",5
"                rows[n+1].blockmap = [rows[n+2]]
                n += 2
            else:
",5
"

",5
"class ThreeFirTrees(Golf, FirTree_GameMethods):
    Hint_Class = CautiousDefaultHint
    Waste_Class = Golf_Waste
",5
"            x0 += 2.5*l.XS

        x, y = l.XM, self.height - l.YS
        s.talon = Golf_Talon(x, y, self, max_rounds=1)
        l.createText(s.talon, 'n')
",5
"    Waste_Class = StackWrapper(Golf_Waste, mod=13)


# ************************************************************************
# * Napoleon Takes Moscow
",5
"# * Napoleon Leaves Moscow
# ************************************************************************

class NapoleonTakesMoscow(Game, FirTree_GameMethods):
    RowStack_Class = StackWrapper(SS_RowStack, base_rank=KING, max_move=1)
",5
"    Hint_Class = CautiousDefaultHint

    def createGame(self):

",5
"        self.setSize(l.XM + rows*l.XS, l.YM + 2*l.YS + playcards*l.XOFFSET)
",5
"        s.talon = InitialDealTalonStack(x, y, self)

        # define stack-groups
",5
"class Beacon(Game):

    def createGame(self, rows=8):
",5
"        # set window
",5
"
        x, y = l.XM, self.height-l.YS
        s.talon = TalonStack(x, y, self)
",5
"            if self.s.talon.cards:
                old_state = self.enterState(self.S_FILL)
                self.s.talon.flipMove()
                self.s.talon.moveMove(1, stack)
                self.leaveState(old_state)
",5
"                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_BALANCED,
                      altnames=('Banner',)))
registerGame(GameInfo(728, ThirtyTwoCards, ""Thirty Two Cards"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_LUCK))
registerGame(GameInfo(731, ThreeFirTrees, ""Three Fir-trees"",
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# ************************************************************************
",5
"# * Tam O'Shanter
# ************************************************************************

class TamOShanter(Game):
",5
"        # set window
        if yoffset is None:
",5
"
        # create stacks
        if texts:
",5
"    def startGame(self):
        self._startAndDealRow()
",5
"# ************************************************************************
",5
"class Strategy_RowStack(BasicRowStack):
",5
"            return False
        # this stack accepts any one card from the Talon
        return from_stack is self.game.s.talon and len(cards) == 1

    def canMoveCards(self, cards):
",5
"
    def clickHandler(self, event):
        if self.game.s.talon.cards:
            self.game.s.talon.playMoveMove(1, self)
            return 1
",5
"        if self.game.s.talon.cards:
            self.game.s.talon.playMoveMove(1, self)
            return 1
        return BasicRowStack.doubleclickHandler(self, event)
",5
"
class Strategy(Game):
    Hint_Class = Numerica_Hint

    def createGame(self, rows=8):
",5
"        # set window
        self.setSize(l.XM + rows*l.XS, l.YM + 4*l.YS)

",5
"        l.defaultStackGroups()
        self.sg.dropstacks.append(s.talon)
",5
"
    #
    # game overrides
    #

",5
"
",5
"

",5
"class Interregnum(Game):
",5
"    GAME_VERSION = 2

    Talon_Class = DealRowTalonStack
    RowStack_Class = StackWrapper(BasicRowStack, max_accept=0, max_move=1)

",5
"        l.defaultStackGroups()

",5
"        self.startDealSample()
        self.s.talon.dealRow()
",5
"                (self.base_cards[i].rank + 1) % 13
            self.flipMove(self.s.talon)
            self.moveMove(1, self.s.talon, self.s.reserves[i])

    def getAutoStacks(self, event=None):
",5
"    def _loadGameHook(self, p):
        ids = []
        for i in range(8):
",5
"        self._dealNumRows(11)
        Interregnum.startGame(self)


# ************************************************************************
",5
"        for i in range(4):
",5
"            s.foundations.append(self.Foundation_Class(x, y, self,
                                 suit=i, max_move=0, base_rank=KING, dir=-1))
",5
"# ************************************************************************

class Amazons_Talon(RedealTalonStack):

    def canDealCards(self):
",5
"        return not self.game.isGameWon()

",5
"    def dealCards(self, sound=False):
",5
"                     frames=-1, sound=False):
        if rows is None:
            rows = []
            i = 0
            for f in self.game.s.foundations:
",5
"                if len(f.cards) < 7:
",5
"        if cards[0].rank == ACE:
            return True
        if not self.cards:
            return False
        rank = self.cards[-1].rank
",5
"        if rank == ACE:
            rank = 5
        if (rank + self.cap.dir) % self.cap.mod != cards[0].rank:
            return False
        if cards[0].rank == QUEEN:
",5
"
",5
"# ************************************************************************
# * Scuffle
# * Acquaintance
# ************************************************************************

",5
"
class Acquaintance_Talon(Scuffle_Talon):
    def dealCards(self, sound=False):
",5
"        Scuffle_Talon.dealCards(self, sound=sound, shuffle=False)


class Acquaintance(AuldLangSyne):
    Talon_Class = StackWrapper(Acquaintance_Talon, max_rounds=3)
",5
"    def createGame(self):
",5
"# ************************************************************************

",5
"    def acceptsCards(self, from_stack, cards):
        if not AbstractFoundationStack.acceptsCards(self, from_stack, cards):
",5
"                (self.cards[-1].rank-1) % 13 == cards[0].rank)

    def getHelp(self):
        return _('Foundation. Build up or down regardless of suit.')
",5
"            x += l.XS
        x, y = l.XM+2*l.XS, l.YM+l.YS
        for i in range(4):
",5
"            s.rows.append(BasicRowStack(x, y, self, max_move=1, max_accept=0))
            x += l.XS

        l.defaultStackGroups()

",5
"    def startGame(self):
        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
",5
"        self._startAndDealRow()
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"        BasicRowStack, \
        DealRowTalonStack, \
        OpenStack, \
        RK_RowStack, \
",5
"        isRankSequence
from pysollib.util import ACE, ANY_RANK, ANY_SUIT, NO_RANK, \
        UNLIMITED_ACCEPTS, \
",5
"    def acceptsCards(self, from_stack, cards):
        if not AbstractFoundationStack.acceptsCards(self, from_stack, cards):
            return False
",5
"                    # found a higher rank or an Ace on the row stacks
                    return c.rank != ACE
        return False


",5
"            l.createText(s.talon, ""ne"")
        else:
",5
"    # game overrides
",5
"    #

    def startGame(self):
        self._startAndDealRow()

",5
"    def isGameWon(self):
        if len(self.s.foundations[0].cards) != 48:
            return False
        for s in self.s.rows:
            if len(s.cards) != 1 or s.cards[0].rank != ACE:
",5
"# ************************************************************************

class Fortunes(AcesUp):
    RowStack_Class = StackWrapper(
",5
"
",5
"# ************************************************************************
# * Russian Aces
# ************************************************************************

",5
"    def dealCards(self, sound=False):
        rows = [s for s in self.game.s.rows if not s.cards]
        if not rows:
",5
"            rows = self.game.s.rows
        return self.dealRowAvail(rows=rows, sound=sound)
",5
"            while r.cards:
                num_cards = num_cards + 1
                game.moveMove(1, r, self, frames=4)
                if self.cards[-1].face_up:
",5
"        if not pile or len(pile) != 4:
",5
"                return (s, 4)
        return (None, 0)


",5
"
    def createGame(self, **layout):
        # create layout
        l, s = Layout(self), self.s
",5
"    #

    def startGame(self):
",5
"        self._startAndDealRow()
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank == card2.rank

",5
"
# ************************************************************************
",5
"
",5
"# ************************************************************************
# * Cover
# * Deck
# ************************************************************************
",5
"
class Cover_RowStack(MonteCarlo_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"    FILL_STACKS_AFTER_DROP = 0          # for MonteCarlo_RowStack

",5
"        for r in self.s.rows:
            if not r.cards:
                self.flipMove(self.s.talon)
                self.moveMove(1, self.s.talon, r)
        self.stopSamples()
",5
"
    def isGameWon(self):
        if self.s.talon.cards:
",5
"
    def fillStack(self, stack):
        pass
",5
"    Foundation_Class = FiringSquad_Foundation
    ReserveStack_Class = ReserveStack

    def createGame(self):
        AcesUp.createGame(self, reserve=True)
",5
"# * Manx
",5
"        # Only allow a sequence if pile is empty
        if len(self.cards) > 0:
            return False
        return True

",5
"        decks = self.gameinfo.decks

        # set window
",5
"        s.reserves.append(self.ReserveStack_Class(x, y, self))
        x += 1.5*l.XS
",5
"                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"# ---------------------------------------------------------------------------##

import pysollib.game
",5
"from pysollib.game import Game
",5
"        DealRowTalonStack, \
        InitialDealTalonStack, \
        KingAC_RowStack, \
",5
"    def createGame(self, max_rounds=-1, num_deal=1, **layout):
        # create layout
        lay, s = Layout(self), self.s
",5
"        for r in lay.s.foundations:
            s.foundations.append(
                self.Foundation_Class(r.x, r.y, self, suit=r.suit))
        for r in lay.s.rows:
",5
"
    def createGame(self, max_rounds=1):
        lay = Klondike.createGame(self, max_rounds=max_rounds)
        self.texts.score = MfxCanvasText(self.canvas,
                                         8, self.height - 8, anchor=""sw"",
",5
"
    def getDemoInfoTextAttr(self, tinfo):
        return tinfo[1]     # ""se"" corner


",5
"        lay = VegasKlondike.createGame(self, max_rounds=3)
        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)
",5
"    def createGame(self):
",5
"# ************************************************************************

class ThumbAndPouch(Klondike):
    RowStack_Class = BO_RowStack

",5
"                (card1.rank + 1 == card2.rank or
                 card2.rank + 1 == card1.rank))


class Chinaman(ThumbAndPouch):
",5
"
class Whitehead_RowStack(SS_RowStack):
    def _isAcceptableSequence(self, cards):
",5
"            self.s.talon.dealRow(rows=self.s.rows[:i], flip=0, frames=0)
        self._startAndDealRowAndCards()


",5
"        for i in range(2):
            self.s.talon.dealRow(flip=0, frames=0)
",5
"        Klondike.createGame(self, rows=8, max_rounds=1, waste=0, playcards=20)


",5
"# ************************************************************************
",5
"# * Westcliff
# * Westhaven
# ************************************************************************

class Westcliff(Eastcliff):
",5
"

# ************************************************************************
# * Pas Seul
",5
"# ************************************************************************
",5
"# * Somerset
# * Morehead
# * Usk
# ************************************************************************
",5
"        self.s.talon.dealRow(rows=self.s.rows[7:])


class Morehead(Somerset):
    RowStack_Class = StackWrapper(BO_RowStack, max_move=1)
",5
"    Solver_Class = None

",5
"
",5
"    RowStack_Class = AC_RowStack
    Solver_Class = FreeCellSolverWrapper(sm='unlimited')

    def createGame(self):
",5
"
",5
"    RowStack_Class = StackWrapper(KingAC_RowStack, max_move=1)
    Solver_Class = FreeCellSolverWrapper(esf='kings')


",5
"
    def createGame(self):
",5
"        Klondike.createGame(self, max_rounds=1, waste=0)

",5
"# * 8 x 8
",5
"        if not RK_RowStack.acceptsCards(self, from_stack, cards):
",5
"
# ************************************************************************
# * Batsford
# * Batsford Again
# ************************************************************************
",5
"    def acceptsCards(self, from_stack, cards):
",5
"        if not ReserveStack.acceptsCards(self, from_stack, cards):
            return False
        # must be a King
        return cards[0].rank == KING

",5
"        lay.createText(s.reserves[0], ""se"")
        if round_text:
",5
"    def createGame(self):
        Batsford.createGame(self, max_rounds=2)


# ************************************************************************
",5
"        lay = Klondike.createGame(self, rows=9, max_rounds=2, round_text=True)
        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)

    def startGame(self, flip=0):
",5
"        for i in range(9):
            self.s.talon.dealRow(rows=self.s.rows[:i], flip=flip, frames=0)
        self._startAndDealRowAndCards()

",5
"
",5
"class OpenJumbo(Jumbo):
    def startGame(self):
        Jumbo.startGame(self, flip=1)

",5
"    DEAL = (0, 1, 0, 1, -1, 0, 1)
",5
"        self.setSize(self.width + lay.XM+4*lay.XS, h)
        for i in range(4):
            for j in range(4):
                x, y = self.width + (j-4)*lay.XS, lay.YM + i*lay.YS
",5
"

# ************************************************************************
# * King Albert
# * Raglan
",5
"    Talon_Class = InitialDealTalonStack
    RowStack_Class = StackWrapper(AC_RowStack, max_move=1)
    Hint_Class = CautiousDefaultHint
",5
"
    ROWS = 9
",5
"                x, y = self.width + (j-rw)*lay.XS, lay.YM + i*lay.YS
                s.reserves.append(OpenStack(x, y, self, max_accept=0))
        lay.defaultStackGroups()
",5
"    def _shuffleHook(self, cards):
        # move Aces to bottom of the Talon (i.e. last cards to be dealt)
        return self._shuffleHookMoveToBottom(
            cards, lambda c: (c.rank == 0, c.suit))

",5
"
    ROWS = 7
",5
"        self.s.talon.dealRow(rows=self.s.foundations)

    shallHighlightMatch = Game._shallHighlightMatch_RK

",5
"    def canDealCards(self):
        return len(self.cards) >= 2
",5
"
",5
"class Jane(Klondike):
    Talon_Class = Jane_Talon
    Foundation_Class = StackWrapper(
        SS_FoundationStack, mod=13, base_rank=NO_RANK, min_cards=1)
",5
"    RowStack_Class = StackWrapper(AC_RowStack, mod=13, base_rank=NO_RANK)
",5
"        s.talon = self.Talon_Class(x, y, self, max_rounds=max_rounds)
",5
"            s.foundations.append(self.Foundation_Class(x, y, self, suit=i))
            x += lay.XS

        x, y = lay.XM, lay.YM+lay.YS+lay.TEXT_HEIGHT
",5
"        # self.setRegion(s.reserves, (x0-lay.XM//2, -999, 999999, 999999),
        #   priority=1)
        lay.defaultStackGroups()
        self.sg.dropstacks.append(s.talon)

",5
"        for s in self.s.rows:
            s.cap.update(cap.__dict__)
",5
"        return 0
",5
"
# ************************************************************************
# * Senate
# ************************************************************************

",5
"            s.rows.append(SS_RowStack(x, y, self))
",5
"            x += lay.XS

",5
"        for y in lay.YM, lay.YM+lay.YS+playcards*lay.YOFFSET:
            x = lay.XM+rows*lay.XS+lay.XS//2
            for i in range(4):
",5
"                stack = OpenStack(x, y, self, max_accept=0)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, lay.YOFFSET
                s.reserves.append(stack)
",5
"            x += lay.XS
",5
"        return self._shuffleHookMoveToTop(
            cards,
            lambda c: (c.rank == ACE, (c.deck, c.suit)))

",5
"    shallHighlightMatch = Game._shallHighlightMatch_SS


",5
"
# ************************************************************************
# * Phoenix
# * Arizona
# ************************************************************************
",5
"

class Phoenix(Klondike):

",5
"        lay, s = Layout(self), self.s
        self.setSize(lay.XM + 10*lay.XS, lay.YM + 4*(lay.YS+lay.YM))

        for i in range(2):
            x = lay.XM + i*lay.XS
",5
"            for j in range(4):
",5
"        self.s.talon.dealCards()          # deal first card to WasteStack

",5
"    def createGame(self):
        lay = Klondike.createGame(self, rows=6, max_rounds=2)
        lay.createRoundText(self.s.talon, 'sss')
",5
"                    self.s.talon.dealCards()
                    if not self.fillWaste():
                        break
            if waste.cards:
",5
"
    def startGame(self):
        Klondike.startGame(self, flip=0, reverse=0)
        self.s.talon.dealRow(rows=self.s.reserves)

",5
"
",5
"class AuntMary(Klondike):
    def createGame(self):
        Klondike.createGame(self, rows=6, max_rounds=1)

",5
"class SevenDevils_RowStack(AC_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not AC_RowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"

",5
"
    def createGame(self):

        lay, s = Layout(self), self.s
        self.setSize(lay.XM + 10*lay.XS, lay.YM+3*lay.YS+12*lay.YOFFSET)
",5
"
",5
"        x += lay.XS
        s.waste = WasteStack(x, y, self)
        lay.createText(s.waste, 'n')

        lay.defaultStackGroups()
",5
"                    pile = from_stack.getPile()
",5
"        lay = Klondike.createGame(self, max_rounds=2, rows=10,
                                  playcards=24, round_text=True)
        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)


",5
"    def startGame(self):
",5
"    def createGame(self):
        Klondike.createGame(self, rows=7)

",5
"
",5
"    def startGame(self):
        Klondike.startGame(self, flip=1)


# ************************************************************************
",5
"    def createGame(self):
        Klondike.createGame(self, num_deal=3)

    def startGame(self):
",5
"# ************************************************************************

",5
"# ************************************************************************
",5
"        lay.createRoundText(self.s.talon, 'ne', dx=lay.XS)


",5
"    def createGame(self):
        Klondike.createGame(self, max_rounds=1, num_deal=3)
",5
"            stack.CARD_YOFFSET = 0
            x += w0
        x, y = lay.XM, lay.YM+3*lay.YS
        for i in range(5):
            stack = self.RowStack_Class(x, y, self, max_move=1)
",5
"
    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(3)
",5
"
    def createGame(self):
        lay, s = Layout(self), self.s
        self.setSize(lay.XM+15*lay.XS, lay.YM+3*lay.YS+15*lay.YOFFSET)

",5
"

# ************************************************************************
# * Athena
# ************************************************************************
",5
"
    def startGame(self):
        self.s.talon.dealRow(frames=0, flip=0)
        self.s.talon.dealRow(frames=0)
",5
"
",5
"# ************************************************************************
# * Eight Sages
# ************************************************************************

",5
"        self.s.talon.dealCards()
",5
"                      GI.GT_KLONDIKE, 1, -1, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(58, ThumbAndPouch, ""Thumb and Pouch"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(67, Whitehead, ""Whitehead"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_KLONDIKE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(224, Easthaven, ""Easthaven"",
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(231, Canister, ""Canister"",
                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(4, EightTimesEight, ""8 x 8"",
                      GI.GT_KLONDIKE, 2, -1, GI.SL_BALANCED))
registerGame(GameInfo(127, AchtmalAcht, ""Eight Times Eight"",
                      GI.GT_KLONDIKE, 2, 2, GI.SL_BALANCED,
                      altnames=(""Achtmal Acht"",)))
",5
"registerGame(GameInfo(236, AgnesBernauer, ""Agnes Bernauer"",
                      GI.GT_RAGLAN, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(263, Phoenix, ""Phoenix"",
                      GI.GT_RAGLAN | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(283, Jumbo, ""Jumbo"",
",5
"                      GI.GT_KLONDIKE, 2, 1, GI.SL_BALANCED))
registerGame(GameInfo(333, OpenJumbo, ""Open Jumbo"",
",5
"registerGame(GameInfo(407, AuntMary, ""Aunt Mary"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(420, DoubleDot, ""Double Dot"",
                      GI.GT_KLONDIKE, 1, 0, GI.SL_BALANCED))
registerGame(GameInfo(434, SevenDevils, ""Seven Devils"",
",5
"registerGame(GameInfo(601, AmericanCanister, ""American Canister"",
",5
"registerGame(GameInfo(630, BigBertha, ""Big Bertha"",
                      GI.GT_RAGLAN | GI.GT_OPEN, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(633, Athena, ""Athena"",
                      GI.GT_KLONDIKE, 1, -1, GI.SL_BALANCED))
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"        DealRowTalonStack, \
        SS_FoundationStack

",5
"        return self.dealRowAvail(rows=top_stacks, sound=sound)


class Labyrinth_RowStack(BasicRowStack):

",5
"        self.setSize(l.XM+8*l.XS, l.YM+l.YS+20*l.YOFFSET)

        # create stacks
        s.talon = Labyrinth_Talon(l.XM, l.YM, self)

",5
"        x, y, = l.XM+2*l.XS, l.YM
        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            x += l.XS
",5
"        x, y = l.XM, l.YM+l.YS
        for i in range(6):
            x = l.XM
            for j in range(8):
                s.rows.append(Labyrinth_RowStack(x, y, self, max_move=1))
",5
"    def _shuffleHook(self, cards):
        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == 0, c.suit))

",5
"    def fillStack(self, stack):
        if stack in self.s.rows[:8] and not stack.cards:
            rows = self.s.rows
",5
"            # if not self.demo:
            #    self.startDealSample()
            old_state = self.enterState(self.S_FILL)
",5
"# GNU General Public License for more details.
#
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.games.spider import Spider_Hint, Spider_RowStack, \
        Spider_SS_Foundation
from pysollib.hint import KlondikeType_Hint, YukonType_Hint
",5
"from pysollib.layout import Layout
from pysollib.mfxutil import kwdefault
from pysollib.stack import \
        AC_RowStack, \
",5
"# * Gypsy
# ************************************************************************

",5
"    RowStack_Class = AC_RowStack
",5
"    Hint_Class = KlondikeType_Hint

    def createGame(self, **layout):
        # create layout
        l, s = Layout(self), self.s
",5
"    def canMoveCards(self, cards):
        if not SS_FoundationStack.canMoveCards(self, cards):
            return False
",5
"# * Irmgard
# ************************************************************************

",5
"

",5
"            self.s.talon.dealRow(rows=r[i:len(r)-i], flip=0, frames=0)
        self._startAndDealRow()

",5
"
    def _shuffleHook(self, cards):
        # move one Ace to bottom of the Talon (i.e. last card to be dealt)
",5
"            cards, lambda c: (c.rank == 0, c.suit), 1)
",5
"
    def startGame(self):
        self._startDealNumRows(6)
        for i in range(3):
",5
"# * Miss Milligan
# * Imperial Guards
# ************************************************************************
",5
"class MissMilligan_ReserveStack(AC_RowStack):
",5
"
    getBottomImage = Stack._getReserveBottomImage


",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"        self._startAndDealRow()


class ImperialGuards(MissMilligan):
    RowStack_Class = AC_RowStack
",5
"    GAME_VERSION = 2
    RowStack_Class = Yukon_AC_RowStack
    Hint_Class = YukonType_Hint

    def getHighlightPilesStacks(self):
",5
"        Mississippi.startGame(self, flip=1)


# ************************************************************************
# * Blockade
",5
"    def fillStack(self, stack):
        if stack in self.s.rows and not stack.cards and self.s.talon.cards:
",5
"class PhantomBlockade(Gypsy):
    Layout_Method = staticmethod(Layout.klondikeLayout)
    RowStack_Class = KingAC_RowStack

",5
"        Gypsy.createGame(self, rows=13, playcards=24)

",5
"        if len(self.cards) == 4:
            return True
        for r in self.game.s.rows:
            if not r.cards:
                return False
",5
"        l.createText(s.talon, 's')
        y += l.YS+2*l.YM
        for i in range(4):
            s.reserves.append(OpenStack(x, y, self, max_accept=0))
            y += l.YS
",5
"        l.defaultStackGroups()

",5
"
        # define stack-groups
        l.defaultStackGroups()

",5
"# ************************************************************************
",5
"    RowStack_Class = KingAC_RowStack

    def createGame(self):
        Gypsy.createGame(self, rows=10)

",5
"            self.s.talon.dealRow(flip=0, frames=0)
",5
"# ************************************************************************

class Hypotenuse(Gypsy):
    Layout_Method = staticmethod(Layout.klondikeLayout)
",5
"    def clickHandler(self, event):
        if self.cards and not self.cards[-1].face_up:
            return self.game.dealCards(sound=True)
        return OpenStack.clickHandler(self, event)
",5
"        self.sg.dropstacks.append(self.s.talon)
        self.sg.openstacks.append(self.s.talon)
        self.sg.reservestacks.append(self.s.talon)

",5
"
# ************************************************************************
# * Trapdoor
# ************************************************************************

",5
"              'waste': 0,
              'texts': 1,
              'reserves': rows}
",5
"        Layout(self).createGame(layout_method=Layout.gypsyLayout,
                                talon_class=Trapdoor_Talon,
",5
"                                foundation_class=self.Foundation_Class,
                                row_class=self.RowStack_Class,
                                reserve_class=OpenStack,
                                **kw
",5
"        self.s.talon.dealCards()


class TrapdoorSpider(Trapdoor):
    Foundation_Class = Spider_SS_Foundation
",5
"    RowStack_Class = Spider_RowStack
",5
"
    def startGame(self, flip=0):
        for i in range(3):
            self.s.talon.dealRow(flip=flip, frames=0)
        r = self.s.rows
",5
"        rows = (r[0], r[3], r[6], r[9])
        self.s.talon.dealRow(rows=rows, flip=flip, frames=0)
        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"              'waste': 0,
              'texts': 1, }
",5
"        Gypsy.createGame(self, rows=13)
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_SS

",5
"
# ************************************************************************
# * Brazilian Patience
# ************************************************************************

",5
"            x += l.XS

        s.talon = DealRowTalonStack(l.XM, l.YM, self)
        l.createText(s.talon, 's')

",5
"        # define stack-groups
",5
"    def startGame(self):
",5
"        for i in range(4):
            self.s.talon.dealRow(rows=self.s.reserves, flip=0, frames=0)
        self.s.talon.dealRow(flip=0, frames=0)
",5
"        self.s.talon.dealRow(flip=0, frames=0)
        self._startAndDealRow()
",5
"            return False
        if self.cards:
            # check suit
            return self.cards[-1].suit == cards[0].suit
",5
"        return True

",5
"
",5
"
    def startGame(self, rows=5):
        self.s.talon.dealRow(rows=self.s.reserves, flip=0, frames=0)
",5
"
class TopsyTurvyQueens(LockedCards):
    Foundation_Class = StackWrapper(LockedCards_Foundation,
                                    base_rank=KING, mod=13)
",5
"        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
        if self.cards:
",5
"        c1 = cards[0]
        for c2 in cards[1:]:
",5
"
",5
"
class Thirty(Game):
",5
"
        l, s = Layout(self), self.s
        self.setSize(l.XM+7*l.XS, l.YM+2*l.YS+12*l.YOFFSET)

",5
"        x, y = l.XM, l.YM
",5
"        for i in range(2):
",5
"            s.reserves.append(OpenStack(x, y, self))
            x += l.XS
",5
"        for i in range(6):
            s.rows.append(Thirty_RowStack(x, y, self,
                          max_move=UNLIMITED_MOVES,
                          max_accept=UNLIMITED_ACCEPTS))
            x += l.XS
",5
"    shallHighlightMatch = Game._shallHighlightMatch_RK
    getQuickPlayScore = Game._getSpiderQuickPlayScore


# register the game
",5
"                      ranks=(0, 6, 7, 8, 9, 10, 11, 12),
",5
"                      GI.GT_GYPSY, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(218, Carlton, ""Carlton"",
                      GI.GT_GYPSY, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(226, Blockade, ""Blockade"",
                      GI.GT_GYPSY, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(412, Cone, ""Cone"",
",5
"registerGame(GameInfo(463, Surprise, ""Surprise"",
                      GI.GT_GYPSY, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(469, PhantomBlockade, ""Phantom Blockade"",
                      GI.GT_GYPSY, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(486, ImperialGuards, ""Imperial Guards"",
",5
"registerGame(GameInfo(580, Trapdoor, ""Trapdoor"",
                      GI.GT_GYPSY | GI.GT_ORIGINAL, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(581, Flamenco, ""Flamenco"",
                      GI.GT_GYPSY | GI.GT_ORIGINAL, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(584, Eclipse, ""Eclipse"",
",5
"from pysollib.util import ACE

",5
"
",5
"
        # define stack-groups
",5
"            if not isSameSuitSequence(row.cards, dir=1):
                return 0
        return 1
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------
",5
"        KingAC_RowStack, \
        OpenStack, \
        OpenTalonStack, \
",5
"
class Bristol_Hint(CautiousDefaultHint):
    # FIXME: demo is not too clever in this game
",5
"# * Bristol
",5
"        x, y, = l.XM + 3*l.XS, l.YM
        for i in range(4):
            s.foundations.append(RK_FoundationStack(x, y, self, max_move=0))
            x += l.XS
        for i in range(2):
",5
"            for j in range(4):
",5
"                x = l.XM + (j*5)*l.XS//2
                stack = RK_RowStack(x, y, self,  base_rank=NO_RANK, max_move=1)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"                s.rows.append(stack)
        x, y, = l.XM + 3*l.XS, l.YM + 4*l.YS
        s.talon = Bristol_Talon(x, y, self)
        l.createText(s.talon, ""sw"")
",5
"            l.createText(stack, 'n')
            s.reserves.append(stack)
            x += l.XS

",5
"        # define stack-groups
        self.sg.openstacks = s.foundations + s.rows
        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.rows + s.reserves

",5
"            while j < i:
                if cards[j].rank != KING:
                    cards[j], cards[i] = cards[i], cards[j]
                    break
",5
"        # remove 1 Ace
        for c in cards:
            if c.rank == 0:
                cards.remove(c)
                break
",5
"    ReserveStack_Class = StackWrapper(
        ReserveStack, max_accept=0, max_cards=UNLIMITED_CARDS)

",5
"    def createGame(self, rows=8, text=False):
        # create layout
        l, s = Layout(self), self.s

",5
"        # set window
",5
"        # create stacks
        x, y, = w-l.XS*self.gameinfo.decks*4, l.YM
        for j in range(self.gameinfo.decks):
            for i in range(4):
",5
"        if text:
",5
"                                            anchor=ta, font=font)

        x, y = w-rows*l.XS, l.YM+l.YS
",5
"            s.rows.append(stack)
            x += l.XS
        x, y, = l.XM, l.YM
        s.talon = self.Talon_Class(x, y, self)
",5
"            stack = self.ReserveStack_Class(x, y, self)
            s.reserves.append(stack)
            l.createText(stack, ""se"")

",5
"
class NewYork_Hint(CautiousDefaultHint):
    def computeHints(self):
        CautiousDefaultHint.computeHints(self)
",5
"            c += 13
",5
"        if 0 <= c <= 3:
            r = self.game.s.reserves[0]
        elif 4 <= c <= 7:
",5
"    def acceptsCards(self, from_stack, cards):
",5
"
class NewYork(Dover):
",5
"        NewYork_ReserveStack, max_accept=1, max_cards=UNLIMITED_CARDS, mod=13)
",5
"
    def updateText(self):
        if self.preview > 1:
",5
"        # deal base_card to Foundations, update foundations cap.base_rank
        self.base_card = self.s.talon.getCard()
",5
"
    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
",5
"# * Spike
# ************************************************************************
",5
"    Foundation_Class = SS_FoundationStack
",5
"        if not RK_RowStack.acceptsCards(self, from_stack, cards):
            return False
        if not self.cards:
            return (from_stack is self.game.s.talon or
",5
"class Gotham(NewYork):
    RowStack_Class = StackWrapper(Gotham_RowStack, base_rank=ANY_RANK, mod=13)

    def startGame(self):
",5
"

# ************************************************************************
# * Interment
",5
"# ************************************************************************

",5
"        if not self.game.s.talon.cards:
            return
        c = self.game.s.talon.cards[-1].rank
",5
"    doubleclickHandler = OpenStack.doubleclickHandler


class Interment_Reserve(OpenStack):
    def canFlipCard(self):
",5
"
",5
"
",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s
",5
"        for i in range(8):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
            x += l.XS
",5
"        # define stack-groups
        l.defaultStackGroups()
        self.sg.dropstacks += s.xwastes
",5
"    def fillStack(self, stack):
        if not stack.cards:
            old_state = self.enterState(self.S_FILL)
            if stack in self.s.rows:
                if self.s.talon.cards:
",5
"registerGame(GameInfo(214, Belvedere, ""Belvedere"",
                      GI.GT_FAN_TYPE, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(266, Dover, ""Dover"",
                      GI.GT_FAN_TYPE, 2, 0, GI.SL_BALANCED))
",5
"                      GI.GT_FAN_TYPE, 2, 0, GI.SL_BALANCED))
",5
"registerGame(GameInfo(604, Interment, ""Interment"",
                      GI.GT_FAN_TYPE, 2, 0, GI.SL_BALANCED))
#!/usr/bin/env python
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"
class Diplomat(Game):
",5
"    Foundation_Class = SS_FoundationStack
    RowStack_Class = StackWrapper(RK_RowStack, max_move=1)
    Hint_Class = FortyThieves_Hint

",5
"        # set window
        self.setSize(l.XM+8*l.XS, l.YM+3*l.YS+12*l.YOFFSET+l.TEXT_HEIGHT)

        # create stacks
        x, y = l.XM, l.YM
",5
"        if max_rounds > 1:
            l.createRoundText(self.s.talon, 'nnn')
        x = x + l.XS
",5
"        # define stack-groups
        l.defaultStackGroups()

",5
"        for i in range(self.DEAL[1]):
",5
"
class Congress(Diplomat):
    DEAL = (0, 1)
    FILL_EMPTY_ROWS = 1

",5
"    Foundation_Classes = [SS_FoundationStack, SS_FoundationStack]
",5
"
",5
"        self.setSize(l.XM + 7*l.XS, l.YM + 4*l.YS)

",5
"            y = l.YM
            for i in range(4):
                s.foundations.append(fnd_cls(x, y, self, suit=i))
                y += l.YS
            x += l.XS
",5
"        x = x + l.XS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, ""s"")
        if max_rounds > 1:
",5
"        SS_FoundationStack,
        StackWrapper(SS_FoundationStack, base_rank=KING, dir=-1),
        ]
    RowStack_Class = UD_SS_RowStack

",5
"        ]
    RowStack_Class = StackWrapper(SS_RowStack, max_move=1)

",5
"registerGame(GameInfo(149, Diplomat, ""Diplomat"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(151, LadyPalk, ""Lady Palk"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
",5
"registerGame(GameInfo(549, Wheatsheaf, ""Wheatsheaf"",
",5
"registerGame(GameInfo(563, TwinQueens, ""Twin Queens"",
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"class Zodiac_Foundation(SS_FoundationStack):
    def acceptsCards(self, from_stack, cards):
        if not SS_FoundationStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        return True
",5
"

",5
"
        # create stacks
        x = l.XM
        for i in range(12):
",5
"
        x = l.XM+4*l.XS
        for i in range(4):
",5
"
",5
"                                  max_rounds=UNLIMITED_REDEALS)
        l.createText(s.talon, 'sw')
        x += l.XS
",5
"        for s in self.game.s.rows:
            if not s.cards:
                break
        else:
            return False
",5
"from pysollib.games.bisley import Bisley
from pysollib.layout import Layout
from pysollib.stack import \
        InitialDealTalonStack, \
        SS_FoundationStack, \
",5
"class Bisley13(Bisley):

",5
"        x, y = l.XM, l.YM+l.YS+8*l.YOFFSET
",5
"        for i in range(6):
            s.rows.append(UD_SS_RowStack(x, y, self, base_rank=NO_RANK))
            x += l.XS
        y = l.YM
        for i in range(4):
",5
"                                 base_rank=KING, max_move=0, dir=-1))
            y += l.YS
",5
"        s.talon = InitialDealTalonStack(w-l.XS, h-l.YS, self)

        # default
",5
"                      GI.GT_1DECK_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"from pysollib.stack import \
        InitialDealTalonStack, \
        OpenStack, \
",5
"    Solver_Class = FreeCellSolverWrapper(preset='streets_and_alleys')
",5
"
",5
"    Foundation_Class = SS_FoundationStack
    # RowStack_Class = RK_RowStack
    RowStack_Class = SuperMoveRK_RowStack

    #
",5
"        # create stacks
",5
"        for i in range(4):
            s.foundations.append(
                self.Foundation_Class(x, y, self, suit=i, max_move=0))
",5
"        if texts:
            tx, ty, ta, tf = l.getTextAttr(None, ""ss"")
",5
"# ************************************************************************

class BeleagueredCastle(StreetsAndAlleys):
    def _shuffleHook(self, cards):
",5
"    # move cards to the Foundations during dealing
    def startGame(self):
        frames = 4
",5
"

# ************************************************************************
# * Fortress
# ************************************************************************
",5
"
class Fortress(Game):
    Layout_Method = staticmethod(Layout.klondikeLayout)
    Talon_Class = InitialDealTalonStack
",5
"        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self)
        if l.s.waste:
            s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
",5
"# * Bastion
# * Ten by One
# * Castles End
# ************************************************************************

",5
"            s.foundations.append(
                self.Foundation_Class(r.x, r.y, self, suit=r.suit))
        for r in l.s.rows:
",5
"    # game overrides
    #
",5
"        self._startDealNumRows(3)
        for i in range(2):
            self.s.talon.dealRow()
",5
"        self.s.talon.dealRow(rows=self.s.reserves)
",5
"
class TenByOne(Bastion):
    def createGame(self):
        Bastion.createGame(self, reserves=1)
",5
"    def acceptsCards(self, from_stack, cards):
        if self.game.getState() == 0:
",5
"
    def createGame(self):
        lay = Bastion.createGame(self)
",5
"        if not self.getState():
            t = """"
        else:
            t = RANKS[self.base_rank]
",5
"        self.base_rank = game.loadinfo.base_rank
        for s in self.s.foundations:
            s.cap.base_rank = game.loadinfo.base_rank
",5
"                break
        p.dump(base_rank)

    shallHighlightMatch = Game._shallHighlightMatch_ACW

",5
"        kwdefault(cap, mod=13, min_cards=1, max_move=0, base_rank=ANY_RANK)
        SS_FoundationStack.__init__(self, x, y, game, suit, **cap)
",5
"

",5
"
    def updateText(self):
        if self.preview > 1:
            return
",5
"        for s in self.s.foundations:
            if s.cards:
                t = RANKS[s.cards[0].rank]
",5
"    Hint_Class = FreeCellType_Hint
",5
"    Hint_Class = FreeCellType_Hint
    Solver_Class = FreeCellSolverWrapper(sbb='rank')

",5
"

",5
"

class Zerline(Game):
",5
"        self.setSize(l.XM+2*w+decks*l.XS, l.YM+l.TEXT_HEIGHT+(rows//2+1)*l.YS)
",5
"
        # create stacks
",5
"                    SS_FoundationStack(
                        x, y, self, i,
                        base_rank=KING, dir=1, max_move=0, mod=13))
",5
"
    #
    # game overrides
    #

",5
"
class Zerline3Decks(Zerline):
",5
"    def createGame(self):
        Zerline.createGame(self, rows=8, reserve_max_cards=6)
",5
"    def createGame(self):
        # create layout
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))
            x += l.XS
        for i in range(4):
",5
"                s.rows.append(stack)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
                x += dx
",5
"            y += l.YS

",5
"# ************************************************************************
# * Castle of Indolence
# ************************************************************************

",5
"                s.rows.append(stack)
",5
"                y += l.YS
        l.setRegion(s.rows[:4], (-999, -999, w-l.CW//2, l.YM+4*l.YS-l.CH//2))
",5
"        # set regions
        l.defaultRegions()

",5
"        x += l.XS
        for i in range(4):
            s.foundations.append(Rittenhouse_Foundation(x, y, self,
",5
"        for i in range(9):
            s.rows.append(UD_RK_RowStack(x, y, self))
            x += l.XS
",5
"        self.startDealSample()
        while talon.cards:
",5
"
    def fillAll(self):
        while True:
            if not self._fillOne():
                break
",5
"
    def _fillOne(self):
        for r in self.s.rows:
            for s in self.s.foundations:
                if s.acceptsCards(r, r.cards[-1:]):
",5
"# ************************************************************************

class Lightweight(StreetsAndAlleys):
    DEAL = (7, 1)
    RowStack_Class = StackWrapper(RK_RowStack, base_rank=KING)
",5
"                s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
                                                        max_move=0))
                x += l.XS
        x, y = l.XM+(max_rows-rows)*l.XS//2, l.YM+l.YS
        for i in range(rows):
",5
"            s.rows.append(self.RowStack_Class(x, y, self))
",5
"        self._startDealNumRows(self.DEAL[0])
        for i in range(self.DEAL[1]):
            self.s.talon.dealRowAvail()

",5
"
",5
"# ************************************************************************
",5
"# * Selective Castle
# ************************************************************************

class SelectiveCastle_RowStack(RK_RowStack):
",5
"            if s.cards:
                return RK_RowStack.canDropCards(self, stacks)
        return (None, 0)
",5
"

class SelectiveCastle(StreetsAndAlleys, Chessboard):
",5
"    shallHighlightMatch = Game._shallHighlightMatch_RKW


# ************************************************************************
# * Soother
",5
"        l, s = Layout(self), self.s
        self.setSize(l.XM+11*l.XS, l.YM+4*l.YS+12*l.YOFFSET)
",5
"        l.createText(s.talon, 's')
        x += l.XS
        s.waste = WasteStack(x, y, self)
",5
"
",5
"    def getQuickPlayScore(self, ncards, from_stack, to_stack):
        return int(to_stack in self.s.rows)

",5
"    Solver_Class = FreeCellSolverWrapper(sbb='rank', esf='kings')


# register the game
registerGame(GameInfo(146, StreetsAndAlleys, ""Streets and Alleys"",
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
",5
"                      GI.SL_SKILL))
registerGame(GameInfo(148, Chessboard, ""Chessboard"",
                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(535, ExiledKings, ""Exiled Kings"",
                      GI.GT_BELEAGUERED_CASTLE | GI.GT_OPEN, 1, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    def __init__(self, x, y, game, suit, **cap):
        kwdefault(cap, mod=13, min_cards=1, max_move=0)
        AC_FoundationStack.__init__(self, x, y, game, suit, **cap)
",5
"
    def acceptsCards(self, from_stack, cards):
        if self.game.getState() == 0:
            if len(cards) != 1 or not cards[0].face_up:
                return False
",5
"        if self.game.getState() == 0:
",5
"            return _('Base card - %s.') % _('any card')
        return SS_FoundationStack.getBaseCard(self)


class Terrace_RowStack(AC_RowStack):
",5
"                self, ncards, to_stack, frames=frames, shadow=shadow)
            return
",5
"        for s in self.game.s.foundations:
            s.cap.base_rank = to_stack.cards[0].rank
        freerows = [s for s in self.game.s.rows if not s.cards]
        self.game.s.talon.dealRow(rows=freerows, sound=True)
",5
"# * Terrace
# ************************************************************************
",5
"class Terrace(Game):
    Talon_Class = Terrace_Talon
    Foundation_Class = Terrace_AC_Foundation
    RowStack_Class = Terrace_RowStack
",5
"    #

    def createGame(self, rows=9, max_rounds=1, num_deal=1, playcards=16):
        # create layout
",5
"        self.base_rank = None

",5
"        # create stacks
        x, y = l.XM + w1, l.YM
        s.talon = self.Talon_Class(
",5
"        x = x + 2*l.XS
        stack = self.ReserveStack_Class(x, y, self)
",5
"            x = x + l.XS

        # define stack-groups
        l.defaultStackGroups()

",5
"        self.s.talon.dealRow(rows=self.s.rows[:nrows])
",5
"            elif stack in self.s.rows and self.s.waste.cards:
                self.s.waste.moveMove(1, stack)
            self.leaveState(old_state)

    def _restoreGameHook(self, game):
",5
"        for s in self.s.foundations:
            s.cap.base_rank = game.loadinfo.base_rank
",5
"

# ************************************************************************
# * Queen of Italy
",5
"# ************************************************************************
",5
"
    def fillStack(self, stack):
        pass
",5
"class GeneralsPatience(Terrace):
    Foundation_Class = Terrace_SS_Foundation
    INITIAL_RESERVE_CARDS = 13


",5
"

",5
"class Wood_RowStack(AC_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not AC_RowStack.acceptsCards(self, from_stack, cards):
",5
"
class Wood(BlondesAndBrunettes):
    RowStack_Class = StackWrapper(Wood_RowStack, mod=13, max_move=1)
",5
"
",5
"# ************************************************************************
# * Bastille Day
# ************************************************************************

class BastilleDay_BastilleStack(Stack):
",5
"        x += 2*l.XS
",5
"        for i in range(12):  # deal to Bastille
            self.s.talon.dealRow(flip=0, rows=[self.s.reserves[0]], frames=0)
        for i in range(9):
            self.s.talon.dealRow(rows=[self.s.reserves[-1]], frames=0)
        for i in range(3):
",5
"                      GI.GT_TERRACE, 2, 0, GI.SL_BALANCED))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"
import math
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.hint import CautiousDefaultHint, DefaultHint
from pysollib.layout import Layout
",5
"

class Braid_RowStack(ReserveStack):
    def fillStack(self):
        if not self.cards and self.game.s.braid.cards:
",5
"            self.game.moveMove(1, self.game.s.braid, self)

    getBottomImage = Stack._getBraidBottomImage
",5
"        if from_stack is self.game.s.braid or from_stack in self.game.s.rows:
            return False
        return ReserveStack.acceptsCards(self, from_stack, cards)
",5
"    #
    # game layout
    #
",5
"        l, s = Layout(self), self.s
        font = self.app.getFont(""canvas_default"")
",5
"        # extra settings
",5
"        for i in range(self.BRAID_CARDS):
",5
"        self.flipMove(self.s.talon)
        self.moveMove(1, self.s.talon, to_stack)
        self.updateText()
",5
"        # deal first card to WasteStack
        self.s.talon.dealCards()

",5
"    shallHighlightMatch = Game._shallHighlightMatch_SSW

",5
"
    #
    # game extras
    #

",5
"            t = """"
        else:
            t = self.RANKS[self.base_card.rank]
            dir = self.getFoundationDir()
",5
"            self.s.talon.dealRow(rows=[self.s.braid], frames=4)
",5
"    def __init__(self, x, y, game, **cap):
        OpenStack.__init__(self, x, y, game, **cap)
        self.CARD_YOFFSET = self.game.app.images.CARD_YOFFSET

    def basicIsBlocked(self):
",5
"    def createGame(self, rows=8):
",5
"
        # set window
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i))

        x, y = l.XM+rows*l.XS//2, l.YM
        s.reserves.append(Backbone_BraidStack(x, y, self, max_accept=0))
",5
"            x += l.XS
",5
"            x += l.XS

        x, y = l.XM+rows*l.XS//2, h-l.YS
",5
"            self.s.talon.dealRow(rows=self.s.reserves[:2], frames=0)
        self.s.talon.dealRow(rows=self.s.reserves, frames=0)
",5
"        self.s.talon.dealRow()
",5
"# * Big Braid
",5
"class Casket_Hint(CautiousDefaultHint):
    def computeHints(self):
        CautiousDefaultHint.computeHints(self)
        if self.hints:
",5
"            return
        if not self.game.s.waste.cards:
",5
"
",5
"
    def createGame(self):
        # create layout
",5
"            s.lid.append(BasicRowStack(x, y, self, max_accept=0))

        # Casket
",5
"            s.rows.append(stack)

        # Reserves
        x, y = l.XM, l.YM+1.5*l.YS
        for i in range(3):
",5
"
    def startGame(self):
        for i in range(13):
",5
"            self.s.talon.dealRow(rows=[self.s.jewels], frames=0, flip=0)
        self.startDealSample()
        self.s.talon.dealToStacksOrFoundations(stacks=self.s.lid)
        self.s.talon.dealToStacksOrFoundations(stacks=self.s.rows)
",5
"
    def fillStack(self, stack):
        if not stack.cards and stack in self.s.lid:
            if self.s.jewels.cards:
                old_state = self.enterState(self.S_FILL)
",5
"
    def dealCards(self, sound=False):
        num_cards = 0
        if sound and self.game.app.opt.animations:
",5
"            self.game.stopSamples()
        return num_cards


",5
"class Well(Game):
    Hint_Class = CautiousDefaultHint
",5
"        # set window
        self.setSize(l.XM+6*l.XS, l.YM+6*l.YS+l.TEXT_HEIGHT)

        # register extra stack variables
",5
"                                 dir=-1, max_move=0))
            suit += 1
",5
"        x, y = l.XM, l.YM+l.YS+l.TEXT_HEIGHT
        stack = SS_RowStack(
            x, y, self, base_rank=ACE, dir=1, mod=13, max_move=1)
        stack.getBottomImage = stack._getReserveBottomImage
        stack.CARD_YOFFSET = 0
",5
"        x, y = l.XM+l.XS, l.YM
        for i in range(5):
            stack = WasteStack(x, y, self)
            l.createText(stack, 's', text_format='%D')
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:4])
",5
"        self.s.talon.dealCards()

",5
"    def fillStack(self, stack):
",5
"        if not stack.cards and stack in self.s.rows[:4]:
",5
"            indx = list(self.s.rows).index(stack)
            r = self.s.reserves[indx]
",5
"                      GI.GT_NAPOLEON, 2, 2, GI.SL_BALANCED,
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

from pysollib.game import Game
",5
"from pysollib.stack import \
",5
"# ************************************************************************
",5
"        return old != self.max_rounds

    def canDealCards(self):
",5
"        if self._updateMaxRounds():
            self.updateText()
        if not self.cards and not self.game.s.waste.cards:
            return False
",5
"        self.texts.misc.config(text=t)

",5
"
",5
"
    getBottomImage = Stack._getSuitBottomImage


# ************************************************************************
",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
        # (set piles so that at least 2/3 of a card is visible with 12 cards)
",5
"        s.waste = Matriarchy_Waste(x, y, self)
        l.createText(s.waste, ""s"")
        y = c2 + l.CH // 2
",5
"        s.talon = Matriarchy_Talon(x, y, self, max_rounds=VARIABLE_REDEALS)
        l.createText(s.talon, ""n"")
",5
"
    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(self.s.rows[8:])
",5
"
",5
"                ((card1.rank + 1) % 13 == card2.rank or
                 (card2.rank + 1) % 13 == card1.rank))
",5
"registerGame(GameInfo(17, Matriarchy, ""Matriarchy"",
                      GI.GT_2DECK_TYPE, 2, VARIABLE_REDEALS, GI.SL_BALANCED))
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"        InitialDealTalonStack, \
",5
"        InvisibleStack, \
        ReserveStack, \
        SS_FoundationStack, \
        Stack, \
",5
"# *
# ************************************************************************


",5
"class SiebenBisAs_Hint(CautiousDefaultHint):
    def computeHints(self):
        game = self.game
        freerows = [s for s in game.s.rows if not s.cards]
        # for each stack
",5
"        for r in game.sg.dropstacks:
            if not r.cards:
                continue
",5
"            assert len(r.cards) == 1 and r.cards[-1].face_up
            pile, rpile = r.cards, []
            # try if we can drop the card
            t, ncards = r.canDropCards(self.game.s.foundations)
            if t:
",5
"                score, color = self._getDropCardScore(
                    score, color, r, t, ncards)
                self.addHint(score, ncards, r, t, color)
            # try if we can move the card
            for t in freerows:
",5
"
",5
"        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
        if self.id % 10 != 0:
",5
"            if s.cards and s.cards[-1].suit == cards[0].suit \
                    and (s.cards[-1].rank + 1) % 13 == cards[0].rank:
                return True
        if self.id % 10 != 10 - 1:
",5
"        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM + 10*l.XS, l.YM + 5*l.YS)
",5
"                    x, y, self, i, base_rank=6, mod=13,
",5
"    #

    def startGame(self):
",5
"
class Maze_Hint(SiebenBisAs_Hint):
    def shallMovePile(self, from_stack, to_stack, pile, rpile):
",5
"        if from_stack is to_stack or \
",5
"        # right neighbour
        s = self.game.s.rows[(self.id + 1) % 54]
        if s.cards:
            if s.cards[-1].suit == cards[0].suit and \
",5
"                    s.cards[-1].rank - 1 == cards[0].rank:
                return True
        return False
",5
"    prepareBottom = Stack.prepareInvisibleBottom

",5
"    Hint_Class = Maze_Hint  # SiebenBisAs_Hint

    #
    # game layout
",5
"        # set window
        self.setSize(l.XM + 9*l.XS, l.YM + 6*l.YS)

        # create stacks
        for i in range(6):
",5
"
",5
"
# register the game
registerGame(GameInfo(118, SiebenBisAs, ""Sieben bis As"",
                      GI.GT_MONTANA | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
                      ranks=(0, 6, 7, 8, 9, 10, 11, 12)))
",5
"registerGame(GameInfo(144, Maze, ""Maze"",
                      GI.GT_MONTANA | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# ************************************************************************
# * Camelot
",5
"            for r in game.s.rows:
                if r.acceptsCards(game.s.talon, [game.s.talon.cards[-1]]):
                    self.addHint(5000, 1, game.s.talon, r)


",5
"            if cr == KING:
                return self.id in (0, 3, 12, 15)
            elif cr == QUEEN:
",5
"                return self.id in (1, 2, 13, 14)
",5
"        if not self.game.is_fill:
            return False
        return cards[0].rank not in (KING, QUEEN, JACK)

",5
"            self.playMoveMove(1, game.s.foundations[0], sound=False)
            self.fillStack()
            return True
        return False
",5
"
    def moveMove(self, ncards, to_stack, frames=-1, shadow=-1):
        if to_stack is not self.game.s.foundations[0]:
            self._dropPairMove(ncards, to_stack, frames=-1, shadow=shadow)
",5
"            game.playSample(""droppair"", priority=200)
        game.moveMove(n, self, f, frames=frames, shadow=shadow)
        game.moveMove(n, other_stack, f, frames=frames, shadow=shadow)
",5
"

class Camelot_Talon(OpenTalonStack):
",5
"    def fillStack(self):
        old_state = self.game.enterState(self.game.S_FILL)
        self.game.saveStateMove(2 | 16)            # for undo
        self.game.is_fill = self.game.isRowsFill()
",5
"
",5
"class Camelot(Game):

",5
"    Talon_Class = Camelot_Talon
    RowStack_Class = StackWrapper(Camelot_RowStack, max_move=0)
    Hint_Class = Camelot_Hint

",5
"    # game layout
    #

    def createGame(self):
",5
"    #
    # game overrides
    #

",5
"
    def isGameWon(self):
",5
"        for i in (5, 6, 9, 10):
            if len(self.s.rows[i].cards) != 0:
                return False
        return len(self.s.talon.cards) == 0

",5
"    def getAutoStacks(self, event=None):
        return ((), (), ())

",5
"class SlyFox_Foundation(SS_FoundationStack):
",5
"    doubleclickHandler = OpenStack.doubleclickHandler

    def moveMove(self, ncards, to_stack, frames=-1, shadow=-1):
        old_state = self.game.enterState(self.game.S_FILL)
",5
"        self.game.saveStateMove(2 | 16)            # for undo
        if old_state == self.game.S_PLAY and to_stack in self.game.s.rows:
            n = self.game.num_dealled
            if n < 0:
",5
"                n = 0
",5
"        if not ReserveStack.acceptsCards(self, from_stack, cards):
            return False
        return from_stack is self.game.s.talon
",5
"        x, y = l.XM, l.YM
        s.talon = SlyFox_Talon(x, y, self)
        s.waste = s.talon
",5
"            cards,
            lambda c: (c.rank in (ACE, KING) and c.deck == 0,
                       (c.suit, c.rank)))

",5
"    def startGame(self):
        self.num_dealled = -1
",5
"
    def fillStack(self, stack):
        if self.num_dealled == -1 and stack in self.s.rows and not stack.cards:
",5
"        playcards = 6

        l, s = Layout(self), self.s
        self.setSize(
            l.XM+10*l.XS, l.YM+3*l.YS+2*playcards*l.YOFFSET+l.TEXT_HEIGHT)
",5
"                stack.CARD_YOFFSET = l.YOFFSET
",5
"
",5
"            for i in range(0, col):
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow()
",5
"        self.s.talon.dealCards()

    shallHighlightMatch = Game._shallHighlightMatch_SS


",5
"
class GrandmammasPatience_Talon(OpenTalonStack):
    rightclickHandler = OpenStack.rightclickHandler
    doubleclickHandler = OpenStack.doubleclickHandler

",5
"        for i in range(4):
            s.foundations.append(
                SS_FoundationStack(
                    x, y, self, suit=i,
                    dir=-1, mod=13, max_move=0, base_rank=ANY_RANK))
",5
"            y += h0

        x, y = l.XM, self.height-l.YS
",5
"        for i in range(4):
            s.reserves.append(ReserveStack(x, y, self))
            x += l.XS
",5
"    def startGame(self):
        c = self.s.talon.cards[-1]
        self.base_rank = c.rank
        to_stack = self.s.foundations[c.suit]
        self.flipMove(self.s.talon)
",5
"        self.moveMove(1, self.s.talon, to_stack, frames=0)
        for s in self.s.foundations[:4]:
            s.cap.base_rank = c.rank
        for s in self.s.foundations[4:]:
            s.cap.base_rank = (c.rank+1) % 13
",5
"                self.s.talon.moveMove(1, stack)
                self.leaveState(old_state)
",5
"        base_rank = self.base_rank
        if base_rank == ANY_RANK:
            t1 = t2 = ''
        else:
",5
"
    def _restoreGameHook(self, game):
        self.base_rank = game.loadinfo.base_rank
",5
"        for s in self.s.foundations[4:]:
            s.cap.base_rank = (self.base_rank+1) % 13

    def _loadGameHook(self, p):
",5
"        s.waste = WasteStack(x, y, self)
",5
"                      GI.GT_NUMERICA | GI.GT_ORIGINAL, 2, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(623, PrincessPatience, ""Princess Patience"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"# ---------------------------------------------------------------------------##
#
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
",5
"from pysollib.hint import AbstractHint
",5
"from pysollib.layout import Layout
from pysollib.stack import \
",5
"        SS_FoundationStack, \
        SS_RowStack, \
",5
"        WasteStack, \
        WasteTalonStack
from pysollib.util import ACE, KING, QUEEN

# ************************************************************************
",5
"class PictureGallery_Hint(AbstractHint):
    def computeHints(self):
        game = self.game

",5
"                score = base_score + 100 * (self.K - c.rank)
",5
"                        continue
",5
"                else:
",5
"        if not self.hints:
            for r in game.s.tableaux:
                pile = r.getPile()
                if not pile or len(pile) != 1:
",5
"                    continue
                rr = self.ClonedStack(r, stackcards=r.cards[:-1])
                if rr.acceptsCards(None, pile):
                    # do not move a card that is already in correct place
                    continue
",5
"
",5
"                rpile = r.cards[:(lr-lp)]   # remaining pile
                if not pile or len(pile) != 1 or len(pile) == len(r.cards):
                    continue
",5
"                        score = base_score + 100 * (self.K - pile[0].rank)
                        self.addHint(score, 1, r, t)
                        break

        # 5) try if we can deal cards
",5
"        if self.level >= 2:
",5
"        self.CARD_YOFFSET = yoffset

    def acceptsCards(self, from_stack, cards):
        if not SS_RowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"    def acceptsCards(self, from_stack, cards):
",5
"        return True

    getBottomImage = Stack._getTalonBottomImage

",5
"    Hint_Class = PictureGallery_Hint

    Foundation_Class = PictureGallery_Foundation
    TableauStack_Classes = [
        StackWrapper(
",5
"
        # set window
        th = l.YS + (12//rows-1) * TABLEAU_YOFFSET
",5
"        self.s.talon.dealRow(rows=self.s.tableaux, frames=0)
",5
"class GreatWheel_Foundation(PictureGallery_Foundation):
    def acceptsCards(self, from_stack, cards):
",5
"class GreatWheel_RowStack(BasicRowStack):
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        c1, c2 = self.cards[-1], cards[0]
        return c1.suit == c2.suit and c1.rank == c2.rank+1

",5
"                old_state = self.enterState(self.S_FILL)
                for i in range(4):
                    if not self.s.waste.cards:
",5
"                    if self.s.waste.cards:
                        self.s.waste.moveMove(1, stack)
                self.leaveState(old_state)
",5
"# ************************************************************************
# * Mount Olympus
# * Zeus
# ************************************************************************

",5
"
        # set window
        self.setSize(l.XM+9*l.XS, l.YM+3*l.YS+12*l.YOFFSET)

        # create stacks
",5
"
    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
        self.s.talon.dealRow()
",5
"            if stack in self.s.rows and len(stack.cards) == 0:
                self.s.talon.dealRow(rows=[stack])

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
",5
"# ************************************************************************
# * Royal Parade
",5
"# ************************************************************************


",5
"            return False
",5
"        old_state = game.enterState(game.S_FILL)
        swap = game.s.internals[0]
        game.moveMove(n, self, swap, frames=0)
        game.moveMove(n, other_stack, self, frames=frames, shadow=shadow)
",5
"class RoyalParade(PictureGallery):
    Talon_Class = DealRowTalonStack
    TableauStack_Classes = [
        StackWrapper(RoyalParade_TableauStack,
",5
"        self.s.talon.dealRow(rows=self.s.tableaux)
        self.s.talon.dealRow()
",5
"
    def canDealCards(self):
        if not DealRowTalonStack.canDealCards(self):
            return False
",5
"    def startGame(self):
        self.s.talon.dealRow(rows=self.s.tableaux[0::8], frames=0)
        self.startDealSample()
        for i in range(3):
",5
"

# register the game
registerGame(GameInfo(7, PictureGallery, ""Picture Gallery"",
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED,
",5
"registerGame(GameInfo(397, GreatWheel, ""Great Wheel"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED,
                      ranks=list(range(12))  # without Kings
                      ))
",5
"registerGame(GameInfo(399, Zeus, ""Zeus"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"registerGame(GameInfo(546, RoyalParade, ""Royal Parade"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_SKILL,
                      rules_filename='virginiareel.html'))
registerGame(GameInfo(547, VirginiaReel, ""Virginia Reel"",
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"from pysollib.stack import \
        AC_RowStack, \
",5
"        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
        for r in l.s.foundations:
            s.foundations.append(
                self.Foundation_Class(r.x, r.y, self, suit=r.suit))
",5
"        # extra
",5
"        return l

",5
"            self.s.talon.dealRow(rows=self.s.rows[i+1:], flip=flip, frames=0)
        self._startAndDealRowAndCards()
",5
"class Pantagruel(DoubleKlondike):
    RowStack_Class = AC_RowStack

",5
"
",5
"
",5
"
    def startGame(self):
",5
"
    def startGame(self):
        DoubleKlondike.startGame(self, flip=1)
    shallHighlightMatch = Game._shallHighlightMatch_SS
",5
"

",5
"# * Arabella
# ************************************************************************
",5
"                s.foundations.append(
                    SS_FoundationStack(x, y, self, suit=j % 4))
                y += l.YS
            x += l.XS
        x, y = l.XM, self.height-l.YS
",5
"
    def createGame(self):
        dx = self.app.images.CARDW//10
        BigDeal.createGame(self, rows=12, max_rounds=1, XOFFSET=dx)

",5
"    def createGame(self):
        DoubleKlondike.createGame(self, max_rounds=1)


# ************************************************************************
",5
"
",5
"    Hint_Class = Spider_Hint

    def createGame(self):
        DoubleKlondike.createGame(self, rows=10, max_rounds=1)
",5
"registerGame(GameInfo(28, DoubleKlondikeByThrees, ""Double Klondike by Threes"",
                      GI.GT_KLONDIKE, 2, -1, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(25, Gargantua, ""Gargantua"",
",5
"                      GI.GT_KLONDIKE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(51, Steps, ""Steps"",
",5
"                      GI.GT_KLONDIKE, 2, 1, GI.SL_BALANCED))
registerGame(GameInfo(273, TripleKlondike, ""Triple Klondike"",
                      GI.GT_KLONDIKE, 3, -1, GI.SL_BALANCED))
registerGame(GameInfo(274, TripleKlondikeByThrees, ""Triple Klondike by Threes"",
                      GI.GT_KLONDIKE, 3, -1, GI.SL_MOSTLY_LUCK))
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"        InvisibleStack, \
        ReserveStack, \
        WasteStack, \
        WasteTalonStack
",5
"                    rw, tw = 4, 2
                c = self.game.cards[t.cards[-1].id - 52]
                if 1 and c in self.game.s.waste.cards:
                    rw = rw - 1
                #
",5
"
# ************************************************************************
# * Pas de Deux
# ************************************************************************
",5
"            return False
        c = self.game.s.waste.cards[-1]
        return c.face_up and cards[0].suit == c.suit and \
            cards[0].rank == c.rank
",5
"        # must be neighbours
        return self.game.isNeighbour(from_stack, self)

    def moveMove(self, ncards, to_stack, frames=-1, shadow=-1):
        assert ncards == 1 and to_stack in self.game.s.rows
",5
"        return self.game.app.images.getSuitBottom(suit)

    def quickPlayHandler(self, event, from_stacks=None, to_stacks=None):
        # find the single stack that can currently move a card
",5
"        for r in self.game.s.rows:
            if r.canMoveCards(r.cards):
                if self.acceptsCards(r, r.cards):
                    r.playMoveMove(len(r.cards), self)
                    return 1
",5
"class PasDeDeux(Game):
    Hint_Class = PasDeDeux_Hint

    #
",5
"                s.rows.append(
                    PasDeDeux_RowStack(x, y, self, max_accept=1, max_cards=2))
        x, y = self.width - 2*l.XS, self.height - l.YS
        s.talon = WasteTalonStack(x, y, self, max_rounds=2)
        l.createText(s.talon, ""se"")
",5
"
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(frames=4)
        self.s.talon.dealCards()          # deal first card to WasteStack

",5
"            if c.suit != r.id // 13 or c.rank != r.id % 13:
                return False
        return True
",5
"    # game extras
    #

",5
"    def getHighlightPilesStacks(self):
        # Pas de Deux special: highlight all moveable cards
",5
"#
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"#
",5
"# ************************************************************************
# * Glenwood
",5
"# ************************************************************************

",5
"    def canMoveCards(self, cards):
        if self.game.base_rank is None:
            return False
        if not AC_RowStack.canMoveCards(self, cards):
            return False
",5
"                    return False
            return True
",5
"        if from_stack in self.game.s.rows and \
                len(cards) != len(from_stack.cards):
",5
"        l.createText(s.waste, ""s"")
        x += 2*l.XS
        for i in range(4):
            s.foundations.append(self.Foundation_Class(x, y, self, i, dir=1,
                                 mod=13, base_rank=ANY_RANK, max_move=0))
",5
"        self.texts.info = MfxCanvasText(self.canvas, tx, ty,
",5
"        l.defaultStackGroups()

",5
"    #
    # game extras
    #

    def updateText(self):
",5
"            return
        if self.base_rank is None:
            t = """"
        else:
            t = RANKS[self.base_rank]
",5
"
",5
"
    def canDealCards(self):
        if self.game.base_rank is None:
            return False
        if self.round == self.max_rounds:
",5
"            return len(self.cards) != 0
        return not self.game.isGameWon()
",5
"                num_cards += self.dealRowAvail(rows=self.game.s.reserves[:5],
                                               sound=False)
",5
"
",5
"
class DoubleFives_Stock(WasteStack):
    def canFlipCard(self):
",5
"            self.texts.ncards.config(text='')

",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM+11*l.XS, l.YM+3*l.YS+16*l.YOFFSET)
",5
"        x += l.XS
",5
"        for i in range(5):
            s.reserves.append(DoubleFives_WasteStack(x, y, self))
",5
"            x += l.XS
        l.createText(s.reserves[0], 'n')
",5
"        self._startDealNumRows(4)
        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.reserves[-2:])

    def _autoDeal(self, sound=True):
",5
"        waste_cards = 0
",5
"    shallHighlightMatch = Game._shallHighlightMatch_SSW


",5
"class MonteCarlo_Hint(DefaultHint):
    # FIXME: demo is not too clever in this game
    pass

",5
"    Hint_Class = MonteCarlo_Hint

    FILL_STACKS_AFTER_DROP = False
",5
"                             max_cards=self.gameinfo.ncards))
        l.createText(s.foundations[0], ""s"")
        y += 2*l.YS
        s.talon = self.Talon_Class(x, y, self, max_rounds=1)
        l.createText(s.talon, ""s"", text_format=""%D"")
",5
"
    def startGame(self):
        self._startAndDealRow()
",5
"
    #
",5
"
    def isNeighbour(self, stack1, stack2):
        if not (0 <= stack1.id <= 24 and 0 <= stack2.id <= 24):
            return False
        column = stack2.id % 5
",5
"        diff = stack1.id - stack2.id
        if column == 0:
            return diff in (-5, -4, 1, 5, 6)
        elif column == 4:
            return diff in (-6, -5, -1, 4, 5)
",5
"            elif free > 0:
                to_stack = self.allstacks[r.id - free]
                self.moveMove(1, r, to_stack, frames=4, shadow=0)
",5
"                    self.moveMove(1, self.s.talon, r)
                    n += 1
",5
"                    return True
        return free and len(self.cards)
",5
"        if free > 0:
            for r in self.s.rows:
                if not r.cards:
                    if not self.s.talon.cards:
                        break
",5
"

# ************************************************************************
# * Simple Pairs
",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM + 6*l.XS, l.YM + 4*l.YS)
",5
"
    def isNeighbour(self, stack1, stack2):
",5
"# ************************************************************************

",5
"class Neighbour_Foundation(AbstractFoundationStack):
    def acceptsCards(self, from_stack, cards):
        if not AbstractFoundationStack.acceptsCards(self, from_stack, cards):
            return False
        # We accept any King. Pairs will get delivered by _dropPairMove.
",5
"        # check the rank
        if self.cards[-1].rank + cards[0].rank != 11:
            return False
        # now look if the stacks are neighbours
",5
"            self.playMoveMove(1, self.game.s.foundations[0], sound=False)
            return 1
        return 0

    def fillStack(self):
",5
"    def getAutoStacks(self, event=None):
        return ((), self.sg.dropstacks, ())

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"    #
    # game layout
    #

",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"        self.setSize(l.XM + 7*l.XS, l.YM + 5*l.YS)

        # create stacks
",5
"        # define stack-groups
        l.defaultStackGroups()

    #
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return card1.rank + card2.rank == 12


",5
"# ************************************************************************

class Nestor_RowStack(MonteCarlo_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"        # check the rank
",5
"            x += l.XS
        x, y = l.XM+2*l.XS, self.height-l.YS
",5
"
    def _shuffleHook(self, cards):
        # no row will have two cards of the same rank
",5
"        for r in self.s.rows[:8]:
            for j in range(6):
                self.s.talon.dealRow(rows=[r], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[8:])
",5
"
",5
"            x += l.XS
        x, y = l.XM, self.height-l.YS
",5
"class TheWish(Game):
",5
"
        # set window
",5
"                return s
",5
"    #
    # game layout
    #
",5
"        l, s = Layout(self, card_x_space=4), self.s

        # set window
        decks = self.gameinfo.decks
",5
"            w = l.XM + 15*l.XS
            dx = l.XS
",5
"        h = l.YM + 5*l.YS
        self.setSize(w, h)
",5
"        # create stacks
        for i in range(4):
",5
"                    DerLetzteMonarch_RowStack(
                        x, y, self, max_accept=1, max_cards=2))
        for i in range(4):
            x, y, = l.XM + (i+2)*l.XS, l.YM
            s.reserves.append(
",5
"        if texts:
            l.createText(s.talon, 'ne')
",5
"    #
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[39:])

    def isGameWon(self):
",5
"    def getDemoInfoText(self):
        return ""Der letzte\nMonarch""

",5
"    def isNeighbour(self, stack1, stack2):
        if not (0 <= stack1.id <= 51 and 0 <= stack2.id <= 51):
            return False
",5
"        column = stack2.id % 13
        diff = stack1.id - stack2.id
        if column == 0:
            return diff in (-13, 1, 13)
",5
"        elif column == 12:
",5
"            return diff in (-13, -1, 13)
",5
"        else:
            return diff in (-13, -1, 1, 13)


",5
"
    def createGame(self):
        DerLetzteMonarch.createGame(self, texts=True)

",5
"        l, s = Layout(self), self.s
        self.setSize(l.XM+12*l.XS, l.YM+3*l.YS+3*l.YOFFSET)

",5
"        x, y = self.width-l.XS, self.height-l.YS
",5
"class RightAndLeft(Game):

    FILL_STACKS_AFTER_DROP = False

",5
"
        l.createText(s.talon, 'se')
        x, y = l.XM+0.5*l.XS, l.YM
",5
"            s.rows.append(stack)
            x += l.XS

",5
"    def startGame(self):
        self._startAndDealRow()


",5
"                      GI.GT_PAIRING_TYPE, 2, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(212, Weddings, ""Weddings"",
                      GI.GT_PAIRING_TYPE, 1, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(90, SimpleCarlo, ""Simple Carlo"",
",5
"                      altnames=(""Der letzte Monarch"",)))
registerGame(GameInfo(328, TheWish, ""The Wish"",
                      GI.GT_PAIRING_TYPE, 1, 0, GI.SL_MOSTLY_LUCK,
",5
"                      GI.SL_MOSTLY_LUCK))
",5
"        Stack, \
        StackWrapper, \
        WasteStack, \
",5
"            score = 20000
        else:
            score = score - (t.cards[-1].rank - r.cards[0].rank) * 1000
",5
"        if self.game.preview > 1:
            return
        if self.texts.misc:
            if len(self.cards) == 0:
",5
"        # this stack accepts any one card from the Waste pile
",5
"        return _('Tableau. Build regardless of rank and suit.')


",5
"# ************************************************************************
",5
"    #

    def _getHelpText(self):
        help = (_('''\
1: 2 3 4 5 6 7 8 9 T J Q K
",5
"3: 6 9 Q 2 5 8 J A 4 7 T K
4: 8 Q 3 7 J 2 6 T A 5 9 K'''))
",5
"        x = l.XM
        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, ""n"")
",5
"    def _shuffleHook(self, cards):
        # prepare first cards
",5
"        topcards = [None] * 4
        for c in cards[:]:
",5
"        l, s = Layout(self), self.s
        help, text_width = self._getHelpText()
        text_width += 2*l.XM
",5
"
",5
"        x, y = x0, l.YM
",5
"        for i in range(4):
            stack = BetsyRoss_Foundation(x, y, self, base_rank=2*i+1,
                                         mod=13, dir=i+1,
                                         max_cards=12, max_move=0)
",5
"
    def _shuffleHook(self, cards):
        # prepare first cards
        topcards = [None] * 8
",5
"# ************************************************************************
# * One234
# ************************************************************************
",5
"    def updateText(self):
",5
"        BetsyRoss_Foundation.updateText(self, update_empty=False)


class One234_RowStack(BasicRowStack):
    # clickHandler = BasicRowStack.doubleclickHandler
",5
"            tx, ty, ta, tf = l.getTextAttr(stack, ""s"")
            font = self.app.getFont(""canvas_default"")
            stack.texts.misc = MfxCanvasText(self.canvas, tx, ty,
                                             anchor=ta, font=font)
",5
"    def dealCards(self, sound=False):
        num_cards = 0
        r = self.game.s.rows[self.round-1]
        if not r.cards:
",5
"            return 1
",5
"            self.game.flipMove(r)
            self.game.moveMove(1, r, self, frames=4, shadow=0)
        self.dealRowAvail(rows=self.game.s.rows[self.round-1:], sound=False)
",5
"class SeniorWrangler(Game):

    def createGame(self):
        l, s = Layout(self), self.s
",5
"        top = []
        ranks = []
        for c in cards[:]:
            if c.rank in range(8) and c.rank not in ranks:
                ranks.append(c.rank)
",5
"# ************************************************************************

class SPatience(Game):
    Hint_Class = Calculation_Hint
",5
"        x0, y0 = l.XM, l.YM
",5
"                       (2, 2.8),
                       (1, 2.6),
",5
"        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
        self.s.talon.dealCards()

",5
"registerGame(GameInfo(653, SeniorWrangler, ""Senior Wrangler"",
                      GI.GT_2DECK_TYPE, 2, 8, GI.SL_BALANCED))
",5
"registerGame(GameInfo(704, SPatience, ""S Patience"",
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"# This program is distributed in the hope that it will be useful,
",5
"from . import bristol  # noqa: F401
",5
"from . import curdsandwhey  # noqa: F401
from . import daddylonglegs  # noqa: F401
from . import dieboesesieben  # noqa: F401
from . import diplomat  # noqa: F401
from . import doublets  # noqa: F401
",5
"from . import headsandtails  # noqa: F401
from . import katzenschwanz  # noqa: F401
from . import klondike  # noqa: F401
",5
"from . import montecarlo  # noqa: F401
from . import napoleon  # noqa: F401
from . import needle  # noqa: F401
from . import numerica  # noqa: F401
",5
"from . import osmosis  # noqa: F401
from . import parallels  # noqa: F401
from . import pasdedeux  # noqa: F401
",5
"from . import spider  # noqa: F401
from . import sthelena  # noqa: F401
from . import sultan  # noqa: F401
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"
",5
"        Stack
from pysollib.util import ACE, JACK, KING, QUEEN
",5
"    #
    # game layout
    #
",5
"
        s.talon = Tournament_Talon(l.XM, l.YM, self, max_rounds=3)
        l.createText(s.talon, ""se"")
        l.createRoundText(s.talon, 'ne')
",5
"            for i in range(4):
                if not self.s.talon.cards:
                    break
                self.s.talon.dealRow([stack])
            if not self.demo:
",5
"        self.game.stopSamples()
        return n


",5
"class KingsdownEights(Game):
",5
"
    def createGame(self):
",5
"            x += l.XS
        x, y = l.XM+2*l.XS, l.YM
        for i in range(8):
",5
"        x, y = l.XM+2*l.XS, l.YM+l.YS
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_AC


",5
"                BasicRowStack(x, y, self, max_move=1, max_accept=0))
            x += l.XS
        x, y = l.XM, 2*l.YM+l.YS
",5
"        self.s.talon.dealRow(rows=self.s.reserves[8:], frames=0)
        self.s.talon.dealRow(frames=0)
        self.startDealSample()
        self.s.talon.dealCards()

",5
"    def createGame(self):
        l, s = Layout(self), self.s
",5
"        x, y, = l.XM+1.5*l.XS, l.YM
        for i in range(6):
",5
"            s.rows.append(LadiesBattle_RowStack(x, y, self,
                                                max_move=1, mod=13))
            x = x + l.XS
        x, y = l.XM, l.YM+l.YS//2
",5
"
    def startGame(self):
        self.s.talon.dealRow(rows=self.s.reserves, frames=0)
        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
",5
"        self._startAndDealRow()
",5
"
",5
"registerGame(GameInfo(386, KingsdownEights, ""Kingsdown Eights"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"        AC_RowStack, \
        BasicRowStack, \
        FreeCell_AC_RowStack, \
        FreeCell_SS_RowStack, \
        InitialDealTalonStack, \
",5
"# ************************************************************************
",5
"        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.reserves)
",5
"
",5
"# ************************************************************************

",5
"class SuperChallengeFreeCell(ChallengeFreeCell):
    RowStack_Class = StackWrapper(FreeCell_AC_RowStack, base_rank=KING)
    Solver_Class = FreeCellSolverWrapper(esf='kings')
",5
"    #

    def createGame(self):
",5
"
        # create layout
        l, s = Layout(self), self.s
",5
"        for i in range(4):
            s.foundations.append(
                self.Foundation_Class(
                    x, y, self, suit=i, mod=13, max_cards=26))
            x += l.XS
",5
"        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.foundations)


# ************************************************************************
",5
"# * Triple Freecell
# ************************************************************************

",5
"        self.setSize(w, h)

        # create stacks
        s.talon = self.Talon_Class(l.XM, h-l.YS, self)

",5
"        l.defaultAll()

",5
"    def startGame(self):
        self._startDealNumRows(12)
        self.s.talon.dealRow(rows=self.s.rows[1:-1])
",5
"        return SuperMoveAC_RowStack.canMoveCards(self, cards)
",5
"
    def canDropCards(self, stacks):
        if len(self.cards) < 13:
",5
"            self.s.talon.dealRow(rows=self.s.rows[i:], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[6:])
",5
"    def _shuffleHook(self, cards):
",5
"        # move two Aces to bottom of the Talon (i.e. last cards to be dealt)
        return self._shuffleHookMoveToBottom(
            cards,
            lambda c: (c.rank == ACE and c.suit in (0, 2), (c.suit)))

",5
"
class Repair(FreeCell):
",5
"# ************************************************************************

class FourColours_RowStack(AC_RowStack):
    getBottomImage = Stack._getReserveBottomImage
",5
"class FourColours(FreeCell):
    Solver_Class = None
",5
"        self.startDealSample()
        while self.s.talon.cards:
            self.dealOne(frames=-1)


",5
"        FreeCell.createGame(self, rows=7)
        suit = 0
        for r in self.s.reserves:
",5
"
class OceanTowers(TripleFreecell):
    Solver_Class = FreeCellSolverWrapper(esf='kings', sbb='suit')
    RowStack_Class = StackWrapper(FreeCell_SS_RowStack, base_rank=KING)

",5
"    def createGame(self):
",5
"        TripleFreecell.createGame(self, rows=14, reserves=8, playcards=20)

    def startGame(self):
",5
"        self.s.talon.dealRow(rows=self.s.reserves[1:-1])

    shallHighlightMatch = Game._shallHighlightMatch_SS


",5
"
# ************************************************************************
# * Headquarters
",5
"        self.s.talon.dealRowAvail()

",5
"
        # create layout
",5
"            x += l.XS

",5
"

class ZeroFcFreeCell(FreeCell):
",5
"    def createGame(self):
        FreeCell.createGame(self, reserves=0)
",5
"registerGame(GameInfo(77, Stalactites, ""Stalactites"",
                      GI.GT_FREECELL | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL,
                      altnames=(""Grampus"", ""Old Mole"")))
registerGame(GameInfo(264, DoubleFreecell, ""Double FreeCell"",
",5
"                      GI.GT_FREECELL | GI.GT_OPEN, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(265, TripleFreecell, ""Triple FreeCell"",
                      GI.GT_FREECELL | GI.GT_OPEN, 3, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(336, ChallengeFreeCell, ""Challenge FreeCell"",
",5
"registerGame(GameInfo(363, Spidercells, ""Spidercells"",
                      GI.GT_SPIDER | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(364, SevenByFour, ""Seven by Four"",
                      GI.GT_FREECELL | GI.GT_OPEN, 1, 0, GI.SL_SKILL))
",5
"                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(448, Repair, ""Repair"",
",5
"                      GI.GT_FREECELL | GI.GT_OPEN | GI.GT_ORIGINAL, 3, 0,
                      GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(513, OceanTowers, ""Ocean Towers"",
",5
"#
# ---------------------------------------------------------------------------

import time
",5
"        AC_RowStack, \
        BasicRowStack, \
        DealRowTalonStack, \
",5
"        InitialDealTalonStack, \
        OpenStack, \
        OpenTalonStack, \
",5
"
",5
"
",5
"# ************************************************************************
# *
",5
"    Hint_Class = Numerica_Hint
    Foundation_Class = StackWrapper(RK_FoundationStack, suit=ANY_SUIT)
    RowStack_Class = StackWrapper(Numerica_RowStack, max_accept=1)

    #
",5
"                   waste_max_cards=1):
        # create layout
",5
"        l, s = Layout(self), self.s
",5
"        decks = self.gameinfo.decks
        foundations = 4*decks

        # set window
",5
"            x = x + l.XS
        x, y = x0, l.YM + l.YS
",5
"        s.waste = WasteStack(x, y, self, max_cards=waste_max_cards)
",5
"

class Numerica2Decks(Numerica):
",5
"

class LastChance_RowStack(Numerica_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
",5
"class LastChance_Reserve(OpenStack):
    def canFlipCard(self):
        return (len(self.game.s.talon.cards) == 0 and
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow()
",5
"        self.s.talon.dealRow(rows=self.s.reserves, flip=False)
        self.s.talon.dealCards()


# ************************************************************************
",5
"# * Puss in the Corner
# ************************************************************************

class PussInTheCorner_Talon(OpenTalonStack):
",5
"        old_state = self.game.enterState(self.game.S_DEAL)
",5
"

class PussInTheCorner_Foundation(SS_FoundationStack):
",5
"    def acceptsCards(self, from_stack, cards):
",5
"        # this stack accepts any one card from the Talon
        return from_stack is self.game.s.talon and len(cards) == 1
",5
"
    getBottomImage = Stack._getReserveBottomImage
",5
"
",5
"# * Fanny
# ************************************************************************

class Frog(Game):

",5
"        x, y, = l.XM, l.YM
        for i in range(8):
            if self.Foundation_Class is RK_FoundationStack:
",5
"            else:
                suit = int(i//2)
            s.foundations.append(self.Foundation_Class(x, y, self,
                                 suit=suit, max_move=0))
            x += l.XS
",5
"        x += l.XS
",5
"        s.waste = WasteStack(x, y, self, max_cards=1)
        x += l.XS
        for i in range(5):
            stack = Numerica_RowStack(x, y, self, max_accept=UNLIMITED_ACCEPTS)
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.foundations)
",5
"class Fanny(Frog):

    Foundation_Class = RK_FoundationStack

",5
"        self.s.talon.dealRow(self.s.reserves)
        self.s.talon.dealCards()


",5
"
class Gnat(Game):
",5
"
    Hint_Class = Numerica_Hint
",5
"            y = l.YM + l.YS//2
",5
"                s.reserves.append(OpenStack(x, y, self, max_accept=0))
                y += l.YS
            x += l.XS
",5
"# ************************************************************************

class Gloaming_Hint(Numerica_Hint):
",5
"        l, s = Layout(self), self.s

        # set window
        n = 52//reserves+1
",5
"            stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, l.YOFFSET
            s.reserves.append(stack)
            x += l.XS
",5
"
",5
"# * Toad
# ************************************************************************


class Toad_TalonStack(DealRowTalonStack):
",5
"
",5
"
class Toad(Game):
    Hint_Class = Gloaming_Hint
",5
"
        # create stacks
        x, y = w-l.XS, h-l.YS
        s.talon = Toad_TalonStack(x, y, self)
        l.createText(s.talon, ""n"")
",5
"
class Shifting_RowStack(Numerica_RowStack):
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return False
",5
"        if not self.cards:
",5
"    Hint_Class = Shifting_Hint
    RowStack_Class = StackWrapper(Shifting_RowStack, max_accept=1)


",5
"    def acceptsCards(self, from_stack, cards):
",5
"            return True
        return False
",5
"    def step030(self, foundations, rows, dropstacks):
        pass

",5
"        self.s.talon.dealCards()

    shallHighlightMatch = Game._shallHighlightMatch_ACW
",5
"    def getHelp(self):
        return _('Tableau. Build regardless of rank and suit.')


",5
"        self.setSize(l.XM+7*l.XS, l.YM+3*l.YS)

        for i, j in ((1, 0),
                     (2, 0),
                     (3, 0),
",5
"        l.createText(s.talon, 'ne')

        l.defaultStackGroups()
",5
"
",5
"        x, y = l.XM, l.YM
        s.talon = Strategerie_Talon(x, y, self)
        l.createText(s.talon, 'ne')
",5
"
        x, y = l.XM, l.YM+l.YS
        for i in range(rows):
            s.rows.append(CircleNine_RowStack(x, y, self, max_accept=1,
",5
"        Measure.createGame(self, rows=10)


# ************************************************************************
",5
"        l, s = Layout(self), self.s

        # set window
",5
"        self.setSize(l.XM + 8 * l.XS, l.YM + 3*l.YS + playcards*l.YOFFSET)
",5
"
",5
"        # create stacks
        x, y = l.XM, l.YM
        for i in range(4):
",5
"        l.defaultStackGroups()

    def startGame(self):
        self.startDealSample()
",5
"# ************************************************************************

class Aglet(Game):
",5
"        for i in range(reserves):
",5
"            x += l.XS
",5
"        for i in range(4):
            s.foundations.append(RK_FoundationStack(x, y, self, suit=ANY_SUIT))
            x += l.XS

",5
"    def _shuffleHook(self, cards):
        # move Aces to top of the Talon (i.e. first cards to be dealt)
        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == ACE, c.suit))
",5
"        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
        self._startDealNumRows(4)
        self.s.talon.dealRowAvail()
        self.s.talon.dealRowAvail()

",5
"
# register the game
registerGame(GameInfo(257, Numerica, ""Numerica"",
                      GI.GT_NUMERICA | GI.GT_CONTRIB, 1, 0, GI.SL_BALANCED,
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"        WasteTalonStack, \
        Yukon_AC_RowStack, \
",5
"        Yukon_SS_RowStack, \
        isAlternateColorSequence, \
",5
"    BONUS_SAME_SUIT_MOVE = 400

    def _preferHighRankMoves(self):
        return 1
",5
"
    def shallMovePile(self, r, t, pile, rpile):
        if not SpiderType_Hint.shallMovePile(self, r, t, pile, rpile):
",5
"            if self.level <= 1 and len(rpile) == 0:
                return True
            return False
",5
"# ************************************************************************
# *
# ************************************************************************

class Spider_RowStack(Spider_SS_RowStack):
",5
"        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self)
        if l.s.waste:
",5
"            s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self))
",5
"
    shallHighlightMatch = Game._shallHighlightMatch_RK
",5
"    getQuickPlayScore = Game._getSpiderQuickPlayScore


# ************************************************************************
# * Spider
",5
"        # no row may be empty
        for r in self.s.rows:
            if not r.cards:
                return False
        return True
",5
"    # A single click deals a new cards to each non-empty row.
    def dealCards(self, sound=True):
        if self.cards:
            rows = [r for r in self.game.s.rows if r.cards]
            if not rows:
",5
"        RelaxedSpider.createGame(self, playcards=22)

",5
"
    def startGame(self):
        for i in range(1, len(self.s.rows)):
            self.s.talon.dealRow(rows=self.s.rows[i:], flip=0, frames=0)
",5
"# ************************************************************************
# * Will o' the Wisp (just like Spiderette)
",5
"        self._startAndDealRow()


class SimpleSimonII(SimpleSimon):
    Solver_Class = None
",5
"
    def createGame(self):
        RelaxedSpider.createGame(self, waste=1, rows=6, texts=1)

",5
"    canDropCards = Spider_RowStack.canDropCards
",5
"# ************************************************************************
",5
"        w, h = l.XM+10*l.XS, l.XM+2*l.XS+15*l.YOFFSET
        self.setSize(w, h)
",5
"            self.s.talon.dealRow(rows=self.s.rows[7:], flip=0, frames=0)
        self.s.talon.dealRow(frames=0)
",5
"

",5
"class RougeEtNoir(Game):
",5
"        # create layout
        l, s = Layout(self), self.s
        kwdefault(layout, rows=10, waste=0, texts=1, playcards=23)
        self.Layout_Method(l, **layout)
",5
"            s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
",5
"            s.rows.append(self.RowStack_Class(r.x, r.y, self))
        # default
        l.defaultAll()
",5
"
    def createGame(self):
",5
"        RelaxedSpider.createGame(self, rows=13, playcards=24, texts=0)

    def startGame(self):
",5
"    Hint_Class = CautiousDefaultHint

    def createGame(self, **layout):
",5
"
    Hint_Class = Spider_Hint
",5
"        l.defaultStackGroups()
",5
"        self.s.talon.dealRow(frames=0, flip=0)
        self.s.talon.dealRow(frames=0)
",5
"        self._startAndDealRow()
",5
"class Lily(Trillium):
",5
"class TripleWakeRobin(WakeRobin):
    def createGame(self):
        Trillium.createGame(self, rows=13)

",5
"
class Chelicera(Game):

    Hint_Class = YukonType_Hint
",5
"        x += l.XS
        for i in range(7):
            s.rows.append(Chelicera_RowStack(x, y, self, base_rank=KING))
",5
"            x += l.XS
",5
"    def isGameWon(self):
",5
"        for s in self.s.rows:
",5
"            s.reserves.append(ReserveStack(r.x, r.y, self))

",5
"
    def startGame(self):
        rows = self.s.rows
",5
"class SpiderWeb(RelaxedSpider):
",5
"                                                      suit=ANY_SUIT))
            x += l.XS
",5
"        self._startDealNumRows(2)
        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.rows[:3])

",5
"class SimonJester(Spider):
",5
"# ************************************************************************
# * Applegate
",5
"class Applegate(Game):
    Hint_Class = YukonType_Hint

",5
"            x += l.XS
",5
"    def startGame(self):
        for i in (6, 6, 0, 0, 0):
",5
"# ************************************************************************
# * Big Spider
",5
"
class BigSpider1Suit(BigSpider):
    pass
",5
"
class Spider3x3(BigSpider):
    def startGame(self):
",5
"        x, y = l.XM, l.YM
",5
"            x += l.XS

        x, y = w-1.5*l.XS, h-l.YS
",5
"        s.talon = self.Talon_Class(x, y, self)
        l.createText(s.talon, 'sw')
",5
"
        l.defaultStackGroups()
        l.defaultRegions()

",5
"    Talon_Class = GroundsForADivorce_Talon
    Foundation_Class = StackWrapper(
        Spider_SS_Foundation, base_rank=ANY_RANK, mod=13)
    RowStack_Class = StackWrapper(Spider_RowStack, mod=13)

",5
"    def createGame(self):
",5
"        Spider4Decks.createGame(self, rows=12)

    def canDealCards(self):
",5
"        return Game.canDealCards(self)
    shallHighlightMatch = Game._shallHighlightMatch_RKW

",5
"

class BigYork(York):
",5
"        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=[self.s.rows[0], self.s.rows[-1]])

# ************************************************************************
",5
"        for r in l.s.foundations:
",5
"class FredsSpider3Decks(FredsSpider):

    def createGame(self):
        Spidike.createGame(self, rows=13, playcards=26)

",5
"            s.rows.append(Spider_RowStack(x, y, self))
            x += l.XS

",5
"        l.defaultStackGroups()
",5
"    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"    def dealCards(self, sound=True):
        if self.cards:
",5
"class FechtersGame_RowStack(AC_RowStack):
    def canDropCards(self, stacks):
",5
"        if len(self.cards) < 13:
            return (None, 0)
        cards = self.cards[-13:]
        for s in stacks:
",5
"            if s is not self and s.acceptsCards(self, cards):
                return (s, 13)
",5
"    def createGame(self):
        l, s = Layout(self), self.s
        self.setSize(l.XM+10*l.XS, l.YM+2*l.YS+18*l.YOFFSET)

        x, y = l.XM+2*l.XS, l.YM
",5
"                old_state = self.enterState(self.S_FILL)
                for s in self.s.rows:
                    if s is stack:
",5
"                for i in range(len(self.s.rows)-1):
                    if self.s.talon.cards:
",5
"                    self.s.talon.dealRow(rows=[stack])
                self.leaveState(old_state)

    shallHighlightMatch = Game._shallHighlightMatch_RK

",5
"            return False                # 5-3-ace
        return isSameSuitSequence(cards, dir=-2)

    def canDropCards(self, stacks):
        cards = self.cards
",5
"        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM+13*l.XS, l.YM+3*l.YS+12*l.YOFFSET)
",5
"        y = l.YM
        for i in range(2):
            x = l.XM+2*l.XS
",5
"                      altnames=(""Scarab"",)))
",5
"registerGame(GameInfo(14, GroundsForADivorce, ""Grounds for a Divorce"",
                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL,
                      altnames=('Scheidungsgrund',)))
registerGame(GameInfo(114, GrandmothersGame, ""Grandmother's Game"",
",5
"registerGame(GameInfo(50, SimpleSimon, ""Simple Simon"",
                      GI.GT_SPIDER | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_SPIDER, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(185, Wasp, ""Wasp"",
                      GI.GT_SPIDER, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(220, RougeEtNoir, ""Rouge et Noir"",
",5
"                      GI.GT_GYPSY, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(269, Spider1Suit, ""Spider (1 suit)"",
                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL,
",5
"                      suits=(0, 0, 0, 0),
                      rules_filename=""spider.html""))
registerGame(GameInfo(270, Spider2Suits, ""Spider (2 suits)"",
                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL,
                      suits=(0, 0, 2, 2),
",5
"                      rules_filename=""spider.html""))
registerGame(GameInfo(305, ThreeBlindMice, ""Three Blind Mice"",
                      GI.GT_SPIDER, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(309, MrsMop, ""Mrs. Mop"",
",5
"registerGame(GameInfo(345, ScorpionHead, ""Scorpion Head"",
                      GI.GT_SPIDER, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"                      rules_filename=""bigspider.html""))
registerGame(GameInfo(449, Spider3x3, ""Spider 3x3"",
                      GI.GT_SPIDER | GI.GT_ORIGINAL, 3, 0, GI.SL_MOSTLY_SKILL,
                      suits=(0, 1, 2),
",5
"                      rules_filename=""bigspider.html""))
",5
"registerGame(GameInfo(454, Spider4Decks, ""Spider (4 decks)"",
                      GI.GT_SPIDER, 4, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(455, GroundsForADivorce4Decks, ""Very Big Divorce"",
                      GI.GT_SPIDER, 4, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(458, Spidike, ""Spidike"",
                      GI.GT_SPIDER, 1, 0, GI.SL_BALANCED))  # GT_GYPSY ?
",5
"registerGame(GameInfo(459, FredsSpider, ""Fred's Spider"",
                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_SPIDER, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(685, FechtersGame, ""Fechter's Game"",
",5
"registerGame(GameInfo(711, TheJollyRoger, ""The Jolly Roger"",
",5
"# it under the terms of the GNU General Public License as published by
",5
"        FreeCell_AC_RowStack, \
        InitialDealTalonStack, \
        OpenStack, \
",5
"            return -1, color
",5
"    # game layout
    #
",5
"        for i in range(rows):
",5
"            stack = self.RowStack_Class(x, y, self)
            stack.CARD_XOFFSET = xoffset
            stack.CARD_YOFFSET = yoffset
            s.rows.append(stack)
",5
"                s.foundations.append(
                    SS_FoundationStack(x+i*l.XS, y, self, suit=suit))
",5
"    #
",5
"    # game overrides
",5
"            if stack.cards and stack is not dragstack:
                dist = (stack.cards[-1].x - cx)**2 + \
                    (stack.cards[-1].y - cy)**2
            else:
",5
"    RowStack_Class = StackWrapper(FreeCell_AC_RowStack, base_rank=NO_RANK)
    Solver_Class = FreeCellSolverWrapper(esf='none')

    def createGame(self):
        DerKatzenschwanz.createGame(self, rows=9, reserves=7)
",5
"
",5
"
    def _shuffleHook(self, cards):
        for c in cards[:]:
            if c.rank == KING:
                cards.remove(c)
",5
"
    def _shuffleHook(self, cards):
",5
"# * Salic Law
# ************************************************************************

",5
"        if len(self.cards) == 0:
",5
"    # game layout
",5
"        l.createText(s.talon, ""s"")

        # define stack-groups
        l.defaultStackGroups()

",5
"        for c in cards[:]:
            if c.rank == KING:
",5
"        cards = self._shuffleHookMoveToTop(cards,
                                           lambda c: (c.rank == QUEEN, None))
        return cards

",5
"
    def startGame(self):
        self._startDealNumRowsAndDealSingleRow(12)

",5
"# * Faerie Queen
# ************************************************************************

class FaerieQueen_RowStack(RK_RowStack):
    def acceptsCards(self, from_stack, cards):
",5
"        ]
    RowStack_Class = StackWrapper(
        FaerieQueen_RowStack, min_cards=1, max_move=1)

",5
"        for s in self.s.foundations:
            if len(s.cards) != 12:
                return False
        return True
",5
"# * Intrigue
# * Laggard Lady
# * Glencoe
# ************************************************************************

",5
"        cards.append(c)
",5
"        for s in self.s.foundations:
            if len(s.cards) != 6:
",5
"        if c.rank in (4, 5):
            i = list(self.game.s.foundations).index(self) % 8
            r = self.game.s.rows[i]
            if not r.cards:
",5
"                return False
            return c.suit == r.cards[0].suit
        return True
",5
"

class Glencoe(Intrigue):
    Foundation_Classes = [
        StackWrapper(Glencoe_Foundation, base_rank=5, max_cards=6),
",5
"    def canDealCards(self):
        if not WasteTalonStack.canDealCards(self):
",5
"    def createGame(self):
        l, s = Layout(self), self.s
",5
"            x += l.XS
        tx, ty, ta, tf = l.getTextAttr(s.foundations[0], ""sw"")
",5
"        for s in self.s.foundations:
            s.cap.base_rank = c.rank
        self.s.talon.dealRow(rows=self.s.reserves, frames=0)
        self.startDealSample()
        self.s.talon.dealRow()
",5
"
    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_rank=None)    # register extra load var.
        self.loadinfo.base_rank = p.load()
",5
"
",5
"            stack.CARD_YOFFSET = yoffset
            s.rows.append(stack)
            x += l.XS
        x, y = l.XM + rows*l.XS, l.YM
",5
"            for i in range(2):
",5
"                       (x - l.CW // 2, -999, 999999, y), priority=1)
        x, y = self.width-3*l.XS//2, self.height-l.YS
        s.talon = InitialDealTalonStack(x, y, self)
",5
"                cards.remove(c)
",5
"registerGame(GameInfo(616, LaggardLady, ""Laggard Lady"",
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"
class PushPin_Hint(AbstractHint):
",5
"
    def computeHints(self):
        game = self.game
",5
"        if pc and nc:
",5
"            self.playMoveMove(1, self.game.s.foundations[0], sound=False)
",5
"            return False
        if abs(self.id - from_stack.id) != 1:
",5
"        game.leaveState(old_state)
",5
"
    getBottomImage = Stack._getBlankBottomImage
",5
"        self.setSize(w, h)

        # create stacks
",5
"
",5
"    def startGame(self):
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[:3])

",5
"                qi = i
            if c.suit == 2 and c.rank == 12:
",5
"# ************************************************************************

class Accordion_Hint(AbstractHint):

",5
"    def computeHints(self):
        game = self.game
        rows = game.s.rows
        for i in range(len(rows)-3):
            r1, r2 = rows[i], rows[i+1]
",5
"                        self.addHint(5000, 1, r2, r1)
            r1, r2 = rows[i], rows[i+3]
            if r1.cards and r2.cards:
                c1, c2 = r1.cards[0], r2.cards[0]
                if c1.rank == c2.rank or c1.suit == c2.suit:
",5
"
class Accordion_RowStack(PushPin_RowStack):

    def acceptsCards(self, from_stack, cards):
        if not self.cards:
",5
"        game.leaveState(old_state)


class Accordion2(Accordion):
    RowStack_Class = Accordion2_RowStack
",5
"
    def isGameWon(self):
        return len(self.s.foundations[0].cards) == 51

",5
"# (at your option) any later version.
#
",5
"        StackWrapper, \
        WasteTalonStack, \
        Yukon_AC_RowStack
",5
"# ************************************************************************


class Sanibel(Gypsy):
    Layout_Method = staticmethod(Layout.klondikeLayout)
",5
"                      GI.GT_YUKON | GI.GT_CONTRIB | GI.GT_ORIGINAL, 2, 0,
                      GI.SL_MOSTLY_SKILL))
#!/usr/bin/env python
",5
"# Copyright (C) 2005-2009 Skomoroh
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"import pysollib.game
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
from pysollib.stack import \
",5
"# ************************************************************************
# * Eiffel Tower
",5
"        OpenStack.__init__(self, x, y, game, max_move=0, max_accept=1)
        self.CARD_YOFFSET = 1

    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"
class EiffelTower(pysollib.game.StartDealRowAndCards, Game):
",5
"    Talon_Class = WasteTalonStack
    Waste_Class = WasteStack

    #
",5
"    #

    def createGame(self):
        # create layout
",5
"        self.setSize(l.XM + 8.5*l.XS, l.YM + 6*l.YS)

        # create stacks
",5
"        x = l.XM + 6 * l.XS
        y = l.YM + 5 * l.YS // 2
        s.waste = self.Waste_Class(x, y, self)
        l.createText(s.waste, ""s"")
        x = x + l.XS
",5
"        return len(self.s.talon.cards) == 0 and len(self.s.waste.cards) == 0

    def getAutoStacks(self, event=None):
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# GNU General Public License for more details.
",5
"        AC_RowStack, \
        BO_RowStack, \
        RK_FoundationStack, \
        RK_RowStack, \
        ReserveStack, \
",5
"

class FortyThieves_Hint(CautiousDefaultHint):
    # FIXME: demo is not too clever in this game
",5
"
",5
"        else:
            l, s = Layout(self, XOFFSET=XOFFSET), self.s

        # set window
",5
"        #   in default window size)
        h = max(2*l.YS, l.YS+(playcards-1)*l.YOFFSET)
        self.setSize(w1, l.YM + l.YS + h + l.YS + l.TEXT_HEIGHT)

",5
"        # foundations
        x = l.XM + (maxrows - 4*decks) * l.XS // 2
",5
"            x = x + l.XS
        # talon, waste
        x = self.width - l.XS
        y = self.height - l.YS
",5
"
        # define stack-groups
",5
"        l.defaultStackGroups()

    #
    # game overrides
",5
"    def startGame(self):
        for i in range(self.DEAL[0]):
            self.s.talon.dealRow(flip=0, frames=0)
        for i in range(self.DEAL[1] - 1):
            self.s.talon.dealRow(frames=0)
",5
"# * Lucas
# * Napoleon's Square
# * Carre Napoleon
# * Josephine
",5
"# * San Juan Hill
# * Famous Fifty
",5
"
class BusyAces(FortyThieves):
    DEAL = (0, 1)

",5
"

class WaningMoon(FortyThieves):
    def createGame(self):
        FortyThieves.createGame(self, rows=13)
",5
"        FortyThieves.createGame(self, rows=12)


",5
"                        return 1
        return 0

    def startGame(self):
        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
",5
"                    break
        self.s.talon.dealCards()

",5
"        FortyThieves.createGame(self, rows=12, playcards=16, XCARDS=96)

",5
"

class SanJuanHill(FortyThieves):

    def _shuffleHook(self, cards):
",5
"
",5
"    DEAL = (0, 1)

    def _shuffleHook(self, cards):
        # move Twos to top of the Talon (i.e. first cards to be dealt)
",5
"    FOUNDATION_MAX_MOVE = 0
",5
"        self.s.talon.dealSingleBaseCard()

    shallHighlightMatch = Game._shallHighlightMatch_SSW


",5
"# ************************************************************************
# * Forty and Eight
",5
"
    ROW_MAX_MOVE = UNLIMITED_MOVES
    FILL_EMPTY_ROWS = 1
",5
"    shallHighlightMatch = Game._shallHighlightMatch_RK
    getQuickPlayScore = Game._getSpiderQuickPlayScore
",5
"# *   rows build down by alternate color
# ************************************************************************

",5
"    def createGame(self):
        Streets.createGame(self, max_rounds=2, rows=12)
",5
"
",5
"    ROW_MAX_MOVE = 1
    FILL_EMPTY_ROWS = 1

",5
"    RowStack_Class = BO_RowStack
    DEAL = (1, 2)

    def createGame(self):
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit != card2.suit and
",5
"

class Midshipman(Indian):
    DEAL = (2, 2)
",5
"# *   rows build down by rank
# ************************************************************************

class NapoleonsExile(FortyThieves):
",5
"    DEAL = (0, 4)

    shallHighlightMatch = Game._shallHighlightMatch_RK


",5
"class DoubleRail(NapoleonsExile):
",5
"
class Octave_Talon(WasteTalonStack):

",5
"            for i in range(num_cards):
",5
"    def updateText(self):
        if self.game.preview > 1 or self.texts.ncards is None:
            return
",5
"        if self.game.s.talon.round == self.game.s.talon.max_rounds:
            t = ''
",5
"
",5
"        # create stacks
        x, y = l.XM+l.XS//2, l.YM
        for i in range(8):
",5
"            s.rows.append(AC_RowStack(x, y, self,
                                      base_rank=ANY_RANK, max_move=1))
            x += l.XS

        x, y = l.XM, h-l.YS
",5
"
        # define stack-groups
",5
"
    def startGame(self):
        self.s.talon.dealRow(rows=self.s.foundations, frames=0)
        self._startDealNumRows(2)
",5
"        self.s.talon.dealRow()
        self.s.talon.dealCards()          # deal first card to WasteStack

    def isGameWon(self):
",5
"            if s.cards:
                return False
        return not self.s.waste.cards

",5
"                    self.moveMove(1, self.s.talon, stack, frames=4, shadow=0)
                    self.leaveState(old_state)

",5
"
# ************************************************************************
# * Fortune's Favor
# ************************************************************************

",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 'se')
        y = 2*l.YM+l.YS
        for i in range(2):
",5
"                stack = SS_RowStack(x, y, self, max_move=1)
                stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, 0
                s.rows.append(stack)
                x += l.XS
",5
"                                          lambda c: (c.rank == ACE, c.suit))
",5
"
    def fillStack(self, stack):
        if len(stack.cards) == 0:
",5
"                self.s.waste.moveMove(1, stack)

    shallHighlightMatch = Game._shallHighlightMatch_SS
",5
"

",5
"        self.setSize(w, h)

",5
"        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.rank == ACE, (c.deck, c.suit)))
",5
"            if not self.s.waste.cards:
",5
"                self.s.talon.dealCards()
",5
"# ************************************************************************
# * Squadron
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
",5
"            x += l.XS
        x, y = l.XM, l.YM+l.YS*3//2
",5
"
        l.defaultStackGroups()
",5
"    ROW_MAX_MOVE = UNLIMITED_MOVES
    DEAL = (0, 1)

    def createGame(self):
        FortyThieves.createGame(self, rows=6)
",5
"    Foundation_Class = StackWrapper(SS_FoundationStack, max_cards=13)

    def startGame(self):
",5
"        if self.cards:
            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
            for i in range(self.num_deal):
                for r in self.game.s.reserves:
",5
"
class TheSpark(Game):
",5
"            stack = WasteStack(x, y, self)
            s.reserves.append(stack)
",5
"            l.createText(stack, 'se')
            y += l.YS
        y = l.YM+l.YS*3//2
        for i in range(2):
            x = l.XM+2*l.XS
",5
"
    def startGame(self):
        self.startDealSample()
        self.s.talon.dealCards()

",5
"# * Unlimited
",5
"# * Triple Interchange
# ************************************************************************
",5
"
class Interchange(FortyThieves):

    RowStack_Class = StackWrapper(SS_RowStack, base_rank=KING)
",5
"
    ROW_MAX_MOVE = UNLIMITED_MOVES
",5
"    shallHighlightMatch = Game._shallHighlightMatch_RK


class FortyNine_RowStack(AC_RowStack):
",5
"    def acceptsCards(self, from_stack, cards):
        if not AC_RowStack.acceptsCards(self, from_stack, cards):
            return False
        if self.cards:
",5
"    RowStack_Class = FortyNine_RowStack

    def startGame(self):
        self._startDealNumRowsAndDealRowAndCards(6)

",5
"    RowStack_Class = SS_RowStack
",5
"        x += l.XS
        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, 's')
",5
"        s.foundations.append(RK_FoundationStack(x, y, self, suit=ANY_SUIT,
                             base_rank=KING, dir=0, max_cards=8))
        x += 3*l.XS
        for i in range(6):
            s.rows.append(RK_RowStack(x, y, self, max_move=1))
",5
"                not to_stack.acceptsCards(from_stack, pile):
            return False
",5
"        #
        if len(rpile) == 0:
            return True
        # now check for loops
        rr = self.ClonedStack(from_stack, stackcards=rpile)
",5
"        else:
            # demo mode
            if rr.cards and not rr.cards[-1].face_up:
                if len(rr.cards) < len(to_stack.cards):
",5
"class BlindPatience_RowStack(AC_RowStack):
    def acceptsCards(self, from_stack, cards):
        if self.cards and not self.cards[-1].face_up:
            return True
        return AC_RowStack.acceptsCards(self, from_stack, cards)
",5
"

",5
"        return (self.sg.dropstacks, self.sg.dropstacks, self.sg.dropstacks)

    def getQuickPlayScore(self, ncards, from_stack, to_stack):
",5
"        if to_stack in self.s.rows:
            if to_stack.cards:
                if to_stack.cards[-1].face_up:
                    # top card is face up
                    return 1001
",5
"        # prefer non-empty piles in to_stack
        return 1001 + int(len(to_stack.cards) != 0)

    shallHighlightMatch = Game._shallHighlightMatch_AC
",5
"
class Foothold(FortyThieves):
    RowStack_Class = UD_AC_RowStack
",5
"    DEAL = (0, 5)
",5
"
    def createGame(self):
        FortyThieves.createGame(self, rows=8, playcards=16)
    shallHighlightMatch = Game._shallHighlightMatch_AC

",5
"
# register the game
registerGame(GameInfo(13, FortyThieves, ""Forty Thieves"",
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED,
                      altnames=(""Maria Luisa"",)))
registerGame(GameInfo(70, NumberTen, ""Number Ten"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
",5
"registerGame(GameInfo(71, RankAndFile, ""Rank and File"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED,
",5
"registerGame(GameInfo(514, Carnation, ""Carnation"",
                      GI.GT_FORTY_THIEVES | GI.GT_ORIGINAL, 4, 0,
                      GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(556, Junction, ""Junction"",
                      GI.GT_FORTY_THIEVES, 4, 0, GI.SL_MOSTLY_SKILL,
                      ranks=(0, 6, 7, 8, 9, 10, 11, 12)))
",5
"registerGame(GameInfo(564, TheSpark, ""The Spark"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(573, DoubleGoldMine, ""Double Gold Mine"",
",5
"registerGame(GameInfo(575, Unlimited, ""Unlimited"",
                      GI.GT_FORTY_THIEVES, 2, -1, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(576, Breakwater, ""Breakwater"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(577, FortyNine, ""Forty Nine"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(588, Roosevelt, ""Roosevelt"",
                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
",5
"registerGame(GameInfo(628, Crossroads, ""Crossroads"",
",5
"                      GI.GT_FORTY_THIEVES, 2, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(765, Foothold, ""Foothold"",
",5
"        RK_RowStack, \
",5
"    def getBottomImage(self):
        if self.cap.base_rank == 1:
",5
"            return self.game.app.images.getLetter(1)
",5
"        l, s = Layout(self), self.s

        # set window
",5
"
",5
"            elif stack in self.s.reserves and self.s.waste.cards:
                self.s.waste.moveMove(1, stack)
            self.leaveState(old_state)

",5
"    def getHighlightPilesStacks(self):
",5
"            return (self.sg.dropstacks, (), self.sg.dropstacks)
        else:
",5
"            # rightclickHandler
            return (self.sg.dropstacks, self.sg.dropstacks, self.sg.dropstacks)

",5
"
class OddAndEven(RoyalCotillion):
    def createGame(self):
        # create layout
",5
"        x, y, = l.XM, l.YM
        for i in range(4):
            s.foundations.append(
                self.Foundation_Class(x, y, self, i, dir=2, mod=13))
            x += l.XS
",5
"                    x, y, self, i, dir=2, mod=13, base_rank=1))
            x += l.XS
        for i in range(2):
            x, y, = l.XM + ((4, 3)[i])*l.XS, l.YM + (i+1)*l.YS
            for j in range((4, 5)[i]):
",5
"# ************************************************************************
",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
        self.setSize(l.XM + 8*l.XS, l.YM + 4*l.YS)
",5
"            s.foundations.append(self.Foundation_Class(x, y, self, ANY_SUIT))
            x += l.XS
        x, y, = l.XM, y + l.YS
",5
"        s.waste = WasteStack(x, y, self)
        l.createText(s.waste, ""se"")

        # define stack-groups
        l.defaultStackGroups()
",5
"# ************************************************************************

",5
"class Alhambra_Hint(CautiousDefaultHint):
    def _getDropCardScore(self, score, color, r, t, ncards):
        return 93000, color
",5
"
",5
"    getBottomImage = Stack._getReserveBottomImage

",5
"            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
",5
"        # create stacks
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
                                                    max_move=0))
            x += l.XS
",5
"        for i in range(4):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i,
",5
"                                 max_move=0, base_rank=KING, dir=-1))
            x += l.XS
        x, y, = l.XM+(8-reserves)*l.XS//2, y+l.YS
",5
"        else:
            l.createText(s.talon, 'n')
        anchor = 'nn'
",5
"        for i in range(rows):
            stack = self.RowStack_Class(x, y, self, mod=13, max_accept=1)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = 0, 0
            s.rows.append(stack)
",5
"                l.createText(stack, 'n')

",5
"        l.defaultStackGroups()

    #
    # game overrides
    #
",5
"        return self._shuffleHookMoveToTop(
            cards, lambda c: (c.deck == 0 and
                              c.rank in (ACE, KING), (c.rank, c.suit)), 8)
",5
"
",5
"            self.s.talon.dealRow(rows=self.s.reserves, frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.reserves)
",5
"        Alhambra.createGame(self, rows=4)


",5
"        for r in self.s.reserves:
            if r.cards:
                continue
            if self.s.talon.cards:
                old_state = self.enterState(self.S_FILL)
",5
"                self.s.talon.flipMove()
                self.s.talon.moveMove(1, r)
",5
"class Carpet(Game):
    Foundation_Class = SS_FoundationStack
",5
"        l.defaultStackGroups()

",5
"        self.s.talon.dealRow()
",5
"            return True
",5
"            return True
        return False


class BritishConstitution_RowStack(BritishConstitution_RowStackMethods,
",5
"            self, from_stack, cards)


class NewBritishConstitution_RowStack(BritishConstitution_RowStackMethods,
",5
"    def acceptsCards(self, from_stack, cards):
        if not RK_RowStack.acceptsCards(self, from_stack, cards):
",5
"    RowStack_Class = BritishConstitution_RowStack

",5
"        y = l.YM+l.YS
",5
"            cards, lambda c: (c.rank == ACE, c.suit))

    def fillStack(self, stack):
",5
"            return False
        return len(self.cards) == 0

    def getHelp(self):
",5
"        return _('Tableau. Empty piles can be filled with any card.')

",5
"        x, y = l.XM, l.YM
        s.talon = DealRowTalonStack(x, y, self)
        l.createText(s.talon, 'se')
        x += 2*l.XS
        for i in range(4):
",5
"        l.defaultStackGroups()

",5
"            self.s.talon.moveMove(1, stack)
",5
"

",5
"        num_cards = 0
        old_state = self.game.enterState(self.game.S_DEAL)
",5
"        if self.cards:
            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
",5
"
class ThreePirates(Game):
",5
"        for i in range(8):
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2))
",5
"
",5
"                    if r.acceptsCards(s, s.cards):
                        self.addHint(5000, 1, s, r)


",5
"        return from_stack in self.game.s.rows
",5
"            return False
        if not (from_stack in self.game.s.reserves or
                from_stack in self.game.s.rows):
",5
"
        self.setSize(l.XM+8*l.XS, l.YM+5*l.YS)

        x0, y0 = l.XM+2*l.XS, l.YM
",5
"    def startGame(self):
        self.s.talon.dealRow(frames=0)
",5
"        self.startDealSample()
",5
"# ************************************************************************
# * Royal Rendezvous
",5
"        # kings
        suit = 0
        for i in (0, 1, 6, 7):
            x = l.XM+(1.5+i)*l.XS
            s.foundations.append(SS_FoundationStack(x, y, self, suit=suit,
",5
"        for i in (2, 3, 4, 5):
            x = l.XM+(1.5+i)*l.XS
            s.foundations.append(SS_FoundationStack(x, y, self, suit=suit))
            suit += 1
        y += l.YS
",5
"        # twos
        suit = 0
",5
"        l.createText(s.waste, 'ne')

",5
"        cards = self._shuffleHookMoveToTop(
            cards,
            lambda c: (c.rank == ACE, (c.deck, c.suit)))
        return cards

",5
"    def startGame(self):
        # deal aces
        self.s.talon.dealRow(rows=self.s.foundations[4:8], frames=0)
        self.s.talon.dealRow(rows=self.s.foundations[12:16], frames=0)
        # deal twos
",5
"        self.s.talon.dealRow(rows=self.s.foundations[8:12], frames=0)
        #
        self.startDealSample()
        self.s.talon.dealRow()
",5
"# * Shady Lanes
",5
"class ShadyLanes_Hint(CautiousDefaultHint):
    def computeHints(self):
        CautiousDefaultHint.computeHints(self)
        if self.hints:
            return
",5
"    Hint_Class = ShadyLanes_Hint

    def createGame(self):
",5
"                    base_suit=suit, suit=ANY_SUIT, color=color))
            x += l.XS
        x, y = l.XM, l.YM+l.YS
",5
"        x, y = self.width-l.XS, l.YM+l.YS
        for i in range(4):
            s.reserves.append(OpenStack(x, y, self, max_accept=0))
            y += l.YS
",5
"                self.s.talon.dealCards()
",5
"                stack.getBottomImage = stack._getSuitBottomImage
                s.rows.append(stack)
                x += l.XS
",5
"            y += 3*l.YS
        # foundations
        decks = self.gameinfo.decks
        for k in range(decks):
",5
"            for i, j in ((0, 3-decks*0.5+k),
                         (8, 3-decks*0.5+k),
",5
"        # talon & waste
        x, y = l.XM+3.5*l.XS, l.YM+2.5*l.YS
        s.talon = WasteTalonStack(x, y, self, max_rounds=2)
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()

    def _shuffleHook(self, cards):
",5
"class BoxingTheCompass(FourWinds):
    pass


",5
"        return index, row

    def acceptsCards(self, from_stack, cards):
",5
"            return False

        self_index, self_row = self._getStackIndex(self)

        if self_row in (1, 2):
",5
"
        below_stack = None
",5
"        if self_row in (0, 1):
            below_stack = self.game.s.rows[self_index+12]
            if below_stack.cards:
",5
"    def createGame(self):
        l, s = Layout(self), self.s
        self.setSize(l.XM+12*l.XS, l.YM+5*l.YS)

        x, y = l.XM+2*l.XS, l.YM
",5
"        for i in range(8):
            s.foundations.append(SS_FoundationStack(x, y, self, suit=i//2,
                                                    max_move=0))
            x += l.XS

",5
"        x, y = l.XM+3*l.XS, l.YM+3.5*l.YS
        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, ""sw"")
        x += l.XS
        s.waste = WasteStack(x, y, self)
",5
"            cards, lambda c: (c.rank == ACE, c.suit))

",5
"class TwilightZone_Talon(OpenTalonStack, WasteTalonStack):
    rightclickHandler = OpenStack.rightclickHandler
",5
"        y = l.YM
        for i in range(2):
            x = l.XM+3*l.XS
",5
"            for j in range(4):
                s.foundations.append(TwilightZone_Foundation(x, y, self,
                                                             suit=j))
                x += l.XS
            y += l.YS
",5
"
        x, y = l.XM+3*l.XS, l.YM+4*l.YS
        for i in range(4):
            s.reserves.append(OpenStack(x, y, self))
",5
"            x += l.XS

        x, y = l.XM, l.YM+l.YS//2
",5
"                i = list(self.s.rows).index(stack)
                from_stack = self.s.reserves[i]
",5
"                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_BALANCED))
registerGame(GameInfo(97, Carpet, ""Carpet"",
",5
"                      GI.GT_1DECK_TYPE, 1, 0, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(391, BritishConstitution, ""British Constitution"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED,
                      ranks=list(range(11)),  # without Queens and Kings
                      altnames=(""Constitution"",)))
",5
"                      GI.GT_2DECK_TYPE, 2, 2, GI.SL_BALANCED))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"    #

    def createGame(self, rows=(7, 7, 7, 5)):
        # create layout
        l, s = Layout(self), self.s
",5
"                s.rows.append(stack)
",5
"
",5
"
        # default
        l.defaultAll()
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_MOSTLY_SKILL))
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
",5
"    def basicIsBlocked(self):
",5
"class Parallels_TalonStack(DealRowTalonStack):
    def dealCards(self, sound=False):
        return self.dealRow(sound=sound)

    def dealRow(self, rows=None, flip=1, reverse=0, frames=-1, sound=False):
",5
"        for i in range(10):
",5
"                            self, rows=[s],
                            frames=frames, sound=sound)
                        n += 1
",5
"        self.startDealSample()
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(615, BritishBlockade, ""British Blockade"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"        InvisibleStack, \
",5
"        self.setRegion(s.rows[:4], (-999, -999, x - l.XM // 2, y))
        self.setRegion(s.rows[4:], (-999,    y, x - l.XM // 2, 999999))
        d = [(0, 0), (1, 0.15), (2, 0.5), (2.5, 1.5), (2, 2.5), (1, 2.85)]
",5
"            x = int(round(x0 + (6.5+d[j][0]) * l.XS))
            y = int(round(y0 + (-1.5+d[j][1]) * l.YS))
",5
"        # define stack-groups
        self.sg.openstacks = s.foundations + s.rows
        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.rows
",5
"        clocks = []
        for c in cards[:]:
            if c.id in ids:
                clocks.append(c)
                cards.remove(c)
",5
"        self._dealNumRows(4)
",5
"# ************************************************************************
# * Dial
# ************************************************************************

",5
"                       (2.5, 1.5),
                       ):
",5
"            y = int(y0 + yy*l.YS)
            s.foundations.append(
                AC_FoundationStack(
",5
"
        l.defaultStackGroups()

    def startGame(self):
",5
"            return False
        if self in self.game.s.rows[4:10]:
            alt_rows = self.game.s.rows[10:]
            color = RED
        else:
",5
"        if not SC_RowStack.acceptsCards(self, from_stack, cards):
",5
"        game = self.game
        old_state = game.enterState(game.S_FILL)
        swap = game.s.internals[0]
        game.moveMove(n, self, swap, frames=0)
        game.moveMove(n, other_stack, self, frames=frames, shadow=shadow)
",5
"class Hemispheres(Game):
    Hint_Class = Hemispheres_Hint

    def createGame(self):

",5
"                       (7,   2),
",5
"            x, y = x0+xx*l.XS, y0+yy*l.YS
",5
"            stack = Hemispheres_RowStack(x, y, self,
                                         base_color=RED, max_move=1)
            stack.CARD_YOFFSET = 0
",5
"            s.rows.append(stack)

        # southern hemisphere (black)
        for xx, yy in ((6.5, 3),
",5
"                       (5.5, 3.5),
",5
"                       (4.5, 3.8),
",5
"                       (2.5, 3.8),
                       (1.5, 3.5),
",5
"                       (0.5, 3),
                       ):
            x, y = x0+xx*l.XS, y0+yy*l.YS
            stack = Hemispheres_RowStack(x, y, self,
",5
"                                                    max_move=0))
            x += l.XS
",5
"        rows_cards = []                 # rows
        for c in cards[:]:
            if c.rank in (ACE, KING):
",5
"                cond = ((c.rank == ACE and c.color == RED) or
                        (c.rank == KING and c.color == BLACK))
",5
"                if cond:
                    cards.remove(c)
                    founds_cards.append(c)
                elif c.deck == 0:
                    cards.remove(c)
",5
"                    rows_cards.append(c)
",5
"        if stack in self.s.rows[4:] and not stack.cards:
            old_state = self.enterState(self.S_FILL)
            if not self.s.waste.cards:
                self.s.talon.dealCards()
            if self.s.waste.cards:
",5
"            self.leaveState(old_state)

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        # by color
",5
"        if not rows:
            # deal to the waste
            if sound and not self.game.demo:
                self.game.playSample(""dealwaste"")
",5
"            return 1
        # deal to the rows
        if sound and self.game.app.opt.animations:
            self.game.startDealSample()
        ncards = 0
",5
"        while rows:
            n = self.dealRowAvail(rows=rows, sound=False)
",5
"            (0,   1.5),
            (0.5, 0.5),
            (1.5, 0.15),
",5
"            x = int(x0 + xx*l.XS)
",5
"                                 mod=13, max_move=0))
            rank += 1
",5
"        x, y = self.width-l.XS, self.height-l.YS
        s.talon = BigBen_Talon(x, y, self, max_rounds=1)
        l.createText(s.talon, 'n')
        x -= l.XS
        s.waste = WasteStack(x, y, self)
",5
"        return cards+clocks

    def startGame(self):
",5
"            self.s.talon.dealRow(frames=4)

    def _autoDeal(self, sound=True):
        # don't deal a card to the waste if the waste is empty
        return 0
",5
"# ************************************************************************
",5
"        game.moveMove(1, swap2, self, frames=0)
        for i in range(ncards):
            game.moveMove(1, swap, self, frames=0)
        if not self.cards[-1].face_up:
            game.flipMove(self)
",5
"            y = l.YM + yy*l.YS
            stack = Clock_RowStack(x, y, self, max_move=0)
            stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"        stack = Clock_RowStack(x, y, self, max_move=1)
        stack.CARD_XOFFSET, stack.CARD_YOFFSET = l.XOFFSET, 0
",5
"
    def startGame(self):
        for i in range(3):
            self.s.talon.dealRow(frames=0, flip=False)
",5
"        return (), (), ()


# register the game
",5
"                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED,
                      altnames=(""The Four Continents"",)))
registerGame(GameInfo(697, BigBen, ""Big Ben"",
                      GI.GT_2DECK_TYPE, 2, 0, GI.SL_BALANCED))
registerGame(GameInfo(737, Clock, ""Clock"",
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"

",5
"    #
    # game layout
    #
",5
"
",5
"        y = l.YM
        for i in range(4):
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, i,
                                 base_rank=KING, max_move=0, dir=-1))
",5
"
        s.talon = InitialDealTalonStack(w-l.XS, h-l.YS, self)

        # default
        l.defaultAll()
",5
"    def startGame(self):
        self._startDealNumRows(3)
        self.s.talon.dealRow()
        self.s.talon.dealRow(rows=self.s.foundations[::2])

",5
"    def _shuffleHook(self, cards):
",5
"# ************************************************************************

class DoubleBisley(Bisley):
",5
"
",5
"    def createGame(self):
        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"
        # default
        l.defaultAll()

",5
"# * Gloria
# ************************************************************************

class Gloria(Game):
",5
"
        x = l.XM+2*l.XS
        for j in range(2):
            for i in range(4):
",5
"                y = l.YM
",5
"                s.foundations.append(SS_FoundationStack(x, y, self,
                                     suit=j*2+i//2, base_rank=KING, dir=-1))
                x += l.XS

        s.reserves.append(ReserveStack(l.XM, l.YM, self))
",5
"
        # default
        l.defaultAll()

",5
"class Realm(Game):

    Hint_Class = CautiousDefaultHint
    RowStack_Class = StackWrapper(UD_AC_RowStack, base_rank=NO_RANK)

",5
"
        # set window
",5
"            s.foundations.append(SS_FoundationStack(x, y, self, i, max_move=0))
            x += 2*l.XM+4*l.XS
            s.foundations.append(SS_FoundationStack(x, y, self, i,
                                 base_rank=KING, max_move=0, dir=-1))
",5
"
        # default
        l.defaultAll()

",5
"    Hint_Class = CautiousDefaultHint

",5
"        # default
        l.defaultAll()

    def updateText(self):
        if self.preview > 1:
",5
"

",5
"# ************************************************************************
# * Cringle
# ************************************************************************
",5
"        for j in range(4):
",5
"        x, y = self.width-l.XS, self.height-l.YS
        s.talon = WasteTalonStack(x, y, self, max_rounds=1)
        l.createText(s.talon, 'n')
",5
"    shallHighlightMatch = Game._shallHighlightMatch_AC

",5
"# register the game
registerGame(GameInfo(290, Bisley, ""Bisley"",
                      GI.GT_1DECK_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
registerGame(GameInfo(372, DoubleBisley, ""Double Bisley"",
",5
"                      1, 0, GI.SL_MOSTLY_SKILL))
",5
"                      GI.GT_1DECK_TYPE, 1, -1, GI.SL_MOSTLY_LUCK))
registerGame(GameInfo(692, BoardPatience, ""Board Patience"",
                      GI.GT_1DECK_TYPE | GI.GT_OPEN, 1, 0, GI.SL_MOSTLY_SKILL))
",5
"# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"    pass

",5
"class TowerOfHanoy(Game):
    RowStack_Class = TowerOfHanoy_RowStack
",5
"
",5
"
    #
",5
"    # game overrides
    #

    def startGame(self):
        self.startDealSample()
",5
"        for i in range(3):
            self.s.talon.dealRow()

",5
"    pass
",5
"# ************************************************************************
# * Hanoi Sequence
# ************************************************************************
",5
"            if len(s.cards) == len(self.cards) and isRankSequence(s.cards):
                return 1
        return 0


",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"        InitialDealTalonStack, \
        OpenStack, \
",5
"        WasteStack, \
        WasteTalonStack
",5
"class Ponytail_Foundation(Braid_Foundation):
    pass

",5
"            yoffset = game.app.images.CARD_YOFFSET
",5
"        self.CARD_YOFFSET = yoffset

",5
"

",5
"            return 1
        return self.cards[-1].suit == cards[0].suit and \
            self.cards[-1].rank - 1 == cards[0].rank

",5
"    def getBottomImage(self):
        return self.game.app.images.getReserveBottom()


class Excuse_RowStack(Tarock_OpenStack):
",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        if not self.cards:
            return 0
        return cards[0].rank == self.cards[-1].rank - 1
",5
"

",5
"
    def canMoveCards(self, cards):
        for i in range(len(cards) - 1):
",5
"        return cards[0].rank == 13 + 8 * (cards[0].suit == 4)

",5
"
class Tarock_GameMethods:
    SUITS = (_(""Wand""), _(""Sword""), _(""Cup""), _(""Coin""), _(""Trump""))
    RANKS = (_(""Ace""), ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"",
             _(""Page""), _(""Valet""), _(""Queen""), _(""King""))
",5
"    # Game layout
",5
"                          yoffset=l.CH//4,
                          max_cards=2, max_move=1, max_accept=1))
        self.setRegion(s.rows, (-999, -999, l.XS * 9, 999999))

        # Create foundations
",5
"        l.createText(s.waste, ""n"")

        # Define stack groups
        l.defaultStackGroups()

",5
"        self.s.talon.dealRow(rows=self.s.rows[:4])
",5
"

",5
"class ImperialTrumps(AbstractTarockGame):

",5
"    def createGame(self):
",5
"        x = l.XM
        s.talon = WasteTalonStack(x, y, self, num_deal=1, max_rounds=-1)
        l.createText(s.talon, ""s"")
        x = x + l.XS
        s.waste = WasteStack(x, y, self)
",5
"        for i in range(8):
            s.rows.append(TrumpWild_RowStack(x, y, self))
",5
"            self.s.talon.dealRow(rows=self.s.rows[i:], flip=0, frames=0)
        self.startDealSample()
        self.s.talon.dealRow(reverse=reverse)
        self.s.talon.dealCards()
",5
"class Pagat(AbstractTarockGame):

    #
    # Game layout
    #
",5
"        y = l.YM
        s.foundations.append(SS_FoundationStack(x, y, self, 0, max_cards=14))
        x = x + l.XS
        s.foundations.append(SS_FoundationStack(x, y, self, 1, max_cards=14))
        x = x + l.XS
",5
"            s.reserves.append(ReserveStack(x, y, self))
            x = x + l.XS
        x = x + l.XS * 6
",5
"        # Create rows
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
",5
"                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))

",5
"        x = l.XM
",5
"            x = x + l.XS
        self.setRegion(s.rows, (-999, int(y), 999999, 999999))

        # Create talon
",5
"    def startGame(self):
",5
"        assert len(self.s.talon.cards) == 78
        self._startDealNumRows(6)
        self.s.talon.dealRow(rows=self.s.rows[3:9])
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        return (card1.suit == card2.suit and
                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))

",5
"        y = l.YM
        s.foundations.append(SS_FoundationStack(x, y, self, 4, max_cards=22))
        y = y + l.YS
        for i in range(4):
            s.foundations.append(
",5
"    # Game over rides
    #

",5
"        for j in range(2):
",5
"        i, n = 0, len(self.s.rows)
        kings = []
        for c in cards:
            if isKing(c):
                kings.append(i)
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.rank + 1 == card2.rank or card1.rank - 1 == card2.rank)

",5
"                s.foundations.append(
                    SS_FoundationStack(x, y, self, j, max_cards=14))
                x = x + l.XS
",5
"
        # Create reserve
        x = l.XM
        y = l.YM + l.YS + l.TEXT_HEIGHT
        s.reserves.append(OpenStack(x, y, self))
",5
"    #
    # Game over rides
",5
"            if r.cards and stack.acceptsCards(r, r.cards[-1:]):
                r.moveMove(1, stack)
        if r.canFlipCard():
            r.flipMove()

",5
"                card1.color != card2.color)

",5
"# ************************************************************************

class Ponytail(Tarock_GameMethods, Braid):

    #
",5
"            x = x + 4 * l.XS
        x = l.XM + 5*l.XS//2
        y = l.YM
        s.braid = Ponytail_PonytailStack(x, y, self, sine=1)
        x = l.XM + 7 * l.XS
",5
"            s.foundations.append(
                Ponytail_Foundation(x, y, self, i, mod=14, max_cards=14))
            s.foundations.append(
                Ponytail_Foundation(
                    x + l.XS, y, self, i, mod=14, max_cards=14))
",5
"            y = y + l.YS
        s.foundations.append(
            Ponytail_Foundation(x, y, self, 4, mod=22, max_cards=22))
",5
"            font=self.app.getFont(""canvas_default""))

        # define stack-groups
",5
"        self.sg.dropstacks = [s.braid] + s.rows + [s.waste]
",5
"

",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"                ((card1.suit == 4 or card2.suit == 4) or
                 card1.color != card2.color))
",5
"            cards, lambda c: (c.rank == 0, c.suit))
",5
"                  ranks=list(range(14)), trumps=list(range(22)))
    registerGame(gi)
    return gi
",5
"
from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.layout import Layout
",5
"            self.game.s.talon.playMoveMove(1, self)
            return 1
        return ReserveStack.clickHandler(self, event)

    rightclickHandler = clickHandler
",5
"
        # create texts 1)
        ta = ""ss""
        x, y = l.XM, l.YM + 2*l.YS
        if self.preview <= 1:
",5
"Straight Flush
Four of a Kind
Full House
Flush
Straight
",5
"            if h >= 2*l.YS:
                ta = ""e""
                t.move(0, -l.YS)
",5
"                font=self.app.getFont(""canvas_default""),
",5
"        s.talon = self.Talon_Class(x, y, self)
",5
"                                  font=self.app.getFont(""canvas_default""))
                self.texts.list.append(t)
            for i in range(20, 25):
",5
"                tx, ty, ta, tf = l.getTextAttr(s.rows[i], anchor=""ss"")
                t = MfxCanvasText(self.canvas, tx, ty, anchor=ta,
                                  font=self.app.getFont(""canvas_default""))
",5
"        self.s.talon.fillStack()

    def isGameWon(self):
",5
"            self.texts.list[i+2].config(text=str(value))
",5
"            score = score + value
        t = '\n'.join(map(str, count))
        self.texts.misc.config(text=t)
        #
",5
"        t = """"
        if score >= self.WIN_SCORE:
            t = _(""WON\n\n"")
",5
"        #
",5
"        if straight:
",5
"            return 5, 15                    # Straight
        #
        if max(same_rank) >= 2:
            same_rank.sort()
",5
"        return -1, 0


# ************************************************************************
",5
"
# register the game
registerGame(GameInfo(139, PokerSquare, ""Poker Square"",
",5
"# Copyright (C) 2005-2009 Skomoroh
#
",5
"# GNU General Public License for more details.
",5
"#
# You should have received a copy of the GNU General Public License
",5
"        InitialDealTalonStack, \
        InvisibleStack, \
        ReserveStack
",5
"        self.fillStack()
        other_stack.fillStack()

",5
"    STEPS = ((-4, 0), (4, 0), (0, -4), (0, 4))
    ROWS = (3, 5, 7, 7, 7, 5, 3)
",5
"        self.STEP_MAP = {}
        for step in self.STEPS:
            self.STEP_MAP[step] = 1
",5
"            self.moveMove(n, self.s.talon, self.s.internals[0], frames=0)
        self.startDealSample()
        rows = list(self.s.rows[:])
        rows.remove(rows[self.EMPTY_STACK_ID])
",5
"            assert len(stacks) == 1
            if stacks[0].id != self.EMPTY_STACK_ID:
                # not perfect
                return won, 1, self.U_WON
",5
"        rows = []
",5
"                    if m and m.cards:
                        rows.append(r)
        return ((rows, 1),)
",5
"

",5
"class Pegged6x6(Pegged):
",5
"
# ************************************************************************
",5
"    registerGame(gi)
    return gi
",5
"

r(180, Pegged, ""Pegged"")
",5
"from pysollib.pysoltk import MfxCanvasText
from pysollib.stack import \
        InitialDealTalonStack, \
        InvisibleStack, \
",5
"        self.game.finishMove()
        self.game.checkForWin()
        return 1
",5
"
    def _dropPairMove(self, n, other_stack, frames=-1, shadow=-1):
",5
"class Memory24(Game):
    Hint_Class = None
",5
"    #
    # game layout
    #
",5
"
    def createGame(self):
",5
"        # create text
        x, y = l.XM, self.ROWS*l.YS
        if self.preview <= 1:
            self.texts.score = MfxCanvasText(
                self.canvas, x, y, anchor=""sw"",
",5
"        w = max(2*l.XS, x)
        self.setSize(l.XM + w + self.COLUMNS*l.XS, l.YM + self.ROWS*l.YS)

        # create stacks
        for i in range(self.ROWS):
",5
"            for j in range(self.COLUMNS):
                x, y = l.XM + w + j*l.XS, l.YM + i*l.YS
",5
"        l.createText(s.talon, anchor=""n"", text_format=""%D"")
        s.internals.append(InvisibleStack(self))

        # define stack-groups
        l.defaultStackGroups()
",5
"
    # Memory special: check score for a perfect game
    def getWinStatus(self):
",5
"        won, status, updated = Game.getWinStatus(self)
        if status == 2 and self.score < self.PERFECT_SCORE:
            return won, 1, self.U_WON
        return won, status, updated
",5
"
    def canSaveGame(self):
        return 0
",5
"
    def canUndo(self):
        return 0

    def _restoreGameHook(self, game):
",5
"    def _saveGameHook(self, p):
",5
"        game.leaveState(old_state)

",5
"
    def createGame(self):
        # create layout
        l, s = Layout(self, card_x_space=4), self.s
",5
"        self.score = 0
",5
"
        # set window
        self.setSize(l.XM + self.COLUMNS*l.XS, l.YM + (self.ROWS+1)*l.YS)
",5
"
    def cardsMatch(self, card1, card2):
        return card1.rank == card2.rank


",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"from pysollib.games.special.tarock import AbstractTarockGame, Grasshopper
from pysollib.games.threepeaks import ThreePeaksNoScore
from pysollib.layout import Layout
",5
"                    not c1.rank + dir == c2.rank):
                return 0
            c1 = c2
        return 1
",5
"            c1 = c2
        return 1

    def isHighRankCard(self, card):
        maxcard = ([self.game.gameinfo.ranks[-1],
",5
"

class Tarock_RK_RowStack(Tarock_OpenStack):
",5
"
    def acceptsCards(self, from_stack, cards):
",5
"        if (not self.basicAcceptsCards(from_stack, cards) or
                not self.isSuitSequence(cards)):
            return 0
",5
"
    def canMoveCards(self, cards):
        return (self.basicCanMoveCards(cards) and
                self.isAlternateColorSequence(cards))

",5
"# ************************************************************************
# *
",5
"        playcards = 4 * l.YS // l.YOFFSET
        xoffset, yoffset = [], []
        for i in range(playcards):
            xoffset.append(0)
            yoffset.append(l.YOFFSET)
",5
"
",5
"            s.reserves.append(ReserveStack(x, y, self))
            x = x + l.XS
        x, y = l.XM + (maxrows - rows) * l.XS // 2, l.YM + l.YS
        self.setRegion(s.reserves, (-999, -999, 999999, y - l.YM // 2))
",5
"    #
",5
"        while self.s.talon.cards:
            card = self.s.talon.cards[-1]
",5
"            if card.rank == 13 + 8 * (card.suit == 4):
                if self.s.rows[i].cards:
                    i = i + 1
            self.s.talon.dealRow(rows=[self.s.rows[i]], frames=4)
",5
"
    # must look at cards
    def _getClosestStack(self, cx, cy, stacks, dragstack):
        closest, cdist = None, 999999999
",5
"        for stack in stacks:
            if stack.cards and stack is not dragstack:
",5
"                closest, cdist = stack, dist
        return closest

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"
# ************************************************************************
",5
"r(13164, DoubleCockroach, 'Double Cockroach', GI.GT_TAROCK, 2, 0,
  GI.SL_MOSTLY_SKILL)
r(13165, Corkscrew, 'Corkscrew', GI.GT_TAROCK, 2, 0, GI.SL_MOSTLY_SKILL)
",5
"# ---------------------------------------------------------------------------##
#
",5
"

class DojoujisGame_Talon(LarasGame_Talon):
    def getActiveRow(self):
",5
"
    def acceptsCards(self, from_stack, cards):
        if not OpenStack.acceptsCards(self, from_stack, cards):
",5
"            return 0
",5
"    # Game overrides
    #

    def getCardFaceImage(self, deck, suit, rank):
",5
"# ************************************************************************

class RelaxedKatrinasGame(KatrinasGame):
    Reserve_Class = LarasGame_Reserve
    Reserve_Cards = 2
",5
"    Reserve_Cards = 3
    MAX_ROUNDS = 3

",5
"# ************************************************************************
# * Bridget's Game
# * In memory of Bridget Bishop
",5
"    Reserve_Class = BridgetsGame_Reserve
    Reserve_Cards = 2
    MAX_ROUNDS = 2
    ROW_LENGTH = 5
",5
"    def Deal_Rows(self, i):
        return 16

",5
"# * Double Bridget's Game
# ************************************************************************

class DoubleBridgetsGame(BridgetsGame):
    Reserve_Cards = 3
",5
"    MAX_ROUNDS = 3

",5
"

# ************************************************************************
",5
"    def Deal_Rows(self, i):
        return 12

",5
"class RelaxedFatimehsGame(FatimehsGame):
    Reserve_Class = LarasGame_Reserve
    Reserve_Cards = 2
",5
"        return i + j * 5

",5
"
# ************************************************************************
# * Relaxed Kali's Game
",5
"
# ************************************************************************
",5
"
    def Mod(self, i):
        return 4

",5
"    def Deal_Rows(self, i):
        return 8

    def Base_Suit(self, i, j):
",5
"#
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"from pysollib.game import Game
from pysollib.gamedb import GI, GameInfo, registerGame
from pysollib.hint import AbstractHint, CautiousDefaultHint, DefaultHint
from pysollib.layout import Layout
",5
"from pysollib.mfxutil import kwdefault
from pysollib.mygettext import _
",5
"        UNLIMITED_ACCEPTS, \
        UNLIMITED_CARDS, \
        UNLIMITED_MOVES
",5
"        self.game.updateText()
",5
"
",5
"        kwdefault(cap, base_suit=0, mod=12, max_cards=120, max_move=0)
        AbstractFoundationStack.__init__(self, x, y, game, suit, **cap)

",5
"    def acceptsCards(self, from_stack, cards):
",5
"            return 0
        pile, rank, suit = from_stack.getPile(), 0, 0
        if self.cards:
            rank = (self.cards[-1].rank + 1) % 12
            suit = self.cards[-1].suit + (rank == 0)
",5
"        if (not pile or len(pile) <= 11 - rank or
                not isSameSuitSequence(pile[-(12 - rank):])):
            return 0
",5
"
    def __init__(self, x, y, game, yoffset, **cap):
        kwdefault(cap, max_move=UNLIMITED_MOVES, max_cards=UNLIMITED_CARDS,
",5
"                  max_accept=UNLIMITED_ACCEPTS, base_rank=0, dir=-1)
        OpenStack.__init__(self, x, y, game, **cap)
        self.CARD_YOFFSET = yoffset

",5
"    def currentForce(self, card):
        force = self._getForce(card)
        hour = time.localtime(time.time())[3]
",5
"
",5
"
class Dashavatara_AF_RowStack(Dashavatara_OpenStack):

    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards) \
",5
"        stackcards = self.cards
        if not len(stackcards):
            return cards[0].rank == 11 or self.cap.base_rank == ANY_RANK
        return self.isSuitSequence([stackcards[-1], cards[0]])
",5
"class Journey_BraidStack(OpenStack):
",5
"            if self.game.s.braidstrong.cards:
",5
"                from_stack is self.game.s.braidweak or
                from_stack in self.game.s.rows):
            return 0
",5
"                not stack.acceptsCards(self, pile[-1:])):
            return (None, 0)
",5
"        if not self.basicAcceptsCards(from_stack, cards):
",5
"        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return 0
        # check
        return not (self.cards or self.game.s.talon.cards)

",5
"    COLORS = (_(""Black""), _(""Red""), _(""Yellow""), _(""Green""), _(""Brown""),
              _(""Orange""), _(""Grey""), _(""White""), _(""Olive""), _(""Crimson""))
    FORCE = (_(""Strong""), _(""Weak""))

",5
"    # Game layout
    #

    def createGame(self):
",5
"        l, s = Layout(self), self.s

        # Set window size
",5
"        # Create talon
        s.talon = InitialDealTalonStack(l.XM + l.XS, l.YM, self)
",5
"class TenAvatars(AbstractDashavataraGame):

    #
    # Game layout
",5
"    #

",5
"            x = x + l.XS
",5
"
",5
"                return 0
        return 1


",5
"                                 r.suit, mod=12, max_cards=12))

        # Create reserve stacks
        for r in l.s.reserves:
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self, l.YOFFSET,
                          suit=ANY_SUIT, base_rank=self.BASE_RANK,
",5
"        self.s.talon.dealRow(rows=self.s.rows[:8], flip=1, frames=3)
",5
"                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))


# ************************************************************************
",5
"    #

    def createGame(self, **layout):
        Balarama.createGame(self)
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank)

",5
"    #

    def createGame(self, **layout):
        Balarama.createGame(self, reserves=0)

",5
"                    (card1.rank + 1 == card2.rank or
                     card2.rank + 1 == card1.rank))
        return (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank)


",5
"    #
    # Game layout
    #

",5
"    def createGame(self, **layout):
        Balarama.createGame(self, reserves=4)
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        # Create foundations
        for r in l.s.foundations:
            s.foundations.append(self.Foundation_Class(r.x, r.y, self,
                                 r.suit, mod=12, max_cards=12, max_move=0))
",5
"
        # Create row stacks
        for r in l.s.rows:
",5
"        self.s.talon.dealCards()
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"
    #
",5
"
",5
"
",5
"    def createGame(self, **layout):
        Matsya.createGame(self, max_rounds=-1, num_deal=3)


# ************************************************************************
",5
"    #

    def createGame(self, **layout):
",5
"# ************************************************************************
",5
"    #

    def createGame(self, **layout):
        Matsya.createGame(self, max_rounds=-1, num_deal=3)
",5
"    #

    def createGame(self):
        # create layout
",5
"        decks = self.gameinfo.decks
        h = max(5 * l.YS + 35, 2*l.YM + 2*l.YS +
                (self.BRAID_CARDS - 1) * l.YOFFSET*self.BRAID_OFFSET)
        self.setSize(l.XM + l.XS * (7 + decks * 2), l.YM + h)

",5
"        s.addattr(braidstrong=None)      # register extra stack variable
",5
"        x, y = l.XM, l.YM
        for j in range(5):
",5
"            s.rows.append(
                Journey_ReserveStack(x + l.XS * (1 + decks), y, self))
            y = y + l.YS
",5
"        x = x + l.XS * 2
        s.waste = WasteStack(x, y, self)
",5
"        for i in range(self.BRAID_CARDS):
            self.s.talon.dealRow(rows=[self.s.braidstrong])
        for i in range(self.BRAID_CARDS):
",5
"            self.s.talon.dealRow(rows=[self.s.braidweak])
        self.s.talon.dealRow()
        # deal base_card to foundations, update cap.base_rank
        self.base_card = self.s.talon.getCard()
",5
"        return ()

    def _restoreGameHook(self, game):
        self.base_card = self.cards[game.loadinfo.base_card_id]
",5
"        if self.preview > 1 or not self.texts.info:
            return
",5
"        if not self.base_card:
            t = """"
        else:
",5
"
        # Create foundation
        x, y = w // 2 - l.CW // 2, h - l.YS
        s.foundations.append(AppachansWaterfall_Foundation(x, y, self, -1))
",5
"        l.defaultStackGroups()

    #
    # Game over rides
    #
",5
"
",5
"        return len(self.s.foundations[0].cards) == 120

",5
"
# ************************************************************************
# * Hiranyaksha
# ************************************************************************
",5
"
class Hiranyaksha(AbstractDashavataraGame):
    RowStack_Class = StackWrapper(Dashavatara_RK_RowStack, base_rank=NO_RANK)
",5
"    #

",5
"        #
        playcards = 4 * l.YS // l.YOFFSET
        xoffset, yoffset = [], []
",5
"        for i in range(playcards):
            xoffset.append(0)
            yoffset.append(l.YOFFSET)
        for i in range(96 * self.gameinfo.decks - playcards):
            xoffset.append(l.XOFFSET)
",5
"                    (stack.cards[-1].y - cy)**2
            else:
                dist = (stack.x - cx)**2 + (stack.y - cy)**2
            if dist < cdist:
                closest, cdist = stack, dist
",5
"        # 2)See if we can move a card to the tableaux
        if not self.hints:
            for r in game.sg.dropstacks:
                pile = r.getPile()
                if not pile or len(pile) != 1:
",5
"                    if rr.acceptsCards(None, pile):
",5
"                        self.addHint(score, 1, r, t)
                        break

        # 3)See if we can move a card from the tableaux
",5
"                    continue
                # find a stack that would accept this card
                for t in game.s.rows:
                    if t is not r and t.acceptsCards(r, pile):
",5
"        # 4)See if we can move a card within the row stacks
        if not self.hints:
",5
"        # create layout
        l, s = Layout(self), self.s
        TABLEAU_YOFFSET = min(9, max(3, l.YOFFSET // 3))

        # set window
",5
"        # create stacks
        s.addattr(tableaux=[])     # register extra stack variable
        x = l.XM + 8 * l.XS + l.XS // 2
",5
"        y = l.YM
",5
"            y = y + th
        x, y = l.XM, y + l.YM
        for i in range(10):
",5
"        self.sg.openstacks = s.tableaux + s.rows + s.reserves
        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.tableaux + s.rows

",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
                (card1.rank + 3 == card2.rank or card2.rank + 3 == card1.rank))
",5
"# ************************************************************************
#  *
#  ***********************************************************************/

def r(id, gameclass, name, game_type, decks, redeals, skill_level):
",5
"    game_type = game_type | GI.GT_DASHAVATARA_GANJIFA
    gi = GameInfo(id, gameclass, name, game_type, decks, redeals, skill_level,
                  suits=list(range(10)), ranks=list(range(12)))
    registerGame(gi)
",5
"
",5
"  1, 0, GI.SL_MOSTLY_SKILL)
r(15414, Balarama, ""Balarama"", GI.GT_DASHAVATARA_GANJIFA, 1, 0,
  GI.SL_MOSTLY_SKILL)
r(15415, Hayagriva, ""Hayagriva"", GI.GT_DASHAVATARA_GANJIFA, 1, 0,
  GI.SL_MOSTLY_SKILL)
",5
"r(15416, Shanka, ""Shanka"", GI.GT_DASHAVATARA_GANJIFA, 1, 0, GI.SL_MOSTLY_SKILL)
r(15417, Journey, ""Journey to Cuddapah"", GI.GT_DASHAVATARA_GANJIFA, 1, 2,
",5
"  GI.SL_BALANCED)
r(15418, LongJourney, ""Long Journey to Cuddapah"", GI.GT_DASHAVATARA_GANJIFA,
  2, 2, GI.SL_BALANCED)
r(15419, Surukh, ""Surukh"", GI.GT_DASHAVATARA_GANJIFA, 1, 0, GI.SL_BALANCED)
r(15420, AppachansWaterfall, ""Appachan's Waterfall"", GI.GT_DASHAVATARA_GANJIFA,
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return ((card1.suit == card2.suit) and
                ((card1.rank + 1 == card2.rank) or
                 (card1.rank - 1 == card2.rank)))

",5
"# ************************************************************************
#  * Flower Foundation Stacks
#  ***********************************************************************/
",5
"
    def updateText(self):
",5
"        for i in range(len(s) - 1):
            if s[i].suit != s[i + 1].suit:
",5
"
    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
            return 0
",5
"        return stackcards[-1].rank == cards[0].rank + 1


",5
"

class Pagoda_Foundation(Flower_FoundationStack):
",5
"        else:
            return a == b

",5
"    def getBottomImage(self):
        return self.game.app.images.getSuitBottom(self.cap.suit)


class MatsuKiri_Foundation(Flower_FoundationStack):
",5
"
    def __init__(self, x, y, game, suit, **cap):
",5
"        kwdefault(cap, max_move=0, max_cards=48, max_accept=4, min_accept=4)
",5
"        AbstractFoundationStack.__init__(self, x, y, game, suit, **cap)
        self.CARD_YOFFSET = self.game.app.images.CARDH // 10

    def acceptsCards(self, from_stack, cards):
        if not self.basicAcceptsCards(from_stack, cards):
",5
"        Flower_FoundationStack.__init__(self, x, y, game, suit, **cap)
        self.CARD_YOFFSET = self.game.app.images.CARDH // 20

",5
"        stackcards = self.cards
        if stackcards:
            return ((stackcards[-1].suit + 1) % 12 == cards[0].suit and
                    cards[0].rank == self.cap.base_rank)
        else:
",5
"
    #      def getBottomImage(self):
    #          return self.game.app.images.getLetter(self.cap.base_rank)


",5
"class Queue_Foundation(AbstractFoundationStack):
    def __init__(self, x, y, game, suit, **cap):
        kwdefault(cap, mod=12, dir=0, base_suit=ANY_SUIT, max_move=0)
        AbstractFoundationStack.__init__(self, x, y, game, suit, **cap)

",5
"        self.CARD_YOFFSET = yoffset

",5
"                return 0
",5
"

class Hanafuda_SequenceStack(Flower_OpenStack):

    def acceptsCards(self, from_stack, cards):
",5
"            return cards[0].rank == 0 or self.cap.base_rank == ANY_RANK
",5
"        return self.isHanafudaSequence([stackcards[-1], cards[0]])

",5
"        if not len(stackcards):
",5
"            return 0
        stackcards = self.cards
        if not stackcards:
            return cards[0].rank == 0
        if cards[0].suit != stackcards[-1].suit:
",5
"            return 0
",5
"        f = self.game.s.foundations[0]
        if not f.cards:
            suit = 0
",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        stackcards = self.cards
        if len(cards) - 1 or len(stackcards) >= 3:
",5
"        offset = self.game.app.images.CARDW / 1.7
",5
"        if not self.cards and self.game.s.braid.cards:
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"from pysollib.gamedb import GI, GameInfo, registerGame
",5
"        AbstractFlowerGame, \
        FlowerClock_Foundation, \
        FlowerClock_RowStack, \
",5
"        Gaji_RowStack, \
        GreatWall_FoundationStack, \
        GreatWall_RowStack, \
        Hanafuda_SS_FoundationStack, \
",5
"        Hanafuda_SequenceStack, \
        MatsuKiri_Foundation, \
",5
"from pysollib.mfxutil import kwdefault
from pysollib.mygettext import _
from pysollib.pysoltk import MfxCanvasText
",5
"
        # Create clock
        xoffset = (1, 2, 2.5, 2, 1, 0, -1, -2, -2.5, -2, -1, 0)
",5
"                                                   yoffset=l.CH//4,
                                                   max_cards=8, max_accept=8))
                x = x + l.XS
        self.setRegion(s.rows, (0, 0, l.XS * 4, 999999))
",5
"
        # Create talon
        s.talon = InitialDealTalonStack(
            self.width - l.XS, self.height - l.YS, self)

",5
"        # Define stack groups
        l.defaultStackGroups()

",5
"        for i in self.s.foundations:
            if len(i.cards) != 4:
                return 0
",5
"
# ************************************************************************
#  * Gaji
#  ***********************************************************************/
",5
"class Gaji(AbstractFlowerGame):

    #
    # Game layout
",5
"    #

",5
"        s.foundations.append(Gaji_Foundation(x, y, self, -1, base_rank=2))
",5
"
        # Create row stacks
        x = l.XS * 2.5 + l.XM
        for i in range(8):
            s.rows.append(Gaji_RowStack(x, y, self, yoffset=l.CH//2,
",5
"                    topcards[c.rank] = c
                    cards.remove(c)
        return topcards + cards
",5
"    def startGame(self):
",5
"            return (card1.rank == card2.rank and
",5
"                    ((((card1.suit + 1) % 12) == card2.suit) or
                     (((card1.suit - 1) % 12) == card2.suit)))
        else:
",5
"            return ((card1.suit == card2.suit) and
                    ((card1.rank + 1 == card2.rank) or
",5
"    #
    # Game layout
    #

",5
"        self.setSize(l.size[0], l.size[1])

",5
"        for s in self.s.rows:
            if (len(s.cards) != 4 or not cardsFaceUp(s.cards) or
                    not s.isHanafudaSequence(s.cards, self.Strictness)):
",5
"    BaseRank = ANY_RANK


# ************************************************************************
# * Oonsoo Times Two
",5
"# ************************************************************************

",5
"    Rows = 24
    Reserves = 1
",5
"

# ************************************************************************
#  * Pagoda
",5
"        l, s = Layout(self), self.s
",5
"                s.foundations.append(stack)
                t = MfxCanvasText(self.canvas, x + l.CW // 2, y - 12,
                                  anchor=""center"", font=font)
                stack.texts.misc = t
",5
"
    def updateText(self):
",5
"        self.s.talon.dealRow(rows=self.s.reserves, reverse=1)
",5
"        self.s.talon.dealCards()

    def fillStack(self, stack):
        if not stack.cards and stack is self.s.waste:
            if self.canDealCards():
",5
"
",5
"class MatsuKiri(AbstractFlowerGame):
",5
"        self.setSize(l.XM * 3 + l.XS * 9, l.YM + l.YS * 6)

        # Create row stacks
",5
"        # Create foundation
        x = x + l.XM * 2
        s.foundations.append(MatsuKiri_Foundation(x, y, self, ANY_SUIT))
        self.setRegion(
",5
"
    def fillStack(self, stack):
        if stack in self.s.rows:
            if len(stack.cards) > 0 and not stack.cards[-1].face_up:
                self.flipMove(stack)
",5
"
",5
"            s.rows, (l.XM + l.XS * 1.25, -999, self.width - l.XS * 1.25,
",5
"        x = self.width // 2 - l.CW // 2
        y = self.height - l.YS * 1.2
",5
"        s.talon = InitialDealTalonStack(x, y, self)

        # Define stack groups
        l.defaultStackGroups()
",5
"    #
    # Game extras
",5
"                self.flipMove(stack)
",5
"
class FourWinds(AbstractFlowerGame):

    #
    # Game layout
",5
"    #

    def createGame(self):
        l, s = Layout(self), self.s
",5
"                                       base_rank=ANY_RANK)
",5
"        l.createText(s.waste, ""s"")

        # Define stack-groups
        l.defaultStackGroups()

",5
"
",5
"class Sumo(AbstractFlowerGame):
    Layout_Method = staticmethod(Layout.sumoLayout)
    Talon_Class = InitialDealTalonStack
",5
"        l.defaultAll()

    #
    # Game over rides
",5
"        self._startDealNumRowsAndDealRowAndCards(5)
",5
"
",5
"        for r in l.s.rows:
",5
"                self.RowStack_Class(r.x, r.y, self, yoffset=l.YOFFSET))
        for r in l.s.reserves:
            s.reserves.append(ReserveStack(r.x, r.y, self))
        l.defaultAll()
",5
"    Talon_Class = WasteTalonStack
",5
"    #

    def createGame(self, max_rounds=1, num_deal=1, **layout):
        l, s = Layout(self), self.s
        kwdefault(layout, rows=self.Rows, waste=1, texts=1, playcards=21)
",5
"        # Create stacks
        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self,
                                   max_rounds=max_rounds, num_deal=num_deal)
        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)
",5
"
        # Create foundations
        for r in l.s.foundations:
",5
"        for r in l.s.rows:
            s.rows.append(
                self.RowStack_Class(r.x, r.y, self, yoffset=l.YOFFSET))
",5
"
        # Define stack groups
",5
"        l.defaultAll()

    #
",5
"
",5
"        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"
    def fillStack(self, stack):
        if not stack.cards and stack is self.s.waste:
",5
"
",5
"class DoubleSamuri(Samuri):
    Rows = 11


# ************************************************************************
",5
"                                 suit=ANY_SUIT, base_rank=r.suit))
        for r in l.s.rows:
            s.rows.append(
",5
"
    #
    # Game over rides
",5
"        self.s.talon.dealRow()
        self.s.talon.dealCards()

    def fillStack(self, stack):
",5
"    Rows = 11

",5
"

",5
"    BaseRank = 0
",5
"
    def createGame(self, **layout):
",5
"
# ************************************************************************
# * Double Your Fun
# ************************************************************************
",5
"        # Create talon
",5
"        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self,
                                   max_rounds=max_rounds, num_deal=num_deal)
        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)

",5
"r(12346, MatsuKiri, ""MatsuKiri"", GI.GT_HANAFUDA | GI.GT_OPEN, 1, 0,
",5
"  GI.SL_MOSTLY_SKILL)
r(12372, MatsuKiriStrict, 'MatsuKiri Strict', GI.GT_HANAFUDA | GI.GT_OPEN, 1,
",5
"r(12359, Firecracker, ""Firecracker"", GI.GT_HANAFUDA, 1, 0, GI.SL_BALANCED)
r(12360, EasyX1, ""Easy x One"", GI.GT_HANAFUDA, 1, 1, GI.SL_BALANCED)
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
",5
"#
",5
"        SS_FoundationStack, \
        SS_RowStack, \
",5
"        kwdefault(cap, mod=12, dir=0, base_rank=NO_RANK, max_move=0)
        AbstractFoundationStack.__init__(self, x, y, game, suit, **cap)

",5
"    def acceptsCards(self, from_stack, cards):
",5
"                == cards[0].rank
",5
"        self.CARD_YOFFSET = yoffset

    def isRankSequence(self, cards, dir=None):
",5
"
    def isAlternateForceSequence(self, cards, dir=None):
        if not dir:
",5
"    def isSuitSequence(self, cards, dir=None):
        if not dir:
            dir = self.cap.dir
",5
"        c1 = cards[0]
        for c2 in cards[1:]:
            if not (c1.suit == c2.suit and c1.rank + dir == c2.rank):
",5
"                return 0
            c1 = c2
        return 1
",5
"        stackcards = self.cards
        if not len(stackcards):
            return cards[0].rank == 11 or self.cap.base_rank == ANY_RANK
        return self.isRankSequence([stackcards[-1], cards[0]])
",5
"            return cards[0].rank == 11 or self.cap.base_rank == ANY_RANK
        return self.isSuitSequence([stackcards[-1], cards[0]])

",5
"
class Circles_RowStack(SS_RowStack):

    def __init__(self, x, y, game, base_rank, yoffset):
",5
"    def __init__(self, x, y, game, xoffset, yoffset):
        OpenStack.__init__(self, x, y, game)
        self.CARD_YOFFSET = int(self.game.app.images.CARD_YOFFSET * yoffset)
        # use a sine wave for the x offsets
        self.CARD_XOFFSET = []
",5
"            self.CARD_XOFFSET.append(int(math.cos(j) * xoffset))
            j = j + .9
",5
"    def fillStack(self):
",5
"            elif self.game.s.braidstrong.cards:
                self.game.moveMove(1, self.game.s.braidstrong, self)

    def getBottomImage(self):
",5
"    FORCE = (_(""Strong""), _(""Weak""))

",5
"    #
",5
"        self.setSize(w, h)

        # Create row stacks
",5
"        x = l.XM
        y = l.YM
        for i in range(4):
            s.foundations.append(
                SS_FoundationStack(
",5
"        x = self.width - l.XS
        y = l.YM
        for i in range(4):
            s.foundations.append(
                SS_FoundationStack(
",5
"    #
",5
"        return ((card1.suit == card2.suit) and
                ((card1.rank + 1 == card2.rank) or
                 (card1.rank - 1 == card2.rank)))


",5
"    def createGame(self):
        l, s = Layout(self), self.s

        # Set window size
",5
"
        # Create talon
        s.talon = DealRowTalonStack(l.XM, self.height - l.YS, self)
",5
"
    def isGameWon(self):
        if len(self.s.talon.cards):
            return 0
        for s in self.s.rows:
",5
"    #
",5
"        l, s = Layout(self), self.s
",5
"
        # Create talon
        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self)

        # Define stack groups
",5
"    def startGame(self):
        assert len(self.s.talon.cards) == 96
        self._startDealNumRows(6)
",5
"#  ***********************************************************************/

class Ghulam(Shamsher):
    Layout_Method = staticmethod(Layout.ghulamLayout)
    Talon_Class = InitialDealTalonStack
",5
"
    #
    # Game layout
    #

",5
"    RowStack_Class = RK_RowStack
    BASE_RANK = 11
    MAX_MOVE = 0

",5
"
        # Create talon
        s.talon = self.Talon_Class(
            l.s.talon.x, l.s.talon.y, self,
            max_rounds=max_rounds, num_deal=num_deal)
",5
"    def startGame(self):
        assert len(self.s.talon.cards) == 96
        for i in range(8):
            self.s.talon.dealRow(rows=self.s.rows[i+1:], flip=0, frames=0)
",5
"                ((card1.rank + 1 == card2.rank) or
",5
"# ************************************************************************
",5
"    RowStack_Class = SS_RowStack
    BASE_RANK = ANY_RANK
    MAX_MOVE = 1

    #
",5
"    def createGame(self, **layout):
        Tipati.createGame(self, max_rounds=-1, num_deal=3)

    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        # set window
        # (piles up to 20 cards are playable - needed for Braid_BraidStack)
        decks = self.gameinfo.decks
        h = max(5 * l.YS + 35, l.YS + (self.BRAID_CARDS - 1) * l.YOFFSET)
",5
"            self.canvas,
            self.width // 2, h - l.YM * 2.5,
",5
"            anchor=""center"",
            font=self.app.getFont(""canvas_default""))
        x += l.XS * 2
",5
"        self.sg.openstacks = s.foundations + s.rows
        self.sg.dropstacks = [s.braidstrong] + [s.braidweak] + s.rows \
            + [s.waste]

    #
",5
"    # game overrides
    #

    def startGame(self):
",5
"        self.flipMove(self.s.talon)
",5
"    def getHighlightPilesStacks(self):
",5
"        return ()
",5
"    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
        self.loadinfo.base_card_id = p.load()

    def _saveGameHook(self, p):
",5
"                t = t + _("" Ascending"")
            elif dir == 11:
                t = t + _("" Descending"")
        self.texts.info.config(text=t)
",5
"

# ************************************************************************
",5
"# ************************************************************************

class AkbarsConquest(AkbarsTriumph):

    BRAID_CARDS = 16
",5
"    RowStack_Class = StackWrapper(Mughal_RK_RowStack, base_rank=NO_RANK)

    #
    # game layout
    #
",5
"            stack = self.RowStack_Class(x, y, self, yoffset=l.YOFFSET)
",5
"    def startGame(self):
        self.startDealSample()
        i = 0
        while self.s.talon.cards:
",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        # check that the base card is correct
",5
"                self.cards[-1].rank + self.cap.dir == cards[0].rank)

    def getBottomImage(self):
        return self.game.app.images.getLetter(self.cap.base_rank)

",5
"class Dikapala_ReserveStack(ReserveStack):
",5
"        OpenStack.__init__(self, x, y, game, **cap)

    def acceptsCards(self, from_stack, cards):
        return (ReserveStack.acceptsCards(self, from_stack, cards) and
                self.game.s.talon.cards)
",5
"                        # do not move a card that is already in correct place
                        continue
                    base_score = 80000 + (4 - r.cap.base_suit)
                else:
",5
"                        break
",5
"
        # 3)See if we can move a card from the tableaux
        #    to a row stack. This can only happen if there are
        #    no more cards to deal.
",5
"                pile = r.getPile()
                if not pile or len(pile) != 1 or len(pile) == len(r.cards):
",5
"        if self.level >= 2:
",5
"# ************************************************************************
# * Ashta Dikapala
# ************************************************************************
",5
"                    Dikapala_TableauStack(
                        x, y, self, i - 1, TABLEAU_YOFFSET))
                x = x + l.XS
            x = x + l.XM
",5
"            s.rows.append(Dikapala_RowStack(x, y, self, max_accept=1))
            x = x + l.XS
        x = self.width - l.XS
",5
"        l.createText(s.talon, ""sw"")

",5
"        # define stack-groups
",5
"        return 1

    def fillStack(self, stack):
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return (card1.suit == card2.suit and
                (card1.rank + 3 == card2.rank or card2.rank + 3 == card1.rank))
",5
"r(14411, Dhanpati, 'Dhanpati', GI.GT_MUGHAL_GANJIFA, 1, 1, GI.SL_BALANCED)
r(14412, AkbarsTriumph, 'Akbar\'s Triumph', GI.GT_MUGHAL_GANJIFA, 1, 2,
  GI.SL_BALANCED)
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"# it under the terms of the GNU General Public License as published by
",5
"from . import hanafuda  # noqa: F401
from . import hanafuda1  # noqa: F401
from . import hexadeck  # noqa: F401
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"    def __init__(self, x, y, game, **cap):
",5
"        return 0

    def canDropCards(self, stacks):
        return (None, 0)

",5
"        # we need to override this because the shade may be hiding
        # the tile (from Tk's stacking view)
        return len(self.cards) - 1

",5
"    def initBindings(self):
        bind(self.group, ""<1>"", self._Stack__clickEventHandler)
        bind(self.group, ""<Control-1>"", self._Stack__controlclickEventHandler)
",5
"        game = self.game
        row = game.s.rows
        if not self.cards or game.drag.stack is self or self.basicIsBlocked():
            return 1
        game.playSample(""move"", priority=10)
",5
"# * Matrix Game
# ************************************************************************

class Matrix3(Game):

",5
"        l, s = Layout(self), self.s
        grid = math.sqrt(self.gameinfo.ncards)
        assert grid == int(grid)
        grid = int(grid)

",5
"
        # Create talon
        x, y = -2*l.XS, 0               # invisible
",5
"
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return ((card1.rank + 1 == card2.rank) or
                (card1.rank - 1 == card2.rank))

",5
"    pass


",5
"class Matrix6(Matrix3):
",5
"class Matrix8(Matrix3):
",5
"    pass

",5
"        category=GI.GC_TRUMP_ONLY, short_name=short_name,
        suits=(), ranks=(), trumps=list(range(ncards)),
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"from pysollib.util import ANY_RANK, ANY_SUIT, NO_RANK, UNLIMITED_ACCEPTS, \
        UNLIMITED_MOVES
",5
"
",5
"        SS_FoundationStack.__init__(self, x, y, game, suit, **cap)


class HexATrump_Foundation(HexADeck_FoundationStack):
    def acceptsCards(self, from_stack, cards):
",5
"        for s in self.game.s.foundations[:3]:
            if len(s.cards) != 16:
                return 0
        return 1

",5
"        if stack_dir == 0:
",5
"            card_dir = (cards[0].rank - self.cards[-1].rank) % self.cap.mod
",5
"        OpenStack.__init__(self, x, y, game, **cap)
",5
"        for c2 in cards[1:]:
            if (c1.color < 2 and c1.color == c2.color or
                    not c1.rank + dir == c2.rank):
                return 0
            c1 = c2
",5
"

",5
"
    def acceptsCards(self, from_stack, cards):
        if (not self.basicAcceptsCards(from_stack, cards) or
                not self.isSuitSequence(cards)):
",5
"    def canMoveCards(self, cards):
",5
"        stackcards = self.cards
        if stackcards or cards[0].suit == 4:
",5
"        id = self.id - 16
",5
"            if (stackcards[-1].suit == 4 or cards[0].suit == 4):
                return 1
        return AC_RowStack.acceptsCards(self, from_stack, cards)
",5
"        if stackcards:
            if (stackcards[-1].suit == 4 or cards[0].suit == 4):
                return stackcards[-1].rank == cards[0].rank + 1
        return AC_RowStack.acceptsCards(self, from_stack, cards)
",5
"        return cards[0].suit == 4
",5
"        return self.game.app.images.getBraidBottom()

",5
"        return ReserveStack.acceptsCards(self, from_stack, cards)

    def getBottomImage(self):
        return self.game.app.images.getTalonBottom()
",5
"

# ************************************************************************
# *
",5
"
    #
    # Game layout
    #
",5
"
    def createGame(self):
",5
"
",5
"            y = y + l.YS
        self.setRegion(s.rows, (0, 0, 999999, 999999))

        # Create talon
",5
"
    #
    # Game over rides
",5
"                    for i in range(4):
                        if c.rank == ranks[i]:
",5
"    def shallHighlightMatch(self, stack1, card1, stack2, card2):
        return 0


# ************************************************************************
",5
"
    def createGame(self, max_rounds=-1, num_deal=1, **layout):
",5
"                self.Foundation_Class(
                    r.x, r.y, self,
                    r.suit, mod=16, max_cards=16, max_move=1))
        r = l.s.foundations[4]
        s.foundations.append(
",5
"                r.x, r.y, self, 4, mod=4,
                max_move=0, max_cards=4, base_rank=ANY_RANK))

        # Create rows
        for r in l.s.rows:
",5
"            s.rows.append(
",5
"                self.RowStack_Class(
                    r.x, r.y, self,
",5
"        # Create talon
        s.talon = self.Talon_Class(
",5
"        r = l.s.foundations[4]
        s.foundations.append(
            HexATrump_Foundation(
                r.x, r.y, self, 4, mod=4,
                max_move=0, max_cards=4, base_rank=ANY_RANK))
",5
"    def createGame(self, max_rounds=-1, num_deal=1, **layout):
        l, s = Layout(self), self.s
        kwdefault(layout, rows=8, waste=1, playcards=20)
",5
"        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self,
                                   max_rounds=max_rounds, num_deal=num_deal)
        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)

",5
"        self.startDealSample()
        self.s.talon.dealRow()
",5
"                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))


# ************************************************************************
",5
"# * Klondike Plus 16
# ************************************************************************

class KlondikePlus16(Game):
",5
"        self.setSize(l.size[0], l.size[1])

        # Create talon
        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self,
                                   max_rounds=max_rounds, num_deal=num_deal)
",5
"                self.Foundation_Class(
                    r.x, r.y, self,
                    r.suit, mod=16, max_cards=16, max_move=1))
",5
"            s.rows.append(self.RowStack_Class(r.x, r.y, self,
                                              suit=ANY_SUIT, base_rank=15))
",5
"        l.createText(s.reserves[0], ""se"")

",5
"        # Define stack groups
        l.defaultAll()

",5
"        self.s.talon.dealRow()
        self.s.talon.dealCards()

",5
"
",5
"    #
",5
"                                              suit=ANY_SUIT, base_rank=15))

        # Create reserve
",5
"        for i in range(len(self.s.rows)):
            self.s.talon.dealRow(rows=self.s.rows[i+1:], flip=0, frames=0)
",5
"                (card1.rank + 1 == card2.rank or card2.rank + 1 == card1.rank))
",5
"    Hint_Class = CautiousDefaultHint
    Layout_Method = staticmethod(Layout.gypsyLayout)
    Talon_Class = WasteTalonStack
    Foundation_Class = SS_FoundationStack
    RowStack_Class = AC_RowStack
",5
"        self.Layout_Method(l, **layout)
        self.setSize(l.size[0], l.size[1])

        # Create talon
        s.talon = self.Talon_Class(l.s.talon.x, l.s.talon.y, self,
",5
"        # Create foundations
        for r in l.s.foundations:
            s.foundations.append(
                self.Foundation_Class(
",5
"                    r.x, r.y, self,
                    r.suit, mod=16, max_cards=16, max_move=1))

",5
"        # Define stack groups
",5
"
",5
"class Drawbridge(Game):
    Hint_Class = CautiousDefaultHint
    Layout_Method = staticmethod(Layout.harpLayout)
",5
"    #
    # Game layout
    #

",5
"                self.Foundation_Class(
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self,
                                              suit=ANY_SUIT,
                                              base_rank=ANY_RANK))
",5
"
    def shallHighlightMatch(self, stack1, card1, stack2, card2):
",5
"        return (card1.color != card2.color and
",5
"# * Double Drawbridge
# ************************************************************************

",5
"    Hint_Class = CautiousDefaultHint
    Layout_Method = staticmethod(Layout.harpLayout)
    Talon_Class = WasteTalonStack
",5
"        # Create foundations
        for r in l.s.foundations:
            s.foundations.append(
                self.Foundation_Class(
                    r.x, r.y, self,
",5
"# ************************************************************************

",5
"class HiddenPassages(Game):
    Hint_Class = CautiousDefaultHint
    Layout_Method = staticmethod(Layout.klondikeLayout)
",5
"    RowStack_Class = AC_RowStack
",5
"    def createGame(self, max_rounds=2, num_deal=1, **layout):
        l, s = Layout(self), self.s
        kwdefault(layout, rows=7, waste=1, playcards=20)
",5
"        self.Layout_Method(l, **layout)
",5
"        s.waste = WasteStack(l.s.waste.x, l.s.waste.y, self)

        # Create foundations
",5
"                max_move=0, max_cards=4, base_rank=ANY_RANK))

        # Create rows
",5
"        for r in l.s.rows:
            s.rows.append(self.RowStack_Class(r.x, r.y, self,
                                              suit=ANY_SUIT,
",5
"
    def startGame(self):
        assert len(self.s.talon.cards) == 68
",5
"        for i in range(2):
",5
"            self.s.talon.dealRow(flip=0, frames=0)
        self.startDealSample()
        self.s.talon.dealRow()
        self.s.talon.dealCards()
",5
"
    #
    # Game layout
    #
",5
"        # create layout
        l, s = Layout(self), self.s

        # set window
",5
"        for i in range(2):
            s.rows.append(Merlins_ReserveStack(x, y, self))
            s.rows.append(Merlins_ReserveStack(x + l.XS, y, self))
",5
"            s.rows.append(Merlins_ReserveStack(x, y + l.YS, self))
            s.rows.append(Merlins_ReserveStack(x + l.XS, y + l.YS, self))
            x = x + l.XS * 4

",5
"        s.talon.texts.rounds = MfxCanvasText(
            self.canvas,
            x + l.CW // 2, y - l.YM,
",5
"            font=self.app.getFont(""canvas_default""))
",5
"    def getHighlightPilesStacks(self):
        return ()

    def _restoreGameHook(self, game):
",5
"        self.base_card = self.cards[game.loadinfo.base_card_id]
        for s in self.s.foundations:
            s.cap.base_rank = self.base_card.rank
",5
"
    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
",5
"        self.texts.info.config(text=t)

",5
"    def isGameWon(self):
        for s in self.s.rows:
            if s.cards and s.cards[0].suit != 4:
                return 0
",5
"    #

",5
"
        # Create foundations
        for r in l.s.foundations:
",5
"            s.foundations.append(
                self.Foundation_Class(
",5
"
",5
"                dist = (stack.cards[-1].x - cx)**2 + \
",5
"  GI.SL_BALANCED)
r(16669, TheFamiliar, 'The Familiar', GI.GT_HEXADECK, 1, 1, GI.SL_BALANCED)
",5
"r(16673, DoubleDrawbridge, 'Double Drawbridge', GI.GT_HEXADECK, 2, 1,
  GI.SL_BALANCED)
r(16674, HiddenPassages, 'Hidden Passages', GI.GT_HEXADECK, 1, 1,
  GI.SL_MOSTLY_LUCK)
",5
"  GI.SL_BALANCED)
r(16676, MerlinsMeander, 'Merlin\'s Meander', GI.GT_HEXADECK, 2, 2,
  GI.SL_BALANCED)
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"from pysollib.pysoltk import MfxCanvasText
from pysollib.stack import \
",5
"                                 suit=r.suit, base_rank=3))

        # Create row stacks
        for r in l.s.rows:
",5
"

",5
"# ************************************************************************
# * Queue
",5
"# ************************************************************************

",5
"
",5
"        yoffset = l.YOFFSET*self.BRAID_OFFSET
        h = l.YM+max(l.YS*5.5, l.YS+self.BRAID_CARDS*yoffset+2*l.TEXT_MARGIN)
        self.setSize(l.XM + l.XS * 10.5, h)

        # extra settings
",5
"                s.rows.append(Queue_RowStack(x + l.XS * (4 + x0 + j + .5), y,
                                             self))
",5
"                s.foundations.append(
                    Queue_Foundation(
                        x + l.XS * (9.5 - j * 2),
",5
"            self.canvas,
            self.width//2, h-l.TEXT_MARGIN,
            anchor=""center"",
",5
"        self.base_card = self.s.talon.getCard()
        to_stack = self.s.foundations[2 * self.base_card.rank]
        self.flipMove(self.s.talon)
        self.moveMove(1, self.s.talon, to_stack)
",5
"                ((card1.suit + 1) % 12 == card2.suit or
                 (card2.suit + 1) % 12 == card1.suit))

",5
"        return ()

    def _restoreGameHook(self, game):
        self.base_card = self.cards[game.loadinfo.base_card_id]
        for s in self.s.foundations:
",5
"            s.cap.base_suit = self.base_card.suit

    def _loadGameHook(self, p):
        self.loadinfo.addattr(base_card_id=None)    # register extra load var.
        self.loadinfo.base_card_id = p.load()
",5
"
    def _saveGameHook(self, p):
",5
"            dir = self.getFoundationDir()
",5
"                t = t + _("" Ascending"")
",5
"        self.texts.info.config(text=t)
",5
"
    def getFoundationDir(self):
        for s in self.s.foundations:
            if len(s.cards) >= 2:
",5
"

class GreaterQueue(LesserQueue):
    Hint_Class = Queue_Hint
    BRAID_CARDS = 40
",5
"class JapaneseGarden(AbstractFlowerGame):
    Hint_Class = CautiousDefaultHint
    RowStack_Class = FlowerClock_RowStack
",5
"
    #
    # Game layout
    #
",5
"
",5
"            for i in range(6):
",5
"            for i in range(self.XROWS):
                row = self.RowStack_Class(
                    x, y, self, yoffset=0, max_accept=self.MAX_MOVE,
",5
"

",5
"
class SixSages(JapaneseGarden):
    Hint_Class = CautiousDefaultHint
    XROWS = 2
    YROWS = 3
",5
"class HanafudaFourSeasons(AbstractFlowerGame):

",5
"    #
",5
"
        # Create rows
        x, y, offset = l.XM, l.YM, self.app.images.CARD_YOFFSET
        for i in range(6):
",5
"        self.setRegion(s.rows, (0, 0, 999999, 999999))

        # Create talon
",5
"        for r in self.s.rows:
",5
"            cards = r.cards
",5
"                return 0
",5
"            if not (cards[0].suit == r.id and r.isHanafudaSequence(cards)):
                return 0
        return 1
",5
"    RowStack_Class = StackWrapper(Hanafuda_SequenceStack, base_rank=NO_RANK)

    #
",5
"        # create stacks
",5
"        x, y = self.width // 2 - l.XS * 3, l.YM
",5
"                x = x + l.XS
            x, y = self.width // 2 - l.XS * 3, y + l.YS
        self.setRegion(
",5
"
    #
",5
"    # game overrides
    #
",5
"                if self.s.rows[i].cards:
                    i = i + 1
",5
"class FlowerArrangement_Hint(AbstractHint):
    def computeHints(self):
        game = self.game

        # 2)See if we can move a card to the tableaux
",5
"                        break
",5
"                    continue
                # find a stack that would accept this card
",5
"                # find a stack that would accept this card
                for t in game.s.rows:
                    if t is not r and t.acceptsCards(r, pile):
                        score = base_score + 100 * (self.K - pile[0].rank)
                        self.addHint(score, 1, r, t)
",5
"
",5
"        self.CARD_YOFFSET = yoffset

    def acceptsCards(self, from_stack, cards):
",5
"        if not self.basicAcceptsCards(from_stack, cards):
            return 0
        # check that the base card is correct
        suits = list(range(self.cap.mod, (self.cap.mod + 4)))
        if self.cards and (self.cards[0].rank == 3 and
",5
"                           self.cards[-1].suit in suits):
            return self.isHanafudaSequence([self.cards[-1], cards[0]])
        return not self.cards and cards[0].rank == 3 and cards[0].suit in suits

    def getBottomImage(self):
",5
"
    def acceptsCards(self, from_stack, cards):
        if not BasicRowStack.acceptsCards(self, from_stack, cards):
            return 0
",5
"
    #
    # game layout
    #

",5
"        th = l.YS + 3 * TABLEAU_YOFFSET
        # (set piles so that at least 2/3 of a card is visible with 10 cards)
        h = (10-1)*l.YOFFSET + l.CH*2//3
        self.setSize(10*l.XS+l.XM, l.YM + 3*th + l.YM + h)

",5
"        # create stacks
",5
"            for j in range(8):
",5
"
        # define stack-groups
        self.sg.openstacks = s.tableaux + s.rows
",5
"        self.sg.talonstacks = [s.talon]
        self.sg.dropstacks = s.tableaux + s.rows

",5
"        self.s.talon.dealRow(rows=self.s.tableaux, frames=0)
        self._startAndDealRow()
",5
"
",5
"del r
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"#
# ---------------------------------------------------------------------------

import re
",5
"from pysollib.mfxutil import Image, Struct, kwdefault
from pysollib.mygettext import _
",5
"    a = 1
    for i in range(x):
",5
"# ************************************************************************
# *
# ************************************************************************

",5
"                    # score = 10000 + r.id + t.id
                    rb = r.blockmap
                    tb = t.blockmap
",5
"                        10000 + \
",5
"class Mahjongg_Foundation(OpenStack):

    def __init__(self, x, y, game, suit=ANY_SUIT, **cap):
",5
"        # We do not accept any cards - pairs will get
        # delivered by _dropPairMove() below.
        return 0

",5
"
        cols = (3, 2, 1, 0)
        for i in cols:
            for j in range(9):
",5
"# *
# ************************************************************************

class Mahjongg_RowStack(OpenStack):
    def __init__(self, x, y, game, **cap):
",5
"        elif c.rank == 9:
            i = 27+c.suit
        else:
            i = c.suit*9+c.rank
        f = self.game.s.foundations[i]
",5
"        self.fillStack()
        other_stack.fillStack()

    #
",5
"        bind(group, ""<1>"", self.__clickEventHandler)
        bind(group, ""<3>"", self.__controlclickEventHandler)
        bind(group, ""<Control-1>"", self.__controlclickEventHandler)
        # bind(group, ""<Enter>"", self._Stack__enterEventHandler)
",5
"        # bind(group, ""<Leave>"", self._Stack__leaveEventHandler)

    def __defaultClickEventHandler(self, event, handler):
        self.game.event_handled = True  # for Game.undoHandler
        if self.game.demo:
",5
"            self.game.stopDemo(event)
        if self.game.busy:
",5
"        # print 'click:', self.id
        return self.__defaultClickEventHandler(event, self.clickHandler)

    def __controlclickEventHandler(self, event):
",5
"            # self.game.playSample(""nomove"")
            return 1
",5
"
    def cancelDrag(self, event=None):
        if event is None:
            self._stopDrag()

",5
"# ************************************************************************
# *
# ************************************************************************
",5
"    RowStack_Class = Mahjongg_RowStack
",5
"            n = t.find(L[i])
            level, height = n // 7, n % 7 + 1
            tx = t.find(L[i+1])
            ty = t.find(L[i+2])
",5
"            dx = l.XOFFSET
            dy = -l.YOFFSET
            d_x = cs.SHADOW_XOFFSET
",5
"
        # width of self.texts.info
",5
"            # stack.G = (level, tx, ty)
            stack.CARD_XOFFSET = dx
",5
"            # right blockers
",5
"
        def get_all_left(s):
            if s.blockmap.all_left is None:
                s.blockmap.all_left = {}
            for t in s.blockmap.left:
",5
"            if s.blockmap.all_right is None:
                s.blockmap.all_right = {}
",5
"            for t in s.blockmap.right:
",5
"
        # create other stacks
        for i in range(4):
            for j in range(9):
",5
"                stack = Mahjongg_Foundation(x, y, self)
                if show_removed:
                    stack.CARD_XOFFSET = dx
                    stack.CARD_YOFFSET = dy
                s.foundations.append(stack)
",5
"        l.defaultStackGroups()

",5
"    def _shuffleHook(self, cards):
        if self.app.opt.mahjongg_create_solvable == 0:
            return cards
        # try to create a solvable game
",5
"        if self.app.opt.mahjongg_create_solvable == 1:
            # easy
",5
"            return self._shuffleHook1(cards[:])
        # hard
        new_cards = self._shuffleHook2(self.s.rows, cards)
        if new_cards is None:
",5
"            # any of right blocks
            for stack in s.blockmap.right:
",5
"                    free_stacks.append(r)
            if len(free_stacks) < 2:
",5
"                return None             # try another way
",5
"            i = factorial(len(free_stacks))//2//factorial(len(free_stacks)-2)
            old_pairs = []
            for j in range(i):
                nc = new_cards[:]
                while True:
",5
"                    return nc
            return None                 # try another way

        new_cards = create_solvable(cards, [None]*len(cards))
",5
"
    def _shuffleHook2(self, rows, cards):

        start_time = time.time()
",5
"                if cards[s.id] == 1:
                    continue
",5
"                if cards[s.id] == 1:
                    continue
",5
"                        if cards[t.id] == 1:
                            continue
",5
"                        if cards[t.id] is not None:
                            # we have empty stack between two non-empty
                            return False
",5
"            for i in range(len(cards)):
                if self.cardsMatch(c1, cards[i]):
",5
"            i = factorial(len(suitable_stacks))//2 \
                // factorial(len(suitable_stacks)-2)
",5
"                if iters[0] > max_iters:
                    return None
                if time.time() - start_time > max_time:
",5
"a solvable configuration.'''),
                                 bitmap='warning')
",5
"
            self.leaveState(old_state)
",5
"
        self.stats.shuffle_moves += 1
",5
"            self.moveMove(1, talon, r, frames=0)

        self.leaveState(old_state)
",5
"        n = 12
        self.s.talon.dealRow(rows=self.s.rows[:self.NCARDS-n], frames=0)
        self.startDealSample()
        self.s.talon.dealRow(rows=self.s.rows[self.NCARDS-n:])
        assert len(self.s.talon.cards) == 0
",5
"
",5
"            return 0
        return self.cardsMatch(card1, card2)

    def getAutoStacks(self, event=None):
",5
"                    n += 1
",5
"
        if f == 0:
            f = _('No Free\nMatching\nPairs')
        else:
            f = ungettext('%d Free\nMatching\nPair',
",5
"
    #
    # Mahjongg special overrides
    #

",5
"    def getHighlightPilesStacks(self):
        # Mahjongg special: highlight all moveable tiles
        return ((self.s.rows, 1),)

",5
"    def _highlightCards(self, info, sleep=1.5, delta=(1, 1, 1, 1)):
        if not Image:
            delta = (-self._delta_x, 0, 0, -self._delta_y)
            return Game._highlightCards(self, info, sleep=sleep, delta=delta)
",5
"                                 anchor=ANCHOR_NW, group=s.group)
            if self.drag.stack and s is self.drag.stack:
",5
"        if not items:
",5
"        if sleep:
            self.sleep(sleep)
            items.reverse()
",5
"            for r in items:
                r.delete()
",5
"
    def getCardBackImage(self, deck, suit, rank):
        # We avoid screen updates caused by flipping cards - all
        # cards are face up anyway. The Talon should be invisible
        # or else the top tile of the Talon will be visible during
",5
"        if card1.suit != card2.suit:
            return 0
        if card1.suit == 3:
            if card1.rank >= 8:
                return card2.rank >= 8
",5
"    assert layout
    if not name:
        name = ""Mahjongg "" + short_name
    classname = re.sub('\\W', '', name)
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"    ""aoaaqaasaauaawaa"" +
",5
"    ""wecyebagacgakgbm"" +
    ""gaogawgbygcaibci"" +
    ""aeiamiauibwicyid"" +
    ""akcckbekagkakkbm"" +
    ""kaokaskbukcwkdyk"" +
",5
"    ""aqdaudaaeaceaeea"" +
    ""geaieakeameaoeas"" +
    ""eaweaqfaufayfaag"" +
    ""acgaegaggaigakga"" +
    ""mgaogasgawgaAgaC"" +
",5
"    ""mgCogCqgCkiCmiCo"" +
    ""i"")
",5
"r(5005, ""Art Moderne"", layout=""0acaaeaagaaiaaka"" +
    ""amaaoaauaawaaaba"" +
    ""lcapcatcavcaxcaa"" +
    ""daddaleapeaseaue"" +
    ""bxeaafacfalganga"" +
",5
"    ""haehtehvehdfhlfh"" +
    ""pfhaghsghughwghd"" +
    ""hhlhhphhaihtihvi"" +
    ""hejhljhpjhukhwkh"" +
    ""ykhdmhfmhhmhjmhl"" +
",5
"    ""mhnmhvmhxmowaoya"" +
    ""ovcoxcozcofdokdo"" +
    ""ueoweoyeoefokfom"" +
",5
"    ""gotgovgoehokhoui"" +
    ""owioyiofjokjovko"" +
    ""xkozkowmoymvgdvj"" +
    ""dvffvjfvlgvfhvjh"" +
",5
"    ""hvoocjoejogjowjo"" +
    ""yjoAjvdjvfjvxjvz"" +
",5
"    ""dcceaeebgeaieaue"" +
    ""bweayecAeaafanfa"" +
",5
"    ""ckaekbgkaikakkas"" +
    ""kaukbwkaykcAkaal"" +
    ""aolaClccmaemaima"" +
",5
"    ""naCnecobkobsoeAo"" +
    ""hobhodhofhaghCgh"" +
    ""aihCi"")
#
r(5008, ""Beatle"", layout=""0aeaagaauaawaaic"" +
",5
"    ""akcamcaocaqcasca"" +
    ""eeageaieakeameao"" +
    ""eaqeaseaueadgafg"" +
    ""ahgajgalgangapga"" +
    ""rgatgavgaeiagiai"" +
",5
"    ""omiooioqiosivbdv"" +
    ""hevjevlevnevpevr"" +
",5
"    ""evfgvhgvjgvlgvng"" +
    ""vpgvrgvhivjivliv"" +
",5
"    ""hckhcmhcohcqhcsh"" +
    ""cuhbwhaAhdeiayia"" +
    ""gjbijbkjbmjbojbq"" +
    ""jbsjbujbwjaAjack"" +
    ""aykcalailaklamla"" +
",5
"r(5013, ""Butterfly"", layout=""0dmadqaaabaebayb"" +
",5
"    ""naynaCncoohgdhwd"" +
    ""heehyehcfhgfhwfh"" +
",5
"    ""jhgjhwjhAjhekhyk"" +
    ""hglhwl"")
#
",5
"    ""ighkgohdojdoldoh"" +
    ""fojfolfohhojholh"" +
    ""oBkoFloAnvievkev"" +
    ""igvkgvBlvFmCjdCh"" +
",5
"    ""ujbwjaEjbekbgkan"" +
    ""karkbykbAkaalapl"" +
    ""aElbdmbfmbzmbBmb"" +
    ""cobeoajoaloanoap"" +
",5
"    ""gipghEghaiipihEi"" +
",5
"    ""gkbikbkkbmkbokbq"" +
    ""kbskbukbwkaemaim"" +
",5
"    ""bmaboabqabsabwab"" +
",5
"    ""cbgcbkcamcbocaqc"" +
    ""bscbwcaycaAcbCcb"" +
",5
"    ""aeaeebgebkeameaq"" +
    ""ebsebweayebCebag"" +
    ""aegbggbigbkgamga"" +
",5
"    ""qgbsgbugbwgaygbC"" +
    ""gbaiaeiagiaiiaki"" +
",5
"    ""aoeaagccgeegekgc"" +
    ""mgaogaaiccieeiek"" +
",5
"    ""wcaycaceaeeageai"" +
    ""eakebmeboeaqease"" +
    ""aueaweayeadgbfga"" +
    ""hgajgalgangapgaE"" +
    ""gayhaChaaiaciaei"" +
",5
"    ""kcjmclmcnmcrmctm"" +
",5
"#    ""ebsebyeaefagfauf"" +
#    ""awfbcgbigakgbmgb"" +
#    ""ogaqgbsgbygaehag"" +
",5
"#    ""gehuehweheghgghu"" +
#    ""ghwghbihzihbkhzk"" +
#    ""omdoododeofeoheo"" +
#    ""teoveoxeomfoofod"" +
#    ""gofgohgotgovgoxg"" +
",5
"    ""vsavecvgcvicvkcv"" +
    ""mcvocvqcvscvucvw"" +
    ""cvycChcCjcClcCnc"" +
",5
"    ""easeaweacfagfakf"" +
    ""aqfaufayfaagaega"" +
    ""igamgaogasgawgaA"" +
    ""gachaghakhaqhauh"" +
",5
"    ""dhfehjehqehuehdf"" +
    ""hhfhlfhofhsfhwfh"" +
    ""fghjghqghughdhhh"" +
    ""hhlhhohhshhwhhfi"" +
    ""hjihqihuihhjhljh"" +
",5
"    ""gowgofhojhoqhouh"" +
    ""ohioliooiosiojjo"" +
    ""qjolkookvldvodvj"" +
",5
"    ""evqevhfvlfvofvsf"" +
    ""vfgvjgvqgvhhvlhv"" +
    ""ohvshvjivqivljvo"" +
    ""j"")
",5
"    ""weaEeagfbkfbofbq"" +
",5
"    ""aemagmapmaymaAma"" +
",5
"    ""CqaEqhbbhdbhfbhz"" +
    ""bhBbhDbhbdhddhfd"" +
",5
"    ""dfhffipfhzfhBfhD"" +
    ""fhnhhphhrhipjhbl"" +
    ""hdlhflhplhzlhBlh"" +
    ""DlhbnhdnhfnhznhB"" +
    ""nhDnhbphdphfphzp"" +
",5
"    ""CcoceoeeoAeoCeoo"" +
    ""hoqhocmoemoAmoCm"" +
    ""ocooeooAooCovddv"" +
    ""BdvphvdnvBn"")
",5
"    ""apharhathavhadia"" +
    ""niaxiaakbckbekag"" +
    ""kakkbmkbokaqkauk"" +
    ""bwkbykaAkcamcgmc"" +
",5
"    ""qebseaueaweacgae"" +
    ""gaggbigckgdmgdog"" +
    ""cqgbsgaugawgayga"" +
    ""ahaAhaChaciaeiag"" +
",5
"    ""hhhjhhvhhxhhfihl"" +
    ""ihtihzihblhhlhxl"" +
    ""hDlhdmhfmhzmhBmh"" +
",5
"    ""acgafgahgakgamga"" +
",5
"    ""gaajacjaejagjakj"" +
    ""amjapjarjavjaxja"" +
    ""zjaBjaalaclaelag"" +
    ""laklamlaplarlavl"" +
    ""axlazlaBlaeoagoa"" +
",5
"    ""ioakoamoapoaroat"" +
    ""oavoaxohbbhgbhlb"" +
    ""hqbhvbhAbhadhcdh"" +
    ""fdhhdhkdhmdhpdhr"" +
",5
"    ""ygaCgachaAhaeiag"" +
    ""iaiibkibmiboibqi"" +
    ""bsiauiawiayiagkc"" +
",5
"    ""awnaEnadoafoaooa"" +
    ""qoazoaBoheahpahA"" +
    ""ahcdhedhgdhndhpd"" +
    ""hrdhydhAdhCdhdhh"" +
",5
"    ""obgoaioakoamoaoo"" +
    ""aqoasobuocwodyoo"" +
    ""jholhonhophorhvn"" +
    ""cvmhvohvnmCnh"")
",5
"r(5041, ""Glade"", layout=""0aaaacaaCaaEaaac"" +
    ""accaCcaEcahdejdc"" +
    ""ldcndbpdcrdctdev"" +
    ""daxddhfcjfblfbnf"" +
",5
"#    ""buiawiayiaekbgkb"" +
#    ""ikakkamkaokaqkbs"" +
",5
"#    ""coaeoagoaioakoam"" +
#    ""oaooaqoasoauoawo"" +
#    ""ayoklcknckpchdhh"" +
#    ""xhklmknmkpm"")
r(5044, ""Helios"", layout=""0eaadcaduaewadac"" +
",5
"    ""bccbucdwcbaeacea"" +
    ""eeaiedkedmeaoeas"" +
    ""eauebwebagacgaeg"" +
    ""aggdigdogaqgasga"" +
    ""ugbwgblhbaiaciae"" +
",5
"#    ""cacdawdaaeaeeame"" +
#    ""aueayeacfagfasfa"" +
",5
"#    ""gaugaygachaghbkh"" +
",5
"#    ""aqoasoauoawoayoh"" +
#    ""abhmbhybhadhmdhy"" +
",5
"#    ""vylCaeCyeCagCygC"" +
#    ""aiCyiCakCyk"")
r(5047, ""Inca"", layout=""0aoaaqaaibakbamb"" +
    ""asbaubawbbocbqca"" +
    ""idbkdbmdbsdbudaw"" +
",5
"    ""upawpaoqaqqhbihD"" +
    ""iCphCpj"")
r(5048, ""Inner Circle"", layout=""0aaaacaayaaAaaac"" +
",5
"    ""cemcimbkmcmmcaob"" +
    ""coceockobmocooca"" +
    ""qccqceqcmqcoqcqq"")
# r(5051, ""K for Kyodai Traditional"", layout=""0acaaeaagaaiaaka"" +
#    ""amaaoaaqaasaauaa"" +
",5
"#    ""gaggaigakgamgaog"" +
#    ""aqgasgaugawgayga"" +
#    ""ahaAhaciaeiagiai"" +
#    ""iakiamiaoiaqiasi"" +
#    ""auiawiayiaekagka"" +
",5
"    ""gcaicbocaqcdscdw"" +
    ""caycbAcdudbaeace"" +
",5
"    ""ocvAcvaevoevAeva"" +
    ""gvogvAgvaivoivAi"" +
    ""CadCodCAdCafCofC"" +
    ""AfCahCohCAh"")
",5
"    ""dfaffaAfdCfaEfba"" +
    ""hcchaehakhamhaoh"" +
    ""ashaAhdChaEhabjc"" +
    ""djafjaAjdCjaEjah"" +
    ""kajkadlbflallazl"" +
",5
"    ""iaakbekbokbwkaEk"" +
    ""aambembgmbimbkmb"" +
    ""ombqmbsmbwmbAmbC"" +
    ""maEmaaobkobwoaEo"" +
",5
"    ""jdcldasdaCdbaeaq"" +
    ""ecvfczfaDfbbgapg"" +
    ""aEhcbiceichickia"" +
    ""oicxiaFjcckcfkci"" +
    ""kclkbokcwkcykbul"" +
",5
"    ""lbklcolbslazlaBl"" +
",5
"    ""afmaxmabnadnahna"" +
    ""jnblnbnnbpnbrnat"" +
    ""navnaznaBnafoaxo"" +
    ""ombooboqbomnoono"" +
    ""qn"")
",5
"    ""AabCabacbecbicbm"" +
    ""cbqcbucbycbCcbae"" +
",5
"    ""bcebeeagebiebkeb"" +
    ""meaoebqebsebueaw"" +
    ""ebyebAebCeaegbig"" +
    ""bmgbqgbugaygbaib"" +
    ""cibeiagibiibkibm"" +
",5
"    ""kbambcmbembimbkm"" +
    ""bmmbqmbsmbumbymb"" +
    ""AmbCm"")
r(5059, ""Moth"", layout=""0baaccaceabgaana"" +
    ""apaarabyacAacCab"" +
",5
"#    ""cgecieakeameaoea"" +
#    ""qeasecueaweacgae"" +
#    ""gcggcigakgcmgaog"" +
#    ""aqgasgcugawgayga"" +
#    ""ahaAhaciaeicgiai"" +
",5
"#    ""sjisl"")
# r(5062, ""Naoki Haga Traditional"", layout=""0acaaeaagaaiaaka"" +
#    ""amaaoaaqaasaauaa"" +
#    ""waayadgcaicakcdm"" +
#    ""caocaqcascaucaee"" +
",5
"    ""eacealeateaCeaEe"" +
",5
"    ""hsfhCfhEfhahhchh"" +
",5
"    ""hqahsahlchnchghh"" +
",5
"    ""ihhkhhohhqhhshhl"" +
",5
"    ""ffchfckfcmfapfar"" +
    ""fcufawfazfcBfaah"" +
",5
"    ""cchcfhahhakhamhc"" +
    ""phcrhcuhawhazhcB"" +
",5
"#    ""lhhmhzmhjnhxnhlo"" +
#    ""hvohnphtponfppfp"" +
",5
"    ""fhughehhshiwhhyh"" +
    ""huihdjhsjhfkhxkh"" +
    ""hlhslhjmhnmhpmhl"" +
",5
"    ""lhonhouhosionnop"" +
    ""nvobvehvghvihvsh"" +
    ""vonCfh"")
r(5069, ""Scorpion"", layout=""0avaacbaebagbaib"" +
    ""aacaxcazcagdaida"" +
",5
"    ""gdbodcceceeakeam"" +
    ""ecqecsebgfbofccg"" +
",5
"    ""aGiaakackafkahka"" +
    ""kkamkapkarkaukaw"" +
",5
"    ""kazkaBkaEkaGkaam"" +
    ""acmafmahmakmamma"" +
    ""pmarmaumawmazmaB"" +
    ""maEmaGmaaoacoafo"" +
    ""ahoakoamoapoaroa"" +
",5
"#
r(5072, ""Seven Pyramids"", layout=""0aaaacaaeaagaaoa"" +
    ""aqaayaaAaaCaaEaa"" +
    ""acaccaecagcaocaq"" +
    ""caycaAcaCcaEcaae"" +
",5
"    ""oagoaooaqoayoaAo"" +
    ""aCoaEoaaqacqaeqa"" +
    ""gqaoqaqqayqaAqaC"" +
",5
"    ""hzbhBbhDbhbdhddh"" +
    ""fdhzdhBdhDdhbfhd"" +
    ""fhffhzfhBfhDfhoh"" +
    ""hqhhojhqjhblhdlh"" +
    ""flhzlhBlhDlhbnhd"" +
",5
"    ""eoeeoAeoCeopiocm"" +
    ""oemoAmoCmocooeoo"" +
    ""AooCovddvBdvdnvB"" +
    ""n"")
",5
"    ""kbvkexkbzkagmaim"" +
",5
"    ""ahfajfavfaxfazfa"" +
    ""BfaDfaahachaehag"" +
    ""haihakhamhaohaqh"" +
    ""ashauhawhayhaAha"" +
    ""ChaEhabjadjafjah"" +
",5
"#    ""hnjhdkhxkhnlhdmh"" +
#    ""xmhnnohaojaolaon"" +
#    ""aopaoraotaofbovb"" +
#    ""odcoxcobdozdoheo"" +
#    ""jeoleoneopeoreot"" +
",5
"r(5078, ""Squaring"", layout=""0caaacaceaciaaka"" +
    ""cmacqaasacuacyaa"" +
    ""AacCaaacaecaicdk"" +
",5
"    ""camcaqcaucaycdAc"" +
    ""aCccaeaceceeciea"" +
    ""kecmecqeasecuecy"" +
    ""eaAecCecahachceh"" +
",5
"    ""jaejaijamjaqjdsj"" +
    ""aujayjaCjcalaclc"" +
    ""elcilaklcmlcqlas"" +
",5
"r(5080, ""Star Ship"", layout=""0eoaaabdmbdqbaCb"" +
    ""accckccscaAcaadb"" +
    ""idbudaCdbceageco"" +
",5
"    ""akaamaaoaaqaaaca"" +
    ""ccaecagcaicakcam"" +
    ""caocaqcaaeaceaoe"" +
    ""aqeaagacgaogaqga"" +
",5
"    ""aiaciaoiaqiaakac"" +
",5
"    ""hlbhnbhpbhbdhddh"" +
    ""fdhhdhjdhldhndhp"" +
    ""dhbfhdfhnfhpfhbh"" +
",5
"    ""jhblhdlhflhhlhjl"" +
    ""hllhnlhplpccoeco"" +
",5
"    ""debbrbbBbdccbvcc"" +
    ""addcecheckecnebD"" +
    ""ecafbtfbAfdcgdjg"" +
    ""dlgbxgcahchhcnhd"" +
",5
"    ""zjaakblkbnkbpkbr"" +
    ""kbtkaEkajlavlaam"" +
    ""acmalmbnmbpmbrma"" +
",5
"#    ""oaioakoamoaooaqo"" +
#    ""asoajqhbbhdbhfbh"" +
#    ""hbhjbhlbhnbhpbhr"" +
",5
"#    ""flvhlvjlvllvnlvp"" +
#    ""lvjn"")
r(5086, ""The Door"", layout=""0amaaoaaqaeicekc"" +
    ""emceoceqcesceuca"" +
    ""gediedueaweaegag"" +
",5
"#
",5
"    ""akkamkaokaqkaska"" +
    ""ukawkaykaAkaCkaE"" +
    ""kaamacmaemagmaim"" +
    ""akmammaomaqmasma"" +
    ""umawmaymaAmaCmaE"" +
",5
"    ""maaoacoaeoagoaio"" +
    ""akoamoaooaqoasoa"" +
    ""uoawoayoaAoaCoaE"" +
",5
"    ""dhAdhlehnehgfhvf"" +
    ""hxfhoghqghjhhyhh"" +
    ""rihtihkjhmjhBjhu"" +
",5
"    ""ekaemacoabqaasaa"" +
    ""acccceeceoccqcas"" +
    ""caaecceeeeeoecqe"" +
    ""aseaagccgeegeogc"" +
    ""qgasgaaiccieeieo"" +
",5
"    ""icqiasiaakbckcek"" +
    ""egkeikekkemkcokb"" +
    ""qkaskvcdvqdwcfwq"" +
    ""fvchvqh"")
",5
"r(5092, ""Tomb"", layout=""0eaabcabeabgabia"" +
    ""bkabmaboabqaesab"" +
    ""accccceccgccicck"" +
    ""ccmccoccqcbscaae"" +
    ""dcebeeageaieakea"" +
",5
"    ""hcvjcvlcvncCgcCi"" +
    ""cCkcCmc"")
#
",5
"    ""aoaaqaasaawaayaa"" +
    ""gcaicbkccmccocbq"" +
    ""cascaucaeeagebie"" +
    ""bkecmecoebqebsea"" +
    ""ueaweacgaegbggci"" +
",5
"    ""kagmaimbkmcmmcom"" +
    ""bqmasmaumacoaeoa"" +
    ""ioakoamoaooaqoas"" +
",5
"    ""ceaAeaafaefagfai"" +
",5
"    ""brkaambcmcembgma"" +
",5
"    ""jhjjhrjhtjhvjhxj"" +
    ""hzjoccoecogcoico"" +
    ""scoucowcoycokdoq"" +
",5
"    ""cAmcCmdEmeaodcoc"" +
    ""eocgobiobkoamoao"" +
",5
"    ""nbinbknamnavnato"" +
    ""hachmchaehmehdfh"" +
    ""jfhaghmghoghdhhj"" +
    ""hhqhhaihmihoihdj"" +
",5
"    ""mhjmhnmhtmhxmhDm"" +
    ""hgphqphApogcoqco"" +
    ""Acoceokeomeoueow"" +
    ""eoEeoggoqgoAgoci"" +
",5
"    ""mmbomaioakoamoao"" +
",5
"#    ""skaukaamacmbembg"" +
#    ""mbimbkmbmmbombqm"" +
",5
"#    ""eoagoaioakoamoao"" +
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"    ""lhecaefoegaehhek"" +
    ""afcifehfgvfgifia"" +
    ""fkagahgcageaggog"" +
    ""gagihgkagmhhaahc"" +
",5
"    ""amebmgbmiamkbogo"" +
    ""ohboicqfcqhcqjas"" +
    ""ejsfasgjshasijsj"" +
    ""askCtgCtibuddufd"" +
    ""uhdujbulovdCvgCv"" +
",5
"    ""ekbemcgabgcageag"" +
    ""mdiacicbieaigeka"" +
    ""dkcckebkgakiakoh"" +
    ""lofmaemcdmecmgbm"" +
    ""iamkammamoomohno"" +
",5
"    ""ahsbascbsgasmaso"" +
    ""auaaughuhauiawih"" +
",5
"    ""wjawkowkhwlawmby"" +
    ""maAchAdaAeoAehAf"" +
",5
"    ""hCbaCc"")
r(5409, ""Rooster"", layout=""0aaaaagabchcccce"" +
    ""ccgadcvdfadiceec"" +
    ""egaeohfoageagoog"" +
    ""ohhoaiehifaigaim"" +
",5
"    ""qhbqiaqkaqmaraor"" +
    ""ahrchrmhsaascbsg"" +
    ""oshbsiaskasmasoa"" +
",5
"    ""habicbiicikcimbj"" +
",5
"    ""sgbsicskcsmbtabu"" +
",5
"    ""bwkbycbyebygbyib"" +
    ""ykbAjaCj"")
",5
"    ""ehCfaCgoCghChaCi"" +
    ""aCk"")
r(5413, ""Ox"", layout=""0aahabeabkbcgoch"" +
    ""bciaeaaecbegbeia"" +
    ""emaeohfbhfnagaag"" +
",5
"    ""ibkkakmbmecmgcmi"" +
    ""bmkaodioeaofjoga"" +
    ""ohjoiaojiokaolcq"" +
",5
"    ""mfamhomhCmhhnhvn"" +
",5
"    ""o"")

",5
"#    ""akhokiakjaklhlfh"" +
#    ""lhhljameamgomgam"" +
",5
"#    ""iomiamkhnfhnhhnj"" +
#    ""aofoofaohoohaojo"" +
",5
"#    ""ojhpfhphhpjaqeaq"" +
#    ""goqgaqioqiaqkhrf"" +
#    ""hrhhrjasdasfosga"" +
",5
"#    ""yaaycoydayeaykoy"" +
#    ""laymayohzbhzdhzl"" +
",5
"#    ""jhuoavabvhavohwa"" +
#    ""hwoaxaaxocyhbzbv"" +
#    ""zhbzncAhCAhbBcvB"" +
#    ""hbBmcChCChbDdvDh"" +
",5
"#    ""bDlbEfcEhbEj"")
# r(5503, ""Cobweb"", layout=""0aacaafhagaahoah"" +
",5
"#    ""gadihdlaeaaecaek"" +
",5
"#    ""hmevmehmgvmghmiv"" +
",5
"#    ""anhoniCnianjanlo"" +
#    ""nlCnlhobvobhoevo"" +
#    ""ehoghoivoiholvol"" +
#    ""apbopbapdopeapfa"" +
",5
"# r(5505, ""Wicker"", layout=""0bafbakbbcbbhbbm"" +
#    ""bcebcjbdbbdgbdlb"" +
#    ""edbeibenbfabffbf"" +
#    ""kbgcbghbgmbhebhj"" +
#    ""bibbigbilbjdbjib"" +
",5
"    ""cjebjhcjkajmajop"" +
    ""johkahkcokhhkmhk"" +
    ""oalaalcqlcalfhlg"" +
    ""alhvlhhlialjalmq"" +
",5
"    ""lmalohmcomhCmhhm"" +
    ""manbqncandhneanf"" +
    ""bnhvnhanjhnkanlq"" +
    ""nmannhocooeoohoo"" +
    ""khomapcppcCpdbpe"" +
",5
"    ""obycayfhygayhoyh"" +
    ""hyiayjbymozcvzho"" +
    ""zmaAbhAcvAcaAdhA"" +
    ""eaAfcAhCAhaAjhAk"" +
    ""aAlhAmvAmaAnoBcC"" +
",5
"    ""BcvBhoBmCBmaCbhC"" +
",5
"        layout=""0daadacdaedagdai"" +
",5
"    ""dskduaducduedugd"" +
    ""uidukdwadwcdwedw"" +
    ""gdwidwkdyadycdye"" +
    ""dygdyidyk"")
# r(5804, ""Rows"", name=""Double Mahjongg Rows"", ncards=288,
",5
"# layout=""0daadacCaddaeCaf"" +
#    ""dagCahdaidakdcad"" +
#    ""ckeeadeceeeeegde"" +
#    ""ieekegaegkeiadic"" +
",5
"#    ""eieeigdiieikekae"" +
#    ""kkemadmcemeemgdm"" +
#    ""iemkeoaeokeqadqc"" +
",5
"    ""oeeaegoegCegaeio"" +
",5
"    ""eaigoigCigaiioii"" +
    ""Ciiaikoikaimoima"" +
    ""iohjbhjdhjfvjfhj"" +
    ""hvjhhjjvjjhjlhjn"" +
    ""akaakcakeokeakgo"" +
",5
"    ""bhBdhBfvBfhBhvBh"" +
    ""hBjvBjhBlhBnaCaa"" +
    ""CcaCeoCeaCgoCgaC"" +
    ""ioCiaCkoCkaCmaCo"" +
    ""hDdhDfhDhhDjhDla"" +
",5
"    ""EcaEeaEgaEiaEkaE"" +
    ""m"")
r(5806, ""Roost"", name=""Double Mahjongg Roost"", ncards=288,
        layout=""0aaahabaacoachad"" +
    ""vadaaeoaehafvafa"" +
",5
"    ""aafcafehfjhflvfl"" +
    ""hfnhgchgeaghagjo"" +
    ""gkaglCglogmagnah"" +
    ""bohcahdoheahfhhi"" +
    ""hhkvhlhhmhibhidv"" +
",5
"    ""CevCeaCfoCfhCgvC"" +
",5
"    ""ddvdecdfvdgcdhCd"" +
    ""hvdicdjvdkcdldea"" +
    ""deoafdaflcgacgoa"" +
    ""hdahlciacioajdaj"" +
",5
"    ""janleoahodoofooj"" +
    ""holeooapdbpfvpfb"" +
    ""pjvpjapleqahqdoq"" +
    ""foqjhqleqoardbrf"" +
",5
"    ""dhhdhjdhldjadjcd"" +
",5
"    ""aaAcaAebAgbAibAk"" +
",5
"    ""isaitoitajahjbhj"" +
",5
"    ""hjthjvajwakcokcv"" +
",5
"    ""oaopooqaorvosaot"" +
",5
"    ""chrdhrfhrhariaro"" +
    ""hrphrrhrtaruasfo"" +
    ""sgvsihsjaskoskas"" +
    ""mosmhsnvsoosqasr"" +
    ""atdhtgathotivtkh"" +
",5
"    ""kaakeckhakjbkmbk"" +
    ""oolmambbmdamghmh"" +
",5
"    ""amiamlhmmamnondo"" +
",5
"        layout=""0eaabacbaebagbai"" +
    ""bakbameaoacaacoa"" +
    ""eaaeoagaagoaiaai"" +
    ""oakaakoamaamoaoa"" +
",5
"    ""EmeEo"")
",5
"#    ""ahaaiabaabkhcahc"" +
#    ""kadaadeadgadkhea"" +
#    ""hefhekafaafeafga"" +
#    ""fkhgahgfhgkahaah"" +
",5
"#    ""aeuagdagjaglagna"" +
#    ""gthhkhhmaieaijai"" +
#    ""loilainaishjkhjm"" +
#    ""akfakjakloklakna"" +
#    ""krhlkhlmameamgam"" +
",5
"#    ""jamlomlamnamqams"" +
",5
"#    ""qhaqjaqlaqnaqpaq"" +
#    ""saraarchrdhrtaru"" +
",5
"#    ""arwaseasgasiaska"" +
#    ""smasoasqassataht"" +
#    ""batchtdhtfithitj"" +
",5
"#    ""nawpawsaxchxdhxk"" +
#    ""hxmhxtaxuayeayha"" +
",5
"#    ""yjayloylaynaypay"" +
#    ""sazchzdhzkhzmhzt"" +
#    ""azuaAeaAgaAjaAlo"" +
#    ""AlaAnaAqaAshBkhB"" +
#    ""maCfaCjaCloClaCn"" +
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
#
",5
"from pysollib.settings import TOOLKIT
",5
"        for r in game.s.rows:
            if r.cards:
                stacks.append(r)
        # find matching tiles
        i = 0
",5
"        for r in stacks:
            for t in stacks[i+1:]:
",5
"                    # simple scoring...
                    if self.TOP_MATCHING:
                        score = 2000 - r.rown - t.rown
                    else:
",5
"
",5
"        # We do not accept any cards - pairs will get
        # delivered by _dropPairMove() below.
        return 0
",5
"
    def basicIsBlocked(self):
",5
"
class Shisen_RowStack(Mahjongg_RowStack):

    def basicIsBlocked(self):
",5
"        return 0
",5
"        game_cols = self.game.cols
        x1, y1 = self.coln+1, self.rown+1
",5
"                        elif d == 4 and dx < 0:
                            return 1
",5
"                        elif d == 2 and y > y2:
                            return 1
                        elif d == 3 and x < x2:
                            return 1
                        elif d == 4 and x > x2:
",5
"                    if direct == d:
",5
"
            if can_move(x, y, x, y+1, direct, 1, direct_chng_cnt):  # 1
                # dcc = direct == 1 and direct_chng_cnt or direct_chng_cnt+1
",5
"                # dcc = direct == 2 and direct_chng_cnt or direct_chng_cnt+1
                p = path[:]
                if direct == 2:
",5
"                    dcc = direct_chng_cnt+1
                    p.append((x, y))
                do_accepts(x, y-1, 2, dcc, p)
            if can_move(x, y, x+1, y, direct, 3, direct_chng_cnt):  # 3
",5
"        other_stack.fillStack()
",5
"        game.updateStackMove(game.s.talon, 1 | 16)            # for redo
        game.leaveState(old_state)
",5
"
    def drawArrow(self, other_stack, sleep):
        game = self.game
",5
"            cardw -= cs.SHADOW_XOFFSET
            cardh -= cs.SHADOW_YOFFSET
        coords = []
        dx = game._delta_x
",5
"        xf, yf = images._xfactor, images._yfactor
        for x, y in path:
            if x == 0:
                coords.append(6)
            elif x == game.L[0]+1:
",5
"        if arrow is not None:
",5
"            dx = l.XOFFSET
            dy = -l.YOFFSET
            d_x = cs.SHADOW_XOFFSET
",5
"                s.rows.append(stack)
                self.cols[col].append(stack)
        # from pprint import pprint
        # pprint(self.cols)

",5
"        # create other stacks
",5
"        s.talon = InitialDealTalonStack(-l.XS-self.canvas.xmargin,
",5
"
    def updateText(self):
        if self.preview > 1 or self.texts.info is None:
            return
",5
"
    def drawHintArrow(self, from_stack, to_stack, ncards, sleep):
",5
"
",5
"    NCARDS = 288
    GRAVITY = False

",5
"    L = (14, 6)
    NCARDS = 84
",5
"
def r(id, gameclass, name, rules_filename=""shisensho.html""):
    decks, ranks, trumps = comp_cardset(gameclass.NCARDS)
    gi = GameInfo(id, gameclass, name,
",5
"    registerGame(gi)
    return gi


",5
"r(11001, Shisen_14x6, ""Shisen-Sho 14x6"")
r(11002, Shisen_18x8, ""Shisen-Sho 18x8"")
r(11003, Shisen_24x12, ""Shisen-Sho 24x12"")
",5
"r(11004, Shisen_14x6_NoGravity, ""Shisen-Sho (No Gravity) 14x6"")
r(11005, Shisen_18x8_NoGravity, ""Shisen-Sho (No Gravity) 18x8"")
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"
",5
"# This layouts converted from Kyodai Mahjongg game
# http://www.kyodai.com/index.en.html
# http://files.cyna.net/layouts.zip
",5
"r(5202, ""Big Mountain"", layout=""0aaaaaqaeihfiagh"" +
    ""ogiagjhhhvhihhja"" +
    ""igoihaiiCiioijai"" +
    ""khjgvjhhjivjjhjk"" +
    ""akfokgakhCkhokia"" +
",5
"    ""ameomfamgomhCmha"" +
    ""miomjCmjamkomlam"" +
    ""mhnehngvnghnivni"" +
    ""hnkvnkhnmaodaofo"" +
    ""ofaohoohCohaojoo"" +
",5
"r(5203, ""Bridge"", layout=""0aaaaacaaeaagaai"" +
",5
"    ""hbahbchbehbghbio"" +
    ""caoccoceocgociwd"" +
",5
"    ""qdaqfoqfoqhvrahr"" +
    ""cvrchrevrehrgvrg"" +
    ""vriosbasdosdasfo"" +
    ""sfoshvtahtcvtcht"" +
    ""evtehtgvtgvtioub"" +
",5
"    ""pqlhqnarbbrdarfb"" +
",5
"    ""hctmbuobvcbvibvq"" +
    ""bxbbxjaxqhyfvyfc"" +
    ""ynazaazeozeazgoz"" +
    ""gazkazqhAdvAdwAf"" +
",5
"    ""jckhdkldlacmhdmn"" +
    ""dnbdodcohdopeqed"" +
    ""qqdsddspdtbdundv"" +
    ""adwldxbdxjdyddyh"" +
",5
"    ""idgkcgmbgoagqaia"" +
    ""bicciedigeiieikd"" +
    ""imciobiqaisakabk"" +
    ""cckedkgekiekkdkm"" +
",5
"    ""bcfbcmbdkodlodnb"" +
    ""dobecaegbemofcbg"" +
    ""abgcbghbgjagloha"" +
    ""vhbohcbiabicbijb"" +
",5
"    ""ebyfbymayohzobAc"" +
    ""aAobBjbCdoCebCfo"" +
    ""CgbCh"")
",5
"    ""ohmqonahncanehng"" +
    ""onihnkanmhnoonqv"" +
    ""oaoochoeaoghoiao"" +
",5
"    ""opehpgapiopihpko"" +
",5
"    ""pmvpoCpqvqaoqchq"" +
    ""eaqghqiaqkhqmoqo"" +
    ""vqqorahrcarehrgo"" +
    ""rihrkarmhroorqhs"" +
    ""aaschseosgvsiosk"" +
",5
"    ""ocjoclocphdahdch"" +
    ""dmhdoaeboebaedae"" +
    ""faehaejaelaenoen"" +
    ""hfahfcvfchfmvfmh"" +
",5
"    ""nhhnjjoaaobCobao"" +
    ""dCodaofCofoogaoh"" +
    ""CohooiaojCojaolC"" +
",5
"    ""oAfoAhoAjoAloApo"" +
",5
"#    ""ofaohoohaojoojao"" +
#    ""loolaonaophpchpe"" +
",5
"    ""abaabcobdabeabga"" +
    ""bjablbbnabphcahc"" +
",5
"    ""ancanebnganjanla"" +
    ""nnbnphochoiholhq"" +
    ""chqfhqihqkaraarc"" +
    ""arearjhschshhslh"" +
",5
"    ""fpugauhhvgawdawf"" +
    ""awhawjjxgdycdyea"" +
    ""ygdyidykjzgaAdaA"" +
    ""faAhaAj"")
",5
"    ""eeaegaeiaekaemae"" +
",5
"    ""oaiaoiaaicoicaie"" +
    ""oieaigoigaiioiia"" +
    ""ikoikaimoimaiooi"" +
",5
"    ""ahqhibhiihipajba"" +
",5
"    ""ckcakeckkamccmea"" +
    ""mgcmmaoecogaoico"" +
    ""ocqaaqgdqiaqkcqq"" +
",5
"    ""alkhllalmaloangb"" +
    ""nibnkanmapebpgbp"" +
    ""iapkapmbrebrgari"" +
",5
"    ""hghagivgihgjagkh"" +
",5
"    ""huoaupoviawchwda"" +
    ""wehwfawghwhawivw"" +
",5
"r(5227, ""Kyodai 18"", layout=""0daidchdcjdegdek"" +
",5
"    ""hhdhhfhhhaiaaico"" +
",5
"    ""hjhakaakcokcakeo"" +
    ""keCkeakgokgakihl"" +
    ""bhldvldhlfvlfhlh"" +
",5
"    ""fhnhaoaaocaoeooe"" +
",5
"    ""aogaoihpdhpfaqaa"" +
    ""qcaqeoqeaqgaqihr"" +
",5
"    ""sihtbhtdvtdhtfvt"" +
    ""fhthauaaucoucaue"" +
    ""oueCueaugougauih"" +
",5
"    ""aifaihaijailhjdh"" +
    ""jhhjlakcakeakgak"" +
    ""iakkakmhlchlehlg"" +
    ""hlihlkhlmambamda"" +
",5
"    ""ldvlfvlhvljamahm"" +
    ""bamcomchmdameome"" +
    ""hmfCmfamgomghmhC"" +
    ""mhamiomihmjamkom"" +
    ""khmlammvndvnfvnh"" +
",5
"    ""aqioqihqjaqkvrfv"" +
    ""rhasdhseasfosfhs"" +
    ""gCsgashoshhsiasj"" +
    ""vtgauehufaugough"" +
    ""uhauiawfhwgawhay"" +
",5
"    ""jbmacmdamgamiomi"" +
    ""amkcmnbmqhnhhnjb"" +
    ""oacoeaohaojcombo"" +
    ""qbqacqfcqicqlbqq"" +
",5
"    ""bsacsgvshcsiCsiv"" +
    ""sjcskbsqbuabuibu"" +
    ""qbvcbvobwebwibwm"" +
    ""bxgbxkbyi"")
#
",5
"    ""cjvddhdevdfhdgCd"" +
    ""gvdhhdivdjCecaee"" +
    ""oeeCeeaegoegaeio"" +
    ""eiCeiCekCfavfbof"" +
    ""chfdvfdhffvffCfg"" +
",5
"    ""hbahbcvbchbeobfv"" +
    ""bgobhhbihbkvbkhb"" +
    ""macbacdacjaclhdb"" +
    ""hddodevdfCdgvdho"" +
",5
"    ""dihdjhdlaecaekhf"" +
    ""chfeoffvfgofhhfi"" +
",5
"    ""ghxiayeayihzdhzf"" +
",5
"#    ""jojlajpvjpbkabkc"" +
#    ""hkiCkiaklvklhkpC"" +
#    ""kpolbolihllalnol"" +
#    ""pbmabmcvmiamjoml"" +
#    ""ampvmphnianlhnpo"" +
",5
"    ""dogeaghogiagjogm"" +
    ""agnhhdhhivhihhna"" +
    ""ieoifaiioiioilai"" +
",5
"    ""hnhonihnjaogooga"" +
    ""oiaokookhpfhpihp"" +
    ""laqeoqfaqioqioql"" +
",5
"    ""awjowoawphxahxih"" +
    ""xqayaoybayioypay"" +
",5
"    ""q"")
r(5240, ""Mini Traditional"", ncards=48, layout=""0aaeacdacfhdeaec"" +
    ""aeeoeeaeghfdvfeh"" +
",5
"    ""mkbmmampcocaopdq"" +
",5
"    ""gbyibykbymaypcAa"" +
    ""cAgaApdCadCgaCpe"" +
    ""EaaEp"")
",5
"    ""ncoeCoecomComvpd"" +
    ""vpfvplvpnoqcoqgo"" +
    ""qkoqohrbhrhhrjhr"" +
",5
"    ""jhBpaCaaCiaCq"")
# r(5244, ""New Layout 2"", layout=""0CabCadCafacapca"" +
#    ""hccvccacepcehcgv"" +
#    ""cgheaveaaecpeche"" +
",5
"#    ""eveeaegpegCfaCfc"" +
#    ""CfeCfgagapgahgcv"" +
",5
"#    ""aChcCheChghiavia"" +
#    ""aicpichievieaigp"" +
#    ""igakaqkahkcwkcak"" +
#    ""eqkehkgwkghmawma"" +
",5
"#    ""apsahscvscasepse"" +
#    ""hsgvsgCtaCtcCteC"" +
#    ""tghuavuaaucpuchu"" +
",5
"#    ""evueaugpugawapwa"" +
#    ""hwcvwcawepwehwgv"" +
",5
"    ""aqfbqhbqjbqlbqnh"" +
    ""qpcrbarpbsebsmct"" +
    ""abtpbudbuncwcbwj"" +
    ""bwocybbyhcyjbylb"" +
",5
"    ""bDqbEebGe"")
#
r(5249, ""Papillon"", layout=""0bagbaibakobhobj"" +
",5
"    ""djbecbeebegbeibe"" +
",5
"    ""ribsbbshbsjbspbu"" +
",5
"    ""qgcqibqkbqmaqoas"" +
    ""cbsebsgbsibskasm"" +
    ""aueaughuhauiauka"" +
",5
"    ""jodjhdlaebaedhef"" +
    ""aehoehhejaelaenh"" +
    ""fcaffhfhafjhfmag"" +
",5
"    ""haCjaClaEfaEl"")
#
",5
"r(5257, ""Roman Arena"", layout=""0CaaCacCaeCagCai"" +
    ""vbbvbdvbfvbhCcao"" +
    ""ccoceocgCcivdbhd"" +
    ""dadehdfvdhCeaoec"" +
    ""oegCeivfbhfdafeh"" +
",5
"    ""ffvfhCgaogcoggCg"" +
",5
"    ""meomgCmgCmivnbhn"" +
    ""dvndanehnfvnfvnh"" +
    ""CoaoocooeCoeoogC"" +
",5
"    ""oAgCAivBbvBdvBfv"" +
    ""BhCCaCCcCCeCCgCC"" +
    ""i"")
r(5258, ""Rugby"", layout=""0aafaahaceacgaci"" +
    ""aecaeeaegaeiaeka"" +
",5
"    ""omopdopjaqahqbaq"" +
    ""chqdaqeiqfaqgvqg"" +
",5
"    ""iqhaqihqjaqkhqla"" +
    ""qmasahsbaschsdas"" +
    ""eisfasgishasihsj"" +
    ""askhslasmauaauch"" +
",5
"    ""kaokaakehkgakhok"" +
    ""hhkjakkokkokmhkn"" +
    ""akohkphlavlaamao"" +
    ""maamchmeamfomghm"" +
",5
"    ""qghqhaqioqioqkhq"" +
",5
"    ""bdhbfhbhhbjhblhb"" +
    ""nhbpacaoccoceocg"" +
",5
"    ""ggbgiagkaiabicci"" +
    ""ecigciibikaimbka"" +
",5
"    ""hboioojbokoolbom"" +
    ""bqacqccqecqgcqic"" +
",5
"    ""kdqaaqcdqeaqgdqi"" +
",5
"    ""aqk"")
r(5265, ""Stairs 3"", layout=""0eaeeageaieakeam"" +
    ""dcfdchdcjdclcegc"" +
    ""eicekbgabghbgjbg"" +
    ""qaicaiiaioalfali"" +
",5
"    ""vjivjkajoojphkav"" +
",5
"    ""hnehnivnkanopnph"" +
    ""oavoaoodaofaohoo"" +
    ""jhopapaopaCpavpc"" +
    ""hpehpghpivpkoppa"" +
    ""pqhqavqaoqdoqfoq"" +
",5
"    ""hoqjhqparaoravrc"" +
",5
"    ""vrevrgvrivrkaroo"" +
    ""rphsahslhspataot"" +
",5
"    ""aptgatmotohubhug"" +
    ""hunavcovcavgpvga"" +
",5
"    ""fiafkafmafoafqhg"" +
    ""bhgpahaahcaheahg"" +
",5
"    ""jghjhakahkbokcak"" +
    ""ehkfokgakialchld"" +
    ""vldoleClevlfalgh"" +
    ""lhamahmbomcamehm"" +
",5
"    ""siatchtdoteatght"" +
    ""hauahuboucauehuf"" +
    ""ougauiavchvdavgh"" +
    ""vhawaaweawi"")
",5
"#
",5
"    ""cchcdacgocghchac"" +
    ""kadahdbadeodehdf"" +
    ""adiodihdjaecoech"" +
    ""edaegoeghehaekaf"" +
",5
"    ""ighihaikajahjbaj"" +
    ""epjehjfajiojihjj"" +
",5
"    ""hodaogooghohaoka"" +
",5
"    ""vkhwghwjawnawpbx"" +
    ""daxjoxkayfaymayo"" +
    ""aCdaCiaEiaFe"")
",5
"r(5271, ""Trika"", layout=""0hagaahiaiaajhak"" +
    ""abfablhceicihcma"" +
    ""ddoddodfadhvdhCd"" +
    ""iadjvdjodladnodn"" +
    ""heeieihemaffaflh"" +
",5
"    ""ggaghigiagjhgkci"" +
    ""iakgokghkhakioki"" +
    ""hkjakkokkhlfhlla"" +
    ""meomeamiammommhn"" +
    ""dhnnaocoocaogaoi"" +
",5
"    ""scoscasgasiaskas"" +
    ""oosohtdhtnaueoue"" +
    ""auiaumoumhvfhvla"" +
    ""wgowghwhawiowihw"" +
",5
"    ""jawkowkcyihAgaAh"" +
    ""iAiaAjhAkaBfaBlh"" +
    ""CeiCihCmaDdoDdoD"" +
    ""faDhvDhCDiaDjvDj"" +
",5
"    ""abgccgedggcgibgk"" +
",5
"    ""yaoydCygCykoynay"" +
    ""qhzcvzfazhvzlhzo"" +
",5
"    ""egaeiCekaemvfchf"" +
    ""evfghfivfkhfmaga"" +
    ""ogcogeoggogiogko"" +
    ""gmagohhahhcvhehh"" +
    ""gvhihhkvhmhhooia"" +
",5
"    ""CmcameCmgamiCmka"" +
    ""mmomohnavnchnevn"" +
",5
"    ""gcmicmkcmmamoaoa"" +
",5
"    ""ghejafcafihgboge"" +
    ""ogghgjahcwhfahio"" +
    ""iahiboicoieoigoi"" +
    ""ihijoikajcvjdwjf"" +
    ""vjhajiokahkbokcC"" +
",5
"    ""hhbhkbhnbhqbjdbj"" +
    ""gbjjbjmbjpbmcbme"" +
    ""bmgbmibmkbmmbmoc"" +
",5
"    ""occoicoocqbcqhcq"" +
",5
"    ""ncsbcshcsncuacuc"" +
    ""cuecugcuicukcumc"" +
    ""wbcwhcwncybcyhcy"" +
",5
"    ""ncAccAicAocCccCe"" +
",5
"    ""qqascbshosibsjas"" +
    ""obugbukewbcwfcwl"" +
    ""ewpdyeeyidymeAde"" +
    ""AnaCcaCiaCohDiaE"" +
    ""baEgaEioEiaEkaEp"" +
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"            frame, variable=self.progress_var,
            text=_('Show progress'))
",5
"        strings = [_('&Start'), _('&Play'), _('&New'), 'sep', _('&Close'), ]
        kw = KwStruct(kw,
                      strings=strings,
                      default=0,
                      )
",5
"    try:
        solver_dialog.top.wm_deiconify()
        solver_dialog.top.tkraise()
    except Exception:
",5
"
# imports
import os
",5
"        self._tooltips = []
        #
        self._row = row
        self._column = column
",5
"        self._columnspan = columnspan
",5
"        self.top_frame.grid(row=self._row, column=self._column,
                            columnspan=self._columnspan, sticky='ew')
        self.frame = ttk.Frame(self.top_frame)
        self.frame.pack(side='left', expand=True, fill='both', padx=0, pady=1)

",5
"
    #
    # public methods
",5
"        if show:
            frame.grid()
",5
"        if 'fg' in kw:
            kw['foreground'] = kw['fg']
            del kw['fg']
        label = getattr(self, name + '_label')
        label.config(**kw)
",5
"            self.top_frame.grid_forget()
        else:
            # show
            self.top_frame.grid(row=self._row, column=self._column,
                                columnspan=self._columnspan, sticky='ew')
",5
"                w.destroy()
",5
"        #
        label = self._createLabel('info', expand=True)
        label.config(padding=(8, 0))
        self._createSizegrip()
",5
"
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"from pysollib.mfxutil import KwStruct
from pysollib.mygettext import _
",5
"from .tkwidget import MfxDialog
",5
"    def __init__(self, parent, title, app, **kw):
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
        self.createBitmaps(top_frame, kw)
",5
"        self.player_var.grid(row=1, column=0, sticky='ew', padx=0, pady=5)
        #
        widget = ttk.Checkbutton(frame, variable=self.confirm_var,
                                 text=_(""Confirm quit""))
",5
"                      strings=(_(""&OK""), _(""&Cancel"")), default=0,
                      padx=10, pady=10,
                      )
        return MfxDialog.initKw(self, kw)
#!/usr/bin/env python
",5
"#
",5
"from pysollib.settings import TITLE
from pysollib.ui.tktile.menubar import MfxMenu, createToolbarMenu
from pysollib.ui.tktile.tkconst import EVENT_HANDLED
from pysollib.ui.tktile.tkutil import loadImage
from pysollib.util import IMAGE_EXTENSIONS
",5
"from pysollib.winsystems import TkSettings

from six.moves import tkinter
from six.moves import tkinter_ttk as ttk
",5
"                      sticky='nsew')
        else:
            pady, padx = TkSettings.toolbar_button_padding
            self.grid(row=self.position,
                      column=0,
",5
"
",5
"            self, parent, toolbar, toolbar_name, position)


class ToolbarSeparator(ttk.Separator):
",5
"    def __init__(self, parent, toolbar, position, **kwargs):
",5
"        kwargs['orient'] = 'vertical'
        ttk.Separator.__init__(self, parent, **kwargs)
        self.toolbar = toolbar
        self.position = position
        self.visible = False
",5
"        self.visible = True
        if orient == 'horizontal':
",5
"    def hide(self):
        if not self.visible:
",5
"        self.visible = True
        padx, pady = TkSettings.toolbar_label_padding
        if orient == 'horizontal':
            self.grid(row=0,
",5
"class PysolToolbarTk:

",5
"        self.frame = ttk.Frame(top, class_='Toolbar',
                               relief=TkSettings.toolbar_relief,
                               borderwidth=TkSettings.toolbar_borderwidth)
        #
",5
"            (n_(""Open""),     self.mOpen,      _(""Open a\nsaved game"")),
            (n_(""Save""),     self.mSave,      _(""Save game"")),
            (None,           None,            None),
            (n_(""Undo""),     self.mUndo,      _(""Undo last move"")),
",5
"                self._createButton(label, f, check=True, tooltip=t)
            else:
                self._createButton(label, f, tooltip=t)
        self.pause_button.config(variable=menubar.tkopt.pause)
",5
"        self.player_label.bind(""<1>"", self.mOptPlayerOptions)
        self.frame.bind(""<3>"", self.rightclickHandler)
        #
        self.setCompound(compound, force=True)

",5
"            widget = getattr(self, w+'_button')
            if v:
",5
"            if w.visible:
                prev_visible = w
                if not isinstance(w, ToolbarLabel):
                    last_visible = w
",5
"
    # util
    def _loadImage(self, name):
        file = os.path.join(self.dir, name)
        image = None
",5
"        return image

    def _createSeparator(self):
        position = len(self._widgets)
",5
"        # factor = 0.6
        color = '#dedede'
        factor = 0.7
        sh = Image.new(dis_im.mode, dis_im.size, color)
",5
"        return button

    def _createLabel(self, name, label=None, tooltip=None):
",5
"        if not self.side or not self.game or not self.menubar:
            return 1
",5
"                padx, pady = TkSettings.vertical_toolbar_padding
                pack_func(row=1, column=2, sticky='ns', padx=padx, pady=pady)
            # set orient
            orient = side in (1, 2) and 'horizontal' or 'vertical'
",5
"    def hide(self, resize=1):
        self.show(0, resize)

    def destroy(self):
        for w in self._tooltips:
",5
"
    def updateImages(self, dir, size):
        if dir == self.dir and size == self.size:
            return 0
        if not os.path.isdir(dir):
",5
"            data.append((name, w))
        label = self.player_label
",5
"        aspect = (400, 300)[size != 0]
        label.config(aspect=aspect)
",5
"        return 1

    def setCompound(self, compound, force=False):
        if not force and self.compound == compound:
            return False
",5
"        if self.compound == 'text':
            return 0
        size = self.size
",5
"        comp = int(self.compound in ('top', 'bottom'))
        return int((size+comp) != 0)
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"# This program is free software: you can redistribute it and/or modify
",5
"        return MfxTreeLeaf


class SelectDialogTreeLeaf(SelectDiagCommon,
",5
"                           BaseSelectDialogTreeLeaf, MfxTreeLeaf):
    pass
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
",5
"        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

        self.demo_sleep_var = tkinter.DoubleVar()
        self.demo_sleep_var.set(app.opt.timeouts['demo'])
",5
"        self.highlight_piles_sleep_var = tkinter.DoubleVar()
",5
"                                padding=(10, 5))
        lframe.pack(expand=True, fill='both', padx=4)
        row = 0
",5
"            (_('Raise card:'),          self.raise_card_sleep_var),
            (_('Highlight piles:'),     self.highlight_piles_sleep_var),
",5
"            widget.grid(row=row, column=1)
            row += 1
        #
",5
"        #
        self.demo_timeout = self.demo_sleep_var.get()
        self.hint_timeout = self.hint_sleep_var.get()
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"from .tkwidget import MfxDialog, MfxMessageDialog
from .tkwidget import PysolScale


class SoundOptionsDialog(MfxDialog):
",5
"        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
        self.createBitmaps(top_frame, kw)
        #
",5
"            ('deal',          _('Deal'),           tkinter.BooleanVar()),
            ('dealwaste',     _('Deal waste'),     tkinter.BooleanVar()),

            ('turnwaste',     _('Turn waste'),     tkinter.BooleanVar()),
",5
"            ('drop',          _('Drop'),           tkinter.BooleanVar()),
            ('droppair',      _('Drop pair'),      tkinter.BooleanVar()),
",5
"            w.grid(row=row, column=0, columnspan=2, sticky='ew')
        #
",5
"        if app.audio.CAN_PLAY_MUSIC:  # and app.startup_opt.sound_mode > 0:
            row += 1
            ttk.Label(frame, text=_('Sample volume:'), anchor='w'
                      ).grid(row=row, column=0, sticky='ew')
",5
"            w.grid(row=row, column=1, sticky='w', padx=5)

        else:
            # remove ""Apply"" button
            kw.strings[1] = None
",5
"        frame.columnconfigure(1, weight=1)
        #
        row = 0
",5
"            w = ttk.Checkbutton(frame, text=t, variable=v)
",5
"            self.app.audio.updateSettings()
",5
"
    def wmDeleteWindow(self, *event):
        return self.mDone(0)

    def mOptSoundDirectX(self, *event):
",5
"# *
# ************************************************************************
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"import os
import time

from pysollib.mfxutil import KwStruct
",5
"        self.notebook_tabs.append(single_frame._w)

",5
"        self.notebook = notebook

        focus = self.createButtons(bottom_frame, kw)
        self.tabChanged()               # configure buttons state
        self.mainloop(focus, kw.timeout)
",5
"
    def initKw(self, kw):
        kw = KwStruct(
",5
"            kw,
            strings=((_(""&Play this game""), 401),
                     ""sep"", _(""&OK""),
                     (_(""&Reset...""), 500)),
            default=0,
",5
"        )
",5
"        else:
            reset_button.config(state='disabled')

",5
"        self.createPieChart(app, won, lost, _(""Current session""))
        #

    #
",5
"        for i in (_(""Won:""),
                  _(""Lost:""),
                  _(""Total:"")):
",5
"            if len(i) > len(t):
                t = i
        t1 = font.measure(t)
        #  t1 = max(font.measure(_(""Won:"")),
        #           font.measure(_(""Lost:"")),
",5
"            plost = 1.0 - pwon
        return pwon, plost
",5
"        c = tkinter.Canvas(frame, width=w, height=h,
                           bg=bg, highlightthickness=0)
",5
"        dy //= 2
        c.create_text(x, ty[0]-dy, text=_(""Won:""),
                      anchor=""nw"", font=tfont, fill=fg)
        c.create_text(x, ty[1]-dy, text=_(""Lost:""),
                      anchor=""nw"", font=tfont, fill=fg)
",5
"        # tx = (160, 250, 280)
        # ty = (21, 41, 75)
        #
        tx, ty = self.tab_x, self.tab_y
",5
"            c.create_rectangle(x, y, x+10, y+10, fill=""#00ff00"")
",5
"            c.create_text(x0+w//2, y0+h//2, text=_(""No games""),
                          anchor=""center"", font=tfont, fill=""#bfbfbf"")
        #
        self._createChartTexts(tx, ty, won, lost)
",5
"        if self.parent_window.tree_tabs:
            self._tabs = self.parent_window.tree_tabs
            return
        tw = 20*self.w
",5
"            tw = measure(t)+8
",5
"    def createHeader(self, player, header):
        i = 0
        for column in ('#0',) + self.parent_window.COLUMNS:
            text = header[i]
            self.tree.heading(
",5
"                column, text=text,
                command=lambda par=self.parent_window, col=column:
",5
"                                  values=(t2, t3, t4, t5, t6, t7))
            self.parent_window.tree_items.append(id)
            self.parent_window.games[id] = t8

        total, played, won, lost, time_, moves, perc = self.getStatSummary()
",5
"        self.tree_items = []
",5
"        vsb = ttk.Scrollbar(frame)
        vsb.grid(row=0, column=1, sticky='ns')
        self.tree = ttk.Treeview(frame, columns=self.COLUMNS,
                                 selectmode='browse')
        self.tree.grid(row=0, column=0, sticky='nsew')
",5
"        #
        self.formatter = TreeFormatter(self.app, self.tree, self,
                                       self.dialog.heading_tkfont,
                                       self.CHAR_W, self.CHAR_H)
        self.createHeader(player)
",5
"
    def mapEvent(self, *args):
        if not self.tree_items:
",5
"            self.fillTreeview(self.player)

    def headerClick(self, column):
        if column == '#0':
",5
"        self.sort_by = sort_by
        self.fillTreeview(self.player)

    def createHeader(self, player):
",5
"        header = self.formatter.getStatHeader()
        self.formatter.createHeader(player, header)

",5
"            self.tree_items = []
        self.formatter.writeStats(player, sort_by=self.sort_by)
",5
"# ************************************************************************
",5
"    def __init__(self, parent, title, app, player, **kw):
",5
"        self.tkfont = tkinter_font.Font(parent, self.font)
        style = ttk.Style(parent)
",5
"        heading_font = style.lookup('Heading', 'font')  # treeview heading
        self.heading_tkfont = tkinter_font.Font(parent, heading_font)
        self.font_metrics = self.tkfont.metrics()
",5
"            if indx == 0:               # ""Full log""
                button = 203
",5
"
",5
"FullLog_StatsDialog = SessionLog_StatsDialog = LogDialog
",5
"    def createHeader(self, player):
",5
"        w1 = (_(""Highlight piles: "") + str(stats.highlight_piles) + ""\n"" +
              _(""Highlight cards: "") + str(stats.highlight_cards) + ""\n"" +
              _(""Highlight same rank: "") +
",5
"        if game.s.talon:
            if game.gameinfo.redeals != 0:
                w2 = w2 + _(""\nRedeals: "") + str(game.s.talon.round - 1)
            w2 = w2 + _(""\nCards in Talon: "") + str(len(game.s.talon.cards))
        if game.s.waste and game.s.waste not in game.s.foundations:
",5
"            w2 = w2 + _(""\nCards in Foundations: "") + str(n)
        #
",5
"            ""\n"" +
            w1 + w2,
            strings=((_(""&Statistics...""), 101),
                     'sep',
",5
"class _TopDialog(MfxDialog):
    def __init__(self, parent, title, app, gameid, top, **kw):
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
",5
"        cnf['text'] = _('Game number')
        label = ttk.Label(**cnf)
        label.grid(row=0, column=2, sticky='ew')
        cnf['text'] = _('Started at')
        label = ttk.Label(**cnf)
",5
"        label.grid(row=0, column=3, sticky='ew')
        cnf['text'] = _('Result')
        label = ttk.Label(**cnf)
",5
"            label = ttk.Label(**cnf)
            label.grid(row=row, column=0, sticky='ew')
            if gameid == 'all':
                name = app.getGameTitleName(i.gameid)
                if name is None:
",5
"                    name = _(""** UNKNOWN %d **"") % i.gameid
                cnf['text'] = name
                label = ttk.Label(**cnf)
                label.grid(row=row, column=1, sticky='ew')
            # Game number
",5
"            cnf['text'] = '#'+str(i.game_number)
            label = ttk.Label(**cnf)
",5
"        self.dialog = dialog

        left_label = ttk.Label(self, image=app.gimages.logos[5])
        left_label.pack(side='left', expand=True, fill='both')

",5
"        frame = ttk.LabelFrame(self, text=_('All games'),
                               padding=(10, 5, 10, 10))
        frame.pack(side='top', expand=True, fill='x', padx=10, pady=10)
",5
"            ttk.Label(frame, text=str(min)
                      ).grid(row=row, column=1, padx=5, pady=5)
            ttk.Label(frame, text=str(max)
                      ).grid(row=row, column=2, padx=5, pady=5)
            ttk.Label(frame, text=str(avr)
",5
"                      ).grid(row=row, column=3, padx=5, pady=5)
            # ttk.Label(frame, text=str(tot)).grid(row=row, column=4)

            def command(gameid=gameid, top=top):
",5
"                self.showTop(gameid, top)
            b = ttk.Button(frame, text=TOP_TITLE+' ...',
                           width=10, command=command)
            b.grid(row=row, column=5)
",5
"
",5
"        self.app = app
",5
"            parent.winfo_screenheight() < 600
        if cond:
",5
"        canvas.pack(side='left', padx=5)

        # right frame
        right_frame = ttk.Frame(frame)
        right_frame.pack(side='left', fill='x', padx=5)
",5
"                            command=self.updateGraph)
",5
"            ('week',  _('Last 7 days')),
",5
"            b.pack(fill='x', expand=True, padx=3, pady=1)
        label_frame = ttk.LabelFrame(right_frame, text=_('Show graphs'))
",5
"        self.won_graph_var.set(True)
        b = ttk.Checkbutton(label_frame, text=_('Won'),
                            command=self.updateGraph,
",5
"                            variable=self.won_graph_var)
        b.pack(fill='x', expand=True, padx=3, pady=1)
",5
"        #
        tw = max(measure(_('Games/day')),
",5
"        canvas.create_line(x1, y0, x1, y1, width=3)
        canvas.create_text(x1+4, y1-4, anchor='s', text=_('% won'))

        # caption
        d = self.text_height
",5
"            t = _('Games/day')
",5
"        # draw result
        games_resolution = float(dy)/games_delta
        percent_resolution = float(dy)/20
",5
"        percent_coords = []
        x = x0+graph_dx
        for res in result:
",5
"            id = canvas.create_line(fill=self.played_color, width=3,
                                    *played_coords)
",5
"            self.items.append(id)
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"
",5
"        self.home = home
        self.url = None
        self.history = Struct(
            list=[],
            index=0,
",5
"        self.closeButton.grid(row=0, column=3, sticky='e')
",5
"        self.initBindings()


# ************************************************************************
# *
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"from pysollib.util import CARDSET

",5
"# * - create menubar
# * - update menubar
# * - menu actions
",5
"    #

    def mOptTheme(self, *event):
        theme = self.tkopt.theme.get()
",5
"        self.app.opt.tile_theme = theme
        self._calc_MfxMessageDialog()(
            self.top, title=_(""Change theme""),
            text=_(""""""\
These settings will take effect
",5
"        submenu = MfxMenu(menu, label=n_(""Set t&heme""))
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"#
# ---------------------------------------------------------------------------

import os

",5
"

class MfxTreeBaseNode:
    def __init__(self, tree, parent_node, text, key):
        self.tree = tree
",5
"        # state
",5
"        self.selected = 0
        self.subnodes = None
        # canvas item ids
        self.symbol_id = None
        self.text_id = None
",5
"        self.symbol_id = -1
        self.drawSymbol(topleftx, toplefty)
        linestart = style.distx + style.width + 5
        self.text_id = -1
        self.drawText(x + linestart, y)
",5
"            #   and has some other re-display annoyances
            # print 'style.font:', style.font
            self.text_id = canvas.create_text(x+1, y, text=self.text,
                                              anchor=""w"", justify=""left"",
",5
"            self.tree.nodes[self.text_id] = self
        #
",5
"            except tkinter.TclError:
                pass
        elif self.selected:
            b = canvas.bbox(self.text_id)
            self.textrect_id = canvas.create_rectangle(
",5
"
",5
"            # draw node
            lx, ly, nx, ny = node.draw(nx, ny, lx, ly)
",5
"            style = self.tree.style
            childx = nx + style.distx + style.width // 2
",5
"        if color is None:
            if self.expanded:
",5
"            self.height = 16        # height of symbol
            self.originx = 0
            self.originy = 0
",5
"    #
    # draw nodes
    #

",5
"    def draw(self):
        nx, ny = self.style.originx, self.style.originy
        # Account for initial offsets, see topleft[xy] in BaseNode.draw().
        # We do this so that our bounding box always starts at (0,0)
        # and the yscrollincrement works nicely.
",5
"        # set scroll region
        bbox = self.canvas.bbox(""all"")
",5
"        # self.canvas.config(scrollregion=bbox)
        # self.canvas.config(scrollregion=(0,0,bbox[2],bbox[3]))
",5
"        pass

    def doubleClick(self, event=None):
        # Overload this if you want to know when a node is d-clicked on.
        self.singleClick(event)
",5
"            if node.selected and node not in l2:
                node.selected = 0
                node.updateSymbol()
",5
"        # note: best results if height is a multiple of style.disty
        MfxTreeInCanvas.__init__(self, parent, nodes, height=25*18)
        self.draw()

    def addNode(self, list, node, filename, text):
",5
"        for filename in filenames:
            self.addNode(contents, node, os.path.join(dir, filename), filename)
        # print ""gotten""
        return contents
",5
"        node = self.findNode(event)
        if not node:
            return
        print(""Clicked node %s %s"" % (node.text, node.key))
",5
"        return ""break""


if __name__ == ""__main__"":
    tk = tkinter.Tk()
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"
# ************************************************************************
# *
# ************************************************************************
",5
"        # print init_font
        kw = self.initKw(kw)
        MfxDialog.__init__(self, parent, title, kw.resizable, kw.default)
        top_frame, bottom_frame = self.createFrames(kw)
        self.createBitmaps(top_frame, kw)
",5
"            if len(init_font) > 2:
                if init_font[2] in ['bold', 'normal']:
                    self.font_weight = init_font[2]
",5
"
        sc = PysolScale(frame, from_=6, to=40, resolution=1,
                        label=_('Size:'), orient='horizontal',
                        command=self.fontupdate, variable=self.size_var)
",5
"        sc.grid(row=4, column=0, columnspan=2, sticky='news')
",5
"            if font.lower() == self.font_family.lower():
                selected = n
                break
",5
"        if self.list_box.curselection():
            self.font_family = self.list_box.get(self.list_box.curselection())
        self.font_weight = self.weight_var.get() and 'bold' or 'normal'
        self.font_slant = self.slant_var.get() and 'italic' or 'roman'
        self.font_size = self.size_var.get()
",5
"        self.entry.configure(font=(self.font_family, self.font_size,
                                   self.font_slant, self.font_weight))

    def initKw(self, kw):
        kw = KwStruct(kw,
",5
"                      strings=(_(""&OK""), _(""&Cancel"")),
                      default=0,
                      )
",5
"
",5
"
class FontsDialog(MfxDialog):
    def __init__(self, parent, title, app, **kw):
        kw = self.initKw(kw)
",5
"                          ('canvas_small',   _('Tableau small: ')),
                          ):
            font = app.opt.fonts[fn]
            self.fonts[fn] = font
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(_('&OK'), _('&Cancel')),
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"from .selecttree import SelectDialogTreeCanvas
",5
"# ************************************************************************

class SelectTileLeaf(SelectDialogTreeLeaf):
    pass

",5
"                node = SelectTileLeaf(
                    self.tree, self, text=obj.name, key=obj.index)
                contents.append(node)
        return contents or self.tree.data.no_contents

",5
"            SelectTileNode(None, _(""Solid Colors""), (
                SelectTileLeaf(None, None, _(""Blue""), key=""#0082df""),
                SelectTileLeaf(None, None, _(""Green""), key=""#008200""),
",5
"                None, _(""All Backgrounds""),
                lambda tile: 1, expanded=e2),
        )
",5
"# ************************************************************************

class SelectTileDialogWithPreview(MfxDialog):
",5
"        self.table_color = app.opt.colors['table']
        if self.TreeDataHolder_Class.data is None:
            self.TreeDataHolder_Class.data = self.TreeData_Class(manager, key)
        #
",5
"        else:
            w1, w2 = 200, 300
        font = app.getFont(""default"")
",5
"                             padx=padx, pady=pady)
",5
"        self.tree.updateNodesWithTree(self.tree.rootnodes, None)
",5
"        self.tree.destroy()
",5
"        self.preview.unbind_all()
        MfxDialog.destroy(self)
",5
"        kw = KwStruct(kw,
                      strings=((_(""&Solid color...""), 10),
",5
"        if button == 0:        # ""OK"" or double click
            if isinstance(self.tree.selection_key, six.string_types):
                self.key = str(self.tree.selection_key)
            else:
                self.key = self.tree.selection_key
",5
"            self.preview_key = key
            self.table_color = key
",5
"from pysollib.ui.tktile.tkutil import makeToplevel, setTransient
",5
"            self.f1.pack(side='left', ipadx=8, ipady=4)
",5
"            self.progress.pack(side='left', expand=True, fill='x')
            self.f2 = ttk.Label(self.frame, image=images[1])
            self.f2.pack(side='left', ipadx=8, ipady=4)
",5
"        else:
            self.progress.pack(expand=True, fill='x')
        self.frame.pack(expand=True, fill='both')
",5
"        self.top.destroy()
        self.top = None
",5
"# ************************************************************************


",5
"        self.parent = parent
        self.progress = PysolProgressBar(
            None, parent, title=""Progress"", color=""#008200"")
        self.progress.pack(ipadx=10, ipady=10)
",5
"            return
        self.progress.update(step=1)
        self.progress.frame.after(30, self.update)


",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"
class MfxDialog:  # ex. _ToplevelDialog
    img = {}
    button_img = {}
",5
"        self.parent = parent
        self.status = 0
        self.button = default
        self.timer = None
",5
"
    def mainloop(self, focus=None, timeout=0, transient=True):
        bind(self.top, ""<Escape>"", self.mCancel)
        bind(self.top, '<Alt-Key>', self.altKeyEvent)  # for accelerators
        if focus is not None:
",5
"                self.top.grab_set()
            except tkinter.TclError:
",5
"
    def destroy(self):
",5
"        self.status = 1
        raise SystemExit

    def mTimeout(self, *event):
        self.status = 2
",5
"                widget = self.accel_keys.get(key)
        if widget is not None:
",5
"            widget.event_generate('<<Invoke>>')

    def initKw(self, kw):
",5
"                      bitmap_padx=10, bitmap_pady=20,
                      image=None, image_side=""left"",
                      image_padx=10, image_pady=20,
",5
"        if kw.bitmap:  # in (""error"", ""info"", ""question"", ""warning"")
            img = self.img.get(kw.bitmap)
            b = ttk.Label(frame, image=img)
            b.pack(side=kw.bitmap_side,
                   padx=kw.bitmap_padx, pady=kw.bitmap_pady)
",5
"            if s:
                s = s.replace('&', '')
",5
"        else:
",5
"                button = int(s[1])
",5
"                xbutton += 1
                button = xbutton
",5
"        frame.columnconfigure(sep_column, weight=1)
        return focus

",5
"        msg = ttk.Label(top_frame, text=kw.text, justify=kw.justify,
                        width=kw.width)
        msg.pack(fill='both', expand=True, padx=kw.padx, pady=kw.pady)
        #
",5
"    def __init__(self, parent, ex, title=""Error"", **kw):
        kw = KwStruct(kw, bitmap=""error"")
",5
"        text = kw.get(""text"", """")
        if not text.endswith(""\n""):
            text = text + ""\n""
",5
"        MfxMessageDialog.__init__(self, parent, title, **kw.getKw())


# ************************************************************************
# *
",5
"        openURL(self._url)


# ************************************************************************
",5
"        if label:
            label = ttk.Label(top_frame, text=label, takefocus=0)
            label.pack(pady=5)
        w = kw.get(""e_width"", 0)    # width in characters
        self.var = ttk.Entry(top_frame, exportselection=1, width=w)
",5
"# ************************************************************************
",5
"        self.widget = widget
        self.text = None
        self.timer = None
        self.cancel_timer = None
",5
"        self.bindings.append(self.widget.bind(""<Leave>"", self._leave))
        self.bindings.append(self.widget.bind(""<ButtonPress>"", self._leave))
",5
"        # user overrideable settings
        self.timeout = 800                    # milliseconds
        self.cancel_timeout = 5000
        self.leave_timeout = 400
        self.relief = 'solid'
",5
"
",5
"        self.cancel_timer = None
        if time.time() - MfxTooltip.last_leave_time < self.leave_timeout/1000.:
            self._showTip()
        else:
",5
"            self.timer = after(self.widget, self.timeout, self._showTip)
",5
"            self.label.destroy()
            destruct(self.label)
            self.label = None
",5
"            destruct(self.tooltip)
            self.tooltip = None
            MfxTooltip.last_leave_time = time.time()

",5
"    def _showTip(self):
        self.timer = None
        if self.tooltip or not self.text:
            return
        #  if isinstance(self.widget, (ttk.Button, ttk.Checkbutton)):
",5
"        self.frame.pack(**kw)

    def grid(self, **kw):
        self.frame.grid(**kw)

",5
"    #
",5
"            if (i == app.tabletile_index and
                    tile.color == app.opt.colors['table']):
                return False
",5
"            return False

        if i == 0:
            self.canvas.config(bg=tile.color)
",5
"            # app.top.config(bg=tile.color)
        else:
            self.canvas.config(bg=app.top_bg)
",5
"    def unbind_all(self):
        unbind_destroy(self.hbar)
        unbind_destroy(self.vbar)
        unbind_destroy(self.canvas)
",5
"        self.hbar.grid_remove()

",5
"
    def _setVbar(self, first, last):
        if self.canvas.busy:
            return
        sb = self.vbar
",5
"        if self.hbar_show:
",5
"            self.canvas.xview(*args)
",5
"        return self._yview('scroll', -5, 'unit')

",5
"
",5
"            self.frame = frame
",5
"            label.pack()
            self.label = label
            self.id = self.canvas.create_window(x, y, window=frame, anchor='n')
",5
"
# ************************************************************************
# * ttk.Scale workaround (label and resolution)
# ************************************************************************
",5
"class MyPysolScale:
    def __init__(self, parent, **kw):
        if 'resolution' in kw:
",5
"            command = kw['command']
        kw['command'] = self._scale_command
        if 'label' in kw:
            self.label_text = kw['label']
            width = len(self.label_text)+4
",5
"        self.label.pack(side=side, expand=False, fill='x')
        self.scale = ttk.Scale(self.frame, **kw)
        self.scale.pack(side=side, expand=True, fill='both', pady=4)

",5
"
    def _round(self, value):
        return int(round(float(value)/self.resolution))*self.resolution

",5
"
    def pack(self, **kw):
        self.frame.pack(**kw)
",5
"
# ************************************************************************
# * ttk.Combobox workaround (clear selection)
",5
"
from .tkwidget import MfxDialog

",5
"class BaseTileMfxDialog(MfxDialog):
    def _calcToolkit(self):
        return ttk
",5
"        notebook = ttk.Notebook(frame)
",5
"
        focus = self.createButtons(bottom_frame, kw)
        self.mainloop(focus, kw.timeout)

    def presetSelected(self, e, w):
",5
"            if w.widget in ('menu', 'preset', 'entry'):
                v = _(v)
            w.variable.set(v)

",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
",5
"#
# This program is distributed in the hope that it will be useful,
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# You should have received a copy of the GNU General Public License
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"from pysollib.ui.tktile.tkcanvas import MfxCanvasImage
from pysollib.ui.tktile.tkutil import loadImage
",5
"from six.moves import tkinter_ttk as ttk

from .selecttree import SelectDialogTreeCanvas
from .selecttree import SelectDialogTreeLeaf, SelectDialogTreeNode
from .tkwidget import MfxDialog, MfxScrolledCanvas, PysolScale
",5
"# * Nodes
# ************************************************************************

class SelectCardsetLeaf(SelectDialogTreeLeaf):
    pass
",5
"

class SelectCardsetNode(SelectDialogTreeNode):
    def _getContents(self):
",5
"    def __init__(self, manager, key):
        SelectDialogTreeData.__init__(self)
        self.all_objects = manager.getAllSortedByName()
",5
"                    None, _(""Uncategorized""), lambda cs: not cs.si.styles))
            select_by_style = SelectCardsetNode(
                None, _(""by Style""), tuple(nodes))
        #
",5
"        items.sort(key=lambda x: x[1])
        nodes = []
",5
"        for key, name in items:
",5
"            if manager.registered_nationalities.get(key):
                nodes.append(
",5
"                    lambda cs: not cs.si.nationalities))
",5
"        items.sort(key=lambda x: x[1])
        nodes = []
        for key, name in items:
            if manager.registered_dates.get(key):
",5
"            nodes.append(
                SelectCardsetNode(
",5
"                 SelectCardsetNode(
                    None, _(""Medium cardsets""),
                    lambda cs: cs.si.size == CSI.SIZE_MEDIUM),
                 SelectCardsetNode(
",5
"        #
        self.rootnodes = [_f for _f in (
",5
"
",5
"

# ************************************************************************
",5
"        # padx, pady = kw.padx, kw.pady
",5
"        padx, pady = 5, 5
",5
"                orient='horizontal', variable=var,
                value=app.opt.scale_x,
                command=self._updateScale)
            self.scale_x.grid(
",5
"                row=2, column=0, sticky='ew', padx=padx, pady=pady)
            #
            self.auto_scale = tkinter.BooleanVar()
            self.auto_scale.set(app.opt.auto_scale)
",5
"            check = ttk.Checkbutton(
                left_frame, text=_('Auto scaling'),
                variable=self.auto_scale,
                takefocus=False,
                command=self._updateAutoScale
",5
"                )
",5
"                                   padx=padx, pady=pady)
            self._updateAutoScale()
        #
",5
"        self.preview.setTile(app, app.tabletile_index, force=True)
        self.preview.pack(fill='both', expand=True, padx=padx, pady=pady)
        self.preview.canvas.preview = 1
",5
"        if USE_PIL:
            s = (_(""&Info / Settings...""), 10)
        else:
",5
"                else:
                    self.scale_values = (self.scale_x.get(),
                                         self.scale_y.get(),
                                         auto_scale,
                                         self.app.opt.preserve_aspect_ratio)
",5
"        if button == 10:                # Info
            cs = self.manager.get(self.tree.selection_key)
            if not cs:
                return
",5
"            # title = CARDSET+"" ""+cs.name
            title = CARDSET.capitalize()+"" ""+cs.name
            d = CardsetInfoDialog(self.top, title=title, cardset=cs,
",5
"            for n in names:
                f = os.path.join(cs.dir, n + cs.ext)
",5
"        i, x, y, sx, sy, dx, dy = 0, 10, 10, 0, 0, cs.CARDW + 10, cs.CARDH + 10
        if USE_PIL:
            xf = self.scale_x.get()
            yf = self.scale_y.get()
            dx = int(dx*xf)
",5
"            dy = int(dy*yf)
            self.scale_images = []
        for image in self.preview_images:
",5
"

class SelectCardsetByTypeDialogWithPreview(SelectCardsetDialogWithPreview):
    Tree_Class = SelectCardsetByTypeTree
    TreeDataHolder_Class = SelectCardsetByTypeTree
",5
"        if cardset.si.nationalities:
            nationalities = '\n'.join([CSI.NATIONALITY[i]
                                       for i in cardset.si.nationalities])
",5
"            # (_('Number of cards:'), str(cardset.ncards)),
            (_('Size:'), '%d x %d' % (cardset.CARDW, cardset.CARDH)),
                ):
",5
"                frow += 1
        if images:
            try:
                from random import choice
                im = choice(images)
",5
"                f = os.path.join(cardset.dir, cardset.backname)
                self.back_image = loadImage(file=f)  # store the image
                label = ttk.Label(info_frame, image=im, padding=5)
                label.grid(row=0, column=2, rowspan=frow+1, sticky='ne')
",5
"
        # bg = top_frame[""bg""]
        bg = 'white'
        text_w = tkinter.Text(frame, bd=1, relief=""sunken"", wrap=""word"",
",5
"        # focus = text_w
        self.mainloop(focus, kw.timeout)

",5
"    def initKw(self, kw):
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"from .selecttree import SelectDialogTreeCanvas
from .selecttree import SelectDialogTreeLeaf, SelectDialogTreeNode
from .tkwidget import MfxDialog, MfxScrolledCanvas

# ************************************************************************
",5
"# * Nodes
# ************************************************************************


",5
"    pass

",5
"
class SelectGameNode(SelectDialogTreeNode):
    def _getContents(self):
        contents = []
",5
"                    node = SelectGameLeaf(self.tree, self, name, key=gi.id)
                    contents.append(node)
        return contents or self.tree.data.no_games
",5
"# ************************************************************************

class SelectGameData(SelectDialogTreeData):
    def __init__(self, app):
",5
"        SelectDialogTreeData.__init__(self)
        self.all_games_gi = list(map(
            app.gdb.get,
",5
"        self.no_games = [SelectGameLeaf(None, None, _(""(no games)""), None), ]
        #
        s_by_type = s_oriental = s_special = s_original = s_contrib = \
            s_mahjongg = None
        g = []
",5
"            s_special = SelectGameNode(None, _(""Special Games""),
                                       tuple(g[2]))
        if g[3]:
            s_original = SelectGameNode(None, _(""Original Games""),
                                        tuple(g[3]))
",5
"            if name is None or not list(filter(
                    select_func, self.all_games_gi)):
                continue
",5
"                return gi.id in games
            if name is None or not list(filter(
                    select_func, self.all_games_gi)):
                continue
            gg.append(SelectGameNode(None, name, select_func))
",5
"            s_by_inventors = SelectGameNode(None, _(""by Inventors""),
                                            tuple(gg))
        #
        ul_alternate_names = UserList(
            list(app.gdb.getGamesTuplesSortedByAlternateName()))
",5
"                    None, _('Mostly skill'),
",5
"                    SelectGameNode(None, _(""48 cards""),
                                   lambda gi: gi.si.ncards == 48),
                    SelectGameNode(None, _(""52 cards""),
                                   lambda gi: gi.si.ncards == 52),
                    SelectGameNode(None, _(""64 cards""),
",5
"    data = None


class SelectGameTree(SelectGameTreeWithPreview):
    def singleClick(self, event=None):
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
",5
"            self.gameid = self.tree.selection_key
",5
"        right_frame = ttk.Frame(paned_window)
        paned_window.add(left_frame)
        paned_window.add(right_frame)
",5
"        # Info
        self.info_labels = {}
        for n, t, f, row in (
            ('name',        _('Name:'),             info_frame,   0),
",5
"        self.preview.canvas.preview = 2
        # create a preview of the current game
        self.preview_key = -1
",5
"            self.preview_game.endGame()
            self.preview_game.destruct()
            destruct(self.preview_game)
        self.preview_game = None
        # destruct the app
",5
"            if self.preview_app:
                destruct(self.preview_app)
            self.preview_app = None
",5
"
    def updatePreview(self, gameid, animations=10):
        if gameid == self.preview_key:
            return
",5
"            self.preview_key = -1
            return
        #
        if self.preview_app is None:
",5
"            self.preview_app = Struct(
                # variables
                audio=self.app.audio,
                canvas=canvas,
",5
"                miscrandom=self.app.miscrandom,
",5
"                opt=self.app.opt.copy(),
                startup_opt=self.app.startup_opt,
                stats=self.app.stats.new(),
                top=None,
",5
"        #
        self.preview_app.audio = None    # turn off audio for initial dealing
",5
"        self.preview_game = gi.gameclass(gi)
",5
"        self.preview_game.createPreview(self.preview_app)
        #
        random = None
",5
"            redeals = _('variable')
",5
"        else:
            percent = ""0.0""
",5
"            ('type',        type),
",5
"            if t in ('', None):
                title_label.grid_remove()
                text_label.grid_remove()
            else:
                title_label.grid()
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"

",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"# ---------------------------------------------------------------------------

import os
import traceback
",5
"
if TOOLKIT == 'tk':
    if USE_TILE:
        from six.moves import tkinter_ttk as ttk

",5
"
# ************************************************************************
# * Init root window
# ************************************************************************
",5
"
    base_init_root_window(root, app)

    # root.self.wm_maxsize(9999, 9999) # unlimited
",5
"        if os.path.exists(f):
            try:
                root.tk.evalfile(f)
",5
"            except Exception:
                traceback.print_exc()
",5
"            else:
",5
"        if color:
            root.option_add('*selectBackground', color, 60)
",5
"                app.opt.fonts['default'] = fn
                # treeview heading
",5
"    else:
        root.option_add('*Entry.background', 'white', 60)
        root.option_add('*Entry.foreground', 'black', 60)
",5
"        root.option_add('*Text.background', 'white', 60)
        root.option_add('*Text.foreground', 'black', 60)
        root.option_add('*selectForeground', 'white', 60)
",5
"        root.option_add('*selectBackground', '#0a5f89', 60)
        root.option_add('*inactiveSelectBackground', '#0a5f89', 60)  # Tk-8.5
        root.option_add('*selectBorderWidth', 0, 60)
        # root.option_add('*borderWidth', '1', 50)
        # root.option_add('*Button.borderWidth', '1', 50)
",5
"        root.option_add('*Scrollbar.borderWidth', 1, 60)
        root.option_add('*Menu.borderWidth', 1, 60)
        root.option_add('*Menu.activeBorderWidth', 1, 60)
        # root.option_add('*Button.HighlightBackground', '#595d59')
",5
"            app.opt.fonts['default'] = fn
        else:
            root.option_add('*font', 'helvetica 12', 60)
            app.opt.fonts['default'] = ('helvetica', 12,
                                        'roman', 'normal')
",5
"# ---------------------------------------------------------------------------
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
",5
"class TkSettings(BaseTkSettings):
    canvas_padding = (1, 1)
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"
def init_root_window(root, app):
    base_init_root_window(root, app)
    if TOOLKIT == 'tk':
        hideTkConsole(root)
",5
"    if TOOLKIT == 'gtk':
        pass
    elif USE_TILE:
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
#
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"import os
import traceback

from pysollib.mfxutil import print_err
from pysollib.mygettext import _
",5
"if TOOLKIT == 'tk':
    from pysollib.ui.tktile.tkutil import loadImage
    if USE_TILE:
",5
"    style = ttk.Style(top)
    try:
        style.theme_use(theme)
    except Exception:
",5
"        font_name = (fa['family'],
                     fa['size'],
",5
"    # set minsize
    sw, sh = (root.winfo_screenwidth(), root.winfo_screenheight())
    if sw < 640 or sh < 480:
        root.wm_minsize(400, 300)
",5
"    elif USE_TILE:
",5
"        pass


",5
"        toolbar_relief = 'raised'
        toolbar_button_relief = 'flat'
        toolbar_separator_relief = 'sunken'
        toolbar_borderwidth = 1
        toolbar_button_borderwidth = 1
",5
"#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------##

",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"def connect_game_solver_dialog(game):
",5
"    global solver_dialog
    solver_dialog = None


def reset_solver_dialog():
",5
"    pass
#!/usr/bin/env python
",5
"# GNU General Public License for more details.
",5
"# ---------------------------------------------------------------------------#

# imports
import os
import sys
",5
"
    def updateText(self, **kw):
        pass

",5
"# ---------------------------------------------------------------------------#

",5
"# Copyright (C) 2016-2017 LB
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# ************************************************************************
",5
"        if not self.visible:
",5
"    # from LApp import LMainWindow
",5
"        self.src = None
        if ('image' in kwargs):
            self.src = kwargs['image'].source
        self.command = None
        if ('command' in kwargs):
",5
"
    def isChecked(self):
        return self.checked
",5
"        else:
            self.allow_stretch = False
            self.checked = True
",5
"            if (self.command is not None):
                self.command()

    def on_release(self):
        pass
",5
"
# ************************************************************************
# * Note: Applications should call show/hide after constructor.
# ************************************************************************

",5
"        sep.bind(""<1>"", self.clickHandler)
        sep.bind(""<3>"", self.rightclickHandler)
        self._createLabel(""player"", label=n_('Player'),
",5
"        side = self.menubar.tkopt.toolbar.get()
        self.win.setTool(None, side)
        return False

",5
"    def getSize(self):
        return 0

    def updateText(self, **kw):
",5
"        pass

",5
"    # Lokale.
",5
"        for ext in IMAGE_EXTENSIONS:
            file = os.path.join(self.dir, name + ext)
            if os.path.isfile(file):
",5
"        return image

    def _createButton(self, label, command, check=False, tooltip=None):
",5
"        name = label.lower()
",5
"        image = self._loadImage(name)
        # position = len(self._widgets)
        button_relief = TkSettings.toolbar_button_relief
",5
"            kw['indicatoron'] = False
            kw['selectcolor'] = ''

            button = MyCheckButton(**kw)
",5
"    def _busy(self):
        # if not self.side or not self.game or not self.menubar:
",5
"# the Free Software Foundation, either version 3 of the License, or
",5
"class SelectDialogTreeLeaf(MfxTreeLeaf):
    def drawSymbol(self, x, y, **kw):
        pass
        '''
",5
"class SelectDialogTreeNode(MfxTreeNode):
    def __init__(self, tree, text, select_func, expanded=0, parent_node=None):
",5
"class SelectDialogTreeCanvas(MfxTreeInCanvas):
    def __init__(self, dialog, parent, key, default,
",5
"#
# This program is distributed in the hope that it will be useful,
",5
"#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# GNU General Public License for more details.
",5
"# Toolkit imports
",5
"# from pysollib.mfxutil import format_time
# from pysollib.mfxutil import kwdefault, KwStruct
# from pysollib.mygettext import _, n_
# from pysollib.pysoltk import MfxScrolledCanvas
",5
"            bcolor = kw['outline']
        if (not bcolor or len(bcolor) < 7):
",5
"            self.radius = kw['radius']

        self.fcolor = (0.9, 0.1, 0.3, 0.5)
",5
"
",5
"        print('SingleGame_StatsDialog: p=%s, g=%s, kw=%s' %
              (player, gameid, kw))
        if isinstance(kw, KwStruct):
            print('kw=%s' % kw.getKw())

",5
"        #
        # createChart = self.create3DBarChart
",5
"        self.font = self.app.getFont(""default"")
#        self.tk_font = tkFont.Font(self.top, self.font)
#        self.font_metrics = self.tk_font.metrics()
        self._calc_tabs()

",5
"
        #
        won, lost = app.stats.getStats(player, gameid)
",5
"
        text1 = _('Total:\n' +
",5
"                  '   won: %(won)s ... %(percentwon)s%%\n' +
",5
"                  '   lost: %(lost)s ... %(percentlost)s%%\n\n') % dict(
            won=won, percentwon=int(round(100.0 * pwon)),
",5
"#        createChart(app, won, lost, _(""Total""))
        won, lost = app.stats.getSessionStats(player, gameid)
        pwon, plost = self._getPwon(won, lost)
",5
"            lost=lost, percentlost=int(round(100.0 * plost)))
        # text2 = 'Current Session:\n   won=%s, lost=%s\n' % (won, lost)

#        createChart(app, won, lost, _(""Current session""))

",5
"
",5
"    def _getPwon(self, won, lost):
        pwon, plost = 0.0, 0.0
        if won + lost > 0:
",5
"                      anchor=""nw"", font=tfont, fill=fg)
        x = tx[1] - 16
        c.create_text(x, ty[0] - dy, text=""%d"" %
                      won, anchor=""ne"", font=tfont, fill=fg)
        c.create_text(x, ty[1] - dy, text=""%d"" %
",5
"        return MfxDialog.initKw(self, kw)

# ************************************************************************
",5
"    pass
",5
"# *
# ************************************************************************

",5
"

class Top_StatsDialog(MfxDialog):
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
# This program is free software: you can redistribute it and/or modify
",5
"# This program is distributed in the hope that it will be useful,
",5
"#
# ---------------------------------------------------------------------------#

import formatter
import os
",5
"
",5
"# ************************************************************************


if get_platform() == 'android':
",5
"        # prepare activity
",5
"        # PythonActivity.mActivity is the instance of the current Activity
",5
"        self.viewer = viewer
",5
"        else:
            font = ('helvetica', 12)
            fixed = ('courier', 12)
",5
"        size = font[1]
",5
"            ""h5"": (font[0], size + 2 * sign, ""bold""),
            ""h6"": (font[0], size + 1 * sign, ""bold""),
            ""bold"": (font[0], size, ""bold""),
            ""italic"": (font[0], size, ""italic""),
            ""pre"": fixed,
",5
"        # print('writer: anchor_bgn %s - %s' % (href, name))
        if href:
",5
"
            url = self.anchor[0]
            fg = '0000cc'
            u = self.viewer.normurl(url, with_protocol=False)
            if u in self.viewer.visited_urls:
",5
"        # print('writer: anchor_end')
        if self.anchor:

            self.anchor = None
",5
"    def anchor_leave(self, *args):
        self.viewer.statusbar.updateText(url='')
        self.text.config(cursor=self.viewer.defcursor)

",5
"    def new_font(self, font):
",5
"            # print ""end_font(%s)"" % `self.font`
            self.text.tag_add(self.font, self.font_mark, ""insert"")
",5
"            # print ""start_font(%s)"" % `font`
            self.font_mark = self.text.index(""insert"")
            if font[0] in self.fontmap:
                self.font = font[0]
",5
"                self.font = ""italic""
            else:
",5
"                self.font = None

    def new_margin(self, margin, level):
        # print('writer: new_margin %s, %s' % (margin, level))
        self.indent = ""    "" * level
",5
"        self.write('\n')
",5
"
    def send_hor_rule(self, *args):
        if (args):
",5
"    def send_flowing_data(self, data):
",5
"            self.anchor = None
        self.formatter.writer.anchor_end()
",5
"class HTMLLabel(Label):
    def __init__(self, **kw):
        super(HTMLLabel, self).__init__(**kw)

",5
"        self.tags = {}
        self.textbuffer = ''
        self.add_widget(self.label)

    def applyBuffer(self):
",5
"    def config(self, **kw):
        # print('config: %s' % kw)
        pass
",5
"        # print('index: %s' % cmd)
        # was sollen wir hier zuruckgeben ?
",5
"
    def make_pop_command(self, parent, title):
",5
"        return pop_command
",5
"        self.updateHistoryXYView()
        return self.display(value)

    def __init__(self, parent, app=None, home=None):
",5
"        self.url = None
",5
"        '''
        buttonline.add_widget(self.homeButton)
        buttonline.add_widget(self.backButton)
        buttonline.add_widget(self.forwardButton)
",5
"        self.backButton = Tkinter.Button(parent, text=_(""Back""),
                                         width=button_width,
",5
"                                         command=self.goBack)
        self.backButton.grid(row=0, column=1, sticky='w')
        self.forwardButton = Tkinter.Button(parent, text=_(""Forward""),
                                            width=button_width,
                                            command=self.goForward)
",5
"        vbar.pack(side='right', fill='y')
        self.text = Tkinter.Text(text_frame,
",5
"        self.text[""yscrollcommand""] = vbar.set
        vbar[""command""] = self.text.yview
        '''

",5
"    def page_up(self, *event):
        return self._yview('scroll', -1, 'page')

    def page_down(self, *event):
",5
"                    url = os.path.join(h2, h1, t1)
",5
"                if os.name == 'nt':
                    url = url.replace('\\', '/')
",5
"            # self.app.game._cancelDrag()
            # pass
",5
"        url = self.basejoin(url, relpath=relpath)

",5
"                file, url = self.openfile(url)
            data = file.read()
            file.close()
            file = None
        except Exception:
",5
"            self.addHistory(self.url, xview=xview, yview=yview)

        # print self.history.index, self.history.list
",5
"            self.backButton.config(state=""disabled"")
        if self.history.index < len(self.history.list):
            self.forwardButton.config(state=""normal"")
",5
"        else:
            self.forwardButton.config(state=""disabled"")
",5
"
",5
"        writer = tkHTMLWriter(self.text, self, self.app)
        fmt = formatter.AbstractFormatter(writer)
        parser = tkHTMLParser(fmt)
        parser.feed(data)
",5
"        parser.close()
        self.text.config(state=""disabled"")
",5
"            self.visited_urls.append(url)
        if self.history.index > 0:
            u, xv, yv = self.history.list[self.history.index - 1]
            if cmp2(u, url) == 0:
                self.updateHistoryXYView()
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------#
#
# Copyright (C) 2017 LB
#
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"from __future__ import division
",5
"
import logging
import math
import traceback
",5
"
from kivy.animation import Animation
from kivy.app import App
from kivy.base import EventLoop
from kivy.base import stopTouchApp
",5
"    Config.set('input', 'mouse', 'mouse,multitouch_on_demand')
",5
"    return platform

# =============================================================================
",5
"
",5
"    so = None
",5
"# =============================================================================
# kivy EventDispatcher passes keywords, that to not correspond to properties
# to the base classes. Finally they will reach 'object'. With python3 (but not
# python2) 'object' throws an exception 'takes no parameters' in that a
",5
"
class LPopCommander(LBase):
    def __init__(self, **kw):
",5
"    def makeAnimStart(self, anim, spos, widget):
        def animStart(dt):
            widget.pos = spos
            # print('LAnimationMgr: animStart = %s ... %s' % (anim, dt))
",5
"
    def checkRunning(self):
        return len(self.animations) > 0

",5
"    def create(self, spos, widget, **kw):
",5
"            # setup first animation for widget
            self.animations.append(anim)
            self.widgets[widget] = [anim]
            Clock.schedule_once(self.makeAnimStart(
                anim, spos, widget), timedelay)
",5
"
LSoundLoader = SoundLoader

# =============================================================================

",5
"
",5
"        return self.size[1]

# =============================================================================


",5
"    def __init__(self, **kwargs):
        super(LImage, self).__init__(**kwargs)
",5
"        self.size = self.texture.size
",5
"
    def getWidth(self):
",5
"        return self.size[0]
",5
"
        # print('LImage: touch_down on %s' % str(touch.pos))
        if self.collide_point(*touch.pos):
",5
"    # print ('MfxCanvas: anchor=%s' % (anchor))
    x = pos[0]
    y = pos[1]
    xa = 0
",5
"        xa = 1
",5
"
",5
"        self.label = MyLabel(**kwargs)
        self.label.texture_update()
        self.coreSize = self.label.texture_size
",5
"        color = LColorToKivy(self.prnt._text_color)
        # print('LText: color = %s' % str(color))
        self.canvas.clear()
        with self.canvas:
",5
"            Color(color[0], color[1], color[2], color[3])
            Rectangle(texture=self.label.texture, pos=pos, size=size)

# =============================================================================

",5
"
# =============================================================================


class LLine(Widget, LBase):
",5
"
        lwidth = 10
",5
"            pts = args[0]
            ipts = iter(pts)
",5
"            for x, y in zip(ipts, ipts):
                print('%s.%s' % (x, y))
                self.corePoly.append(x)
                self.corePoly.append(y)
                if x < xmin:
",5
"            self.fill = fill
            if ('arrowshape' in kw):
",5
"                self.corePoly.append(y)
                if x < xmin:
                    xmin = x
",5
"        self.pos = self.corePos
",5
"    def updateCanvas(self, instance, value):
        # size = self.size
",5
"        # pos = self.pos

        # Linie:
        poly = None
",5
"            # x = self.ashape[0]
            # y = self.ashape[1]
            o = self.ashape[2]
",5
"            Color(self.bcolor[0], self.bcolor[1],
                  self.bcolor[2], self.bcolor[3])
            Line(points=poly, width=wpoly, cap='none', joint='bevel')
            if (len(atrio) > 2):
",5
"class LRectangle(Widget, LBase):
    def __init__(self, prnt, args, **kw):
        super(LRectangle, self).__init__(**kw)
        self.prnt = prnt
",5
"            bcolor = kw['outline']
",5
"        if 'group' in kw:
            self.group = kw['group']

",5
"
        self.bind(size=self.updateCanvas)
        self.bind(pos=self.updateCanvas)

",5
"        tpos, dmy = self.prnt.CoreToKivy(self.bottomright)
",5
"            (0.0, 0.0), (self.border, self.border))
        border = brd[1]

        self.canvas.clear()
        with self.canvas:
",5
"            Color(self.fcolor[0], self.fcolor[1],
                  self.fcolor[2], self.fcolor[3])
",5
"                    ppos, psize = self.group.canvas.KivyToCore(touch.pos)
                    event = LEvent()
                    event.x = ppos[0]
                    event.y = ppos[1]
                    self.group.bindings['<ButtonRelease-1>'](event)
",5
"                    return True
",5
"                return

    def on_touch_down(self, touch):

",5
"            if self.card is None:
",5
"                return False
",5
"            if self.game is None:
                return False
",5
"            # release my grabbed touch!
            print('ungrab')
",5
"        if self.collide_point(*touch.pos):

            for c in self.children:
",5
"                                event = LEvent()
                                event.x = ppos[0]
                                event.y = ppos[1]
                                event.cardid = i
",5
"
        # print('LCardImage: touch_up on %s' % str(touch.pos))
",5
"                        touch.pos, self.size)
",5
"                    event.y = ppos[1]
                    event.cardid = i
                    stack._motionEventHandler(event)
                    return True

",5
"                if ti.is_open:
                    lastopen = ti
",5
"
        super(LTreeNode, self).__init__(markup=True, **kw)
",5
"        # self.gameview.bind(size=self.scaleFontCB)
        # nicht skalieren!
",5
"
        self.bind(on_release=self.on_released)
        self.bind(is_selected=self.onSelect)
",5
"            # self.text = '[size='+fs+'][b]'+self.title+'[/b][/size]'
            # self.text = 'o '+self.title
",5
"        else:
            self.text = self.title
            self.text = u'    ' + self.title
            # self.text = u'\u25cb  '+self.title # unicode open circle
        self.texture_update()
",5
"    def scaleFontCB(self, instance, value):
        self.scaleFont(value[1])

",5
"    def collapseChildren(self, deep=False):

        def cc(p, n):
            for c in n.nodes:
                if c.is_open:
",5
"                    cc(p, c)
                    p.toggle_node(c)

",5
"            for c in n.nodes:
                if c.is_open:
                    cc(p, c)
                    p.toggle_node(c)
",5
"        self.bind(size=self.update_rect)

    def update_rect(self, *args):
        self.rect.pos = self.pos
        self.rect.size = self.size
",5
"
    def wm_minsize(self, w, h):
        pass
",5
"

class LTopLine(ButtonBehavior, Label, LBase):

    def __init__(self, **kw):
",5
"
# =============================================================================

",5
"
class LTopLevel0(BoxLayout, LBase):
",5
"        super(LTopLevel0, self).__init__(
            orientation=""vertical"", **kw)

        # self.canvas.add(Color(0, 1, 0, 0.4))
",5
"        if ('size_hint' not in kw):
",5
"        self.add_widget(self.content)

",5
"                        ret = t.pop()
                    pass
        return ret
",5
"
",5
"
        # Letztes Menu entfernen
",5
"        for c in self.children:
            if (type(c) is LMenuItem):
",5
"            else:
                # print ('LMenu: unknown child %s' % c)
                pass
",5
"        # super(LMenuItem, self).__init__()
        self.bar = None
        self.submenu = None
        self.menu = menu
        self.menu.addItem(self)
",5
"
    def setSubMenu(self, submenu):
",5
"    def __init__(self, **kw):
",5
"        self.touch = None

    def delayReset(self, dt):
",5
"
",5
"        return ScrollView.on_touch_up(self, touch)
",5
"
    def cget(self, strg):
        return False

",5
"
        self.screenSize = (d.getWidth(), d.getHeight())
",5
"
    def winfo_screendepth(self):
        return 32
",5
"
    def option_get(self, a, b):
        return 0
",5
"    def wm_geometry(self, val):
        logging.info(""LTkBase: wm_geometry %s"" % str(val))
        pass

",5
"        except Exception:
            self.in_loop = False
            logging.info(""LTkBase: update_idletasks: exception"")

    def wm_state(self):
",5
"
",5
"        logging.info('LTkBase: mainquit')
        lapp = App.get_running_app()
",5
"            EventLoop.idle()
",5
"
",5
"
",5
"        self.add_widget(self.topLine)
        self.add_widget(self.menuArea)
        self.add_widget(self.topLine1)
",5
"
        self.workStack = LStack()
",5
"            print(' - interval is', touch.triple_tap_time)
            print(' - distance between previous is', touch.triple_tap_distance)
        '''
        # (Eventloop reentrancy check)
        if self.in_loop:
",5
"
        # (demo mode stop - nur auf spielflÃ¤che)
        if '<KeyPress>' in self.bindings:
            pgs = self.workStack.peek('playground')
            if pgs:
",5
"                pg = pgs[1]
                if pg.collide_point(*touch.pos):
                    event = LEvent()
                    event.char = True
",5
"            if ret:
                break
        return ret

",5
"            if ret:
                break

        # multitouch support
",5
"
    def setMenu(self, menu):
",5
"    def setTool(self, toolbar, pos=0):
        if (toolbar is not None):
            self.toolBar = toolbar
        self.toolBarPos = pos
",5
"        self.workContainerO.add_widget(self.workContainer)
        if self.toolBar is not None and self.toolBarPos == 4:
",5
"            self.workContainerO.add_widget(self.toolBar)
",5
"        for w in self.workStack.items:
            self.workContainer.add_widget(w[1])
",5
"        w = None
        if self.workStack.size() > 0:
            w = self.workStack.pop(key)
            self.rebuildContainer()
        return w
",5
"                    self.popWork(t[0])
                    ret = True
            if ret:
",5
"# =============================================================================


class LApp(App):
",5
"        # Config.set('input', 'multitouchscreen1', 'tuio,0.0.0.0:3333')

",5
"
    def delayedRebuild(self, dt):
        logging.info(""LApp: delayedRebuild"")
        self.mainWindow.rebuildContainer()
",5
"        def delayedRebuild(dt):
            # Clock.schedule_once(self.delayedRebuild, 0.01)
            Clock.schedule_once(self.delayedRebuild, 0.5)
        return delayedRebuild

",5
"            logging.info(""LApp: size changed %s - %s (%s)"" % (obj, val, mval))
            Clock.schedule_once(self.makeDelayedRebuild(), 0.01)
",5
"        pass

    def on_start(self):
",5
"        logging.info('mw = %s,  w = %s' % (self.mainWindow, Window))
",5
"        logging.info(""LApp: on_stop"")
        if self.startCode > 0:
            return
        # lapp: erweiterte klasse dieser (mit pysolfc app members).
        lapp = App.get_running_app()
",5
"            return
",5
"        except Exception:
            traceback.print_exc()
            pass
        logging.info(""LApp: on_pause - gamesaved"")

",5
"        so = go
        logging.info(""LApp: on_resume, Window.size=%s"" % str(Window.size))
        # ANM:
        # kivy.core.window.Window hat hier u.U. eine falsche dimension
        # und unterscheidet sich vom display (-> in get_screen_ori).
",5
"        # Eine korrektur der Parameter von Window kann hier wie skizziert
",5
"# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"
from kivy.event import EventDispatcher
",5
"from pysollib.mfxutil import Struct
from pysollib.mygettext import _
from pysollib.pysoltk import MfxMessageDialog
from pysollib.pysoltk import connect_game_find_card_dialog
",5
"

class LMenuDialog(object):
",5
"
    dialogCache = {}

    def make_pop_command(self, parent, title):
        def pop_command(event):
",5
"        window.titleline.bind(on_press=pc)
        self.parent.pushWork(title, window)
",5
"        self.window = window
        self.running = True

        if self.persist:
",5
"        tv.size_hint = 1, None
        tv.bind(minimum_height=tv.setter('height'))

        # menupunkte aufbauen.

",5
"        self.buildTree(tv, None)

        # tree in einem Scrollwindow prÃ¤sentieren.

",5
"
    def make_game_command(self, command):
        def game_command():
            command()
            self.closeWindow(0)
",5
"            LTreeNode(
                text=_(""Games""),
                command=self.make_game_command(
                    self.menubar.mSelectGameDialog)))
        rg = tv.add_node(
",5
"            LTreeNode(
                text=_(""Tools""),
                command=self.make_game_command(self.menubar.mEditMenuDialog)))
        rg = tv.add_node(
            LTreeNode(
",5
"            LTreeNode(
                text=_(""Assist""),
                command=self.make_game_command(
                    self.menubar.mAssistMenuDialog)))
        rg = tv.add_node(
",5
"            LTreeNode(text=_('Recent games')))
        # Recent Liste
        recids = self.app.opt.recent_gameid
",5
"                    rid, self.menubar._mSelectGame)
                tv.add_node(
                    LTreeNode(text=gi.name, command=command), rg)
",5
"                        LTreeNode(text=gi.name, command=command), rg)

        tv.add_node(LTreeNode(
            text=_('Load'), command=self.menubar.mOpen))
        tv.add_node(LTreeNode(
",5
"            text=_('Save'), command=self.menubar.mSaveAs))

",5
"        tv.add_node(LTreeNode(
",5
"            text=_('Quit'), command=self.menubar.mHoldAndQuit))

# ************************************************************************


",5
"
    def addCheckNode(self, tv, rg, title, auto_var, auto_com):
",5
"        command = self.make_auto_command(auto_var, auto_com)
        rg1 = tv.add_node(
            LTreeNode(text=title, command=command, variable=auto_var), rg)
",5
"        return rg1

    def buildTree(self, tv, node):
        tv.add_node(LTreeNode(
",5
"        tv.add_node(LTreeNode(
            text=_('Deal cards'), command=self.menubar.mDeal))

        self.addCheckNode(tv, None,
",5
"                          _('Pause'),
                          self.menubar.tkopt.pause,
",5
"        for i in range(9):
",5
"            label = _(""Bookmark %d"") % (i + 1)
            acc = m + ""%d"" % (i + 1)
",5
"            label=n_(""&Clear bookmarks""), command=self.mClearBookmarks)
",5
"        kw['size_hint'] = (0.2, 1)
        kw['persist'] = True
",5
"        super(GameMenuDialog, self).__init__(
            menubar, parent, title, app, **kw)

",5
"
        # tv.add_node(LTreeNode(
        #   text='All games ...',
        #   command=self.make_command(102, self.menubar.mPlayerStats)), None)
",5
"
    # -------------------------------------------
    # TBD ? - just to remember original tk code.
    '''
",5
"        menu.add_command(
",5
"    '''
    '''
",5
"        submenu.add_command(
            label=n_(""All games...""),
            command=lambda x: self.mPlayerStats(mode=102))
",5
"    def __init__(self, menubar, parent, title, app, **kw):
        kw['size_hint'] = (0.2, 1)
        kw['persist'] = True
        super(AssistMenuDialog, self).__init__(
            menubar, parent, title, app, **kw)
",5
"
",5
"        tv.add_node(LTreeNode(
            text=_('Highlight piles'), command=self.menubar.mHighlightPiles))

",5
"        # tv.add_node(LTreeNode(
        #   text='Find Card', command=self.menubar.mFindCard))
",5
"
        tv.add_node(LTreeNode(
            text=_('Demo'), command=self.menubar.mDemo))

",5
"            command=self.mStackDesk, accelerator=""F2"")
        '''
",5
"
    def buildTree(self, tv, node):

",5
"        # -------------------------------------------
        # Automatic play settings

        rg = tv.add_node(
            LTreeNode(text=_('Automatic play')))
",5
"                              self.menubar.mOptEnableHint)

            self.addCheckNode(tv, rg,
                              _('Enable shuffle'),
                              self.menubar.tkopt.shuffle,
",5
"                              self.menubar.mOptEnableHighlightCards)

            self.addCheckNode(tv, rg,
                              _('Enable highlight same rank'),
                              self.menubar.tkopt.highlight_samerank,
",5
"                              _('Highlight no matching'),
                              self.menubar.tkopt.highlight_not_matching,
                              self.menubar.mOptEnableHighlightNotMatching)

            # submenu.add_separator()
",5
"                              _('Show removed tiles (in Mahjongg games)'),
                              self.menubar.tkopt.mahjongg_show_removed,
                              self.menubar.mOptMahjonggShowRemoved)
",5
"                              self.menubar.mOptShisenShowHint)

            # submenu.add_separator()

        # -------------------------------------------
",5
"        rg = tv.add_node(
            LTreeNode(text=_('Language')))
",5
"                                  self.menubar.mOptSoundSampleVol)
                self.addRadioNode(tv, rg1,
                                  _('50%'),
                                  self.menubar.tkopt.sound_sample_volume, 50,
",5
"                self.addCheckNode(
                    tv, rg1,
                    _('auto flip'),
                    self.menubar.tkopt.sound_sample_vars[key],
                    self.make_vars_command(self.menubar.mOptSoundSample, key))
",5
"                    _('auto pilot lost'),
                    self.menubar.tkopt.sound_sample_vars[key],
",5
"                self.addCheckNode(
                    tv, rg1,
                    _('auto pilot won'),
                    self.menubar.tkopt.sound_sample_vars[key],
                    self.make_vars_command(self.menubar.mOptSoundSample, key))
",5
"                key = 'flip'
",5
"                    self.make_vars_command(self.menubar.mOptSoundSample, key))
                key = 'startdrag'
                self.addCheckNode(
",5
"
            csm = self.app.cardset_manager
            # cnt = csm.len()
",5
"                rg1 = self.addRadioNode(tv, rg,
                                        cs.name,
                                        self.menubar.tkopt.cardset, i,
                                        self.menubar.mOptCardset)
",5
"                if rg1:
                    cbs = cs.backnames
                    self.menubar.tkopt.cardbacks[i] = IntVar()
",5
"                i += 1
",5
"        rg = tv.add_node(
",5
"                self.addRadioNode(
                    tv, rg1,
                    _('Green'),
                    self.menubar.tkopt.color_vars[key], '#008200',
",5
"                self.addRadioNode(
                    tv, rg1,
",5
"                    _('Olive'),
                    self.menubar.tkopt.color_vars[key], '#868200',
                    self.menubar.mOptTableColor)
                self.addRadioNode(
                    tv, rg1,
",5
"                    _('Teal'),
                    self.menubar.tkopt.color_vars[key], '#008286',
                    self.menubar.mOptTableColor)

            rg1 = tv.add_node(
",5
"            if rg1:
                tm = self.app.tabletile_manager
                # cnt = tm.len()
                i = 1
",5
"                    if ti is None:
",5
"        if rg:
            self.addCheckNode(tv, rg,
",5
"            self.addCheckNode(tv, rg,
",5
"                              self.menubar.mOptNegativeBottom)

",5
"
            self.addCheckNode(tv, rg,
                              _('Shade filled stacks'),
                              self.menubar.tkopt.shade_filled_stacks,
                              self.menubar.mOptShadeFilledStacks)
",5
"            LTreeNode(text=_('Animations')))
        if rg:
            self.addRadioNode(tv, rg,
                              _('None'),
",5
"            self.addRadioNode(tv, rg,
",5
"        if rg:
            self.addRadioNode(tv, rg,
",5
"            # sinnlos mit touch-device:
            # self.addRadioNode(tv, rg,
",5
"
        # -------------------------------------------
        # TBD ?

",5
"            # self.addRadioNode(tv, rg,
            #   'Top',
            #   self.menubar.tkopt.toolbar, 1,
            #   self.menubar.mOptToolbar)
            # self.addRadioNode(tv, rg,
",5
"            self.addRadioNode(tv, rg,
                              _('Left'),
                              self.menubar.tkopt.toolbar, 3,
",5
"                              self.menubar.mOptToolbar)
",5
"             variable=self.tkopt.statusbar,
",5
"
        # self.addCheckNode(tv, None,
        #   'Demo logo',
        #   self.menubar.tkopt.demo_logo,
        #   self.menubar.mOptDemoLogo)
",5
"            command()
            self.closeWindow(0)
        return help_command

    def buildTree(self, tv, node):
",5
"        tv.add_node(
            LTreeNode(
",5
"                text=_('About %s...') % TITLE,
",5
"        #   command=self.makeHtmlCommand(self.menubar, ""kivy.html"")))
",5
"    def labeltoname(self, label):
        name = re.sub(r""[^0-9a-zA-Z]"", """", label).lower()
        label = _(label)
        underline = label.find('&')
",5
"            label = label.replace('&', '')
        return name, label, underline

    def add_cascade(self, cnf={}, **kw):
        self.add('cascade', cnf or kw)
",5
"                    path = str(self._w) + ""."" + name
                    self.addPath(path, self, self.n, cnf.get(""menu""))
",5
"
    def cget(self, key):
",5
"        return key

# ************************************************************************


",5
"    def __init__(self, master, **kw):
        super(MfxMenubar, self).__init__(master, **kw)
        topmenu = self.name == 'menubar'

        self.menu = LMenu(not topmenu, text=self.name)
",5
"        if topmenu:
            master.setMenu(self.menu)

# ************************************************************************
# * - create menubar
",5
"        self.progress = progress
        # create menus
",5
"        self._createMenubar()
        self.top = top

",5
"
        # set the menubar
",5
"        # self.top.config(menu=self.__menubar)

",5
"        # structure to convert menu-options to Toolkit variables
",5
"            shisen_show_hint=BooleanVar(),
            sound=BooleanVar(),
",5
"            shrink_face_down=BooleanVar(),
            toolbar=IntVar(),
            toolbar_style=StringVar(),
",5
"            toolbar_relief=StringVar(),
            toolbar_compound=StringVar(),
",5
"            helpbar=BooleanVar(),
            save_games_geometry=BooleanVar(),
            splashscreen=BooleanVar(),
            demo_logo=BooleanVar(),
            mouse_type=StringVar(),
",5
"            mouse_undo=BooleanVar(),
            negative_bottom=BooleanVar(),
            display_win_message=BooleanVar(),
            pause=BooleanVar(),
",5
"            language=StringVar(),
",5
"        )
",5
"        for k in self.app.opt.colors:
            self.tkopt.color_vars[k] = StringVar()

    def _setOptions(self):
        tkopt, opt = self.tkopt, self.app.opt
",5
"        # set state of the menu items
        tkopt.autofaceup.set(opt.autofaceup)
        tkopt.autodrop.set(opt.autodrop)
        tkopt.autodeal.set(opt.autodeal)
        tkopt.quickplay.set(opt.quickplay)
",5
"        tkopt.toolbar.set(opt.toolbar)
        tkopt.toolbar_style.set(opt.toolbar_style)
        tkopt.toolbar_relief.set(opt.toolbar_relief)
        tkopt.toolbar_compound.set(opt.toolbar_compound)
        tkopt.toolbar_size.set(opt.toolbar_size)
",5
"        # print ('MfxMenubar: _addPath %s, %s' % (path, menu))
        # y = self.yy
        if path not in self.__menupath:
            # print path, menu, index, submenu
",5
"        return ""disabled""

",5
"    def updateProgress(self):
        if self.progress:
            self.progress.update(step=1)

    #
",5
"                  text=_(""Menu""), command=self.mMainMenuDialog)

        MfxMenubar.addPath = None
",5
"        sequence = ""<"" + modifier + ""KeyPress-"" + key + "">""
        bind(self.top, sequence, func)
        if len(key) == 1 and key != key.upper():
            key = key.upper()
            sequence = ""<"" + modifier + ""KeyPress-"" + key + "">""
",5
"
    def _keyPressHandler(self, event):
        r = EVENT_PROPAGATE
        if event and self.game:
",5
"            if self.game.demo:
",5
"                # stop the demo by setting self.game.demo.keypress
                if event.char:    # ignore Ctrl/Shift/etc.
                    self.game.demo.keypress = event.char
                    r = EVENT_HANDLED
",5
"    # Select Game menu creation
    #
    '''
    def _addSelectGameMenu(self, menu):
",5
"        games = map(self.app.gdb.get, self.app.gdb.getGamesIdSortedByName())
        m = ""Ctrl-""
        if sys.platform == ""darwin"":
            m = ""Cmd-""
",5
"                continue
            if need_sep:
                menu.add_separator()
                need_sep = 0
",5
"                return
            label = c0 + ' - ' + c1
            if c0 == c1:
                label = c0
",5
"            if len(g0) + len(g1) >= self.__cb_max:
                add_menu(g0, c0, c1)
                g0 = g1
",5
"        if self._getNumGames(games, GI.SELECT_ORIENTAL_GAME_BY_TYPE) == 0:
",5
"            return
",5
"                                   GI.SELECT_SPECIAL_GAME_BY_TYPE,
",5
"            label = games[n].name[:3] + ' - ' + games[m].name[:3]

",5
"
    # Eine 'closure' in Python? - voila!
    def make_gamesetter(self, n, variable, command):
        def gamesetter(x):
            variable.set(n)
",5
"                label = gi.short_name
            else:
",5
"
            # menu.tk.call((menu._w, 'add', 'radiobutton') +
            #             menu._options({'command': command,
            #                            'variable': variable,
            #                            'columnbreak': columnbreak,
",5
"
    def mFileMenuDialog(self, *event):
        if self._cancelDrag(break_pause=False):
            return
",5
"        return EVENT_HANDLED

    def mEditMenuDialog(self, *event):
        if self._cancelDrag(break_pause=False):
",5
"            return
        self.game.setCursor(cursor=CURSOR_WATCH)
        after_idle(self.top, self.__restoreCursor)
        EditMenuDialog(self, self.top, title=_(""Tools""), app=self.app)
",5
"        if d.gameid != self.game.id:
            self.tkopt.gameid.set(d.gameid)
            self.tkopt.gameid_popular.set(d.gameid)
            self._cancelDrag()
",5
"            self.game.endGame()
            self.game.quitGame(d.gameid, random=d.random)
        return EVENT_HANDLED

    def __restoreCursor(self, *event):
",5
"            ms = ms or s
",5
"        menu.entryconfig(index, state=state(ms and x))

    def updateBackgroundImagesMenu(self):
        # LB:
        print('updateBackgroundImagesMenu - fake')
",5
"        return

        mp = self.__menupath.get("".menubar.options.cardbackground"")
",5
"        # delete all entries
        submenu = mp[2]
        submenu.delete(0, ""last"")
        # insert new cardbacks
",5
"                    hidemargin=0)
    #
    # menu updates
    #
",5
"    #
    # menu actions
",5
"    #

    DEFAULTEXTENSION = "".pso""
    # TRANSLATORS: Usually, 'PySol files'
    FILETYPES = ((_(""%s files"") % TITLE, ""*"" + DEFAULTEXTENSION),
",5
"        if gameid not in self.app.opt.favorite_gameid:
            self.app.opt.favorite_gameid.append(gameid)
            self.updateFavoriteGamesMenu()

    def mDelFavor(self, *event):
",5
"        # filename = self.game.filename
        filename = ""lastgame.pso""
        if filename:
            idir, ifile = os.path.split(os.path.normpath(filename))
        else:
",5
"            idir, ifile = """", """"
        if not idir:
            idir = self.app.dn.savegames
",5
"            return
",5
"    def mOptLanguage(self, *args):
",5
"        if self._cancelDrag(break_pause=False):
            return
",5
"            return
        self.app.opt.sound_sample_volume = self.tkopt.sound_sample_volume.get()

",5
"        ov = self.app.opt.colors['table']
        self.app.opt.colors['table'] = nv
        if ov != nv:
            self.app.top_bg = nv
            self.app.tabletile_index = 0
",5
"        self.app.opt.autofaceup = self.tkopt.autofaceup.get()
",5
"
    def mOptAutoDrop(self, *args):
        if self._cancelDrag():
",5
"            return
        self.app.opt.quickplay = self.tkopt.quickplay.get()

    def mOptEnableUndo(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"
",5
"        # self.game.updateMenus()
",5
"
    def mOptEnableHighlightNotMatching(self, *args):
        if self._cancelDrag(break_pause=False):
",5
"            return
        self.app.opt.shade_filled_stacks = self.tkopt.shade_filled_stacks.get()
",5
"        self.game.endGame(bookmark=1)
        self.game.quitGame(bookmark=1)

",5
"        if idx >= 0:
            self.app.nextgame.cardset = cs
            self._cancelDrag()
            self.game.endGame(bookmark=1)
",5
"                app=self.app, manager=self.app.cardset_manager, key=key,
",5
"        cs.updateCardback(backindex=val)
        # ANM: wir kÃ¶nnen den Background nur fÃ¼r das aktuell
        # selektierte Cardset wirklich Ã¤ndern. Nur dieses wird
        # wird in den Optionen gespeichert.
",5
"    def mOptCardback(self, *event):
        self._mOptCardback(self.tkopt.cardback.get())

    def mOptChangeCardback(self, *event):
",5
"        side = self.tkopt.statusbar.get()
        self.app.opt.statusbar = side
        resize = not self.app.opt.save_games_geometry
",5
"            return
        if not self.app.helpbar:
            return
        show = self.tkopt.helpbar.get()
",5
"        dir = self.app.getToolbarImagesDir()
        if self.app.toolbar.updateImages(dir, size):
            self.game.updateStatus(player=self.app.opt.player)
            self.top.update_idletasks()

",5
"        dir = self.app.getToolbarImagesDir()
        size = self.app.opt.toolbar_size
        if self.app.toolbar.updateImages(dir, size):
            # self.game.updateStatus(player=self.app.opt.player)
            self.top.update_idletasks()
",5
"
",5
"            self.top.update_idletasks()
",5
"        self.top.update_idletasks()
",5
"    def wizardDialog(self, edit=False):
        from pysollib.wizardutil import write_game, reset_wizard
        from wizarddialog import WizardDialog

        if edit:
",5
"                if edit:
                    gameid = write_game(self.app, game=self.game)
                else:
",5
"
",5
"            return
        self.wizardDialog(edit=True)

",5
"        self.text = text
        self.key = key
",5
"            lk.append(self)
            self.tree.keys[self.key] = lk
",5
"        if self.parent_node is None:
            return (self.text, )
        else:
            return self.parent_node.whoami() + (self.text, )

",5
"        if self.tree.nodes.get(self.text_id) is self:
            canvas.itemconfig(self.text_id, fill=fg)
        else:
            # note: I don't use Label + canvas.create_window here
            #   because it doesn't propagate events to the canvas
",5
"            #   and has some other re-display annoyances
            # print 'style.font:', style.font
            self.text_id = canvas.create_text(x + 1, y, text=self.text,
                                              anchor=""w"", justify=""left"",
                                              font=style.font,
",5
"
    def updateSymbol(self):
",5
"
",5
"            ny = self.drawChildren(childx, childy, clastx, clasty)
        return lx, ly, x, ny

",5
"    #
    #
    #
",5
"            else:
                color = ""pink""
        MfxTreeBaseNode.drawSymbol(self, x, y, color=color)


",5
"        self.selection_key = None
        self.nodes = {}
",5
"        self.keys = {}
        #
        self.style = self.Style()
        # self.style.text_normal_fg = self.canvas.cget(""insertbackground"")
        self.style.text_normal_fg = self.canvas.option_get(
",5
"            'foreground', '') or self.canvas.cget(""insertbackground"")
        self.style.text_normal_bg = bg
        #
        bind(self.canvas, ""<ButtonPress-1>"", self.singleClick)
",5
"        id = self.canvas.find_withtag('current')
        if id:
            return self.nodes.get(id[0])
",5
"    #
    # draw nodes
    #

    def draw(self):
",5
"        nx = nx - self.style.distx
        ny = ny + self.style.height / 2
        for node in self.rootnodes:
            # update tree
            node.tree = self
",5
"            # draw
            try:
                lx, ly, nx, ny = node.draw(nx, ny, None, None)
",5
"
    def clear(self):
        self.nodes = {}
        self.keys = {}
        self.canvas.delete(""all"")
",5
"        self.canvas[""cursor""] = oldcur
",5
"    #
    #

",5
"    def doubleClick(self, event=None):
        # Overload this if you want to know when a node is d-clicked on.
        self.singleClick(event)
",5
"
",5
"'''
",5
"# the Free Software Foundation, either version 3 of the License, or
",5
"#
",5
"#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------#
",5
"    '''
    global find_card_dialog
    try:
",5
"    '''


def connect_game_find_card_dialog(game):
",5
"    except:
        pass
    '''
",5
"'''
#!/usr/bin/env python
",5
"# (at your option) any later version.
",5
"#
# ---------------------------------------------------------------------------#

",5
"from pysollib.acard import AbstractCard
from pysollib.kivy.LApp import LImage
from pysollib.kivy.LApp import LImageItem
",5
"
class _HideableCard(AbstractCard):
    def hide(self, stack):
",5
"        # print ""unhide:"", self.id, self.item.coords()
        self.item.config(state=""normal"")
        self.hide_stack = None
        return 1

",5
"    # moveBy aus Basisklasse Ã¼berschreiben.
    def moveBy(self, dx, dy):
",5
"# * turn the card.
# * This makes turning cards a little bit slower, but dragging cards
# * around is noticeable faster as the total number of images is
# * reduced by half.
# ************************************************************************
",5
"        _HideableCard.__init__(self, id, deck, suit, rank, game, x=x, y=y)

",5
"        self._active_image.clear_widgets()
        self._active_image.add_widget(image)
",5
"            self.tkraise(unhide)
",5
"            self.face_up = 0
",5
"# ************************************************************************
",5
"        if self.face_up:
",5
"            if unhide:
                self._setImage(image=self._face_image)
            self.item.tkraise()
            self.face_up = 1
",5
"            self.face_up = 0
",5
"        if not self.face_up and not self.hide_stack:
            self._setImage(image=image)

",5
"# *
# * The card consists of two CanvasImages. To show the card face up,
",5
"# * the face item is placed in front of the back. To show it face
# * down, this is reversed.
# ************************************************************************
",5
"
",5
"            game.canvas, self.x, self.y,
",5
"        self.__back.addtag(self.item)

",5
"        self.__back.config(image=image)
",5
"            image=game.getCardFaceImage(deck, suit, rank), anchor=""nw"")
",5
"        self.__back.addtag(self.item)

    def showFace(self, unhide=1):
        if not self.face_up:
            self.__back.move(0, 10000)
",5
"        if jnius is None:
            return
        self.PythonActivity = jnius.autoclass(
",5
"            haveperms = haveperms and self.getPerm(perm)
        return haveperms

    # invoke the permissions dialog
    def requestPerms(self, permissions):
",5
"

def getStoragePerm():
    ap = AndroidPerms()
    return ap.getPerms(
",5
"

",5
"def requestStoragePerm():
    ap = AndroidPerms()
    # ap.requestPerms(
    #    [""android.permission.READ_EXTERNAL_STORAGE"",""android.permission.WRITE_EXTERNAL_STORAGE""])
",5
"# ---------------------------------------------------------------------------#
#
",5
"        return
",5
"
",5
"    def reset(self, percent=0):
        return
#!/usr/bin/env python
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------#
#
# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
",5
"#
# This program is free software: you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
#
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------#
# Note:
# Many classes or some methods of classes are dead code resulting from the tk
",5
"from kivy.uix.boxlayout import BoxLayout
from kivy.uix.label import Label

from pysollib.kivy.LApp import LBoxLayout
from pysollib.kivy.LApp import LImage
",5
"from pysollib.kivy.LApp import LScrollView
",5
"from pysollib.kivy.LApp import LTopLevel
from pysollib.kivy.tkcanvas import MfxCanvas
",5
"                      image=None, image_side=""left"",
",5
"        return a, b


",5
"
# ************************************************************************
# * replacement for the tk_dialog script
",5
"    def __init__(self, **kw):
        super(FLabel, self).__init__(**kw)

        self.bind(size=self.onUpdate)
",5
"
        label = FText(text=kw.text, halign='center')
        self.top.add_widget(label)

",5
"# *
# ************************************************************************


class MfxExceptionDialog(MfxMessageDialog):
",5
"        kw.text = text + t
        MfxMessageDialog.__init__(self, parent, title, **kw.getKw())


# ************************************************************************
",5
"
        self.parent = parent
        self.app = app
",5
"        if (onlyone):
            onlyone.parent.pushWork('AboutDialog', onlyone.window)
            onlyone.running = True
            return

",5
"            image = LImage(texture=kw['image'].texture)
            image.size_hint = (1, 0.8)
",5
"            al = AnchorLayout()
",5
"    def __init__(self, widget):
",5
"        self.bindings = []
        self.bindings.append(self.widget.bind(""<Enter>"", self._enter))
",5
"        self.timeout = 800                    # milliseconds
        self.cancel_timeout = 5000
        self.leave_timeout = 400
",5
"    def _enter(self, *event):
        after_cancel(self.timer)
        after_cancel(self.cancel_timer)
        self.cancel_timer = None
",5
"        timediff = time.time() - MfxTooltip.last_leave_time
        if timediff < self.leave_timeout / 1000.:
            self._showTip()
        else:
            self.timer = after(self.widget, self.timeout, self._showTip)
",5
"
    def _leave(self, *event):
",5
"        self.tooltip.wm_deiconify()
        self.cancel_timer = after(
            self.widget, self.cancel_timeout, self._leave)
        # self.tooltip.tkraise()
'''
",5
"# ************************************************************************
# Kivy implementation of MfxScrolledCanvas.
",5
"        self.vbar_show = False
        self.createCanvas(kw)
        # self.frame.grid_rowconfigure(0, weight=1)
        # self.frame.grid_columnconfigure(0, weight=1)
",5
"
    def destroy(self):
        logging.info('MfxRoot: destroy')
        self.unbind_all()
",5
"
",5
"    #
    #
    #

",5
"        print('setTile: (tile) %s, index=%s' % (tile, i))

        if tile is None or tile.error:
            return False
",5
"        print(
            'MfxScrolledCanvas: tile.color, app.top_bg %s, %s'
            % (tile.color, app.top_bg))
        if i == 0:
            if force:
",5
"    #
",5
"    #

    def deleteAllItems(self):
        logging.info('MfxRoot: deleteAllItems')
        # self.parent.getWork()
",5
"        # self.parent.popWork()
        # self.frame.clear_widgets()
        self.canvas.clear_widgets()
",5
"        # self.canvas.pack(expand=True, fill='both')

    def createHbar(self):
        pass
        '''
",5
"    def _setHbar(self, first, last):
        if self.canvas.busy:
            return
",5
"        sb = self.hbar
        if float(first) <= 0 and float(last) >= 1:
            sb.grid_remove()
            self.hbar_show = False
        else:
",5
"                sb.grid()
                self.vbar_show = True
        sb.set(first, last)

",5
"        if self.vbar_show:
            self.canvas.yview(*args)
        return 'break'

    def page_up(self, *event):
",5
"    def page_down(self, *event):
        return self._yview('scroll', 1, 'page')

    def unit_up(self, *event):
        return self._yview('scroll', -1, 'unit')
",5
"    def scroll_top(self, *event):
",5
"# PySol imports
",5
"# ---------------------------------------------------------------------------#

# Toolkit imports
",5
"
",5
"    def destroy(self):
        pass

",5
"        pass

",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
",5
"# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
",5
"# * Dialog
",5
"# ************************************************************************
# not used with kivy. dummy def.


",5
"
    def __init__(self, parent, title, app, manager, key=None, **kw):
        if key is None:
            key = 1
",5
"                  width=600, height=400,
                  )
        return MfxDialog.initKw(self, kw)

    def createInfo(self):
",5
"#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
",5
"    (Tkinter.TOP,    n_('Text below icons')),
    (Tkinter.LEFT,   n_('Text beside icons')),
    ('text',         n_('Text only')),
    )
'''
",5
"# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
",5
"from __future__ import division

import logging
",5
"
",5
"def setTransient(window, parent, relx=None, rely=None, expose=1):
    # Make an existing toplevel window transient for a parent.
    #
    # The window must exist but should not yet have been placed; in
    # other words, this should be called after creating all the
",5
"    return


",5
"def makeToplevel(parent, title=None):
    print('tkutil: makeTopLevel')

    # Create a Toplevel window.
",5
"    # window = LTopLevelPopup(parent, title)
",5
"    return window.content

",5
"
def make_help_toplevel(app, title=None):
",5
"    # logging.info('tkutil: bind  %s %s %s %s '
    #              % (widget, sequence, func, add))

    # logging.info('tkutil: bind canvas = ' % str(widget.canvas))
",5
"        #              % (sequence, widget, func, add))
        widget.bindings[sequence] = func
    else:
        # logging.info('tkutil: bind failed %s %s' % (sequence, widget))
        pass
",5
"    if (sequence == '<KeyPress-Right>'):
        return
",5
"    if (sequence == '<Shift-1>'):
        return
    if (sequence == '<Double-1>'):
",5
"        return
",5
"    if (sequence == '<Unmap>'):
",5
"        return
    if (sequence == '<Configure>'):
        return
",5
"
",5
"

",5
"        # print('makeImage: source = %s' % file)
        # if (file=='/home/lb/PRG/Python/Kivy/pysolfc/data/images/redeal.gif'):
        #    y = self.yy
",5
"    else:
        assert data is not None
        kw[""texture""] = data
        # ob das geht ?? - kommt das vor ?
",5
"        # yy = self.yy
    '''
    if 'source' in kw:
        logging.info (""makeImage: "" + kw[""source""])
    if 'texture' in kw:
",5
"    return LImage(**kw)


loadImage = makeImage

",5
"
def copyImage(image, x, y, width, height):
",5
"    # return Image(source=image.source)
    # return Image(texture=image.texture)
",5
"    # logging.info(""fillImage: t=%s, f=%s o=%s, w=%s"" %
    #              (texture, fill, outline, owidth))
",5
"    height = texture.height

    ox = round(owidth)
",5
"    ow = int(ox)  # muss int sein!
",5
"        if (fill[0] == '#'):
            fill = fill[1:]
        fi0 = int(fill[0:2], 16)
        fi1 = int(fill[2:4], 16)
",5
"        fi2 = int(fill[4:6], 16)
        fi3 = 255
        if len(fill) >= 8:
            fi3 = int(fill[6:8], 16)
",5
"        f = (fi0, fi1, fi2, fi3) * width
        f = (f, ) * height
        assert len(f) == height
        f = sum(f, ())
",5
"        ou3 = 255
        if len(outline) >= 8:
            ou3 = int(outline[6:8], 16)

        l1 = (
",5
"    fillTexture(texture, fill, outline, outwidth)
    image = LImage(texture=texture)
    # logging.info(""createImage: LImage create %s"" % image)
    return image

",5
"    return None
    # Kivy nicht benÃ¶tigt. aber - was tut das ?
",5
"        col = 0
    if (color == 'white'):
        col = 255

    g = texture.pixels
",5
"
",5
"    mask = Texture.create(size=texture.size, colorfmt='rgba')
    mask.blit_buffer(arr, colorfmt='rgba', bufferfmt='ubyte')
",5
"    return mask
",5
"    ag = array('B', g)
    gw, gh = texture.size

    # print('size:',width,height)
",5
"    # print('texture size:',gw,gh)

    bb = array('B', [0 for x in range(width * height * 4)])
    # print ('bb length: ',len(bb))
    # print ('gg length: ',gw*gh*4)
",5
"
",5
"
",5
"    th = 1                              # thickness
",5
"# Copyright (C) 2005-2009 Skomoroh
# Copyright (C) 2017 LB
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
",5
"        xa = 1
    elif anchor == ""ne"":
",5
"    xa = 0
    ya = 0
",5
"        x = x + size[0] / 2.0
    elif xa == 1:
        x = x + size[0]
",5
"
    def addtag(self, tag, option=""withtag""):
        # logging.info('MfxCanvasGroup: addtag(%s, %s)' % (tag, option))
        # self.canvas.addtag(tag, option, self.id)
",5
"        self.canvas = canvas
        self.animation = None

        ed = kwargs['image']
        size = ed.size
",5
"                image = LImage(texture=ed.texture)
                image.size = [ed.getWidth(), ed.getHeight()]
",5
"        pass

    def tkraise(self, aboveThis=None):
",5
"
    def addtag(self, tag):
        # print('MfxCanvasImage: addtag %s' % tag)
        self.group = tag
",5
"        if (self.image):
            self.image.group = tag
        pass

    def dtag(self, tag):
",5
"            # print('MfxCanvasImage: animStart')
            image = self.image
",5
"
    def makeAnimEnd(self, dpos, dsize):
        def animEnd(anim, widget):
",5
"            image.pos, image.size = self.canvas.CoreToKivy(dpos, dsize)
            pass
        return animEnd

    def animatedMove(self, dx, dy, duration=0.2):
",5
"
",5
"
        self.canvas = canvas
        line = LLine(canvas, args, **kwargs)
",5
"
    def delete(self):
",5
"        self.canvas = canvas
        self.rect = rect
        self.widget = rect
",5
"
    def delete(self):
        # print('MfxCanvasRectangle: delete()')
        self.canvas.clear_widgets([self.rect])
",5
"    def delete_deferred(self, seconds):
        # self.canvas.canvas.ask_update()
        # print ('MfxCanvasRectangle: delete_deferred(%s)' % seconds)
        Clock.schedule_once(
",5
"        print(
            'MfxCanvasText: %s | %s, %s, %s | %s'
",5
"        # super(MfxCanvas, self).__init__(**kw)
        super(MfxCanvas, self).__init__()
",5
"        print('MfxCanvas: wmain = %s' % self.wmain)

        # Tkinter.Canvas.__init__(self, *args, **kw)
        self.preview = 0
",5
"        # KÃ¶nnte z.B. Ã¼ber Doppelklick umgeschaltet werden. (Die
",5
"        newscale = self.scalefactor()
",5
"
        for c in self.children:
            if not hasattr(c, 'corePos'):
                continue
",5
"            bsiz = c.coreSize
",5
"                Rectangle(pos=self.pos, size=self.size))
",5
"                    self.canvas.before.add(
",5
"                        Rectangle(texture=texture, pos=tpos, size=tsize))

    def setBackgroundImage(self, event=None):

",5
"    def winfo_height(self):
",5
"        print('MfxCanvas: xview')
        return [1, 1]
        pass

    def yview(self):
",5
"                # print('MfxCanvas: tag_raise: to top')
",5
"                self.clear_widgets([itm])
                self.add_widget(itm)
            else:
",5
"        print('MfxCanvas: deleteAllItems')
",5
"        print('MfxCanvas: findCard(%s, %s)' % (stack, event))
        if (event.cardid > -1):
",5
"            return event.cardid

        print('MfxCanvas: findCard no cardid')
",5
"            #    item.config(fill=self._text_color)
",5
"            # print ('setTile: no image!')
            self._bg_img = None
            self.update_widget(self.pos, self.size)
        return 1
",5
"    #
    # Pause support
    #

    def hideAllItems(self):
",5
"
    # Erweiterungen fuer Tk Canvas (prÃ¼fen was noch nÃ¶tig!!).
",5
"#
",5
"
from pysollib.gamedb import GI
",5
"
",5
"        return None


class SelectGameNode(SelectDialogTreeNode):
",5
"    def _getContents(self):
        contents = []
        if isinstance(self.select_func, UserList):
            # key/value pairs
",5
"                    name = gi.name
                    node = SelectGameLeaf(self.tree, self, name, key=gi.id)
                    contents.append(node)
",5
"            map(app.gdb.get, app.gdb.getGamesIdSortedByName()))
        self.no_games = [SelectGameLeaf(None, None, _(""(no games)""), None), ]
        #
",5
"                if name is None or not filter(select_func, self.all_games_gi):
",5
"                gg.append(SelectGameNode(None, _(name), select_func))
            g.append(gg)

        def select_mahjongg_game(gi): return gi.si.game_type == GI.GT_MAHJONGG
",5
"        g.append(gg)
        if g[0]:
            s_by_type = SelectGameNode(None, _(""French games""),
                                       tuple(g[0]), expanded=1)
        if g[1]:
",5
"        if g[5]:
            s_mahjongg = g[5]
        #
        # all games sorted (in pieces).
",5
"        while True:
            # columnbreak = i > 0 and (i % d) == 0
            i += 1
",5
"            if not agames[n:n + d]:
                break
            m = min(n + d - 1, len(agames) - 1)
",5
"            name = _(""New games in v. %(version)s"") % {'version': name}
            gg.append(SelectGameNode(None, name, select_func))
        if 1 and gg:
            s_by_pysol_version = SelectGameNode(None, _(""by PySol version""),
",5
"        if 1 and gg:
            s_by_inventors = SelectGameNode(None, _(""by Inventors""),
                                            tuple(gg))
        #
        ul_alternate_names = UserList(
",5
"            s_oriental,
",5
"            s_by_type,
            s_all_games,
            SelectGameNode(None, _('by Skill Level'), (
                SelectGameNode(None, _('Luck only'),
",5
"                                   lambda gi: gi.si.ncards == 78),
",5
"                )),
                SelectGameNode(None, _(""by Number of Redeals""), (
                    SelectGameNode(None, _(""No redeal""),
                               lambda gi: gi.si.redeals == 0),
",5
"                               lambda gi: gi.si.redeals == -2),
                    SelectGameNode(None, _(""Other number of redeals""),
                               lambda gi: gi.si.redeals not in
                               (-1, 0, 1, 2, 3)),
",5
"                )),
",5
"                s_by_compatibility,
",5
"                               lambda gi: gi.si.game_flags & GI.GT_RELAXED),
",5
"# * Canvas that shows the tree
# ************************************************************************
'''
class SelectGameTreeWithPreview(SelectDialogTreeCanvas):
    data = None
",5
"

class LGameRoot(LTreeRoot):
    def __init__(self, gametree, gameview, **kw):
        super(LGameRoot, self).__init__(**kw)
",5
"        self.command = None
        if 'command' in kw:
",5
"
    # font skalierung.

    def scaleFont(self, value):
        self.font_size = int(self.coreFont * value / 550.0)
",5
"                print('touch.pos %s' % str(touch.pos))
                return

            print ('touch move on %s - %s' % (self.text, touch.profile))
",5
"    # Dialog, einmal erzeugt, wird rezykliert.
    SingleInstance = None

    def onClick(self, event):
",5
"        self.parent = parent
",5
"        self.window = None
",5
"        if (si and si.running):
            si.parent.popWork('SelectGame')
            si.running = False
            return
",5
"
        # neuen Dialog aufbauen.

        window = LTopLevel(parent, title)
",5
"            if node:
                if not hasattr(node, ""gamenode""):
",5
"                    # (das lÃ¶st ein problem mit dem root knoten),
                    return
",5
"                n.tree = treeview.gametree

                nodes = n.getContents()
                if type(nodes) is list:
",5
"
",5
"        window.content.add_widget(root)

",5
"#!/usr/bin/env python
",5
"# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------##
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"from pysollib.settings import TITLE
from pysollib.ui.tktile.tkconst import EVENT_HANDLED

from six.moves import tkinter

",5
"    def _getMaxIters(self):
        try:
            i = self.max_iters_var.get()
        except Exception:
            i = 100000
",5
"
    def __init__(self, parent, app, **kw):
",5
"        gamenames = ['']
        for id in games:
",5
"        gamenames.sort()
        self.gamenames = gamenames
        self.games_var = self._createGamesVar(frame, row)
",5
"
        #
        row += 1
",5
"        self.max_iters_var = tkinter.IntVar()
        self.max_iters_var.set(self.app.opt.solver_max_iterations)
        self._calcToolkit().Label(
            frame, text=_('Max iterations:'), anchor='w').grid(
",5
"        #
        row += 1
        self.progress_var = tkinter.BooleanVar()
",5
"            top_frame, text=_('Progress'))
",5
"        frow = 0
        self._calcToolkit().Label(
            label_frame, text=_('Iteration:'), anchor='w').grid(
            row=frow, column=0, sticky='ew', padx=4, pady=2)
",5
"        lb = self._calcToolkit().Label(label_frame, anchor='w')
        lb.grid(row=frow, column=1, sticky='ew', padx=4, pady=2)
        self.iter_label = lb
        frow += 1
        self._calcToolkit().Label(
",5
"        self._calcToolkit().Label(
            label_frame, text=_('Stored-States:'), anchor='w').grid(
            row=frow, column=0, sticky='ew', padx=4, pady=2)
        lb = self._calcToolkit().Label(label_frame, anchor='w')
        lb.grid(row=frow, column=1, sticky='ew', padx=4, pady=2)
",5
"        elif button == 1:
",5
"    def reset(self):
        self.play_button.config(state='disabled')

    def startSolving(self):
        from pysollib.mygettext import ungettext
",5
"                      iters_step=iters_step)
",5
"        try:
            solver.computeHints()
        except RuntimeError:
",5
"            if solver.solver_state == 'intractable':
                t = ungettext('This game can be hinted in %d move.',
                              'This game can be hinted in %d moves.',
",5
"                 if solver.solver_state == 'unsolved'
                 else _('Iterations count exceeded (Intractable)'))
            self.play_button.config(state='disabled')

    def startPlay(self):
",5
"        self.app.top.after(200)
        self.app.game.startDemo(level=3)

",5
"
def connect_game_solver_dialog(game):
    try:
        solver_dialog.connectGame(game)
    except Exception:
",5
"    solver_dialog = None


def reset_solver_dialog():
    if solver_dialog:
",5
"        try:
",5
"            # traceback.print_exc()
            pass
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
",5
"# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"                x, y,
",5
"                image=self.tree.data.img[2+(self.key is None)], anchor=""nw"")
            self.tree.nodes[self.symbol_id] = self

",5
"
class BaseSelectDialogTreeNode:
    def __init__(self, tree, text, select_func, expanded=0, parent_node=None):
",5
"        return []

",5
"# * Tree database
# ************************************************************************
",5
"                width=width, height=height,
                hbar=hbar, vbar=vbar)
        self.style.distx = 20
",5
"    def destroy(self):
        if self.n_expansions > 0:   # must save updated xyview
            self.data.tree_xview = self.canvas.xview()
            self.data.tree_yview = self.canvas.yview()
        self._calc_MfxTreeInCanvas().destroy(self)
",5
"        if isinstance(node, self._calc_MfxTreeLeaf()):
            if node.key is not None:
                self.n_selections = self.n_selections + 1
                self.updateSelection(node.key)
",5
"                self.dialog.mDone(self.default)
        elif isinstance(node, self._calc_MfxTreeNode()):
",5
"#!/usr/bin/env python
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
",5
"
class BaseColorsDialog:
    def _calcFrame(self):
",5
"        self.text_var = tkinter.StringVar()
",5
"        #
        focus = self.createButtons(bottom_frame, kw)
        self.mainloop(focus, kw.timeout)
        #
",5
"        except Exception:
",5
"            if c and c[1]:
                label.configure(bg=c[1])
                # label.configure(text=c[1]) # don't work
",5
"    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(_(""&OK""), _(""&Cancel"")),
                      default=0,
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"import pysollib.htmllib2 as htmllib
from pysollib.mfxutil import openURL
from pysollib.mygettext import _
from pysollib.settings import TITLE
from pysollib.ui.tktile.tkutil import bind, unbind_destroy
",5
"            fixed = app.getFont(""fixed"")
        else:
            font = ('helvetica', 12)
            fixed = ('courier', 12)
",5
"            ""h6"": (font[0], size + 1*sign, ""bold""),
            ""bold"": (font[0], size, ""bold""),
            ""italic"": (font[0], size, ""italic""),
            ""pre"": fixed,
",5
"            def __call__(self, *args):
                self.viewer.updateHistoryXYView()
                return self.viewer.display(self.arg)
",5
"            tag = ""href_"" + url
            self.text.tag_add(tag, self.anchor_mark, ""insert"")
            self.text.tag_bind(tag, ""<1>"", self.createCallback(url))
            self.text.tag_bind(
",5
"        self.viewer.statusbar.updateText(url=url)
        self.text.config(cursor=self.viewer.handcursor)
",5
"        self.viewer.statusbar.updateText(url='')
        self.text.config(cursor=self.viewer.defcursor)

",5
"        if font:
",5
"
    def send_paragraph(self, blankline):
        self.write(""\n"" * blankline)
",5
"    def send_hor_rule(self, *args):
        width = int(int(self.text[""width""]) * 0.9)
        self.write(""_"" * width)
        self.write(""\n"")
",5
"        bind(w, ""<KeyPress-BackSpace>"", self.goBack)

    def destroy(self, *event):
",5
"
",5
"    def page_up(self, *event):
        return self._yview('scroll', -1, 'page')

    def page_down(self, *event):
",5
"
",5
"            if relpath and baseurl and not os.path.isabs(url):
                h1, t1 = os.path.split(url)
                h2, t2 = os.path.split(baseurl)
",5
"                return codecs.open(url, encoding='utf-8')
            else:
                return open(url, ""rb"")
        return my_open(url), url

",5
"                if not openURL(url):
                    self.errorDialog(_('''%(app)s HTML limitation:
The %(protocol)s protocol is not supported yet.
",5
"
Please use your standard web browser
",5
"to open the following URL:
%(url)s
''') % {'app': TITLE, 'protocol': p, 'url': url})
                return
",5
"                file.close()
            self.errorDialog(_(""Unable to service request:\n"") + url +
                             ""\n\n"" + str(ex))
            return
        except Exception:
",5
"
",5
"        self.text.config(cursor=self.defcursor)
        self.text.update_idletasks()
",5
"        # self.frame.config(cursor=self.defcursor)
        # self.frame.update_idletasks()
        self.text.config(state=""normal"")
",5
"        # self.images = {}
        writer = tkHTMLWriter(self.text, self, self.app)
",5
"        self.history.list.append((url, xview, yview))
        self.history.index = self.history.index + 1

    def updateHistoryXYView(self):
",5
"        try:
            img = tkinter.PhotoImage(master=self.parent, file=fn)
        except Exception:
            img = None
        self.images[fn] = img
",5
"
",5
"from pysollib.gamedb import GI
from pysollib.hint import PySolHintLayoutImportError
from pysollib.mfxutil import Image, USE_PIL
from pysollib.mfxutil import Struct, kwdefault
",5
"from six.moves import tkinter_tkfiledialog
",5
"    menu.add_radiobutton(label=n_(""Bottom""),
",5
"    menu.add_radiobutton(label=n_(""Right""),
                         variable=menubar.tkopt.toolbar, value=4,
                         command=menubar.mOptToolbar)
",5
"    menu.add_separator()
    submenu = MfxMenu(menu, label=n_('Visible buttons'), tearoff=tearoff)
    for w in TOOLBAR_BUTTONS:
        submenu.add_checkbutton(
",5
"        self.name = kw[""name""]
        tearoff = 0
",5
"                cnf[""underline""] = cnf.get(""underline"", underline)
            cnf[""label""] = label
            if name and self.addPath:
",5
"                path = str(self._w) + ""."" + name
                self.addPath(path, self, self.n, cnf.get(""menu""))
        tkinter.Menu.add(self, itemType, cnf)
        self.n = self.n + 1

",5
"        self._createTkOpt()
",5
"        self.progress = progress
        # create menus
        self.menubar = None
",5
"            highlight_cards=tkinter.BooleanVar(),
            highlight_samerank=tkinter.BooleanVar(),
            highlight_not_matching=tkinter.BooleanVar(),
",5
"            num_cards=tkinter.BooleanVar(),
            helpbar=tkinter.BooleanVar(),
            save_games_geometry=tkinter.BooleanVar(),
            splashscreen=tkinter.BooleanVar(),
",5
"            theme=tkinter.StringVar(),
            toolbar_vars={},
        )
",5
"        tkopt.bookmarks.set(opt.bookmarks)
        tkopt.highlight_piles.set(opt.highlight_piles)
",5
"        tkopt.toolbar_compound.set(opt.toolbar_compound)
        tkopt.toolbar_size.set(opt.toolbar_size)
        tkopt.toolbar_relief.set(opt.toolbar_relief)
",5
"        tkopt.statusbar.set(opt.statusbar)
        tkopt.num_cards.set(opt.num_cards)
        tkopt.helpbar.set(opt.helpbar)
",5
"        tkopt.save_games_geometry.set(opt.save_games_geometry)
        tkopt.demo_logo.set(opt.demo_logo)
        tkopt.splashscreen.set(opt.splashscreen)
        tkopt.mouse_type.set(opt.mouse_type)
        tkopt.mouse_undo.set(opt.mouse_undo)
",5
"        tkopt.negative_bottom.set(opt.negative_bottom)
        for w in TOOLBAR_BUTTONS:
            tkopt.toolbar_vars[w].set(opt.toolbar_vars.get(w, False))

",5
"    # create a GTK-like path
",5
"        if sys.platform == ""darwin"":
            m = ""Cmd-""
",5
"            command=self.mSelectGameById, accelerator=m+""M"")
        menu.add_separator()
        submenu = MfxMenu(menu, label=n_(""Fa&vorite games""))
        menu.add_command(label=n_(""A&dd to favorites""), command=self.mAddFavor)
        menu.add_command(
",5
"        self._addSelectGameMenu(menu)

",5
"        if self.progress:
            self.progress.update(step=1)
",5
"            command=self.mUndo, accelerator=""Z"")
        menu.add_command(
            label=n_(""&Redo""),
",5
"            command=self.mRedo, accelerator=""R"")
",5
"            label=n_(""&Edit current game""),
            command=self.mWizardEdit)

",5
"            label=n_(""&Pause""), variable=self.tkopt.pause,
            command=self.mPause, accelerator=""P"")
        # menu.add_command(
",5
"            label=n_(""&Statistics...""),
",5
"            command=lambda: self.mPlayerStats(mode=1101))

        menu = MfxMenu(self.menubar, label=n_(""&Assist""))
",5
"        menu.add_command(
            label=n_(""&Demo""),
            command=self.mDemo, accelerator=m+""D"")
        menu.add_command(
",5
"            menu.add_command(label=n_(""&Solver""), command=self.mSolver)
        else:
            menu.add_command(label=n_(""&Solver""), state='disabled')
",5
"        submenu.add_checkbutton(
",5
"        submenu.add_checkbutton(
            label=n_(""Auto &deal""), variable=self.tkopt.autodeal,
            command=self.mOptAutoDeal)
        submenu.add_separator()
",5
"        submenu = MfxMenu(menu, label=n_(""Assist &level""))
        submenu.add_checkbutton(
            label=n_(""Enable &undo""), variable=self.tkopt.undo,
            command=self.mOptEnableUndo)
",5
"        submenu.add_checkbutton(
            label=n_(""Enable highlight &cards""),
            variable=self.tkopt.highlight_cards,
",5
"            label=n_(""Show hint &arrow (in Shisen-Sho games)""),
",5
"            command=self.mSelectCardsetDialog, accelerator=m+""E"")
        menu.add_command(
",5
"            variable=self.tkopt.negative_bottom,
",5
"        submenu.add_radiobutton(
            label=n_(""&None""), variable=self.tkopt.animations, value=0,
            command=self.mOptAnimations)
        submenu.add_radiobutton(
",5
"                variable=self.tkopt.win_animation,
                command=self.mWinAnimation)
        submenu = MfxMenu(menu, label=n_(""&Mouse""))
",5
"        submenu.add_radiobutton(
            label=n_(""&Drag-and-Drop""), variable=self.tkopt.mouse_type,
",5
"        submenu.add_checkbutton(
            label=n_(""Use mouse for undo/redo""),
",5
"        # if not USE_PIL:
        menu.add_checkbutton(
            label=n_(""Save games &geometry""),
",5
"            variable=self.tkopt.save_games_geometry,
            command=self.mOptSaveGamesGeometry)
        menu.add_checkbutton(
",5
"
        menu = MfxMenu(self.menubar, label=n_(""&Help""))
        menu.add_command(
",5
"            command=self.mHelp, accelerator=m+""F1"")
        menu.add_command(
            label=n_(""&How to play""),
",5
"        ctrl = ""Control-""
",5
"        self._bindKey(ctrl, ""g"", self.mRestart)
        self._bindKey("""",   ""space"", self.mDeal)        # undocumented
        self._bindKey(ctrl, ""y"", lambda e: self.mPlayerStats(mode=100))
",5
"        self._bindKey("""",   ""i"", self.mHighlightPiles)
        self._bindKey("""",   ""F3"", self.mFindCard)
",5
"            self._bindKey(ctrl, ""equal"", self.mIncreaseCardset)
            self._bindKey(ctrl, ""minus"", self.mDecreaseCardset)
            self._bindKey(ctrl, ""0"", self.mOptAutoScale)
        self._bindKey(ctrl, ""b"", self.mOptChangeCardback)  # undocumented
",5
"        self._bindKey("""", ""slash"", lambda e: self.mPlayerStats(mode=106))
        #
",5
"
        # undocumented, devel
        self._bindKey(ctrl, ""End"", self.mPlayNextMusic)
        self._bindKey(ctrl, ""Prior"", self.mSelectPrevGameByName)
        self._bindKey(ctrl, ""Next"", self.mSelectNextGameByName)
",5
"            sequence = ""<"" + modifier + ""KeyPress-"" + key + "">""
            bind(self.top, sequence, func)
",5
"                    r = EVENT_HANDLED
",5
"                # if func and (event.state & ~2) == 0:
",5
"        return r

",5
"    #
",5
"
    def _addSelectGameMenu(self, menu):
",5
"        # games = map(self.app.gdb.get,
        #   self.app.gdb.getGamesIdSortedByShortName())
        games = list(map(
            self.app.gdb.get, self.app.gdb.getGamesIdSortedByName()))
",5
"        # menu = MfxMenu(menu, label=""Select &game"")
        m = ""Ctrl-""
        if sys.platform == ""darwin"":
",5
"
    def _getNumGames(self, games, select_data):
        ngames = 0
",5
"        for label, select_func in select_data:
",5
"            ngames += len(list(filter(select_func, games)))
        return ngames

    def _addSelectMahjonggGameSubMenu(self, games, menu, command, variable):
        def select_func(gi):
",5
"                games[c] = [gi]
        games = list(games.items())
        games.sort()
        g0 = []
",5
"                g0 += g1
                c1 = c
        add_menu(g0, c0, c1)

",5
"        data = (n_(""&Popular games""), select_func)
",5
"    def _addSelectOrientalGameSubMenu(self, games, menu, command, variable):
        if self._getNumGames(games, GI.SELECT_ORIENTAL_GAME_BY_TYPE) == 0:
",5
"            return
        submenu = MfxMenu(menu, label=n_(""&Oriental games""))
        self._addSelectGameSubMenu(games, submenu,
",5
"                                   GI.SELECT_ORIENTAL_GAME_BY_TYPE,
                                   self.mSelectGame, self.tkopt.gameid)
",5
"
",5
"        i = 0
        while True:
",5
"        # cb = (25, self.cb_max) [ len(g) > 4 * 25 ]
",5
"                                        'variable': variable,
                                        'columnbreak': columnbreak,
",5
"    def updateGamesMenu(self, menu, games):
        menu.delete(0, 'last')
        if len(games) == 0:
            menu.add_radiobutton(label=_('<none>'), name=None,
                                 state='disabled')
",5
"    #
",5
"        if d.status == 0 and d.button == 0 and d.gameid != self.game.id:
            self.tkopt.gameid.set(d.gameid)
            self.tkopt.gameid_popular.set(d.gameid)
",5
"        return EVENT_HANDLED

    def __restoreCursor(self, *event):
",5
"        self.game.setCursor(cursor=CURSOR_WATCH)
        after_idle(self.top, self.__restoreCursor)
        d = self._calcSelectGameDialog()(
            self.top, title=_(""Select game""),
",5
"            return
        self.game.setCursor(cursor=CURSOR_WATCH)
        bookmark = None
",5
"    #

    def updateFavoriteGamesMenu(self):
",5
"
    def updateBookmarkMenuState(self):
        state = self._getEnabledState
        mp1 = self.menupath.get("".menubar.edit.setbookmark"")
        mp2 = self.menupath.get("".menubar.edit.gotobookmark"")
",5
"
    #
    # menu actions
    #
",5
"
    DEFAULTEXTENSION = "".pso""
    FILETYPES = ((_(""%s files"") % TITLE, ""*"" + DEFAULTEXTENSION),
                 (_(""All files""), ""*""))

",5
"
    def mDelFavor(self, *event):
",5
"            self.app.opt.favorite_gameid.remove(gameid)
            self.updateFavoriteGamesMenu()

    def mOpen(self, *event):
        if self._cancelDrag(break_pause=False):
",5
"            # filename = os.path.normcase(filename)
            if os.path.isfile(filename):
",5
"
",5
"                filename += ""-"" + self.game.getGameNumber(format=0)
",5
"Unsupported game for import.
'''),
",5
"        if not idir:
            idir = self.app.dn.savegames
        d = tkinter_tkfiledialog.Open()
",5
"        key = 'PYSOL_DEBUG_IMPORT'
        if key not in os.environ:
            filename = d.show(filetypes=self.FILETYPES,
",5
"                            fh, game, self)
                    except PySolHintLayoutImportError as err:
                        self._calc_MfxMessageDialog()(
",5
"                            title=_('Import game error'),
                            text=err.format(),
                            bitmap='error'
",5
"                        game.busy = False
                        game.endGame()
                        game.newGame()
",5
"        idir, ifile = os.path.split(os.path.normpath(filename))
        if not idir:
",5
"                          initialdir=idir, initialfile=ifile)
",5
"        if filename:
            filename = os.path.normpath(filename)
",5
"        if not self.game.pause:
            if self._cancelDrag():
                return
",5
"        if self._cancelDrag():
",5
"            return
",5
"        self.app.opt.autodeal = self.tkopt.autodeal.get()
        if self.app.opt.autodeal:
            self.game.autoPlay()

    def mOptQuickPlay(self, *args):
",5
"        self.game.updateMenus()
",5
"
",5
"    def mOptEnableHint(self, *args):
        if self._cancelDrag(break_pause=False):
            return
        self.app.opt.hint = self.tkopt.hint.get()
        self.game.updateMenus()
",5
"        self.game.updateMenus()
",5
"        self.game.updateMenus()

    def mOptEnableHighlightSameRank(self, *args):
",5
"            return
        self.app.opt.highlight_not_matching = \
            self.tkopt.highlight_not_matching.get()
        # self.game.updateMenus()
",5
"        self.app.opt.redeal_animation = self.tkopt.redeal_animation.get()

",5
"    def mOptShisenShowHint(self, *args):
        if self._cancelDrag(break_pause=False):
            return
",5
"        geom = (self.app.canvas.winfo_width(),
                self.app.canvas.winfo_height())
        self.app.opt.game_geometry = geom
        self.app.game.resizeGame()
",5
"        if self.app.opt.auto_scale:
            w, h = self.app.opt.game_geometry
",5
"            self.app.top.wm_geometry("""")    # cancel user-specified geometry
        # self.app.top.update_idletasks()

    def mIncreaseCardset(self, *event):
        if self._cancelDrag(break_pause=True):
",5
"            self.app.opt.scale_y += 0.1
        else:
            return
        self.app.opt.auto_scale = False
",5
"        self.app.opt.auto_scale = auto_scale
        self.tkopt.auto_scale.set(auto_scale)
        self._updateCardSize()
",5
"
    def _mOptCardback(self, index):
        if self._cancelDrag(break_pause=False):
            return
        cs = self.app.cardset
",5
"            if self.app.setTile(i):
",5
"                self.tkopt.tabletile.set(i)
",5
"
    def mSelectTileDialog(self, *event):
        if self._cancelDrag(break_pause=False):
            return
",5
"        self.setToolbarSide(self.tkopt.toolbar.get())

    def mOptToolbarStyle(self, *event):
",5
"            return
        if not self.app.statusbar:
",5
"            return
        side = self.tkopt.statusbar.get()
        self.app.opt.statusbar = side
        resize = not self.app.opt.save_games_geometry
",5
"        if self.app.statusbar.show(side, resize=resize):
            self.top.update_idletasks()

    def mOptNumCards(self, *event):
        if self._cancelDrag(break_pause=False):
",5
"    def mOptHelpbar(self, *event):
",5
"        resize = not self.app.opt.save_games_geometry
        if self.app.helpbar.show(show, resize=resize):
            self.top.update_idletasks()

",5
"        self.app.opt.save_games_geometry = self.tkopt.save_games_geometry.get()
",5
"
    def mOptDemoLogo(self, *event):
        if self._cancelDrag(break_pause=False):
            return
",5
"        self.app.opt.demo_logo = self.tkopt.demo_logo.get()

",5
"        self.app.opt.splashscreen = self.tkopt.splashscreen.get()
",5
"
",5
"        resize = not self.app.opt.save_games_geometry
        if self.app.toolbar.show(side, resize=resize):
            self.top.update_idletasks()

    def setToolbarSize(self, size):
",5
"            self.game.updateStatus(player=self.app.opt.player)
            self.top.update_idletasks()

",5
"    def setToolbarStyle(self, style):
",5
"        if self._cancelDrag(break_pause=False):
            return
",5
"    def wizardDialog(self, edit=False):
        from pysollib.wizardutil import write_game, reset_wizard
        WizardDialog = self._calcWizardDialog()
",5
"            self._mSelectGame(gameid, force=True)

    def mWizard(self, *event):
        if self._cancelDrag(break_pause=False):
            return
",5
"# This program is distributed in the hope that it will be useful,
",5
"
from pysollib.mygettext import _
from pysollib.settings import TITLE
from pysollib.ui.tktile.tkcanvas import MfxCanvas, MfxCanvasGroup
from pysollib.ui.tktile.tkcanvas import MfxCanvasImage, MfxCanvasRectangle
",5
"SMALL_EMBLEMS_SIZE = (31, 21)

",5
"        #
        # self.images_dir = dir
        if size == 'large':
            self.images_dir = os.path.join(dir, 'large')
            self.label_width, self.label_height = LARGE_EMBLEMS_SIZE
",5
"            1000*game.app.opt.timeouts['highlight_samerank'])
        self.hidden_timeout = 200
        self.timer = None
",5
"
",5
"            fn = os.path.join(dir, r+s+'.gif')
            im = makeImage(file=fn)
            FindCardDialog.CARD_IMAGES[(rank, suit)] = im
",5
"        cim.lower()
        #
",5
"        self.groups.append(group)

    def connectGame(self, game):
        self.canvas.delete('all')
",5
"        # print 'enterEvent', suit, rank, self.busy
        if self.busy:
            return
        if self.game.demo:
            return
",5
"            self.timer = after(self, self.normal_timeout, self.timeoutEvent)
        rect.config(state='normal')
",5
"        self.canvas.update_idletasks()
        self.busy = False

    def leaveEvent(self, suit, rank, rect, group):
        # print 'leaveEvent', suit, rank, self.busy
",5
"        rect.config(state='hidden')
        if self.game.canvas:
            self.game.canvas.update_idletasks()
        self.canvas.update_idletasks()
        self.busy = False
",5
"        if self.highlight_items:
",5
"            state = self.highlight_items[0].cget('state')
            if state in ('', 'normal'):
                state = 'hidden'
",5
"                                   self.timeoutEvent)
            for item in self.highlight_items:
                item.config(state=state)

",5
"            for i in self.highlight_items:
                i.delete()
        tkinter.Toplevel.destroy(self)
",5
"#!/usr/bin/env python
",5
"
# ************************************************************************
# *
# ************************************************************************
",5
"    def hide(self, stack):
",5
"# * New implementation since 2.10
# *
# * We use a single CanvasImage and call CanvasImage.config() to
",5
"
    def showFace(self, unhide=1):
        if not self.face_up:
            self._setImage(image=self._face_image)
            self.tkraise(unhide)
",5
"        if self.face_up:
            img = self._face_image
",5
"# * Hide a card by configuring the canvas image to None.
# ************************************************************************
",5
"
",5
"    #   __face, __back -- the canvas items making up the card
    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
",5
"    # Private instance variables:
    #   __face, __back -- the canvas items making up the card
    def __init__(self, id, deck, suit, rank, game, x=0, y=0):
        _HideableCard.__init__(self, id, deck, suit, rank, game, x=x, y=y)
        self.item = MfxCanvasGroup(game.canvas)
",5
"                deck, suit, rank), anchor=""nw"")
        self.__back = MfxCanvasImage(
            game.canvas, self.x, self.y, image=game.getCardBackImage(
",5
"                deck, suit, rank), anchor=""nw"")
",5
"        if not self.face_up:
",5
"        self.__back.config(image=image)


# choose the implementation
Card = _TwoImageCardWithHideItem
",5
"
    def __str__(self):
",5
"    def keys(self):
",5
"        return (x1, y1), (x2, y2)
",5
"        return self.canvas.itemconfig(self.id, _cnfmerge((cnf, kw)))

    def coords(self, pts=()):
        flat = ()
        for x, y in pts:
",5
"        CanvasItem.__init__(self, canvas, 'bitmap', *args, **kw)

",5
"class Rectangle(CanvasItem):
    def __init__(self, canvas, *args, **kw):
        CanvasItem.__init__(self, canvas, 'rectangle', *args, **kw)

",5
"class CanvasText(CanvasItem):
    def __init__(self, canvas, *args, **kw):
        CanvasItem.__init__(self, canvas, 'text', *args, **kw)

",5
"
class Window(CanvasItem):
    def __init__(self, canvas, *args, **kw):
        CanvasItem.__init__(self, canvas, 'window', *args, **kw)
",5
"        return self.canvas._getints(self._do('bbox'))

    def bind(self, sequence=None, command=None, add=None):
        return self.canvas.tag_bind(self.id, sequence, command, add)
",5
"
    def coords(self, *pts):
        return self._do('coords', pts)
",5
"        self._do('focus')
",5
"# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
",5
"#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# ---------------------------------------------------------------------------

",5
"        kw = self.initKw(kw)
        self._calc_MfxDialog().__init__(
",5
"        frame = self._calcToolkit().Frame(top_frame)
        frame.pack(expand=True, fill='both', padx=5, pady=10)
        frame.columnconfigure(0, weight=1)

",5
"        if gi.redeals == -2:
            redeals = 'VARIABLE'
        elif gi.redeals == -1:
            redeals = 'UNLIMITED'
        else:
",5
"        version = None
        for t in GI.GAMES_BY_PYSOL_VERSION:
            if gi.id in t[1]:
",5
"                     ('Short name:', gi.short_name),
                     ('ID:', gi.id),
                     ('Alt names:', '\n'.join(gi.altnames)),
                     ('PySol version:', version),
                     ('Decks:', gi.decks),
",5
"                     ('Type:', type),
                     ('Flags:', '\n'.join(flags)),
                     ('Skill level:', skill_level),
",5
"                     ('Rules filename:', gi.rules_filename),
                     ('Module:', game.__module__),
                     ('Class:', game.__class__.__name__),
",5
"                     ('Hint:', hint),
                     ):
            if t:
                self._calcToolkit().Label(
                    frame, text=n, anchor='w').grid(
",5
"                    row=row, column=0, sticky='nw')
                self._calcToolkit().Label(
",5
"                    frame, text=t, anchor='w', justify='left').grid(
                    row=row, column=1, sticky='nw')
",5
"        if game.s.waste:
",5
"            self.showStacks(frame, row, 'Waste:', game.s.waste)
            row += 1
        for t, s in (
            ('Foundations:', game.s.foundations,),
            ('Rows:',        game.s.rows,),
",5
"            ('Reserves:',    game.s.reserves,),
",5
"    def initKw(self, kw):
",5
"        kw = KwStruct(kw,
                      strings=(_(""&OK""),),
                      default=0,
                      separator=True,
                      )
",5
"
    def initKw(self, kw):
        kw = KwStruct(kw,
                      strings=(_(""&OK""), _(""&Cancel"")),
                      default=-1,
",5
"        self.sleep_var = 0
        self.after_id = None
",5
"        # self.bind('<ButtonPress>', self._sleepEvent, add=True)
",5
"        elif 0:
            # and this is even worse
",5
"        self.sleep_var.set(1)
        self.update()
",5
"
    def _sleepEvent(self, *args):
        return
        print('_sleepEvent', args)
",5
"        self.update()
",5
"            pass
#!/usr/bin/env python
# -*- mode: python; coding: utf-8; -*-
# ---------------------------------------------------------------------------
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
",5
"# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
",5
"# ---------------------------------------------------------------------------##

from pysollib.mygettext import n_

",5
"from six.moves import tkinter

# ************************************************************************
# * constants
",5
"CURSOR_DRAG = ""hand1""
CURSOR_WATCH = ""watch""
",5
"ANCHOR_NW = tkinter.NW
",5
"ANCHOR_NE = tkinter.NE
ANCHOR_S = tkinter.S
ANCHOR_SW = tkinter.SW
ANCHOR_SE = tkinter.SE
",5
"ANCHOR_W = tkinter.W
ANCHOR_E = tkinter.E

",5
"    ""pause"",
    ""statistics"",
    ""rules"",
",5
"from six.moves import tkinter_font


",5
"# ************************************************************************
# * window manager util
",5
"    if window.wm_state() != ""iconic"":
        if maximized and WIN_SYSTEM == ""win32"":
            window.wm_state(""zoomed"")
        else:
",5
"__wm_get_geometry_re = re.compile(r""^(\d+)x(\d+)\+([\-]?\d+)\+([\-]?\d+)$"")
",5
"

def wm_get_geometry(window):
    g = window.wm_geometry()
    m = __wm_get_geometry_re.search(g)
",5
"    if title:
        window.wm_title(title)
        window.wm_iconname(title)
    return window
",5
"
def __getWidgetXY(widget, parent, relx=None, rely=None,
                  w_width=None, w_height=None):
    if w_width is None:
",5
"    if parent and parent.winfo_ismapped():
",5
"        # print parent.wm_geometry()
        # print parent.winfo_geometry(), parent.winfo_x(), parent.winfo_y(), \
        #   parent.winfo_rootx(), parent.winfo_rooty(), parent.winfo_vrootx(),\
        #   parent.winfo_vrooty()
        m_x = m_y = None
",5
"        if m_x is None:
",5
"            m_x = parent.winfo_x()
            m_y = parent.winfo_y()
            m_width = parent.winfo_width()
            m_height = parent.winfo_height()
            if relx is None:
",5
"                relx = 0.5
            if rely is None:
                rely = 0.3
        else:
            if relx is None:
",5
"
# ************************************************************************
",5
"__mfx_bindings = {}
__mfx_wm_protocols = (""WM_DELETE_WINDOW"", ""WM_TAKE_FOCUS"", ""WM_SAVE_YOURSELF"")

",5
"    if k in __mfx_bindings:
        __mfx_bindings[k].append((sequence, funcid))
    else:
        __mfx_bindings[k] = [(sequence, funcid)]

",5
"                if sequence in __mfx_wm_protocols:
",5
"                    widget.tk.call(""wm"", ""protocol"", widget._w, sequence, """")
                    # widget.deletecommand(funcid)
                else:
                    widget.unbind(sequence, funcid)
",5
"def after_cancel(t):
    if t is not None:
",5
"        except tkinter.TclError:
            pass


",5
"            self._pil_image = image
            if pil_image_orig:
",5
"            else:
                self._pil_image_orig = image
",5
"            w, h = self._pil_image_orig.size
            w0, h0 = int(w*xf), int(h*yf)
            im = self._pil_image_orig.resize((w0, h0), Image.ANTIALIAS)
            return PIL_Image(image=im, pil_image_orig=self._pil_image_orig)
",5
"        kw[""data""] = data
    if Image:
        # use PIL
        if file:
",5
"            return im
        # fromstring(mode, size, data, decoder_name='raw', *args)
        else:
            return tkinter.PhotoImage(data=data)
",5
"    assert dest.width() == width
    assert dest.height() == height
    return dest
",5
"    if 1:                               # shadow
        color, factor = '#6ae400', 0.3
        sh = Image.new('RGBA', image.size, color)
        tmp = Image.blend(image, sh, factor)
    else:                               # negate
",5
"        x, y = (w1 - w0) // 2, (h1 - h0) // 2
        out.paste(back, (x, y), back)
    return out

",5
"
",5
"# Copyright (C) 1998-2003 Markus Franz Xaver Johannes Oberhumer
# Copyright (C) 2003 Mt. Hood Playing Card Co.
# Copyright (C) 2005-2009 Skomoroh
#
",5
"# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
",5
"# This program is distributed in the hope that it will be useful,
",5
"# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
",5
"# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
",5
"# ---------------------------------------------------------------------------

",5
"# * canvas items
# ************************************************************************

class MfxCanvasGroup(Group):
    def __init__(self, canvas, tag=None):
",5
"    def moveTo(self, x, y):
",5
"    def show(self):
",5
"        self.config(state='normal')

    def hide(self):
        self.config(state='hidden')

",5
"        self.preview = 0
        self.busy = False
        # this is also used by lib-tk/Canvas.py
        self.items = {}
",5
"        # private
        self.__tileimage = None
        self.__tiles = []           # id of canvas items
        self.__topimage = None
",5
"        # friend MfxCanvasText
        self._text_color = ""#000000""
        self._stretch_bg_image = 0
",5
"        stretch = self._stretch_bg_image
        save_aspect = self._save_aspect_bg_image
        if Image:
",5
"                    im = self._bg_img.resize((w0, h0))
                else:
                    im = self._bg_img.resize((w, h))
                image = ImageTk.PhotoImage(im)
",5
"            iw, ih = image.width(), image.height()
            sw, sh = self._geometry()
            for x in range(-self.xmargin, sw, iw):
                for y in range(-self.ymargin, sh, ih):
",5
"                    id = self._x_create(
",5
"    def _geometry(self):
        w = max(self.winfo_width(), int(self.cget('width')))
        h = max(self.winfo_height(), int(self.cget('height')))
        scrollregion = self.cget('scrollregion')
",5
"        if self.__tops:
            self.tk.call(self._w, ""lower"", id, self.__tops[0])
",5
"    def deleteAllItems(self):
        self._text_items = []
",5
"            #          return i
",5
"            if self.preview:
                dx, dy = 0, 0
            else:
                dx, dy = -self.xmargin, -self.ymargin
",5
"            # print c, "":"", v, ""luminance"", luminance
",5
"            for id in self.__tiles:
                self.delete(id)
            self.__tiles = []
",5
"        return 1

    def setTopImage(self, image, cw=0, ch=0):
        try:
",5
"        self.__topimage = image
",5
"        iw, ih = image.width(), image.height()
",5
"            # ch = max(int(self.cget(""height"")),  self.winfo_height())
            ch = self.winfo_height()
        # print iw, ih, cw, ch
",5
"        funcid = self._register(func, self._substitute, needcleanup)
        cmd = ('%sif {""[%s %s]"" == ""break""} break\n' %
               (add and '+' or '', funcid, ""%x %y""))
        self.tk.call(what + (sequence, cmd))
",5
"        self.foundations = [
            pysollib.stack.SS_FoundationStack(0, 0, self, s) for s in range(4)]
        self.rows = [pysollib.stack.AC_RowStack(0, 0, self) for s in range(8)]
        self.reserves = [
",5
"class Mock_S_Game:
",5
"
",5
"''', 'import worked with utf-8 bom')

",5
"            self.assertEqual(err.msg, ""Duplicate cards in input"")
            self.assertEqual(err.cards, [""KC""])
            self.assertEqual(err.line_num, 1)
",5
"    def test_throw_error_on_invalid_foundations_line(self):
",5
"        except PySolHintLayoutImportError as err:
            self.assertEqual(err.msg, ""Invalid Foundations line"")
            self.assertEqual(err.cards, [])
            self.assertEqual(err.line_num, 1)
",5
"            return
        self.fail(""No exception thrown."")

    def test_throw_error_on_missing_cards(self):
",5
"
",5
"from pysol_tests.common_mocks1 import MockApp, MockCanvas, MockItem, MockTalon

import pysollib.stack
from pysollib.acard import AbstractCard
from pysollib.games.spider import Scorpion_RowStack, Spider_RowStack
",5
"        self.foundations = [
",5
"
    def moveMove(self, cnt, frm, to, frames=0):
",5
"    def _calc_Scorpion_stack(self):
        g = MockGame()
        stack = Scorpion_RowStack(0, 0, g)
",5
"        for s, r in [(2, 5), (3, 7), (2, 7), (2, 0), (2, 3), (2, 4), (1, 4)]:
            c = AbstractCard(1000+r*100+s*10, 0, s, r, g)
",5
"        self.assertTrue(stack)

    def _calc_Spider_stack(self):
        g = MockGame()
        stack = Spider_RowStack(0, 0, g)
",5
"            c.face_up = True
            c.item = MockItem()
            stack.addCard(c)
        return stack

",5
"        self.assertTrue(stack)
",5
"        d = GameDrag()
        d.shadows.append(""test"")
",5
"from pysollib.mfxutil import latin1_normalize


",5
"

",5
"

class MockOpt:
    def __init__(self):
",5
"
pysollib.stack.MfxCanvasGroup = _empty_override
# Written by Shlomi Fish, under the MIT Expat License.

import unittest
",5
"        # TEST
        self.assertEqual(card1.color, 0, 'card1.color is sane.')

        # TEST
",5
"        self.assertEqual(card1.rank, 2, 'card1.rank')

        card2 = AbstractCard(1001, 0, 3, 7, 3001)
",5
"#
# PySol -- a Python Solitaire game
#
# Copyright (C) 2000 Markus Franz Xaver Johannes Oberhumer
",5
"# along with this program; see the file COPYING.
# If not, write to the Free Software Foundation, Inc.,
# 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
",5
"
",5
"        def test_24(blurb):
            game = Game(""freecell"", 24, RandomBase.DEALS_PYSOLFC)
",5
"            got_s = game.calc_layout_string(ren)
            self.assertEqual(got_s, '''4C 2C 9C 8C QS 4S 2H
",5
"        got_s = game.calc_layout_string(ren)
        self.assertEqual(got_s, '''QD TC AS KC AH KH 6H
",5
"6D TD 8D TH 7C 2H 9C
AC AD 5C 5H 8C 9H 9D
JS 8S 4D 4C 2S 7D 3C
",5
"JD QH 6S 4H QC 8H
''', 'Microsoft Deal 123456')
",5
"4D JS AD 6S JH JC JD
KH 3H KS AS TC 5D AC
TD 7C 9C 7H 3C 3S
",5
"6D QC 8S TH 7D 8H
",5
"        self._cmp_board(game.calc_layout_string(ren), '''5S AH 4H TD 4S JD JS
3C 8C 4C AC JC AS QS
",5
"7C QH 2D QD 8S 9D AD
KS 7S 5H 3H TS 3S 5D
9S 7H KC TH 8D 6S
5C KD 9H 2H 2S 6D
9C JH 8H 3D 4D QC
",5
"KH 6H 6C TC 2C 7D
''', 'ms100001')
",5
"        seed = 24000024
        rand = constructRandom(str(seed))
        expected0 = rand.randint(0, 100)
        expected1 = rand.randint(0, 100)
        rand.reset()
",5
"        got0 = rand.randint(0, 100)
        got1 = rand.randint(0, 100)
        # TEST
",5
"    pass

try:
    os.mkdir('html/rules')
except Exception:
",5
"    ret.update(y)
    return ret
",5
"    ('intro.html', 'PySol - Introduction'),
    ('license.html', 'PySol Software License'),
",5
"    ('matrix.html', 'PySol - Rules for Matrix'),
    ('pegged.html', 'PySol - Rules for Pegged'),
",5
"<meta name=""license"" content=""GNU General Public License"">
<meta http-equiv=""content-type"" content=""text/html; charset=utf-8"">
</head>
<body text=""#000000"" bgcolor=""#F7F3FF"" link=""#0000FF"" vlink=""#660099""
",5
"<html>
",5
"<head>
<title>%(title)s</title>
<meta name=""license"" content=""GNU General Public License"">
<meta http-equiv=""content-type"" content=""text/html; charset=utf-8"">
",5
"    files_list = []
    for fn, tt in rules_files:
        rules_list.append(('rules', fn, tt, ''))
",5
"        gi = GAME_DB.get(id)

        rules_fn = gi.rules_filename
",5
"        if rules_fn in rules_ls:
            rules_dir = 'rules'
        elif rules_fn in wikipedia_ls:
            rules_dir = 'wikipedia'
",5
"    print(_fmt(main_header, {'title': 'PySol - a Solitaire Game Collection'}),
",5
"    for name, fn in altnames:
",5
"        with open(os.path.join(dir, filename), 'r', encoding='utf-8') as file:
            print(file.read(), file=outfile)
        print(_fmt(rules_footer, {'footer': footer}), file=outfile)
",5
"        outfile.close()


",5
"# This program is free software; you can redistribute it and/or modify
",5
"# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
",5
"if '--kivy' not in sys.argv:
    sys.argv.append('--kivy')

runmain = True
",5
"    from pysollib.init import init
init()
",5
"# import pychecker.checker

",5
"
GAME_BY_TYPE = {
    GI.GT_BAKERS_DOZEN: ""Baker's Dozen"",
    GI.GT_BELEAGUERED_CASTLE: ""Beleaguered Castle"",
",5
"    GI.GT_CANFIELD: ""Canfield"",
    GI.GT_FAN_TYPE: ""Fan"",
    GI.GT_FORTY_THIEVES: ""Forty Thieves"",
",5
"    GI.GT_TERRACE: ""Terrace"",
    GI.GT_YUKON: ""Yukon"",
    GI.GT_1DECK_TYPE: ""One-Deck game"",
    GI.GT_2DECK_TYPE: ""Two-Deck game"",
    GI.GT_3DECK_TYPE: ""Three-Deck game"",
",5
"    GI.GT_TAROCK: ""Tarock"",
",5
"
",5
"def by_type():
    games = GAME_DB.getGamesIdSortedById()
    games_by_type = {}
    for id in games:
",5
"            games_by_type[gt] = 1
    games_by_type_list = list(games_by_type.items())
    games_by_type_list.sort(key=lambda x: x[0])
",5
"    for i in games_by_type_list:
        print('<li>%s (%s games)</li>' % i)
    print('</ul>')
    return
",5
"
",5
"
",5
"''')
",5
"    print('<h2>Categories</h2>')
",5
"
",5
"    for id in get_games_func():
        gi = GAME_DB.get(id)
",5
"        games_list[gi.name] = ''
        if gi.name != gi.short_name:
            games_list[gi.short_name] = ''
",5
"

",5
"            games_list[n] = ''
    games_list = games_list.keys()
    games_list.sort()
    for g in games_list:
        print(g)
",5
"            for n in gi.altnames:
                print(n)
",5
"import re
from sys import platform

IS_MAC = (platform == ""darwin"")
TEST_TAGS = os.getenv('TEST_TAGS', '')
",5
"

def _has_tag(tag):
",5
"
PY_VERS = ([] if _has_tag('SKIP_PY2') else [2])+[3]
SKIP_GTK = _has_tag('SKIP_GTK')
module_names = []
for d, _, files in os.walk(""pysollib""):
",5
"print('1..1')
sys.path.insert(0, ""."")
import %(module_name)s
print('ok 1 - imported')
",5
"            'pysol_tests.game_drag',
            'pysol_tests.hint',
",5
"            ]:
        open(os.path.join(""."", ""tests"", ""unit-generated"",
                          'test__%s__v%d.py' % (mod, ver)
                          ), 'w').write('''#!/usr/bin/env python%(ver)d
import unittest
",5
"# -*- mode: python; coding: utf-8; -*-
",5
"import sys

alpha = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'

",5
"
",5
"def encode_layout(layout):
    # encode positions
    s = '0'
",5
"                    continue
                s += alpha[i_0*7+(i_n-i_0)] + alpha[x] + alpha[y]
                i_0 = i_n = i
            s += alpha[i_0*7+(i_n-i_0)] + alpha[x] + alpha[y]
",5
"            if c == '1':
                layout.append((z, x, y))
            x += 1
",5
"        if y == 20:
            y = 0
            z += 1
",5
"

",5
"    layout = []
    layer = 0
    while True:
",5
"        x = int(mylist.pop())
        if x == 127:
",5
"    return normalize(layout)
",5
"    # KMahjongg
    fd = open(filename)
    fd.readline()
    lines = fd.readlines()
    level = 0
",5
"        row, col, lev = s.split()
        layout.append((int(lev), int(col), int(row)))
",5
"    elif sys.argv[1] in ['m', 'kmahjongg']:
        parse_func = parse_kmahjongg
    elif sys.argv[1] in ['a', 'ace']:
        parse_func = parse_ace
    else:
",5
"        layout = normalize(layout)

",5
"        # print filename, len(layout)
",5
"StatusMsg: ""Installing MS Visual C++ 2010 SP1 Redistributable Package (x86)""; \
Check: not isVCInstalled', file=out)
",5
"  find: TFindRec;
begin
",5
"    Result := False;
  end;
 end;
",5
"#!/usr/bin/env python
# -*- mode: python; coding: koi8-r; -*-
",5
"
import os
import sys
from glob import glob
from math import cos, pi, sin, sqrt
",5
"try:
",5
"    }

all_imgs = False
",5
"            type = cardset_type[l0[3]]
        else:
            # type = 'Unknown'
            type = 'French'
        l1 = lines[1].split(';')
",5
"        name = l1[1].strip()
        l2 = lines[2].split()
",5
"                        neww = int(w*cos(a)+h*sin(a))
                        newh = int(h*cos(a)+w*sin(a))
                        # print w, h, neww, newh
                        d = int(sqrt(w*w+h*h))
",5
"                            tmp.paste(im, (1, 1), im)
                            im = tmp.resize((int(w*z), int(h*z)),
                                            resample=filter)
",5
"                        else:
                            im = im.resize((int(w*z), int(h*z)),
",5
"
                else:
                    zoom_label.config(text='')
                image = ImageTk.tkinter.PhotoImage(im)
            else:
",5
"                image = tkinter.PhotoImage(file=f)
            tk_images.append(image)
            ff = os.path.split(f)[1]
            if pf is None:
",5
"                pf = ff[:2]
                x, y = 10, 10
            elif ff[:2] != pf:
",5
"def zoom_in(*args):
    global zoom
    zoom += 1
    show_cardset()

",5
"    list_box.bind('<<ListboxSelect>>', show_cardset)
",5
"    button.pack(side=tkinter.RIGHT)
    if Image:
        global rotate_var, filter_var
        rotate_var = tkinter.IntVar(root)
",5
"        button.pack(side=tkinter.LEFT, fill='y')
        om = tkinter.OptionMenu(
            b_frame, filter_var,
            'NEAREST', 'BILINEAR', 'BICUBIC', 'ANTIALIAS',
            command=show_cardset)
",5
"        om.pack(side=tkinter.LEFT, fill='y')

        zoom_label = tkinter.Label(b_frame)
        zoom_label.pack(side=tkinter.LEFT)
",5
"    root.title('Show Cardsets')

    return root


",5
"
gc = None

",5
"
def draw_rect():
    global gc
    if gc is None:
",5
"        colormap.alloc_color(color)
        gc.set_rgb_fg_color(color)
    drawing_area.window.draw_rectangle(gc, True, 0, 0, 800, 800)


",5
"def save_image(fn, w, h, x=0, y=0):
",5
"    pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, True, 8, w, h)
    pixbuf.fill(fill_color)
    pb = pixbuf.get_from_drawable(drawing_area.window,
                                  drawing_area.get_colormap(),
",5
"                                  x, y, 0, 0, w, h)
    pb.save(os.path.join(imdir, fn+"".""+imtype), imtype)
    drawing_area.window.clear()
    draw_rect()
",5
"

done = False


",5
"    w, h = 32, 32
    w, h = 24, 24
    for fn, state, shadow in (
        (""tree-n"", gtk.STATE_NORMAL,      gtk.SHADOW_OUT),
",5
"        (""tree-h"", gtk.STATE_PRELIGHT,    gtk.SHADOW_OUT),
        (""tree-p"", gtk.STATE_ACTIVE,      gtk.SHADOW_IN),
",5
"                        None, drawing_area, ""stepper"", 0, 0, w, h)
        save_image(fn, w, h)

    # sizegrip
",5
"    w, h = 16, 16
    fn = 'sizegrip'
    style.paint_resize_grip(drawing_area.window, gtk.STATE_NORMAL, None,
",5
"                             gtk.STATE_PRELIGHT, gtk.SHADOW_NONE,
                             None, progress, ""bar"", 0, 0, w, h)
",5
"    save_image(fn, w, h)

",5
"    # button
    w, h = 32, 32
    w, h = 28, 28
    for fn, state, shadow in (
        (""button-n"", gtk.STATE_NORMAL,      gtk.SHADOW_OUT),
",5
"                    None, togglebutton, ""buttondefault"", 0, 0, w, h)
    save_image(""button-pa"", w, h)
",5
"
    # toolbar
    w, h = 16, 16
    w, h = 24, 24

",5
"        ('ha', msl, sw, gtk.STATE_PRELIGHT,    gtk.ORIENTATION_HORIZONTAL),
        ('hp', msl, sw, gtk.STATE_NORMAL,      gtk.ORIENTATION_HORIZONTAL),
        ('hd', msl, sw, gtk.STATE_INSENSITIVE, gtk.ORIENTATION_HORIZONTAL),

",5
"        else:
            if orient == gtk.ORIENTATION_VERTICAL:
                w, h = h, w
            style.paint_box(drawing_area.window, state, shadow,
                            None, drawing_area, ""stepper"", 0, 0, w, h)
",5
"        save_image(fn, w, h)
",5
"
        (""arrowdown-n"", 0, y1, sn, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
        (""arrowdown-a"", 0, y1, sp, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
        (""arrowdown-p"", 0, y1, sa, gtk.SHADOW_IN,  gtk.ARROW_DOWN, vscroll),
        (""arrowdown-d"", 0, y1, si, gtk.SHADOW_OUT, gtk.ARROW_DOWN, vscroll),
",5
"        (""radio-pc"", gtk.STATE_ACTIVE,      gtk.SHADOW_IN),
        (""radio-pu"", gtk.STATE_ACTIVE,      gtk.SHADOW_OUT),
",5
"        (""radio-dc"", gtk.STATE_INSENSITIVE, gtk.SHADOW_IN),
        (""radio-du"", gtk.STATE_INSENSITIVE, gtk.SHADOW_OUT),
",5
"        style.paint_option(drawing_area.window, state, shadow,
",5
"        (""tab-a"", 2, gtk.STATE_ACTIVE),
            ):
        #  style.paint_box_gap(drawing_area.window, state, shadow,
        #                      gtk.gdk.Rectangle(0, 0,w,gap_h), drawing_area,
",5
"
def pack(w, row, col):
    table.attach(w,
                 col, col+1,              row, row+1,
                 gtk.EXPAND | gtk.FILL,   gtk.EXPAND | gtk.FILL,
",5
"
entry = gtk.Entry()
",5
"row += 1

togglebutton = gtk.ToggleButton()
pack(togglebutton, row, col)
togglebutton.set_active(True)
",5
"row += 1
",5
"    'plyfile',
    'pandas',
",6
"
setup(
    name='torch_geometric',
    version=__version__,
    description='Geometric Deep Learning Extension Library for PyTorch',
",6
"def test_debug():
    assert is_debug_enabled() is False
    set_debug(True)
",6
"        assert is_debug_enabled() is True
    assert is_debug_enabled() is False

    assert is_debug_enabled() is False
",6
"        assert is_debug_enabled() is False
    assert is_debug_enabled() is True
",6
"        assert is_debug_enabled() is True
    assert is_debug_enabled() is False
import torch
",6
"    edge_attr = torch.tensor([[1], [2], [3], [4]])

",6
"    out = sort_edge_index(edge_index, edge_attr)
",6
"
",6
"def test_train_test_split_edges():
    edge_index = torch.tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
                               [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])
    data = Data(edge_index=edge_index)
    data.num_nodes = edge_index.max().item() + 1
",6
"    row = torch.tensor([0, 1, 1, 1, 2, 2, 3, 3, 4, 4])
",6
"
def test_erdos_renyi_graph():
",6
"    ]

    edge_index = erdos_renyi_graph(5, 0.5, directed=True)
    assert edge_index.tolist() == [
        [1, 1, 2, 2, 3, 4, 4, 4],
",6
"def test_stochastic_blockmodel_graph():
    torch.manual_seed(12345)

    block_sizes = [2, 2, 4]
",6
"    edge_index = stochastic_blockmodel_graph(
        block_sizes, edge_probs, directed=False)
    assert edge_index.tolist() == [
        [2, 3, 4, 4, 5, 5, 6, 7, 7, 7],
",6
"    torch.manual_seed(12345)
",6
"    assert edge_index.size() == (2, 26)
import torch
from torch_geometric.utils import (contains_self_loops, remove_self_loops,
                                   segregate_self_loops, add_self_loops,
",6
"def test_contains_self_loops():
    edge_index = torch.tensor([[0, 1, 0], [1, 0, 0]])
",6
"    edge_index = torch.tensor([[0, 1, 1], [1, 0, 2]])
    assert not contains_self_loops(edge_index)


def test_remove_self_loops():
",6
"    assert out[2].tolist() == [[0], [0]]
    assert out[3] is None

    edge_attr = torch.tensor([1, 2, 3])
    out = segregate_self_loops(edge_index, edge_attr)
",6
"
",6
"    adj[edge_index[0], edge_index[1]] = True
",6
"    neg_edge_index = negative_sampling(edge_index, num_neg_samples=2)
    assert neg_edge_index.size(1) <= 2
",6
"
",6
"    i, j, k = structured_negative_sampling(edge_index)
    assert i.size(0) == edge_index.size(1)
",6
"    adj[edge_index[0], edge_index[1]] = True

    neg_adj = torch.zeros(8, 8, dtype=torch.bool)
    neg_adj[neg_edge_index[0], neg_edge_index[1]] = True
",6
"def test_contains_isolated_nodes():
",6
"
    edge_index = torch.tensor([[0, 1, 2, 0], [1, 0, 2, 0]])
",6
"    assert contains_isolated_nodes(edge_index)
",6
"    out, _, mask = remove_isolated_nodes(edge_index)
    assert out.tolist() == [[0, 1, 0], [1, 0, 0]]
    assert mask.tolist() == [1, 1]

    out, _, mask = remove_isolated_nodes(edge_index, num_nodes=3)
",6
"import networkx as nx
from torch_sparse import coalesce

from torch_geometric.data import Data
from torch_geometric.utils import (to_scipy_sparse_matrix,
",6
"
    edge_attr = torch.Tensor([1, 2, 3])
",6
"def test_from_scipy_sparse_matrix():
    edge_index = torch.tensor([[0, 1, 0], [1, 0, 0]])
    adj = to_scipy_sparse_matrix(edge_index)

",6
"def test_to_networkx():
",6
"        G = to_networkx(data, node_attrs=['x', 'pos'], edge_attrs=['weight'],
                        remove_self_loops=remove_self_loops)

        assert G.nodes[0]['x'] == [1, 2]
",6
"def test_to_networkx_undirected():
    x = torch.Tensor([[1, 2], [3, 4]])
",6
"        assert G.nodes[0]['x'] == [1, 2]
",6
"            assert nx.to_numpy_matrix(G).tolist() == [[3, 2], [2, 0]]


def test_from_networkx():
",6
"def test_from_networkx_non_consecutive():
    graph = nx.Graph()
",6
"    pos = torch.tensor([[0, 0, 0], [1, 0, 0], [0, 1, 0], [1, 1, 0]],
                       dtype=torch.float)
    face = torch.tensor([[0, 1, 2], [1, 2, 3]]).t()

",6
"
def test_geodesic_distance():
    pos = torch.Tensor([[0, 0, 0], [2, 0, 0], [0, 2, 0], [2, 2, 0]])
",6
"    face = torch.tensor([[0, 1, 3], [0, 2, 3]]).t()

    out = geodesic_distance(pos, face)
    expected = [
        [0, 1, 1, sqrt(2)],
",6
"    out = geodesic_distance(pos, face, norm=False)
    expected = [
",6
"
    out = geodesic_distance(pos, face, src=src[0:1])
    expected = [0, 1, 1, sqrt(2)]
    assert torch.allclose(out, torch.tensor(expected))

",6
"    out = geodesic_distance(pos, face, dest=dest)
    expected = [0, 0, 0, 0]
    assert torch.allclose(out, torch.Tensor(expected))
",6
"import torch
from torch_geometric.utils import dense_to_sparse
",6
"    edge_index, edge_attr = dense_to_sparse(tensor)

    assert edge_index.tolist() == [[0, 0, 1], [0, 1, 0]]
    assert edge_attr.tolist() == [3, 1, 2]
import torch
",6
"    assert adj.size() == (1, 5, 5)
",6
"        [[7, 8], [9, 10], [11, 12]],
    ]
    assert out.size() == (3, 3, 2)
    assert out.tolist() == expected
",6
"    torch.manual_seed(5)
    out = dropout_adj(edge_index, edge_attr, force_undirected=True)
    assert out[0].tolist() == [[1, 2], [2, 1]]
",6
"
",6
"import torch
from torch_geometric.utils import softmax


",6
"

def test_k_hop_subgraph():
    edge_index = torch.tensor([
        [0, 1, 2, 3, 4, 5],
",6
"        [2, 2, 4, 4, 6, 6],
    ])

    subset, edge_index, mapping, edge_mask = k_hop_subgraph(
",6
"        6, 2, edge_index, relabel_nodes=True)
    assert subset.tolist() == [2, 3, 4, 5, 6]
    assert edge_index.tolist() == [[0, 1, 2, 3], [2, 2, 4, 4]]
    assert mapping.tolist() == [4]
    assert edge_mask.tolist() == [False, False, True, True, True, True]
",6
"                                                            relabel_nodes=True)
",6
"
",6
"    assert accuracy(pred, target) == 0.5
    assert true_positive(pred, target, num_classes=2).tolist() == [1, 1]
",6
"    assert is_undirected(torch.stack([row, col], dim=0))
    assert is_undirected(torch.stack([row, col], dim=0), sym_weight)
    assert not is_undirected(torch.stack([row, col], dim=0), asym_weight)

    row = torch.tensor([0, 1, 1])
",6
"def test_to_undirected():
    row = torch.tensor([0, 1, 1])
    col = torch.tensor([1, 0, 2])

    edge_index = to_undirected(torch.stack([row, col], dim=0))
",6
"
",6
"

def test_one_hot_degree():
    assert OneHotDegree(max_degree=3).__repr__() == 'OneHotDegree(3)'
",6
"    data = Data(edge_index=edge_index, num_nodes=4)
    data = OneHotDegree(max_degree=3)(data)
    assert len(data) == 2
    assert data.edge_index.tolist() == edge_index.tolist()
",6
"    data = Distance(norm=True)(data)
    assert len(data) == 3
",6
"    assert data.pos.tolist() == pos.tolist()
",6
"def test_center():
    assert Center().__repr__() == 'Center()'

    pos = torch.Tensor([[0, 0], [2, 0], [4, 0]])
",6
"
",6
"    data = Data(edge_index=edge_index, pos=pos, edge_attr=edge_attr)
    data = Spherical(norm=True)(data)
    assert len(data) == 3
    assert data.pos.tolist() == pos.tolist()
",6
"    assert data.edge_index.tolist() == edge_index.tolist()
    assert torch.allclose(
        data.edge_attr,
        torch.Tensor([[1, 1, 0, 0.5], [1, 1, 0.5, 0.5]]),
        atol=1e-04)
",6
"
",6
"    data = Spherical(norm=True)(data)
    assert len(data) == 3
    assert data.pos.tolist() == pos.tolist()
",6
"    assert data.edge_index.tolist() == edge_index.tolist()
    assert torch.allclose(
",6
"def test_random_rotate():
    assert RandomRotate([-180, 180]).__repr__() == ('RandomRotate('
                                                    '[-180, 180], axis=0)')

",6
"    data = Data(pos=pos)
",6
"    assert len(data) == 1
    assert data.pos.tolist() == [[-2, -2], [-2, 2], [2, -2], [2, 2]]
import torch
from torch_geometric.data import Data
",6
"                                         avg_degree=2), exact=True)
    data = gdc(data)
",6
"    data = gdc(data)
    mat = to_dense_adj(data.edge_index, edge_attr=data.edge_attr).squeeze()
    assert torch.all(mat >= -1e-8)
    assert torch.allclose(mat, mat.t(), atol=1e-4)

",6
"                                         dim=1), exact=True)
",6
"    data = gdc(data)
",6
"    assert torch.all(mat >= -1e-8)
    assert torch.all(
",6
"              sparsification_kwargs=dict(method='threshold',
",6
"                                         avg_degree=2), exact=False)
    data = gdc(data)
",6
"
def test_face_to_edge():
    assert FaceToEdge().__repr__() == 'FaceToEdge()'

    face = torch.tensor([[0, 0], [1, 1], [2, 3]])
",6
"from torch_geometric.data import Data
",6
"
    data = Data(pos=pos, y=y, batch=batch)
    data = GridSampling(size=5, start=0)(data)
    assert len(data) == 3
",6
"import torch
from torch_geometric.transforms import RemoveIsolatedNodes
",6
"
    edge_index = torch.tensor([[0, 2, 1, 0], [2, 0, 1, 0]])
    edge_attr = torch.tensor([1, 2, 3, 4])
    x = torch.tensor([[1], [2], [3]])
",6
"import torch
from torch_geometric.transforms import AddSelfLoops
from torch_geometric.data import Data

",6
"

def test_laplacian_lambda_max():
",6
"    out = LaplacianLambdaMax().__repr__()
    assert out == 'LaplacianLambdaMax(normalization=None)'

    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)
",6
"    data = Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=3)
    out = LaplacianLambdaMax(normalization='sym', is_undirected=True)(data)
",6
"    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])

    data = Data(edge_index=edge_index, pos=pos)
",6
"    assert data.pos.tolist() == [[-2, 0], [0, 0], [2, 0]]
    assert data.edge_index.tolist() == [[0, 0, 1, 1, 1, 2, 2],
                                        [0, 1, 0, 1, 2, 1, 2]]
",6
"        pos=torch.randn(100, 3), x=torch.randn(100, 16), y=torch.randn(1),
        edge_attr=torch.randn(100, 3))
    out = FixedPoints(50)(data)
    assert len(out) == 4
    assert out.pos.size() == (50, 3)
",6
"import torch
from torch_geometric.transforms import GenerateMeshNormals
from torch_geometric.data import Data
",6
"    assert LocalCartesian().__repr__() == 'LocalCartesian()'

    pos = torch.Tensor([[-1, 0], [0, 0], [2, 0]])
    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])
",6
"    edge_attr = torch.Tensor([1, 1, 1, 1])
",6
"    assert data.edge_attr.tolist() == [[1, 0.5], [0.25, 0.5], [1, 0.5],
                                       [0, 0.5]]

",6
"    assert data.edge_attr.tolist() == [[1, 1, 0.5], [1, 0.25, 0.5],
                                       [1, 1, 0.5], [1, 0, 0.5]]
import torch
from torch_geometric.transforms import RandomTranslate
",6
"    data = Data(pos=pos)
    data = RandomTranslate(0)(data)
    assert len(data) == 1
    assert data.pos.tolist() == pos.tolist()
",6
"
    data = Data(pos=pos)
",6
"from torch_geometric.transforms import Polar
from torch_geometric.data import Data
",6
"from torch_sparse import coalesce


def test_radius_graph():
    assert RadiusGraph(r=1).__repr__() == 'RadiusGraph(r=1)'
",6
"def test_line_graph():
    assert LineGraph().__repr__() == 'LineGraph()'

    # Directed.
    edge_index = torch.tensor([
",6
"

def test_sample_points():
    assert SamplePoints(1024).__repr__() == 'SamplePoints(1024)'

",6
"
def test_constant():
    assert Constant().__repr__() == 'Constant(value=1)'

",6
"    assert data.x.tolist() == [[1], [1], [1]]
",6
"
def test_random_flip():
    assert RandomFlip(axis=0).__repr__() == 'RandomFlip(axis=0, p=0.5)'

",6
"    assert RandomShear(0.1).__repr__() == 'RandomShear(0.1)'

    pos = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])

    data = Data(pos=pos)
",6
"    makedirs(raw_folder)
    makedirs(processed_folder)
    for resource in resources:
",6
"    dataset = MNIST(root, download=False)
",6
"
    dataset.transform = T.Compose([T.ToTensor(), ToSLIC()])

",6
"    data, y = dataset[0]
    assert len(data) == 2
    assert data.pos.dim() == 2 and data.pos.size(1) == 2
    assert data.x.dim() == 2 and data.x.size(1) == 1
    assert data.pos.size(0) == data.x.size(0)
",6
"    assert data.seg.max().item() + 1 == data.x.size(0)
    assert y == 7

",6
"    assert LocalDegreeProfile().__repr__() == 'LocalDegreeProfile()'
",6
"    data = Data(edge_index=edge_index, pos=x)
    data = LocalDegreeProfile()(data)
    assert data.x.tolist() == expected

    data.x = x
",6
"        [0, 1, 2, 3],
        [4, 0, 0, 0],
",6
"    assert data.y.size() == (5, )
",6
"        [6, 0, 0, 0, 0],
        [0, 0, 0, 0, 0],
    ]
    assert data.mask.tolist() == [1, 1, 1, 1, 0]
",6
"from torch_geometric.transforms import LinearTransformation
from torch_geometric.data import Data
",6
"
    data = Data(pos=pos)
    data = transform(data)
    assert len(data) == 1
",6
"
",6
"    assert data.pos.tolist() == pos.tolist()
    assert data.norm.tolist() == norm.tolist()
",6
"    assert data.edge_index.tolist() == edge_index.tolist()
    assert torch.allclose(
",6
"    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])
    edge_attr = torch.Tensor([1, 1, 1, 1])
",6
"    assert len(data) == 3
",6
"    pos = torch.randn((10, 3))

",6
"    assert data.pos.max().item() < 1
from math import sqrt
",6
"    pos = torch.Tensor([[-2, -2], [-1, -1], [0, 0], [1, 1], [2, 2]])
    norm = torch.Tensor([[-1, 1], [-1, 1], [-1, 1], [-1, 1], [-1, 1]])
    data = Data(pos=pos)
",6
"    assert len(data) == 2
",6
"
    expected_pos = torch.Tensor([
        [-2 * sqrt(2), 0],
        [-sqrt(2), 0],
",6
"        [0, 0],
        [sqrt(2), 0],
        [2 * sqrt(2), 0],
    ])
    expected_norm = [[0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]
",6
"    data.norm = norm
    data = NormalizeRotation(max_points=3)(data)
",6
"
def test_two_hop():
    assert TwoHop().__repr__() == 'TwoHop()'

    edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
",6
"    assert len(data) == 2
    assert data.edge_index.tolist() == [[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],
                                        [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2]]
    assert data.edge_attr.tolist() == [1, 2, 3, 1, 0, 0, 2, 0, 0, 3, 0, 0]

",6
"from torch_geometric.transforms import Delaunay
from torch_geometric.data import Data
",6
"

def test_delaunay():
    assert Delaunay().__repr__() == 'Delaunay()'

",6
"    pos = torch.tensor([[-1, -1], [-1, 1], [1, 1]], dtype=torch.float)
    data = Data(pos=pos)
    data = Delaunay()(data)
",6
"    assert len(data) == 2
    assert data.face.tolist() == [[0], [1], [2]]
",6
"    assert data.edge_index.tolist() == [[], []]
import sys
",6
"
def test_read_off():
",6
"    data = read_off(osp.join('test', 'io', 'example2.off'))
",6
"    path = osp.join('/', 'tmp', '{}.off'.format(name))
    write_off(Data(pos=pos, face=face), path)
    data = read_off(path)
    os.unlink(path)

",6
"class Net(torch.nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Net, self).__init__()
",6
"
        def _download(self):
            pass

        def _process(self):
",6
"
    data1 = Data(x=x, edge_index=edge_index, face=face, test_int=i, test_str=s)
    data1.num_nodes = 10

",6
"    assert dataset[0].num_nodes == 10
    assert len(dataset[0]) == 5
    assert dataset[1].num_nodes == 5
",6
"        [1, 0, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 1],
    ])

",6
"        [1, 1, 1, 0, 0, 0],
        [1, 1, 1, 0, 0, 0],
        [1, 0, 0, 1, 1, 1],
        [0, 0, 0, 1, 1, 1],
",6
"    data = cluster_data[1]
",6
"    data = next(iter(loader))
    assert data.x.tolist() == [
",6
"def test_batch():
    torch_geometric.set_debug(True)

    x1 = torch.tensor([1, 2, 3], dtype=torch.float)
",6
"    e1 = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])
    s1 = '1'
    x2 = torch.tensor([1, 2], dtype=torch.float)
    e2 = torch.tensor([[0, 1], [1, 0]])
    s2 = '2'
",6
"    assert len(data_list[0]) == 3
    assert data_list[0].x.tolist() == [1, 2, 3]
    assert data_list[0].edge_index.tolist() == [[0, 1, 1, 2], [1, 0, 2, 1]]
",6
"    assert data_list[0].s == ['1']
",6
"    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])
    face = torch.tensor([[0], [1], [2]])

    data = Data(x=x, edge_index=edge_index, y=2)
    assert data.__repr__() == 'Data(edge_index=[2, 4], x=[3, 1], y=2)'
",6
"    data.face = face
",6
"
    loader = DataLoader([data, data], batch_size=2, shuffle=False)

    for batch in loader:
",6
"    loader = DataLoader([data, data], batch_size=2, shuffle=False,
                        follow_batch=['edge_index'])
",6
"
",6
"    assert len(loader) == 5

    for batch_size, n_id, adjs in loader:
        assert batch_size == 2
",6
"        assert all(np.isin(n_id, torch.arange(10)).tolist())
        assert n_id.unique().size(0) == n_id.size(0)
        for (edge_index, e_id, size) in adjs:
",6
"            assert int(edge_index[0].max() + 1) <= size[0]
",6
"            assert int(edge_index[1].max() + 1) <= size[1]
            assert all(np.isin(e_id, torch.arange(E)).tolist())
            assert e_id.unique().size(0) == e_id.size(0)
            assert size[0] >= size[1]
",6
"    assert len(out) == 3


@pytest.mark.skipif(not with_sample, reason='Latest torch-sparse not found')
def test_cora():
",6
"            return x

        def full(self, x, edge_index):
            for conv in self.convs:
",6
"
    _, n_id, adjs = next(iter(loader))
    out1 = model.batch(data.x[n_id], adjs)
",6
"    assert torch.allclose(out1, out2)

    class GAT(torch.nn.Module):
        def __init__(self, in_channels, out_channels):
            super(SAGE, self).__init__()
",6
"            self.convs.append(GATConv(in_channels, 16, heads=2))
            self.convs.append(GATConv(32, 16, heads=2))
            self.convs.append(GATConv(32, out_channels, heads=2, concat=False))

",6
"
        def full(self, x, edge_index):
            for conv in self.convs:
",6
"
    shutil.rmtree(root)
import torch
from torch_geometric.data import (Data, GraphSAINTNodeSampler,
",6
"        [1, 1, 1, 0, 1, 0],
        [1, 1, 0, 1, 0, 1],
        [1, 0, 1, 0, 1, 0],
        [0, 1, 0, 1, 0, 1],
        [1, 0, 1, 0, 1, 0],
",6
"                                         num_steps=4, log=False)

    for sample in loader:
",6
"        assert sample.edge_norm.numel() == sample.num_edges
",6
"
    assert sorted(data.keys) == ['edge_index', 'x']
    assert len(data) == 2
",6
"
",6
"    assert data.num_faces is None
    assert data.num_node_features == 2
    assert data.num_features == 2

    data.edge_attr = torch.randn(data.num_edges, 2)
",6
"    data.x = None
",6
"    assert data.num_nodes is None
    assert data.num_edges is None

    data.num_nodes = 4
",6
"
#     data, slices = collate_to_set([Data(x1, e1), Data(x2, e2)])

#     assert len(data) == 2
#     assert data.x.tolist() == [1, 2, 3, 1, 2]
",6
"# def test_split_set():
#     output, output_slices = split_set(dataset, slices, torch.tensor([0]))

#     assert len(output) == 2
#     assert output.x.tolist() == x1.tolist()
",6
"#     assert output_slices['x'].tolist() == [0, 3]
#     assert output_slices['edge_index'].tolist() == [0, 4]
import torch
",6
"        super(MyData, self).__init__(x=x, edge_index=edge_index, arg=arg)

    def random(self):
        return torch.randn(list(self.x.size()) + list(self.arg.size()))

",6
"        pass


class MyDataset(Dataset):
",6
"        arg = torch.randn(4, 3)
        return MyData(x, edge_index, arg)


",6
"def test_inherit():
    dataset = MyDataset()
",6
"
",6
"import random
",6
"
    shutil.rmtree(root)
from __future__ import division

import sys
",6
"    assert len(dataset.shuffle(return_perm=True)) == 2
    assert len(dataset[:100]) == 100
",6
"    dataset.transform = ToDense(num_nodes=126)
    loader = DenseDataLoader(dataset, batch_size=len(dataset))
",6
"    shutil.rmtree(root)


",6
"    dataset = TUDataset(root, 'ENZYMES', cleaned=True)
",6
"
    assert len(dataset) == 595

    shutil.rmtree(root)
import sys
",6
"import random
import os.path as osp
import shutil

",6
"    root = osp.join('/', 'tmp', str(random.randrange(sys.maxsize)))
    dataset = TUDataset(root, 'MUTAG')

    assert len(dataset) == 188
",6
"    dataset = TUDataset(root, 'MUTAG', use_node_attr=True)
    assert dataset.num_features == 7

",6
"        assert len(data) == 7
        assert list(data.x.size()) == [data.num_nodes, 3703]
        assert list(data.y.size()) == [data.num_nodes]
",6
"        assert data.is_undirected()

    dataset = Planetoid(root, 'Citeseer', split='full')
    data = dataset[0]
",6
"def test_karate():
    dataset = KarateClub()
",6
"
",6
"    x = torch.randn(10, 4)
",6
"    assert op.__repr__() == 'Reshape(5, 2, 4)'

    assert op(x).size() == (5, 2, 4)
",6
"    assert x.min() >= -0.5
    assert x.max() <= 0.5
",6
"    assert x.max() <= 1.25

    zeros(x)
    assert x.tolist() == [[0, 0, 0, 0]]

",6
"                model = MetaLayer(em, nm, gm)
                out = model(mock.MagicMock(), edge_index=(""row"", ""col""),
                            edge_attr=""edge_attr"", u=""u"",
                            batch=mock.MagicMock())

",6
"
                if em is not None:
                    em.assert_called_once()
",6
"    class GlobalModel(torch.nn.Module):
        def __init__(self):
            super(GlobalModel, self).__init__()
            self.global_mlp = Seq(Lin(20 + 10, 20), ReLU(), Lin(20, 20))

",6
"        def forward(self, x, edge_index, edge_attr, u, batch):
            out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)
            return self.global_mlp(out)

",6
"    op = MetaLayer(EdgeModel(), NodeModel(), GlobalModel())

    x = torch.randn(20, 10)
    edge_attr = torch.randn(40, 5)
",6
"    batch = torch.tensor([0] * 10 + [1] * 10)
    edge_index = torch.randint(0, high=10, size=(2, 20), dtype=torch.long)
    edge_index = torch.cat([edge_index, 10 + edge_index], dim=1)

",6
"
    nn = Seq(Lin(2 * in_channels, 32), ReLU(), Lin(32, out_channels))
",6
"        'DynamicEdgeConv(nn=Sequential(\n'
        '  (0): Linear(in_features=32, out_features=32, bias=True)\n'
        '  (1): ReLU()\n'
        '  (2): Linear(in_features=32, out_features=32, bias=True)\n'
        '), k=6)')
",6
"    assert conv(x).size() == (num_nodes, out_channels)

",6
"
    conv = DynamicEdgeConv(nn, k=6, aggr='max')
",6
"from torch_geometric.nn import FeaStConv


def test_feast_conv():
",6
"
def test_gcn_conv():
    in_channels, out_channels = (16, 32)
    edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
",6
"
",6
"    pseudo = torch.rand((edge_index.size(1), 3))

    conv = GMMConv(in_channels, out_channels, dim=3, kernel_size=25)
    assert conv.__repr__() == 'GMMConv(16, 32)'
",6
"

def test_spline_conv():
",6
"    pseudo = torch.rand((edge_index.size(1), 3))

    conv = SplineConv(in_channels, out_channels, dim=3, kernel_size=5)
    assert conv.__repr__() == 'SplineConv(16, 32, dim=3)'
    with torch_geometric.debug():
",6
"        assert conv(x, edge_index, pseudo).size() == (num_nodes, out_channels)
import torch
from torch_geometric.nn import GCNConv

",6
"
",6
"def test_static_gcn_conv():
    in_channels, out_channels = (16, 32)
",6
"
    conv = GCNConv(in_channels, out_channels, node_dim=1)
",6
"    in_channels, out_channels = (16, 32)
    pos_ei = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    neg_ei = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    num_nodes = pos_ei.max().item() + 1
",6
"    assert conv(x, edge_index, edge_weight,
",6
"
class GCNConv(MessagePassing):
    def __init__(self, in_channels, out_channels):
",6
"        self.lin = torch.nn.Linear(in_channels, out_channels)

    def forward(self, x, edge_index):
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))
",6
"    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j

    def update(self, aggr_out):
",6
"        return aggr_out


def test_create_gnn():
",6
"    num_nodes = edge_index.max().item() + 1
    x = torch.randn((num_nodes, in_channels))

    conv = AGNNConv(requires_grad=True)
    assert conv.__repr__() == 'AGNNConv()'
",6
"def test_point_conv():
    in_channels, out_channels = (16, 32)
    edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
",6
"

",6
"import torch
",6
"    assert conv.__repr__() == 'HypergraphConv(16, 32)'
    out = conv(x, hyperedge_index)
    assert out.size() == (num_nodes, out_channels)
    out = conv(x, hyperedge_index, hyperedge_weight)
",6
"    assert out.size() == (num_nodes, 2 * out_channels)

    conv = HypergraphConv(in_channels,
                          out_channels,
                          use_attention=True,
",6
"                          heads=2,
",6
"import copy
",6
"
import torch
",6
"def test_message_passing_with_edge_index():
    edge_index = torch.tensor([
        [0, 0, 0, 1, 1, 1],
        [0, 1, 2, 0, 1, 2],
    ])
",6
"    out = MessagePassing(flow='target_to_source').propagate(
        edge_index, x=x, size=(2, 3))
    assert out.tolist() == [[6], [6]]
    out = MessagePassing().propagate(adj, x=x)
    assert out.tolist() == [[6], [6]]
",6
"    out = MessagePassing(flow='source_to_target').propagate(edge_index, x=x)
",6
"    x = (torch.Tensor([[1], [2]]), torch.Tensor([[1], [2], [3]]))
",6
"    out = MessagePassing().propagate(adj, x=x)
    assert out.tolist() == [[6], [6]]


class MyConv(MessagePassing):
",6
"    def __init__(self):
",6
"    conv = copy.deepcopy(conv)
    assert conv != conv2
    assert conv.weight.data_ptr != conv2.weight.data_ptr
",6
"import torch
from torch_geometric.nn import LEConv
",6
"    num_nodes = edge_index.max().item() + 1
    x = torch.randn((num_nodes, in_channels))

    conv = LEConv(in_channels, out_channels)
",6
"
    conv = GATConv(in_channels, out_channels, heads=2, concat=False)
    assert conv(x, edge_index).size() == (num_nodes, out_channels)
",6
"    assert conv((x, x), edge_index).size() == (num_nodes, out_channels)

    out = conv(x, edge_index, return_attention_weights=True)
    assert out[0].size() == (num_nodes, out_channels)
    assert out[1][1].size() == (edge_index.size(1) + num_nodes, 2)
",6
"    def forward(self, x, edge_index):
        return self.propagate(edge_index, x=x)


def test_static_graph():
",6
"    data2 = Data(edge_index=edge_index, x=x2)
",6
"        assert out1.size(0) == 6
        conv.node_dim = 1
        out2 = conv(x, edge_index)
        assert out2.size()[:2] == (2, 3)
        assert torch.allclose(out1, out2.view(-1, out2.size(-1)))
",6
"    edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    num_nodes = edge_index.max().item() + 1
    x = torch.randn((num_nodes, in_channels))
",6
"
    conv = GraphConv(in_channels, out_channels)
    assert conv.__repr__() == 'GraphConv(16, 32)'
    assert conv(x, edge_index).size() == (num_nodes, out_channels)
",6
"import torch
from torch_geometric.nn import SAGEConv
",6
"

def test_sage_conv():
",6
"    num_nodes = edge_index.max().item() + 1
    x = torch.randn((4, num_nodes, in_channels))

    conv = MFConv(in_channels, out_channels, node_dim=1)
",6
"import torch
from torch_geometric.nn import RGCNConv


",6
"def test_rgcn_conv():
    in_channels, out_channels = (16, 32)
    num_relations = 8
",6
"    edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])
    num_nodes = edge_index.max().item() + 1
    x = torch.randn((num_nodes, in_channels))
    edge_type = torch.randint(0, num_relations, (edge_index.size(1), ))
",6
"        '))')
    assert conv(x, edge_index, edge_attr).size() == (num_nodes, out_channels)
    conv = GINEConv(nn, train_eps=False)
    assert conv(x, edge_index, edge_attr).size() == (num_nodes, out_channels)

",6
"
def test_gin_conv_on_regular_graph():
    edge_index = torch.tensor([[0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5],
                               [1, 5, 0, 2, 1, 3, 2, 4, 3, 5, 0, 4]])
",6
"import torch
from torch.nn import Sequential as Seq, Linear as Lin, ReLU
",6
"
",6
"    assert conv.__repr__() == (
        'PPFConv(local_nn=Sequential(\n'
        '  (0): Linear(in_features=20, out_features=32, bias=True)\n'
        '  (1): ReLU()\n'
        '  (2): Linear(in_features=32, out_features=32, bias=True)\n'
",6
"        '))')
    assert conv(x, pos, norm, edge_index).size() == (num_nodes, out_channels)
",6
"from torch_geometric.data import Batch
from torch_geometric.nn import avg_pool_x, avg_pool
",6
"

def test_sag_pooling():
    in_channels = 16
",6
"
",6
"    edge_index, edge_attr = filter_adj(edge_index, edge_attr, perm)
",6
"    edge_index = torch.tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],
",6
"    assert pool.__repr__() == 'TopKPooling(16, ratio=0.5, multiplier=1)'

    x, edge_index, _, _, _, _ = pool(x, edge_index)
    assert x.size() == (num_nodes // 2, in_channels)
    assert edge_index.size() == (2, 2)
",6
"
",6
"
    for GNN in [GraphConv, GCNConv]:
        pool = ASAPooling(in_channels, ratio=0.5, GNN=GNN,
",6
"        assert out[1].size() == (2, 2)

        pool = ASAPooling(in_channels, ratio=0.5, GNN=GNN, add_self_loops=True)
        assert pool.__repr__() == ('ASAPooling(16, ratio=0.5)')
",6
"
",6
"    raw = torch.randn(edge_index.size(1))
    e = EdgePooling.compute_edge_score_softmax(raw, edge_index, 6)
",6
"    assert torch.all(e >= 0) and torch.all(e <= 1)

    # Test whether all incoming edge scores sum up to one.
    assert torch.allclose(scatter_add(e, edge_index[1]),
                          torch.Tensor([1, 1, 1, 1, 1, 1]))
",6
"

",6
"    raw = torch.randn(edge_index.size(1))
",6
"    edge_index = torch.tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5],
                               [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2, 5, 4]])
    raw = torch.randn(edge_index.size(1))
    e = EdgePooling.compute_edge_score_sigmoid(raw, edge_index, 6)
    assert torch.all(e >= 0) and torch.all(e <= 1)
",6
"    x = torch.Tensor([[0], [1], [2], [3], [4], [5], [-1]])
    edge_index = torch.tensor([[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5, 6],
",6
"                               [1, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2, 5, 4, 0]])
    batch = torch.tensor([0, 0, 0, 0, 1, 1, 0])

    op = EdgePooling(in_channels=1)
",6
"    op.lin.weight[0, 0] = 1
    op.lin.weight[0, 1] = 1
",6
"
    assert new_x.size(0) == new_batch.size(0) == 4
    assert new_batch.tolist() == [1, 0, 0, 0]
    assert torch.all(new_batch == torch.tensor([1, 0, 0, 0]))
",6
"    batch = torch.tensor([0, 0, 0, 0, 1, 1])
    new_x, new_edge_index, new_batch, _ = op(x, edge_index, batch)
",6
"

",6
"    out = max_pool_x(cluster, x, batch, size=2)
    assert out.tolist() == [[5, 6], [7, 8], [11, 12], [0, 0]]


def test_max_pool():
",6
"
    assert data.x.tolist() == [[5, 6], [7, 8], [11, 12]]
    assert data.pos.tolist() == [[1, 1], [2, 2], [4.5, 4.5]]
",6
"def test_batch_norm():
    norm = BatchNorm(16)
    assert norm.__repr__() == (
",6
"    assert out.size() == (100, 16)

    norm = BatchNorm(16, affine=False, track_running_stats=False)
    out = norm(torch.randn(100, 16))
",6
"

def test_instance_norm():
",6
"    assert torch.allclose(norm1.running_mean, norm2.running_mean, atol=1e-6)
    assert torch.allclose(norm1.running_var, norm2.running_var, atol=1e-6)
",6
"def test_graph_size_norm():
    batch = torch.repeat_interleave(torch.full((10, ), 10, dtype=torch.long))
    norm = GraphSizeNorm()
    out = norm(torch.randn(100, 16), batch)
    assert out.size() == (100, 16)
",6
"    # First graph output has been filled up with zeros.
    assert out[0, -1].tolist() == [0, 0, 0, 0]
",6
"    expected = 4 - torch.arange(5)
    assert out[1, :, -1].argsort().tolist() == expected.tolist()


def test_global_sort_pool_smaller_than_k():
",6
"    out = global_sort_pool(x, batch, k=10)
    assert out.size() == (2, 10 * 4)
",6
"    assert out[1, -1].tolist() == [0, 0, 0, 0]

",6
"    expected = 5 - torch.arange(6)
    assert out[1, :6, -1].argsort().tolist() == expected.tolist()
import torch
from torch_geometric.nn import (global_add_pool, global_mean_pool,
",6
"    N_1, N_2 = 4, 6
    x = torch.randn(N_1 + N_2, 4)
    batch = torch.tensor([0 for _ in range(N_1)] + [1 for _ in range(N_2)])
",6
"    assert out[0].tolist() == x[:4].mean(dim=0).tolist()
",6
"    assert out[1].tolist() == x[4:].mean(dim=0).tolist()
",6
"    batch = torch.cat([torch.zeros(N_1), torch.ones(N_2)]).to(torch.long)
",6
"    perm = torch.randperm(N_1 + N_2)

",6
"    px = x[perm]
",6
"

",6
"    gate_nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, 1))
    nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, channels))

    glob = GlobalAttention(gate_nn, nn)
    assert glob.__repr__() == (
",6
"
def test_set2set():
    set2set = Set2Set(in_channels=2, processing_steps=1)
    assert set2set.__repr__() == 'Set2Set(2, 4)'
",6
"    out_2 = set2set(x_2, batch_2).view(-1)
",6
"from torch_geometric.nn import GraphConv, DenseGraphConv


def test_dense_gcn_conv():
",6
"    # Ensure same weights and bias.
    dense_conv.weight = sparse_conv.weight
",6
"    x = torch.randn((5, channels))
    edge_index = torch.tensor([[0, 0, 1, 1, 2, 2, 3, 4],
",6
"            [1, 0, 1],
            [1, 1, 0],
",6
"        [1, 0, 1],
        [1, 1, 0],
    ])

",6
"    assert conv(x, adj, mask).size() == (batch_size, num_nodes, channels)
",6
"
",6
"
",6
"    assert dense_out[1, 2].abs().sum().item() == 0
    dense_out = dense_out.view(6, channels)[:-1]
",6
"                               [1, 2, 0, 2, 0, 1, 4, 3]])

",6
"    batch_size, num_nodes, channels = 8, 3, 16
    conv = DenseSAGEConv(channels, channels)

",6
"    ])

",6
"
",6
"    x = torch.randn((batch_size, num_nodes, channels))
    adj = torch.rand((batch_size, num_nodes, num_nodes))
    s = torch.randn((batch_size, num_nodes, num_clusters))
    mask = torch.randint(0, 2, (batch_size, num_nodes), dtype=torch.bool)
",6
"
    x, adj, link_loss, ent_loss = dense_diff_pool(x, adj, s, mask)
    assert x.size() == (2, 10, 16)
    assert adj.size() == (2, 10, 10)
    assert link_loss.item() >= 0
",6
"
def test_dense_sage_conv():
    channels = 16
    nn = Seq(Lin(channels, channels), ReLU(), Lin(channels, channels))
",6
"        '  (2): Linear(in_features=16, out_features=16, bias=True)\n'
        '))')
",6
"            [1, 0, 0],
            [0, 0, 0],
        ],
    ])
    mask = torch.tensor([[1, 1, 1], [1, 1, 0]], dtype=torch.bool)
",6
"
    assert dense_out[1, 2].abs().sum().item() == 0
    dense_out = dense_out.view(6, channels)[:-1]
",6
"
    x = model.create_spectral_features(train_pos_index, train_neg_index, 10)
",6
"    z = model(x, train_pos_index, train_neg_index)
    assert z.size() == (10, 16)
",6
"import shutil

",6
"import torch
",6
"            root, pre_transform=RENet.pre_transform(seq_len))
        self.data, self.slices = torch.load(self.processed_paths[0])

",6
"        data_list = super(MyTestEventDataset, self).process()
",6
"        torch.save(self.collate(data_list), self.processed_paths[0])
",6
"    dataset = MyTestEventDataset(root, seq_len=4)
    loader = DataLoader(dataset, 2, follow_batch=['h_sub', 'h_obj'])

",6
"
try:
",6
"    edge_index_dict = {
",6
"        ('author', 'writes', 'paper'):
        torch.tensor([[0, 1, 1, 2], [0, 0, 1, 1]]),
        ('paper', 'written_by', 'author'):
        torch.tensor([[0, 0, 1, 1], [0, 1, 1, 2]])
",6
"    metapath = [
",6
"
    loss = model.loss(pos_rw, neg_rw)
    assert 0 <= loss.item()
",6
"
",6
"        summary=lambda z, *args: z.mean(dim=0),
        corruption=lambda x: x + 1)

    assert model.__repr__() == 'DeepGraphInfomax(16)'
",6
"    assert 0 <= acc and acc <= 1
import torch
from torch_geometric.nn import GNNExplainer, GCNConv
",6
"

",6
"from torch import Tensor as T
",6
"from torch_geometric.nn import GAE, VGAE, ARGA, ARGVA
",6
"    assert adj.tolist() == torch.sigmoid(
        torch.Tensor([[+2, -1, +1], [-1, +5, +4], [+1, +4, +5]])).tolist()

    edge_index = torch.tensor([[0, 1], [1, 2]])
",6
"
def test_vgae():
",6
"    model = VGAE(encoder=lambda x: (x, x))

",6
"    x = torch.Tensor([[1, -1], [1, 2], [2, 1]])
    model.encode(x)
    model.reparametrize(model.__mu__, model.__logvar__)
",6
"
def test_knn_interpolate():
    x = torch.Tensor([[1], [10], [100], [-1], [-10], [-100]])
    pos_x = torch.Tensor([[-1, 0], [0, 0], [1, 0], [-2, 0], [0, 0], [2, 0]])
",6
"    pos_y = torch.Tensor([[-1, -1], [1, 1], [-2, -2], [2, 2]])
    batch_x = torch.tensor([0, 0, 0, 1, 1, 1])
",6
"    version='0.1.0',
    description='PyTorch Geometric Benchmark Suite',
    author='Matthias Fey',
    author_email='matthias.fey@tu-dortmund.de',
    url='https://github.com/rusty1s/pytorch_geometric_benchmark',
",6
"from points.datasets import get_dataset
from points.train_eval import run
",6
"parser.add_argument('--lr', type=float, default=0.001)
parser.add_argument('--lr_decay_factor', type=float, default=0.5)
parser.add_argument('--lr_decay_step_size', type=int, default=50)
parser.add_argument('--weight_decay', type=float, default=0)
",6
"    def __init__(self, num_classes):
        super(Net, self).__init__()

        nn = Seq(Lin(3, 25), ReLU(), Lin(25, 1 * 64))
        self.conv1 = NNConv(1, 64, nn, aggr='mean')
",6
"        self.conv3 = NNConv(64, 128, nn, aggr='mean')

",6
"        self.lin3 = torch.nn.Linear(256, num_classes)

    def forward(self, pos, batch):
        x = pos.new_ones((pos.size(0), 1))

",6
"        radius = 1
        edge_index = radius_graph(pos, r=radius, batch=batch)
        pseudo = pos[edge_index[1]] - pos[edge_index[0]]
        x = F.relu(self.conv3(x, edge_index, pseudo))

",6
"        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.relu(self.lin2(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin3(x)
",6
"parser = argparse.ArgumentParser()
parser.add_argument('--epochs', type=int, default=200)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--lr', type=float, default=0.001)
",6
"
        x = F.relu(self.conv2(x, pos, batch))

",6
"        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin3(x)
",6
"        return F.log_softmax(x, dim=-1)


",6
"        x = F.relu(self.conv1(None, pos, edge_index))

        idx = fps(pos, batch, ratio=0.5)
        x, pos, batch = x[idx], pos[idx], batch[idx]
",6
"        idx = fps(pos, batch, ratio=0.25)
        x, pos, batch = x[idx], pos[idx], batch[idx]
",6
"
        radius = 1
        edge_index = radius_graph(pos, r=radius, batch=batch)
",6
"        x = self.lin3(x)
        return F.log_softmax(x, dim=-1)


",6
"    pre_transform = T.NormalizeScale()
    transform = T.SamplePoints(num_points)

",6
"        path,
",6
"
",6
"from torch_geometric.data import DataLoader

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"        test_acc = test(model, test_loader, device)

",6
"        print('Epoch: {:03d}, Test: {:.4f}, Duration: {:.2f}'.format(
            epoch, test_acc, t_end - t_start))

",6
"    model.train()

    for data in train_loader:
        optimizer.zero_grad()
",6
"
parser = argparse.ArgumentParser()
",6
"parser.add_argument('--weight_decay', type=float, default=0)
args = parser.parse_args()


",6
"    def __init__(self, num_classes):
        super(Net, self).__init__()

",6
"        num_edges += data.num_edges
    for data in test_dataset:
        data = RadiusGraph(0.2)(data)
        num_nodes += data.num_nodes
",6
"
    num_graphs = len(train_dataset) + len(test_dataset)
    print('Graphs', num_graphs)
    print('Nodes', num_nodes / num_graphs)
",6
"
print_dataset(*get_dataset(num_points=1024))
from .datasets import get_dataset
",6
"from .train_eval import run

__all__ = [
",6
"    'run',
]
import time

",6
"        optimizer.step()
",6
"import torch
from torch_geometric.datasets import Planetoid, Entities

from runtime.gcn import GCN
from runtime.gat import GAT
",6
"from runtime.rgcn import RGCN
",6
"for d, Net in product([Cora, CiteSeer, PubMed], [GCN, GAT]):
    model = Net(d.num_features, d.num_classes)
    t = train_runtime(model, d[0], epochs=200, device=device)
",6
"        self.conv2 = GCNConv(16, out_channels, cached=True)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
",6
"import torch
import torch.nn.functional as F
from torch_geometric.nn import GATConv


",6
"    def __init__(self, in_channels, out_channels):
        super(GAT, self).__init__()
",6
"        self.conv1 = GATConv(in_channels, 8, heads=8, dropout=0.6)
        self.conv2 = GATConv(8 * 8, out_channels, dropout=0.6)

    def forward(self, data):
",6
"        x, edge_index = data.x, data.edge_index
        x = F.dropout(x, p=0.6, training=self.training)
        x = F.elu(self.conv1(x, edge_index))
        x = F.dropout(x, p=0.6, training=self.training)
",6
"        self.conv2 = RGCNConv(16, out_channels, num_relations, num_bases=30)

    def forward(self, data):
        edge_index, edge_type = data.edge_index, data.edge_type
        x = F.relu(self.conv1(None, edge_index, edge_type))
",6
"
__all__ = [
    'train_runtime',
]
import time
",6
"    if hasattr(data, 'features'):
        x = torch.tensor(data.features, dtype=torch.float, device=device)
    else:
        x = None
    mask = data.train_mask if hasattr(data, 'train_mask') else data.train_idx
",6
"
    model = model.to(device)
    model.train()
",6
"    if torch.cuda.is_available():
        torch.cuda.synchronize()
    t_start = time.perf_counter()

    for epoch in range(epochs):
",6
"        optimizer.zero_grad()
",6
"from dgl import DGLGraph

from runtime.dgl.gcn import GCN, GCNSPMV
from runtime.dgl.gat import GAT, GATSPMV
from runtime.dgl.rgcn import RGCN, RGCNSPMV
",6
"from runtime.dgl.train import train_runtime
",6
"    CiteSeer = citation_graph.load_citeseer()
    PubMed = citation_graph.load_pubmed()
    MUTAG = load_data('mutag')  # fair comparison
",6
"    norm = torch.pow(g.in_degrees().float(), -0.5)
    norm[torch.isinf(norm)] = 0
",6
"    g.edata.update({'type': edge_type, 'norm': edge_norm})
",6
"
class GCNConv(torch.nn.Module):
    def __init__(self, g, in_channels, out_channels):
",6
"        super(GCNConv, self).__init__()
        self.g = g
        self.weight = Parameter(torch.Tensor(in_channels, out_channels))
        self.bias = Parameter(torch.Tensor(out_channels))
",6
"        glorot(self.weight)
        zeros(self.bias)

    def gcn_msg(self, edge):
        return {'m': edge.src['x'] * edge.src['norm']}
",6
"        x = x + self.bias
",6
"

class GCNSPMVConv(torch.nn.Module):
    def __init__(self, g, in_channels, out_channels):
",6
"        super(GCNSPMVConv, self).__init__()
",6
"import torch
import torch.nn.functional as F
from torch.nn import Parameter
from torch_geometric.nn.inits import glorot, zeros
",6
"        super(GATConv, self).__init__()

        self.g = g
        self.in_channels = in_channels
        self.out_channels = out_channels
",6
"        return {'x': x}

    def forward(self, x):
        x = torch.mm(x, self.weight).view(-1, self.heads, self.out_channels)
",6
"                 out_channels,
                 heads=1,
                 negative_slope=0.2,
                 dropout=0):
",6
"        super(GATSPMVConv, self).__init__()
        self.g = g
        self.out_channels = out_channels
        self.heads = heads
",6
"    def edge_attention(self, edge):
        a = F.leaky_relu(edge.src['a1'] + edge.dst['a2'], self.negative_slope)
        return {'a': a}
",6
"import torch
",6
"        super(RGCNConv, self).__init__()

",6
"
",6
"                w = self.w.view(-1, self.out_channels)
                index = edge.data['type'] * self.in_channels + edge.src['id']
                m = w.index_select(0, index) * edge.data['norm'].unsqueeze(1)
                return {'m': m}
",6
"        self.conv1 = RGCNConv(g, in_channels, 16, num_relations, num_bases=30)
",6
"

",6
"        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_relations = num_relations
",6
"
            def msg_func(edge):
                w = self.w.view(-1, self.out_channels)
                index = edge.data['type'] * self.in_channels + edge.src['id']
                m = w.index_select(0, index) * edge.data['norm'].unsqueeze(1)
",6
"        return F.log_softmax(x, dim=1)
import torch
import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn import SAGEConv, global_mean_pool, JumpingKnowledge
",6
"        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

",6
"        self.convs = torch.nn.ModuleList()
        for i in range(num_layers - 1):
",6
"        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [x]
        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
",6
"        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__
",6
"import torch.nn.functional as F
from torch.nn import Linear, Sequential, ReLU, BatchNorm1d as BN
from torch_geometric.nn import GINConv, global_mean_pool, JumpingKnowledge
",6
"
    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
",6
"        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
",6
"        return F.log_softmax(x, dim=-1)

    def __repr__(self):
",6
"        ),
                             train_eps=False)
",6
"                    Linear(hidden, hidden),
",6
"
    def reset_parameters(self):
",6
"        self.jump.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

",6
"
    def __repr__(self):
        return self.__class__.__name__

",6
"                             train_eps=True)
        self.convs = torch.nn.ModuleList()
",6
"            self.convs.append(
                GINConv(Sequential(
                    Linear(hidden, hidden),
                    ReLU(),
                    Linear(hidden, hidden),
",6
"    def reset_parameters(self):
        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        self.lin1.reset_parameters()
",6
"            x = conv(x, edge_index)
        x = global_mean_pool(x, batch)
",6
"        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

    def __repr__(self):
        return self.__class__.__name__
",6
"            ReLU(),
            BN(hidden),
        ),
                             train_eps=True)
",6
"                    Linear(hidden, hidden),
                    ReLU(),
                    Linear(hidden, hidden),
                    ReLU(),
                    BN(hidden),
",6
"                        train_eps=True))
",6
"
    def reset_parameters(self):
        self.conv1.reset_parameters()
",6
"        self.lin1.reset_parameters()
        self.lin2.reset_parameters()
",6
"        for conv in self.convs:
            x = conv(x, edge_index)
            xs += [x]
",6
"        x = self.jump(xs)
        x = global_mean_pool(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
",6
"import torch.nn.functional as F
",6
"class Set2SetNet(torch.nn.Module):
    def __init__(self, dataset, num_layers, hidden):
        super(Set2SetNet, self).__init__()
        self.conv1 = SAGEConv(dataset.num_features, hidden)
        self.convs = torch.nn.ModuleList()
",6
"        self.lin2 = Linear(hidden, dataset.num_classes)

",6
"        x = F.relu(self.conv1(x, edge_index))
",6
"        xs = [global_mean_pool(x, batch)]
",6
"        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
",6
"import torch
import torch.nn.functional as F
",6
"
",6
"class TopK(torch.nn.Module):
    def __init__(self, dataset, num_layers, hidden, ratio=0.8):
        super(TopK, self).__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
",6
"        self.pools = torch.nn.ModuleList()
        self.convs.extend([
            GraphConv(hidden, hidden, aggr='mean')
",6
"        self.lin1 = Linear(num_layers * hidden, hidden)
",6
"        xs = [global_mean_pool(x, batch)]
        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
",6
"        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

",6
"    def __repr__(self):
",6
"        self.att.reset_parameters()
        self.lin1.reset_parameters()
",6
"        self.lin2.reset_parameters()

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
",6
"        for conv in self.convs:
            x = F.relu(conv(x, edge_index))
        x = self.att(x, batch)
        x = F.relu(self.lin1(x))
        x = F.dropout(x, p=0.5, training=self.training)
",6
"
class ASAP(torch.nn.Module):
    def __init__(self, dataset, num_layers, hidden, ratio=0.8, dropout=0):
",6
"            GraphConv(hidden, hidden, aggr='mean')
            for i in range(num_layers - 1)
",6
"            ASAPooling(hidden, ratio, dropout=dropout)
            for i in range((num_layers) // 2)
        ])
",6
"class NormalizedDegree(object):
",6
"        self.mean = mean
",6
"        self.std = std

",6
"        for data in dataset:
            degs += [degree(data.edge_index[0], dtype=torch.long)]
            max_degree = max(max_degree, degs[-1].max().item())

",6
"        if max_degree < 1000:
            dataset.transform = T.OneHotDegree(max_degree)
        else:
",6
"            dataset.transform = T.Compose(
                [dataset.transform, T.ToDense(num_nodes)])

",6
"            x = F.relu(conv(x, edge_index))
        x = global_sort_pool(x, batch, self.k)
        x = x.view(len(x), self.k, -1).permute(0, 2, 1)
        x = F.relu(self.conv1d(x))
        x = x.view(len(x), -1)
",6
"        x = F.relu(self.lin1(x))
",6
"from edge_pool import EdgePool
from global_attention import GlobalAttentionNet
",6
"from asap import ASAP

",6
"parser = argparse.ArgumentParser()
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--batch_size', type=int, default=128)
parser.add_argument('--lr', type=float, default=0.01)
",6
"args = parser.parse_args()
",6
"nets = [
    GCNWithJK,
",6
"]

",6
"            dataset,
            model,
            folds=10,
            epochs=args.epochs,
",6
"
import torch
import torch.nn.functional as F
from torch import tensor
",6
"    for fold, (train_idx, test_idx,
",6
"
        if 'adj' in train_dataset[0]:
            train_loader = DenseLoader(train_dataset, batch_size, shuffle=True)
            val_loader = DenseLoader(val_dataset, batch_size, shuffle=False)
            test_loader = DenseLoader(test_dataset, batch_size, shuffle=False)
",6
"                'val_loss': val_losses[-1],
                'test_acc': accs[-1],
            }
",6
"                    param_group['lr'] = lr_decay_factor * param_group['lr']

        if torch.cuda.is_available():
            torch.cuda.synchronize()

",6
"    acc_mean = acc.mean().item()
",6
"    acc_std = acc.std().item()
    duration_mean = duration.mean().item()
    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} Â± {:.3f}, Duration: {:.3f}'.
          format(loss_mean, acc_mean, acc_std, duration_mean))

",6
"
",6
"    for data in loader:
",6
"        optimizer.zero_grad()
        data = data.to(device)
",6
"

def eval_loss(model, loader):
    model.eval()
",6
"import torch
import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn import GCNConv, global_mean_pool, JumpingKnowledge
",6
"

class GCN(torch.nn.Module):
    def __init__(self, dataset, num_layers, hidden):
",6
"        self.lin1.reset_parameters()
",6
"
    def forward(self, data):
",6
"    def __init__(self, dataset, num_layers, hidden):
        super(EdgePool, self).__init__()
        self.conv1 = GraphConv(dataset.num_features, hidden, aggr='mean')
        self.convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
",6
"            conv.reset_parameters()
        for pool in self.pools:
            pool.reset_parameters()
        self.lin1.reset_parameters()
",6
"            if i % 2 == 0 and i < len(self.convs) - 1:
",6
"import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn import (GraphConv, SAGPooling, global_mean_pool,
                                JumpingKnowledge)
",6
"        self.conv1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
        for pool in self.pools:
",6
"            pool.reset_parameters()
        self.lin1.reset_parameters()
        self.lin2.reset_parameters()

",6
"    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = F.relu(self.conv1(x, edge_index))
        xs = [global_mean_pool(x, batch)]
",6
"        for i, conv in enumerate(self.convs):
            x = F.relu(conv(x, edge_index))
            xs += [global_mean_pool(x, batch)]
            if i % 2 == 0 and i < len(self.convs) - 1:
",6
"                pool = self.pools[i // 2]
                x, edge_index, _, batch, _, _ = pool(x, edge_index,
                                                     batch=batch)
",6
"__all__ = [
    'get_dataset',
",6
"import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn import DenseSAGEConv, dense_diff_pool, JumpingKnowledge

",6
"        self.conv1 = DenseSAGEConv(in_channels, hidden_channels)
        self.conv2 = DenseSAGEConv(hidden_channels, out_channels)
        self.jump = JumpingKnowledge(mode)
        if mode == 'cat':
",6
"        self.conv1.reset_parameters()
        self.conv2.reset_parameters()
        self.lin.reset_parameters()
",6
"    def forward(self, data):
        x, adj, mask = data.x, data.adj, data.mask

        s = self.pool_block1(x, adj, mask, add_loop=True)
",6
"                x, adj, _, _ = dense_diff_pool(x, adj, s)

        x = self.jump(xs)
        x = F.relu(self.lin1(x))
",6
"        return F.log_softmax(x, dim=-1)
",6
"
    def __repr__(self):
        return self.__class__.__name__
",6
"import argparse
import torch
import torch.nn.functional as F
",6
"    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
",6
"parser.add_argument('--lr', type=float, default=0.01)
parser.add_argument('--weight_decay', type=float, default=0.0005)
",6
"parser.add_argument('--num_stacks', type=int, default=1)
parser.add_argument('--num_layers', type=int, default=1)
parser.add_argument('--shared_weights', type=bool, default=False)
parser.add_argument('--skip_dropout', type=float, default=0.75)
",6
"        self.conv1.reset_parameters()
        self.conv2.reset_parameters()

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
",6
"        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, p=args.dropout, training=self.training)
        x = self.conv2(x, edge_index)
",6
"        return F.log_softmax(x, dim=1)
",6
"    args.early_stopping, permute_masks)
import os.path as osp

from torch_geometric.datasets import Planetoid
import torch_geometric.transforms as T
",6
"
    return dataset
from __future__ import division

",6
"    mask[index] = 1
    return mask


def random_planetoid_splits(data, num_classes):
",6
"        index = (data.y == i).nonzero().view(-1)
        index = index[torch.randperm(index.size(0))]
        indices.append(index)

",6
"    return data
",6
"        t_start = time.perf_counter()
",6
"            if eval_info['val_loss'] < best_val_loss:
                best_val_loss = eval_info['val_loss']
                test_acc = eval_info['test_acc']

",6
"            val_loss_history.append(eval_info['val_loss'])
            if early_stopping > 0 and epoch > epochs // 2:
",6
"    optimizer.step()

",6
"
",6
"        outs['{}_loss'.format(key)] = loss
        outs['{}_acc'.format(key)] = acc

    return outs
import argparse
",6
"parser.add_argument('--normalize_features', type=bool, default=True)
args = parser.parse_args()


class Net(torch.nn.Module):
",6
"import argparse
",6
"parser.add_argument('--epochs', type=int, default=1000)
parser.add_argument('--lr', type=float, default=0.005)
",6
"parser.add_argument('--weight_decay', type=float, default=0.0005)
parser.add_argument('--early_stopping', type=int, default=100)
",6
"dataset = get_planetoid_dataset(args.dataset, args.normalize_features)
",6
"        super(Net, self).__init__()
        self.conv1 = ChebConv(dataset.num_features, args.hidden, args.num_hops)
        self.conv2 = ChebConv(args.hidden, dataset.num_classes, args.num_hops)
",6
"    print('Nodes', data.num_nodes)
",6
"
for name in ['Cora', 'CiteSeer', 'PubMed']:
    print_dataset(get_planetoid_dataset(name))
from .datasets import get_planetoid_dataset
from .train_eval import random_planetoid_splits, run
",6
"        super(Net, self).__init__()
        self.lin1 = Linear(dataset.num_features, args.hidden)
        self.lin2 = Linear(args.hidden, dataset.num_classes)
        self.prop1 = APPNP(args.K, args.alpha)
",6
"    """"""

    def __init__(self):
        self.prev = is_debug_enabled()

",6
"
    def __exit__(self, *args):
        set_debug_enabled(self.prev)
",6
"    def __init__(self, mode):
        self.prev = is_debug_enabled()
",6
"        set_debug_enabled(mode)

",6
"import torch_geometric.transforms
import torch_geometric.utils

__version__ = '1.5.0'
",6
"    <https://arxiv.org/abs/1802.04364>`_ paper.
",6
"        return_vocab (bool, optional): If set to :obj:`True`, will return an
            identifier for each clique (ring, bond, bridged compounds, single).
            (default: :obj:`False`)

    :rtype: (LongTensor, LongTensor, int)
",6
"                if len(set(cliques[c1]) & set(cliques[c2])) > 2:
                    cliques[c1] = set(cliques[c1]) | set(cliques[c2])
                    xs[c1] = 2
",6
"    xs = [x for x in xs if x >= 0]

    # Update `atom2clique` mappings.
",6
"    # Add singleton cliques in case there are more than 2 intersecting
    # cliques. We further compute the ""initial"" clique graph.
",6
"        cs = atom2clique[atom]
        if len(cs) <= 1:
",6
"            c2 = len(cliques) - 1
",6
"
def dropout_adj(edge_index, edge_attr=None, p=0.5, force_undirected=False,
                num_nodes=None, training=True):
",6
"                         'but got {}'.format(p))

",6
"
    if force_undirected:
        row, col, edge_attr = filter_adj(row, col, edge_attr, row < col)

    mask = edge_index.new_full((row.size(0), ), 1 - p, dtype=torch.float)
",6
"
",6
"        dtype (:obj:`torch.dtype`, optional): The desired data type of the
            returned tensor.
",6
"            edge features. (default: :obj:`None`)
        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting
            :obj:`edge_index` will be relabeled to hold consecutive indices
            starting from zero. (default: :obj:`False`)
",6
"        num_nodes (int, optional): The number of nodes, *i.e.*
",6
"    num_nodes = maybe_num_nodes(edge_index, num_nodes)

    assert flow in ['source_to_target', 'target_to_source']
    if flow == 'target_to_source':
        row, col = edge_index
",6
"    else:
        col, row = edge_index

",6
"    for _ in range(num_hops):
        node_mask.fill_(False)
        node_mask[subsets[-1]] = True
        torch.index_select(node_mask, 0, row, out=edge_mask)
        subsets.append(col[edge_mask])
",6
"from .num_nodes import maybe_num_nodes


def sort_edge_index(edge_index, edge_attr=None, num_nodes=None):
    r""""""Row-wise sorts edge indices :obj:`edge_index`.
",6
"            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: (:class:`LongTensor`, :class:`Tensor`)
    """"""
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
",6
"import networkx as nx
",6
"    row, col = edge_index.cpu()

    if edge_attr is None:
",6
"    A = A.tocoo()
",6
"    G.add_nodes_from(range(data.num_nodes))

",6
"        if torch.is_tensor(item):
",6
"        else:
",6
"        if to_undirected and v > u:
            continue

",6
"        if remove_self_loops and u == v:
",6
"
    data['edge_index'] = edge_index.view(2, -1)
    data = torch_geometric.data.Data.from_dict(data)
    data.num_nodes = G.number_of_nodes()

",6
"    return data


",6
"
",6
"    """"""

    if trimesh is None:
        raise ImportError('Package `trimesh` could not be found.')
",6
"

def from_trimesh(mesh):
    r""""""Converts a :obj:`trimesh.Trimesh` to a
",6
"    into positive and negative train/val/test edges, and adds attributes of
    `train_pos_edge_index`, `train_neg_adj_mask`, `val_pos_edge_index`,
    `val_neg_edge_index`, `test_pos_edge_index`, and `test_neg_edge_index`
    to :attr:`data`.
",6
"            edges. (default: :obj:`0.05`)
        test_ratio (float, optional): The ratio of positive test
            edges. (default: :obj:`0.1`)

",6
"    data.edge_index = None
",6
"    # Return upper triangular portion.
    mask = row < col
    row, col = row[mask], col[mask]

",6
"    neg_adj_mask = neg_adj_mask.triu(diagonal=1).to(torch.bool)
    neg_adj_mask[row, col] = 0

    neg_row, neg_col = neg_adj_mask.nonzero().t()
    perm = random.sample(range(neg_row.size(0)),
",6
"    row, col = neg_row[n_v:n_v + n_t], neg_col[n_v:n_v + n_t]
    data.test_neg_edge_index = torch.stack([row, col], dim=0)

    return data
import torch
",6
"    :math:`N_{\max} = \max_i^B N_i`).
    In addition, a second tensor holding
    :math:`[N_1, \ldots, N_B] \in \mathbb{N}^B` is returned.

    Args:
",6
"        fill_value (float, optional): The value for invalid entries in the
            resulting dense output tensor. (default: :obj:`0`)

",6
"
    mask = torch.zeros(batch_size * max_num_nodes, dtype=torch.bool,
                       device=x.device)
    mask[idx] = 1
    mask = mask.view(batch_size, max_num_nodes)
",6
"
    return out, mask
from __future__ import division

",6
"    r""""""Computes the number of false positive predictions.

    Args:
",6
"
",6
"    out = []
    for i in range(num_classes):
        out.append(((pred != i) & (target == i)).sum())
",6
"    :math:`\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}}` of predictions.

",6
"
def f1_score(pred, target, num_classes):
    r""""""Computes the :math:`F_1` score
    :math:`2 \cdot \frac{\mathrm{precision} \cdot \mathrm{recall}}
    {\mathrm{precision}+\mathrm{recall}}` of predictions.
",6
"        target (Tensor): The targets.
        num_classes (int): The number of classes.
",6
"
    :rtype: :class:`Tensor`
    """"""
    prec = precision(pred, target, num_classes)
",6
"
    return score


",6
"        batch (LongTensor): The assignment vector which maps each pred-target
            pair to an example.

    :rtype: (:class:`LongTensor`, :class:`LongTensor`)
",6
"        target (LongTensor): The targets.
        num_classes (int): The number of classes.
        batch (LongTensor): The assignment vector which maps each pred-target
",6
"    node-pairs.

",6
"            up runtime dramatically. (default: :obj:`None`)
        num_workers (int, optional): How many subprocesses to use for
            calculating geodesic distances.
",6
"
    dtype = pos.dtype

    pos = pos.detach().cpu().to(torch.double).numpy()
",6
"        src = np.arange(pos.shape[0], dtype=np.int32)
    else:
        src = src.detach().cpu().to(torch.int).numpy()

    dest = None if dest is None else dest.detach().cpu().to(torch.int).numpy()
",6
"                [(pos, face, src, dest, max_distance, norm, i, dtype)
",6
"    if dest is None:
        out = out.view(-1, pos.shape[0])
",6
"    return torch.from_numpy(out).to(dtype)
import torch

",6
"    Args:
        edge_index (LongTensor): The edge indices.
        edge_attr (Tensor, optional): Edge weights or multi-dimensional
            edge features. (default: :obj:`None`)
",6
"
    :rtype: (:class:`LongTensor`, :class:`Tensor`)
    """"""
    row, col = edge_index
",6
"    edge_index = edge_index[:, mask]

    return edge_index, edge_attr
",6
"
",6
"    loop_index = torch.arange(0, num_nodes, dtype=torch.long,
",6
"        loop_weight = edge_weight.new_full((num_nodes, ), fill_value)
        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)

",6
"    non-existent self-loops will be added with edge weights denoted by
    :obj:`fill_value`.

",6
"        assert edge_weight.numel() == edge_index.size(1)
        inv_mask = ~mask

        loop_weight = torch.full(
",6
"            loop_weight[row[inv_mask]] = remaining_edge_weight
        edge_weight = torch.cat([edge_weight[mask], loop_weight], dim=0)
",6
"
    loop_index = torch.arange(0, num_nodes, dtype=row.dtype, device=row.device)
    loop_index = loop_index.unsqueeze(0).repeat(2, 1)
    edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)

",6
"    return out
",6
"    undirected.
",6
"            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

    :rtype: bool
    """"""
    num_nodes = maybe_num_nodes(edge_index, num_nodes)
",6
"                   add_remaining_self_loops)
from .isolated import contains_isolated_nodes, remove_isolated_nodes
from .subgraph import subgraph, k_hop_subgraph
from .get_laplacian import get_laplacian
from .to_dense_batch import to_dense_batch
",6
"from .tree_decomposition import tree_decomposition
from .convert import to_scipy_sparse_matrix, from_scipy_sparse_matrix
from .convert import to_networkx, from_networkx
",6
"    'get_laplacian',
",6
"    'precision',
    'recall',
    'f1_score',
",6
"    return index, value
",6
"

def negative_sampling(edge_index, num_nodes=None, num_neg_samples=None,
",6
"
    Args:
",6
"            negative edge for every positive edge. (default: :obj:`None`)
        method (string, optional): The method to use for negative sampling,
            *i.e.*, :obj:`""sparse""` or :obj:`""dense""`.
",6
"    size = num_nodes * num_nodes
    num_neg_samples = min(num_neg_samples, size - edge_index.size(1))

    row, col = edge_index

",6
"    if force_undirected:
",6
"        idx = row * num_nodes + col - row * (row + 1) // 2
    else:
        idx = row * num_nodes + col
",6
"        # (-sqrt((2 * N + 1)^2 - 8 * perm) + 2 * N + 1) / 2
        row = torch.floor((-torch.sqrt((2. * num_nodes + 1.)**2 - 8. * perm) +
                           2 * num_nodes + 1) / 2)
        col = perm - row * (2 * num_nodes - row - 1) // 2
",6
"        neg_edge_index = torch.stack([row, col], dim=0).long()
        neg_edge_index = to_undirected(neg_edge_index)
",6
"        idx_2 = i[rest] * num_nodes + tmp
        mask = torch.from_numpy(np.isin(idx_2, idx_1)).to(torch.bool)
        k[rest] = tmp
        rest = rest[mask.nonzero().view(-1)]

",6
"            for every positive edge. (default: :obj:`None`)
        method (string, optional): The method to use for negative sampling,
",6
"
    edge_index = grid_index(height, width, device)
    pos = grid_pos(height, width, dtype, device)
    return edge_index, pos

",6
"    return torch.stack([x, y], dim=-1)
",6
"import torch
from torch_scatter import scatter_add


def to_dense_adj(edge_index, batch=None, edge_attr=None):
",6
"    dtype = torch.float if edge_attr is None else edge_attr.dtype
    adj = torch.zeros(size, dtype=dtype, device=edge_index.device)

    edge_index_0 = batch[edge_index[0]].view(1, -1)
",6
"        edge_attr (Tensor): Edge weights or multi-dimensional edge features.
        num_nodes (int, optional): The number of nodes, *i.e.*
            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)

",6
"    # Filter edges.
    mask = torch.rand(idx.size(0)) < edge_prob
    idx = idx[mask]
",6
"        row, col = idx / num_nodes, idx % num_nodes
    else:
        row, col = torch.combinations(torch.arange(num_nodes)).t()

",6
"    mask = torch.bernoulli(prob[node_idx[row], node_idx[col]]).to(torch.bool)
    edge_index = torch.stack([row[mask], col[mask]], dim=0)
",6
"
    Args:
        num_nodes (int): The number of nodes.
",6
"from .num_nodes import maybe_num_nodes_dict


def group_hetero_graph(edge_index_dict, num_nodes_dict=None):
    num_nodes_dict = maybe_num_nodes_dict(edge_index_dict, num_nodes_dict)
",6
"    local2global = {}
    for i, (key, N) in enumerate(num_nodes_dict.items()):
        key2int[key] = i
        node_types.append(tmp.new_full((N, ), i))
",6
"    edge_type = torch.cat(edge_types, dim=0)

    return (edge_index, edge_type, node_type, local_node_idx, local2global,
            key2int)
from copy import copy
",6
"

def maybe_num_nodes_dict(edge_index_dict, num_nodes_dict=None):
    num_nodes_dict = {} if num_nodes_dict is None else copy(num_nodes_dict)
",6
"    if (len(src) < length):
        return src + list(itertools.repeat(src[-1], length - len(src)))
    return src
",6
"

",6
"def get_laplacian(edge_index, edge_weight=None, normalization=None, dtype=None,
",6
"                  num_nodes=None):
",6
"        edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]
",6
"
        # L = I - A_norm.
        edge_index, edge_weight = add_self_loops(edge_index, -edge_weight,
",6
"        self.cat = cat
",6
"            data.edge_attr = deg

",6
"        return data

",6
"    def __init__(self,
                 k=6,
                 loop=False,
                 force_undirected=False,
",6
"        self.flow = flow

    def __call__(self, data):
",6
"        data.edge_attr = None
        batch = data.batch if 'batch' in data else None
        edge_index = knn_graph(
            data.pos, self.k, batch, loop=self.loop, flow=self.flow)

",6
"
        return data
",6
"

class GridSampling(object):
",6
"        cluster = voxel_grid(data.pos, batch, self.size, self.start, self.end)
        cluster, perm = consecutive_cluster(cluster)

        for key, item in data:
            if bool(re.search('edge', key)):
",6
"
",6
"    Args:
        value (int, optional): The value to add. (default: :obj:`1`)
",6
"        self.value = value
",6
"    r""""""Saves the relative Cartesian coordinates of linked nodes in its edge
    attributes.

",6
"    Args:
",6
"        cat (bool, optional): If set to :obj:`False`, all existing edge
            attributes will be replaced. (default: :obj:`True`)
    """"""
    def __init__(self, norm=True, max_value=None, cat=True):
        self.norm = norm
",6
"        self.max = max_value
        self.cat = cat

",6
"
        cart = pos[col] - pos[row]
        cart = cart.view(-1, 1) if cart.dim() == 1 else cart

",6
"            data.edge_attr = torch.cat([pseudo, cart.type_as(pseudo)], dim=-1)
        else:
",6
"            data.edge_attr = cart

",6
"        return data

",6
"    def __repr__(self):
        return '{}(norm={}, max_value={})'.format(self.__class__.__name__,
                                                  self.norm, self.max)
import torch
",6
"    def __call__(self, data):
        edge_index, edge_attr = data.edge_index, data.edge_attr
        N = data.num_nodes

",6
"        value = edge_index.new_ones((edge_index.size(1), ), dtype=torch.float)

        index, value = spspmm(edge_index, value, edge_index, value, N, N, N)
        value.fill_(0)
        index, value = remove_self_loops(index, value)
",6
"            value = value.view(-1, *[1 for _ in range(edge_attr.dim() - 1)])
",6
"import random


",6
"        return data

    def __repr__(self):
        return '{}(axis={}, p={})'.format(self.__class__.__name__, self.axis,
                                          self.p)
",6
"        if data.pos.size(0) == 2:
            data.edge_index = torch.tensor([[0, 1], [1, 0]], dtype=torch.long,
",6
"
            data.face = face.t().contiguous().to(data.pos.device, torch.long)

        return data
",6
"        return '{}()'.format(self.__class__.__name__)
import torch
import torch.nn.functional as F
from torch_scatter import scatter_add
",6
"        assert 'face' in data
        pos, face = data.pos, data.face

        vec1 = pos[face[1]] - pos[face[0]]
        vec2 = pos[face[2]] - pos[face[0]]
",6
"        return '{}()'.format(self.__class__.__name__)
",6
"import torch
from torch_geometric.transforms import LinearTransformation


class RandomShear(object):
",6
"
    def __call__(self, data):
        dim = data.pos.size(-1)
",6
"        self.cat = cat
",6
"            data.edge_attr = torch.cat([pseudo, cart.type_as(pseudo)], dim=-1)
        else:
            data.edge_attr = cart

",6
"            expects undirected graphs as input, and can hence speed up the
            computation of the largest eigenvalue. (default: :obj:`False`)
    """"""

",6
"
        eig_fn = eigs
        if self.is_undirected and self.normalization != 'rw':
",6
"
",6
"    def __repr__(self):
        return '{}(normalization={})'.format(self.__class__.__name__,
",6
"                                             self.normalization)
import torch


class SamplePoints(object):
",6
"    r""""""Uniformly samples :obj:`num` points on the mesh faces according to
",6
"        mask = frac.sum(dim=-1) > 1
        frac[mask] = 1 - frac[mask]

        vec1 = pos[face[1]] - pos[face[0]]
        vec2 = pos[face[2]] - pos[face[0]]
",6
"
        if self.include_normals:
            data.norm = torch.nn.functional.normalize(vec1.cross(vec2), p=2)

        pos_sampled = pos[face[0]]
",6
"
        edge_index, _ = add_self_loops(edge_index, num_nodes=N)
",6
"

class GDC(object):
    r""""""Processes the graph via Graph Diffusion Convolution (GDC) from the
",6
"        normalization_in (str, optional): Normalization of the transition
            matrix on the original (input) graph. Possible values:
",6
"            (default: :obj:`""col""`)
        diffusion_kwargs (dict, optional): Dictionary containing the parameters
",6
"            :obj:`""heat""` or :obj:`""coeff""`).
            Each diffusion method requires different additional parameters.
",6
"        exact (bool, optional): Whether to exactly calculate the diffusion
            matrix.
            Note that the exact variants are not scalable.
            They densify the adjacency matrix and calculate either its inverse
",6
"
        if self_loop_weight:
",6
"            edge_index, edge_weight = self.transition_matrix(
                edge_index, edge_weight, N, self.normalization_in)
            diff_mat = self.diffusion_matrix_exact(edge_index, edge_weight, N,
                                                   **self.diffusion_kwargs)
            edge_index, edge_weight = self.sparsify_dense(
",6
"        data.edge_attr = edge_weight

",6
"        r""""""Calculate the approximate, sparse diffusion on a given sparse
        matrix.
",6
"
                1. :obj:`""sym""`: Symmetric normalization
                   :math:`\mathbf{T} = \mathbf{D}^{-1/2} \mathbf{A}
                   \mathbf{D}^{-1/2}`.
                2. :obj:`""col""`: Column-wise normalization
",6
"            deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)
",6
"        elif normalization == 'col':
            _, col = edge_index
            deg = scatter_add(edge_weight, col, dim=0, dim_size=num_nodes)
",6
"
                1. :obj:`""ppr""`: Use personalized PageRank as diffusion.
                   Additionally expects the parameter:

",6
"            # Assumes coalesced edge_index.
            _, indptr, out_degree = np.unique(edge_index_np[0],
                                              return_index=True,
",6
"                     'non-exact GDC computation.').format(normalization))

",6
"
        Args:
            matrix (Tensor): Matrix to sparsify.
",6
"                     :obj:`eps` required to achieve a given :obj:`avg_degree`.

                2. :obj:`""topk""`: Keep edges with top :obj:`k` edge weights per
",6
"        :rtype: (:class:`LongTensor`, :class:`Tensor`)
        """"""
        assert matrix.shape[0] == matrix.shape[1]
        N = matrix.shape[1]
",6
"            assert kwargs['dim'] in [0, 1]
",6
"            edge_weight (Tensor): One-dimensional edge weights.
            num_nodes (int): Number of nodes.
            method (str): Method of sparsification:
",6
"        else:
",6
"            diff_mat_np = expm(matrix.cpu().numpy())
            diff_mat = torch.Tensor(diff_mat_np).to(matrix.device)
        return diff_mat
",6
"            return -np.inf

        left = sorted_edges[avg_degree * num_nodes - 1]
",6
"                (default: :obj:`""cpu""`)

        :rtype: (:class:`LongTensor`, :class:`Tensor`)
        """"""
",6
"        else:
            raise ValueError(
                f""PPR matrix normalization {normalization} unknown."")
",6
"                        r[vnode] = _val

                    res_vnode = r[vnode] if vnode in r else 0
                    if res_vnode >= alpha_eps * out_degree[vnode]:
",6
"        replace (bool, optional): If set to :obj:`False`, samples fixed
            points without replacement. In case :obj:`num` is greater than
            the number of points, duplicated points are kept to a
",6
"        r (float): The distance.
        loop (bool, optional): If :obj:`True`, the graph will contain
            self-loops. (default: :obj:`False`)
",6
"            :obj:`""target_to_source""`). (default: :obj:`""source_to_target""`)
    """"""

",6
"                 loop=False,
                 max_num_neighbors=32,
",6
"            of nodes will get automatically inferred. (default: :obj:`None`)
    """"""
    def __init__(self, num_nodes=None):
        self.num_nodes = num_nodes
",6
"
    def __call__(self, data):
        assert data.edge_index is not None

        orig_num_nodes = data.num_nodes
",6
"        if x is not None and self.cat:
            x = x.view(-1, 1) if x.dim() == 1 else x
            data.x = torch.cat([x, deg.to(x.dtype)], dim=-1)
",6
"    If the data additionally holds normals saved in :obj:`data.norm` these will
    be also rotated.

    Args:
",6
"        max_points (int, optional): If set to a value greater than :obj:`0`,
            only a random number of :obj:`max_points` points are sampled and
            used to compute eigenvectors. (default: :obj:`-1`)
    """"""
",6
"        C = torch.matmul(pos.t(), pos)
        e, v = torch.eig(C, eigenvectors=True)  # v[:,j] is j-th eigenvector

        data.pos = torch.matmul(data.pos, v)
",6
"
",6
"            data.norm = F.normalize(torch.matmul(data.norm, v))
",6
"        N = data.num_nodes
        edge_index, edge_attr = data.edge_index, data.edge_attr
        (row, col), edge_attr = coalesce(edge_index, edge_attr, N, N)

",6
"            data.edge_index = torch.stack([row, col], dim=0)
",6
"                return torch.stack([row, col], dim=0)
",6
"            N = row.size(0) // 2
            joints, _ = coalesce(joints, None, N, N)

",6
"        cat (bool, optional): If set to :obj:`False`, all existing edge
            attributes will be replaced. (default: :obj:`True`)
    """"""
    def __init__(self, norm=True, max_value=None, cat=True):
",6
"            dist = dist / (dist.max() if self.max is None else self.max)

        if pseudo is not None and self.cat:
",6
"            pseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo
            data.edge_attr = torch.cat([pseudo, dist.type_as(pseudo)], dim=-1)
        else:
",6
"            data.edge_attr = dist

        return data

    def __repr__(self):
",6
"            degrees = (-abs(degrees), abs(degrees))
        assert isinstance(degrees, (tuple, list)) and len(degrees) == 2
        self.degrees = degrees
",6
"        self.axis = axis

    def __call__(self, data):
        degree = math.pi * random.uniform(*self.degrees) / 180.0
",6
"        sin, cos = math.sin(degree), math.cos(degree)
",6
"
        if data.pos.size(-1) == 2:
",6
"                matrix = [[cos, sin, 0], [-sin, cos, 0], [0, 0, 1]]
        return LinearTransformation(torch.tensor(matrix))(data)
",6
"
        x = torch.stack([deg, min_deg, max_deg, mean_deg, std_deg], dim=1)

",6
"
        return data

    def __repr__(self):
        return '{}()'.format(self.__class__.__name__)
",6
"import torch
from torch_geometric.nn.conv.ppf_conv import point_pair_features

",6
"
    of linked nodes in its edge attributes, where :math:`\mathbf{d}_{j,i}`
    denotes the difference vector between, and :math:`\mathbf{n}_i` and
",6
"            attributes will be replaced. (default: :obj:`True`)
    """"""

    def __init__(self, cat=True):
        self.cat = cat
",6
"            data.edge_attr = ppf
",6
"            will not be removed.
",6
"from itertools import repeat

import torch

",6
"    r""""""Translates node positions by randomly sampled translation values
    within a given interval. In contrast to other random transformations,
",6
"from .linear_transformation import LinearTransformation
from .random_scale import RandomScale
from .random_rotate import RandomRotate
from .random_shear import RandomShear
from .normalize_features import NormalizeFeatures
",6
"from .radius_graph import RadiusGraph
from .face_to_edge import FaceToEdge
",6
"from .line_graph import LineGraph
from .laplacian_lambda_max import LaplacianLambdaMax
",6
"    'LocalDegreeProfile',
    'Center',
",6
"    'AddSelfLoops',
    'RemoveIsolatedNodes',
    'KNNGraph',
    'RadiusGraph',
",6
"    'FaceToEdge',
    'SamplePoints',
    'FixedPoints',
    'ToDense',
",6
"
class RandomScale(object):
",6
"    given interval, *e.g.*, resulting in the transformation matrix

    .. math::
        \begin{bmatrix}
",6
"    r""""""Saves the spherical coordinates of linked nodes in its edge attributes.

    Args:
        norm (bool, optional): If set to :obj:`False`, the output will not be
",6
"    def __init__(self, norm=True, max_value=None, cat=True):
        self.norm = norm
        self.max = max_value
        self.cat = cat

",6
"        (row, col), pos, pseudo = data.edge_index, data.pos, data.edge_attr
        assert pos.dim() == 2 and pos.size(1) == 3

        cart = pos[col] - pos[row]
",6
"
        theta = torch.atan2(cart[..., 1], cart[..., 0]).view(-1, 1)
        theta = theta + (theta < 0).type_as(theta) * (2 * PI)

",6
"        assert matrix.size(0) == matrix.size(1), (
            'Transformation matrix should be square. Got [{} x {}] rectangular'
            'matrix.'.format(*matrix.size()))

        self.matrix = matrix
",6
"
    def __call__(self, data):
",6
"        polar = torch.cat([rho, theta], dim=-1)

        if pseudo is not None and self.cat:
            pseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo
",6
"
",6
"    Args:
",6
"    """"""
    def __init__(self, add_seg=False, add_img=False, **kwargs):
",6
"        data = Data(x=x, pos=pos)

        if self.add_seg:
",6
"    if not len(faces) or not len(vertices):
        return None

    pos = torch.tensor(vertices, dtype=torch.float)
",6
"    face = torch.tensor(faces, dtype=torch.long).t().contiguous()
",6
"
",6
"        src = src[1:]
    else:
        src[0] = src[0][3:]

    num_nodes, num_faces = [int(item) for item in src[0].split()[:2]]
",6
"
def read_off(path):
    r""""""Reads an OFF (Object File Format) file, returning both the position of
",6
"    """"""
",6
"    with open(path, 'r') as f:
        src = f.read().split('\n')[:-1]
    return parse_off(src)
",6
"    r""""""Writes a :class:`torch_geometric.data.Data` object to an OFF (Object
    File Format) file.

    Args:
",6
"
def read_txt_array(path, sep=None, start=0, end=None, dtype=None, device=None):
    with open(path, 'r') as f:
",6
"        src = f.read().split('\n')[:-1]
",6
"        return parse_npz(f)


def parse_npz(f):
    x = sp.csr_matrix((f['attr_data'], f['attr_indices'], f['attr_indptr']),
",6
"
names = [
    'A', 'graph_indicator', 'node_labels', 'node_attributes'
    'edge_labels', 'edge_attributes', 'graph_labels', 'graph_attributes'
",6
"    names = [f.split(os.sep)[-1][len(prefix) + 1:-4] for f in files]

    edge_index = read_file(folder, prefix, 'A', torch.long).t() - 1
    batch = read_file(folder, prefix, 'graph_indicator', torch.long) - 1
",6
"
    edge_attributes, edge_labels = None, None
",6
"    if 'graph_attributes' in names:  # Regression problem.
        y = read_file(folder, prefix, 'graph_attributes')
    elif 'graph_labels' in names:  # Classification problem.
        y = read_file(folder, prefix, 'graph_labels', torch.long)
        _, y = y.unique(sorted=True, return_inverse=True)
",6
"    edge_slice = torch.cumsum(torch.from_numpy(np.bincount(batch[row])), 0)
",6
"
    slices = {'edge_index': edge_slice}
",6
"    if data.x is not None:
        slices['x'] = node_slice
    if data.edge_attr is not None:
        slices['edge_attr'] = edge_slice
    if data.y is not None:
",6
"    with open(path, 'rb') as f:
        data = PlyData.read(f)

    pos = ([torch.tensor(data['vertex'][axis]) for axis in ['x', 'y', 'z']])
    pos = torch.stack(pos, dim=-1)
",6
"        tx_ext = torch.zeros(len_test_indices, tx.size(1))
        tx_ext[sorted_test_index - test_index.min(), :] = tx
",6
"        ty_ext = torch.zeros(len_test_indices, ty.size(1))
        ty_ext[sorted_test_index - test_index.min(), :] = ty

        tx, ty = tx_ext, ty_ext

",6
"            out = pickle.load(f)

",6
"from .obj import read_obj
from .sdf import read_sdf, parse_sdf
from .off import read_off, write_off
from .npz import read_npz, parse_npz
",6
"    'read_ply',
    'read_obj',
    'read_sdf',
    'parse_sdf',
",6
"    'read_npz',
    'parse_npz',
]
",6
"import torch
import torch.nn.functional as F
from torch_sparse import coalesce
from torch_geometric.io import parse_txt_array
from torch_geometric.data import Data
",6
"
def influence(model, src, *args):
    x = src.clone().requires_grad_()
    out = model(x, *args).sum(dim=-1)

",6
"    influences = []
    for j in range(src.size(0)):
",6
"        influences.append(influence / influence.sum())

    return torch.stack(influences, dim=0)
",6
"from typing import List

import copy
",6
"import torch
",6
"import torch.utils.data
",6
"    <https://arxiv.org/abs/1905.07953>`_ paper.

    Args:
        data (torch_geometric.data.Data): The graph data object.
",6
"            recursive bisection instead of multilevel k-way partitioning.
            (default: :obj:`False`)
        save_dir (string, optional): If set, will save the partitioned data to
            the :obj:`save_dir` directory for faster re-use.
",6
"            progress. (default: :obj:`True`)
",6
"        path = osp.join(save_dir or '', filename)
        if save_dir is not None and osp.exists(path):
",6
"            if log:  # pragma: no cover
                print('Done!')

",6
"        self.data = self.__permute_data__(data, perm, adj)
        self.partptr = partptr
",6
"    def __permute_data__(self, data, perm, adj):
        data = copy.copy(data)
        num_nodes = data.num_nodes
",6
"        data.edge_attr = value

        return data

",6
"        form mini-batches of clusters.
        For an example of using Cluster-GCN, see `examples/cluster_gcn.py
        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/
        cluster_gcn.py>`_.
",6
"
    Args:
        cluster_data (torch_geometric.data.ClusterData): The already
",6
"            partioned data object.
        batch_size (int, optional): How many samples per batch to load.
            (default: :obj:`1`)
",6
"        shuffle (bool, optional): If set to :obj:`True`, the data will be
",6
"                num_nodes = data.num_nodes
                for key, item in data:
",6
"
            data = cluster_data.data.__class__()
            data.num_nodes = adj.size(0)
",6
"            data.edge_index = torch.stack([row, col], dim=0)
",6
"                else:
                    data[key] = torch.cat([d[key] for d in data_list],
                                          dim=ref.__cat_dim__(key, ref[key]))
",6
"
",6
"    e_id: torch.Tensor
    size: Tuple[int, int]

    def to(self, *args, **kwargs):
        return Adj(self.edge_index.to(*args, **kwargs),
",6
"    r""""""The neighbor sampler from the `""Inductive Representation Learning on
    Large Graphs"" <https://arxiv.org/abs/1706.02216>`_ paper, which allows
    for mini-batch training of GNNs on large-scale graphs where full-batch
    training is not feasible.
",6
"    The actual computation graphs are then returned in reverse-mode, meaning
    that we pass messages from a larger set of nodes to a smaller one, until we
",6
"    reach the nodes for which we originally wanted to compute embeddings.

",6
"    computation, and a list of bipartite graph objects via the tuple
    :obj:`(edge_index, e_id, size)`, where :obj:`edge_index` represents the
",6
"    bipartite edges between source and target nodes, :obj:`e_id` denotes the
",6
"        edge_index (LongTensor): The edge indices of the full-graph.
        size ([int]): The number of neighbors to
            sample for each node in each layer. If set to :obj:`sizes[i] = -1`,
",6
"            all neighbors are included in layer :obj:`l`.
        node_idx (LongTensor, optional): The nodes that should be considered
            for creating mini-batches. If set to :obj:`None`, all nodes will be
            considered.
",6
"
        if node_idx is None:
",6
"        assert self.flow in ['source_to_target', 'target_to_source']

",6
"        super(NeighborSampler, self).__init__(node_idx.tolist(),
                                              collate_fn=self.sample, **kwargs)

    def sample(self, batch):
        if not isinstance(batch, torch.Tensor):
",6
"import copy
import warnings

import torch
import torch_geometric
",6
"        out = '{\n' + ',\n'.join(lines) + '\n' + indent_str + '}'
",6
"    else:
        out = str(item)

    return f'{indent_str}{key}={out}'

",6
"            (default: :obj:`None`)
        pos (Tensor, optional): Node position matrix with shape
",6
"            :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)
        norm (Tensor, optional): Normal vector matrix with shape
            :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)
        face (LongTensor, optional): Face adjacency matrix with shape
",6
"                 f'found type `{edge_index.dtype}`.'))

        if face is not None and face.dtype != torch.long:
            raise ValueError(
                (f'Argument `face` needs to be of type `torch.long` but found '
",6
"        data = cls()
",6
"        keys = [key for key in self.__dict__.keys() if self[key] is not None]
        keys = [key for key in keys if key[:2] != '__' and key[-2:] != '__']
",6
"        return keys

    def __len__(self):
        r""""""Returns the number of all present attributes.""""""
        return len(self.keys)
",6
"
    def __contains__(self, key):
        r""""""Returns :obj:`True`, if the attribute :obj:`key` is present in the
        data.""""""
",6
"        return key in self.keys

",6
"    def __call__(self, *keys):
",6
"    def num_faces(self):
        r""""""Returns the number of faces in the mesh.""""""
        if self.face is not None:
            return self.face.size(self.__cat_dim__('face', self.face))
",6
"        if self.edge_attr is None:
            return 0
        return 1 if self.edge_attr.dim() == 1 else self.edge_attr.size(1)

",6
"    def coalesce(self):
",6
"        return self.apply(lambda x: x.contiguous(), *keys)
",6
"
",6
"                     ' {}').format(torch.long, self.edge_index.dtype))
",6
"                raise RuntimeError(
                    ('Face indices should have shape [3, num_faces] but found'
                     ' shape {}').format(self.face.size()))
",6
"        if self.face is not None and self.num_nodes is not None:
            if self.face.numel() > 0:
                min_index = self.face.min()
                max_index = self.face.max()
            else:
",6
"        if self.norm is not None and self.num_nodes is not None:
",6
"
    def __repr__(self):
",6
"        has_dict = any([isinstance(item, dict) for _, item in self])

        if not has_dict:
",6
"            return '{}({})'.format(cls, ', '.join(info))
        else:
            info = [size_repr(key, item, indent=2) for key, item in self]
",6
"
from torch_geometric.data import Data, Batch
from torch._six import container_abcs, string_classes, int_classes
",6
"
class Collater(object):
    def __init__(self, follow_batch):
        self.follow_batch = follow_batch

",6
"    def collate(self, batch):
",6
"            return Batch.from_data_list(batch, self.follow_batch)
",6
"            return type(elem)(*(self.collate(s) for s in zip(*batch)))
        elif isinstance(elem, container_abcs.Sequence):
",6
"class DataLoader(torch.utils.data.DataLoader):
    r""""""Data loader which merges data objects from a
    :class:`torch_geometric.data.dataset` to a mini-batch.
",6
"
    def __init__(self, dataset, batch_size=1, shuffle=False, follow_batch=[],
",6
"                 **kwargs):
        super(DataLoader,
              self).__init__(dataset, batch_size, shuffle,
",6
"
    .. note::

",6
"    Args:
        dataset (Dataset): The dataset from which to load the data.
        batch_size (int, optional): How many samples per batch to load.
            (default: :obj:`1`)
",6
"    def collate(self, data_list):
        batch = Batch()
        for key in data_list[0].keys:
            batch[key] = default_collate([d[key] for d in data_list])
",6
"        return batch

    def __call__(self, batch):
        return self.collate(batch)

",6
"
",6
"        super(DenseDataLoader, self).__init__(
            dataset, batch_size, shuffle, collate_fn=DenseCollater(), **kwargs)
from __future__ import print_function
",6
"        print('Extracting', path)
",6
"

def extract_tar(path, folder, mode='r:gz', log=True):
",6
"    with tarfile.open(path, mode) as f:
        f.extractall(folder)
",6
"    maybe_log(path, log)
    with zipfile.ZipFile(path, 'r') as f:
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
",6
"        r""""""Alias for :py:attr:`~num_node_features`.""""""
",6
"        return self.num_node_features
",6
"                'delete `{}` first.'.format(self.processed_dir))

        if files_exist(self.processed_paths):  # pragma: no cover
            return
",6
"        r""""""The number of examples in the dataset.""""""
        if self.__indices__ is not None:
            return len(self.__indices__)
",6
"            if idx.dtype == torch.long:
                if len(idx.shape) == 0:
                    idx = idx.unsqueeze(0)
",6
"            indices = [indices[i] for i in idx]
        else:
            raise IndexError(
                'Only integers, slices (`:`), list, tuples, and long or bool '
                'tensors are valid indices (got {}).'.format(
",6
"        if log:
            print('Using exist file', filename)
        return path
",6
"
    if log:
",6
"    into memory.
",6
"    tutorial.

    Args:
        root (string, optional): Root directory where the dataset should be
",6
"                                              pre_filter)
",6
"    def num_classes(self):
        r""""""The number of classes in the dataset.""""""
        y = self.data.y
",6
"    def collate(self, data_list):
        r""""""Collates a python list of data objects to the internal storage
",6
"            if torch.is_tensor(item):
                data[key] = torch.cat(data[key],
                                      dim=data.__cat_dim__(key, item))
            elif isinstance(item, int) or isinstance(item, float):
",6
"            slices[key] = torch.tensor(slices[key], dtype=torch.long)

        return data, slices

    def copy(self, idx=None):
",6
"import copy
",6
"import os.path as osp

import torch
",6
"    <https://arxiv.org/abs/1907.04931>`_ paper.
    Given a graph in a :obj:`data` object, this class samples nodes and
    constructs subgraphs that can be processed in a mini-batch fashion.
    Normalization coefficients for each mini-batch are given via
    :obj:`node_norm` and :obj:`edge_norm` data attributes.
",6
"    """"""
    def __init__(self, data, batch_size, num_steps=1, sample_coverage=50,
                 save_dir=None, num_workers=0, log=True):
",6
"        assert data.edge_index is not None
        assert 'node_norm' not in data
        assert 'edge_norm' not in data

        self.N = N = data.num_nodes
",6
"
        self.adj = SparseTensor(row=data.edge_index[0], col=data.edge_index[1],
                                value=data.edge_attr, sparse_sizes=(N, N))

",6
"        self.data.edge_index = None
        self.data.edge_attr = None

        self.batch_size = batch_size
        self.num_steps = num_steps
",6
"        if self.num_workers > 0:
",6
"                self.__sample_workers__.append(worker)

        path = osp.join(save_dir or '', self.__filename__)
",6
"                torch.save((self.node_norm, self.edge_norm), path)

        if self.num_workers > 0:
",6
"        raise NotImplementedError

    def __sample__(self, num_examples):
",6
"        node_samples = self.__sample_nodes__(num_examples)

",6
"            pbar = tqdm(total=self.N * self.sample_coverage)
",6
"                for _ in range(200):
                    node_idx, edge_idx, _ = self.__sample_queue__.get()
                    node_count[node_idx] += 1
                    edge_count[edge_idx] += 1
",6
"                    num_sampled_nodes += node_idx.size(0)
            else:
",6
"                samples = self.__sample__(200)
                for node_idx, edge_idx, _ in samples:
                    node_count[node_idx] += 1
",6
"        row, col, value = adj.coo()
",6
"        return data

",6
"            sample = self.__sample_queue__.get()
",6
"            data = self.__get_data_from_sample__(sample)
            queue.put(data)

    def __next__(self):
",6
"
    def __iter__(self):
",6
"        return self


",6
"class GraphSAINTNodeSampler(GraphSAINTSampler):
    r""""""The GraphSAINT node sampler class (see
    :class:`torch_geometric.data.GraphSAINTSampler`).
",6
"        return node_sample.unbind(dim=0)


",6
"class GraphSAINTEdgeSampler(GraphSAINTSampler):
    r""""""The GraphSAINT edge sampler class (see
    :class:`torch_geometric.data.GraphSAINTSampler`).

",6
"    """"""
    def __sample_nodes__(self, num_examples):
        # This function corresponds to the `Edge2` sampler in the official
        # code repository that weights all edges as equally important.
",6
"        # This is the default configuration in the GraphSAINT implementation.
        edge_sample = torch.randint(0, self.E, (num_examples, self.batch_size),
                                    dtype=torch.long)
",6
"from .dataset import Dataset
from .in_memory_dataset import InMemoryDataset
from .dataloader import DataLoader, DataListLoader, DenseDataLoader
from .sampler import NeighborSampler
",6
"    'Data',
",6
"    'Batch',
    'Dataset',
    'InMemoryDataset',
    'DataLoader',
    'DataListLoader',
",6
"from torch_geometric.data import Data


class Batch(Data):
",6
"    r""""""A plain old python object modeling a batch of graphs as one big
    (dicconnected) graph. With :class:`torch_geometric.data.Data` being the
    base class, all its methods can also be used here.
    In addition, single graphs can be reconstructed via the assignment vector
    :obj:`batch`, which maps each node to its respective graph identifier.
",6
"            batch.batch = None

        for key in batch.keys:
",6
"            elif isinstance(item, int) or isinstance(item, float):
                batch[key] = torch.tensor(batch[key])
",6
"
        if torch_geometric.is_debug_enabled():
",6
"            batch.debug()
",6
"        return batch.contiguous()

    def to_data_list(self):
        r""""""Reconstructs the list of :class:`torch_geometric.data.Data` objects
",6
"        The batch object must have been created via :meth:`from_data_list` in
",6
"                    data[key] = self[key].narrow(
                        data.__cat_dim__(key,
                                         self[key]), self.__slices__[key][i],
",6
"                    if self[key].dtype != torch.bool:
                        data[key] = data[key] - cumsum[key]
                else:
                    data[key] = self[key][self.__slices__[key][i]:self.
                                          __slices__[key][i + 1]]
",6
"
    @property
",6
"
import torch
",6
"        synthetic node features using transforms such as
        like :class:`torch_geometric.transforms.Constant` or
        :class:`torch_geometric.transforms.OneHotDegree`.
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"        super(TUDataset, self).__init__(root, transform, pre_transform,
",6
"            num_edge_attributes = self.num_edge_attributes
            self.data.edge_attr = self.data.edge_attr[:, num_edge_attributes:]
",6
"
    @property
    def num_node_attributes(self):
",6
"        return self.data.x.size(1) - self.num_node_labels

    @property
    def num_edge_labels(self):
",6
"
    @property
    def raw_file_names(self):
        names = ['A', 'graph_indicator']
        return ['{}_{}.txt'.format(self.name, name) for name in names]
",6
"
    def download(self):
        url = self.cleaned_url if self.cleaned else self.url
        folder = osp.join(self.root, self.name)
        path = download_url('{}/{}.zip'.format(url, self.name), folder)
",6
"            data_list = [data for data in data_list if self.pre_filter(data)]
            self.data, self.slices = self.collate(data_list)

        if self.pre_transform is not None:
            data_list = [self.get(idx) for idx in range(len(self))]
",6
"            self.data, self.slices = self.collate(data_list)
",6
"
        torch.save((self.data, self.slices), self.processed_paths[0])

    def __repr__(self):
        return '{}({})'.format(self.name, len(self))
",6
"
    def __init__(self, root, transform=None):
",6
"        events = glob.glob(osp.join(self.raw_dir, 'event*-hits.csv'))
        events = [e.split(osp.sep)[-1].split('-')[0][5:] for e in events]
        self.events = sorted(events)
",6
"        file_names += [f'event{idx}-particles.csv' for idx in event_indices]
        file_names += [f'event{idx}-truth.csv' for idx in event_indices]
        return file_names

",6
"
",6
"        value = torch.from_numpy(cell['value'].values).to(torch.float)
",6
"        super(Reddit, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

",6
"        data = Data(x=x, edge_index=edge_index, y=y)
        data.train_mask = split == 1
        data.val_mask = split == 2
",6
"        torch.save(self.collate([data]), self.processed_paths[0])

    def __repr__(self):
",6
"        return '{}()'.format(self.__class__.__name__)
import os
",6
"import glob

import torch
",6
"        Data objects hold mesh faces instead of edge indices.
        To convert the mesh to a graph, use the
        :obj:`torch_geometric.transforms.FaceToEdge` as :obj:`pre_transform`.
        To convert the mesh to a point cloud, use the
",6
"        sample a fixed number of points on the mesh faces according to their
        face area.

",6
"    Args:
",6
"    @property
    def raw_file_names(self):
        return ['2d_circle']
",6
"
",6
"            paths = glob.glob('{}/*.off'.format(folder))
            for path in paths:
                data = read_off(path)
                data.pos = data.pos - data.pos.mean(dim=0, keepdim=True)
                data.y = torch.tensor([target])
",6
"    from rdkit import rdBase
    from rdkit.Chem.rdchem import HybridizationType
    from rdkit import RDConfig
    from rdkit.Chem import ChemicalFeatures
",6
"])

",6
"atomrefs = {
    6: [0., 0., 0., 0., 0.],
    7: [
        -13.61312172, -1029.86312267, -1485.30251237, -2042.61123593,
",6
"    energy conformation of the atoms in the molecule.
",6
"    In addition, we provide the atom features from the `""Neural Message
    Passing for Quantum Chemistry"" <https://arxiv.org/abs/1704.01212>`_ paper.
",6
"    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+
    | 3      | :math:`\epsilon_{\textrm{LUMO}}` | Lowest unoccupied molecular orbital energy                                        | :math:`\textrm{eV}`                         |
    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+
",6
"    | 17     | :math:`B`                        | Rotational constant                                                               | :math:`\textrm{GHz}`                        |
    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+
    | 18     | :math:`C`                        | Rotational constant                                                               | :math:`\textrm{GHz}`                        |
    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+
",6
"        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"            transformed version. The data object will be transformed before
            being saved to disk. (default: :obj:`None`)
        pre_filter (callable, optional): A function that takes in an
            :obj:`torch_geometric.data.Data` object and returns a boolean
",6
"            value, indicating whether the data object should be included in the
",6
"
    def __init__(self, root, transform=None, pre_transform=None,
                 pre_filter=None):
        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)
",6
"            return 'qm9_v1.pt'
        else:
            return ['gdb9.sdf', 'gdb9.sdf.csv', 'uncharacterized.txt']
",6
"    @property
    def processed_file_names(self):
        return 'data.pt'

    def download(self):
",6
"            file_path = download_url(self.raw_url, self.raw_dir)
            extract_zip(file_path, self.raw_dir)
            os.unlink(file_path)
",6
"
            self.data, self.slices = torch.load(self.raw_paths[0])
            data_list = [self.get(i) for i in range(len(self))]

            if self.pre_filter is not None:
",6
"            target = f.read().split('\n')[1:-1]
            target = [[float(x) for x in line.split(',')[1:20]]
",6
"            target = target * conversion.view(1, -1)

        with open(self.raw_paths[2], 'r') as f:
            skip = [int(x.split()[0]) for x in f.read().split('\n')[9:-2]]
        assert len(skip) == 3054
",6
"                continue
            if i in skip:
                continue

            text = suppl.GetItemText(i)
",6
"            N = mol.GetNumAtoms()

            pos = text.split('\n')[4:4 + N]
            pos = [[float(x) for x in line.split()[:3]] for line in pos]
            pos = torch.tensor(pos, dtype=torch.float)
",6
"            aromatic = []
            sp = []
            sp2 = []
            sp3 = []
",6
"
            feats = factory.GetFeaturesForMol(mol)
            for j in range(0, len(feats)):
",6
"
            edge_index = torch.tensor([row, col], dtype=torch.long)
",6
"                        edge_attr=edge_attr, y=y, name=name, idx=i)
",6
"
        torch.save(self.collate(data_list), self.processed_paths[0])
",6
"import os
import os.path as osp
",6
"

class PCPNetDataset(InMemoryDataset):
    r""""""The PCPNet dataset from the `""PCPNet: Learning Local Shape Properties
    from Raw Point Clouds"" <https://arxiv.org/abs/1710.04954>`_ paper,
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
            final dataset. (default: :obj:`None`)
    """"""
",6
"        'All': 'testset_all.txt',
        'NoNoise': 'testset_no_noise.txt',
        'LowNoise': 'testset_low_noise.txt',
",6
"
    def download(self):
        path = download_url(self.url, self.raw_dir)
        extract_zip(path, self.raw_dir)
        os.unlink(path)
",6
"            filenames = f.read().split('\n')[:-1]
        data_list = []
        for filename in filenames:
",6
"        return '{}({}, category={})'.format(self.__class__.__name__, len(self),
                                            self.category)
import os
import os.path as osp
",6
"import shutil

import h5py
import torch
from torch_geometric.data import (InMemoryDataset, Data, download_url,
",6
"        os.rename(osp.join(self.root, name), self.raw_dir)

    def process(self):
",6
"            ys += torch.from_numpy(f['label'][:]).to(torch.long).unbind(0)

        test_area = 'Area_{}'.format(self.test_area)
        train_data_list, test_data_list = [], []
",6
"        Data objects hold mesh faces instead of edge indices.
",6
"        To convert the mesh to a graph, use the
        :obj:`torch_geometric.transforms.FaceToEdge` as :obj:`pre_transform`.
",6
"            otherwise the test dataset. (default: :obj:`True`)
        transform (callable, optional): A function/transform that takes in an
",6
"            :obj:`torch_geometric.data.Data` object and returns a transformed
            version. The data object will be transformed before every access.
",6
"            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
            transformed version. The data object will be transformed before
",6
"        pre_filter (callable, optional): A function that takes in an
            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
            final dataset. (default: :obj:`None`)
",6
"        return 'MPI-FAUST.zip'

    @property
    def processed_file_names(self):
        return ['training.pt', 'test.pt']
",6
"            'Dataset not found. Please download {} from {} and move it to {}'.
            format(self.raw_file_names, self.url, self.raw_dir))

",6
"
        path = osp.join(self.raw_dir, 'MPI-FAUST', 'training', 'registrations')
        path = osp.join(path, 'tr_reg_{0:03d}.ply')
        data_list = []
        for i in range(100):
",6
"            data_list.append(data)
",6
"from torch_geometric.data import InMemoryDataset, download_url, Data


class QM7b(InMemoryDataset):
",6
"    r""""""The QM7b dataset from the `""MoleculeNet: A Benchmark for Molecular
",6
"    Machine Learning"" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of
    7,211 molecules with 14 regression targets.
",6
"        super(Yelp, self).__init__(root, transform, pre_transform)
",6
"
        path = osp.join(self.raw_dir, 'class_map.json')
        gdd.download_file_from_google_drive(self.class_map_id, path)

",6
"        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))
        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])
        adj = adj.tocoo()
",6
"        col = torch.from_numpy(adj.col).to(torch.long)
        edge_index = torch.stack([row, col], dim=0)

        x = np.load(osp.join(self.raw_dir, 'feats.npy'))
",6
"from torch_geometric.io import read_txt_array

from .icews import EventDataset
",6
"    Args:
        root (string): Root directory where the dataset should be saved.
        split (string): If :obj:`""train""`, loads the training dataset.
",6
"            If :obj:`""val""`, loads the validation dataset.
            If :obj:`""test""`, loads the test dataset. (default: :obj:`""train""`)
        transform (callable, optional): A function/transform that takes in an
            :obj:`torch_geometric.data.Data` object and returns a transformed
",6
"            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
",6
"import torch
from torch_geometric.data import (InMemoryDataset, Data, download_url,
                                  extract_zip)
from torch_geometric.io import read_txt_array
",6
"
",6
"        transform (callable, optional): A function/transform that takes in an
            :obj:`torch_geometric.data.Data` object and returns a transformed
            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
",6
"        return ['cat0.vert', 'cat0.tri']
",6
"
    @property
    def processed_file_names(self):
        return '{}.pt'.format('_'.join([cat[:2] for cat in self.categories]))
",6
"
",6
"    def process(self):
",6
"                face = read_txt_array('{}.tri'.format(path), dtype=torch.long)
                data = Data(pos=pos, face=face.t().contiguous())
                if self.pre_filter is not None and not self.pre_filter(data):
                    continue
                if self.pre_transform is not None:
",6
"    Conflict and Fission in Small Groups""
    <http://www1.ind.ku.dk/complexLearning/zachary1977.pdf>`_ paper, containing
    34 nodes, connected by 154 (undirected and unweighted) edges.
",6
"
class DBP15K(InMemoryDataset):
",6
"            :obj:`""en_ja""`, :obj:`""zh_en""`, :obj:`""fr_en""`, :obj:`""ja_en""`).
        transform (callable, optional): A function/transform that takes in an
            :obj:`torch_geometric.data.Data` object and returns a transformed
            version. The data object will be transformed before every access.
            (default: :obj:`None`)
",6
"        extract_zip(path, self.root)
        os.unlink(path)
        shutil.rmtree(self.raw_dir)
",6
"                if len(info) > 300:
                    embs[info[0]] = torch.tensor([float(x) for x in info[1:]])
                else:
",6
"                    embs['**UNK**'] = torch.tensor([float(x) for x in info])
",6
"            g1_path, x1_path, embs)
        x2, edge_index2, rel2, assoc2 = self.process_graph(
            g2_path, x2_path, embs)

",6
"        test_path = osp.join(self.raw_dir, self.pair, 'test.examples.1000')
        test_y = self.process_y(test_path, assoc1, assoc2)

        data = Data(x1=x1, edge_index1=edge_index1, rel1=rel1, x2=x2,
",6
"
        idx = torch.tensor(list(x_dict.keys()))
        assoc = torch.full((idx.max().item() + 1, ), -1, dtype=torch.long)
",6
"        row, col, mask = read_txt_array(path, sep='\t', dtype=torch.long).t()
        mask = mask.to(torch.bool)
",6
"        To convert the mesh to a graph, use the
        :obj:`torch_geometric.transforms.FaceToEdge` as :obj:`pre_transform`.
        To convert the mesh to a point cloud, use the
        :obj:`torch_geometric.transforms.SamplePoints` as :obj:`transform` to
",6
"        face area.

    Args:
",6
"            :obj:`""knees""`, :obj:`""light_hopping_loose""`,
            :obj:`""light_hopping_stiff""`, :obj:`""one_leg_jump""`,
            :obj:`""one_leg_loose""`, :obj:`""personal_move""`, :obj:`""punching""`,
            :obj:`""running_on_spot""`, :obj:`""running_on_spot_bugfix""`,
",6
"            transformed version. The data object will be transformed before
            being saved to disk. (default: :obj:`None`)
        pre_filter (callable, optional): A function that takes in an
            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
",6
"        '50002', '50004', '50007', '50009', '50020', '50021', '50022', '50025',
        '50026', '50027'
",6
"            ''.join([w[0] for w in cat.split('_')]) for cat in self.categories
        ])
        return '{}_{}.pt'.format(sids, cats)

    def download(self):
",6
"        raise RuntimeError(
            'Dataset not found. Please download male registrations '
            '(registrations_m.hdf5) and female registrations '
            '(registrations_f.hdf5) from {} and '
            'move it to {}'.format(self.url, self.raw_dir))
",6
"
        face = torch.from_numpy(fm['faces'][()]).to(torch.long)
",6
"        face = face.t().contiguous()

        data_list = []
        for (sid, cat) in product(self.subjects, self.categories):
",6
"                pos = torch.from_numpy(fm[idx][()])
",6
"            data_list.append(Data(pos=pos, face=face))

        if self.pre_filter is not None:
",6
"        torch.save(self.collate(data_list), self.processed_paths[0])
",6
"            version. The data object will be transformed before every access.
",6
"            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
",6
"    def __init__(self, root, group, name, transform=None, pre_transform=None):
        self.group = group
        self.name = name
",6
"        super(SuiteSparseMatrixCollection,
              self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
",6
"
        row = torch.from_numpy(mat.row).to(torch.long)
        col = torch.from_numpy(mat.col).to(torch.long)
",6
"                    num_nodes=num_nodes)

",6
"
import torch
",6
"
    Args:
        root (string): Root directory where the dataset should be saved.
        transform (callable, optional): A function/transform that takes in an
            :obj:`torch_geometric.data.Data` object and returns a transformed
",6
"            version. The data object will be transformed before every access.
            (default: :obj:`None`)
        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
            transformed version. The data object will be transformed before
",6
"
    @property
",6
"
    def download(self):
        path = osp.join(self.raw_dir, 'adj_full.npz')
        gdd.download_file_from_google_drive(self.adj_full_id, path)

",6
"
        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,
                    val_mask=val_mask, test_mask=test_mask)
",6
"
        data = data if self.pre_transform is None else self.pre_transform(data)

        torch.save(self.collate([data]), self.processed_paths[0])
",6
"from torch_geometric.data import InMemoryDataset, download_url
from torch_geometric.io import read_npz

",6
"            version. The data object will be transformed before every access.
",6
"        self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    def raw_dir(self):
        return osp.join(self.root, self.name, 'raw')
",6
"    def raw_file_names(self):
        return '{}.npz'.format(self.name)

    @property
    def processed_file_names(self):
",6
"        return 'data.pt'

",6
"    def download(self):
        download_url(self.url.format(self.name), self.raw_dir)

    def process(self):
        data = read_npz(self.raw_paths[0])
",6
"        data = data if self.pre_transform is None else self.pre_transform(data)
",6
"
",6
"    :obj:`name=""cora""`.""""""
",6
"        Data objects hold mesh faces instead of edge indices.
        To convert the mesh to a graph, use the
        :obj:`torch_geometric.transforms.FaceToEdge` as :obj:`pre_transform`.
        To convert the mesh to a point cloud, use the
",6
"        '40': 'http://modelnet.cs.princeton.edu/ModelNet40.zip'
    }

    def __init__(self, root, name='10', train=True, transform=None,
                 pre_transform=None, pre_filter=None):
",6
"    def raw_file_names(self):
        return [
            'bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor',
            'night_stand', 'sofa', 'table', 'toilet'
",6
"        shutil.rmtree(self.raw_dir)
        os.rename(folder, self.raw_dir)

        # Delete osx metadata generated during compression of ModelNet10
        metadata_folder = osp.join(self.root, '__MACOSX')
",6
"
    def process(self):
        torch.save(self.process_set('train'), self.processed_paths[0])
        torch.save(self.process_set('test'), self.processed_paths[1])

",6
"        categories = glob.glob(osp.join(self.raw_dir, '*', ''))
        categories = sorted([x.split(os.sep)[-2] for x in categories])

        data_list = []
        for target, category in enumerate(categories):
",6
"        root (string): Root directory where the dataset should be saved.
",6
"    url = ('http://www.di.ens.fr/willow/research/graphlearning/'
           'WILLOW-ObjectClass_dataset.zip')

    categories = ['face', 'motorbike', 'car', 'duck', 'winebottle']

",6
"        assert category.lower() in self.categories
        self.category = category
        super(WILLOWObjectClass, self).__init__(root, transform, pre_transform,
                                                pre_filter)
",6
"
    @property
    def raw_dir(self):
        return osp.join(self.root, 'raw')
",6
"
    def process(self):
",6
"                continue

            with open('{}.png'.format(name), 'rb') as f:
                img = Image.open(f).convert('RGB')

",6
"            # Rescale keypoints.
",6
"            vgg16_outputs.clear()

",6
"
            out1 = F.interpolate(vgg16_outputs[0], (256, 256), mode='bilinear',
                                 align_corners=False)
            out2 = F.interpolate(vgg16_outputs[0], (256, 256), mode='bilinear',
                                 align_corners=False)
",6
"                data.img = None
                data.x = torch.cat([x_1.t(), x_2.t()], dim=-1)
            del out1
            del out2
",6
"            data_list = [data for data in data_list if self.pre_filter(data)]

        if self.pre_transform is not None:
            data_list = [self.pre_transform(data) for data in data_list]

",6
"        elif key == 'circle_batch':
            return item.max().item() + 1 if item.numel() > 0 else 0
        else:
",6
"            featnames = f.read().split('\n')[:-1]
            featnames = [' '.join(x.split(' ')[1:]) for x in featnames]
            all_featnames += featnames
    all_featnames = sorted(list(set(all_featnames)))
",6
"        egofeat_file = files[i + 2]
        feat_file = files[i + 3]
        featnames_file = files[i + 4]

",6
"        x = pandas.read_csv(feat_file, sep=' ', header=None, dtype=np.float32)
        x = torch.from_numpy(x.values)

",6
"
        edge_index = pandas.read_csv(edges_file, sep=' ', header=None,
",6
"                                     dtype=np.int64)
        edge_index = torch.from_numpy(edge_index.values).t()
        edge_index = edge_index.flatten()
",6
"        edge_index = edge_index.view(2, -1)
        row, col = edge_index

",6
"        row_ego = torch.full((x.size(0), ), x.size(0), dtype=torch.long)
        col_ego = torch.arange(x.size(0))

        # Ego node should be connected to every other node.
",6
"        data_list.append(data)

",6
"    edge_index = pandas.read_csv(files[0], sep='\t', header=None,
",6
"                                 skiprows=skiprows, dtype=np.int64)
    edge_index = torch.from_numpy(edge_index.values).t()
",6
"    num_nodes = edge_index.max().item() + 1
",6
"    edge_index, _ = coalesce(edge_index, None, num_nodes, num_nodes)

    return [Data(edge_index=edge_index, num_nodes=num_nodes)]


",6
"
    idx = torch.unique(edge_index.flatten())
    idx_assoc = torch.full((edge_index.max() + 1, ), -1, dtype=torch.long)
",6
"    """"""
",6
"        'soc-epinions1': ['soc-Epinions1.txt.gz'],
        'soc-livejournal1': ['soc-LiveJournal1.txt.gz'],
",6
"        'soc-pokec': ['soc-pokec-relationships.txt.gz'],
        'soc-slashdot0811': ['soc-Slashdot0811.txt.gz'],
        'soc-slashdot0922': ['soc-Slashdot0902.txt.gz'],
        'wiki-vote': ['wiki-Vote.txt.gz'],
",6
"    }

",6
"    @property
    def raw_dir(self):
        return osp.join(self.root, self.name, 'raw')

    @property
",6
"    @property
    def processed_file_names(self):
",6
"        return 'data.pt'
",6
"        for name in self.available_datasets[self.name]:
            path = download_url('{}/{}'.format(self.url, name), self.raw_dir)
            print(path)
            if name.endswith('.tar.gz'):
",6
"        raw_files = sorted([osp.join(raw_dir, f) for f in os.listdir(raw_dir)])

",6
"            data_list = read_soc(raw_files, self.name[:4])
        elif self.name[:5] == 'wiki-':
            data_list = read_wiki(raw_files, self.name[5:])
        else:
",6
"from itertools import chain
from xml.dom import minidom

",6
"    import torchvision.models as models
    import torchvision.transforms as T
    from PIL import Image
",6
"class PascalVOCKeypoints(InMemoryDataset):
    r""""""The Pascal VOC 2011 dataset with Berkely annotations of keypoints from
    the `""Poselets: Body Part Detectors Trained Using 3D Human Pose
    Annotations"" <https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/
    human/ poselets_iccv09.pdf>`_ paper, containing 0 to 23 keypoints per
",6
"                 'VOCtrainval_25-May-2011.tar')
",6
"                      'vision/shape/poselets/voc2011_keypoints_Feb2012.tgz')
    # annotation_url = 'http://www.roemisch-drei.de/pascal_annotations.tar'
    # split_url = 'http://cvgl.stanford.edu/projects/ucn/voc2011_pairs.npz'
",6
"    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    batch_size = 32
",6
"
    def __init__(self, root, category, train=True, transform=None,
",6
"        path = self.processed_paths[0] if train else self.processed_paths[1]
        self.data, self.slices = torch.load(path)

    @property
    def raw_dir(self):
",6
"    def process(self):
",6
"        train_split = list(splits['train'])[category_idx]
        test_split = list(splits['test'])[category_idx]

",6
"        def hook(module, x, y):
            vgg16_outputs.append(y)

        vgg16 = models.vgg16(pretrained=True).to(self.device)
",6
"        ])

        train_set, test_set = [], []
        for i, name in enumerate(chain(train_split, test_split)):
            filename = '_'.join(name.split('/')[1].split('_')[:-1])
",6
"            occ = obj.getElementsByTagName('occluded')
",6
"
            if self.category == 'person' and int(filename[:4]) > 2008:
                continue

            xmin = float(obj.getElementsByTagName('xmin')[0].firstChild.data)
",6
"            poss, ys = [], []
            for keypoint in keypoints:
                label = keypoint.attributes['name'].value
                if label not in labels:
                    labels[label] = len(labels)
",6
"                ys.append(labels[label])
                x = float(keypoint.attributes['x'].value)
                y = float(keypoint.attributes['y'].value)
                poss += [x, y]
            y = torch.tensor(ys, dtype=torch.long)
",6
"            # Add a small offset to the bounding because some keypoints lay
            # outside the bounding box intervals.
            box = (min(pos[:, 0].min().floor().item(), box[0]) - 16,
",6
"            :obj:`""MUTAG""`, :obj:`""BGS""`, :obj:`""AM""`).
        transform (callable, optional): A function/transform that takes in an
",6
"            an :obj:`torch_geometric.data.Data` object and returns a
            transformed version. The data object will be transformed before
            being saved to disk. (default: :obj:`None`)
    """"""
",6
"        path = download_url(self.url.format(self.name), self.root)
",6
"        with gzip.open(graph_file, 'rb') as f:
            g.parse(file=f, format='nt')
",6
"        def freq(rel):
            return freq_[rel] if rel in freq_ else 0

",6
"        relations = sorted(set(g.predicates()), key=lambda rel: -freq(rel))
        subjects = set(g.subjects())
        objects = set(g.objects())
",6
"import os.path as osp
from glob import glob
",6
"
import torch
",6
"from torch_geometric.data import InMemoryDataset, extract_zip
from torch_geometric.io import read_ply
",6
"

class CoMA(InMemoryDataset):
    r""""""The CoMA 3D faces dataset from the `""Generating 3D faces using
",6
"            transformed version. The data object will be transformed before
            being saved to disk. (default: :obj:`None`)
        pre_filter (callable, optional): A function that takes in an
            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
",6
"
    categories = [
        'bareteeth',
        'cheeks_in',
        'eyebrow',
",6
"        'lips_up',
        'mouth_down',
        'mouth_extreme',
        'mouth_middle',
        'mouth_open',
",6
"    ]

    def __init__(self, root, train=True, transform=None, pre_transform=None,
                 pre_filter=None):
",6
"    def download(self):
        raise RuntimeError(
",6
"            'Dataset not found. Please download COMA_data.zip from {} and '
",6
"        train_data_list, test_data_list = [], []
        for folder in folders:
            for i, category in enumerate(self.categories):
",6
"                files = sorted(glob(osp.join(folder, category, '*.ply')))
                for j, f in enumerate(files):
                    data = read_ply(f)
",6
"
",6
"
class MNISTSuperpixels(InMemoryDataset):
    r""""""MNIST superpixels dataset from the `""Geometric Deep Learning on
    Graphs and Manifolds Using Mixture Model CNNs""
    <https://arxiv.org/abs/1611.08402>`_ paper, containing 70,000 graphs with
",6
"    """"""
",6
"                 transform=None,
                 pre_transform=None,
                 pre_filter=None):
        super(MNISTSuperpixels, self).__init__(root, transform, pre_transform,
",6
"            m, n = y.size(0), 75
            x, pos = x.view(m * n, 1), pos.view(m * n, 2)
            node_slice = torch.arange(0, (m + 1) * n, step=n, dtype=torch.long)
            graph_slice = torch.arange(m + 1, dtype=torch.long)
",6
"import json

import torch
import numpy as np
import networkx as nx
",6
"from networkx.readwrite import json_graph
from torch_geometric.data import (InMemoryDataset, Data, download_url,
                                  extract_zip)
",6
"from torch_geometric.utils import remove_self_loops

",6
"
class PPI(InMemoryDataset):
",6
"            :obj:`torch_geometric.data.Data` object and returns a boolean
            value, indicating whether the data object should be included in the
            final dataset. (default: :obj:`None`)
    """"""
",6
"        if split == 'train':
",6
"    def processed_file_names(self):
        return ['train.pt', 'val.pt', 'test.pt']

    def download(self):
",6
"
",6
"            x = np.load(osp.join(self.raw_dir, '{}_feats.npy').format(split))
            x = torch.from_numpy(x).to(torch.float)
",6
"            idx = torch.from_numpy(np.load(path)).to(torch.long)
            idx = idx - idx.min()
",6
"                edge_index, _ = remove_self_loops(edge_index)

                data = Data(edge_index=edge_index, x=x[mask], y=y[mask])

",6
"                if self.pre_filter is not None and not self.pre_filter(data):
                    continue
",6
"
                if self.pre_transform is not None:
                    data = self.pre_transform(data)

",6
"    categories.
    Each category is annotated with 2 to 6 parts.

    Args:
        root (string): Root directory where the dataset should be saved.
",6
"            If :obj:`""trainval""`, loads the training and validation dataset.
            If :obj:`""test""`, loads the test dataset.
",6
"        'Chair': [12, 13, 14, 15],
        'Earphone': [16, 17, 18],
        'Guitar': [19, 20, 21],
        'Knife': [22, 23],
        'Lamp': [24, 25, 26, 27],
",6
"        'Laptop': [28, 29],
        'Motorbike': [30, 31, 32, 33, 34, 35],
",6
"        elif split == 'val':
            path = self.processed_paths[1]
        elif split == 'test':
            path = self.processed_paths[2]
        elif split == 'trainval':
",6
"        else:
            raise ValueError((f'Split {split} found, but expected either '
                              'train, val, trainval or test'))

        self.data, self.slices = torch.load(path)
",6
"        cats = '_'.join([cat[:3].lower() for cat in self.categories])
        return [
",6
"            os.path.join('{}_{}.pt'.format(cats, split))
",6
"
            data = read_txt_array(osp.join(self.raw_dir, name))
",6
"                data = self.pre_transform(data)
",6
"                                              len(self), self.categories)
import os.path as osp

",6
"    Training, validation and test splits are given by binary masks.

    Args:
        root (string): Root directory where the dataset should be saved.
",6
"    url = 'https://github.com/kimiyoung/planetoid/raw/master/data'

",6
"
            remaining = (~data.train_mask).nonzero().view(-1)
            remaining = remaining[torch.randperm(remaining.size(0))]
",6
"    def raw_file_names(self):
        names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']
        return ['ind.{}.{}'.format(self.name.lower(), name) for name in names]

",6
"from torch_geometric.data import InMemoryDataset, download_url
from torch_geometric.io import read_npz
",6
"

class Coauthor(InMemoryDataset):
    r""""""The Coauthor CS and Coauthor Physics networks from the
    `""Pitfalls of Graph Neural Network Evaluation""
",6
"        pre_transform (callable, optional): A function/transform that takes in
            an :obj:`torch_geometric.data.Data` object and returns a
",6
"
    def process(self):
",6
"import torch
import torch.nn.functional as F
import networkx as nx
from torch_geometric.data import (InMemoryDataset, Data, download_url,
                                  extract_zip, extract_tar)
",6
"from torch_geometric.utils import to_undirected

",6
"
class GEDDataset(InMemoryDataset):
    r""""""The GED datasets from the `""Graph Edit Distance Computation via Graph
    Neural Networks"" <https://arxiv.org/abs/1808.05689>`_ paper.
    GEDs can be accessed via the global attributes :obj:`ged` and
",6
"        pre_transform (callable, optional): A function/transform that takes in
",6
"            'extract': extract_zip,
            'pickle': '1OpV4bCHjBkdpqI6H5Mg0-BqlA2ee2eBW',
",6
"        'IMDBMulti': {
            'id': '12QxZ7EhYA7pJiF4cO-HuE8szhSOWcfST',
            'extract': extract_zip,
            'pickle': '1wy9VbZvZodkixxVIOuRllC-Lp-0zdoYZ',
",6
"        path = osp.join(self.processed_dir, '{}_ged.pt'.format(self.name))
        self.ged = torch.load(path)
",6
"        name = self.datasets[self.name]['id']
        path = download_url(self.url.format(name), self.raw_dir)
        self.datasets[self.name]['extract'](path, self.raw_dir)
",6
"        for r_path, p_path in zip(self.raw_paths, self.processed_paths):
            names = glob.glob(osp.join(r_path, '*.gexf'))
            ids.append(sorted([int(i.split(os.sep)[-1][:-5]) for i in names]))

",6
"                Ns.append(G.number_of_nodes())
                edge_index = torch.tensor(list(G.edges)).t().contiguous()
",6
"
                if self.pre_filter is not None and not self.pre_filter(data):
",6
"        path = osp.join(self.raw_dir, self.name, 'ged.pickle')
        mat = torch.full((len(assoc), len(assoc)), float('inf'))
        with open(path, 'rb') as f:
            obj = pickle.load(f)
            xs, ys, gs = [], [], []
",6
"            g = torch.tensor(gs, dtype=torch.float)
            mat[x, y], mat[y, x] = g, g
",6
"
        path = osp.join(self.processed_dir, '{}_ged.pt'.format(self.name))
",6
"        N = torch.tensor(Ns, dtype=torch.float)
        norm_mat = mat / (0.5 * (N.view(-1, 1) + N.view(1, -1)))

        path = osp.join(self.processed_dir, '{}_norm_ged.pt'.format(self.name))
",6
"        torch.save(norm_mat, path)

",6
"from .tu_dataset import TUDataset
from .planetoid import Planetoid
from .citation_full import CitationFull, CoraFull
from .coauthor import Coauthor
from .amazon import Amazon
",6
"    'DynamicFAUST',
    'ShapeNet',
",6
"    'ICEWS18',
    'GDELT',
    'DBP15K',
",6
"    .. note::

        Data objects hold mesh faces instead of edge indices.
        To convert the mesh to a graph, use the
        :obj:`torch_geometric.transforms.FaceToEdge` as :obj:`pre_transform`.
",6
"            an :obj:`torch_geometric.data.Data` object and returns a
",6
"    partialities = ['holes', 'cuts']

    def __init__(self, root, partiality, category, train=True, transform=None,
",6
"        assert category.lower() in self.categories
",6
"
    def download(self):
        path = download_url(self.train_url, self.raw_dir)
        extract_zip(path, self.raw_dir)
        os.unlink(path)
",6
"            osp.join(self.raw_paths[0], 'null', '{}.off'.format(self.cat)))
",6
"        name = '{}_{}_*.off'.format(self.part, self.cat)
        paths = glob.glob(osp.join(self.raw_paths[1], self.part, name))
",6
"        paths = [path[:-4] for path in paths]
        paths = sorted(paths, key=lambda e: (len(e), e))

",6
"
",6
"        if self.pre_filter is not None:
            train_list = [d for d in train_list if self.pre_filter(d)]
",6
"                                  extract_gz)


",6
"    Args:
        root (string): Root directory where the dataset should be saved.
        edge_window_size (int, optional): The window size for the existence of
            an edge in the graph sequence since its initial creation.
            (default: :obj:`10`)
",6
"
    def process(self):
        with open(self.raw_paths[0], 'r') as f:
            data = f.read().split('\n')[:-1]
",6
"            edge_index = edge_index - edge_index.min()
            edge_index = edge_index.t().contiguous()
            num_nodes = edge_index.max().item() + 1
",6
"            data_list = [d for d in data_list if self.pre_filter(d)]

        if self.pre_transform is not None:
",6
"        torch.save((data, slices), self.processed_paths[0])
import torch
from torch_geometric.data import InMemoryDataset, download_url, Data
from torch_geometric.io import read_txt_array
",6
"

class EventDataset(InMemoryDataset):
    def __init__(self, root, transform=None, pre_transform=None,
",6
"                 pre_filter=None):
        super(EventDataset, self).__init__(root, transform, pre_transform,
                                           pre_filter)
",6
"
",6
"    events collected from 1/1/2018 to 10/31/2018 (24 hours time granularity).

    Args:
        root (string): Root directory where the dataset should be saved.
        split (string): If :obj:`""train""`, loads the training dataset.
",6
"            If :obj:`""val""`, loads the validation dataset.
            If :obj:`""test""`, loads the test dataset. (default: :obj:`""train""`)
",6
"    def raw_file_names(self):
",6
"
    def download(self):
        for filename in self.raw_file_names:
            download_url('{}/{}'.format(self.url, filename), self.raw_dir)

",6
"    def process_events(self):
        events = []
",6
"        df = df.join(author, on='name')

        author_y = torch.from_numpy(df['y'].values) - 1
        author_y_index = torch.from_numpy(df['idx'].values)
",6
"
        # Get venue labels.
        path = osp.join(self.raw_dir, 'id_conf.txt')
",6
"        M, N = int(paper_author[0].max() + 1), int(paper_author[1].max() + 1)
        paper_author, _ = coalesce(paper_author, None, M, N)
        author_paper, _ = transpose(paper_author, None, M, N)

",6
"        paper_venue = paper_venue.t().contiguous()
        M, N = int(paper_venue[0].max() + 1), int(paper_venue[1].max() + 1)
        paper_venue, _ = coalesce(paper_venue, None, M, N)
",6
"                ('author', 'wrote', 'paper'): author_paper,
",6
"                ('venue', 'published', 'paper'): venue_paper,
            },
",6
"            :obj:`""Cat""`, :obj:`""Chair""`, :obj:`""Diningtable""`, :obj:`""Dog""`,
            :obj:`""Horse""`, :obj:`""Motorbike""`, :obj:`""Person""`,
            :obj:`""Pottedplant""`, :obj:`""Sheep""`, :obj:`""Sofa""`,
            :obj:`""Train""`, :obj:`""TVMonitor""`)
",6
"    url = ('https://www.di.ens.fr/willow/research/proposalflow/dataset/'
           'PF-dataset-PASCAL.zip')

    categories = [
        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat',
",6
"
",6
"    def download(self):
        path = download_url(self.url, self.root)
        extract_zip(path, self.root)
        shutil.rmtree(self.raw_dir)
        os.rename(osp.join(self.root, 'PF-dataset-PASCAL'), self.raw_dir)
",6
"
",6
"            mask = ~torch.isnan(pos[:, 0])
",6
"    Nodes represent goods and edges represent that two goods are frequently
    bought together.
    Given product reviews as bag-of-words node features, the task is to
",6
"        assert self.name in ['computers', 'photo']
        super(Amazon, self).__init__(root, transform, pre_transform)
        self.data, self.slices = torch.load(self.processed_paths[0])

",6
"    def download(self):
        download_url(self.url + self.raw_file_names, self.raw_dir)

    def process(self):
",6
"        data = read_npz(self.raw_paths[0])
        data = data if self.pre_transform is None else self.pre_transform(data)
",6
"
import torch

",6
"        scale /= ((tensor.size(-2) + tensor.size(-1)) * tensor.var())
        tensor.data *= scale.sqrt()


def zeros(tensor):
",6
"    if tensor is not None:
        tensor.data.fill_(1)


def normal(tensor, mean, std):
",6
"        tensor.data.normal_(mean, std)
",6
"        You need to use the :class:`torch_geometric.data.DataListLoader` for
        this module.

    Args:
",6
"
",6
"            data = Batch.from_data_list(data_list).to(self.src_device)
            return self.module(data)

",6
"class Reshape(torch.nn.Module):
    def __init__(self, *shape):
",6
"    :obj:`global_model`, respectively.

    To allow for batch-wise graph processing, all callable functions take an
",6
"            features based on its source and target node features, its current
            edge features and its global features. (default: :obj:`None`)
        node_model (Module, optional): A callable which updates a graph's node
",6
"        from torch_scatter import scatter_mean
",6
"            def forward(self, src, dest, edge_attr, u, batch):
                # source, target: [E, F_x], where E is the number of edges.
                # edge_attr: [E, F_e]
                # u: [B, F_u], where B is the number of graphs.
                # batch: [E] with max entry B - 1.
",6
"                out = torch.cat([src, dest, edge_attr, u[batch]], 1)
",6
"                # edge_index: [2, E] with max entry N - 1.
                # edge_attr: [E, F_e]
",6
"                # u: [B, F_u]
",6
"                # batch: [N] with max entry B - 1.
                out = torch.cat([u, scatter_mean(x, batch, dim=0)], dim=1)
                return self.global_mlp(out)

",6
"
    def reset_parameters(self):
        for item in [self.node_model, self.edge_model, self.global_model]:
            if hasattr(item, 'reset_parameters'):
",6
"    def forward(self, x, edge_index, edge_attr=None, u=None, batch=None):
        """"""""""""
",6
"
",6
"            u = self.global_model(x, edge_index, edge_attr, u, batch)

        return x, edge_attr, u
",6
"                '    node_model={},\n'
                '    global_model={}\n'
                ')').format(self.__class__.__name__, self.edge_model,
                            self.node_model, self.global_model)
",6
"    r""""""The local extremum graph neural network operator from the
    `""ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph
    Representations"" <https://arxiv.org/abs/1911.07979>`_ paper, which finds
    the importance of nodes with respect to their neighbors using the
",6
"        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
    """"""
    def __init__(self, in_channels, out_channels, bias=True, **kwargs):
",6
"        super(LEConv, self).__init__(aggr='add', **kwargs)

",6
"
        self.reset_parameters()

    def reset_parameters(self):
        self.lin1.reset_parameters()
",6
"        self.lin2.reset_parameters()
        self.lin3.reset_parameters()

    def forward(self, x, edge_index, edge_weight=None):
        """"""""""""
",6
"    def __repr__(self):
",6
"    and Hypergraph Attention"" <https://arxiv.org/abs/1901.08150>`_ paper

    .. math::
        \mathbf{X}^{\prime} = \mathbf{D}^{-1} \mathbf{H} \mathbf{W}
        \mathbf{B}^{-1} \mathbf{H}^{\top} \mathbf{X} \mathbf{\Theta}
",6
"
    Args:
",6
"        use_attention (bool, optional): If set to :obj:`True`, attention
",6
"        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
    """"""
",6
"        if self.use_attention:
            self.heads = heads
            self.concat = concat
            self.negative_slope = negative_slope
            self.dropout = dropout
",6
"            alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)
            alpha = F.leaky_relu(alpha, self.negative_slope)
            alpha = softmax(alpha, hyperedge_index[0], x.size(0))
            alpha = F.dropout(alpha, p=self.dropout, training=self.training)

",6
"
        if self.concat is True:
            out = out.view(-1, self.heads * self.out_channels)
        else:
",6
"])
",6
"    'edge_index_i',
    'edge_index_j',
    'size_i',
    'size_j',
",6
"])

aggr_special_args = set([
",6
"update_special_args = set([])
",6
"    Args:
        aggr (string, optional): The aggregation scheme to use
            (:obj:`""add""`, :obj:`""mean""`, :obj:`""max""` or :obj:`None`).
",6
"        node_dim (int, optional): The axis along which to propagate.
            (default: :obj:`0`)
",6
"    """"""

    def __init__(self, aggr=""add"", flow=""source_to_target"", node_dim=0):
        super(MessagePassing, self).__init__()
",6
"
",6
"        self.__msg_aggr_params__ = inspect.signature(
            self.message_and_aggregate).parameters
",6
"        for arg in self.__user_args__:
            if arg[-2:] not in ij.keys():
                out[arg] = kwargs.get(arg, inspect.Parameter.empty)
",6
"
",6
"                if data is inspect.Parameter.empty:
                    out[arg] = data
                    continue

",6
"            out['edge_index_j'] = edge_index.storage.col()
            out['index'] = edge_index.storage.row()
            out['ptr'] = edge_index.storage.rowptr()
            out['edge_attr'] = edge_index.storage.value()
",6
"        out = {}
        for key, param in params.items():
            data = kwargs.get(key, inspect.Parameter.empty)
            if data is inspect.Parameter.empty:
                if param.default is inspect.Parameter.empty:
",6
"            **kwargs: Any additional data which is needed to construct and
                aggregate messages, and to update node embeddings.
        """"""
",6
"
        if mp_type == 'adj_t' and self.flow == 'target_to_source':
            raise ValueError(
                ('Flow direction ""target_to_source"" is invalid for message '
",6
"
        return x_j

    def aggregate(self, inputs, index, ptr=None, dim_size=None):
",6
"
",6
"        :math:`\gamma_{\mathbf{\Theta}}` for each node
        :math:`i \in \mathcal{V}`.
",6
"

class NNConv(MessagePassing):
    r""""""The continuous kernel-based convolutional operator from the
    `""Neural Message Passing for Quantum Chemistry""
",6
"    `""Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on
    Graphs"" <https://arxiv.org/abs/1704.02901>`_ paper (see
    :class:`torch_geometric.nn.conv.ECConv` for an alias):
",6
"        root_weight (bool, optional): If set to :obj:`False`, the layer will
            not add the transformed root node features to the output.
",6
"                 aggr='add',
                 root_weight=True,
                 bias=True,
",6
"        return self.propagate(edge_index, x=x, pseudo=pseudo)

",6
"from torch_geometric.utils import remove_self_loops, add_self_loops

",6
"from ..inits import reset


class PointConv(MessagePassing):
",6
"    defines the position of each point.
",6
"        super(PointConv, self).__init__(aggr='max', **kwargs)

        self.local_nn = local_nn
",6
"            pos (Tensor or tuple): The node position matrix. Either given as
                tensor for use in general message passing or as tuple for use
                in message passing in bipartite graphs.
            edge_index (LongTensor): The edge indices.
",6
"        """"""
",6
"        return '{}(local_nn={}, global_nn={})'.format(
            self.__class__.__name__, self.local_nn, self.global_nn)
import torch
from torch.nn import Parameter
",6
"import torch.nn.functional as F
from torch_scatter import scatter_add
",6
"
",6
"        \mathbf{X}_k^{(t+1)} = \sigma \left( \mathbf{\hat{L}}
        \mathbf{X}_k^{(t)} \mathbf{W} + \mathbf{X}^{(0)} \mathbf{V} \right),

",6
"    modified Laplacian :math:`\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2}
",6
"
        K, T, F_in, F_out = num_stacks, num_layers, in_channels, out_channels

        w = torch.nn.Parameter(torch.Tensor(K, F_in, F_out))
",6
"        self.ws = torch.nn.ParameterList([w])
        for i in range(min(1, T - 1) if shared_weights else T - 1):
            self.ws.append(Parameter(torch.Tensor(K, F_out, F_out)))
",6
"        self.vs = torch.nn.ParameterList([])
        for i in range(1 if shared_weights else T):
            self.vs.append(Parameter(torch.Tensor(K, F_in, F_out)))
",6
"            glorot(w)
",6
"
",6
"
        lap = deg_inv[row] * edge_weight * deg_inv[col]

        x = x.unsqueeze(0)
        out = x
",6
"        for t in range(self.num_layers):
",6
"
            out = out + skip

",6
"                out = self.act(out)

        return out.mean(dim=0)

    def __repr__(self):
",6
"            self.num_stacks, self.num_layers)
import torch
from torch.nn import Parameter, Linear
import torch.nn.functional as F
",6
"    """"""
    def __init__(self, in_channels, out_channels, heads=1, concat=True,
                 negative_slope=0.2, dropout=0, bias=True, **kwargs):
",6
"        if bias and concat:
            self.bias = Parameter(torch.Tensor(heads * out_channels))
        elif bias and not concat:
            self.bias = Parameter(torch.Tensor(out_channels))
        else:
",6
"
    def reset_parameters(self):
        glorot(self.lin.weight)
        glorot(self.att_i)
        glorot(self.att_j)
",6
"        zeros(self.bias)

    def forward(self, x, edge_index, return_attention_weights=False):
        """"""""""""
",6
"        edge_index, _ = add_self_loops(edge_index,
                                       num_nodes=x[1].size(self.node_dim))

        out = self.propagate(edge_index, x=x,
                             return_attention_weights=return_attention_weights)
",6
"            out = out + self.bias

        if return_attention_weights:
            alpha, self.__alpha__ = self.__alpha__, None
",6
"
        return x_j * alpha.view(-1, self.heads, 1)

",6
"    def __repr__(self):
        return '{}({}, {}, heads={})'.format(self.__class__.__name__,
",6
"                                             self.out_channels, self.heads)
",6
"    r""""""The (translation-invariant) feature-steered convolutional operator from
    the `""FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis""
    <https://arxiv.org/abs/1706.05206>`_ paper

    .. math::
",6
"        x_j = torch.mm(x_j, self.weight).view(x_j.size(0), self.heads, -1)

        return (x_j * q.view(-1, self.heads, 1)).sum(dim=1)

",6
"    def update(self, aggr_out):
        if self.bias is not None:
",6
"            aggr_out = aggr_out + self.bias
        return aggr_out
",6
"    r""""""The signed graph convolutional operator from the `""Signed Graph
    Convolutional Network"" <https://arxiv.org/abs/1808.06354>`_ paper

    .. math::
        \mathbf{x}_v^{(\textrm{pos})} &= \mathbf{\Theta}^{(\textrm{pos})}
",6
"        \sum_{w \in \mathcal{N}^{-}(v)} \mathbf{x}_w^{(\textrm{pos})} ,
        \mathbf{x}_v^{(\textrm{neg})} \right]
",6
"
    otherwise.
    In case :obj:`first_aggr` is :obj:`False`, the layer expects :obj:`x` to be
    a tensor where :obj:`x[:, :in_channels]` denotes the positive node features
    :math:`\mathbf{X}^{(\textrm{pos})}` and :obj:`x[:, in_channels:]` denotes
",6
"    the negative node features :math:`\mathbf{X}^{(\textrm{neg})}`.
",6
"
    Args:
",6
"            an additive bias. (default: :obj:`True`)
        **kwargs (optional): Additional arguments of
",6
"        self.out_channels = out_channels
        self.first_aggr = first_aggr

",6
"
            x_pos = torch.cat([self.propagate(pos_edge_index, x=x), x], dim=1)
",6
"            x_neg = torch.cat([
                self.propagate(pos_edge_index, x=x_2),
                self.propagate(neg_edge_index, x=x_1),
                x_2,
            ],
",6
"
from ..inits import glorot, zeros


class ChebConv(MessagePassing):
",6
"    and :math:`\mathbf{\hat{L}}` denotes the scaled and normalized Laplacian
    :math:`\frac{2\mathbf{L}}{\lambda_{\max}} - \mathbf{I}`.

    Args:
        in_channels (int): Size of each input sample.
",6
"            1. :obj:`None`: No normalization
            :math:`\mathbf{L} = \mathbf{D} - \mathbf{A}`

",6
"            this operator in case the normalization is non-symmetric.
",6
"    """"""
    def __init__(self, in_channels, out_channels, K, normalization='sym',
",6
"        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)

",6
"        edge_index, edge_weight = get_laplacian(edge_index, edge_weight,
",6
"
        if batch is not None and torch.is_tensor(lambda_max):
",6
"
        return edge_index, edge_weight

    def forward(self, x, edge_index, edge_weight=None, batch=None,
",6
"        lambda_max = 2.0 if lambda_max is None else lambda_max

        edge_index, norm = self.norm(edge_index, x.size(self.node_dim),
",6
"                                     edge_weight, self.normalization,
",6
"        for k in range(2, self.weight.size(0)):
            Tx_2 = 2 * self.propagate(edge_index, x=Tx_1, norm=norm) - Tx_0
            out = out + torch.matmul(Tx_2, self.weight[k])
            Tx_0, Tx_1 = Tx_1, Tx_2
",6
"
        if self.bias is not None:
            out = out + self.bias

",6
"        return out

    def message(self, x_j, norm):
",6
"        return norm.view(-1, 1) * x_j

    def __repr__(self):
        return '{}({}, {}, K={}, normalization={})'.format(
",6
"
        self.reset_parameters()

    def reset_parameters(self):
        if self.requires_grad:
",6
"            :class:`torch_geometric.nn.conv.MessagePassing`.
    """"""

",6
"    def __init__(self,
                 out_channels,
                 num_layers,
                 aggr='add',
",6
"        self.num_layers = num_layers

        self.weight = Param(Tensor(num_layers, out_channels, out_channels))
",6
"
    def reset_parameters(self):
",6
"from torch_geometric.nn.conv import MessagePassing
",6
"     `""Topology Adaptive Graph Convolutional Networks""
",6
"     <https://arxiv.org/abs/1710.10370>`_ paper

",6
"        K (int, optional): Number of hops :math:`K`. (default: :obj:`3`)
        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
        normalize (bool, optional): Whether to apply symmetric normalization.
            (default: :obj:`True`)
",6
"                 normalize=True, **kwargs):
        super(TAGConv, self).__init__(aggr='add', **kwargs)

        self.in_channels = in_channels
",6
"        self.out_channels = out_channels
        self.K = K
        self.normalize = normalize

        self.lin = Linear(in_channels * (self.K + 1), out_channels, bias=bias)
",6
"    @staticmethod
    def norm(edge_index, num_nodes, edge_weight=None, dtype=None):
        if edge_weight is None:
",6
"        for k in range(self.K):
",6
"        out_channels (int): Size of each output sample.
        num_relations (int): Number of relations.
        num_bases (int): Number of bases used for basis-decomposition.
",6
"    """"""
    def __init__(self, in_channels, out_channels, num_relations, num_bases,
                 root_weight=True, bias=True, **kwargs):
        super(RGCNConv, self).__init__(aggr='add', **kwargs)

",6
"        if bias:
            self.bias = Param(torch.Tensor(out_channels))
        else:
            self.register_parameter('bias', None)
",6
"        uniform(size, self.basis)
        uniform(size, self.att)
        uniform(size, self.root)
        uniform(size, self.bias)
",6
"        w = torch.matmul(self.att, self.basis.view(self.num_bases, -1))
",6
"            out = torch.bmm(x_j.unsqueeze(1), w).squeeze(-2)

        return out if edge_norm is None else out * edge_norm.view(-1, 1)

",6
"        return '{}({}, {}, num_relations={})'.format(self.__class__.__name__,
                                                     self.in_channels,
                                                     self.out_channels,
",6
"        get_angle(norm_i, pseudo),
",6
"        get_angle(norm_j, pseudo),
        get_angle(norm_i, norm_j)
    ],
                       dim=1)

",6
"
",6
"            :class:`torch.nn.Sequential`. (default: :obj:`None`)
        global_nn (torch.nn.Module, optional): A neural network
",6
"        kaiming_uniform(self.weight, fan=self.weight.size(1), a=math.sqrt(5))
        uniform(self.weight.size(1), self.bias)

",6
"        # Output: [*, out_channels]

        if self.groups > 1:
",6
"            out = torch.matmul(src, self.weight)
            out = out.transpose(1, 0).contiguous()
            out = out.view(*(size + [self.out_channels]))
        else:
",6
"                                                       self.groups,
",6
"                                                       self.bias is not None)

",6
"        self.lin_k = Linear(in_channels, out_channels, groups, bias)
        self.lin_v = Linear(in_channels, out_channels, groups, bias)
",6
"        self.lin_v.reset_parameters()
",6
"        assert key.size(-2) == value.size(-2)

        query = self.lin_q(query)
        key = self.lin_k(key)
        value = self.lin_v(value)
",6
"
        value_size = size + [value.size(-2), self.heads, out_channels_per_head]
        value = value.view(*value_size).transpose(-2, -3)
",6
"    <https://arxiv.org/abs/1904.04849>`_ paper

    .. math::
        \mathbf{x}_v^{(t)} = h_{\mathbf{\Theta}}^{(t)} \left( \mathbf{x}_{v
",6
"            coefficients. (default: :obj:`0`)
        cached (bool, optional): If set to :obj:`True`, the layer will cache
            the computation of :math:`\mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
            \mathbf{\hat{D}}^{-1/2}` on first execution, and will use the
",6
"            cached version for further executions.
",6
"        self.multi_head = MultiHead(channels, channels, heads, groups, dropout,
                                    bias)
",6
"        self.reset_parameters()

    def reset_parameters(self):
",6
"        # edge_index: [2, num_edges]
        # edge_weight: [num_edges]
",6
"                             'channels].')
        num_nodes, num_layers, channels = x.size()

",6
"
    .. math::
        \mathbf{x}^{\prime}_i = h_{\mathbf{\Theta}} \left( (1 + \epsilon) \cdot
        \mathbf{x}_i + \sum_{j \in \mathcal{N}(i)} \mathbf{x}_j \right)
",6
"    Args:
        nn (torch.nn.Module): A neural network :math:`h_{\mathbf{\Theta}}` that
            maps node features :obj:`x` of shape :obj:`[-1, in_channels]` to
",6
"        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
",6
"        return x_j

",6
"class GINEConv(MessagePassing):
    r""""""The modified :class:`GINConv` operator from the `""Strategies for
",6
"        eps (float, optional): (Initial) :math:`\epsilon` value.
",6
"        reset(self.nn)
        self.eps.data.fill_(self.initial_eps)

    def forward(self, x, edge_index, edge_attr):
        """"""""""""
",6
"        x = x.unsqueeze(-1) if x.dim() == 1 else x
        if edge_attr.dim() == 1:
            edge_attr = edge_attr.unsqueeze(-1)
        assert x.size(-1) == edge_attr.size(-1)
",6
"
    def __repr__(self):
",6
"        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
",6
"        self.max_degree = max_degree
        self.root_weight = root_weight

        self.rel_lins = ModuleList([
            Linear(in_channels, out_channels, bias=bias)
",6
"            self.root_lins = ModuleList([
                Linear(in_channels, out_channels, bias=False)
                for _ in range(max_degree + 1)
            ])

",6
"
        out = x.new_empty(list(x.size())[:-1] + [self.out_channels])

        for i in deg.unique().tolist():
",6
"            idx = (deg == i).nonzero().view(-1)

            r = self.rel_lins[i](h.index_select(self.node_dim, idx))
            if self.root_weight:
                r = r + self.root_lins[i](x.index_select(self.node_dim, idx))
",6
"except ImportError:
    spline_basis = None
",6
"    <https://arxiv.org/abs/1711.08920>`_ paper

    .. math::
        \mathbf{x}^{\prime}_i = \frac{1}{|\mathcal{N}(i)|} \sum_{j \in
        \mathcal{N}(i)} \mathbf{x}_j \cdot
",6
"    .. note::

        Pseudo-coordinates must lay in the fixed interval :math:`[0, 1]` for
",6
"            operator will use a closed B-spline basis in this dimension.
            (default :obj:`True`)
        degree (int, optional): B-spline basis degrees. (default: :obj:`1`)
        aggr (string, optional): The aggregation operator to use
",6
"            (default: :obj:`""mean""`)
        root_weight (bool, optional): If set to :obj:`False`, the layer will
            not add transformed root node features to the output.
            (default: :obj:`True`)
        bias (bool, optional): If set to :obj:`False`, the layer will not learn
",6
"    def __init__(self, in_channels, out_channels, dim, kernel_size,
                 is_open_spline=True, degree=1, aggr='mean', root_weight=True,
                 bias=True, **kwargs):
        super(SplineConv, self).__init__(aggr=aggr, **kwargs)

",6
"
",6
"        self.register_buffer('is_open_spline', is_open_spline)

        K = kernel_size.prod().item()
        self.weight = Parameter(torch.Tensor(K, in_channels, out_channels))

",6
"
        if bias:
            self.bias = Parameter(torch.Tensor(out_channels))
",6
"        self.reset_parameters()

    def reset_parameters(self):
",6
"        zeros(self.bias)

    def forward(self, x, edge_index, pseudo):
        """"""""""""
        x = x.unsqueeze(-1) if x.dim() == 1 else x
",6
"                          'your data to the GPU.')

        if torch_geometric.is_debug_enabled():
",6
"                        self.in_channels, x.size(1)))
",6
"        self.reset_parameters()
",6
"    def forward(self, x, edge_index):
        """"""""""""
        x = x.unsqueeze(-1) if x.dim() == 1 else x

",6
"    r""""""The dynamic edge convolutional operator from the `""Dynamic Graph CNN
    for Learning on Point Clouds"" <https://arxiv.org/abs/1801.07829>`_ paper
    (see :class:`torch_geometric.nn.conv.EdgeConv`), where the graph is
    dynamically constructed using nearest neighbors in the feature space.
",6
"
        if knn_graph is None:
",6
"            raise ImportError('`DynamicEdgeConv` requires `torch-cluster`.')

        self.k = k
",6
"import torch
import torch.nn.functional as F
from torch.nn import Linear
from torch_geometric.nn.conv import MessagePassing
",6
"        normalize (bool, optional): If set to :obj:`True`, output features
            will be :math:`\ell_2`-normalized, *i.e.*,
            :math:`\frac{\mathbf{x}^{\prime}_i}
            {\| \mathbf{x}^{\prime}_i \|_2}`.
            (default: :obj:`False`)
",6
"
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.normalize = normalize
",6
"
        self.lin_rel = Linear(in_channels, out_channels, bias=bias)
",6
"        self.lin_rel.reset_parameters()
        self.lin_root.reset_parameters()

    def forward(self, x, edge_index, edge_weight=None):
",6
"        out = self.lin_rel(out) + self.lin_root(x[1])

        if self.normalize:
            out = F.normalize(out, p=2, dim=-1)
",6
"
        return out

    def message(self, x_j, edge_weight):
        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j
",6
"    def __repr__(self):
        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,
                                   self.out_channels)
from .message_passing import MessagePassing
from .gcn_conv import GCNConv
",6
"from .sg_conv import SGConv
from .appnp import APPNP
from .mf_conv import MFConv
from .rgcn_conv import RGCNConv
from .signed_conv import SignedConv
",6
"from .dna_conv import DNAConv
from .point_conv import PointConv
from .gmm_conv import GMMConv
from .spline_conv import SplineConv
from .nn_conv import NNConv, ECConv
",6
"    'MessagePassing',
    'GCNConv',
    'ChebConv',
    'SAGEConv',
",6
"    'SignedConv',
",6
"    'NNConv',
    'ECConv',
",6
"    'CGConv',
    'EdgeConv',
    'DynamicEdgeConv',
    'XConv',
",6
"    'FeaStConv',
    'HypergraphConv',
",6
"
try:
",6
"        bias (bool, optional): If set to :obj:`False`, the layer will not learn
            an additive bias. (default: :obj:`True`)
        **kwargs (optional): Additional arguments of
",6
"
        self.in_channels = in_channels
",6
"        self.out_channels = out_channels
",6
"
        self.mlp2 = S(
            L(D * K, K**2),
            ELU(),
            BN(K**2),
",6
"
        row, col = knn_graph(pos, K * self.dilation, batch, loop=True,
                             flow='target_to_source', **self.kwargs)
",6
"        pos = pos[col] - pos[row]

        x_star = self.mlp1(pos.view(N * K, D))
",6
"            x = x.unsqueeze(-1) if x.dim() == 1 else x
            x = x[col].view(N, K, self.in_channels)
            x_star = torch.cat([x_star, x], dim=-1)
        x_star = x_star.transpose(1, 2).contiguous()
        x_star = x_star.view(N, self.in_channels + self.hidden_channels, K, 1)
",6
"
    Args:
        in_channels (int): Size of each input sample.
",6
"            if edge_index.size(1) != self.cached_num_edges:
",6
"                        self.cached_num_edges, edge_index.size(1)))

        if not self.cached:
            x = self.lin(x)
",6
"    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j
",6
"            learning scenarios. (default: :obj:`False`)
",6
"        self.weight = Parameter(torch.Tensor(in_channels, out_channels))

        if bias:
",6
"            self.bias = Parameter(torch.Tensor(out_channels))
        else:
",6
"                                     device=edge_index.device)

",6
"        fill_value = 1 if not improved else 2
        edge_index, edge_weight = add_remaining_self_loops(
            edge_index, edge_weight, fill_value, num_nodes)
",6
"
        edge_index, norm = self.cached_result

",6
"        return self.propagate(edge_index, x=x, norm=norm)

    def message(self, x_j, norm):
        return norm.view(-1, 1) * x_j if norm is not None else x_j

",6
"
",6
"    Args:
",6
"
        hidden = x
        for k in range(self.K):
            x = self.propagate(edge_index, x=x, norm=norm)
            x = x * (1 - self.alpha)
",6
"
EPS = 1e-15

",6
"    Deep Learning on Graphs and Manifolds using Mixture Model CNNs""
    <https://arxiv.org/abs/1611.08402>`_ paper

    .. math::
",6
"        **kwargs (optional): Additional arguments of
            :class:`torch_geometric.nn.conv.MessagePassing`.
    """"""

    def __init__(self, in_channels, out_channels, dim, kernel_size,
",6
"        self.in_channels = in_channels
        self.out_channels = out_channels
",6
"        self.dim = dim
        self.kernel_size = kernel_size
        self.separate_gaussians = separate_gaussians

",6
"        if self.bias is not None:
            out = out + self.bias

        return out
",6
"
        else:
            gaussian = -0.5 * (pseudo.view(E, 1, 1, 1, D) -
                               self.mu.view(1, F, M, K, D)).pow(2)
",6
"            gaussian = gaussian.sum(dim=-1)  # [E, F, M]

            return (x_j.view(E, F, 1) * gaussian).sum(dim=-2)  # [E, M]

    def __repr__(self):
",6
"from torch_scatter import scatter_mean
",6
"    num_nodes = cluster.size(0)
",6
"                                         num_nodes)
    return edge_index, edge_attr


def pool_batch(perm, batch):
",6
"            :class:`torch_geometric.nn.conv.GCNConv` or
            any GNN which supports the :obj:`edge_weight` parameter).
            (default: :obj:`None`)
        dropout (float, optional): Dropout probability of the normalized
            attention coefficients which exposes each node to a stochastically
",6
"            loops to the new graph connectivity. (default: :obj:`False`)
",6
"        self.negative_slope = negative_slope
        self.dropout = dropout
        self.GNN = GNN
        self.add_self_loops = add_self_loops
",6
"    def reset_parameters(self):
        self.lin.reset_parameters()
        self.att.reset_parameters()
        self.gnn_score.reset_parameters()
",6
"        if self.GNN is not None:
            self.gnn_intra_cluster.reset_parameters()

    def forward(self, x, edge_index, edge_weight=None, batch=None):
        N = x.size(0)
",6
"                                            edge_weight=edge_weight)

        x_pool_j = x_pool[edge_index[0]]
        x_q = scatter(x_pool_j, edge_index[1], dim=0, reduce='max')
        x_q = self.lin(x_q)[edge_index[1]]
",6
"        else:
            A = A.remove_diag()

        row, col, edge_weight = A.coo()
        edge_index = torch.stack([row, col], dim=0)
",6
"
def topk(x, ratio, batch, min_score=None, tol=1e-7):
    if min_score is not None:
",6
"        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)
        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()

        cum_num_nodes = torch.cat(
",6
"    <https://arxiv.org/abs/1905.05178>`_, `""Towards Sparse
",6
"        .. math::
            \mathbf{y} &= \frac{\mathbf{X}\mathbf{p}}{\| \mathbf{p} \|}
",6
"
    Args:
        in_channels (int): Size of each input sample.
        ratio (float): Graph pooling ratio, which is used to compute
            :math:`k = \lceil \mathrm{ratio} \cdot N \rceil`.
",6
"            :math:`\mathbf{i} = \mathbf{y}_i > \tilde{\alpha}`.
            When this value is not :obj:`None`, the :obj:`ratio` argument is
            ignored. (default: :obj:`None`)
",6
"        super(TopKPooling, self).__init__()

        self.in_channels = in_channels
        self.ratio = ratio
",6
"        return '{}({}, {}={}, multiplier={})'.format(
            self.__class__.__name__, self.in_channels,
            'ratio' if self.min_score is None else 'min_score',
            self.ratio if self.min_score is None else self.min_score,
",6
"def max_pool_x(cluster, x, batch, size=None):
",6
"            B-1\}}^N`, which assigns each node to a specific example.
        size (int, optional): The maximum number of clusters in a single
",6
"
    cluster, perm = consecutive_cluster(cluster)
    x = _max_pool_x(cluster, x)
",6
"    within the same cluster, node positions are averaged and edge indices are
    defined to be the union of the edge indices of all nodes within the same
    cluster.

",6
"    Args:
",6
"    batch = None if data.batch is None else pool_batch(perm, data.batch)
    pos = None if data.pos is None else pool_pos(cluster, data.pos)

    data = Batch(batch=batch, x=x, edge_index=index, edge_attr=attr, pos=pos)
",6
"
    :rtype: (:class:`Tensor`, :class:`LongTensor`) if :attr:`size` is
        :obj:`None`, else :class:`Tensor`
    """"""
    if size is not None:
",6
"
def avg_pool(cluster, data, transform=None):
    r""""""Pools and coarsens a graph given by the
    :class:`torch_geometric.data.Data` object according to the clustering
    defined in :attr:`cluster`.
",6
"
    :rtype: :class:`torch_geometric.data.Data`
    """"""
    cluster, perm = consecutive_cluster(cluster)
",6
"
    x = None if data.x is None else _avg_pool_x(cluster, data.x)
",6
"
class EdgePooling(torch.nn.Module):
    r""""""The edge pooling operator from the `""Towards Graph Pooling by Edge
    Contraction"" <https://graphreason.github.io/papers/17.pdf>`_ and
    `""Edge Contraction Pooling for Graph Neural Networks""
",6
"    In short, a score is computed for each edge.
    Edges are contracted iteratively according to that score unless one of
    their nodes has already been part of a contracted edge.

",6
"    :obj:`add_to_edge_score` to :obj:`0`.

",6
"            Included functions are
            :func:`EdgePooling.compute_edge_score_softmax`,
            :func:`EdgePooling.compute_edge_score_tanh`, and
",6
"        dropout (float, optional): The probability with
            which to drop edge scores during training. (default: :obj:`0`)
        add_to_edge_score (float, optional): This is added to each
",6
"            stability. (default: :obj:`0.5`)
    """"""

    unpool_description = namedtuple(
",6
"        return softmax(raw_edge_score, edge_index[1], num_nodes)
",6
"
    def forward(self, x, edge_index, batch):
        r""""""Forward computation which computes the raw edge score, normalizes
        it, and merges the edges.

",6
"                                              cluster=cluster, batch=batch,
                                              new_edge_score=new_edge_score)

        return new_x, new_edge_index, new_batch, unpool_info
",6
"
    def unpool(self, x, unpool_info):
        r""""""Unpools a previous edge pooling step.
",6
"            \mathbf{y} &= \mathrm{softmax}(\textrm{GNN}(\mathbf{X},\mathbf{A}))

            \mathbf{i} &= \mathbf{y}_i > \tilde{\alpha}

",6
"    Projections scores are learned based on a graph neural network layer.

    Args:
        in_channels (int): Size of each input sample.
        ratio (float): Graph pooling ratio, which is used to compute
",6
"        **kwargs (optional): Additional parameters for initializing the graph
            neural network layer.
    """"""

    def __init__(self, in_channels, ratio=0.5, GNN=GraphConv, min_score=None,
",6
"        self.min_score = min_score
        self.multiplier = multiplier
        self.nonlinearity = nonlinearity

        self.reset_parameters()
",6
"    def reset_parameters(self):
        self.gnn.reset_parameters()
",6
"
    def forward(self, x, edge_index, edge_attr=None, batch=None, attn=None):
",6
"
        if self.min_score is None:
            score = self.nonlinearity(score)
        else:
            score = softmax(score, batch)
",6
"                                           num_nodes=score.size(0))

        return x, edge_index, edge_attr, batch, perm, score[perm]
",6
"        random_start (bool, optional): If set to :obj:`False`, use the first
            node in :math:`\mathbf{X}` as starting node. (default: obj:`True`)

",6
"    r""""""Finds for each element in :obj:`y` the :obj:`k` nearest points in
    :obj:`x`.

    Args:
        x (Tensor): Node feature matrix
",6
"    return torch_cluster.knn(x, y, k, batch_x, batch_y, cosine)
",6
"        cosine (boolean, optional): If :obj:`True`, will use the cosine
",6
"    distance :obj:`r`.

    Args:
        x (Tensor): Node feature matrix
            :math:`\mathbf{X} \in \mathbb{R}^{N \times F}`.
",6
"            :math:`\mathbf{Y} \in \mathbb{R}^{M \times F}`.
        r (float): The radius.
        batch_x (LongTensor, optional): Batch vector
            :math:`\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
",6
"        batch = torch.tensor([0, 0, 0, 0])
        edge_index = radius_graph(x, r=1.5, batch=batch, loop=False)
    """"""
    if torch_cluster is None:
",6
"            :math:`\mathbf{Y} \in \mathbb{R}^{M \times F}`.
        batch_x (LongTensor, optional): Batch vector
            :math:`\mathbf{b} \in {\{ 0, \ldots, B-1\}}^N`, which assigns each
            node to a specific example. (default: :obj:`None`)
        batch_y (LongTensor, optional): Batch vector
",6
"            :math:`\mathbf{b} \in {\{ 0, \ldots, B-1\}}^M`, which assigns each
            node to a specific example. (default: :obj:`None`)

",6
"def voxel_grid(pos, batch, size, start=None, end=None):
",6
"    start = start.tolist() if torch.is_tensor(start) else start
    end = end.tolist() if torch.is_tensor(end) else end

    size, start, end = repeat(size, dim), repeat(start, dim), repeat(end, dim)
",6
"    Reducing Internal Covariate Shift"" <https://arxiv.org/abs/1502.03167>`_
    paper

    .. math::
        \mathbf{x}^{\prime}_i = \frac{\mathbf{x} -
",6
"        in_channels (int): Size of each input sample.
",6
"            running variance computation. (default: :obj:`0.1`)
        affine (bool, optional): If set to :obj:`True`, this module has
            learnable affine parameters :math:`\gamma` and :math:`\beta`.
            (default: :obj:`True`)
",6
"
    def __repr__(self):
        return ('{}({}, eps={}, momentum={}, affine={}, '
                'track_running_stats={})').format(self.__class__.__name__,
",6
"    paper

    .. math::
        \mathbf{x}^{\prime}_i = \frac{\mathbf{x} -
        \textrm{E}[\mathbf{x}]}{\sqrt{\textrm{Var}[\mathbf{x}] + \epsilon}}
",6
"
    Args:
",6
"        if self.training and self.track_running_stats:
            momentum = self.momentum
            self.running_mean = (
                1 - momentum) * self.running_mean + momentum * mean.mean(dim=0)
            self.running_var = (
",6
"                1 - momentum
            ) * self.running_var + momentum * unbiased_var.mean(dim=0)

        if not self.training and self.track_running_stats:
            mean = self.running_mean.view(1, -1).expand(batch_size, -1)
",6
"        return out
import torch
import torch.nn as nn
from torch_geometric.utils import degree
",6
"    def __init__(self):
",6
"
__all__ = [
    'BatchNorm',
",6
"from torch_scatter import scatter_add
from torch_geometric.utils import softmax

from ..inits import reset
",6
"
    .. math::
        \mathbf{r}_i = \sum_{n=1}^{N_i} \mathrm{softmax} \left(
        h_{\mathrm{gate}} ( \mathbf{x}_n ) \right) \odot
        h_{\mathbf{\Theta}} ( \mathbf{x}_n ),
",6
"        gate = self.gate_nn(x).view(-1, 1)
        x = self.nn(x) if self.nn is not None else x
        assert gate.dim() == x.dim() and gate.size(0) == x.size(0)

",6
"        \mathbf{q}_t &= \mathrm{LSTM}(\mathbf{q}^{*}_{t-1})

        \alpha_{i,t} &= \mathrm{softmax}(\mathbf{x}_i \cdot \mathbf{q}_t)

",6
"        in_channels (int): Size of each input sample.
",6
"            LSTM and computing the final results. (default: :obj:`1`)
",6
"        self.reset_parameters()

",6
"
    def forward(self, x, batch):
        """"""""""""
        batch_size = batch.max().item() + 1
",6
"
",6
"    :rtype: :class:`Tensor`
",6
"            B-1\}}^N`, which assigns each node to a specific example.
        k (int): The number of nodes to hold for each graph.
",6
"    batch_x = batch_x.view(B, N, D)
",6
"
    if N >= k:
        batch_x = batch_x[:, :k].contiguous()
    else:
",6
"from .set2set import Set2Set

__all__ = [
    'global_add_pool',
",6
"        self.reset_parameters()

    def reset_parameters(self):
        self.lin_rel.reset_parameters()
        self.lin_root.reset_parameters()
",6
"        r""""""
",6
"            add_loop (bool, optional): If set to :obj:`False`, the layer will
                not automatically add self-loops to the adjacency matrices.
",6
"        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj
        B, N, _ = adj.size()

",6
"        self.nn = nn
        self.initial_eps = eps
",6
"                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\mathbf{A} \in \mathbb{R}^{B
                \times N \times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
",6
"                the complete batch.
",6
"
        if mask is not None:
            out = out * mask.view(B, N, 1).to(x.dtype)

        return out
",6
"

class DenseGraphConv(torch.nn.Module):
    r""""""See :class:`torch_geometric.nn.conv.GraphConv`.
",6
"
    def forward(self, x, adj, mask=None):
        r""""""
        Args:
",6
"                number of nodes :math:`N` for each graph, and feature
                dimension :math:`F`.
            adj (Tensor): Adjacency tensor :math:`\mathbf{A} \in \mathbb{R}^{B
                \times N \times N}`. The adjacency tensor is broadcastable in
                the batch dimension, resulting in a shared adjacency matrix for
",6
"    'dense_mincut_pool',
",6
"            self.register_parameter('bias', None)

        self.reset_parameters()
",6
"        zeros(self.bias)

    def forward(self, x, adj, mask=None, add_loop=True):
        r""""""
",6
"                (default: :obj:`True`)
        """"""
",6
"    r""""""MinCUt pooling operator from the `""Mincut Pooling in Graph Neural
",6
"    where :math:`\mathbf{D}` is the degree matrix, and (2) the orthogonality
    loss
",6
"
    Args:
        x (Tensor): Node feature tensor :math:`\mathbf{X} \in \mathbb{R}^{B
",6
"    # MinCUT regularization.
    mincut_num = _rank3_trace(out_adj)
    d_flat = torch.einsum('ijk->ij', adj)
",6
"        torch.matmul(torch.matmul(s.transpose(1, 2), d), s))
    mincut_loss = -(mincut_num / mincut_den)
    mincut_loss = torch.mean(mincut_loss)

",6
"    # Fix and normalize coarsened adjacency matrix.
    ind = torch.arange(k, device=out_adj.device)
    out_adj[:, ind, ind] = 0
    d = torch.einsum('ijk->ij', out_adj)
",6
"

def _rank3_trace(x):
",6
"
",6
"            :math:`F`.
",6
"            :math:`\mathbf{M} \in {\{ 0, 1 \}}^{B \times N}` indicating
            the valid nodes for each graph. (default: :obj:`None`)

    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,
",6
"        :class:`Tensor`)
",6
"        x, s = x * mask, s * mask

    out = torch.matmul(s.transpose(1, 2), x)
    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)

",6
"
    ent_loss = (-s * torch.log(s + EPS)).sum(dim=-1).mean()

    return out, out_adj, link_loss, ent_loss
import torch
",6
"try:
    import torch_cluster  # noqa
    random_walk = torch.ops.torch_cluster.random_walk
",6
"EPS = 1e-15
",6
"        self.walk_length = walk_length - 1
        self.context_size = context_size
        self.walks_per_node = walks_per_node
        self.p = p
        self.q = q
",6
"        return torch.cat(walks, dim=0)

",6
"        # Positive loss.
        start, rest = pos_rw[:, 0], pos_rw[:, 1:].contiguous()

        h_start = self.embedding(start).view(pos_rw.size(0), 1,
",6
"        r""""""Evaluates latent space quality via a logistic regression downstream
        task.""""""
        clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,
                                 **kwargs).fit(train_z.detach().cpu().numpy(),
",6
"                                               train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(),
                         test_y.detach().cpu().numpy())

",6
"import os.path as osp
from math import pi as PI
import warnings
",6
"from torch_geometric.nn import radius_graph, MessagePassing

",6
"try:
    import schnetpack as spk
",6
"    3: 'lumo',
    4: 'gap',
    5: 'electronic_spatial_extent',
    6: 'zpve',
",6
"class SchNet(torch.nn.Module):
",6
"
",6
"    Args:
        hidden_channels (int, optional): Hidden embedding size.
",6
"        num_interactions (int, optional): The number of interaction blocks.
",6
"
",6
"            self.interactions.append(block)
",6
"
        self.lin1 = Linear(hidden_channels, hidden_channels // 2)
        self.act = ShiftedSoftplus()
        self.lin2 = Linear(hidden_channels // 2, 1)

",6
"        self.atomref = None
        if atomref is not None:
            self.atomref = Embedding(100, 1)
            self.atomref.weight.data.copy_(atomref)
",6
"            interaction.reset_parameters()
        torch.nn.init.xavier_uniform_(self.lin1.weight)
        self.lin1.bias.data.fill_(0)
        torch.nn.init.xavier_uniform_(self.lin2.weight)
        self.lin2.bias.data.fill_(0)
",6
"        assoc[idx] = torch.arange(idx.size(0))

        train_idx = assoc[train_idx[np.isin(train_idx, idx)]]
        val_idx = assoc[val_idx[np.isin(val_idx, idx)]]
",6
"        path = osp.join(root, 'trained_schnet_models', name, 'best_model')

        with warnings.catch_warnings():
            warnings.filterwarnings('ignore')
            state = torch.load(path, map_location='cpu')
",6
"        net.embedding.weight = state.representation.embedding.weight
",6
"                              net.interactions):
",6
"        net.lin1.bias = state.output_modules[0].out_net[1].out_net[0].bias
        net.lin2.weight = state.output_modules[0].out_net[1].out_net[1].weight
        net.lin2.bias = state.output_modules[0].out_net[1].out_net[1].bias

",6
"        mean = state.output_modules[0].atom_pool.average
",6
"
        h = self.lin1(h)
",6
"            h = h * self.std + self.mean

        if not self.dipole and self.atomref is not None:
",6
"            h = h + self.atomref(z)
",6
"        if self.scale is not None:
            out = self.scale * out

        return out

",6
"    def __repr__(self):
        return (f'{self.__class__.__name__}('
",6
"class InteractionBlock(torch.nn.Module):
    def __init__(self, hidden_channels, num_gaussians, num_filters, cutoff):
        super(InteractionBlock, self).__init__()
        self.mlp = Sequential(
            Linear(num_gaussians, num_filters),
",6
"    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.mlp[0].weight)
",6
"EPS = 1e-15
",6
"    Explanations for Graph Neural Networks""
    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph
    structures and small subsets node features that play a crucial role in a
    GNNâs node-predictions.
",6
"
    .. note::

        For an example of using GNN-Explainer, see `examples/gnn_explainer.py
",6
"        <https://github.com/rusty1s/pytorch_geometric/blob/master/examples/
        gnn_explainer.py>`_.

    Args:
",6
"            (default: :obj:`0.01`)
        log (bool, optional): If set to :obj:`False`, will not log any learning
            progress. (default: :obj:`True`)
    """"""
",6
"            if isinstance(module, MessagePassing):
                module.__explain__ = True
                module.__edge_mask__ = self.edge_mask

    def __clear_masks__(self):
",6
"        self.edge_mask = None

    def __num_hops__(self):
        num_hops = 0
",6
"                return module.flow
        return 'source_to_target'

    def __subgraph__(self, node_idx, x, edge_index, **kwargs):
",6
"        num_nodes, num_edges = x.size(0), edge_index.size(1)

        subset, edge_index, mapping, edge_mask = k_hop_subgraph(
            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,
",6
"                item = item[subset]
            elif torch.is_tensor(item) and item.size(0) == num_edges:
                item = item[edge_mask]
            kwargs[key] = item
",6
"        with torch.no_grad():
            log_logits = self.model(x=x, edge_index=edge_index, **kwargs)
",6
"            pred_label = log_logits.argmax(dim=-1)
",6
"        self.__clear_masks__()

        return node_feat_mask, edge_mask

    def visualize_subgraph(self, node_idx, edge_index, edge_mask, y=None,
",6
"        # Only operate on a k-hop subgraph around `node_idx`.
        subset, edge_index, _, hard_edge_mask = k_hop_subgraph(
            node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,
            num_nodes=None, flow=self.__flow__())
",6
"import torch
",6
"
from ..inits import reset
",6
"EPS = 1e-15
MAX_LOGVAR = 10


",6
"
    def decode(self, *args, **kwargs):
",6
"
",6
"

",6
"class VGAE(GAE):
    r""""""The Variational Graph Auto-Encoder model from the
    `""Variational Graph Auto-Encoders"" <https://arxiv.org/abs/1611.07308>`_
    paper.
",6
"
",6
"                :obj:`None`, uses the last computation of :math:`mu`.
                (default: :obj:`None`)
            logvar (Tensor, optional): The latent space for
                :math:`\log\sigma^2`.  If set to :obj:`None`, uses the last
",6
"    <https://arxiv.org/abs/1802.04407>`_ paper.
    paper.

    Args:
",6
"        encoder (Module): The encoder module.
        discriminator (Module): The discriminator module.
        decoder (Module, optional): The decoder module. If set to :obj:`None`,
",6
"        reset(self.discriminator)

    def reg_loss(self, z):
        r""""""Computes the regularization loss of the encoder.
",6
"    """"""
    def __init__(self, encoder, discriminator, decoder=None):
",6
"        """"""""""""
",6
"from scipy import special as sp
",6
"
def Jn_zeros(n, k):
    zerosj = np.zeros((n, k), dtype='float32')
    zerosj[0] = np.arange(1, k + 1) * np.pi
    points = np.arange(1, k + n) * np.pi
",6
"    return zerosj


def spherical_bessel_formulas(n):
    x = sym.symbols('x')
",6
"
    f = [sym.sin(x) / x]
    a = sym.sin(x) / x
    for i in range(1, n):
",6
"    x = sym.symbols('x')
    bess_basis = []
    for order in range(n):
        bess_basis_tmp = []
",6
"                             f[order].subs(x, zeros[order, i] * x))
            ]
        bess_basis += [bess_basis_tmp]
    return bess_basis

",6
"
    P_l_m[0][0] = 1
    if k > 0:
        P_l_m[1][0] = z

",6
"                for j in range(i + 2, k):
                    P_l_m[j][i] = sym.simplify(
                        ((2 * j - 1) * z * P_l_m[j - 1][i] -
                         (i + j - 1) * P_l_m[j - 2][i]) / (j - i))

",6
"    return P_l_m


def real_sph_harm(k, zero_m_only=True, spherical_coordinates=True):
    if not zero_m_only:
",6
"                                     sym.sin(theta) * sym.cos(phi)).subs(
                                         y,
",6
"                Y_func_l_m[i][-j] = sym.simplify(
                    2**0.5 * sph_harm_prefactor(i, -j) * S_m[j] * P_l_m[i][j])
",6
"import math

import torch
",6
"    :math:`f_{\mathbf{\Theta}}` as a linear projection.

    Args:
",6
"            final prediction. (default: :obj:`0.`)
        bias (bool, optional): If set to :obj:`False`, all layers will not
            learn an additive bias. (default: :obj:`True`)
    """"""

",6
"    def __init__(self, num_nodes, num_rels, hidden_channels, seq_len,
                 num_layers=1, dropout=0., bias=True):
        super(RENet, self).__init__()

        self.num_nodes = num_nodes
",6
"        self.hidden_channels = hidden_channels
        self.num_rels = num_rels
        self.seq_len = seq_len
        self.dropout = dropout

",6
"                           batch_first=True, bias=bias)
",6
"
        self.sub_lin = Linear(3 * hidden_channels, num_nodes, bias=bias)
        self.obj_lin = Linear(3 * hidden_channels, num_nodes, bias=bias)

        self.reset_parameters()
",6
"        r""""""Precomputes history objects

        .. math::
            \{ \mathcal{O}^{(t-k-1)}_r(s), \ldots, \mathcal{O}^{(t-1)}_r(s) \}
",6
"                node, r = torch.tensor(hists, dtype=torch.long).view(
                    -1, 2).t().contiguous()
                node = node[r == rel]
                t = torch.cat(ts, dim=0)[r == rel]
",6
"                    hist[i].append([])
                return hist
",6
"
            def __repr__(self):  # pragma: no cover
                return '{}(seq_len={})'.format(self.__class__.__name__,
                                               self.seq_len)

",6
"
        h_sub = scatter_mean(self.ent[data.h_sub], h_sub_t, dim=0,
                             dim_size=batch_size * seq_len).view(
                                 batch_size, seq_len, -1)
        h_obj = scatter_mean(self.ent[data.h_obj], h_obj_t, dim=0,
",6
"                             dim_size=batch_size * seq_len).view(
                                 batch_size, seq_len, -1)

        sub = self.ent[data.sub].unsqueeze(1).repeat(1, seq_len, 1)
        rel = self.rel[data.rel].unsqueeze(1).repeat(1, seq_len, 1)
",6
"        log_prob_sub = F.log_softmax(self.obj_lin(h_obj), dim=1)

        return log_prob_obj, log_prob_sub

",6
"        return torch.tensor([mrr, hits1, hits3, hits10])
import torch
",6
"    architecture with graph pooling and unpooling operations.

    Args:
",6
"        depth (int): The depth of the U-Net architecture.
        pool_ratios (float or [float], optional): Graph pooling ratio for each
            depth. (default: :obj:`0.5`)
",6
"
        channels = hidden_channels

        self.down_convs = torch.nn.ModuleList()
        self.pools = torch.nn.ModuleList()
",6
"        self.up_convs = torch.nn.ModuleList()
        for i in range(depth - 1):
            self.up_convs.append(GCNConv(in_channels, channels, improved=True))
",6
"
    def forward(self, x, edge_index, batch=None):
        """"""""""""
        if batch is None:
",6
"            batch = edge_index.new_zeros(x.size(0))
        edge_weight = x.new_ones(edge_index.size(1))

        x = self.down_convs[0](x, edge_index, edge_weight)
        x = self.act(x)
",6
"            up[perm] = x
            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)

            x = self.up_convs[i](x, edge_index, edge_weight)
",6
"            alpha = torch.softmax(alpha, dim=-1)
            return (x * alpha.unsqueeze(-1)).sum(dim=1)
",6
"    r""""""The MetaPath2Vec model from the `""metapath2vec: Scalable Representation
    Learning for Heterogeneous Networks""
    <https://ericdongyx.github.io/papers/
",6
"    KDD17-dong-chawla-swami-metapath2vec.pdf>`_ paper where random walks based
    on a given :obj:`metapath` are sampled in a heterogeneous graph, and node
    embeddings are learned via negative sampling optimization.

",6
"        metapath2vec.py>`_.
",6
"            positive samples. This parameter increases the effective sampling
            rate by reusing samples across different source nodes.
",6
"        walks_per_node (int, optional): The number of walks to sample for each
            node. (default: :obj:`1`)
        num_negative_samples (int, optional): The number of negative samples to
            use for each positive sample. (default: :obj:`1`)
        num_nodes_dict (dict, optional): Dictionary holding the number of nodes
",6
"        super(MetaPath2Vec, self).__init__()

        if num_nodes_dict is None:
            num_nodes_dict = {}
",6
"                num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))

                key = keys[-1]
                N = int(edge_index[1].max() + 1)
",6
"        adj_dict = {}
        for keys, edge_index in edge_index_dict.items():
            sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])
            row, col = edge_index
",6
"        self.context_size = context_size
",6
"        offset = [self.start[metapath[0][0]]]
        offset += [self.start[keys[-1]] for keys in metapath
",6
"        for i in range(self.walk_length):
            keys = self.metapath[i % len(self.metapath)]
",6
"
        rws = [batch]
        for i in range(self.walk_length):
            keys = self.metapath[i % len(self.metapath)]
",6
"                                 **kwargs).fit(train_z.detach().cpu().numpy(),
                                               train_y.detach().cpu().numpy())
        return clf.score(test_z.detach().cpu().numpy(),
",6
"from .node2vec import Node2Vec
",6
"    'VGAE',
    'ARGA',
",6
"    r""""""The signed graph convolutional network model from the `""Signed Graph
",6
"    Convolutional Network"" <https://arxiv.org/abs/1808.06354>`_ paper.
    Internally, this module uses the
    :class:`torch_geometric.nn.conv.SignedConv` operator.

    Args:
",6
"            learn an additive bias. (default: :obj:`True`)
    """"""
",6
"            test_ratio (float, optional): The ratio of test edges.
                (default: :obj:`0.2`)
        """"""
",6
"        Args:
",6
"            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
            num_nodes (int, optional): The number of nodes, *i.e.*
                :obj:`max_val + 1` of :attr:`pos_edge_index` and
                :attr:`neg_edge_index`. (default: :obj:`None`)
",6
"        row, col = edge_index
        edge_index = torch.cat([edge_index, torch.stack([col, row])], dim=1)
        val = torch.cat([val, val], dim=0)

        edge_index, val = coalesce(edge_index, val, N, N)
",6
"            z = F.relu(conv(z, pos_edge_index, neg_edge_index))
        return z

    def discriminate(self, z, edge_index):
",6
"        negative or non-existent.

        Args:
            x (Tensor): The input node features.
            edge_index (LongTensor): The edge indices.
",6
"        """"""
        value = torch.cat([z[edge_index[0]], z[edge_index[1]]], dim=1)
        value = self.lin(value)
        return torch.log_softmax(value, dim=1)
",6
"
        Args:
",6
"
        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)
        none_edge_index = negative_sampling(edge_index, z.size(0))
",6
"            pos_edge_index (LongTensor): The positive edge indices.
            neg_edge_index (LongTensor): The negative edge indices.
        """"""
        with torch.no_grad():
            pos_p = self.discriminate(z, pos_edge_index)[:, :2].max(dim=1)[1]
",6
"    :math:`\mathcal{C}`.

    Args:
        hidden_channels (int): The latent space dimensionality.
        encoder (Module): The encoder module :math:`\mathcal{E}`.
",6
"        super(DeepGraphInfomax, self).__init__()
        self.hidden_channels = hidden_channels
        self.encoder = encoder
        self.summary = summary
",6
"        self.corruption = corruption

        self.weight = Parameter(torch.Tensor(hidden_channels, hidden_channels))

        self.reset_parameters()
",6
"    def reset_parameters(self):
        reset(self.encoder)
",6
"        cor = self.corruption(*args, **kwargs)
        cor = cor if isinstance(cor, tuple) else (cor, )
        neg_z = self.encoder(*cor)
        summary = self.summary(pos_z, *args, **kwargs)
        return pos_z, neg_z, summary
",6
"            self.discriminate(pos_z, summary, sigmoid=True) + EPS).mean()
        neg_loss = -torch.log(
",6
"        clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,
                                 **kwargs).fit(train_z.detach().cpu().numpy(),
                                               train_y.detach().cpu().numpy())
",6
"except ImportError:
    sym = None
",6
"    def reset_parameters(self):
        torch.arange(1, self.freq.numel() + 1, out=self.freq).mul_(PI)

",6
"        self.envelope = Envelope(envelope_exponent)
",6
"            for j in range(num_radial):
                bessel = sym.lambdify([x], bessel_forms[i][j], modules)
                self.bessel_funcs.append(bessel)
",6
"        self.lin = Linear(3 * hidden_channels, hidden_channels)

        self.reset_parameters()

    def reset_parameters(self):
",6
"        self.lin.reset_parameters()

    def forward(self, x, rbf, i, j):
        x = self.lin_x(x)
        rbf = self.act(self.lin_rbf(rbf))
",6
"        self.lin1 = Linear(hidden_channels, hidden_channels)
",6
"
        self.reset_parameters()

    def reset_parameters(self):
",6
"            h = layer(h)
        h = self.act(self.lin(h)) + x
        for layer in self.layers_before_skip:
            h = layer(h)

",6
"                 act=swish):
        super(OutputBlock, self).__init__()
        self.act = act

        self.lin_rbf = Linear(num_radial, hidden_channels, bias=False)
",6
"
        self.reset_parameters()
",6
"            lin.bias.data.fill_(0)
",6
"
        self.output_blocks = torch.nn.ModuleList([
",6
"        idx_i = col.repeat_interleave(num_triplets)
        idx_j = row.repeat_interleave(num_triplets)
",6
"        idx_kj = adj_t_row.storage.value()[mask]
",6
"        """"""""""""
        j, i = edge_index
        idx_i, idx_j, idx_k, idx_kj, idx_ji = self.triplets(
            edge_index, num_nodes=x.size(0))

",6
"        # Calculate distances.
        dist = (pos[i] - pos[j]).pow(2).sum(dim=-1).sqrt()
",6
"
",6
"        \mathbf{f}(y) = \frac{\sum_{i=1}^k w(x_i) \mathbf{f}(x_i)}{\sum_{i=1}^k
        w(x_i)} \textrm{, where } w(x_i) = \frac{1}{d(\mathbf{p}(y),
        \mathbf{p}(x_i))^2}

",6
"    and :math:`\{ x_1, \ldots, x_k \}` denoting the :math:`k` nearest points
    to :math:`y`.

",6
"from torch_geometric.datasets import Planetoid
from torch_geometric.nn import Node2Vec

",6
"        optimizer.step()
",6
"colors = [
    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535', '#ffd700'
]
plot_points(colors)
import os.path as osp
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
dataset = Planetoid(path, dataset)
",6
"        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        return F.log_softmax(x, dim=1)
",6
"

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"

best_val_acc = test_acc = 0
for epoch in range(1, 101):
    train()
",6
"        test_acc = tmp_test_acc
    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'
    print(log.format(epoch, train_acc, best_val_acc, test_acc))
import os.path as osp

",6
"import torch
",6
"        dim = 32
",6
"        x = F.relu(self.conv2(x, edge_index))
",6
"    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        output = model(data.x, data.edge_index, data.batch)
        loss = F.nll_loss(output, data.y)
",6
"        optimizer.step()
    return loss_all / len(train_dataset)
",6
"
def test(loader):
    model.eval()

",6
"def MLP(channels, batch_norm=True):
",6
"    def forward(self, data):
        sa0_out = (data.x, data.pos, data.batch)
",6
"def train(epoch):
    model.train()

    for data in train_loader:
        data = data.to(device)
",6
"        correct += pred.eq(data.y).sum().item()
    return correct / len(loader.dataset)

",6
"    pre_transform, transform = T.NormalizeScale(), T.SamplePoints(1024)
    train_dataset = ModelNet(path, '10', True, transform, pre_transform)
    test_dataset = ModelNet(path, '10', False, transform, pre_transform)
",6
"    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,
                              num_workers=6)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,
                             num_workers=6)

",6
"
    for epoch in range(1, 201):
        train(epoch)
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Reddit')
dataset = Reddit(path)
data = dataset[0]

train_loader = NeighborSampler(data.edge_index, node_idx=data.train_mask,
",6
"    def __init__(self, in_channels, hidden_channels, out_channels):
",6
"            x_target = x[:size[1]]  # Target nodes are always placed first.
            x = self.convs[i]((x, x_target), edge_index)
            if i != self.num_layers - 1:
",6
"        pbar = tqdm(total=x_all.size(0) * self.num_layers)
        pbar.set_description('Evaluating')
",6
"
        # Compute representations of nodes layer by layer, using *all*
        # available edges. This leads to faster computation in contrast to
",6
"        # immediately computing the final representations of each batch.
        for i in range(self.num_layers):
            xs = []
            for batch_size, n_id, adj in subgraph_loader:
",6
"                x_target = x[:size[1]]
",6
"model = model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

x = data.x.to(device)
y = data.y.squeeze().to(device)
",6
"        out = model(x[n_id], adjs)
        loss = F.nll_loss(out, y[n_id[:batch_size]])
        loss.backward()
        optimizer.step()
",6
"        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())
",6
"    approx_acc = total_correct / int(data.train_mask.sum())
",6
"    return loss, approx_acc


",6
"@torch.no_grad()
",6
"    return results


for epoch in range(1, 11):
",6
"
from pointnet2_classification import MLP

category = 'Airplane'
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'ShapeNet')
transform = T.Compose([
    T.RandomTranslate(0.01),
",6
"def train():
    model.train()
",6
"            total_loss = correct_nodes = total_nodes = 0


def test(loader):
",6
"    model.eval()

    correct_nodes = total_nodes = 0
",6
"    for cat in range(len(loader.dataset.categories)):
        ious[cat] = torch.tensor(ious[cat]).mean().item()

    return correct_nodes / total_nodes, torch.tensor(ious).mean().item()

",6
"
for epoch in range(1, 31):
    train()
    acc, iou = test(test_loader)
    print('Epoch: {:02d}, Acc: {:.4f}, IoU: {:.4f}'.format(epoch, acc, iou))
",6
"import torch.nn.functional as F
from tqdm import tqdm
from ogb.nodeproppred import PygNodePropPredDataset, Evaluator
",6
"        self.num_layers = num_layers

        self.convs = torch.nn.ModuleList()
",6
"        # `train_loader` computes the k-hop neighborhood of a batch of nodes,
        # and returns, for each layer, a bipartite graph object, holding the
        # bipartite edges `edge_index`, the index `e_id` of the original edges,
        # and the size/shape `size` of the bipartite graph.
",6
"        # Target nodes are also included in the source nodes so that one can
        # easily apply skip-connections or add self-loops.
        for i, (edge_index, _, size) in enumerate(adjs):
            x_target = x[:size[1]]  # Target nodes are always placed first.
            x = self.convs[i]((x, x_target), edge_index)
",6
"                x = F.relu(x)
                x = F.dropout(x, p=0.5, training=self.training)
        return x.log_softmax(dim=-1)

    def inference(self, x_all):
",6
"def train(epoch):
    model.train()

    pbar = tqdm(total=train_idx.size(0))
",6
"    loss = total_loss / len(train_loader)
    approx_acc = total_correct / train_idx.size(0)
",6
"        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)
",6
"        self.lin0 = torch.nn.Linear(dataset.num_features, dim)

        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))
        self.conv = NNConv(dim, dim, nn, aggr='mean')
        self.gru = GRU(dim, dim)
",6
"
",6
"        out = self.lin2(out)
        return out.view(-1)
",6
"
",6
"                                                       factor=0.7, patience=5,
                                                       min_lr=0.00001)


",6
"        test_error = test(test_loader)
        best_val_error = val_error

    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '
",6
"          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))
import os.path as osp

",6
"from torch_geometric.datasets import ModelNet
import torch_geometric.transforms as T
from torch_geometric.data import DataLoader
from torch_geometric.nn import DynamicEdgeConv, global_max_pool

",6
"        out = model(data)
        loss = F.nll_loss(out, data.y)
",6
"import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
",6
"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
",6
"optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)

",6
"        loss_all += data.num_graphs * loss.item()
",6
"    loss = train(epoch)
    train_acc = test(train_loader)
    test_acc = test(test_loader)
    print('Epoch: {:03d}, Loss: {:.5f}, Train Acc: {:.5f}, Test Acc: {:.5f}'.
",6
"import torch_geometric.transforms as T
from torch_geometric.nn import SplineConv, global_mean_pool, DataParallel

path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'MNIST')
",6
"dataset = MNISTSuperpixels(path, transform=T.Cartesian()).shuffle()
loader = DataListLoader(dataset, batch_size=1024, shuffle=True)
",6
"    def forward(self, data):
        print('Inside Model:  num graphs: {}, device: {}'.format(
            data.num_graphs, data.batch.device))
",6
"    loss.backward()
    optimizer.step()
import os.path as osp

",6
"                                     completeness_score)
from sklearn.manifold import TSNE
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
",6
"dataset = Planetoid(path, dataset, T.NormalizeFeatures())
data = dataset.get(0)
",6
"
data.train_mask = data.val_mask = data.test_mask = None
data = train_test_split_edges(data)

",6
"        x = F.relu(self.lin2(x))
",6
"                              out_channels=32)
model = ARGVA(encoder, discriminator)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"    loss = model.recon_loss(z, data.train_pos_edge_index)
",6
"@torch.no_grad()
def plot_points(colors):
    model.eval()
    z = model.encode(data.x, data.train_pos_edge_index)
",6
"colors = [
    '#ffc0cb', '#bada55', '#008080', '#420420', '#7fe5f0', '#065535', '#ffd700'
]
plot_points(colors)
",6
"import os.path as osp
from math import ceil

",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'PROTEINS')
dataset = TUDataset(path, name='PROTEINS').shuffle()
average_nodes = int(dataset.data.x.size(0) / len(dataset))
n = (len(dataset) + 9) // 10
",6
"class Net(torch.nn.Module):
",6
"
",6
"
        x = self.conv3(x, adj)
",6
"        return F.log_softmax(x, dim=-1), mc1 + mc2, o1 + o2
",6
"    model.train()
    loss_all = 0

",6
"    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
",6
"    return loss_all / len(train_dataset)


@torch.no_grad()
def test(loader):
",6
"    model.eval()
    correct = 0
",6
"        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()

    return loss, correct / len(loader.dataset)

",6
"    print('Epoch: {:03d}, '
          'Train Loss: {:.3f}, Train Acc: {:.3f}, '
          'Val Loss: {:.3f}, Val Acc: {:.3f}, '
          'Test Loss: {:.3f}, Test Acc: {:.3f}'.format(epoch, train_loss,
",6
"import torch
import torch.nn as nn
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv, DeepGraphInfomax
",6
"dataset = 'Cora'
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
dataset = Planetoid(path, dataset)


",6
"class Encoder(nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super(Encoder, self).__init__()
        self.conv = GCNConv(in_channels, hidden_channels, cached=True)
",6
"

",6
"
",6
"import torch_geometric.transforms as T
",6
"    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)
",6
"    loss = F.nll_loss(log_logits[data.train_mask], data.y[data.train_mask])
",6
"
explainer = GNNExplainer(model, epochs=200)
node_idx = 10
node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)
ax, G = explainer.visualize_subgraph(node_idx, edge_index, edge_mask, y=data.y)
",6
"
import argparse
import torch
import torch.nn.functional as F
",6
"assert args.model in ['GAE', 'VGAE']
assert args.dataset in ['Cora', 'CiteSeer', 'PubMed']
kwargs = {'GAE': GAE, 'VGAE': VGAE}
",6
"
",6
"            self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)
",6
"            self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)
            self.conv_logvar = GCNConv(2 * out_channels, out_channels,
",6
"data.train_mask = data.val_mask = data.test_mask = data.y = None
data = train_test_split_edges(data)
x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

",6
"    optimizer.step()


def test(pos_edge_index, neg_edge_index):
    model.eval()
",6
"        out, attn_loss, _ = model(data)
        loss = ((out - data.y).pow(2) + 100 * attn_loss).mean()
        loss.backward()
        total_loss += loss.item() * data.num_graphs
",6
"               epoch, loss, train_acc, val_acc, test_acc1, test_acc2,
               test_acc3, train_ratio, val_ratio, test_ratio))
",6
"        accs.append(acc)
    return accs


best_val_acc = test_acc = 0
",6
"from torch_geometric.datasets import FAUST
import torch_geometric.transforms as T
",6
"from torch_geometric.data import DataLoader
from torch_geometric.nn import SplineConv

path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'FAUST')
",6
"pre_transform = T.Compose([T.FaceToEdge(), T.Constant(value=1)])
train_dataset = FAUST(path, True, T.Cartesian(), pre_transform)
",6
"test_dataset = FAUST(path, False, T.Cartesian(), pre_transform)
train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)
",6
"d = train_dataset[0]
",6
"        self.conv1 = SplineConv(1, 32, dim=3, kernel_size=5, aggr='add')
        self.conv2 = SplineConv(32, 64, dim=3, kernel_size=5, aggr='add')
        self.conv3 = SplineConv(64, 64, dim=3, kernel_size=5, aggr='add')
",6
"        self.conv4 = SplineConv(64, 64, dim=3, kernel_size=5, aggr='add')
        self.conv5 = SplineConv(64, 64, dim=3, kernel_size=5, aggr='add')
        self.conv6 = SplineConv(64, 64, dim=3, kernel_size=5, aggr='add')
        self.lin1 = torch.nn.Linear(64, 256)
        self.lin2 = torch.nn.Linear(256, d.num_nodes)
",6
"
    def forward(self, data):
        x, edge_index, pseudo = data.x, data.edge_index, data.edge_attr
        x = F.elu(self.conv1(x, edge_index, pseudo))
",6
"        return F.log_softmax(x, dim=1)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"
",6
"    test_acc = test()
    print('Epoch: {:02d}, Test: {:.4f}'.format(epoch, test_acc))
import os.path as osp
",6
"import torch_geometric.transforms as T
from torch_geometric.nn import GCNConv, ChebConv  # noqa

parser = argparse.ArgumentParser()
",6
"
class Net(torch.nn.Module):
    def __init__(self):
",6
"                             normalize=not args.use_gdc)
        # self.conv1 = ChebConv(data.num_features, 16, K=2)
        # self.conv2 = ChebConv(16, data.num_features, K=2)

",6
"        self.reg_params = self.conv1.parameters()
        self.non_reg_params = self.conv2.parameters()

",6
"@torch.no_grad()
def test():
",6
"
best_val_acc = test_acc = 0
for epoch in range(1, 201):
    train()
    train_acc, val_acc, tmp_test_acc = test()
",6
"    train()
    log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'
",6
"    print(log.format(epoch, *test()))
import os.path as osp
",6
"from tqdm import tqdm
from torch_geometric.datasets import QM9
",6
"    def __call__(self, data):
        dist = (data.pos.view(-1, 1, 3) - data.pos.view(1, -1, 3)).norm(dim=-1)
        dist.fill_diagonal_(float('inf'))
        mask = dist <= args.cutoff
        data.edge_index = mask.nonzero().t()
",6
"
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'QM9')
dataset = QM9(path, transform=MyTransform()).shuffle()
",6
"train_dataset = dataset[:110000]
val_dataset = dataset[110000:120000]
",6
"
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = DimeNet(in_channels=dataset.num_node_features, hidden_channels=128,
                out_channels=1, num_blocks=6, num_bilinear=8, num_spherical=7,
",6
"        optimizer.step()

        total_loss += loss.item() * data.num_graphs
        pbar.set_description(f'Loss: {loss:.4f}')
",6
"    for data in loader:
        data = data.to(device)
        out = model(data.x, data.pos, data.edge_index, data.batch)
        total_mae += (out.squeeze(-1) - data.y).abs().sum().item()
",6
"

best_val_mae = test_mae = float('inf')
for epoch in range(1, 501):
",6
"        return x


",6
"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
",6
"    ys, preds = [], []
    for data in loader:
        ys.append(data.y)
        with torch.no_grad():
            out = model(data.x.to(device), data.edge_index.to(device))
",6
"from torch_geometric.nn import GraphUNet
from torch_geometric.utils import dropout_adj

",6
"dataset = 'Cora'
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
",6
"                                    num_nodes=data.num_nodes,
                                    training=self.training)
        x = F.dropout(data.x, p=0.92, training=self.training)

        x = self.unet(x, edge_index)
",6
"        accs.append(acc)
    return accs

",6
"    if val_acc > best_val_acc:
        best_val_acc = val_acc
        test_acc = tmp_test_acc
",6
"        cluster = graclus(data.edge_index, weight, data.x.size(0))
        x, batch = max_pool_x(cluster, data.x, data.batch)

        x = global_mean_pool(x, batch)
        x = F.elu(self.fc1(x))
",6
"

def train(epoch):
    model.train()
",6
"        optimizer.step()


def test():
    model.eval()
",6
"    train(epoch)
    test_acc = test()
    print('Epoch: {:02d}, Test: {:.4f}'.format(epoch, test_acc))
",6
"import torch
",6
"from torch_geometric.datasets import Reddit
from torch_geometric.data import ClusterData, ClusterLoader, NeighborSampler
",6
"from torch_geometric.nn import SAGEConv

dataset = Reddit('../data/Reddit')
",6
"            if i != len(self.convs) - 1:
                x = F.relu(x)
                x = F.dropout(x, p=0.5, training=self.training)
        return F.log_softmax(x, dim=-1)

",6
"    def inference(self, x_all):
        pbar = tqdm(total=x_all.size(0) * len(self.convs))
        pbar.set_description('Evaluating')

",6
"                edge_index, _, size = adj.to(device)
                x = x_all[n_id].to(device)
                x_target = x[:size[1]]
                x = conv((x, x_target), edge_index)
                if i != len(self.convs) - 1:
",6
"
",6
"        total_nodes += nodes

    return total_loss / total_nodes
",6
"    y_pred = out.argmax(dim=-1)

    accs = []
    for mask in [data.train_mask, data.val_mask, data.test_mask]:
",6
"dataset = TUDataset(path, name='PROTEINS')
dataset = dataset.shuffle()
n = len(dataset) // 10
",6
"train_loader = DataLoader(train_dataset, batch_size=60)


",6
"        self.lin2 = torch.nn.Linear(128, 64)
        self.lin3 = torch.nn.Linear(64, dataset.num_classes)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
",6
"optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)


",6
"        optimizer.zero_grad()
",6
"    return correct / len(loader.dataset)


for epoch in range(1, 201):
    loss = train(epoch)
",6
"import os.path as osp

import torch
",6
"data.edge_attr = 1. / degree(col, data.num_nodes)[col]  # Norm by in-degree.

loader = GraphSAINTRandomWalkSampler(data, batch_size=6000, walk_length=2,
                                     num_steps=5, sample_coverage=1000,
                                     save_dir=dataset.processed_dir,
",6
"                                     num_workers=4)
",6
"        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))
",6
"        x = torch.cat([x1, x2, x3], dim=-1)
        x = self.lin(x)
        return x.log_softmax(dim=-1)
",6
"    model.train()
",6
"
def train_full():
    model.train()
    model.set_aggr('mean')

",6
"    accs = test()
    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, '
          f'Val: {accs[1]:.4f}, Test: {accs[2]:.4f}')
import os.path as osp
",6
"transform = T.Compose([
    T.RandomTranslate(0.01),
",6
"    T.RandomRotate(15, axis=1),
    T.RandomRotate(15, axis=2)
",6
"])
pre_transform = T.NormalizeScale()
train_dataset = ShapeNet(path, category, split='trainval', transform=transform,
                         pre_transform=pre_transform)
",6
"                          num_workers=6)
",6
"class FPModule(torch.nn.Module):
    def __init__(self, k, nn):
        super(FPModule, self).__init__()
        self.k = k
",6
"        self.nn = nn

    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):
        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)
",6
"        if x_skip is not None:
            x = torch.cat([x, x_skip], dim=1)
        x = self.nn(x)
",6
"        self.fp1_module = FPModule(3, MLP([128 + 3, 128, 128, 128]))
",6
"        sa2_out = self.sa2_module(*sa1_out)
",6
"
        fp3_out = self.fp3_module(*sa3_out, *sa2_out)
        fp2_out = self.fp2_module(*fp3_out, *sa1_out)
        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)
",6
"
",6
"        x = self.lin3(x)
        return F.log_softmax(x, dim=-1)
",6
"        out = model(data)
        loss = F.nll_loss(out, data.y)
        loss.backward()
",6
"    total_loss = 0
    for i, (pos_rw, neg_rw) in enumerate(loader):
        optimizer.zero_grad()
        loss = model.loss(pos_rw.to(device), neg_rw.to(device))
",6
"
        if (i + 1) % eval_steps == 0:
",6
"
    z = model('author', batch=data.y_index_dict['author'])
    y = data.y_dict['author']

    perm = torch.randperm(z.size(0))
",6
"import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
import torch_geometric.transforms as T
from torch_geometric.nn import SplineConv
",6
"
class Net(torch.nn.Module):
    def __init__(self):
",6
"        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index, edge_attr)
        return F.log_softmax(x, dim=1)

",6
"    optimizer.step()


",6
"
name = 'MUTAG'
path = osp.join(
    osp.dirname(osp.realpath(__file__)), '..', 'data', 'Entities', name)
",6
"        self.conv1 = RGCNConv(
            data.num_nodes, 16, dataset.num_relations, num_bases=30)
        self.conv2 = RGCNConv(
",6
"    def forward(self, edge_index, edge_type, edge_norm):
",6
"        x = self.conv2(x, edge_index, edge_type)
",6
"    return acc


for epoch in range(1, 51):
    train()
",6
"
import torch
import torch.nn.functional as F
from torch_geometric.datasets import ICEWS18, GDELT  # noqa
from torch_geometric.data import DataLoader
",6
"from torch_geometric.nn.models.re_net import RENet

seq_len = 10

# Load the dataset and precompute history objects.
",6
"train_dataset = ICEWS18(path, pre_transform=RENet.pre_transform(seq_len))
test_dataset = ICEWS18(path, split='test')
",6
"
",6
"model = RENet(
",6
"    hidden_channels=200,
    seq_len=seq_len,
    dropout=0.5,
).to(device)
optimizer = torch.optim.Adam(
",6
"    # Train model via multi-class classification against the corresponding
",6
"def test(loader):
",6
"    # Compute Mean Reciprocal Rank (MRR) and Hits@1/3/10.
    result = torch.tensor([0, 0, 0, 0], dtype=torch.float)
",6
"    train()
    results = test(test_loader)
    print('Epoch: {:02d}, MRR: {:.4f}, Hits@1: {:.4f}, Hits@3: {:.4f}, '
",6
"loss_op = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.005)


def train():
",6
"
import torch
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score
",6
"    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = GCNConv(dataset.num_features, 128)
        self.conv2 = GCNConv(128, 64)

",6
"    link_labels = torch.zeros(pos_edge_index.size(1) +
",6
"
    link_logits = model(pos_edge_index, neg_edge_index)
    link_labels = get_link_labels(pos_edge_index, neg_edge_index)

    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)
",6
"        pos_edge_index, neg_edge_index = [
            index for _, index in data(""{}_pos_edge_index"".format(prefix),
                                       ""{}_neg_edge_index"".format(prefix))
",6
"pos_edge_indices, neg_edge_indices = [], []
for data in dataset:
    pos_edge_indices.append(data.edge_index[:, data.edge_attr > 0])
",6
"train_pos_edge_index, test_pos_edge_index = model.split_edges(pos_edge_index)
train_neg_edge_index, test_neg_edge_index = model.split_edges(neg_edge_index)
",6
"    loss.backward()
",6
"path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)
dataset = Planetoid(path, dataset)
data = dataset[0]
data.train_mask = data.val_mask = data.test_mask = None

",6
"

data = gen_uniform_20_20_60_split(data)

",6
"        super(Net, self).__init__()
        self.hidden_channels = hidden_channels
",6
"
    def reset_parameters(self):
        self.lin1.reset_parameters()
        for conv in self.convs:
            conv.reset_parameters()
",6
"    in_channels=dataset.num_features,
    hidden_channels=128,
    out_channels=dataset.num_classes,
",6
"    loss.backward()
    optimizer.step()
",6
"transform = T.Cartesian(cat=False)
",6
"train_dataset = MNISTSuperpixels(path, True, transform=transform)
test_dataset = MNISTSuperpixels(path, False, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
",6
"
        nn2 = nn.Sequential(nn.Linear(2, 25), nn.ReLU(), nn.Linear(25, 2048))
        self.conv2 = NNConv(32, 64, nn2, aggr='mean')

",6
"        self.fc2 = torch.nn.Linear(128, d.num_classes)

    def forward(self, data):
        data.x = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr))
",6
"        weight = normalized_cut_2d(data.edge_index, data.pos)
        cluster = graclus(data.edge_index, weight, data.x.size(0))
        data.edge_attr = None
        data = max_pool(cluster, data, transform=transform)

",6
"        x = F.elu(self.fc1(x))
        x = F.dropout(x, training=self.training)
",6
"        return F.log_softmax(self.fc2(x), dim=1)


",6
"        for param_group in optimizer.param_groups:
",6
"            param_group['lr'] = 0.001

    if epoch == 26:
",6
"dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())
data = dataset[0]


",6
"
    def forward(self):
        x = F.dropout(data.x, training=self.training)
        x = F.relu(self.lin1(x))
",6
"        x = self.lin2(x)
",6
"
def test():
    model.eval()
    logits, accs = model(), []
",6
"        data.x = F.elu(self.conv2(data.x, data.edge_index, data.edge_attr))
        cluster = voxel_grid(data.pos, data.batch, size=7, start=0, end=28)
        data.edge_attr = None
        data = max_pool(cluster, data, transform=transform)
",6
"
        x = x.view(-1, self.fc1.weight.size(1))
        x = F.elu(self.fc1(x))
        x = F.dropout(x, training=self.training)
",6
"        x = self.fc2(x)
",6
"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)
",6
"    print('Epoch: {:02d}, Test: {:.4f}'.format(epoch, test_acc))
import os.path as osp

import torch
import torch.nn.functional as F
",6
"        return F.log_softmax(x, dim=1)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model, data = Net().to(device), data.to(device)
",6
"    writer.add_scalar('Accuracy/test', test_acc, epoch)
import os.path as osp

import torch
",6
"dataset = QM9(path)

",6
"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

for target in range(12):
    model, datasets = SchNet.from_qm9_pretrained(path, dataset, target)
",6
"    mae = torch.cat(maes, dim=0)
    print(f'Target: {target:02d}, MAE: {mae.mean():.5f} Â± {mae.std():.5f}')
",6
"
",6
"    def __call__(self, data):
        return data.num_nodes <= max_nodes

",6
"
path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data',
",6
"            self.lin = None

",6
"        x = x.view(-1, num_channels)
        x = getattr(self, 'bn{}'.format(i))(x)
",6
"        num_nodes = ceil(0.25 * num_nodes)
        self.gnn2_pool = GNN(3 * 64, 64, num_nodes)
        self.gnn2_embed = GNN(3 * 64, 64, 64, lin=False)

        self.gnn3_embed = GNN(3 * 64, 64, 64, lin=False)
",6
"        x = x.mean(dim=1)
        x = F.relu(self.lin1(x))
",6
"
    for data in loader:
        data = data.to(device)
        pred = model(data.x, data.adj, data.mask)[0].max(dim=1)[1]
",6
"        correct += pred.eq(data.y.view(-1)).sum().item()
    return correct / len(loader.dataset)


",6
"best_val_acc = test_acc = 0
for epoch in range(1, 151):
    train_loss = train(epoch)
    val_acc = test(val_loader)
",6
"    def __init__(self):
        super(Net, self).__init__()

",6
"        self.lins = torch.nn.ModuleList()
        for _ in range(K + 1):
            self.lins.append(Linear(dataset.num_node_features, 1024))
        self.lin = Linear((K + 1) * 1024, dataset.num_classes)

",6
"    def forward(self):
",6
"    model.train()
    optimizer.zero_grad()
    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()
    optimizer.step()
",6
"
class GAT(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,
                 heads):
        super(GAT, self).__init__()
",6
"        self.convs.append(GATConv(dataset.num_features, hidden_channels,
",6
"                                  heads))
        for _ in range(num_layers - 2):
            self.convs.append(
",6
"
        self.skips = torch.nn.ModuleList()
        self.skips.append(Lin(dataset.num_features, hidden_channels * heads))
        for _ in range(num_layers - 2):
",6
"        # and the size/shape `size` of the bipartite graph.
        # Target nodes are also included in the source nodes so that one can
",6
"
    def inference(self, x_all):
        pbar = tqdm(total=x_all.size(0) * self.num_layers)
        pbar.set_description('Evaluating')

",6
"
                if i != self.num_layers - 1:
                    x = F.elu(x)
                xs.append(x.cpu())

",6
"x = data.x.to(device)
",6
"
    total_loss = total_correct = 0
    for batch_size, n_id, adjs in train_loader:
        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.
",6
"        adjs = [adj.to(device) for adj in adjs]
",6
"        loss.backward()
        optimizer.step()

        total_loss += float(loss)
        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())
",6
"
    pbar.close()
",6
"    approx_acc = total_correct / train_idx.size(0)

",6
"
            if val_acc > best_val_acc:
",6
"                best_val_acc = val_acc
                final_test_acc = test_acc
",6
"test_acc = torch.tensor(test_accs)
print('============================')
print(f'Final Test: {test_acc.mean():.4f} Â± {test_acc.std():.4f}')
import os.path as osp
",6
"    def __call__(self, data):
        data.attn = torch.softmax(data.x, dim=0).flatten()
        data.x = None
        return data

",6
"train_loader = DataLoader(dataset[:30000], batch_size=60, shuffle=True)
",6
"    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch

",6
"

def train(epoch):
",6
"
    total_loss = 0
    for data in train_loader:
        data = data.to(device)
",6
"        loss = ((out - data.y).pow(2) + 100 * attn_loss).mean()
        loss.backward()
        total_loss += loss.item() * data.num_graphs
        optimizer.step()
",6
"
    return total_loss / len(train_loader.dataset)
",6
"

def test(loader):
    model.eval()
",6
"    return torch.cat(corrects, dim=0), total_ratio / len(loader)

",6
"
    train_acc = train_correct.sum().item() / train_correct.size(0)
    val_acc = val_correct.sum().item() / val_correct.size(0)
",6
"               train_ratio, val_ratio, test_ratio))
import datetime
import sphinx_rtd_theme
import doctest
",6
"    'sphinx.ext.napoleon',
    'sphinx.ext.viewcode',
",6
"    'sphinx.ext.githubpages',
]
",6
"
version = torch_geometric.__version__
release = torch_geometric.__version__

",6
